From dwinsemius at comcast.net  Tue Oct  1 00:06:51 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 30 Sep 2013 15:06:51 -0700
Subject: [R] multilevel analysis
In-Reply-To: <CAM8BP_mZ5qoLL9kLtQV3K8RojsLxXdfYK=Jsf83hGcOayrKGWQ@mail.gmail.com>
References: <CAM8BP_mZ5qoLL9kLtQV3K8RojsLxXdfYK=Jsf83hGcOayrKGWQ@mail.gmail.com>
Message-ID: <FD724C3C-0744-47BD-916C-5509B2544775@comcast.net>


On Sep 30, 2013, at 2:50 PM, srecko joksimovic wrote:

> I have an example of multilevel analysis with 3 levels, but data are
> non-normally distributed. In case of normal distribution, I would perform
> multilevel linear analysis using lme function, but what should I do in case
> of non-normal distribution?
> 

But normal distribution is not a requirement for linear models. Please review your theory.

> thanks,
> Srecko
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From sreckojoksimovic at gmail.com  Tue Oct  1 00:22:18 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Mon, 30 Sep 2013 15:22:18 -0700
Subject: [R] multilevel analysis
In-Reply-To: <FD724C3C-0744-47BD-916C-5509B2544775@comcast.net>
References: <CAM8BP_mZ5qoLL9kLtQV3K8RojsLxXdfYK=Jsf83hGcOayrKGWQ@mail.gmail.com>
	<FD724C3C-0744-47BD-916C-5509B2544775@comcast.net>
Message-ID: <CAM8BP_=di+dSYMSq0K=wxZfx3wZ-QOgq1nz=oAE2euA9pZn4Aw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/b78fcef6/attachment.pl>

From djnordlund at frontier.com  Tue Oct  1 02:04:28 2013
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Mon, 30 Sep 2013 17:04:28 -0700
Subject: [R] multilevel analysis
In-Reply-To: <CAM8BP_=di+dSYMSq0K=wxZfx3wZ-QOgq1nz=oAE2euA9pZn4Aw@mail.gmail.com>
References: <CAM8BP_mZ5qoLL9kLtQV3K8RojsLxXdfYK=Jsf83hGcOayrKGWQ@mail.gmail.com><FD724C3C-0744-47BD-916C-5509B2544775@comcast.net>
	<CAM8BP_=di+dSYMSq0K=wxZfx3wZ-QOgq1nz=oAE2euA9pZn4Aw@mail.gmail.com>
Message-ID: <38C0EAD9610B4E30B2BF44F21598AF99@Aragorn>



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of srecko joksimovic
> Sent: Monday, September 30, 2013 3:22 PM
> To: David Winsemius
> Cc: R help
> Subject: Re: [R] multilevel analysis
> 
> I thought so, but then I found this:
> "Normality
> 
> The assumption of normality states that the error terms at every level of
> the model are normally distributed"
> 
> maybe I misinterpreted something.
> 

Yes, error terms (i.e. residuals), not your raw data, should be normally distributed if you are going to conduct significance tests that rely on the assumption of normality.  But as David said, the assumption of normality (in any form) is not necessary for estimating linear models.

Dan


> 
> On Mon, Sep 30, 2013 at 3:06 PM, David Winsemius
> <dwinsemius at comcast.net>wrote:
> 
> >
> > On Sep 30, 2013, at 2:50 PM, srecko joksimovic wrote:
> >
> > > I have an example of multilevel analysis with 3 levels, but data are
> > > non-normally distributed. In case of normal distribution, I would
> perform
> > > multilevel linear analysis using lme function, but what should I do in
> > case
> > > of non-normal distribution?
> > >
> >
> > But normal distribution is not a requirement for linear models. Please
> > review your theory.
> >
> > > thanks,
> > > Srecko
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
>

Daniel Nordlund
Bothell, WA USA
 


From dwinsemius at comcast.net  Tue Oct  1 02:14:15 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 30 Sep 2013 17:14:15 -0700
Subject: [R] multilevel analysis
In-Reply-To: <CAM8BP_=di+dSYMSq0K=wxZfx3wZ-QOgq1nz=oAE2euA9pZn4Aw@mail.gmail.com>
References: <CAM8BP_mZ5qoLL9kLtQV3K8RojsLxXdfYK=Jsf83hGcOayrKGWQ@mail.gmail.com>
	<FD724C3C-0744-47BD-916C-5509B2544775@comcast.net>
	<CAM8BP_=di+dSYMSq0K=wxZfx3wZ-QOgq1nz=oAE2euA9pZn4Aw@mail.gmail.com>
Message-ID: <0FA8827B-0ED7-44EF-9DBA-09D3334C9A5D@comcast.net>


On Sep 30, 2013, at 3:22 PM, srecko joksimovic wrote:

> I thought so, but then I found this:
> "Normality
> The assumption of normality states that the error terms at every level of the model are normally distributed"
> maybe I misinterpreted something. 

Notice that it is the _error_terms_ that are to be normally distributed, not the data itself. One might even infer that "normally distrited data might be suspect because the "correct distribution should be a mixture of normals. Since the errors never are going to fit on a straight line on a QQ plot, the real question is "how far from Normal" and what the impact might be on the quantities being estimated.

-- 
David.
> 
> 
> On Mon, Sep 30, 2013 at 3:06 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> On Sep 30, 2013, at 2:50 PM, srecko joksimovic wrote:
> 
> > I have an example of multilevel analysis with 3 levels, but data are
> > non-normally distributed. In case of normal distribution, I would perform
> > multilevel linear analysis using lme function, but what should I do in case
> > of non-normal distribution?
> >
> 
> But normal distribution is not a requirement for linear models. Please review your theory.
> 
> > thanks,
> > Srecko
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From sreckojoksimovic at gmail.com  Tue Oct  1 03:25:53 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Mon, 30 Sep 2013 18:25:53 -0700
Subject: [R] multilevel analysis
In-Reply-To: <0FA8827B-0ED7-44EF-9DBA-09D3334C9A5D@comcast.net>
References: <CAM8BP_mZ5qoLL9kLtQV3K8RojsLxXdfYK=Jsf83hGcOayrKGWQ@mail.gmail.com>
	<FD724C3C-0744-47BD-916C-5509B2544775@comcast.net>
	<CAM8BP_=di+dSYMSq0K=wxZfx3wZ-QOgq1nz=oAE2euA9pZn4Aw@mail.gmail.com>
	<0FA8827B-0ED7-44EF-9DBA-09D3334C9A5D@comcast.net>
Message-ID: <CAM8BP_m78mNzmQv_oqivGPv_EBipScv0jdcr4AVqWO9jFbe+ug@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130930/b3bfca7e/attachment.pl>

From xchen at dr.com  Tue Oct  1 00:17:53 2013
From: xchen at dr.com (Xianwen Chen)
Date: Tue, 01 Oct 2013 00:17:53 +0200
Subject: [R] [sm.density.compare] scale up y-axis and additional line type
Message-ID: <5249F891.5000001@dr.com>

Dear fellows,

The two questions are on sm.density.compare(). I compare kernel density 
estimates of two arrays of data.

I'd like to scale up y-axis so that I can show better the differences in 
y values. English is not my first language so I'll try to explain it. I 
would like to stretch y-axis a bit longer but not to change the range of 
y values. How can I do this?

Second, I'm using a solid line for one array of date and a dashed line 
for another array of data. The difference is not easy to see, because 
the two curves are approximate to some degree. Is it possible to plot 
one array of data with *, instead of dash?

Thanks!

Kind regards,

Xianwen


From smartpink111 at yahoo.com  Tue Oct  1 05:52:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 30 Sep 2013 20:52:38 -0700 (PDT)
Subject: [R] Reshape problem
Message-ID: <1380599558.8220.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this helps.
dat1<- structure(list(trialnumber = 1:9, Control = c(0L, 1L, 0L, 0L, 
1L, 0L, 1L, 0L, 0L), HC = c(0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 1L
), LC = c(1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L), pleasantness = c(3L, 
3L, 2L, 2L, 3L, 4L, 3L, 3L, 2L)), .Names = c("trialnumber", "Control", 
"HC", "LC", "pleasantness"), class = "data.frame", row.names = c(NA, 
-9L))

library(reshape2)

res<- melt(dat1,id.vars=c("trialnumber","pleasantness"))
colnames(res)[3]<- "type"

A.K.


I have an experiment where people get to see a picture which is a 
control, HC or LC picture. They then have to rate its pleasantness. 

I tried to change the data so that I would get one column (for example "type" with 3 groups) instead of the 3 separate columns. 

Can anyone help me out? 
Thanks 

trialnumber	 ? Control	HC	LC	pleasantness 
? ? ? ? 1	 ? 0 ? ? ? ? ? ?0	1	3 
? ? ? ? 2	 ? 1	 ? ? ? ?0	0	3 
? ? ? ? 3	 ? 0 ? ? ? ? ? 1	0	2 
? ? ? ? 4	 ? 0 ? ? ? ? ? 1	0	2 
? ? ? ? 5	 ? 1	 ? ? ? ?0	0	3 
? ? ? ? 6	 ? 0	 ? ? ? ?0	1	4 
? ? ? ? 7	 ? 1	 ? ? ? ?0	0	3 
? ? ? ? 8	 ? 0	 ? ? ? ?0	1	3 
? ? ? ? 9	 ? 0	 ? ? ? ?1	0	2


From jim at bitwrit.com.au  Tue Oct  1 06:00:50 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 01 Oct 2013 14:00:50 +1000
Subject: [R] [sm.density.compare] scale up y-axis and additional line
 type
In-Reply-To: <5249F891.5000001@dr.com>
References: <5249F891.5000001@dr.com>
Message-ID: <524A48F2.8030205@bitwrit.com.au>

On 10/01/2013 08:17 AM, Xianwen Chen wrote:
> Dear fellows,
>
> The two questions are on sm.density.compare(). I compare kernel density
> estimates of two arrays of data.
>
> I'd like to scale up y-axis so that I can show better the differences in
> y values. English is not my first language so I'll try to explain it. I
> would like to stretch y-axis a bit longer but not to change the range of
> y values. How can I do this?
>
> Second, I'm using a solid line for one array of date and a dashed line
> for another array of data. The difference is not easy to see, because
> the two curves are approximate to some degree. Is it possible to plot
> one array of data with *, instead of dash?
>
Hi Xianwen,
You can specify the width and height of the graphics device:

dev.new(height=9)

OR

png("myplot.png",height=600)

or some other type of device. This will produce a plot that is 
noticeably higher than it is wide. For the second question, try:

lty=3,lwd=3

Jim


From forzacch at gmail.com  Tue Oct  1 06:59:38 2013
From: forzacch at gmail.com (ChungHoon Cho)
Date: Tue, 1 Oct 2013 13:59:38 +0900
Subject: [R] Can I use R for implementing GBI?
Message-ID: <000001cebe63$0b23fa30$216bee90$@com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/a49e8c0b/attachment.pl>

From smartpink111 at yahoo.com  Tue Oct  1 05:20:27 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 30 Sep 2013 20:20:27 -0700 (PDT)
Subject: [R] Apply function to do pairwise calculation
In-Reply-To: <CALwvZ4Vzeex8+=W4j6D6+8GAAuOvbBXZ2X0ahPhFsDsSwENuhA@mail.gmail.com>
References: <CALwvZ4Vzeex8+=W4j6D6+8GAAuOvbBXZ2X0ahPhFsDsSwENuhA@mail.gmail.com>
Message-ID: <1380597627.29928.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Not sure if this helps.

#example dataset
set.seed(24)
?mat1<-matrix(sample(1:50,20*20,replace=TRUE),ncol=20)
? set.seed(49)
?colnames(mat1)<- sample(rep(LETTERS[1:4],5),20)
?rownames(mat1)<- colnames(mat1)

mat2<-combn(LETTERS[1:4],2)
res<- sapply(split(mat2,col(mat2)),function(x){ x1<-mat1[rownames(mat1)%in% x[1],colnames(mat1)%in%x[1]]; x2<- mat1[rownames(mat1)%in% x[2],colnames(mat1)%in% x[2]];avecor(x1,x2)})
names(res)<- apply(mat2,2,paste,collapse="")
res
#?????? AB??????? AC??????? AD??????? BC??????? BD??????? CD 
#0.4806725 0.4505996 0.6160342 0.5567617 0.3721136 0.4480448 

A.K.




----- Original Message -----
From: Amanda Li <amandali at uchicago.edu>
To: r-help at r-project.org
Cc: 
Sent: Monday, September 30, 2013 10:55 AM
Subject: [R] Apply function to do pairwise calculation

Hello,

I want to do pairwise calculation, but I am not sure how to do so.

i.e. I have a correlation matrix M 200*200. Namely colnames(M)=rownames(M).
In addition, colnames(M) is one of A, B, C, D. I want to first sort the
matrix M into 16 modules according to colnames and rownames, and then apply:
avecor <- function(x,y) {
z <- (sum(cor(x,y)*cor(x,y))/length(cor(x,y)))^0.5
return(z)
}

So as to calculate the average correlation between A,B; A,C; A,D; B,C; B,D;
C,D.

Thanks in advance for your help!

Best,
Amanda

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ana.arjona at northwestern.edu  Tue Oct  1 07:34:56 2013
From: ana.arjona at northwestern.edu (Ana Arjona)
Date: Tue, 1 Oct 2013 05:34:56 +0000
Subject: [R] Nested and non-nested factors in a panel using lmer
In-Reply-To: <CE6B4C62.2E238%ana.arjona@northwestern.edu>
Message-ID: <CE6FB27A.35AA4%ana.arjona@northwestern.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/d822c751/attachment.pl>

From tobi_gebetsberger at gmx.at  Tue Oct  1 09:53:37 2013
From: tobi_gebetsberger at gmx.at (happyR)
Date: Tue, 1 Oct 2013 00:53:37 -0700 (PDT)
Subject: [R] barplot - easy for experienced, difficult for me
In-Reply-To: <CAN5YmCHtTOUjZim6HnsKJtd96Hg6uityGnJX-dv_wOqZkGiS_A@mail.gmail.com>
References: <1380546308922-4677251.post@n4.nabble.com>
	<CAN5YmCHtTOUjZim6HnsKJtd96Hg6uityGnJX-dv_wOqZkGiS_A@mail.gmail.com>
Message-ID: <trinity-184a24a1-7397-4200-b08b-ad691a37721e-1380613954933@3capp-gmx-bs11>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/d7b1ffa0/attachment.pl>

From jim at bitwrit.com.au  Tue Oct  1 10:36:00 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 01 Oct 2013 18:36:00 +1000
Subject: [R] barplot - easy for experienced, difficult for me
In-Reply-To: <trinity-184a24a1-7397-4200-b08b-ad691a37721e-1380613954933@3capp-gmx-bs11>
References: <1380546308922-4677251.post@n4.nabble.com>	<CAN5YmCHtTOUjZim6HnsKJtd96Hg6uityGnJX-dv_wOqZkGiS_A@mail.gmail.com>
	<trinity-184a24a1-7397-4200-b08b-ad691a37721e-1380613954933@3capp-gmx-bs11>
Message-ID: <524A8970.2080808@bitwrit.com.au>

On 10/01/2013 05:53 PM, happyR wrote:
> ...
> Do you think it might have sth to do with how&nbsp;my dataset is built up?
>
Yes, happyR, it is definitely your dataset. I think this one is far 
superior:

spineless<-matrix(c(6,3,9,5,4,6,7,1,3,8,7,6,10,4,3,7,6,11),
  nrow=2)
slnames<-c("Bug","Slug","Wasp","Tick","Nit","Worm",
  "Gnat","Midge","Fly")
barpos<-barplot(spineless,col=c("yellow","purple"),
  main="Spineless pests",xlab="Critter",ylab="Peskiness",
  beside=TRUE)
legend(7,10,c("Here","There"),fill=c("yellow","purple"))
library(plotrix)
staxlab(1,at=colSums(barpos)/2,labels=slnames)

Lobachevsky


From r.otasuke at gmail.com  Tue Oct  1 12:28:32 2013
From: r.otasuke at gmail.com (Kunio Takezawa)
Date: Tue, 1 Oct 2013 19:28:32 +0900
Subject: [R] A new book "Learning Regression Analysis by Simulation
	(Springer)"
Message-ID: <CALeE8o5Ys3REfA6A5xRu-D0Td1a6dY6hJi3oiabFRpb3WDEWbg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/1b1d8df4/attachment.pl>

From jrkrideau at inbox.com  Tue Oct  1 13:53:09 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 1 Oct 2013 03:53:09 -0800
Subject: [R] barplot - easy for experienced, difficult for me
In-Reply-To: <1380546308922-4677251.post@n4.nabble.com>
Message-ID: <C70E0AC401C.000011ADjrkrideau@inbox.com>

There is a slight problem with that second link. It is the same as the first. 

It is easier to sent the data (or a decent sample of it) in the email by using dput.  Type ?dput for more information.  Essentially you just do dput(myfile) copy it and paste it into the email. This allow the reader tp see exactly the data set that you are using.  I think Jim (Lobachevski?) Lemon has given you an answer. 

While this link is not directly linked to your request for other ideas of how to plot the data it may give you some ideas.  I tend to like the point + error bar graph but I am no expert and obviously it depends on your data.

And another off-topic matter, you might want to have a look at the ggplot2 package for graphing. Very different from base graphics but powerful.

Here is a different approach with bar plots using ggplot2 and Jim's data that I have shamelessly appropriated.  It is a more complicated approach as I had to reshape the data into a from that ggplot2 would accept. The data is supplied in dput format.

dat1 <-  structure(list(park1 = c(6, 9, 4, 7, 3, 7, 10, 3, 6), park2 = c(3, 
5, 6, 1, 8, 6, 4, 7, 11), bugs = structure(c(1L, 6L, 8L, 7L, 
5L, 9L, 3L, 4L, 2L), .Label = c("Bug", "Fly", "Gnat", "Midge", 
"Nit", "Slug", "Tick", "Wasp", "Worm"), class = "factor")), .Names = c("park1", 
"park2", "bugs"), row.names = c(NA, -9L), class = "data.frame")


mdat  <-  melt(dat1, id.var = "bugs")  # reshape data using the rehape2 command melt
names(mdat) <-  c("Invertibrate", "park", "Count")

ggplot(mdat, aes(Invertibrate, Count, fill  = park)) + 
  geom_bar(stat="identity") + facet_grid(park ~ .) +
  theme(legend.position="none")


John Kane
Kingston ON Canada


> -----Original Message-----
> From: tobi_gebetsberger at gmx.at
> Sent: Mon, 30 Sep 2013 06:05:09 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] barplot - easy for experienced, difficult for me
> 
> hey guys,
> 
> I wanna make a simple barplot, looking like this excel graph:
> <http://r.789695.n4.nabble.com/file/n4677251/barplot_invertebrates.jpg>
> 
> my data set includes 9 groups of invertebrates (x-axes) and total number
> (y-axes) from two different parks (1 and 2).
> 
> my data-set looks like that:
> 
> <http://r.789695.n4.nabble.com/file/n4677251/barplot_invertebrates.jpg>
> 
> I'm a bloody beginner and happy for your help.
> 
> ps: if you know what other graph could be interesting to make out of this
> very simple data, go ahead and let me know!
>

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From dimitri.liakhovitski at gmail.com  Tue Oct  1 16:41:31 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 1 Oct 2013 10:41:31 -0400
Subject: [R] glm's for a logistic regression - no warnings?
Message-ID: <CAN2xGJapNsusCHFiJ9S+uJC4zOTqa_-cSZaSqt8DMjSGAjFYMg@mail.gmail.com>

I have this weird data set with 2 predictors and one dependent variable -
attached.

predictor1 has all zeros except for one 1.
I am runnning a simple logistic regression:

temp<-read.csv("x data for reg224.csv")
myreg <- glm(dv~predictor1+predictor2,data=temp,
             family=binomial("logit"))
myreg$coef2

Everything runs fine and I get the coefficients - and the fact that there
is only one 1 on one of the predictors doesn't seem to cause any problems.

However, when I run the same regression in SAS, I get warnings:
 Model Convergence Status  Quasi-complete separation of data points
detected.

Warning: The maximum likelihood estimate may not exist.
Warning: The LOGISTIC procedure continues in spite of the above warning.
Results shown are based on the last maximum likelihood iteration. Validity
of the model fit is questionable.

And the coefficients SAS produces are quite different from mine.

I know I'll probably get screamed at because it's not a pure R question -
but any idea why R is not giving me any warnings in such a situation?
Does it have no problems with ML estimation in this case?

Thanks a lot!


-- 
Dimitri Liakhovitski

From gunter.berton at gene.com  Tue Oct  1 16:49:35 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 1 Oct 2013 07:49:35 -0700
Subject: [R] glm's for a logistic regression - no warnings?
In-Reply-To: <CAN2xGJapNsusCHFiJ9S+uJC4zOTqa_-cSZaSqt8DMjSGAjFYMg@mail.gmail.com>
References: <CAN2xGJapNsusCHFiJ9S+uJC4zOTqa_-cSZaSqt8DMjSGAjFYMg@mail.gmail.com>
Message-ID: <CACk-te31zbnzOufp_EPuEQWVi5SO5ACKKzZXWEiyMRZ=5rBrhw@mail.gmail.com>

google "complete separation logistic"

-- Bert

On Tue, Oct 1, 2013 at 7:41 AM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> I have this weird data set with 2 predictors and one dependent variable -
> attached.
>
> predictor1 has all zeros except for one 1.
> I am runnning a simple logistic regression:
>
> temp<-read.csv("x data for reg224.csv")
> myreg <- glm(dv~predictor1+predictor2,data=temp,
>              family=binomial("logit"))
> myreg$coef2
>
> Everything runs fine and I get the coefficients - and the fact that there
> is only one 1 on one of the predictors doesn't seem to cause any problems.
>
> However, when I run the same regression in SAS, I get warnings:
>  Model Convergence Status  Quasi-complete separation of data points
> detected.
>
> Warning: The maximum likelihood estimate may not exist.
> Warning: The LOGISTIC procedure continues in spite of the above warning.
> Results shown are based on the last maximum likelihood iteration. Validity
> of the model fit is questionable.
>
> And the coefficients SAS produces are quite different from mine.
>
> I know I'll probably get screamed at because it's not a pure R question -
> but any idea why R is not giving me any warnings in such a situation?
> Does it have no problems with ML estimation in this case?
>
> Thanks a lot!
>
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From Xochitl.Cormon at ifremer.fr  Tue Oct  1 16:52:36 2013
From: Xochitl.Cormon at ifremer.fr (Xochitl CORMON)
Date: Tue, 01 Oct 2013 16:52:36 +0200
Subject: [R] glm's for a logistic regression - no warnings?
In-Reply-To: <CAN2xGJapNsusCHFiJ9S+uJC4zOTqa_-cSZaSqt8DMjSGAjFYMg@mail.gmail.com>
References: <CAN2xGJapNsusCHFiJ9S+uJC4zOTqa_-cSZaSqt8DMjSGAjFYMg@mail.gmail.com>
Message-ID: <524AE1B4.5040600@ifremer.fr>

Hi,

I did have warning messages about convergence issues using binomial GLM 
with logit link with my data in the past....

Do you detect separation using the function separation.detection{brglm}?

Regards,

Xochitl C.


<>< <>< <>< <><

Xochitl CORMON
+33 (0)3 21 99 56 84

Doctorante en sciences halieutiques
PhD student in fishery sciences

<>< <>< <>< <><

IFREMER
Centre Manche Mer du Nord
150 quai Gambetta
62200 Boulogne-sur-Mer

<>< <>< <>< <><



Le 01/10/2013 16:41, Dimitri Liakhovitski a ?crit :
> I have this weird data set with 2 predictors and one dependent variable -
> attached.
>
> predictor1 has all zeros except for one 1.
> I am runnning a simple logistic regression:
>
> temp<-read.csv("x data for reg224.csv")
> myreg<- glm(dv~predictor1+predictor2,data=temp,
>               family=binomial("logit"))
> myreg$coef2
>
> Everything runs fine and I get the coefficients - and the fact that there
> is only one 1 on one of the predictors doesn't seem to cause any problems.
>
> However, when I run the same regression in SAS, I get warnings:
>   Model Convergence Status  Quasi-complete separation of data points
> detected.
>
> Warning: The maximum likelihood estimate may not exist.
> Warning: The LOGISTIC procedure continues in spite of the above warning.
> Results shown are based on the last maximum likelihood iteration. Validity
> of the model fit is questionable.
>
> And the coefficients SAS produces are quite different from mine.
>
> I know I'll probably get screamed at because it's not a pure R question -
> but any idea why R is not giving me any warnings in such a situation?
> Does it have no problems with ML estimation in this case?
>
> Thanks a lot!
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From anon.r.user at gmail.com  Tue Oct  1 17:01:07 2013
From: anon.r.user at gmail.com (john doe)
Date: Tue, 1 Oct 2013 08:01:07 -0700
Subject: [R] Understanding classes in R
In-Reply-To: <CANVKczOxUFFkH3mBCjWiBcqA1iMjZKfA291eJrmS44nxdxJjkw@mail.gmail.com>
References: <1e60753163cd48f9bf82ca92af41fac9@EX-0-HT0.lancs.local>
	<CANVKczOxUFFkH3mBCjWiBcqA1iMjZKfA291eJrmS44nxdxJjkw@mail.gmail.com>
Message-ID: <CAFWa_VsgRr05CCy=8XDMXODg5jvufJZER67yxfFeuL+NNa+gqQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/992dbbfc/attachment.pl>

From dimitri.liakhovitski at gmail.com  Tue Oct  1 17:29:24 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 1 Oct 2013 11:29:24 -0400
Subject: [R] glm's for a logistic regression - no warnings?
In-Reply-To: <524AE1B4.5040600@ifremer.fr>
References: <CAN2xGJapNsusCHFiJ9S+uJC4zOTqa_-cSZaSqt8DMjSGAjFYMg@mail.gmail.com>
	<524AE1B4.5040600@ifremer.fr>
Message-ID: <CAN2xGJbgAB87K2s5UbHwd+cgCmc3P96zqjz5rCQskE79NMZzyw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/ad12fc90/attachment.pl>

From Xochitl.Cormon at ifremer.fr  Tue Oct  1 17:34:18 2013
From: Xochitl.Cormon at ifremer.fr (Xochitl CORMON)
Date: Tue, 01 Oct 2013 17:34:18 +0200
Subject: [R] glm's for a logistic regression - no warnings?
In-Reply-To: <CAN2xGJbgAB87K2s5UbHwd+cgCmc3P96zqjz5rCQskE79NMZzyw@mail.gmail.com>
References: <CAN2xGJapNsusCHFiJ9S+uJC4zOTqa_-cSZaSqt8DMjSGAjFYMg@mail.gmail.com>
	<524AE1B4.5040600@ifremer.fr>
	<CAN2xGJbgAB87K2s5UbHwd+cgCmc3P96zqjz5rCQskE79NMZzyw@mail.gmail.com>
Message-ID: <524AEB7A.2000301@ifremer.fr>




<>< <>< <>< <><

Xochitl CORMON

Le 01/10/2013 17:29, Dimitri Liakhovitski a ?crit :
> Thank you very much, Bert - it's very helpful.
> This post says that R issues a warning:
>
> Warning message:
> *glm.fit: fitted probabilities numerically 0 or 1 occurred
> *

Actually the warning message should be something like:
glm.fit: algorithm did not converge

The fist warning is not fatal contrary to the second one.. 
(https://stat.ethz.ch/pipermail/r-help/2012-March/307352.html)

> However, in my case there is no warning. How could I detect complete
> separation in my data? I need to be able to flag it in my function.

As said use the separation dectection function: separation.detection{brglm}

> Thank you very much!
> Dimitri
>
>
>
> On Tue, Oct 1, 2013 at 10:52 AM, Xochitl CORMON
> <Xochitl.Cormon at ifremer.fr <mailto:Xochitl.Cormon at ifremer.fr>> wrote:
>
>     Hi,
>
>     I did have warning messages about convergence issues using binomial
>     GLM with logit link with my data in the past....
>
>     Do you detect separation using the function separation.detection{brglm}?
>
>     Regards,
>
>     Xochitl C.
>
>
>     <>< <>< <>< <><
>
>     Xochitl CORMON
>     +33 (0)3 21 99 56 84 <tel:%2B33%20%280%293%2021%2099%2056%2084>
>
>     Doctorante en sciences halieutiques
>     PhD student in fishery sciences
>
>     <>< <>< <>< <><
>
>     IFREMER
>     Centre Manche Mer du Nord
>     150 quai Gambetta
>     62200 Boulogne-sur-Mer
>
>     <>< <>< <>< <><
>
>
>
>     Le 01/10/2013 16:41, Dimitri Liakhovitski a ?crit :
>
>         I have this weird data set with 2 predictors and one dependent
>         variable -
>         attached.
>
>         predictor1 has all zeros except for one 1.
>         I am runnning a simple logistic regression:
>
>         temp<-read.csv("x data for reg224.csv")
>         myreg<- glm(dv~predictor1+predictor2,__data=temp,
>                        family=binomial("logit"))
>         myreg$coef2
>
>         Everything runs fine and I get the coefficients - and the fact
>         that there
>         is only one 1 on one of the predictors doesn't seem to cause any
>         problems.
>
>         However, when I run the same regression in SAS, I get warnings:
>            Model Convergence Status  Quasi-complete separation of data
>         points
>         detected.
>
>         Warning: The maximum likelihood estimate may not exist.
>         Warning: The LOGISTIC procedure continues in spite of the above
>         warning.
>         Results shown are based on the last maximum likelihood
>         iteration. Validity
>         of the model fit is questionable.
>
>         And the coefficients SAS produces are quite different from mine.
>
>         I know I'll probably get screamed at because it's not a pure R
>         question -
>         but any idea why R is not giving me any warnings in such a
>         situation?
>         Does it have no problems with ML estimation in this case?
>
>         Thanks a lot!
>
>
>
>
>
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>     ________________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/__listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/__posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Dimitri Liakhovitski


From dimitri.liakhovitski at gmail.com  Tue Oct  1 17:41:17 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 1 Oct 2013 11:41:17 -0400
Subject: [R] glm's for a logistic regression - no warnings?
In-Reply-To: <524AEB7A.2000301@ifremer.fr>
References: <CAN2xGJapNsusCHFiJ9S+uJC4zOTqa_-cSZaSqt8DMjSGAjFYMg@mail.gmail.com>
	<524AE1B4.5040600@ifremer.fr>
	<CAN2xGJbgAB87K2s5UbHwd+cgCmc3P96zqjz5rCQskE79NMZzyw@mail.gmail.com>
	<524AEB7A.2000301@ifremer.fr>
Message-ID: <CAN2xGJYjRc=6aBacFqFswXQmJJ0LzxFVRpVjGofqaL3RDPLsVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/930753d1/attachment.pl>

From Xochitl.Cormon at ifremer.fr  Tue Oct  1 17:47:20 2013
From: Xochitl.Cormon at ifremer.fr (Xochitl CORMON)
Date: Tue, 01 Oct 2013 17:47:20 +0200
Subject: [R] glm's for a logistic regression - no warnings?
In-Reply-To: <CAN2xGJYjRc=6aBacFqFswXQmJJ0LzxFVRpVjGofqaL3RDPLsVg@mail.gmail.com>
References: <CAN2xGJapNsusCHFiJ9S+uJC4zOTqa_-cSZaSqt8DMjSGAjFYMg@mail.gmail.com>
	<524AE1B4.5040600@ifremer.fr>
	<CAN2xGJbgAB87K2s5UbHwd+cgCmc3P96zqjz5rCQskE79NMZzyw@mail.gmail.com>
	<524AEB7A.2000301@ifremer.fr>
	<CAN2xGJYjRc=6aBacFqFswXQmJJ0LzxFVRpVjGofqaL3RDPLsVg@mail.gmail.com>
Message-ID: <524AEE88.4060806@ifremer.fr>


Le 01/10/2013 17:41, Dimitri Liakhovitski a ?crit :
> Ah, thank you very much - I did not understand first brglm was the name
> of a package!
> Dimitri

My bad!

If there is separation you should see it in the way the coefficient 
diverges from one (it's pretty exponential). You can increase the number 
of step if you see nothing but in my opinion 30 steps are enough.

There is several packages to handle separated data, brglm and logistf 
are the two I recall.

Good luck!

Xochitl C.

>
> On Tue, Oct 1, 2013 at 11:34 AM, Xochitl CORMON
> <Xochitl.Cormon at ifremer.fr <mailto:Xochitl.Cormon at ifremer.fr>> wrote:
>
>
>
>
>     <>< <>< <>< <><
>
>     Xochitl CORMON
>
>     Le 01/10/2013 17:29, Dimitri Liakhovitski a ?crit :
>
>         Thank you very much, Bert - it's very helpful.
>         This post says that R issues a warning:
>
>         Warning message:
>         *glm.fit: fitted probabilities numerically 0 or 1 occurred
>         *
>
>
>     Actually the warning message should be something like:
>     glm.fit: algorithm did not converge
>
>     The fist warning is not fatal contrary to the second one..
>     (https://stat.ethz.ch/__pipermail/r-help/2012-March/__307352.html
>     <https://stat.ethz.ch/pipermail/r-help/2012-March/307352.html>)
>
>
>         However, in my case there is no warning. How could I detect complete
>         separation in my data? I need to be able to flag it in my function.
>
>
>     As said use the separation dectection function:
>     separation.detection{brglm}
>
>         Thank you very much!
>         Dimitri
>
>
>
>         On Tue, Oct 1, 2013 at 10:52 AM, Xochitl CORMON
>         <Xochitl.Cormon at ifremer.fr <mailto:Xochitl.Cormon at ifremer.fr>
>         <mailto:Xochitl.Cormon at __ifremer.fr
>         <mailto:Xochitl.Cormon at ifremer.fr>>> wrote:
>
>              Hi,
>
>              I did have warning messages about convergence issues using
>         binomial
>              GLM with logit link with my data in the past....
>
>              Do you detect separation using the function
>         separation.detection{brglm}?
>
>              Regards,
>
>              Xochitl C.
>
>
>         <>< <>< <>< <><
>
>              Xochitl CORMON
>         +33 (0)3 21 99 56 84 <tel:%2B33%20%280%293%2021%2099%2056%2084>
>         <tel:%2B33%20%280%293%2021%__2099%2056%2084>
>
>
>              Doctorante en sciences halieutiques
>              PhD student in fishery sciences
>
>         <>< <>< <>< <><
>
>              IFREMER
>              Centre Manche Mer du Nord
>              150 quai Gambetta
>              62200 Boulogne-sur-Mer
>
>         <>< <>< <>< <><
>
>
>
>              Le 01/10/2013 16:41, Dimitri Liakhovitski a ?crit :
>
>                  I have this weird data set with 2 predictors and one
>         dependent
>                  variable -
>                  attached.
>
>                  predictor1 has all zeros except for one 1.
>                  I am runnning a simple logistic regression:
>
>                  temp<-read.csv("x data for reg224.csv")
>                  myreg<- glm(dv~predictor1+predictor2,____data=temp,
>
>                                 family=binomial("logit"))
>                  myreg$coef2
>
>                  Everything runs fine and I get the coefficients - and
>         the fact
>                  that there
>                  is only one 1 on one of the predictors doesn't seem to
>         cause any
>                  problems.
>
>                  However, when I run the same regression in SAS, I get
>         warnings:
>                     Model Convergence Status  Quasi-complete separation
>         of data
>                  points
>                  detected.
>
>                  Warning: The maximum likelihood estimate may not exist.
>                  Warning: The LOGISTIC procedure continues in spite of
>         the above
>                  warning.
>                  Results shown are based on the last maximum likelihood
>                  iteration. Validity
>                  of the model fit is questionable.
>
>                  And the coefficients SAS produces are quite different
>         from mine.
>
>                  I know I'll probably get screamed at because it's not a
>         pure R
>                  question -
>                  but any idea why R is not giving me any warnings in such a
>                  situation?
>                  Does it have no problems with ML estimation in this case?
>
>                  Thanks a lot!
>
>
>
>
>
>                  __________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>         mailing list
>         https://stat.ethz.ch/mailman/____listinfo/r-help
>         <https://stat.ethz.ch/mailman/__listinfo/r-help>
>
>         <https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>                  PLEASE do read the posting guide
>         http://www.R-project.org/____posting-guide.html
>         <http://www.R-project.org/__posting-guide.html>
>
>         <http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>>
>                  and provide commented, minimal, self-contained,
>         reproducible code.
>
>
>              __________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>         mailing list
>         https://stat.ethz.ch/mailman/____listinfo/r-help
>         <https://stat.ethz.ch/mailman/__listinfo/r-help>
>
>         <https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>              PLEASE do read the posting guide
>         http://www.R-project.org/____posting-guide.html
>         <http://www.R-project.org/__posting-guide.html>
>
>         <http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>>
>              and provide commented, minimal, self-contained,
>         reproducible code.
>
>
>
>
>         --
>         Dimitri Liakhovitski
>
>
>
>
> --
> Dimitri Liakhovitski


From hnorpois at gmail.com  Tue Oct  1 14:06:32 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Tue, 1 Oct 2013 14:06:32 +0200
Subject: [R] leveneTest - output
Message-ID: <CAKyZeBvF6u_Zyf-7byTh3wqO5EnBHRLRW5zVLAtVdK1VzTYSNg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/43ba3476/attachment.pl>

From tobi_gebetsberger at gmx.at  Tue Oct  1 11:32:29 2013
From: tobi_gebetsberger at gmx.at (happyR)
Date: Tue, 1 Oct 2013 02:32:29 -0700 (PDT)
Subject: [R] barplot - easy for experienced, difficult for me
In-Reply-To: <524A8970.2080808@bitwrit.com.au>
References: <1380546308922-4677251.post@n4.nabble.com>
	<CAN5YmCHtTOUjZim6HnsKJtd96Hg6uityGnJX-dv_wOqZkGiS_A@mail.gmail.com>
	<trinity-184a24a1-7397-4200-b08b-ad691a37721e-1380613954933@3capp-gmx-bs11>
	<524A8970.2080808@bitwrit.com.au>
Message-ID: <trinity-63721ddb-b912-45ed-bc55-5566df27e548-1380619905175@3capp-gmx-bs11>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/cb07bc1c/attachment.pl>

From khatriumesh88 at gmail.com  Tue Oct  1 12:06:36 2013
From: khatriumesh88 at gmail.com (umesh khatri)
Date: Tue, 1 Oct 2013 15:36:36 +0530
Subject: [R] Tex-mining in R
Message-ID: <CAJQybkmEqxvJ85TUa0_1r=7TG1=k=zq311m3-eEkHvRgyCv5JQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/960d7892/attachment.pl>

From randolph_steven_d at lilly.com  Tue Oct  1 13:22:42 2013
From: randolph_steven_d at lilly.com (Steven Dwayne Randolph)
Date: Tue, 1 Oct 2013 11:22:42 +0000
Subject: [R] 'XML' package cannot be un-zipped or un-tar'd"
Message-ID: <66C71547284587479F8009E05C07DA9704F6FF71@USTLMLLYC107.RF.lilly.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/4d10e3f3/attachment.pl>

From rolf.kemper at renesas.com  Tue Oct  1 15:24:30 2013
From: rolf.kemper at renesas.com (rolf.kemper at renesas.com)
Date: Tue, 01 Oct 2013 15:24:30 +0200
Subject: [R] Basic help on  DF creation row by row
Message-ID: <OF9951AA9A.6A0838B5-ONC1257BF7.0048BD2C-C1257BF7.0049A79E@eu.necel.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/a843c813/attachment.pl>

From sobom.some at univ-fcomte.fr  Tue Oct  1 16:13:04 2013
From: sobom.some at univ-fcomte.fr (Matthew)
Date: Tue, 1 Oct 2013 07:13:04 -0700 (PDT)
Subject: [R] Save intermediate result in a same file
Message-ID: <1380636784723-4677350.post@n4.nabble.com>

Hello everybody,

i have to save a 100 iteration computation in a file every 5 iterations
until the end.
I first give a vector A  of 100 elements for the 100 iterations and i want
to update A every 5 iterations.

I use "save" but it doesn't work. 
Someone has an idea,  i need a help

Cheers.





--
View this message in context: http://r.789695.n4.nabble.com/Save-intermediate-result-in-a-same-file-tp4677350.html
Sent from the R help mailing list archive at Nabble.com.


From matilderosa at dgs.pt  Tue Oct  1 15:55:59 2013
From: matilderosa at dgs.pt (=?iso-8859-1?Q?Matilde_de_Ara=FAjo_e_S=E1_Valente_Rosa?=)
Date: Tue, 1 Oct 2013 14:55:59 +0100
Subject: [R] Question ANACOR-HELP
Message-ID: <8A4318FEED71CA4FA9A5FF86BC92E10C038019CC@davinci.dgs.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/06177c27/attachment.pl>

From jfox at mcmaster.ca  Tue Oct  1 20:02:51 2013
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 1 Oct 2013 14:02:51 -0400
Subject: [R] leveneTest - output
In-Reply-To: <CAKyZeBvF6u_Zyf-7byTh3wqO5EnBHRLRW5zVLAtVdK1VzTYSNg@mail.gmail.com>
References: <CAKyZeBvF6u_Zyf-7byTh3wqO5EnBHRLRW5zVLAtVdK1VzTYSNg@mail.gmail.com>
Message-ID: <007501cebed0$72331b30$56995190$@mcmaster.ca>

Dear Hermann,

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Hermann Norpois
> Sent: Tuesday, October 01, 2013 8:07 AM
> To: r-help
> Subject: [R] leveneTest - output
> 
> Hello,
> 
> I have a question concerning the output of leveneTest. I don't
> understand
> the "7" in my output

That's the denominator df for F.

Best,
 John

> 
> Levene's Test for Homogeneity of Variance (center = median)
>       Df F value Pr(>F)
> group  2  0.0173 0.9829
>        7        # Where does this number come from?
> 
> Thanks.
> Hermann
> 
> 
> > res
>    group.ID    qtrait
> 1         0 6462.3288
> 2         0  816.7808
> 3         0 6031.3356
> 4         0 1013.5274
> 5         0 1517.2500
> 6         1 1585.2740
> 7         1 2481.6781
> 8         1 8871.5753
> 9         2 4913.5274
> 10        2  833.7329
> > ltest <- leveneTest (qtrait~group.ID, res)
> > ltest
> Levene's Test for Homogeneity of Variance (center = median)
>       Df F value Pr(>F)
> group  2  0.0173 0.9829
>        7
> > dput (res)
> structure(list(group.ID = structure(c(1L, 1L, 1L, 1L, 1L, 2L,
> 2L, 2L, 3L, 3L), .Label = c("0", "1", "2"), class = "factor"),
>     qtrait = c(6462.32876712329, 816.780821917808, 6031.33561643836,
>     1013.52739726027, 1517.25, 1585.27397260274, 2481.67808219178,
>     8871.57534246575, 4913.52739726027, 833.732876712329)), .Names =
> c("group.ID",
> "qtrait"), row.names = c(NA, -10L), class = "data.frame")
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Tue Oct  1 20:10:08 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 1 Oct 2013 14:10:08 -0400
Subject: [R] Tex-mining in R
In-Reply-To: <CAJQybkmEqxvJ85TUa0_1r=7TG1=k=zq311m3-eEkHvRgyCv5JQ@mail.gmail.com>
References: <CAJQybkmEqxvJ85TUa0_1r=7TG1=k=zq311m3-eEkHvRgyCv5JQ@mail.gmail.com>
Message-ID: <CA+vqiLFx9Dxbq8UqgNREehbFJ7sL+CO46PHP7NNE-EHqKNp3Tg@mail.gmail.com>

Do you know about task views? Try
http://cran.r-project.org/web/views/NaturalLanguageProcessing.html

Best,
Ista

On Tue, Oct 1, 2013 at 6:06 AM, umesh khatri <khatriumesh88 at gmail.com> wrote:
> Can anyone please guide me on any useful links or resource regarding text
> mining in R?
>
> --
> Regards
> Umesh Khatri
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From scfriant at wisc.edu  Tue Oct  1 20:15:08 2013
From: scfriant at wisc.edu (Sagan Friant)
Date: Tue, 1 Oct 2013 13:15:08 -0500
Subject: [R] over dispersion plot
Message-ID: <CA+tD=u5QpOVmdwD1noYw=4KxxrcVwcKAAB_S99vAvH26wxLAzg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/9917780b/attachment.pl>

From smartpink111 at yahoo.com  Tue Oct  1 20:19:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 1 Oct 2013 11:19:45 -0700 (PDT)
Subject: [R] Basic help on  DF creation row by row
In-Reply-To: <OF9951AA9A.6A0838B5-ONC1257BF7.0048BD2C-C1257BF7.0049A79E@eu.necel.com>
References: <OF9951AA9A.6A0838B5-ONC1257BF7.0048BD2C-C1257BF7.0049A79E@eu.necel.com>
Message-ID: <1380651585.67493.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,

Not sure if this helps.

deviceSummary <- data.frame(item = character(0) ,? value = numeric(0) , unit = character(0) ,stringsAsFactors=FALSE)
newlst<-? list("primitiveSpace",1.1,"mm2")
deviceSummary[nrow(deviceSummary)+1,]<- newlst

newlst2<-? list("primitiveSpace",2.2,"mm2")
?deviceSummary[nrow(deviceSummary)+1,]<- newlst2


?str(deviceSummary)
#'data.frame':??? 2 obs. of? 3 variables:
# $ item : chr? "primitiveSpace" "primitiveSpace"
# $ value: num? 1.1 2.2
# $ unit : chr? "mm2" "mm2"
?deviceSummary
#??????????? item value unit
#1 primitiveSpace?? 1.1? mm2
#2 primitiveSpace?? 2.2? mm2

A.K.

----- Original Message -----
From: "rolf.kemper at renesas.com" <rolf.kemper at renesas.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, October 1, 2013 9:24 AM
Subject: [R] Basic help on  DF creation row by row



Dear Experts

I'm very new to R and after some days or reading and testing? I tried to make my first small application (and failed ...)
In general I would like to work with sqldf , ggplot2 to create some graphical output.

At present I got stuck with this:

PROG #############################################################################
deviceSummary <- data.frame(item = character(0) ,? value = numeric(0) , unit = character(0) )
print ( sapply(deviceSummary, class))

newRow <- c("primitiveSpace", 1.1 , "mm2")
deviceSummary <-rbind(deviceSummary , newRow )
print(deviceSummary)

newRow <- c("primitiveCellSpace", 2.2 , "mm2")
deviceSummary <-rbind(deviceSummary , newRow )
print(deviceSummary )

OUTPUT ############################################################################
? ? item? ?  value? ? ? unit
"factor" "numeric"? "factor"
? X.primitiveSpace. X.1.1. X.mm2.
1? ? primitiveSpace? ? 1.1? ? mm2
? X.primitiveSpace. X.1.1. X.mm2.
1? ? primitiveSpace? ? 1.1? ? mm2
2? ? ? ? ? ? ? <NA>?  <NA>? ? mm2
Warning messages:
1: In `[<-.factor`(`*tmp*`, ri, value = "primitiveCellSpace") :
? invalid factor level, NA generated
2: In `[<-.factor`(`*tmp*`, ri, value = "2.2") :
? invalid factor level, NA generated

Inserting the first record went fine , but the next one will fail as you can see.
Repeating only the first one (value1.1) went fine.

May be my imagination of DF is totally wrong. Hope someone can guide me.

Thanks a lot

Rolf




Rolf? Kemper, Manager, Mixed Signal Design, Networking, Renesas Electronics Europe GmbH, , Arcadiastr. 10, 40472, Duesseldorf, Germany,? Phone:+49 211
6503-1475, Fax:+49 211 6503-1540, mailto:Rolf.Kemper at renesas.com, http://www.renesas.eu

This message is intended only for the use of the address...{{dropped:24}}

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ruipbarradas at sapo.pt  Tue Oct  1 20:38:16 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 01 Oct 2013 19:38:16 +0100
Subject: [R] Basic help on  DF creation row by row
In-Reply-To: <OF9951AA9A.6A0838B5-ONC1257BF7.0048BD2C-C1257BF7.0049A79E@eu.necel.com>
References: <OF9951AA9A.6A0838B5-ONC1257BF7.0048BD2C-C1257BF7.0049A79E@eu.necel.com>
Message-ID: <524B1698.1070107@sapo.pt>

Hello,

The main problem is in the way you form newRow. You can't mix data 
classes in a vector created with c(), so all its elements become 
characters, the least common denominator:

newRow <- c("primitiveSpace", 1.1 , "mm2")
newRow
[1] "primitiveSpace" "1.1"            "mm2"


Then when you rbind it with the data frame, they are all converted to 
factors. This is because the default behavior is to have the option 
stringsAsFactors set to TRUE. Try to check it:

options()$stringsAsFactors  # TRUE


Now, each of those factors was created with only one level, so when you 
try to assign something different to them, with the second rbind, NAs 
are generated.

The correct way would be something like the following.


newRow <- data.frame(item = "primitiveSpace", value = 1.1 , unit = "mm2")
deviceSummary <- rbind(deviceSummary , newRow )
print(deviceSummary)
str(deviceSummary)  # to check what you have

newRow <- data.frame(item = "primitiveCellSpace", value = 2.2 , unit = 
"mm2")
deviceSummary <-rbind(deviceSummary , newRow )
print(deviceSummary )


Hope this helps,

Rui Barradas

Em 01-10-2013 14:24, rolf.kemper at renesas.com escreveu:
>
>
> Dear Experts
>
> I'm very new to R and after some days or reading and testing  I tried to make my first small application (and failed ...)
> In general I would like to work with sqldf , ggplot2 to create some graphical output.
>
> At present I got stuck with this:
>
> PROG #############################################################################
> deviceSummary <- data.frame(item = character(0) ,  value = numeric(0) , unit = character(0) )
> print ( sapply(deviceSummary, class))
>
> newRow <- c("primitiveSpace", 1.1 , "mm2")
> deviceSummary <-rbind(deviceSummary , newRow )
> print(deviceSummary)
>
> newRow <- c("primitiveCellSpace", 2.2 , "mm2")
> deviceSummary <-rbind(deviceSummary , newRow )
> print(deviceSummary )
>
> OUTPUT ############################################################################
>      item     value      unit
>   "factor" "numeric"  "factor"
>    X.primitiveSpace. X.1.1. X.mm2.
> 1    primitiveSpace    1.1    mm2
>    X.primitiveSpace. X.1.1. X.mm2.
> 1    primitiveSpace    1.1    mm2
> 2              <NA>   <NA>    mm2
> Warning messages:
> 1: In `[<-.factor`(`*tmp*`, ri, value = "primitiveCellSpace") :
>    invalid factor level, NA generated
> 2: In `[<-.factor`(`*tmp*`, ri, value = "2.2") :
>    invalid factor level, NA generated
>
> Inserting the first record went fine , but the next one will fail as you can see.
> Repeating only the first one (value1.1) went fine.
>
> May be my imagination of DF is totally wrong. Hope someone can guide me.
>
> Thanks a lot
>
> Rolf
>
>
>
>
> Rolf  Kemper, Manager, Mixed Signal Design, Networking, Renesas Electronics Europe GmbH, , Arcadiastr. 10, 40472, Duesseldorf, Germany,  Phone:+49 211
> 6503-1475, Fax:+49 211 6503-1540, mailto:Rolf.Kemper at renesas.com, http://www.renesas.eu
>
> This message is intended only for the use of the address...{{dropped:24}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Tue Oct  1 20:44:01 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 01 Oct 2013 19:44:01 +0100
Subject: [R] leveneTest - output
In-Reply-To: <007501cebed0$72331b30$56995190$@mcmaster.ca>
References: <CAKyZeBvF6u_Zyf-7byTh3wqO5EnBHRLRW5zVLAtVdK1VzTYSNg@mail.gmail.com>
	<007501cebed0$72331b30$56995190$@mcmaster.ca>
Message-ID: <524B17F1.6020501@sapo.pt>

Hello,

Just to add that the value 0.9829 [Pr(>F)] can be checked with

pf(0.0173, df1 = 2, df2 = 7, lower.tail = FALSE)

Rui Barradas

Em 01-10-2013 19:02, John Fox escreveu:
> Dear Hermann,
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Hermann Norpois
>> Sent: Tuesday, October 01, 2013 8:07 AM
>> To: r-help
>> Subject: [R] leveneTest - output
>>
>> Hello,
>>
>> I have a question concerning the output of leveneTest. I don't
>> understand
>> the "7" in my output
>
> That's the denominator df for F.
>
> Best,
>   John
>
>>
>> Levene's Test for Homogeneity of Variance (center = median)
>>        Df F value Pr(>F)
>> group  2  0.0173 0.9829
>>         7        # Where does this number come from?
>>
>> Thanks.
>> Hermann
>>
>>
>>> res
>>     group.ID    qtrait
>> 1         0 6462.3288
>> 2         0  816.7808
>> 3         0 6031.3356
>> 4         0 1013.5274
>> 5         0 1517.2500
>> 6         1 1585.2740
>> 7         1 2481.6781
>> 8         1 8871.5753
>> 9         2 4913.5274
>> 10        2  833.7329
>>> ltest <- leveneTest (qtrait~group.ID, res)
>>> ltest
>> Levene's Test for Homogeneity of Variance (center = median)
>>        Df F value Pr(>F)
>> group  2  0.0173 0.9829
>>         7
>>> dput (res)
>> structure(list(group.ID = structure(c(1L, 1L, 1L, 1L, 1L, 2L,
>> 2L, 2L, 3L, 3L), .Label = c("0", "1", "2"), class = "factor"),
>>      qtrait = c(6462.32876712329, 816.780821917808, 6031.33561643836,
>>      1013.52739726027, 1517.25, 1585.27397260274, 2481.67808219178,
>>      8871.57534246575, 4913.52739726027, 833.732876712329)), .Names =
>> c("group.ID",
>> "qtrait"), row.names = c(NA, -10L), class = "data.frame")
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From carlisle.thacker at gmail.com  Tue Oct  1 20:05:05 2013
From: carlisle.thacker at gmail.com (carlisle thacker)
Date: Tue, 1 Oct 2013 14:05:05 -0400
Subject: [R] can no longer install packages on OSX
Message-ID: <CAAZ8xcmuXX6T4E+j4+xV5PabQuSf3YsVAoFA2=c38kp7U5f2JA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/7e0abfb1/attachment.pl>

From xchen at dr.com  Tue Oct  1 20:43:23 2013
From: xchen at dr.com (Xianwen Chen)
Date: Tue, 01 Oct 2013 20:43:23 +0200
Subject: [R] [sm.density.compare] scale up y-axis and additional line
 type
In-Reply-To: <524A48F2.8030205@bitwrit.com.au>
References: <5249F891.5000001@dr.com> <524A48F2.8030205@bitwrit.com.au>
Message-ID: <524B17CB.9010903@dr.com>

Thanks Jim,

The picture width is adjusted. That was great help! I really appreciate it.

Does lwd mean 'line width'? I'm not exactly sure how that will help. Can 
you please explain the intuition behind it?

Can I also ask another question? My graph is made from 7 plots from 
sm.density.compare(). These 7 plots are put together by:

      par(mfrow=c(4,2))

To make all 7 plots comparable, I specify y- and x-axis ranges. Here is 
the sample code for one of the plots:

     sm.density.compare(
             c(sample_1, sample_2), # sample_1 and sample_2 are two 
vectors, each corresponding to a sample
             rep(1:2, rep(140, 2)),
             lty = c(1, 3),
             lwd = c(1, 3), # This change was made by taking your 
suggestion.
             col = c("black", "black"),
             xlab="Sample",
             xlim=c(-40, 60),
             ylim=c(0, 0.15)
     )

     legend("topright", c("MMNL", "GMNL"), lty = c(1, 3), cex = 1)

Somehow, xlim and ylim do not have an effect. I did not have this 
problem when I was running R in Arch Linux; but now I'm using Debian Linux.

Thanks!

Kind regards,

Xianwen

Jim Lemon wrote:
> On 10/01/2013 08:17 AM, Xianwen Chen wrote:
>> Dear fellows,
>>
>> The two questions are on sm.density.compare(). I compare kernel density
>> estimates of two arrays of data.
>>
>> I'd like to scale up y-axis so that I can show better the differences in
>> y values. English is not my first language so I'll try to explain it. I
>> would like to stretch y-axis a bit longer but not to change the range of
>> y values. How can I do this?
>>
>> Second, I'm using a solid line for one array of date and a dashed line
>> for another array of data. The difference is not easy to see, because
>> the two curves are approximate to some degree. Is it possible to plot
>> one array of data with *, instead of dash?
>>
> Hi Xianwen,
> You can specify the width and height of the graphics device:
>
> dev.new(height=9)
>
> OR
>
> png("myplot.png",height=600)
>
> or some other type of device. This will produce a plot that is 
> noticeably higher than it is wide. For the second question, try:
>
> lty=3,lwd=3
>
> Jim
>


From istazahn at gmail.com  Tue Oct  1 21:26:14 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 1 Oct 2013 15:26:14 -0400
Subject: [R] can no longer install packages on OSX
In-Reply-To: <CAAZ8xcmuXX6T4E+j4+xV5PabQuSf3YsVAoFA2=c38kp7U5f2JA@mail.gmail.com>
References: <CAAZ8xcmuXX6T4E+j4+xV5PabQuSf3YsVAoFA2=c38kp7U5f2JA@mail.gmail.com>
Message-ID: <CA+vqiLFihfW5uxQYf6LnCBkWxbgL4ge3kimHFLArrZqiT2t8PA@mail.gmail.com>

On Tue, Oct 1, 2013 at 2:05 PM, carlisle thacker
<carlisle.thacker at gmail.com> wrote:
> R running on my MacPro under OS X 10.6.8 no longer installs packages.  I
> would greatly appreciate help in sorting this out.
>
> Typically I get the messages like:
>> install.packages("party")
> Warning: unable to access index for repository
> http://software.rc.fas.harvard.edu/mirrors/R/bin/macosx/leopard/contrib/2.13

There is no such mirror. Change it to one of those listed at
http://cran.r-project.org/mirrors.html

Best,
Ista

> Warning message:
> In getDependencies(pkgs, dependencies, available, lib) :
>   package ?party? is not available (for R version 2.13.1)
>
> The repository URL mentioned in the first warning indicates leopard, not
> snow leopard, the name for OS X 10.6.8.  Is this an issue?  If so, what to
> do?
>
> The second message seems to indicate that I might need a different version
> of R.  If so, which?  How to preserve the existing version while checking
> out the new version?
>
> And version seems to indicate darwin9.8.0.  Any idea why?
>> version
>                _
> platform       x86_64-apple-darwin9.8.0
> arch           x86_64
> os             darwin9.8.0
> system         x86_64, darwin9.8.0
> status
> major          2
> minor          13.1
> year           2011
> month          07
> day            08
> svn rev        56322
> language       R
> version.string R version 2.13.1 (2011-07-08)
>
> Otherwise R is currently functioning fine.  I really don't want to screw
> that up.  If there is a fix without installing a new version, I would like
> to try that first.
>
> I've never updated to a newer version, and it's been a while since I
> installed on a mac, so step-by-step instructions are needed.
>
> Thanks,
>
> Carlisle
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Tue Oct  1 21:44:28 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 01 Oct 2013 15:44:28 -0400
Subject: [R] can no longer install packages on OSX
In-Reply-To: <CAAZ8xcmuXX6T4E+j4+xV5PabQuSf3YsVAoFA2=c38kp7U5f2JA@mail.gmail.com>
References: <CAAZ8xcmuXX6T4E+j4+xV5PabQuSf3YsVAoFA2=c38kp7U5f2JA@mail.gmail.com>
Message-ID: <524B261C.7070906@gmail.com>

On 01/10/2013 2:05 PM, carlisle thacker wrote:
> R running on my MacPro under OS X 10.6.8 no longer installs packages.  I
> would greatly appreciate help in sorting this out.
>
> Typically I get the messages like:
> > install.packages("party")
> Warning: unable to access index for repository
> http://software.rc.fas.harvard.edu/mirrors/R/bin/macosx/leopard/contrib/2.13
> Warning message:
> In getDependencies(pkgs, dependencies, available, lib) :
>    package ?party? is not available (for R version 2.13.1)

Version 2.13.1 is very old; you might find that package binaries are not 
maintained for such an old version, and current versions of the packages 
might not work in it. I would update to R 3.0.2.

Duncan Murdoch

>
> The repository URL mentioned in the first warning indicates leopard, not
> snow leopard, the name for OS X 10.6.8.  Is this an issue?  If so, what to
> do?
>
> The second message seems to indicate that I might need a different version
> of R.  If so, which?  How to preserve the existing version while checking
> out the new version?
>
> And version seems to indicate darwin9.8.0.  Any idea why?
> > version
>                 _
> platform       x86_64-apple-darwin9.8.0
> arch           x86_64
> os             darwin9.8.0
> system         x86_64, darwin9.8.0
> status
> major          2
> minor          13.1
> year           2011
> month          07
> day            08
> svn rev        56322
> language       R
> version.string R version 2.13.1 (2011-07-08)
>
> Otherwise R is currently functioning fine.  I really don't want to screw
> that up.  If there is a fix without installing a new version, I would like
> to try that first.
>
> I've never updated to a newer version, and it's been a while since I
> installed on a mac, so step-by-step instructions are needed.
>
> Thanks,
>
> Carlisle
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rolf.turner at xtra.co.nz  Tue Oct  1 22:22:56 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Wed, 02 Oct 2013 09:22:56 +1300
Subject: [R] 'XML' package cannot be un-zipped or un-tar'd"
In-Reply-To: <66C71547284587479F8009E05C07DA9704F6FF71@USTLMLLYC107.RF.lilly.com>
References: <66C71547284587479F8009E05C07DA9704F6FF71@USTLMLLYC107.RF.lilly.com>
Message-ID: <524B2F20.70600@xtra.co.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/a389f586/attachment.pl>

From ebs15242 at gmail.com  Tue Oct  1 22:35:18 2013
From: ebs15242 at gmail.com (Ed Siefker)
Date: Tue, 1 Oct 2013 15:35:18 -0500
Subject: [R] Java requested System.exit(130)
Message-ID: <CALRb-ofvrHg4w0OkaEdm7cTo297r_czhVXmdO6C0GYwp1aPf3w@mail.gmail.com>

I'm used to using ctrl-c to end operations without killing R.  But I've used
xlsx in this session, which loads Java, which apparently intercepts the
ctrl-C.  Accordingly, I hit ctrl-C, R died, and I lost a lot of work.

I did some looking, and found a
thread(http://comments.gmane.org/gmane.comp.lang.r.rosuda.devel/1368)
that says:

"Yes, at least on Sun JVMs you need to add -Xrs java option so the JVM
doesn't steal SIGINT from R (see archives)."

So, how do I actually do that? I'm not running java from the command line,
I'm using "library(xlsx)".  How do I tell R to pass that option to the JVM?
Thanks
-Ed


From jim at bitwrit.com.au  Wed Oct  2 01:07:24 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 02 Oct 2013 09:07:24 +1000
Subject: [R] barplot - easy for experienced, difficult for me
In-Reply-To: <trinity-63721ddb-b912-45ed-bc55-5566df27e548-1380619905175@3capp-gmx-bs11>
References: <1380546308922-4677251.post@n4.nabble.com>	<CAN5YmCHtTOUjZim6HnsKJtd96Hg6uityGnJX-dv_wOqZkGiS_A@mail.gmail.com>	<trinity-184a24a1-7397-4200-b08b-ad691a37721e-1380613954933@3capp-gmx-bs11>	<524A8970.2080808@bitwrit.com.au>
	<trinity-63721ddb-b912-45ed-bc55-5566df27e548-1380619905175@3capp-gmx-bs11>
Message-ID: <524B55AC.1020506@bitwrit.com.au>

On 10/01/2013 07:32 PM, happyR wrote:
> hey lobachevsky - thanks!
>
> but: Error in barplot.default (matrix, col = c(&quot;yellow&quot;,&quot;purple&quot;), beside = TRUE) :
>    &#39;height&#39; must be a vector or a matrix
>
> what to do? :)
>
First, one must always avoid confusing the general case with a specific 
instance. If you were standing by the side of the Coolgardie-Esperance 
Highway, as I once was, trying to thumb a ride across the Nullarbor, it 
would be a crushing disappointment if the driver who pulled over offered 
to take humanity all the way to Ceduna.

You have accomplished something similar in the above example. "matrix" 
is the sort of object that you want to pass to "barplot", not the 
specific matrix named "spineless" that was specially prepared for you. 
You are, in a sense, requesting that poor old "barplot" illustrate the 
function that turns various sorts of things into matrices. Sorry, 
happyR, it just doesn't compute.

Lobachevsky


From robert.b.lynch at gmail.com  Wed Oct  2 03:01:29 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Tue, 1 Oct 2013 18:01:29 -0700
Subject: [R] re-coding variables
Message-ID: <CACYeG1hr4c7ZiaNqtJNyJZd=dnkn6954Xon-tck15xNdctmZAw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/6008cf2a/attachment.pl>

From jim at bitwrit.com.au  Wed Oct  2 03:24:19 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 02 Oct 2013 11:24:19 +1000
Subject: [R] [sm.density.compare] scale up y-axis and additional line
 type
In-Reply-To: <524B17CB.9010903@dr.com>
References: <5249F891.5000001@dr.com> <524A48F2.8030205@bitwrit.com.au>
	<524B17CB.9010903@dr.com>
Message-ID: <524B75C3.9020603@bitwrit.com.au>

On 10/02/2013 04:43 AM, Xianwen Chen wrote:
> Thanks Jim,
>
> The picture width is adjusted. That was great help! I really appreciate it.
>
> Does lwd mean 'line width'? I'm not exactly sure how that will help. Can
> you please explain the intuition behind it?
>
Yes, "lwd" refers to line width. The combination lty=3,lwd=3 should give 
you a thick dotted line.

> Can I also ask another question? My graph is made from 7 plots from
> sm.density.compare(). These 7 plots are put together by:
>
> par(mfrow=c(4,2))
>
> To make all 7 plots comparable, I specify y- and x-axis ranges. Here is
> the sample code for one of the plots:
>
> sm.density.compare(
> c(sample_1, sample_2), # sample_1 and sample_2 are two vectors, each
> corresponding to a sample
> rep(1:2, rep(140, 2)),
> lty = c(1, 3),
> lwd = c(1, 3), # This change was made by taking your suggestion.
> col = c("black", "black"),
> xlab="Sample",
> xlim=c(-40, 60),
> ylim=c(0, 0.15)
> )
>
> legend("topright", c("MMNL", "GMNL"), lty = c(1, 3), cex = 1)
>
> Somehow, xlim and ylim do not have an effect. I did not have this
> problem when I was running R in Arch Linux; but now I'm using Debian Linux.
>
xlim and ylim seem to work correctly when I tried this:

sample_1<-runif(280,-20,40)
sample_2<-runif(280,0,0.1)

sm.density.compare(c(sample_1, sample_2),
             rep(1:2, rep(140, 2)),
             lty = c(1, 3),
             lwd = c(1, 3),
             col = c("black", "black"),
             xlab="Sample",
             xlim=c(-40, 60),
             ylim=c(0, 0.15)
     )

However, while the lty=3 worked correctly, the lwd=3 didn't. I think 
that this function does not pass all of the graphics parameters to the 
plot function - see the help page on sm.options.

Jim


From odsen at ualberta.ca  Tue Oct  1 23:37:30 2013
From: odsen at ualberta.ca (Sonya Odsen)
Date: Tue, 1 Oct 2013 15:37:30 -0600
Subject: [R] package:nlme unexpected varIdent behaviour
Message-ID: <CAE1e_UMkE3mDv0cW7VB--SNrDEEKyfjf9YnZ6udUvuN_7iQg1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131001/324ad509/attachment.pl>

From tcmuigai at gmail.com  Wed Oct  2 08:32:48 2013
From: tcmuigai at gmail.com (Charles Thuo)
Date: Wed, 2 Oct 2013 09:32:48 +0300
Subject: [R] transferring a graph from R into word
Message-ID: <CAAJc=rOxUvjS-=nmCX-fXGCi4LUcHSwAx44Wm7Hx61M8=V-Rqw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/330656aa/attachment.pl>

From patrick.bergman at lnu.se  Wed Oct  2 09:15:05 2013
From: patrick.bergman at lnu.se (pattebegga)
Date: Wed, 2 Oct 2013 00:15:05 -0700 (PDT)
Subject: [R] missclassification in estimating proportions
Message-ID: <1380698104881-4677385.post@n4.nabble.com>

Hi

Assume that I want to compare two methods, say skinfold measurement and BMI,
in how they classify subjects into four categories. In a 2x2 table I would
simply calculate sensitivity and specificity and NPV an PPV, using the
standard formulas, but can the same be directly applied in the 4x4 table? Or
are other methods preferable?

Thanks in advance

Patrick



--
View this message in context: http://r.789695.n4.nabble.com/missclassification-in-estimating-proportions-tp4677385.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Wed Oct  2 10:31:47 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 2 Oct 2013 08:31:47 +0000
Subject: [R] transferring a graph from R into word
In-Reply-To: <CAAJc=rOxUvjS-=nmCX-fXGCi4LUcHSwAx44Wm7Hx61M8=V-Rqw@mail.gmail.com>
References: <CAAJc=rOxUvjS-=nmCX-fXGCi4LUcHSwAx44Wm7Hx61M8=V-Rqw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B94D06@SRVEXCHMBX.precheza.cz>

Hi

I am not sure if right clicking was meant as standard way to transferring graph to Word. Anyway there shall be menu with several options for saving graph or copying them to clipboard.

You probably shall also check

?pdf, ?png, ?postsript

or other devices.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Charles Thuo
> Sent: Wednesday, October 02, 2013 8:33 AM
> To: r-help at r-project.org
> Subject: [R] transferring a graph from R into word
> 
> I have been  copying graphs as bitmap image from R by right clicking on
> them and pasting on word. However this does not seem to be working any
> more. Is there another way.
> 
> Charles
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Oct  2 10:36:31 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 02 Oct 2013 09:36:31 +0100
Subject: [R] transferring a graph from R into word
In-Reply-To: <CAAJc=rOxUvjS-=nmCX-fXGCi4LUcHSwAx44Wm7Hx61M8=V-Rqw@mail.gmail.com>
References: <CAAJc=rOxUvjS-=nmCX-fXGCi4LUcHSwAx44Wm7Hx61M8=V-Rqw@mail.gmail.com>
Message-ID: <524BDB0F.4070703@sapo.pt>

Hello,

Left click on the graph and then on the file menu, choose "save as". You 
will have a choice of graphics file formats. Word accepts several of 
them, so it's up for you to choose. PNG or BMP, for instance.

Hope this helps,

Rui Barradas

Em 02-10-2013 07:32, Charles Thuo escreveu:
> I have been  copying graphs as bitmap image from R by right clicking on
> them and pasting on word. However this does not seem to be working any
> more. Is there another way.
>
> Charles
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chainsawtiney at gmail.com  Wed Oct  2 11:07:26 2013
From: chainsawtiney at gmail.com (C.H.)
Date: Wed, 2 Oct 2013 17:07:26 +0800
Subject: [R] Command line r
In-Reply-To: <BAY175-W1085BD329837B744D0F339D62A0@phx.gbl>
References: <BAY175-W1085BD329837B744D0F339D62A0@phx.gbl>
Message-ID: <CAHfK2MtHk20E9MHZ305WuNwUzn=YXznkRVBCYMfSzuTtS1j35w@mail.gmail.com>

Have a look at the littler.

http://dirk.eddelbuettel.com/code/littler.html

On Sun, Sep 29, 2013 at 3:36 AM, Tomek R <rtomek at outlook.com> wrote:
> Hi,
> I have found myself often doing simple statistical analysis using Linux command line on a single dataset. Therefore, I put a perl script together, which makes it easier:https://github.com/religa/statshttps://github.com/religa/stats/blob/master/r
> The idea behind simpleR is that it becomes a standard part of any Linux pipe.
> For example, to get a summary of your data, one would have to type: 'r summary file.txt'; to plot it: 'r -p file.txt'; to calculate sum of numbers from 1 to 100: 'seq 1 100 | r sum -';
> I tried to test it under Linux / Mac, including various types of pipes and redirects. I am looking forward to your comments on how to improve it.
> Tomek
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From info at aghmed.fsnet.co.uk  Wed Oct  2 12:50:16 2013
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Wed, 02 Oct 2013 11:50:16 +0100
Subject: [R] over dispersion plot
In-Reply-To: <CA+tD=u5QpOVmdwD1noYw=4KxxrcVwcKAAB_S99vAvH26wxLAzg@mail.g
	mail.com>
References: <CA+tD=u5QpOVmdwD1noYw=4KxxrcVwcKAAB_S99vAvH26wxLAzg@mail.gmail.com>
Message-ID: <Zen-1VRK0e-000C34-8P@smarthost01a.mail.zen.net.uk>

At 19:15 01/10/2013, Sagan Friant wrote:
>I want to show over dispersion in my data by plotting the variance against
>the mean for 8 groups.  I used the following code to plot by type
>(parasite).
>
>scatterplot(variance~mean | parasite, reg.line=lm, smooth=FALSE,
>spread=FALSE, boxplots=FALSE, span=0.5, by.groups=TRUE, data=Disp2)

If you are going to get meaningful help you need to be open with us 
about what you did. Where did you get the function scatterplot from?


>I now want to add a hypothetical regression line that would show what a 1:1
>ratio would look on the same plot.

It may be that you can do this with abline but in the absence of more 
details about scatterplot it is hard to be sure.

>I also want to label specific points by their sample name, or by a specific
>color.
>
>help please?
>
>--
>Sagan C. Friant, MSc
>Environment & Resources Ph.D Program
>Nelson Institute of Environmental Studies
>University of Wisconsin - Madison
>
>         [[alternative HTML version deleted]]

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From pdalgd at gmail.com  Wed Oct  2 13:04:04 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 2 Oct 2013 13:04:04 +0200
Subject: [R] Command line r
In-Reply-To: <CAHfK2MtHk20E9MHZ305WuNwUzn=YXznkRVBCYMfSzuTtS1j35w@mail.gmail.com>
References: <BAY175-W1085BD329837B744D0F339D62A0@phx.gbl>
	<CAHfK2MtHk20E9MHZ305WuNwUzn=YXznkRVBCYMfSzuTtS1j35w@mail.gmail.com>
Message-ID: <97567854-8B15-4F27-A4B9-96EC3A7240F1@gmail.com>


On Oct 2, 2013, at 11:07 , C.H. wrote:

> Have a look at the littler.
> 
> http://dirk.eddelbuettel.com/code/littler.html
> 

Or Rscript (comes standard with R) for that matter:

$ echo '2+2' | Rscript -
[1] 4

-pd


> On Sun, Sep 29, 2013 at 3:36 AM, Tomek R <rtomek at outlook.com> wrote:
>> Hi,
>> I have found myself often doing simple statistical analysis using Linux command line on a single dataset. Therefore, I put a perl script together, which makes it easier:https://github.com/religa/statshttps://github.com/religa/stats/blob/master/r
>> The idea behind simpleR is that it becomes a standard part of any Linux pipe.
>> For example, to get a summary of your data, one would have to type: 'r summary file.txt'; to plot it: 'r -p file.txt'; to calculate sum of numbers from 1 to 100: 'seq 1 100 | r sum -';
>> I tried to test it under Linux / Mac, including various types of pipes and redirects. I am looking forward to your comments on how to improve it.
>> Tomek
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From f.harrell at Vanderbilt.Edu  Wed Oct  2 13:34:54 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Wed, 2 Oct 2013 06:34:54 -0500
Subject: [R] missclassification in estimating proportions
Message-ID: <524C04DE.4000008@vanderbilt.edu>

This is dichotomania and is an inappropriate use of continuous 
variables.  Use an information-preserving approach such as rank 
correlation.  Also, this is not an R question.
Frank

-----------
Assume that I want to compare two methods, say skinfold measurement and 
BMI, in how they classify subjects into four categories. In a 2x2 table 
I would simply calculate sensitivity and specificity and NPV an PPV, 
using the standard formulas, but can the same be directly applied in the 
4x4 table? Or are other methods preferable?

Thanks in advance

Patrick


-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University


From smartpink111 at yahoo.com  Wed Oct  2 14:10:36 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 2 Oct 2013 05:10:36 -0700 (PDT)
Subject: [R] Removing time and min from Date
In-Reply-To: <1380692310.65170.YahooMailNeo@web121302.mail.ne1.yahoo.com>
References: <1380692310.65170.YahooMailNeo@web121302.mail.ne1.yahoo.com>
Message-ID: <1380715836.72138.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi Farnoosh,

Use ?as.Date()
dat1<- read.table(text="V1
2012-01-12 08:23:00
2012-01-19 15:29:00",sep=",",header=TRUE,stringsAsFactors=FALSE)


dat1$V1<- as.Date(dat1$V1)
?dat1
#????????? V1
#1 2012-01-12
#2 2012-01-19
A.K.





________________________________
From: farnoosh sheikhi <farnoosh_81 at yahoo.com>
To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
Sent: Wednesday, October 2, 2013 1:38 AM
Subject: Removing time and min from Date



Hi Arun,

I have a variable including time and date together like below.
I want to just keep the date part (2012-01-12 ) and drop the hour and minutes.

V1
2012-01-12 08:23:00
2012-01-19 15:29:00



Thanks a lot.?


From spyqqqdia at yahoo.com  Wed Oct  2 15:18:51 2013
From: spyqqqdia at yahoo.com (Michael Meyer)
Date: Wed, 2 Oct 2013 21:18:51 +0800 (SGT)
Subject: [R] optim evils
Message-ID: <1380719931.23823.YahooMailNeo@web193403.mail.sg3.yahoo.com>

Greetings,

In obedient deference to the demands of the collective I emailed a?BUG report containing 
code and data to r-bugs at r-project.org but found subsequently that I am unable to load the page
http://bugs.r-project.org/ to check on the status of this report.

Can anyone else load this page?

Thanks,


Michael Meyer


From smartpink111 at yahoo.com  Wed Oct  2 15:17:21 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 2 Oct 2013 06:17:21 -0700 (PDT)
Subject: [R] Vector from csv file.
Message-ID: <1380719841.190.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

It is not clear whether you read the file correctly or not.? Please check 


str(tbl_all)

The code you showed should work if the file was read correctly.


For example:
set.seed(468)
tbl_all<- as.data.frame(matrix(sample(1:10,10*22,replace=TRUE),ncol=22,dimnames=list(NULL,c("A","V",LETTERS[3:22]))))
str(tbl_all)
#'data.frame':??? 10 obs. of? 22 variables:
# $ A: int? 8 5 7 4 2 4 7 4 3 5
# $ V: int? 4 1 9 1 4 5 3 9 8 3
# $ C: int? 1 5 9 6 1 5 1 8 2 2
# $ D: int? 3 2 1 4 8 2 5 6 2 8
# $ E: int? 5 10 7 7 6 7 10 2 10 7
--------------------------------------
---------------------------------

vec_seq1<-tbl_all[,2]
?is.vector(vec_seq1)
#[1] TRUE
#or 

vec_seq2<-tbl_all[,"V"]
?is.vector(vec_seq2)
#[1] TRUE
?identical(vec_seq1,vec_seq2)
#[1] TRUE


A.K.



I want to make a vector of my column "V" in the csv (it's a 22 column in number) so I put this come: 

vec_seq <- tbl_all[,2] 

I thought that's so easy and it doesnt work. R says "Error in `[.data.frame`(tbl_all, , 22) : undefined columns selected"


From kw.stat at gmail.com  Wed Oct  2 15:52:56 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 2 Oct 2013 08:52:56 -0500
Subject: [R] package:nlme unexpected varIdent behaviour
In-Reply-To: <CAE1e_UMkE3mDv0cW7VB--SNrDEEKyfjf9YnZ6udUvuN_7iQg1A@mail.gmail.com>
References: <CAE1e_UMkE3mDv0cW7VB--SNrDEEKyfjf9YnZ6udUvuN_7iQg1A@mail.gmail.com>
Message-ID: <CAKFxdiScc5ifuV9Lv2Pqe-enOPjzYXofHrXLvfeUQE7499DgvQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/c09be981/attachment.pl>

From pkdavidsen at gmail.com  Wed Oct  2 11:42:09 2013
From: pkdavidsen at gmail.com (Peter Davidsen)
Date: Wed, 2 Oct 2013 10:42:09 +0100
Subject: [R] In which order should the "p" argument within chisq.test() be
 specified when working in 3 dimensions?
Message-ID: <CAGu5RCNqFvWc37tES9Q94ZTw31UxxoOyvwHfu+Rfm3cedqeAHw@mail.gmail.com>

Dear List,

I'm in the process of setting up a chi square test with 3 groups (A, B
and C). Hence, I have generated an array object like this:

my.obj <- array(c(overlap_ABC, overlap_AB, overlap_AC, unique_A,
overlap_BC, unique_B, unique_C, not_in_any), dim=c(2,2,2))

Now I'm in the process of generating a vector of probabilities that I
can use to define the "p" argument within the chisq.test() command.
However, I'm unsure as to which order my vector 'p' needs to be
defined?
Is is just:
p=c(overlap_ABC, overlap_AB, overlap_AC, unique_A, overlap_BC,
unique_B, unique_C, not_in_any) # same sequence as I used to define my
array matrix

Many thanks,


From sdonnelly758 at qub.ac.uk  Wed Oct  2 12:41:43 2013
From: sdonnelly758 at qub.ac.uk (Stephen Donnelly)
Date: Wed, 2 Oct 2013 03:41:43 -0700 (PDT)
Subject: [R] r - Forecast model
Message-ID: <1380710502784-4677392.post@n4.nabble.com>

Hi All,


I'm currently completing my MSc dissertation, using R to build a realised
volatility model using HAR.

There is a great guide on using high frequency in R which has been
invaluable to me. I was wondering though if you could all help with one
issue?

I've successfully achieved page 16 example in this pdf:
http://cran.r-project.org/web/packages/highfrequency/highfrequency.pdf

However, I would like to forecast the model into the future for a few
periods. So far I have had no success and it doesn't seem to let me forecast
harmodel like an ar model.

Do you have any suggestions? I thought it would be relatively easy to extend
the forecast that takes place in the example you already provided.

My dissertation would be grateful for any help you can offer.

Thanks very much, Stephen Donnelly

P.S:

rm(list=ls(all=TRUE))
library("highfrequency")

log.ret <- function(x) { y <- diff(log(x)); return(y) }

x <- as.matrix(read.csv("C:/users/u590799/Desktop/DATA-TEST.csv"))

dates <- x[,1]
times <- x[,2]
values <- as.numeric(x[,3])
times[which(times=="")] <- "00:00:00"

date.n.time <- matrix(NA, NROW(x), 1)
for(i in seq(1, NROW(x), 1)){date.n.time[i,1] <- paste(dates[i], times[i],
sep="     ")}
date.n.time2 <- as.Date(as.character(date.n.time), "%Y-%m-%d %H:%M:%OS")

x <- as.matrix(values); rownames(x) <- date.n.time; colnames(x)
y <- log.ret(x) #5 min log returns
y <- as.xts(y)

setwd("C:/Users/u590799/Documents/QUB/RV/Output") 

fname <- "The New Style-Settings-Normalised"
y.out <- harModel(data=y, periods = c(1,5,22),RVest = c("rCov"),
type="HARRV",h=1,     transform=NULL)
capture.output(summary(y.out),file=paste(fname, "out-summary.txt", sep="-"))
pdf(file=paste(fname, "out-plot.pdf", sep="-"), paper="a4r", width=12 ,
height=11.7); plot(y.out); dev.off()



--
View this message in context: http://r.789695.n4.nabble.com/r-Forecast-model-tp4677392.html
Sent from the R help mailing list archive at Nabble.com.


From flaviomargarito at gmail.com  Wed Oct  2 13:06:49 2013
From: flaviomargarito at gmail.com (Flavio Barros)
Date: Wed, 2 Oct 2013 08:06:49 -0300
Subject: [R] transferring a graph from R into word
In-Reply-To: <524BDB0F.4070703@sapo.pt>
References: <CAAJc=rOxUvjS-=nmCX-fXGCi4LUcHSwAx44Wm7Hx61M8=V-Rqw@mail.gmail.com>
	<524BDB0F.4070703@sapo.pt>
Message-ID: <CAOKagtOoNmgbh8zyPnqNdg=EbvKbEAofybXFiSS24rH4Ek3ByQ@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/cc21cf84/attachment.pl>

From murdoch.duncan at gmail.com  Wed Oct  2 16:02:10 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 02 Oct 2013 10:02:10 -0400
Subject: [R] optim evils
In-Reply-To: <1380719931.23823.YahooMailNeo@web193403.mail.sg3.yahoo.com>
References: <1380719931.23823.YahooMailNeo@web193403.mail.sg3.yahoo.com>
Message-ID: <524C2762.3040703@gmail.com>

On 02/10/2013 9:18 AM, Michael Meyer wrote:
> Greetings,
>
> In obedient deference to the demands of the collective I emailed a BUG report containing
> code and data to r-bugs at r-project.org but found subsequently that I am unable to load the page
> http://bugs.r-project.org/ to check on the status of this report.
>
> Can anyone else load this page?

No, the server is currently down.  The volunteer who runs the server is 
currently away from his office, so I expect it won't get fixed until he 
gets back in a few days.

By the way, the collective is made up of individuals.  Most of us don't 
demand anything.

Duncan Murdoch


From stefano.sofia at regione.marche.it  Wed Oct  2 16:09:41 2013
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Wed, 2 Oct 2013 14:09:41 +0000
Subject: [R] Group all the consecutive days
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F0DA25202@CHIENTI.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F0DA25202@CHIENTI.regionemarche.intra>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F0DA25218@CHIENTI.regionemarche.intra>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/449cd9e4/attachment.pl>

From frederic.bioinfo at gmail.com  Wed Oct  2 16:12:49 2013
From: frederic.bioinfo at gmail.com (Frederic Fournier)
Date: Wed, 02 Oct 2013 10:12:49 -0400
Subject: [R] How to pass an object between two independant environment?
Message-ID: <524C29E1.2010506@gmail.com>

Hello everyone,

I am trying to pass an object cleanly between two independant 
environments, any ideas on how to do that?

I have something like this:

calling.function <- function(my.object) {
... ...
local(source("function_to_which_I_want_to_pass_my_object.Rda", local = 
new.env(parent = .GlobalEnv))) # I can't change this part of the code
}

The calling function will be part of a package, so I don't want to use 
the global environment (that's the user's space, not a space that should 
be used by the packages). Writing a temp file is unclean for the same 
reason (and using the user's hard-drive is actually worse than using its 
space in R!). The package namespace is locked when the package is 
loaded, so using the package environment is not a perfect option either.

I was wondering, is there a way to create a named environment in R? If 
it was possible to do that, then the calling function could 'assign' to 
the named-environment and the scripted function could 'get' from it and 
the problem would be solved.

Thanks for your help,

Frederic


From murdoch.duncan at gmail.com  Wed Oct  2 16:19:38 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 02 Oct 2013 10:19:38 -0400
Subject: [R] How to pass an object between two independant environment?
In-Reply-To: <524C29E1.2010506@gmail.com>
References: <524C29E1.2010506@gmail.com>
Message-ID: <524C2B7A.8030009@gmail.com>

On 02/10/2013 10:12 AM, Frederic Fournier wrote:
> Hello everyone,
>
> I am trying to pass an object cleanly between two independant
> environments, any ideas on how to do that?
>
> I have something like this:
>
> calling.function <- function(my.object) {
> ... ...
> local(source("function_to_which_I_want_to_pass_my_object.Rda", local =
> new.env(parent = .GlobalEnv))) # I can't change this part of the code
> }
>
> The calling function will be part of a package, so I don't want to use
> the global environment (that's the user's space, not a space that should
> be used by the packages). Writing a temp file is unclean for the same
> reason (and using the user's hard-drive is actually worse than using its
> space in R!). The package namespace is locked when the package is
> loaded, so using the package environment is not a perfect option either.
>
> I was wondering, is there a way to create a named environment in R? If
> it was possible to do that, then the calling function could 'assign' to
> the named-environment and the scripted function could 'get' from it and
> the problem would be solved.

name <- new.env()

creates an environment named "name".

Duncan Murdoch


From ruipbarradas at sapo.pt  Wed Oct  2 16:34:08 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 02 Oct 2013 15:34:08 +0100
Subject: [R] Basic help on  DF creation row by row
In-Reply-To: <OF3AA7FF49.7BF59F2A-ONC1257BF8.004DB530-C1257BF8.004E61A1@eu.necel.com>
References: <OF9951AA9A.6A0838B5-ONC1257BF7.0048BD2C-C1257BF7.0049A79E@eu.necel.com>
	<524B1698.1070107@sapo.pt>
	<OF3AA7FF49.7BF59F2A-ONC1257BF8.004DB530-C1257BF8.004E61A1@eu.necel.com>
Message-ID: <524C2EE0.7070903@sapo.pt>

Hello,

Inline.

Em 02-10-2013 15:16, rolf.kemper at renesas.com escreveu:
>
> Hello Rui,
>
> thanks a lot for the quick and exhaustive  reply !
> It shows that my understanding of DF is totally wrong.
> I'm familiar with relational DBs where the columns of table have specific data types.
> Hence , I thought a DF collum is always of one specific type and the rows are just an index equal to all columns.

Right. In a df, each column is a vector, therefore all elements are of 
the same type.
> In particular , what you call FACTORS is something new to me. I have nod idea of statistics , but looking into several examples it looks like very
> useful to me.

A factor corresponds to the statistical concept of categorical variable. 
They are internally coded as integers, with a levels attribute, giving 
the several categories of the factor.

>
> What is the best reference manual to get a better imagination of how a DF is implemented and what can I do with c() function ?
> The doc I found so-far is not very exhaustive.

Try the R project home page, http://www.r-project.org. There's a link to 
several manuals, on the lower left.

Rui Barradas
>
> Thanks a lot
> R. Kemper
>
>
>
>
>
>
> Rolf  Kemper, Manager, Mixed Signal Design, Networking, Renesas Electronics Europe GmbH, , Arcadiastr. 10, 40472, Duesseldorf, Germany,  Phone:+49 211
> 6503-1475, Fax:+49 211 6503-1540, mailto:Rolf.Kemper at renesas.com, http://www.renesas.eu
>
> This message is intended only for the use of the addressee(s) and may contain confidential and/or legally privileged information. If you are not the
> intended recipient, you are hereby notified that any dissemination of this email (including any attachments thereto) is strictly prohibited. If you
> have received this email in error, please notify the sender immediately by telephone or email  and permanently destroy the original without making any
> copy. Please note that any material and advice from this mail is provided free of charge and shall be used as an example for demonstration purposes
> only.
> RENESAS MAKES NO WARRANTIES THAT THE USAGE OF INFORMATION OR ADVICE FROM THIS E-MAIL WILL NOT INFRINGE ANY INTELLECTUAL PROPERTY RIGHTS (E.G. PATENTS,
> COPYRIGHTS). RENESAS CANNOT GUARANTEE BUG FREE OPERATION AND THE RECIPIENT WILL USE AND/OR DISTRIBUTE IT ONLY AT HIS OWN RISK. IN NO EVENT SHALL
> RENESAS BE LIABLE FOR ANY DAMAGE.  The communication with Renesas Electronics Europe GmbH does not amend any written agreement in place. Renesas
> Electronics Europe GmbH
>
> Geschaeftsfuehrer/Managing Director: Robert Green Sitz der Gesellschaft/Registered office: Duesseldorf, Arcadiastrasse 10, 40472 Duesseldorf, Germany
> Handelsregister/Commercial Register: Duesseldorf, HRB 3708 USt-IDNr./Tax identification no.: DE 119353406 WEEE-Reg.-Nr./WEEE reg. no.: DE 14978647
>
> From:	Rui Barradas <ruipbarradas at sapo.pt>
> To:	rolf.kemper at renesas.com,
> Cc:	r-help at r-project.org
> Date:	10/01/2013 08:38 PM
> Subject:	Re: [R] Basic help on  DF creation row by row
>
>
>
> Hello,
>
> The main problem is in the way you form newRow. You can't mix data
> classes in a vector created with c(), so all its elements become
> characters, the least common denominator:
>
> newRow <- c("primitiveSpace", 1.1 , "mm2")
> newRow
> [1] "primitiveSpace" "1.1"            "mm2"
>
>
> Then when you rbind it with the data frame, they are all converted to
> factors. This is because the default behavior is to have the option
> stringsAsFactors set to TRUE. Try to check it:
>
> options()$stringsAsFactors  # TRUE
>
>
> Now, each of those factors was created with only one level, so when you
> try to assign something different to them, with the second rbind, NAs
> are generated.
>
> The correct way would be something like the following.
>
>
> newRow <- data.frame(item = "primitiveSpace", value = 1.1 , unit = "mm2")
> deviceSummary <- rbind(deviceSummary , newRow )
> print(deviceSummary)
> str(deviceSummary)  # to check what you have
>
> newRow <- data.frame(item = "primitiveCellSpace", value = 2.2 , unit =
> "mm2")
> deviceSummary <-rbind(deviceSummary , newRow )
> print(deviceSummary )
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 01-10-2013 14:24, rolf.kemper at renesas.com escreveu:
>>
>>
>> Dear Experts
>>
>> I'm very new to R and after some days or reading and testing  I tried to make my first small application (and failed ...)
>> In general I would like to work with sqldf , ggplot2 to create some graphical output.
>>
>> At present I got stuck with this:
>>
>> PROG #############################################################################
>> deviceSummary <- data.frame(item = character(0) ,  value = numeric(0) , unit = character(0) )
>> print ( sapply(deviceSummary, class))
>>
>> newRow <- c("primitiveSpace", 1.1 , "mm2")
>> deviceSummary <-rbind(deviceSummary , newRow )
>> print(deviceSummary)
>>
>> newRow <- c("primitiveCellSpace", 2.2 , "mm2")
>> deviceSummary <-rbind(deviceSummary , newRow )
>> print(deviceSummary )
>>
>> OUTPUT ############################################################################
>>       item     value      unit
>>    "factor" "numeric"  "factor"
>>     X.primitiveSpace. X.1.1. X.mm2.
>> 1    primitiveSpace    1.1    mm2
>>     X.primitiveSpace. X.1.1. X.mm2.
>> 1    primitiveSpace    1.1    mm2
>> 2              <NA>   <NA>    mm2
>> Warning messages:
>> 1: In `[<-.factor`(`*tmp*`, ri, value = "primitiveCellSpace") :
>>     invalid factor level, NA generated
>> 2: In `[<-.factor`(`*tmp*`, ri, value = "2.2") :
>>     invalid factor level, NA generated
>>
>> Inserting the first record went fine , but the next one will fail as you can see.
>> Repeating only the first one (value1.1) went fine.
>>
>> May be my imagination of DF is totally wrong. Hope someone can guide me.
>>
>> Thanks a lot
>>
>> Rolf
>>
>>
>>
>>
>> Rolf  Kemper, Manager, Mixed Signal Design, Networking, Renesas Electronics Europe GmbH, , Arcadiastr. 10, 40472, Duesseldorf, Germany,  Phone:+49
> 211
>> 6503-1475, Fax:+49 211 6503-1540, mailto:Rolf.Kemper at renesas.com, http://www.renesas.eu
>>
>> This message is intended only for the use of the address...{{dropped:24}}
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From mary.kindall at gmail.com  Wed Oct  2 16:52:29 2013
From: mary.kindall at gmail.com (Mary Kindall)
Date: Wed, 2 Oct 2013 10:52:29 -0400
Subject: [R] How to create an ROC with three possible classes?
Message-ID: <CANStr5691i+cUhvbM-D-ZwQ0g2_HFyQbt7ps9QqWEshxX-Ps8Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/2829c727/attachment.pl>

From S.Ellison at LGCGroup.com  Wed Oct  2 16:59:25 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 2 Oct 2013 15:59:25 +0100
Subject: [R] leveneTest - output
In-Reply-To: <CAKyZeBvF6u_Zyf-7byTh3wqO5EnBHRLRW5zVLAtVdK1VzTYSNg@mail.gmail.com>
References: <CAKyZeBvF6u_Zyf-7byTh3wqO5EnBHRLRW5zVLAtVdK1VzTYSNg@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487C2732B@GOLD.corp.lgc-group.com>


> I have a question concerning the output of leveneTest. I don't
> understand
> the "7" in my output

It's the residual degrees of freedom for the corresponding ANOVA table. You'd get the same value if you did a one-way ANOVA by group.ID.

Having said that, your test isn't going to tell you much if the example data is the data of interest. First, the dispersions don't look much different on plotting; unless you have reason to believe there should be an underlying difference in variance you could probably stop there. Second, I seem to recall Levene's test is rather flaky for unbalanced data - it doesn't just test the null of equal variance. And third, for the data set size you have in the example, it's got very low power indeed. Based on exploratory simulations I've done myself, for factor-of-four changes in variance between your largest and smallest variance, you'll probably have test power under 5%. Think about that for a second: for a well-behaved test you should expect 5% test power for a negligibly small effect just by setting 95% confidence. Levene's test is fair for larger sets (10 per group and up) and more robust than some, but on this size of data set it doesn't even give you the chance 'reject' rate you asked for at the null. At this size, if I had to apply a test I'd consider bartlett's test instead; although I recall that as having pretty severe caveats around normality at least it preserves the expected confidence level reasonably well.

Still, I suppose that if you apply a test that is guaranteed to pass in all but catastrophically extreme circumstances, at least you can say you've applied a test.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From tghoward at gw.dec.state.ny.us  Wed Oct  2 17:17:29 2013
From: tghoward at gw.dec.state.ny.us (Tim Howard)
Date: Wed, 02 Oct 2013 11:17:29 -0400
Subject: [R] update.packages fails on pdf write - CSAgent
Message-ID: <524C00C9020000D500B80313@gwsmtp.dec.state.ny.us>

All,
I work in a building where our computers are running Windows XP with
Cisco Security Agent (CSA) activated, locking many automated actions,
especially file writes. We (lowly staff) are allowed to install
software, so on upgrading to R 3.0.2, I tried the standard approach for
updating my packages: Copying the non-base folders from my older
installation into the library folder and running
 
update.packages(checkBuilt=TRUE, ask=FALSE)
 
R merrily downloads from the mirror and then continues installation --
until it gets to a package that has a pdf to write, as follows:
 
> update.packages(checkBuilt=TRUE, ask=FALSE)
--- Please select a CRAN mirror for use in this session ---
trying URL
'http://cran.mirrors.hoobly.com/bin/windows/contrib/3.0/akima_0.5-11.zip'
Content type 'application/zip' length 370759 bytes (362 Kb)
opened URL
downloaded 362 Kb
 
trying URL
'http://cran.mirrors.hoobly.com/bin/windows/contrib/3.0/bitops_1.0-6.zip'
Content type 'application/zip' length 35878 bytes (35 Kb)
opened URL
downloaded 35 Kb
 
trying URL
'http://cran.mirrors.hoobly.com/bin/windows/contrib/3.0/chron_2.3-44.zip'
Content type 'application/zip' length 105192 bytes (102 Kb)
opened URL
downloaded 102 Kb
trying URL
'http://cran.mirrors.hoobly.com/bin/windows/contrib/3.0/colorspace_1.2-4.zip'
Content type 'application/zip' length 384585 bytes (375 Kb)
opened URL
downloaded 375 Kb
< .. many more packages ...>
 
package ?akima? successfully unpacked and MD5 sums checked
package ?bitops? successfully unpacked and MD5 sums checked
package ?chron? successfully unpacked and MD5 sums checked
Error in unzip(zipname, exdir = dest) : 
  cannot open file 'C:/Program
Files/R/R-3.0.2/library/file8ec2cd16e8/colorspace/doc/hcl-colors.pdf':
Permission denied
> 
Here's the message from the Application log in my Event Viewer:
 
The process 'C:\Program Files\R\R-3.0.2\bin\i386\Rgui.exe' (as user
<myusername>) attempted to access 'C:\Program
Files\R\R-3.0.2\library\file8ec2cd16e8\colorspace\doc\hcl-colors.pdf'.
The attempted access was a write (operation = OPEN/CREATE). The
operation was denied.
 
So it seems to me that CSA is blocking the installation of this package
because of the PDF write attempt. Please correct me if my interpretation
is wrong!
 
I can re-install these packages manually, but would love to do it
automatically.
 
My Questions:
 
It seems that the pdf is 'extra' since it isn't required for all
packages. Is there a way for me to tell update.packages to not install
these extras? I don't see that as an option at ?update.packages, but I
may be missing it.
 
Alternatively, is there an easy way to identify and download the zips
needed in a folder of my choice and but then finish the install
manually?
 
> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                
         
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base   
 

loaded via a namespace (and not attached):
[1] tools_3.0.2
> 
 
Thanks for any help
 
 Tim


From jholtman at gmail.com  Wed Oct  2 17:29:23 2013
From: jholtman at gmail.com (jim holtman)
Date: Wed, 2 Oct 2013 11:29:23 -0400
Subject: [R] Group all the consecutive days
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F0DA25218@CHIENTI.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F0DA25202@CHIENTI.regionemarche.intra>
	<8B435C9568170B469AE31E8891E8CC4F0DA25218@CHIENTI.regionemarche.intra>
Message-ID: <CAAxdm-7pXV2zJn=YY-yMbic1wcMfOF4QGQB7cjAg6f7akcdTWw@mail.gmail.com>

try this:

> rain <- read.table(text = '"year" "month" "day" "rainfall" "landslide"
+ "3" 2007 6 6 1.6 0
+ "4" 2007 6 7 1.8 0
+ "6" 2007 6 12 4.6 0
+ "8" 2007 7 5 6.6 0
+ "9" 2007 7 10 3 0
+ "10" 2007 7 11 1.2 0
+ "11" 2007 8 3 6.4 0
+ "12" 2007 8 10 2.8 0
+ "14" 2007 9 4 5.4 0
+ "15" 2007 9 5 1 0
+ "16" 2007 9 10 2.8 0
+ "17" 2007 9 11 6.8 0
+ "18" 2007 9 18 1.4 0
+ "19" 2007 9 19 1 0
+ "20" 2007 9 27 3 0
+ "21" 2007 10 6 41.4 0
+ "22" 2007 10 7 146 1
+ "23" 2007 10 10 2 0
+ "24" 2007 10 11 3.4 0
+ "26" 2007 10 18 17.4 0
+ "28" 2007 10 20 12.8 0
+ "29" 2007 10 21 1.8 0
+ "30" 2007 10 22 15.6 0
+ "33" 2007 10 25 8.6 0
+ "35" 2007 10 30 5.2 0
+ "36" 2007 10 31 34 1
+ "37" 2007 11 1 7.6 0
+ "39" 2007 11 9 6.8 1
+ "40" 2007 11 14 6.2 0
+ "41" 2007 11 15 3.8 0
+ "42" 2007 11 16 9.2 0', header = TRUE)
>
> # convert to Date
> rain$Date <- as.Date(paste0(rain$year, '-', rain$month, '-', rain$day))
>
> # determine consecutive if difference is one
> rain$consec <- cumsum(!c(TRUE, diff(rain$Date) == 1))
>
> # now split by consecutive days and create one row
> x <- split(rain, rain$consec)
>
> result <- do.call(rbind
+     , lapply(x, function(days){
+         data.frame(date = paste(days$Date, collapse = ',')
+                 , total = sum(days$rainfall)
+                 , stringsAsFactors = FALSE
+                 )
+         })
+     )
>
>
>
> result
                               date total
0             2007-06-06,2007-06-07   3.4
1                        2007-06-12   4.6
2                        2007-07-05   6.6
3             2007-07-10,2007-07-11   4.2
4                        2007-08-03   6.4
5                        2007-08-10   2.8
6             2007-09-04,2007-09-05   6.4
7             2007-09-10,2007-09-11   9.6
8             2007-09-18,2007-09-19   2.4
9                        2007-09-27   3.0
10            2007-10-06,2007-10-07 187.4
11            2007-10-10,2007-10-11   5.4
12                       2007-10-18  17.4
13 2007-10-20,2007-10-21,2007-10-22  30.2
14                       2007-10-25   8.6
15 2007-10-30,2007-10-31,2007-11-01  46.8
16                       2007-11-09   6.8
17 2007-11-14,2007-11-15,2007-11-16  19.2
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Oct 2, 2013 at 10:09 AM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R-users,
> I have a data frame where in each row there is the daily rainfall cumulative;
> missing days mean that in that days rainfall has been zero.
> I need to group all the consecutive days in a single row and store in the field "rainfall" the sum of these consecutive days.
> Is there a reasonable way to do that?
>
> Thank you for your help
> Stefano
>
> "year" "month" "day" "rainfall" "landslide"
> "3" 2007 6 6 1.6 0
> "4" 2007 6 7 1.8 0
> "6" 2007 6 12 4.6 0
> "8" 2007 7 5 6.6 0
> "9" 2007 7 10 3 0
> "10" 2007 7 11 1.2 0
> "11" 2007 8 3 6.4 0
> "12" 2007 8 10 2.8 0
> "14" 2007 9 4 5.4 0
> "15" 2007 9 5 1 0
> "16" 2007 9 10 2.8 0
> "17" 2007 9 11 6.8 0
> "18" 2007 9 18 1.4 0
> "19" 2007 9 19 1 0
> "20" 2007 9 27 3 0
> "21" 2007 10 6 41.4 0
> "22" 2007 10 7 146 1
> "23" 2007 10 10 2 0
> "24" 2007 10 11 3.4 0
> "26" 2007 10 18 17.4 0
> "28" 2007 10 20 12.8 0
> "29" 2007 10 21 1.8 0
> "30" 2007 10 22 15.6 0
> "33" 2007 10 25 8.6 0
> "35" 2007 10 30 5.2 0
> "36" 2007 10 31 34 1
> "37" 2007 11 1 7.6 0
> "39" 2007 11 9 6.8 1
> "40" 2007 11 14 6.2 0
> "41" 2007 11 15 3.8 0
> "42" 2007 11 16 9.2 0
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Wed Oct  2 17:33:00 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 2 Oct 2013 08:33:00 -0700
Subject: [R] missclassification in estimating proportions
In-Reply-To: <1380698104881-4677385.post@n4.nabble.com>
References: <1380698104881-4677385.post@n4.nabble.com>
Message-ID: <41CEF449-5E2A-4528-8520-95557EB4DA06@comcast.net>


On Oct 2, 2013, at 12:15 AM, pattebegga wrote:

> Hi
> 
> Assume that I want to compare two methods, say skinfold measurement and BMI,
> in how they classify subjects into four categories. In a 2x2 table I would
> simply calculate sensitivity and specificity and NPV an PPV, using the
> standard formulas, but can the same be directly applied in the 4x4 table


> Or are other methods preferable?

 This is the wrong place for this question, please send your statisical question to a venue where this would be on topic, or if this is homework, then consult your instructor.

-- 

David Winsemius
Alameda, CA, USA


From asis.hallab at gmail.com  Wed Oct  2 18:28:36 2013
From: asis.hallab at gmail.com (Asis Hallab)
Date: Wed, 2 Oct 2013 18:28:36 +0200
Subject: [R] Bioconductor / AnnotationDbi: Why does a GOAllFrame contain
 more rows than its argument GoFrame?
Message-ID: <CAPccJQF5usoNPks3pehMkDjjX_qo6C0DVrWESRDkxOmYmPUzrQ@mail.gmail.com>

Dear Bioconductor Experts,

thank you for providing such a useful tool-set.

I have a question regarding the package AnnotationDbi, specifically
the classes GOFrame and GOALLFrame.

During a GO Enrichment Analysis I create a data frame with Arabidopsis
thaliana GO annotations and from that first a GOFrame and than from
this GOFrame a GOALLFrame. Checking the result with

nrow(  getGOFrameData(  athal.go.all.frame ) ) # The GOAllFrame

and comparing it with

nrow( athal.go.frame )                                     # The GoFrame

I realize that the GOALLFrame has more than 5 times more rows than my
original GO annotation table. If I provide
organism='Arabidopsis thaliana'
to the constructor of GOFrame this ratio increases even further.

Unfortunately I could not find any documentation on this, so I feel
forced to bother you with my questions:

1) Why does GOALLFrame so many more annotations?
2) Why and from where does it retrieve the organism specific ones that
are added when a model organism like 'Arabidopsis thaliana' is
provided?
3) I suspected that all ancestors of annotated terms are added, but
when I did so myself, I still got less GO term annotations? So do you
add ancestors of the "is_a" type and possibly other relationship types
like "part_of" etc. ?

Please let me know your answers soon. Your help will be much appreciated.

Kind regards!


From axel.urbiz at gmail.com  Wed Oct  2 18:37:24 2013
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Wed, 2 Oct 2013 12:37:24 -0400
Subject: [R] Help with vapply() loop
Message-ID: <CAAyVsXKpXwb=aXJiKK2fjiNaFyiORLJJLt_-M=bgY=54VKUBqg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/d06a37e5/attachment.pl>

From ecjbosu at aim.com  Wed Oct  2 16:58:55 2013
From: ecjbosu at aim.com (Joe Byers)
Date: Wed, 2 Oct 2013 10:58:55 -0400 (EDT)
Subject: [R] (no subject)
Message-ID: <8D08D970CB91A22-908-422CB@webmail-d244.sysops.aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/aa8e5b2d/attachment.pl>

From Alex.Johnson at theaa.com  Wed Oct  2 17:19:18 2013
From: Alex.Johnson at theaa.com (Johnson, Alex)
Date: Wed, 2 Oct 2013 16:19:18 +0100
Subject: [R] R Excel - Microsoft Excel is waiting for OLE action
Message-ID: <6DBEEF9C09ACF64B8BCFE8F66EDA1B1F05622657@aa-exb01.theaa.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/ea10be51/attachment.pl>

From fcorreia at gmail.com  Wed Oct  2 17:33:10 2013
From: fcorreia at gmail.com (Filipe Correia)
Date: Wed, 2 Oct 2013 16:33:10 +0100
Subject: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U) test
Message-ID: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>

Hello everyone,

I'm having some trouble interpreting the results of a Wilcoxon
(Mann-Whitney U) test. Hope you can help.

This is the R script that I am running:

a <- c(1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 5, 1, 1, 1, 3, 1, 1,
1, 1, 1, 1, 3, 1, 1)
b <- c(1, 2, 1, 1, 2, 3, 2, 2, 1, 2, 1, 1, 1, 2)
wilcox.test(a, b, alternative="t", mu=0, exact=FALSE, paired=FALSE)  #1st
wilcox.test(a, b, alternative="l", mu=0, exact=FALSE, paired=FALSE)  #2nd
wilcox.test(a, b, alternative="g", mu=0, exact=FALSE, paired=FALSE)  #3rd

... and it's returning:

Wilcoxon rank sum test with continuity correction data:  a and b
W = 145, p-value = 0.08969
alternative hypothesis: true location shift is not equal to 0

Wilcoxon rank sum test with continuity correction data:  a and b
W = 145, p-value = 0.04485
alternative hypothesis: true location shift is less than 0

Wilcoxon rank sum test with continuity correction data:  a and b
W = 145, p-value = 0.9582
alternative hypothesis: true location shift is greater than 0

The null hypothesis is that the populations are equivalent (mu=0). The
alternative hypothesis are that they differ, with the 2nd and 3rd runs
of the test above considering respectively that a<b and b>a. Plus, I'm
considering an alfa of 0.05.

My issue is that from the first run I could not conclude that there
was a difference between the two populations (0.08969>0.05), but the
second run leads me to think that a<b (because 0.04485<0.05).

Am I misinterpreting the results?

Thanks!

Filipe


From smartpink111 at yahoo.com  Wed Oct  2 17:45:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 2 Oct 2013 08:45:41 -0700 (PDT)
Subject: [R] Group all the consecutive days
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F0DA25218@CHIENTI.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F0DA25202@CHIENTI.regionemarche.intra>
	<8B435C9568170B469AE31E8891E8CC4F0DA25218@CHIENTI.regionemarche.intra>
Message-ID: <1380728741.78794.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:


dat1<- read.table(text='"year" "month" "day" "rainfall" "landslide"
"3" 2007 6 6 1.6 0
"4" 2007 6 7 1.8 0
"6" 2007 6 12 4.6 0
"8" 2007 7 5 6.6 0
"9" 2007 7 10 3 0
"10" 2007 7 11 1.2 0
"11" 2007 8 3 6.4 0
"12" 2007 8 10 2.8 0
"14" 2007 9 4 5.4 0
"15" 2007 9 5 1 0
"16" 2007 9 10 2.8 0
"17" 2007 9 11 6.8 0
"18" 2007 9 18 1.4 0
"19" 2007 9 19 1 0
"20" 2007 9 27 3 0
"21" 2007 10 6 41.4 0
"22" 2007 10 7 146 1
"23" 2007 10 10 2 0
"24" 2007 10 11 3.4 0
"26" 2007 10 18 17.4 0
"28" 2007 10 20 12.8 0
"29" 2007 10 21 1.8 0
"30" 2007 10 22 15.6 0
"33" 2007 10 25 8.6 0
"35" 2007 10 30 5.2 0
"36" 2007 10 31 34 1
"37" 2007 11 1 7.6 0
"39" 2007 11 9 6.8 1
"40" 2007 11 14 6.2 0
"41" 2007 11 15 3.8 0
"42" 2007 11 16 9.2 0',sep="",header=TRUE,stringsAsFactors=FALSE)
?vec1<- as.Date(paste(dat1[,1],sprintf("%02d",dat1[,2]), sprintf("%02d",dat1[,3]),sep="-"))
?indx<-c(0,cumsum(1-(diff(vec1)==1)))
res<- do.call(rbind,lapply(split(dat1,indx),function(x) {x$rainfall<-sum(x$rainfall);x$Date<-paste(paste(x[,1],sprintf("%02d",x[,2]),sprintf("%02d",x[,3]),sep="-"),collapse=",");x; x[1,c(6,4:5)]}))


A.K.



----- Original Message -----
From: Stefano Sofia <stefano.sofia at regione.marche.it>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, October 2, 2013 10:09 AM
Subject: [R] Group all the consecutive days

Dear R-users,
I have a data frame where in each row there is the daily rainfall cumulative;
missing days mean that in that days rainfall has been zero.
I need to group all the consecutive days in a single row and store in the field "rainfall" the sum of these consecutive days.
Is there a reasonable way to do that?

Thank you for your help
Stefano

"year" "month" "day" "rainfall" "landslide"
"3" 2007 6 6 1.6 0
"4" 2007 6 7 1.8 0
"6" 2007 6 12 4.6 0
"8" 2007 7 5 6.6 0
"9" 2007 7 10 3 0
"10" 2007 7 11 1.2 0
"11" 2007 8 3 6.4 0
"12" 2007 8 10 2.8 0
"14" 2007 9 4 5.4 0
"15" 2007 9 5 1 0
"16" 2007 9 10 2.8 0
"17" 2007 9 11 6.8 0
"18" 2007 9 18 1.4 0
"19" 2007 9 19 1 0
"20" 2007 9 27 3 0
"21" 2007 10 6 41.4 0
"22" 2007 10 7 146 1
"23" 2007 10 10 2 0
"24" 2007 10 11 3.4 0
"26" 2007 10 18 17.4 0
"28" 2007 10 20 12.8 0
"29" 2007 10 21 1.8 0
"30" 2007 10 22 15.6 0
"33" 2007 10 25 8.6 0
"35" 2007 10 30 5.2 0
"36" 2007 10 31 34 1
"37" 2007 11 1 7.6 0
"39" 2007 11 9 6.8 1
"40" 2007 11 14 6.2 0
"41" 2007 11 15 3.8 0
"42" 2007 11 16 9.2 0


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From celsnrt at 163.com  Wed Oct  2 17:51:58 2013
From: celsnrt at 163.com (yy)
Date: Wed, 2 Oct 2013 23:51:58 +0800 (CST)
Subject: [R] Drawing garbled
Message-ID: <2311f4b1.7d65.14179de5d3b.Coremail.celsnrt@163.com>

Hi:
       I am Chinese, I am developing a java application, and  deploy it  to tomcat 7.0.42, I use rJava to use the R, when I use the command line to start tomcat, the R drawing well done, see attachment histview.png,but when i use windows service to start tomcat, the R drawing bad, see attachment histview2.png, I don't why, can you give me a suggestion? My window OS is window 7 home, thanks your help!
-------------- next part --------------
A non-text attachment was scrubbed...
Name: histview.png
Type: image/png
Size: 4083 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/12efc51e/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: histview2.png
Type: image/png
Size: 2567 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/12efc51e/attachment-0001.png>

From rolf.kemper at renesas.com  Wed Oct  2 16:33:29 2013
From: rolf.kemper at renesas.com (rolf.kemper at renesas.com)
Date: Wed, 02 Oct 2013 16:33:29 +0200
Subject: [R] ggplot2 multiple legends modification
Message-ID: <OFB2B1CE2E.841DE102-ONC1257BF8.004E62C7-C1257BF8.004FF892@eu.necel.com>



Dear ALL,

please find attached a small test file. (code is copied in this mail too)
Basically (as shown) I would like to combine several results in one graph.
I could succeed to plot the data correctly, but the legend generation does not fit.
For the dfStartPoints and the dfEndpoints I just want to be able to select the color AND (if possible the shape of each one)

The legend I'm getting could be modified for its title , but I was not able to to change the label value itself.

My final wish is to get 3 Legends (the one for dfXY is fully OK)
Legend one (Titled Cell/Area...) is fully OK as it is
Legend two should have Title "Start Point"s"  color "red" AND the count of data points as value
Legend three should have Tile ?nd Points color "green"AND the count of data points as value.

I think I can easily get the count , but I have no idea how to modify the related  legends in code

There are many examples of this (e.g. http://docs.ggplot2.org/current/guide_legend.html )  , but  nothing fits really.

Hope someone can help on this

Rolf

######################## code as attached ###############################
require(sqldf)
options(gsubfn.engine = "R")
require(ggplot2)

rm(list=ls(all=TRUE))
maxCells = max(primitiveDensityMap$c)

#craete a 100 * 100 grid with random values(cellCount)
dfXY <- data.frame(x=rep(0:99, each=100) , y=rep(0:99, each=1)  , cellCount=sample(0:99, 10000 , replace=T) )

dfStartPoints <- data.frame(x=sample(10:20, 3 , replace=T) , y=sample(30:40, 3 , replace=T)  )
dfEndPoints <- data.frame(x=sample(70:80, 3 , replace=T) , y=sample(90:100, 3 , replace=T)  )



nrow(dfXY)
#get max and min
maxCells = max(dfXY$cellCount)

ggplot(dfXY, aes(x=x,y=y)) +
	geom_tile(aes(fill= cellCount), as= 1) +
	labs(title="Primitive Cell Density", x="mm", y="mm") +
	scale_fill_continuous(  space= "Lab" , low="white", high="black" , breaks=seq(0,maxCells ,by=round(maxCells/10) ), guide = guide_legend( title =
"Cells/Area\n(100um^2)" ) ) +
	coord_fixed() +
	geom_point(data=dfStartPoints  , aes( colour="red"  ) ) +
	labs(color="Start Points" ) +
	geom_point(data=dfEndPoints  , aes( colour="green"  ) ) +
	labs(color="End Points" )

#######################################################################

(See attached file: R_test.PNG)(See attached file: help_test_2.r)

Rolf  Kemper, Manager, Mixed Signal Design, Networking, Renesas Electronics Europe GmbH, , Arcadiastr. 10, 40472, Duesseldorf, Germany,  Phone:+49 211
6503-1475, Fax:+49 211 6503-1540, mailto:Rolf.Kemper at renesas.com, http://www.renesas.eu

This message is intended only for the use of the addressee(s) and may contain confidential and/or legally privileged information. If you are not the
intended recipient, you are hereby notified that any dissemination of this email (including any attachments thereto) is strictly prohibited. If you
have received this email in error, please notify the sender immediately by telephone or email  and permanently destroy the original without making any
copy. Please note that any material and advice from this mail is provided free of charge and shall be used as an example for demonstration purposes
only.
RENESAS MAKES NO WARRANTIES THAT THE USAGE OF INFORMATION OR ADVICE FROM THIS E-MAIL WILL NOT INFRINGE ANY INTELLECTUAL PROPERTY RIGHTS (E.G. PATENTS,
COPYRIGHTS). RENESAS CANNOT GUARANTEE BUG FREE OPERATION AND THE RECIPIENT WILL USE AND/OR DISTRIBUTE IT ONLY AT HIS OWN RISK. IN NO EVENT SHALL
RENESAS BE LIABLE FOR ANY DAMAGE.  The communication with Renesas Electronics Europe GmbH does not amend any written agreement in place. Renesas
Electronics Europe GmbH

Geschaeftsfuehrer/Managing Director: Robert Green Sitz der Gesellschaft/Registered office: Duesseldorf, Arcadiastrasse 10, 40472 Duesseldorf, Germany
Handelsregister/Commercial Register: Duesseldorf, HRB 3708 USt-IDNr./Tax identification no.: DE 119353406 WEEE-Reg.-Nr./WEEE reg. no.: DE 14978647

From jdnewmil at dcn.davis.CA.us  Wed Oct  2 19:24:06 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 02 Oct 2013 10:24:06 -0700
Subject: [R] Bioconductor / AnnotationDbi: Why does a GOAllFrame contain
	more rows than its argument GoFrame?
In-Reply-To: <CAPccJQF5usoNPks3pehMkDjjX_qo6C0DVrWESRDkxOmYmPUzrQ@mail.gmail.com>
References: <CAPccJQF5usoNPks3pehMkDjjX_qo6C0DVrWESRDkxOmYmPUzrQ@mail.gmail.com>
Message-ID: <f54d050b-9a5c-4b05-93fb-835964727c24@email.android.com>

You have addressed the wrong mailing list. See http://www.bioconductor.org/help/mailing-list/
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Asis Hallab <asis.hallab at gmail.com> wrote:
>Dear Bioconductor Experts,
>
>thank you for providing such a useful tool-set.
>
>I have a question regarding the package AnnotationDbi, specifically
>the classes GOFrame and GOALLFrame.
>
>During a GO Enrichment Analysis I create a data frame with Arabidopsis
>thaliana GO annotations and from that first a GOFrame and than from
>this GOFrame a GOALLFrame. Checking the result with
>
>nrow(  getGOFrameData(  athal.go.all.frame ) ) # The GOAllFrame
>
>and comparing it with
>
>nrow( athal.go.frame )                                     # The
>GoFrame
>
>I realize that the GOALLFrame has more than 5 times more rows than my
>original GO annotation table. If I provide
>organism='Arabidopsis thaliana'
>to the constructor of GOFrame this ratio increases even further.
>
>Unfortunately I could not find any documentation on this, so I feel
>forced to bother you with my questions:
>
>1) Why does GOALLFrame so many more annotations?
>2) Why and from where does it retrieve the organism specific ones that
>are added when a model organism like 'Arabidopsis thaliana' is
>provided?
>3) I suspected that all ancestors of annotated terms are added, but
>when I did so myself, I still got less GO term annotations? So do you
>add ancestors of the "is_a" type and possibly other relationship types
>like "part_of" etc. ?
>
>Please let me know your answers soon. Your help will be much
>appreciated.
>
>Kind regards!
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mtmorgan at fhcrc.org  Wed Oct  2 19:32:51 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 02 Oct 2013 10:32:51 -0700
Subject: [R] Bioconductor / AnnotationDbi: Why does a GOAllFrame contain
 more rows than its argument GoFrame?
In-Reply-To: <CAPccJQF5usoNPks3pehMkDjjX_qo6C0DVrWESRDkxOmYmPUzrQ@mail.gmail.com>
References: <CAPccJQF5usoNPks3pehMkDjjX_qo6C0DVrWESRDkxOmYmPUzrQ@mail.gmail.com>
Message-ID: <524C58C3.1020001@fhcrc.org>

On 10/02/2013 09:28 AM, Asis Hallab wrote:
> Dear Bioconductor Experts,

This will be responded to on the Bioconductor mailing list; please address any 
follow-ups there.

http://bioconductor.org/help/mailing-list/

Martin


>
> thank you for providing such a useful tool-set.
>
> I have a question regarding the package AnnotationDbi, specifically
> the classes GOFrame and GOALLFrame.
>
> During a GO Enrichment Analysis I create a data frame with Arabidopsis
> thaliana GO annotations and from that first a GOFrame and than from
> this GOFrame a GOALLFrame. Checking the result with
>
> nrow(  getGOFrameData(  athal.go.all.frame ) ) # The GOAllFrame
>
> and comparing it with
>
> nrow( athal.go.frame )                                     # The GoFrame
>
> I realize that the GOALLFrame has more than 5 times more rows than my
> original GO annotation table. If I provide
> organism='Arabidopsis thaliana'
> to the constructor of GOFrame this ratio increases even further.
>
> Unfortunately I could not find any documentation on this, so I feel
> forced to bother you with my questions:
>
> 1) Why does GOALLFrame so many more annotations?
> 2) Why and from where does it retrieve the organism specific ones that
> are added when a model organism like 'Arabidopsis thaliana' is
> provided?
> 3) I suspected that all ancestors of annotated terms are added, but
> when I did so myself, I still got less GO term annotations? So do you
> add ancestors of the "is_a" type and possibly other relationship types
> like "part_of" etc. ?
>
> Please let me know your answers soon. Your help will be much appreciated.
>
> Kind regards!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From deter088 at umn.edu  Wed Oct  2 19:50:34 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 2 Oct 2013 12:50:34 -0500
Subject: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U) test
In-Reply-To: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>
References: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>
Message-ID: <CAOLJphmmGffr32rpT0fcHzeaNzr6hFc9gTC6fvkdU+we5GcKMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/26fff257/attachment.pl>

From dwinsemius at comcast.net  Wed Oct  2 19:56:37 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 2 Oct 2013 10:56:37 -0700
Subject: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U) test
In-Reply-To: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>
References: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>
Message-ID: <346C8C4A-C167-4F37-9A6E-529FFD7FFDC4@comcast.net>


On Oct 2, 2013, at 8:33 AM, Filipe Correia wrote:

> Hello everyone,
> 
> I'm having some trouble interpreting the results of a Wilcoxon
> (Mann-Whitney U) test. Hope you can help.
> 
> This is the R script that I am running:
> 
> a <- c(1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 5, 1, 1, 1, 3, 1, 1,
> 1, 1, 1, 1, 3, 1, 1)
> b <- c(1, 2, 1, 1, 2, 3, 2, 2, 1, 2, 1, 1, 1, 2)
> wilcox.test(a, b, alternative="t", mu=0, exact=FALSE, paired=FALSE)  #1st
> wilcox.test(a, b, alternative="l", mu=0, exact=FALSE, paired=FALSE)  #2nd
> wilcox.test(a, b, alternative="g", mu=0, exact=FALSE, paired=FALSE)  #3rd
> 
> ... and it's returning:
> 
> Wilcoxon rank sum test with continuity correction data:  a and b
> W = 145, p-value = 0.08969
> alternative hypothesis: true location shift is not equal to 0
> 
> Wilcoxon rank sum test with continuity correction data:  a and b
> W = 145, p-value = 0.04485
> alternative hypothesis: true location shift is less than 0
> 
> Wilcoxon rank sum test with continuity correction data:  a and b
> W = 145, p-value = 0.9582
> alternative hypothesis: true location shift is greater than 0
> 
> The null hypothesis is that the populations are equivalent (mu=0). The
> alternative hypothesis are that they differ, with the 2nd and 3rd runs
> of the test above considering respectively that a<b and b>a. Plus, I'm
> considering an alfa of 0.05.
> 
> My issue is that from the first run I could not conclude that there
> was a difference between the two populations (0.08969>0.05), but the
> second run leads me to think that a<b (because 0.04485<0.05).

This is not an appropriate question for R-help. You should ask your statistics instructor or pose the question in a venue where explanations of purely statistical problems are on-topic. (Just because you used R to get results that confused you does not make this an R-help-problem.)

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html


-- 

David Winsemius
Alameda, CA, USA


From rolf.kemper at renesas.com  Wed Oct  2 20:12:18 2013
From: rolf.kemper at renesas.com (rolf.kemper at renesas.com)
Date: Wed, 02 Oct 2013 20:12:18 +0200
Subject: [R] ggplot2 multiple legends modification (resent witout
	attachments)
Message-ID: <OFFF8B794A.AF7E6D4A-ONC1257BF8.0063DB50-C1257BF8.006400FA@eu.necel.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/b05c9cb0/attachment.pl>

From rayd at liondatasystems.com  Wed Oct  2 20:44:59 2013
From: rayd at liondatasystems.com (Ray DiGiacomo, Jr.)
Date: Wed, 2 Oct 2013 11:44:59 -0700
Subject: [R] Prevalence Assessment in R (Free Webinar)
Message-ID: <CACT39Na79EyHzeSh6b3Dv4hErsP=Gt8Ac7wF-X2HXuAHwDAbYw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/5c78244d/attachment.pl>

From dwinsemius at comcast.net  Wed Oct  2 20:57:08 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 2 Oct 2013 11:57:08 -0700
Subject: [R] ggplot2 multiple legends modification (resent witout
	attachments)
In-Reply-To: <OFFF8B794A.AF7E6D4A-ONC1257BF8.0063DB50-C1257BF8.006400FA@eu.necel.com>
References: <OFFF8B794A.AF7E6D4A-ONC1257BF8.0063DB50-C1257BF8.006400FA@eu.necel.com>
Message-ID: <40E32A14-63D2-4964-A0A6-03CD38F77F63@comcast.net>


On Oct 2, 2013, at 11:12 AM, rolf.kemper at renesas.com wrote:

> 
> I resent this as I recognized that attachments are not allowed.

Attachments are allowed, but only certain types . To attach data it should be MIME-text and the usual way to get attachments recognized as such jointly by your mail-client and the R mail-server is to name the file with a '.txt' extension. Extensions such as '.csv', '.dat', '.fil', '.doc' will not be forwarded to R-help subscribers. I'm not sure if '.rtf' files pass muster, so I'll just try in this reply:

-------------- next part --------------


I wonder if the googlegroups discussion forum for ggplot2 would allow attachmets of whatever type yours was?

https://groups.google.com/forum/?fromgroups#!forum/ggplot2



> Dear ALL,
> 
> please find attached a small test file. (code is copied in this mail too)
> Basically (as shown) I would like to combine several results in one graph.
> I could succeed to plot the data correctly, but the legend generation does not fit.
> For the dfStartPoints and the dfEndpoints I just want to be able to select the color AND (if possible the shape of each one)
> 
> The legend I'm getting could be modified for its title , but I was not able to to change the label value itself.
> 
> My final wish is to get 3 Legends (the one for dfXY is fully OK)
> Legend one (Titled Cell/Area...) is fully OK as it is
> Legend two should have Title "Start Point"s"  color "red" AND the count of data points as value
> Legend three should have Tile ?nd Points color "green"AND the count of data points as value.
> 
> I think I can easily get the count , but I have no idea how to modify the related  legends in code
> 
> There are many examples of this (e.g. http://docs.ggplot2.org/current/guide_legend.html )  , but  nothing fits really.
> 
> Hope someone can help on this
> 
> Rolf
> 
> ######################## code as attached ###############################
> require(sqldf)
> options(gsubfn.engine = "R")
> require(ggplot2)
> 
> rm(list=ls(all=TRUE))

Personally I consider it impolite to place that as uncommented code. I have utility functions that get blown away by that code. It would be more considerate to place it as a comment

# ------- To be uncommented to be more reproducible
# rm(list=ls(all=TRUE))


> maxCells = max(primitiveDensityMap$c)
> 
> #craete a 100 * 100 grid with random values(cellCount)
> dfXY <- data.frame(x=rep(0:99, each=100) , y=rep(0:99, each=1)  , cellCount=sample(0:99, 10000 , replace=T) )
> 
> dfStartPoints <- data.frame(x=sample(10:20, 3 , replace=T) , y=sample(30:40, 3 , replace=T)  )
> dfEndPoints <- data.frame(x=sample(70:80, 3 , replace=T) , y=sample(90:100, 3 , replace=T)  )
> 
> 
> 
> nrow(dfXY)
> #get max and min
> maxCells = max(dfXY$cellCount)
> 
> ggplot(dfXY, aes(x=x,y=y)) +
> 	geom_tile(aes(fill= cellCount), as= 1) +
> 	labs(title="Primitive Cell Density", x="mm", y="mm") +
> 	scale_fill_continuous(  space= "Lab" , low="white", high="black" , breaks=seq(0,maxCells ,by=round(maxCells/10) ), guide = guide_legend( title =
> "Cells/Area\n(100um^2)" ) ) +
> 	coord_fixed() +
> 	geom_point(data=dfStartPoints  , aes( colour="red"  ) ) +
> 	labs(color="Start Points" ) +
> 	geom_point(data=dfEndPoints  , aes( colour="green"  ) ) +
> 	labs(color="End Points" )
> 
> #######################################################################

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Wed Oct  2 21:47:22 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 02 Oct 2013 12:47:22 -0700
Subject: [R] Drawing garbled
In-Reply-To: <2311f4b1.7d65.14179de5d3b.Coremail.celsnrt@163.com>
References: <2311f4b1.7d65.14179de5d3b.Coremail.celsnrt@163.com>
Message-ID: <1e29ad3f-0d85-4a58-aad5-21e22d295a04@email.android.com>

Off topic here, this list is about R and your question is about system configuration. FWIW a common problem with execution of programs as services is permissions issues, but I have no desire to debug such OS-specific issues for you. BTW, both images look the same to me.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

yy <celsnrt at 163.com> wrote:
>Hi:
>I am Chinese, I am developing a java application, and  deploy it  to
>tomcat 7.0.42, I use rJava to use the R, when I use the command line to
>start tomcat, the R drawing well done, see attachment histview.png,but
>when i use windows service to start tomcat, the R drawing bad, see
>attachment histview2.png, I don't why, can you give me a suggestion? My
>window OS is window 7 home, thanks your help!
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Oct  2 22:23:04 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 02 Oct 2013 13:23:04 -0700
Subject: [R] R Excel - Microsoft Excel is waiting for OLE action
In-Reply-To: <6DBEEF9C09ACF64B8BCFE8F66EDA1B1F05622657@aa-exb01.theaa.local>
References: <6DBEEF9C09ACF64B8BCFE8F66EDA1B1F05622657@aa-exb01.theaa.local>
Message-ID: <9fb3e5ad-10a2-45bd-b3a1-2b1a22bbe0f7@email.android.com>

There is a mailing list devoted to supporting RExcel that you should be posting on at http://rcom.univie.ac.at/.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"Johnson, Alex" <Alex.Johnson at theaa.com> wrote:
>Hi,
>
> 
>
>I am hoping you may be able to help please?
>
>I am trying to use R Excel to run an R script using
>"RInterface.RunRFile"
>
>I have tested this command on basic scripts and they work fine. However
>when I try to run quite a long script which runs a number of forecasts
>using the forecast package, linear regressions and then tries to print
>and excel workbook I get the error
>
>Microsoft Excel is waiting for OLE action. It also opens a box that
>says
>R graphics. Both of which I can't get rid of and have to terminate
>excel.
>
> 
>
>The script works fine in R, although it takes about 8-10 minutes to run
>as it is on a lot of data and runs a number of things. But it does work
>fine.
>
>I wonder if it is the fact that the script takes so long to run that
>excel gets lost waiting for R to do its thing....
>
> 
>
>I was hoping if someone may be able to offer help please? If someone
>has
>had a similar problem which they were able to solve?
>
> 
>
>Or alternatively any idea of how to run an R script without the use of
>R
>Excel please? - through the command line?...
>
> 
>
>Thank you for your help
>
>
>Alex
>
> 
>
> 
>
>Alex Johnson
>
>Operational Research Analyst
>
>The AA
>
> 
>
>Automobile Association Developments Limited. Registered office: Fanum
>House, Basing View, Basingstoke, RG21 4EA. Registered in England and
>Wales Number: 01878835 
>
> 
>
>"To our Members we're the 4th Emergency Service"
>This electronic message contains information from The
>Au...{{dropped:17}}
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From fcorreia at gmail.com  Wed Oct  2 22:31:39 2013
From: fcorreia at gmail.com (Filipe Correia)
Date: Wed, 2 Oct 2013 21:31:39 +0100
Subject: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U) test
In-Reply-To: <CAOLJphmmGffr32rpT0fcHzeaNzr6hFc9gTC6fvkdU+we5GcKMQ@mail.gmail.com>
References: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>
	<CAOLJphmmGffr32rpT0fcHzeaNzr6hFc9gTC6fvkdU+we5GcKMQ@mail.gmail.com>
Message-ID: <CAKxRbrfw4JmefLe57WypmocXeokFD6GASPUcqzDcoXgNAPjcTg@mail.gmail.com>

Hi,

Thank you for your answer Charles.

On Wed, Oct 2, 2013 at 6:50 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
> When you chose a different alternative argument you are asking a different
> null hypothesis.

I was considering the null hypothesis was expressed through the "mu"
argument. I think I got this idea from R's docs where it states that
"the null hypothesis is that the distributions of x and y differ by a
location shift of mu" (when "a" and "b" are both given and "paired" is
FALSE).  Does the "alternative" argument also influence the null
hypothesis in some way that I may be missing?

My understanding was that by using the "alternative" argument one
would be expressing the alternative hypothesis only.

> You are looking at a two-tailed, lesser than, and greater
> than hypotheses.  Which one you chose is dependent upon your initial
> question.  Are you asking generically if your two populations (a and b) are
> different?  Are you asking if a > b or a < b?

Well, I guess I'm asking all of the three... :)
Not with the intent to choose which one fits, but because I was
experimenting and making sure I really understand how I could use R's
implementation of the Wilcoxon test. But I'm intrigued that the answer
to "are a and b different" is not consistent with "is a less than
b"... Maybe my understanding of the function's arguments and return
values is not correct? :\


Thanks,
Filipe


From fcorreia at gmail.com  Wed Oct  2 22:33:50 2013
From: fcorreia at gmail.com (Filipe Correia)
Date: Wed, 2 Oct 2013 21:33:50 +0100
Subject: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U) test
In-Reply-To: <346C8C4A-C167-4F37-9A6E-529FFD7FFDC4@comcast.net>
References: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>
	<346C8C4A-C167-4F37-9A6E-529FFD7FFDC4@comcast.net>
Message-ID: <CAKxRbrcx6UPVQ-SHx-iXK+KBYfN4ss2LxMs=Ktb2YS2Par_R2A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/fbc0ee9b/attachment.pl>

From patze003 at umn.edu  Wed Oct  2 23:40:25 2013
From: patze003 at umn.edu (Edward Patzelt)
Date: Wed, 2 Oct 2013 17:40:25 -0400
Subject: [R] fminsearch usage
Message-ID: <CADgQx8P59NecE0aW7O7bEh8j1pz4UhtURHPJwf=xW5hpTcUr9g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/61a6456a/attachment.pl>

From dwinsemius at comcast.net  Wed Oct  2 23:45:12 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 2 Oct 2013 14:45:12 -0700
Subject: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U) test
In-Reply-To: <CAKxRbrcx6UPVQ-SHx-iXK+KBYfN4ss2LxMs=Ktb2YS2Par_R2A@mail.gmail.com>
References: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>
	<346C8C4A-C167-4F37-9A6E-529FFD7FFDC4@comcast.net>
	<CAKxRbrcx6UPVQ-SHx-iXK+KBYfN4ss2LxMs=Ktb2YS2Par_R2A@mail.gmail.com>
Message-ID: <82BDCC2B-6E9F-43F5-BC26-92A8D194D3AE@comcast.net>


On Oct 2, 2013, at 1:33 PM, Filipe Correia wrote:

> David,
> 
> On Wed, Oct 2, 2013 at 6:56 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> This is not an appropriate question for R-help. You should ask your statistics instructor or pose the question in a venue where explanations of purely statistical problems are on-topic. (Just because you used R to get results that confused you does not make this an R-help-problem.)
> 
> Well, I'm not sure whether I'm asking a statistics question or a question about how this function should be called. Of course, any help on the statistical side would also be very welcome, but if you're able to confirm that my understanding of the function's arguments and return values is right you're already helping to me a lot! :-) 

I didn't see any problems with your code. You asked three substantially different question and got appropriately different results.

-- 

David Winsemius
Alameda, CA, USA


From jim at bitwrit.com.au  Wed Oct  2 23:57:21 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 03 Oct 2013 07:57:21 +1000
Subject: [R] Drawing garbled
In-Reply-To: <2311f4b1.7d65.14179de5d3b.Coremail.celsnrt@163.com>
References: <2311f4b1.7d65.14179de5d3b.Coremail.celsnrt@163.com>
Message-ID: <524C96C1.3040101@bitwrit.com.au>

On 10/03/2013 01:51 AM, yy wrote:
> Hi:
>         I am Chinese, I am developing a java application, and  deploy it  to tomcat 7.0.42, I use rJava to use the R, when I use the command line to start tomcat, the R drawing well done, see attachment histview.png,but when i use windows service to start tomcat, the R drawing bad, see attachment histview2.png, I don't why, can you give me a suggestion? My window OS is window 7 home, thanks your help!
>
>
Hi yy,
I think that the problem is that your Windows system does not have the 
fonts to display the Chinese characters. I am not familiar with tomcat, 
but if there is a way to save the plot as a bitmapped image, that could 
be imported into Windows with the characters already rendered.

Jim


From pmenese at gmail.com  Thu Oct  3 00:11:01 2013
From: pmenese at gmail.com (Pablo Menese Camargo)
Date: Wed, 2 Oct 2013 19:11:01 -0300
Subject: [R] foreign package problem with stata 13
Message-ID: <CAG-zrWrpHVYLyB+RV6cY8Av-716jsXNpdNPhiX0WvB_2az+zhg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/4d6bdfc9/attachment.pl>

From ecjbosu at aim.com  Wed Oct  2 21:06:40 2013
From: ecjbosu at aim.com (Joe Byers)
Date: Wed, 2 Oct 2013 19:06:40 +0000
Subject: [R] rJava does not see the htmlunit java package
References: <8D08D970CB91A22-908-422CB@webmail-d244.sysops.aol.com>
Message-ID: <loom.20131002T210437-90@post.gmane.org>

Joe Byers <ecjbosu <at> aim.com> writes:
Sorry I forgot a subject.

This thread is for rJava not seeing the htmlunit java package


From richardkwock at gmail.com  Thu Oct  3 01:04:19 2013
From: richardkwock at gmail.com (Richard Kwock)
Date: Wed, 2 Oct 2013 16:04:19 -0700
Subject: [R] foreign package problem with stata 13
In-Reply-To: <CAG-zrWrpHVYLyB+RV6cY8Av-716jsXNpdNPhiX0WvB_2az+zhg@mail.gmail.com>
References: <CAG-zrWrpHVYLyB+RV6cY8Av-716jsXNpdNPhiX0WvB_2az+zhg@mail.gmail.com>
Message-ID: <CAJU8Py0gX+Bpx9YWVxVOfPDrhp9qJstg0Ly9_POPe_uoCV4JUw@mail.gmail.com>

Use "saveold" instead of "save" when you save your dataset in stata.

I don't think foreign library in R supports stata 13 yet.

Richard

On Wed, Oct 2, 2013 at 3:11 PM, Pablo Menese Camargo <pmenese at gmail.com> wrote:
> foreign package does not support dataset saved at stata 13.
> anyone knows any wayt to make it works?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pmenese at gmail.com  Thu Oct  3 01:14:51 2013
From: pmenese at gmail.com (Pablo Menese Camargo)
Date: Wed, 2 Oct 2013 20:14:51 -0300
Subject: [R] foreign package problem with stata 13
In-Reply-To: <CAJU8Py0gX+Bpx9YWVxVOfPDrhp9qJstg0Ly9_POPe_uoCV4JUw@mail.gmail.com>
References: <CAG-zrWrpHVYLyB+RV6cY8Av-716jsXNpdNPhiX0WvB_2az+zhg@mail.gmail.com>
	<CAJU8Py0gX+Bpx9YWVxVOfPDrhp9qJstg0Ly9_POPe_uoCV4JUw@mail.gmail.com>
Message-ID: <CAG-zrWrt=O69yJN8Hi6dCK8AEnatgr199sgSyFMC2Wqcw4eW4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131002/822e6bf1/attachment.pl>

From loverdyk at uoguelph.ca  Thu Oct  3 00:51:23 2013
From: loverdyk at uoguelph.ca (Orlen)
Date: Wed, 2 Oct 2013 15:51:23 -0700 (PDT)
Subject: [R] YSI data in R
Message-ID: <1380754283964-4677459.post@n4.nabble.com>

I am dealing with a huge data set collected from an YSI water monitoring
probe - the data includes water depth, transect location, temperature,
conductivity, salinity, pressure etc etc.  I am trying to do basic summary
statistics on my data and analyze the data.  

My data is organized by water depth (3, 10, 20, 40), week (1-5) and by five
transects.

I am having trouble dealing with my data and separating it by week and by
transect to see if there are trends.

I also want to do basic tests of normality.

Any suggestions? Please help.





--
View this message in context: http://r.789695.n4.nabble.com/YSI-data-in-R-tp4677459.html
Sent from the R help mailing list archive at Nabble.com.


From rolf.turner at xtra.co.nz  Thu Oct  3 03:44:48 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Thu, 03 Oct 2013 14:44:48 +1300
Subject: [R] YSI data in R
In-Reply-To: <1380754283964-4677459.post@n4.nabble.com>
References: <1380754283964-4677459.post@n4.nabble.com>
Message-ID: <524CCC10.9090502@xtra.co.nz>

On 10/03/13 11:51, Orlen wrote:
> I am dealing with a huge data set collected from an YSI water monitoring
> probe - the data includes water depth, transect location, temperature,
> conductivity, salinity, pressure etc etc.  I am trying to do basic summary
> statistics on my data and analyze the data.
>
> My data is organized by water depth (3, 10, 20, 40), week (1-5) and by five
> transects.
>
> I am having trouble dealing with my data and separating it by week and by
> transect to see if there are trends.
>
> I also want to do basic tests of normality.
>
> Any suggestions? Please help.

Your question is far too vague for anyone to be able to say anything 
even remotely
useful.  What have you tried?  What "trouble" are you having? Illustrate 
the problem(s)
with small toy data set or a small subset of your real data?

Why do you want to do tests of normality?  These are usually completely 
irrelevant.

     cheers,

     Rolf Turner


From gunter.berton at gene.com  Thu Oct  3 05:12:04 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 2 Oct 2013 20:12:04 -0700
Subject: [R] YSI data in R
In-Reply-To: <524CCC10.9090502@xtra.co.nz>
References: <1380754283964-4677459.post@n4.nabble.com>
	<524CCC10.9090502@xtra.co.nz>
Message-ID: <CACk-te1jUSG23TQxiPBM4pgJipy9-=ZmeqMs5JxnMzgLgcSYdA@mail.gmail.com>

... and I would suggest that you read and follow The Posting Guide.

-- Bert

On Wed, Oct 2, 2013 at 6:44 PM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:
> On 10/03/13 11:51, Orlen wrote:
>>
>> I am dealing with a huge data set collected from an YSI water monitoring
>> probe - the data includes water depth, transect location, temperature,
>> conductivity, salinity, pressure etc etc.  I am trying to do basic summary
>> statistics on my data and analyze the data.
>>
>> My data is organized by water depth (3, 10, 20, 40), week (1-5) and by
>> five
>> transects.
>>
>> I am having trouble dealing with my data and separating it by week and by
>> transect to see if there are trends.
>>
>> I also want to do basic tests of normality.
>>
>> Any suggestions? Please help.
>
>
> Your question is far too vague for anyone to be able to say anything even
> remotely
> useful.  What have you tried?  What "trouble" are you having? Illustrate the
> problem(s)
> with small toy data set or a small subset of your real data?
>
> Why do you want to do tests of normality?  These are usually completely
> irrelevant.
>
>     cheers,
>
>     Rolf Turner
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From loverdyk at uoguelph.ca  Thu Oct  3 04:13:25 2013
From: loverdyk at uoguelph.ca (Orlen)
Date: Wed, 2 Oct 2013 19:13:25 -0700 (PDT)
Subject: [R] YSI data in R
In-Reply-To: <1380754283964-4677459.post@n4.nabble.com>
References: <1380754283964-4677459.post@n4.nabble.com>
Message-ID: <1380766405064-4677465.post@n4.nabble.com>

My apologies.

I want to test for normality to determine whether I need to use parametric
or nonparametric tests to analyze the data.  A prof suggested this was a
good place to start with my data.

I have attached a copy of part of my data.

There are five transects, and five weeks, and each transect has up to four
water depths (3, 10, 20, 40)
<http://r.789695.n4.nabble.com/file/n4677465/Screen_Shot_2013-10-02_at_9.56.50_PM.png> 

Does this make it a bit more clear? Please let me know if there is anything
else I can add to clarify the issues I am having.

I have tried doing histograms but i cant figure out how to make multiple
ones at one time for each variable by week for each transect.



--
View this message in context: http://r.789695.n4.nabble.com/YSI-data-in-R-tp4677459p4677465.html
Sent from the R help mailing list archive at Nabble.com.


From rtomek at outlook.com  Thu Oct  3 07:25:55 2013
From: rtomek at outlook.com (Tomek R)
Date: Thu, 3 Oct 2013 01:25:55 -0400
Subject: [R] Command line r
In-Reply-To: <97567854-8B15-4F27-A4B9-96EC3A7240F1@gmail.com>
References: <BAY175-W1085BD329837B744D0F339D62A0@phx.gbl>
	<CAHfK2MtHk20E9MHZ305WuNwUzn=YXznkRVBCYMfSzuTtS1j35w@mail.gmail.com>,
	<97567854-8B15-4F27-A4B9-96EC3A7240F1@gmail.com>
Message-ID: <BAY175-W181A0D86AE6E28C90C43F2D6170@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/2e9c01ac/attachment.pl>

From jim at bitwrit.com.au  Thu Oct  3 08:06:22 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 03 Oct 2013 16:06:22 +1000
Subject: [R] YSI data in R
In-Reply-To: <1380766405064-4677465.post@n4.nabble.com>
References: <1380754283964-4677459.post@n4.nabble.com>
	<1380766405064-4677465.post@n4.nabble.com>
Message-ID: <524D095E.8000305@bitwrit.com.au>

On 10/03/2013 12:13 PM, Orlen wrote:
> My apologies.
>
> I want to test for normality to determine whether I need to use parametric
> or nonparametric tests to analyze the data.  A prof suggested this was a
> good place to start with my data.
>
> I have attached a copy of part of my data.
>
> There are five transects, and five weeks, and each transect has up to four
> water depths (3, 10, 20, 40)
> <http://r.789695.n4.nabble.com/file/n4677465/Screen_Shot_2013-10-02_at_9.56.50_PM.png>
>
> Does this make it a bit more clear? Please let me know if there is anything
> else I can add to clarify the issues I am having.
>
> I have tried doing histograms but i cant figure out how to make multiple
> ones at one time for each variable by week for each transect.
>
>
Hi Orlen,
The picture of the data you posted gives just about enough information 
to answer some of your questions.

You can get summary statistics like means broken down by factors (e.g. 
week and transect) using the "by" function.

You can plot multiple figures by small numbers of factors using various 
"panel" functions to illustrate changes over time and location.

You can test for normality using the functions in the "nortest" package.

Note that a picture of the data is unlikely to induce someone to 
laboriously type in those data. If you want to post data, take a subset 
and use the "dput" function:

dput(mydata[week==1,])

Jim


From petr.pikal at precheza.cz  Thu Oct  3 09:01:47 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 3 Oct 2013 07:01:47 +0000
Subject: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U) test
In-Reply-To: <CAKxRbrfw4JmefLe57WypmocXeokFD6GASPUcqzDcoXgNAPjcTg@mail.gmail.com>
References: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>
	<CAOLJphmmGffr32rpT0fcHzeaNzr6hFc9gTC6fvkdU+we5GcKMQ@mail.gmail.com>
	<CAKxRbrfw4JmefLe57WypmocXeokFD6GASPUcqzDcoXgNAPjcTg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B94FAE@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Filipe Correia
> Sent: Wednesday, October 02, 2013 10:32 PM
> To: Charles Determan Jr
> Cc: r-help at r-project.org
> Subject: Re: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U)
> test
> 
> Hi,
> 
> Thank you for your answer Charles.
> 
> On Wed, Oct 2, 2013 at 6:50 PM, Charles Determan Jr <deter088 at umn.edu>
> wrote:
> > When you chose a different alternative argument you are asking a
> > different null hypothesis.
> 
> I was considering the null hypothesis was expressed through the "mu"
> argument. I think I got this idea from R's docs where it states that
> "the null hypothesis is that the distributions of x and y differ by a
> location shift of mu" (when "a" and "b" are both given and "paired" is
> FALSE).  Does the "alternative" argument also influence the null
> hypothesis in some way that I may be missing?
> 
> My understanding was that by using the "alternative" argument one would
> be expressing the alternative hypothesis only.
> 
> > You are looking at a two-tailed, lesser than, and greater than
> > hypotheses.  Which one you chose is dependent upon your initial
> > question.  Are you asking generically if your two populations (a and
> > b) are different?  Are you asking if a > b or a < b?
> 
> Well, I guess I'm asking all of the three... :) Not with the intent to
> choose which one fits, but because I was experimenting and making sure
> I really understand how I could use R's implementation of the Wilcoxon
> test. But I'm intrigued that the answer to "are a and b different" is
> not consistent with "is a less than b"... Maybe my understanding of the

Your understanding of statistical test is not correct. When asking /a is not equal b/ you are "splitting" probability of alternative hypothesis to both sides, with asking /a is lower than b/ probability of alternative hypothesis is only at one side of distribution. It is really not a question of R but a question of basic statistics.

If some program gave you same answer to those questions you shall get rid of it immediately.

Regards
Petr


> function's arguments and return values is not correct? :\
> 
> 
> Thanks,
> Filipe
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p_connolly at slingshot.co.nz  Thu Oct  3 09:52:00 2013
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Thu, 3 Oct 2013 20:52:00 +1300
Subject: [R] plot multiple graphs in one graph and in multiple windows
In-Reply-To: <13A371591163EE48BD95F2D2B244AAF41C1B18F0@SNICKERS.dataventures.local>
References: <13A371591163EE48BD95F2D2B244AAF41C1B18F0@SNICKERS.dataventures.local>
Message-ID: <20131003075200.GA4253@slingshot.co.nz>


On Thu, 26-Sep-2013 at 04:47PM +0000, Hui Du wrote:

|> 
|> Hi All,
|> 
|> I have a question about plotting graphs. Supposedly, I want to plot
|> 12 graphs. Putting 12 graphs to one window seems too
|> crowded. Ideally, I want to put 4 pictures in one window and plot
|> them in three separate window. For exmaple, my psuedo code is like

Depends how you use them.  I'd be inclined to make them into a 3 page
PDF file.  However, if you really need to see them simultaneously on
the screen and can see 3 plotting windows on your screen, it would be
easier still to make the plotting window larger and do all 12 in that
window using par(mfrow = c(4, 3)) pr par(mfrow = c(3, 4)).

HTH

|> 
|> par(mfrow = c(2, 2))
|> 
|> for( I in 1:12)
|> {
|> plot(rnorm(100));
|> 
|> if( i %% 4 == 0)
|> #
|> # open a New window with par(mfrow = c(2, 2)):
|> # My question is how to control here? Thank you for your help.
|> #
|> }
|> 
|> HXD
|> 
|> 	[[alternative HTML version deleted]]
|> 
|> ______________________________________________
|> R-help at r-project.org mailing list
|> https://stat.ethz.ch/mailman/listinfo/r-help
|> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From rolf.kemper at renesas.com  Thu Oct  3 10:35:49 2013
From: rolf.kemper at renesas.com (rolf.kemper at renesas.com)
Date: Thu, 03 Oct 2013 10:35:49 +0200
Subject: [R] Status of  installing XML package on widows
Message-ID: <OF242C7C2B.03A384B6-ONC1257BF9.002E8118-C1257BF9.002F39D9@eu.necel.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/e8ec1140/attachment.pl>

From fcorreia at gmail.com  Thu Oct  3 11:13:00 2013
From: fcorreia at gmail.com (Filipe Correia)
Date: Thu, 3 Oct 2013 10:13:00 +0100
Subject: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U) test
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B94FAE@SRVEXCHMBX.precheza.cz>
References: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>
	<CAOLJphmmGffr32rpT0fcHzeaNzr6hFc9gTC6fvkdU+we5GcKMQ@mail.gmail.com>
	<CAKxRbrfw4JmefLe57WypmocXeokFD6GASPUcqzDcoXgNAPjcTg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B94FAE@SRVEXCHMBX.precheza.cz>
Message-ID: <CAKxRbrfTFi8O04J7d3xOfxOp_mukh_gyR2fkAXkfHcNkHHhNHA@mail.gmail.com>

Hi Petr,

On Thu, Oct 3, 2013 at 8:01 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>> Well, I guess I'm asking all of the three... :) Not with the intent to
>> choose which one fits, but because I was experimenting and making sure
>> I really understand how I could use R's implementation of the Wilcoxon
>> test. But I'm intrigued that the answer to "are a and b different" is
>> not consistent with "is a less than b"... Maybe my understanding of the
>
> Your understanding of statistical test is not correct. When asking /a is not equal b/ you are "splitting" probability of alternative hypothesis to both sides, with asking /a is lower than b/ probability of alternative hypothesis is only at one side of distribution. It is really not a question of R but a question of basic statistics.
>
> If some program gave you same answer to those questions you shall get rid of it immediately.

I see what you mean. Makes sense! Thank you.

Filipe


From todd.morley at clearpeak.com  Thu Oct  3 10:55:51 2013
From: todd.morley at clearpeak.com (Todd Morley)
Date: Thu, 3 Oct 2013 08:55:51 +0000
Subject: [R] tilting procedure in tilting library hangs or errors
Message-ID: <CE728D35.10E7E%Todd.Morley@clearpeak.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/25032619/attachment.pl>

From anna.longari at quantide.com  Thu Oct  3 10:13:34 2013
From: anna.longari at quantide.com (Anna Longari)
Date: Thu, 3 Oct 2013 10:13:34 +0200
Subject: [R] Problem with makePSOCKcluster R3.0.1
Message-ID: <CAJzs90VetoEsKZCqxJ0m7=ihB7LzZhq8+KkRNnhW+-0MnpATJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/d555733b/attachment.pl>

From hnorpois at gmail.com  Thu Oct  3 11:41:16 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Thu, 3 Oct 2013 11:41:16 +0200
Subject: [R] prcomp - surprising structure
Message-ID: <CAKyZeBtUUbYLYdEEaPD0aaCc8zng=BjBg9TWf3kXS-eWsrGWpw@mail.gmail.com>

Hello,

I did a pca with over 200000 snps for 340 observations (ids). If I plot the
eigenvectors (called rotation in prcomp) 2,3 and 4 (e.g. plot
(rotation[,2]) I see a strange "column" in my data (see attachment). I
suggest it is an artefact (but of what?).

Suggestion:
I used prcomp this way: prcomp (mat), where mat is a matrix with the column
means already substracted followed by a normalisation procedure (see below
for details). Is that okay? Or does prcomp repeat substraction steps?

Originally my approach was driven by the idea to compute a covariation
matrix followed by the use of eigen, but the covariation matrix was to huge
to handle. So I switched to prcomp.

As I guess that the "columns" in my plots reflect some artefact production
I hope to get some help. For the case that my use of prcomp was not okay,
could you please give me instructions how to use it - including with the
normalisation procedure that I need to include before doing a pca.

Thanks
Hermann

#
# mat: matrix with genotypes coded as 0,1 and 2 (columns); IDs
(observations) as rows.
#
prcomp.snp <- function (mat)
  {
    m <- ncol (mat)
    n <- nrow (mat)
    snp.namen <- colnames (mat)
    for (i in 1:m)
                   {
                     # snps in columns
                     ui <- mat[,i]
                     n <- length (which (!is.na(ui)))
                     # see methods Price et al. as correction
                     pi <- (1+ sum(ui, na.rm=TRUE))/(2+2*n)

                     # substract mean
                     ui <- ui - mean (ui, na.rm=TRUE)
                     # NAs set to zero
                     ui[is.na(ui)] <- 0
                     # normalisation of the genotype for each ID
important normalisation step
                     ui <- ui/ (sqrt (pi*(1-pi)))
                     # fill matrix with ui
                     mat[,i] <- ui
                   }
    mat <- prcomp (mat)
    return (mat)
   }
-------------- next part --------------
A non-text attachment was scrubbed...
Name: rotplot.png
Type: image/png
Size: 17486 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/04b3d9e5/attachment.png>

From ripley at stats.ox.ac.uk  Thu Oct  3 12:46:26 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 03 Oct 2013 11:46:26 +0100
Subject: [R] Problem with makePSOCKcluster R3.0.1
In-Reply-To: <CAJzs90VetoEsKZCqxJ0m7=ihB7LzZhq8+KkRNnhW+-0MnpATJA@mail.gmail.com>
References: <CAJzs90VetoEsKZCqxJ0m7=ihB7LzZhq8+KkRNnhW+-0MnpATJA@mail.gmail.com>
Message-ID: <524D4B02.3050800@stats.ox.ac.uk>

On 03/10/2013 09:13, Anna Longari wrote:
> Hello,
> I am using function makePSOCKcluster to make parallel computation on 3 EC2
> Amazon machines.
> I have a passwordless between machines and ssh is correct.
> In the R 2.15.1 release this function works correctly.
> Installing R 3.0.1 on my EC2 machines makePSOCKcluster does not produce the
> cluster.
> If I run the function with outfile="" option, I obtain this message
>
> Error in socketConnection(master, port = port, blocking = TRUE, open =
> "a+b",  :
>    cannot open the connection
> Calls: <Anonymous> ... doTryCatch -> recvData -> makeSOCKmaster ->
> socketConnection
> In addition: Warning message:
> In socketConnection(master, port = port, blocking = TRUE, open = "a+b",  :
>    ip-10-158-31-12:11883 cannot be opened
> Execution halted
>
> Can you help me?

No.  The issue is in your configuration -- that sockets cannot be opened 
is not an R issue.

Look at the NEWS file to see what has changed and hence how you might be 
able to address it:

     ? The port used by socket clusters is chosen randomly: this should
       help to avoid clashes observed when two users of a multi-user
       machine try to create a cluster at the same time.  To reproduce
       the previous behaviour set environment variable R_PARALLEL_PORT
       to 10187.


>
> Best regards
>
> Anna Longari
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

PLEASE do: no HTML mail for a start, and use current R.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From S.Ellison at lgcgroup.com  Thu Oct  3 13:05:29 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Thu, 3 Oct 2013 12:05:29 +0100
Subject: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U) test
In-Reply-To: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>
References: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487C275ED@GOLD.corp.lgc-group.com>



> I'm having some trouble interpreting the results of a Wilcoxon
> (Mann-Whitney U) test. Hope you can help.

Two-tailed and one tailed tests generally give different p-values, with the two-tailed p-value twice (one of) the one-tailed values for rather obvious reasons. You need to sort out which question you wanted the answer to.

Having said that, if a factor of two in the p-value changes your interpretation, you probably haven't got a really compelling result.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From istazahn at gmail.com  Thu Oct  3 13:19:54 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 3 Oct 2013 07:19:54 -0400
Subject: [R] Status of installing XML package on widows
In-Reply-To: <OF242C7C2B.03A384B6-ONC1257BF9.002E8118-C1257BF9.002F39D9@eu.necel.com>
References: <OF242C7C2B.03A384B6-ONC1257BF9.002E8118-C1257BF9.002F39D9@eu.necel.com>
Message-ID: <CA+vqiLEAWVxUVzB0nyYMDVX+x8THT7ypiYHFfPkZCXVEOrYZ8Q@mail.gmail.com>

Hi Rolf,

On Thu, Oct 3, 2013 at 4:35 AM,  <rolf.kemper at renesas.com> wrote:
>
>
> Hello Experts,
>
> I would like to utilize the XML package which is obviously quite new.

I think it's been around for quite some time actually. The ReadMe file
says it was originally developed in 1999.

>
> There are tons of messages in the web dealing with issues on that.

Dealing with issues in on what?

> But I did not see any clear up to date solution.

Solution to what? What is the problem.

> On top my R on windows tell me that this is not available fro 3.01 which is quite puzzling for me.
>
> So what is the latest status ?
> Can I run it with R 3.01 ?

As far as I know this should just work.

>
> Here is what I did:
> #########################################################################################################
>> version
>                _
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          3
> minor          0.1
> year           2013
> month          05
> day            16
> svn rev        62743
> language       R
> version.string R version 3.0.1 (2013-05-16)
> nickname       Good Sport
>>
>> install.packages('XML', repos='http://cran.r-mirror.de')
> Warning: unable to access index for repository http://cran.r-mirror.de/bin/windows/contrib/3.0
> Warning message:
> package ?XML? is not available (for R version 3.0.1)

Try a different mirror (if you omit the repos argument and have not
changed the default you can select on interactively when you run
install.packages()

>>
> ##########################################################################################################
>
> Do I have a chance to install it somehow ?
> What about installing on linux for redhat5 ?

You seem to be under the impression that installing the XML package is
difficult or unusual. As far as I know neither of these is true. It
should just work.

>
>
> Sorry for so many questions. I think this is a very, very  useful package and I see many possible applications.
>
> Thanks a lot
>
> Rolf
>
>
>
> Rolf  Kemper, Manager, Mixed Signal Design, Networking, Renesas Electronics Europe GmbH, , Arcadiastr. 10, 40472, Duesseldorf, Germany,  Phone:+49 211
> 6503-1475, Fax:+49 211 6503-1540, mailto:Rolf.Kemper at renesas.com, http://www.renesas.eu
>
> This message is intended only for the use of the address...{{dropped:24}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tghoward at gw.dec.state.ny.us  Thu Oct  3 13:56:08 2013
From: tghoward at gw.dec.state.ny.us (Tim Howard)
Date: Thu, 03 Oct 2013 07:56:08 -0400
Subject: [R] update.packages fails on pdf write - CSAgent
In-Reply-To: <mailman.31.1380794408.18042.r-help@r-project.org>
References: <mailman.31.1380794408.18042.r-help@r-project.org>
Message-ID: <524D2318020000D500B803D8@gwsmtp.dec.state.ny.us>

For the archives, the solution I've come up with is to complete the install in a location where write permissions are allowed for exe files and then simply copy the extracted files from this folder to R's library folder, using the components of update.packages as follows:


#get a list of old packages
x <- old.packages()

#download the zips            
download.packages(pkgs = x,  destdir = "C:/pathToLocationWhereWritesAreAllowed")               

#install them in the safe folder            
setwd("C:/pathToLocationWhereWritesAreAllowed")
y <- list.files(pattern = ".zip")
install.packages(pkgs = y, repos = NULL, lib = "C:/pathToLocationWhereWritesAreAllowed")

#now manually copy the folders to the R installation and overwrite the existing ones. 
 
Tim

>>>>>>>>>>>>>>>>>
Date: Wed, 02 Oct 2013 11:17:29 -0400
From: "Tim Howard" <tghoward at gw.dec.state.ny.us>
To: <r-help at r-project.org>
Subject: [R] update.packages fails on pdf write - CSAgent
Message-ID: <524C00C9020000D500B80313 at gwsmtp.dec.state.ny.us>
Content-Type: text/plain; charset=UTF-8

All,
I work in a building where our computers are running Windows XP with
Cisco Security Agent (CSA) activated, locking many automated actions,
especially file writes. We (lowly staff) are allowed to install
software, so on upgrading to R 3.0.2, I tried the standard approach for
updating my packages: Copying the non-base folders from my older
installation into the library folder and running

update.packages(checkBuilt=TRUE, ask=FALSE)

R merrily downloads from the mirror and then continues installation --
until it gets to a package that has a pdf to write, as follows:

> update.packages(checkBuilt=TRUE, ask=FALSE)
--- Please select a CRAN mirror for use in this session ---
trying URL
'http://cran.mirrors.hoobly.com/bin/windows/contrib/3.0/akima_0.5-11.zip'
Content type 'application/zip' length 370759 bytes (362 Kb)
opened URL
downloaded 362 Kb

trying URL
'http://cran.mirrors.hoobly.com/bin/windows/contrib/3.0/bitops_1.0-6.zip'
Content type 'application/zip' length 35878 bytes (35 Kb)
opened URL
downloaded 35 Kb

trying URL
'http://cran.mirrors.hoobly.com/bin/windows/contrib/3.0/chron_2.3-44.zip'
Content type 'application/zip' length 105192 bytes (102 Kb)
opened URL
downloaded 102 Kb
trying URL
'http://cran.mirrors.hoobly.com/bin/windows/contrib/3.0/colorspace_1.2-4.zip'
Content type 'application/zip' length 384585 bytes (375 Kb)
opened URL
downloaded 375 Kb
< .. many more packages ...>

package ?akima? successfully unpacked and MD5 sums checked
package ?bitops? successfully unpacked and MD5 sums checked
package ?chron? successfully unpacked and MD5 sums checked
Error in unzip(zipname, exdir = dest) : 
  cannot open file 'C:/Program
Files/R/R-3.0.2/library/file8ec2cd16e8/colorspace/doc/hcl-colors.pdf':
Permission denied
> 
Here's the message from the Application log in my Event Viewer:

The process 'C:\Program Files\R\R-3.0.2\bin\i386\Rgui.exe' (as user
<myusername>) attempted to access 'C:\Program
Files\R\R-3.0.2\library\file8ec2cd16e8\colorspace\doc\hcl-colors.pdf'.
The attempted access was a write (operation = OPEN/CREATE). The
operation was denied.

So it seems to me that CSA is blocking the installation of this package
because of the PDF write attempt. Please correct me if my interpretation
is wrong!

I can re-install these packages manually, but would love to do it
automatically.

My Questions:

It seems that the pdf is 'extra' since it isn't required for all
packages. Is there a way for me to tell update.packages to not install
these extras? I don't see that as an option at ?update.packages, but I
may be missing it.

Alternatively, is there an easy way to identify and download the zips
needed in a folder of my choice and but then finish the install
manually?

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                
         
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base   


loaded via a namespace (and not attached):
[1] tools_3.0.2
> 

Thanks for any help

Tim


From nalimilan at club.fr  Thu Oct  3 14:19:04 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Thu, 03 Oct 2013 14:19:04 +0200
Subject: [R] Status of  installing XML package on widows
In-Reply-To: <OF242C7C2B.03A384B6-ONC1257BF9.002E8118-C1257BF9.002F39D9@eu.necel.com>
References: <OF242C7C2B.03A384B6-ONC1257BF9.002E8118-C1257BF9.002F39D9@eu.necel.com>
Message-ID: <1380802744.13506.55.camel@milan>

Le jeudi 03 octobre 2013 ? 10:35 +0200, rolf.kemper at renesas.com a
?crit :
> 
> Hello Experts,
> 
> I would like to utilize the XML package which is obviously quite new.
> 
> There are tons of messages in the web dealing with issues on that.
> But I did not see any clear up to date solution.
> On top my R on windows tell me that this is not available fro 3.01
> which is quite puzzling for me.
> 
> So what is the latest status ?
> Can I run it with R 3.01 ?
> 
> Here is what I did:
> #########################################################################################################
> > version
>                _
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          3
> minor          0.1
> year           2013
> month          05
> day            16
> svn rev        62743
> language       R
> version.string R version 3.0.1 (2013-05-16)
> nickname       Good Sport
> >
> > install.packages('XML', repos='http://cran.r-mirror.de')
> Warning: unable to access index for repository
> http://cran.r-mirror.de/bin/windows/contrib/3.0
> Warning message:
> package ?XML? is not available (for R version 3.0.1)
> >
> ##########################################################################################################
> 
> Do I have a chance to install it somehow ?
> What about installing on linux for redhat5 ?
> 
> 
> Sorry for so many questions. I think this is a very, very  useful
> package and I see many possible applications.
The XML package is a little special on Windows: you must not point via
the "repos" option to a CRAN mirror, since XML is hosted on Brian
Ripley's CRAN extras repository at http://www.stats.ox.ac.uk/pub/RWin/
(see the R FAQ point 5.1.2). This repository is enabled by default on
Windows, so
install.packages("XML")
should be enough there.


Regards

> Thanks a lot
> 
> Rolf
> 
> 
> 
> Rolf  Kemper, Manager, Mixed Signal Design, Networking, Renesas
> Electronics Europe GmbH, , Arcadiastr. 10, 40472, Duesseldorf,
> Germany,  Phone:+49 211
> 6503-1475, Fax:+49 211 6503-1540, mailto:Rolf.Kemper at renesas.com,
> http://www.renesas.eu
> 
> This message is intended only for the use of the address...{{dropped:24}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nalimilan at club.fr  Thu Oct  3 14:20:38 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Thu, 03 Oct 2013 14:20:38 +0200
Subject: [R] Status of  installing XML package on widows
In-Reply-To: <OF242C7C2B.03A384B6-ONC1257BF9.002E8118-C1257BF9.002F39D9@eu.necel.com>
References: <OF242C7C2B.03A384B6-ONC1257BF9.002E8118-C1257BF9.002F39D9@eu.necel.com>
Message-ID: <1380802838.13506.56.camel@milan>

Le jeudi 03 octobre 2013 ? 10:35 +0200, rolf.kemper at renesas.com a
?crit :
> 
> Hello Experts,
> 
> I would like to utilize the XML package which is obviously quite new.
> 
> There are tons of messages in the web dealing with issues on that.
> But I did not see any clear up to date solution.
> On top my R on windows tell me that this is not available fro 3.01
> which is quite puzzling for me.
> 
> So what is the latest status ?
> Can I run it with R 3.01 ?
> 
> Here is what I did:
> #########################################################################################################
> > version
>                _
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          3
> minor          0.1
> year           2013
> month          05
> day            16
> svn rev        62743
> language       R
> version.string R version 3.0.1 (2013-05-16)
> nickname       Good Sport
> >
> > install.packages('XML', repos='http://cran.r-mirror.de')
> Warning: unable to access index for repository
> http://cran.r-mirror.de/bin/windows/contrib/3.0
> Warning message:
> package ?XML? is not available (for R version 3.0.1)
> >
> ##########################################################################################################
> 
> Do I have a chance to install it somehow ?
> What about installing on linux for redhat5 ?
> 
> 
> Sorry for so many questions. I think this is a very, very  useful
> package and I see many possible applications.
The XML package is a little special on Windows: you must not point via
the "repos" option to a CRAN mirror, since XML is hosted on Brian
Ripley's CRAN extras repository at http://www.stats.ox.ac.uk/pub/RWin/
(see the R FAQ point 5.1.2). This repository is enabled by default on
Windows, so
install.packages("XML")
should be enough there.


Regards

> Thanks a lot
> 
> Rolf
> 
> 
> 
> Rolf  Kemper, Manager, Mixed Signal Design, Networking, Renesas
> Electronics Europe GmbH, , Arcadiastr. 10, 40472, Duesseldorf,
> Germany,  Phone:+49 211
> 6503-1475, Fax:+49 211 6503-1540, mailto:Rolf.Kemper at renesas.com,
> http://www.renesas.eu
> 
> This message is intended only for the use of the address...{{dropped:24}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nalimilan at club.fr  Thu Oct  3 14:21:11 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Thu, 03 Oct 2013 14:21:11 +0200
Subject: [R] Status of  installing XML package on widows
In-Reply-To: <OF242C7C2B.03A384B6-ONC1257BF9.002E8118-C1257BF9.002F39D9@eu.necel.com>
References: <OF242C7C2B.03A384B6-ONC1257BF9.002E8118-C1257BF9.002F39D9@eu.necel.com>
Message-ID: <1380802871.13506.57.camel@milan>

Le jeudi 03 octobre 2013 ? 10:35 +0200, rolf.kemper at renesas.com a
?crit :
> 
> Hello Experts,
> 
> I would like to utilize the XML package which is obviously quite new.
> 
> There are tons of messages in the web dealing with issues on that.
> But I did not see any clear up to date solution.
> On top my R on windows tell me that this is not available fro 3.01
> which is quite puzzling for me.
> 
> So what is the latest status ?
> Can I run it with R 3.01 ?
> 
> Here is what I did:
> #########################################################################################################
> > version
>                _
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          3
> minor          0.1
> year           2013
> month          05
> day            16
> svn rev        62743
> language       R
> version.string R version 3.0.1 (2013-05-16)
> nickname       Good Sport
> >
> > install.packages('XML', repos='http://cran.r-mirror.de')
> Warning: unable to access index for repository
> http://cran.r-mirror.de/bin/windows/contrib/3.0
> Warning message:
> package ?XML? is not available (for R version 3.0.1)
> >
> ##########################################################################################################
> 
> Do I have a chance to install it somehow ?
> What about installing on linux for redhat5 ?
> 
> 
> Sorry for so many questions. I think this is a very, very  useful
> package and I see many possible applications.
The XML package is a little special on Windows: you must not point via
the "repos" option to a CRAN mirror, since XML is hosted on Brian
Ripley's CRAN extras repository at http://www.stats.ox.ac.uk/pub/RWin/
(see the R FAQ point 5.1.2). This repository is enabled by default on
Windows, so
install.packages("XML")
should be enough there.


Regards

> Thanks a lot
> 
> Rolf
> 
> 
> 
> Rolf  Kemper, Manager, Mixed Signal Design, Networking, Renesas
> Electronics Europe GmbH, , Arcadiastr. 10, 40472, Duesseldorf,
> Germany,  Phone:+49 211
> 6503-1475, Fax:+49 211 6503-1540, mailto:Rolf.Kemper at renesas.com,
> http://www.renesas.eu
> 
> This message is intended only for the use of the address...{{dropped:24}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Thu Oct  3 14:57:41 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 3 Oct 2013 08:57:41 -0400
Subject: [R] How to extract the error flag from 'try'
Message-ID: <CAN2xGJZP0Ow32DfEntRMfU_YLvCj-+=mJ0AN2dWRYTYLACi0AQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/8cd853f2/attachment.pl>

From ggrothendieck at gmail.com  Thu Oct  3 15:07:54 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 3 Oct 2013 09:07:54 -0400
Subject: [R] How to extract the error flag from 'try'
In-Reply-To: <CAN2xGJZP0Ow32DfEntRMfU_YLvCj-+=mJ0AN2dWRYTYLACi0AQ@mail.gmail.com>
References: <CAN2xGJZP0Ow32DfEntRMfU_YLvCj-+=mJ0AN2dWRYTYLACi0AQ@mail.gmail.com>
Message-ID: <CAP01uR=QfXRo_KZWRsdGCx8wsJ6PukA6QPqH5aG5nNux9R4vww@mail.gmail.com>

On Thu, Oct 3, 2013 at 8:57 AM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Hello!
>
> I need to flag my operation as an error if it produces an error.
>
> For example, this expression produces an error:
> test<-try(log("a"))
> str(test)
>
> However, how can I proceed using the information contained in test object?
> I am looking for something like:
> if test is an error {do this and this}
> But I am not sure how to do it.
>
> I tried:
>
> class(test) %in% "try_error"
>

Try this code:

> res <- try(log("a"))
Error in log("a") : non-numeric argument to mathematical function
> if (inherits(res, "try-error")) cat(attr(res, "condition")$message, "\n")
non-numeric argument to mathematical function

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From dimitri.liakhovitski at gmail.com  Thu Oct  3 15:09:56 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 3 Oct 2013 09:09:56 -0400
Subject: [R] How to extract the error flag from 'try'
In-Reply-To: <CAP01uR=QfXRo_KZWRsdGCx8wsJ6PukA6QPqH5aG5nNux9R4vww@mail.gmail.com>
References: <CAN2xGJZP0Ow32DfEntRMfU_YLvCj-+=mJ0AN2dWRYTYLACi0AQ@mail.gmail.com>
	<CAP01uR=QfXRo_KZWRsdGCx8wsJ6PukA6QPqH5aG5nNux9R4vww@mail.gmail.com>
Message-ID: <CAN2xGJZq6MJ21iTTgxB28PjWkvVdxfo7+-q-yEoO4O8nr=buAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/29535596/attachment.pl>

From murdoch.duncan at gmail.com  Thu Oct  3 15:20:00 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 03 Oct 2013 09:20:00 -0400
Subject: [R] How to extract the error flag from 'try'
In-Reply-To: <CAN2xGJZq6MJ21iTTgxB28PjWkvVdxfo7+-q-yEoO4O8nr=buAA@mail.gmail.com>
References: <CAN2xGJZP0Ow32DfEntRMfU_YLvCj-+=mJ0AN2dWRYTYLACi0AQ@mail.gmail.com>
	<CAP01uR=QfXRo_KZWRsdGCx8wsJ6PukA6QPqH5aG5nNux9R4vww@mail.gmail.com>
	<CAN2xGJZq6MJ21iTTgxB28PjWkvVdxfo7+-q-yEoO4O8nr=buAA@mail.gmail.com>
Message-ID: <524D6F00.9010803@gmail.com>

On 03/10/2013 9:09 AM, Dimitri Liakhovitski wrote:
> Thank you very much!
> inherits(res, "try-error") is what I was looking for!

I would have expected to see this in the ?try examples section, but it's 
really hidden.  I'll look into making it more obvious.

Duncan Murdoch

>
>
> On Thu, Oct 3, 2013 at 9:07 AM, Gabor Grothendieck
> <ggrothendieck at gmail.com>wrote:
>
> > On Thu, Oct 3, 2013 at 8:57 AM, Dimitri Liakhovitski
> > <dimitri.liakhovitski at gmail.com> wrote:
> > > Hello!
> > >
> > > I need to flag my operation as an error if it produces an error.
> > >
> > > For example, this expression produces an error:
> > > test<-try(log("a"))
> > > str(test)
> > >
> > > However, how can I proceed using the information contained in test
> > object?
> > > I am looking for something like:
> > > if test is an error {do this and this}
> > > But I am not sure how to do it.
> > >
> > > I tried:
> > >
> > > class(test) %in% "try_error"
> > >
> >
> > Try this code:
> >
> > > res <- try(log("a"))
> > Error in log("a") : non-numeric argument to mathematical function
> > > if (inherits(res, "try-error")) cat(attr(res, "condition")$message, "\n")
> > non-numeric argument to mathematical function
> >
> > --
> > Statistics & Software Consulting
> > GKX Group, GKX Associates Inc.
> > tel: 1-877-GKX-GROUP
> > email: ggrothendieck at gmail.com
> >
>
>
>


From pdalgd at gmail.com  Thu Oct  3 15:27:22 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 3 Oct 2013 15:27:22 +0200
Subject: [R] prcomp - surprising structure
In-Reply-To: <CAKyZeBtUUbYLYdEEaPD0aaCc8zng=BjBg9TWf3kXS-eWsrGWpw@mail.gmail.com>
References: <CAKyZeBtUUbYLYdEEaPD0aaCc8zng=BjBg9TWf3kXS-eWsrGWpw@mail.gmail.com>
Message-ID: <0008DD19-B983-43A2-92CC-C4B0D8D4801B@gmail.com>

It's not so obvious to me that this is an artifact. What prcomp() says is that some of the eigenvectors have a lot of "activity" in some relatively narrow ranges of SNPs (on the same chromosome, perhaps?). If something artificial is going on, I could imagine effects not so much of centering columns but maybe one of
(a) imputing zero for missing values 
(b) the scaling by sqrt(pi*(1-pi)) implicitly requiring Hardy-Weinberg equilibrium, so if your data are all 0 or 2 (aa or AA) there will be overdispersion.

However, it could also be a biological effect. Are your ids by any chance from the same pedigree? If so, you might be seeing something like the effect of a crossover event in a distant ancestor. (Talk to a geneticist, I just "play one on TV".) 

To investigate further, you could go looking at the individual scores and see who is having extreme values on component 2-4 and then go back and see if there is something peculiar about their SNPs in the "strange" region.

Of course, you might have stumbled upon a bug in R, but I doubt so. 

Happy hunting!

-pd


On Oct 3, 2013, at 11:41 , Hermann Norpois wrote:

> Hello,
> 
> I did a pca with over 200000 snps for 340 observations (ids). If I plot the
> eigenvectors (called rotation in prcomp) 2,3 and 4 (e.g. plot
> (rotation[,2]) I see a strange "column" in my data (see attachment). I
> suggest it is an artefact (but of what?).
> 
> Suggestion:
> I used prcomp this way: prcomp (mat), where mat is a matrix with the column
> means already substracted followed by a normalisation procedure (see below
> for details). Is that okay? Or does prcomp repeat substraction steps?
> 
> Originally my approach was driven by the idea to compute a covariation
> matrix followed by the use of eigen, but the covariation matrix was to huge
> to handle. So I switched to prcomp.
> 
> As I guess that the "columns" in my plots reflect some artefact production
> I hope to get some help. For the case that my use of prcomp was not okay,
> could you please give me instructions how to use it - including with the
> normalisation procedure that I need to include before doing a pca.
> 
> Thanks
> Hermann
> 
> #
> # mat: matrix with genotypes coded as 0,1 and 2 (columns); IDs
> (observations) as rows.
> #
> prcomp.snp <- function (mat)
>  {
>    m <- ncol (mat)
>    n <- nrow (mat)
>    snp.namen <- colnames (mat)
>    for (i in 1:m)
>                   {
>                     # snps in columns
>                     ui <- mat[,i]
>                     n <- length (which (!is.na(ui)))
>                     # see methods Price et al. as correction
>                     pi <- (1+ sum(ui, na.rm=TRUE))/(2+2*n)
> 
>                     # substract mean
>                     ui <- ui - mean (ui, na.rm=TRUE)
>                     # NAs set to zero
>                     ui[is.na(ui)] <- 0
>                     # normalisation of the genotype for each ID
> important normalisation step
>                     ui <- ui/ (sqrt (pi*(1-pi)))
>                     # fill matrix with ui
>                     mat[,i] <- ui
>                   }
>    mat <- prcomp (mat)
>    return (mat)
>   }
> <rotplot.png>______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mbressan at arpa.veneto.it  Thu Oct  3 16:41:40 2013
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Thu, 03 Oct 2013 16:41:40 +0200
Subject: [R] storing element number of a list in a column data frame
Message-ID: <524D8224.5080604@arpa.veneto.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/9c94f049/attachment.pl>

From gunter.berton at gene.com  Thu Oct  3 16:55:05 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 3 Oct 2013 07:55:05 -0700
Subject: [R] storing element number of a list in a column data frame
In-Reply-To: <524D8224.5080604@arpa.veneto.it>
References: <524D8224.5080604@arpa.veneto.it>
Message-ID: <CACk-te2085SvVLT8oB6KmKbJz4amvE5r=BDuv2TYsDssob3TvA@mail.gmail.com>

Have you read An Introduction to R (ships with R) or another of the
many excellent R tutorials on the web? I ask, because you do not
appear to be using a sensible data structure. As your list appears to
be of a single type (probably numeric, maybe integer), it would be
preferable to use a vector, like this:

y <- c(45, NA, 18, NA, 99)

(The NULLS must be converted to NA's to "hold" their places).

There would then seem to be little need for the data frame structure,
as it tends to slow things down in R. But if you insist,

which(is.na(y))

will give you the indices of the NA's.

See also: ?is.na  ?is.null.


Cheers,
Bert



On Thu, Oct 3, 2013 at 7:41 AM, Massimo Bressan <mbressan at arpa.veneto.it> wrote:
> #let's suppose I have a list like this
>
> mytest<-list(45, NULL, 18, NULL, 99)
>
> #to note that this is just an amended example because in fact
>
> #I'm dealing with a long list (more than 400 elements)
>
> #with no evident pattern of the NULL values
>
> #I want to end up with a data frame like the following
>
> data.frame(i=c(1,3,5), n=c(45,18,99))
>
> #i.e. a data frame storing in
>
> #column i the number of corresponding element list
>
> #column n the unique component of that element
>
> #I've been trying with
>
> do.call(rbind, mytest)
>
> #or
>
> do.call(rbind.data.frame, mytest)
>
> #but this approach is not properly achieving the desired result
>
> #now I'm in trouble on how to store each element number of the list in
> the first column data frame
>
> #any help for this?
>
> #thanks
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From sarah.goslee at gmail.com  Thu Oct  3 16:58:07 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 3 Oct 2013 10:58:07 -0400
Subject: [R] storing element number of a list in a column data frame
In-Reply-To: <524D8224.5080604@arpa.veneto.it>
References: <524D8224.5080604@arpa.veneto.it>
Message-ID: <CAM_vjukmX25UPSAVL6X2510KoGWDxeKbvNTXOBO01gdVaJ3_cw@mail.gmail.com>

Hi,

Something like this, maybe:
> mytest.df <- data.frame(i=seq_along(mytest)[!sapply(mytest, is.null)], n=unlist(mytest))
> mytest.df
  i  n
1 1 45
2 3 18
3 5 99

It took me a couple of tries, because I wasn't expecting unlist() to
drop the NULL values:

> unlist(mytest)
[1] 45 18 99

Sarah

On Thu, Oct 3, 2013 at 10:41 AM, Massimo Bressan
<mbressan at arpa.veneto.it> wrote:
> #let's suppose I have a list like this
>
> mytest<-list(45, NULL, 18, NULL, 99)
>
> #to note that this is just an amended example because in fact
>
> #I'm dealing with a long list (more than 400 elements)
>
> #with no evident pattern of the NULL values
>
> #I want to end up with a data frame like the following
>
> data.frame(i=c(1,3,5), n=c(45,18,99))
>
> #i.e. a data frame storing in
>
> #column i the number of corresponding element list
>
> #column n the unique component of that element
>
> #I've been trying with
>
> do.call(rbind, mytest)
>
> #or
>
> do.call(rbind.data.frame, mytest)
>
> #but this approach is not properly achieving the desired result
>
> #now I'm in trouble on how to store each element number of the list in
> the first column data frame
>
> #any help for this?
>
> #thanks
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.functionaldiversity.org


From dcarlson at tamu.edu  Thu Oct  3 17:12:56 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 3 Oct 2013 10:12:56 -0500
Subject: [R] storing element number of a list in a column data frame
In-Reply-To: <524D8224.5080604@arpa.veneto.it>
References: <524D8224.5080604@arpa.veneto.it>
Message-ID: <009701cec04b$0a2b67a0$1e8236e0$@tamu.edu>

Try this

> i=which(!sapply(mytest, is.null))
> n=do.call(rbind, mytest[i])
> mydf <- data.frame(i, n)
> mydf
  i  n
1 1 45
2 3 18
3 5 99

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Massimo
Bressan
Sent: Thursday, October 3, 2013 9:42 AM
To: r-help at r-project.org
Subject: [R] storing element number of a list in a column data
frame

#let's suppose I have a list like this

mytest<-list(45, NULL, 18, NULL, 99)

#to note that this is just an amended example because in fact

#I'm dealing with a long list (more than 400 elements)

#with no evident pattern of the NULL values

#I want to end up with a data frame like the following

data.frame(i=c(1,3,5), n=c(45,18,99))

#i.e. a data frame storing in

#column i the number of corresponding element list

#column n the unique component of that element

#I've been trying with

do.call(rbind, mytest)

#or

do.call(rbind.data.frame, mytest)

#but this approach is not properly achieving the desired result

#now I'm in trouble on how to store each element number of the
list in 
the first column data frame

#any help for this?

#thanks


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From mbressan at arpa.veneto.it  Thu Oct  3 17:42:47 2013
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Thu, 03 Oct 2013 17:42:47 +0200
Subject: [R] storing element number of a list in a column data frame
In-Reply-To: <CACk-te2085SvVLT8oB6KmKbJz4amvE5r=BDuv2TYsDssob3TvA@mail.gmail.com>
References: <524D8224.5080604@arpa.veneto.it>
	<CACk-te2085SvVLT8oB6KmKbJz4amvE5r=BDuv2TYsDssob3TvA@mail.gmail.com>
Message-ID: <524D9077.8050402@arpa.veneto.it>

the list I'm dealing with is the follow-up of an lapply() not a "native" 
data structure I've been set up for storing data originally;
the list it's a data structure I have to manage as a consequence of my 
previous operations, something like:
path<-"./"
files <-list.files(path, pattern=".csv")
mylist<-lapply(files, function(files) 
na.omit(read.csv(paste0(path,"/",files)), header=TRUE))

anyway, thank you for the good hint: is.null seems promising
cheers
m


Il 03/10/2013 16:55, Bert Gunter ha scritto:
> Have you read An Introduction to R (ships with R) or another of the
> many excellent R tutorials on the web? I ask, because you do not
> appear to be using a sensible data structure. As your list appears to
> be of a single type (probably numeric, maybe integer), it would be
> preferable to use a vector, like this:
>
> y <- c(45, NA, 18, NA, 99)
>
> (The NULLS must be converted to NA's to "hold" their places).
>
> There would then seem to be little need for the data frame structure,
> as it tends to slow things down in R. But if you insist,
>
> which(is.na(y))
>
> will give you the indices of the NA's.
>
> See also: ?is.na  ?is.null.
>
>
> Cheers,
> Bert
>
>
>
> On Thu, Oct 3, 2013 at 7:41 AM, Massimo Bressan<mbressan at arpa.veneto.it>  wrote:
>> #let's suppose I have a list like this
>>
>> mytest<-list(45, NULL, 18, NULL, 99)
>>
>> #to note that this is just an amended example because in fact
>>
>> #I'm dealing with a long list (more than 400 elements)
>>
>> #with no evident pattern of the NULL values
>>
>> #I want to end up with a data frame like the following
>>
>> data.frame(i=c(1,3,5), n=c(45,18,99))
>>
>> #i.e. a data frame storing in
>>
>> #column i the number of corresponding element list
>>
>> #column n the unique component of that element
>>
>> #I've been trying with
>>
>> do.call(rbind, mytest)
>>
>> #or
>>
>> do.call(rbind.data.frame, mytest)
>>
>> #but this approach is not properly achieving the desired result
>>
>> #now I'm in trouble on how to store each element number of the list in
>> the first column data frame
>>
>> #any help for this?
>>
>> #thanks
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Thu Oct  3 18:01:53 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 3 Oct 2013 09:01:53 -0700 (PDT)
Subject: [R] a simple question
In-Reply-To: <BLU170-W802FE25B05F0A1E7CED77B89170@phx.gbl>
References: <BLU170-W802FE25B05F0A1E7CED77B89170@phx.gbl>
Message-ID: <1380816113.92158.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:


set.seed(494)
?h<- matrix(sample(1:40,4*124,replace=TRUE),ncol=4)

?set.seed(39)
?m<- matrix(sample(1:100,10*124,replace=TRUE),ncol=10)
?colnames(h)<- paste0("h",1:4)
?colnames(m)<- paste0("m",1:10)
mat1<-combn(colnames(m),4)

?res<- lapply(colnames(h),function(x) {x1<- h[,x];dat1<- do.call(rbind,lapply(seq_len(ncol(mat1)),function(i){ x2<- m[,mat1[,i]];GG<- lm(x1~x2[,1]+x2[,2]+x2[,3]+x2[,4]);GGsum<- summary(GG); data.frame( Models=paste(colnames(x2),collapse=","), Multiple_Rsq= GGsum$r.squared, Adjusted_Rsq = GGsum$adj.r.squared, Pval = paste(GGsum$coef[-1,4],collapse=","),stringsAsFactors=FALSE)? })); dat1[rev(order(dat1[,3])),][1:10,]})

names(res)<- colnames(h)


A.K.





________________________________
From: eliza botto <eliza_botto at hotmail.com>
To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
Sent: Thursday, October 3, 2013 11:07 AM
Subject: a simple question




Dear Arun,
I hope you are fine. I actually
wanted to discuss the following problem.
I have a linear model of the
following form. 
GG<-lm(h[,any column]~m[,any
column]+m[,any other column] +m[,any other column] +m[,any other column])
where,
h is matrix with 4 columns and
124 rows
m is matrix with 10 columns and
124 rows
what I want is the following
make a loop command to run the
linear model of all the possible combinations of columns of ?m? with each
column of ?h?. 
more precisely, if i take column
1 of matrix ?h?, it should be linear modeled with every combination of 10 (210
combinations) columns of ?m?.
All the columns of ?h? & ?m?
have certain names (you can suppose any). ?The summary(GG) will give Multiple R-squared,??? Adjusted R-squared ?and 4 values of Pr(>|t|). 
I want in the end a table in the
following format.

Models ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Multiple R-squared ? ? ? ?Adjusted R-squared ? ? ? Pr(>|t|)
Name of columns of m separated by
comma????? Multiple R-squared???????? Adjusted R-squared?????? Pr(>|t|) separated by comma

For Example?

Models ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Multiple R-squared ? ? ? ?Adjusted R-squared ? ? ??Pr(>|t|)
eliza, allen, murphy, jack ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.544 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.56 ? ? ? ? ? ? ? ? ? ? ? ? 0.000114,0.000112,0.01114,0.002114

where,
eliza, allen, murphy, jack are column names.

The models are to be enlisted in the order of their Adjusted R-squared values. The models with highest?Adjusted R-squared value should be on the top and so on. i m only interested in top 10 models. so the remaining should be ignored.?

I tried to put in my question everything but if there is anything wrong plz inform me.

Thankyou very much in advance,

Eliza


From jroyrobertson at comcast.net  Thu Oct  3 18:10:48 2013
From: jroyrobertson at comcast.net (jroyrobertson at comcast.net)
Date: Thu, 3 Oct 2013 16:10:48 +0000 (UTC)
Subject: [R] When to use RProfile.site or .Rprofile
In-Reply-To: <1050148361.2065851.1380816428893.JavaMail.root@comcast.net>
Message-ID: <774131953.2069487.1380816648137.JavaMail.root@comcast.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/a2febf45/attachment.pl>

From riccardo.marzano at polimi.it  Thu Oct  3 15:19:02 2013
From: riccardo.marzano at polimi.it (Riccardo Marzano)
Date: Thu, 3 Oct 2013 15:19:02 +0200
Subject: [R] spatialprobit
Message-ID: <001e01cec03b$24a80e40$6df82ac0$@polimi.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/af7b13af/attachment.pl>

From ecjbosu at aim.com  Thu Oct  3 15:25:17 2013
From: ecjbosu at aim.com (Joe Byers)
Date: Thu, 3 Oct 2013 13:25:17 +0000
Subject: [R] Java requested System.exit(130)
References: <CALRb-ofvrHg4w0OkaEdm7cTo297r_czhVXmdO6C0GYwp1aPf3w@mail.gmail.com>
Message-ID: <loom.20131003T152401-797@post.gmane.org>

Ed Siefker <ebs15242 <at> gmail.com> writes:

> 
> I'm used to using ctrl-c to end operations without killing R.  But I've used
> xlsx in this session, which loads Java, which apparently intercepts the
> ctrl-C.  Accordingly, I hit ctrl-C, R died, and I lost a lot of work.
> 
> I did some looking, and found a
> thread(http://comments.gmane.org/gmane.comp.lang.r.rosuda.devel/1368)
> that says:
> 
> "Yes, at least on Sun JVMs you need to add -Xrs java option so the JVM
> doesn't steal SIGINT from R (see archives)."
> 
> So, how do I actually do that? I'm not running java from the command line,
> I'm using "library(xlsx)".  How do I tell R to pass that option to the JVM?
> Thanks
> -Ed
> 
> 

You might try
#set the java.parameters option to the rs flags.

 options(java.parameters="-Xmx512mrs")
#check the option set
getOption("java.parameters") 
Good Luck
Joe


From efisio.solazzo at jrc.ec.europa.eu  Thu Oct  3 15:25:08 2013
From: efisio.solazzo at jrc.ec.europa.eu (efx)
Date: Thu, 3 Oct 2013 06:25:08 -0700 (PDT)
Subject: [R] lattice multi-panel layout
Message-ID: <1380806708263-4677500.post@n4.nabble.com>

Dear,
I seem to be unable to work out a solution for multi-panel layout using
xyplot. I have tried with layout, grid.layout (latticeExtra), but
unsuccessfully. I can produce all plots individually, but just can't figure
out how to put them all in the same panel! Here is a piece of the code. 

vlayout <- grid.layout(2,3,widths=unit(2,"inches"), heights=unit(1.5,
"inches")) 

lapply(seq(vh), function(i) {
                 for (k in 1:num_bins){
                 indexx <- which(vh[[i]]$dist<= (k*radius/num_bins) &
vh[[i]]$dist> ((k-1)*radius/num_bins))
                 bin_avg[k]<-mean(vh[[i]]$gamma[indexx])      } 
              
  plott[[i]] <- xyplot(   bin_avg ~ dist , type=("p"),  layout= vlayout) 
) } )

 - If I use grid.layout I got the error: "Error in panel.layout[1] *
panel.layout[2] : 
  non-numeric argument to binary operator"
 - If set just layout as c(2,3) all plots are drawn in the bottom left of
the panel!!!
 - If layout is not set at all, all plots are produced in different pages.

I would be grateful if you could help me out.
Regards





--
View this message in context: http://r.789695.n4.nabble.com/lattice-multi-panel-layout-tp4677500.html
Sent from the R help mailing list archive at Nabble.com.


From hnorpois at gmail.com  Thu Oct  3 16:30:57 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Thu, 3 Oct 2013 16:30:57 +0200
Subject: [R] prcomp - surprising structure
In-Reply-To: <0008DD19-B983-43A2-92CC-C4B0D8D4801B@gmail.com>
References: <CAKyZeBtUUbYLYdEEaPD0aaCc8zng=BjBg9TWf3kXS-eWsrGWpw@mail.gmail.com>
	<0008DD19-B983-43A2-92CC-C4B0D8D4801B@gmail.com>
Message-ID: <CAKyZeBvt46RLRGGZija+4sEcvdE56z9x+sm+7yeNpC8sCD6TnQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/673635be/attachment.pl>

From michael.cantinotti at uqtr.ca  Thu Oct  3 16:45:04 2013
From: michael.cantinotti at uqtr.ca (Michael Cantinotti)
Date: Thu, 03 Oct 2013 10:45:04 -0400
Subject: [R] Testing custom linear contrasts with Welch correction (anova
	function)
Message-ID: <524D82F0.60406@uqtr.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/2db86fcc/attachment.pl>

From smartpink111 at yahoo.com  Thu Oct  3 16:53:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 3 Oct 2013 07:53:58 -0700 (PDT)
Subject: [R] storing element number of a list in a column data frame
In-Reply-To: <524D8224.5080604@arpa.veneto.it>
References: <524D8224.5080604@arpa.veneto.it>
Message-ID: <1380812038.55131.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
You may try:
names(mytest)<- 1:length(mytest)
mat1<-? do.call(rbind,mytest)

dat1<-data.frame(i=row.names(mat1),n=mat1[,1])
?row.names(dat1)<- 1:nrow(dat1)
?dat1
#? i? n
#1 1 45
#2 3 18
#3 5 99

A.K.

----- Original Message -----
From: Massimo Bressan <mbressan at arpa.veneto.it>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Thursday, October 3, 2013 10:41 AM
Subject: [R] storing element number of a list in a column data frame

#let's suppose I have a list like this

mytest<-list(45, NULL, 18, NULL, 99)

#to note that this is just an amended example because in fact

#I'm dealing with a long list (more than 400 elements)

#with no evident pattern of the NULL values

#I want to end up with a data frame like the following

data.frame(i=c(1,3,5), n=c(45,18,99))

#i.e. a data frame storing in

#column i the number of corresponding element list

#column n the unique component of that element

#I've been trying with

do.call(rbind, mytest)

#or

do.call(rbind.data.frame, mytest)

#but this approach is not properly achieving the desired result

#now I'm in trouble on how to store each element number of the list in 
the first column data frame

#any help for this?

#thanks


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From daniel.hickman at live.com  Thu Oct  3 17:32:26 2013
From: daniel.hickman at live.com (Daniel Hickman)
Date: Thu, 3 Oct 2013 15:32:26 +0000
Subject: [R] =?utf-8?q?time_series_has_no_or_less_than_2_periods?=
Message-ID: <BAY403-EAS621ABB2212BCD6AA9ADEB0ED170@phx.gbl>

Hello,



I have been tasked with taking an excel file that my colleague had implemented Triple Exponential Smoothing and recreate using R. 

The following image shows the before and after of smoothing out a fixed interval time series data using Triple Exponential Smoothing inside of Excel.

enter image description here

I am trying to perform the same triple exponential smoothing in R.  I created a csv file with the before smoothing data.  The csv file is attached and can also be found here.

I found the HoltWinters method but I keep getting an error when I try to apply HoltWinters against the csv.
setwd("C:/temp")
data <- read.table("TripleExpSmoothingXLS.csv", header=TRUE, sep=",")
ts <- ts(data$QtyPerWeek, frequency=52)
HoltWinters(ts,0.46924,0.05,0.2)

This results in the following error. "Error in decompose(ts(x[1L:wind], start = start(x), frequency = f), seasonal) : time series has no or less than 2 periods"

In case it helps,  excel file with the triple exponential smoothing formulas and original data can be found here.

Any advice? 

Thanks, Dan

From careyshan at gmail.com  Thu Oct  3 18:27:28 2013
From: careyshan at gmail.com (Shane Carey)
Date: Thu, 3 Oct 2013 17:27:28 +0100
Subject: [R] Counting numbers in R
Message-ID: <CA+jRDxAQ=StpYU3V47gUQVo8KjYi0B7dSGOAqieynh456GkVoA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/07dcca2e/attachment.pl>

From jszhao at yeah.net  Thu Oct  3 18:48:33 2013
From: jszhao at yeah.net (Jinsong Zhao)
Date: Fri, 04 Oct 2013 00:48:33 +0800
Subject: [R] text position with offset
Message-ID: <524D9FE1.6070205@yeah.net>

Hi there,

I have draw a scatter plot. Now, I hope to label the points in the plot. 
For example:

plot(1:10)
text(1:10, 1:10, LETTERS[1:10])

In the above line, I can set position for each labels with pos, e.g.:

text(1:10, 1:10, LETTERS[1:10], pos = sample(1:4, 10, replace = TRUE))

as what you have seen, the length of pos can be longer than 1. in the 
above case, it has the length 10.

However, I can not set offset with length longer than 1. The following 
code always set the offset to 0.1 rather than 0.1, 0.2, ..., 1 for the 
10 labels.

text(1:10, 1:10, LETTERS[1:10], pos = sample(1:4, 10, replace = TRUE), 
offset = seq(0.1, 1, 0.1))

it seems that adj also can not be set for multiple points with different 
values.

Any hints? Thanks in advance.

Regards,
Jinsong


From olivier.crouzet at univ-nantes.fr  Thu Oct  3 18:58:57 2013
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Thu, 3 Oct 2013 18:58:57 +0200
Subject: [R] Counting numbers in R
In-Reply-To: <CA+jRDxAQ=StpYU3V47gUQVo8KjYi0B7dSGOAqieynh456GkVoA@mail.gmail.com>
References: <CA+jRDxAQ=StpYU3V47gUQVo8KjYi0B7dSGOAqieynh456GkVoA@mail.gmail.com>
Message-ID: <20131003185857.c577b9809a5156d0bd0d324c@univ-nantes.fr>

Hmmm....

Perhaps I did not understand anything but it seems to me that there
are no numbers in your data. These are character strings that you
must convert to numbers before you can identify your categories.

And also I clearly do not see any reason why you should use these
loops...

If I put your data into a data.frame called x:

> summary(x)

   Analyte             Tm_ugL           
 Length:2600        Length:2600  
 Class :character   Class :character  
 Mode  :character   Mode  :character

So you can't find what you're looking for anyway as there are no
numbers in it... You need to convert the Tm_ugL column to numeric. And
also (most of all I should say) I'm sure you don't need all these
loops...

Is this homework for a course ? This should not take more than 3/4
lines of code !

Olivier.


On Thu,
3 Oct 2013 17:27:28 +0100 Shane Carey <careyshan at gmail.com> wrote:

> Hi,
> 
> I have a set of data and I need to find out how many points are below
> a certain value but R will not calculate this properly for me.
> Negative numbers seem to be causing the issue.
> 
> This is my data:
> structure(list(Analyte = c("584501W", "584502W", "584504W", "584506W",
> "584507W", "584508W", "584509W", "584510W", "584511W", "584513W",
> "584514W", "584516W", "584517W", "584518W", "584519W", "584520W",
> "584521W", "584522W", "584523W", "584525W", "584526W", "584527W",
> "584528W", "584529W", "584530W", "584531W", "584532W", "584533W",
> "584534W", "584535W", "584536W", "584537W", "584539W", "584540W",
> "584543W", "584545W", "584546W", "584547W", "584548W", "584549W",
> "584550W", "584551W", "584552W", "584553W", "584554W", "584555W",
> "584556W", "584558W", "584561W", "584562W", "584563W", "584565W",
> "584566W", "584569W", "584570W", "584571W", "584572W", "584573W",
> "584574W", "584575W", "584577W", "584578W", "584579W", "584580W",
> "584581W", "584582W", "584584W", "584585W", "584586W", "584587W",
> "584588W", "584589W", "584590W", "584591W", "584592W", "584594W",
> "584595W", "584597W", "584599W", "584600W", "584601W", "584602W",
> "584603W", "584604W", "584606W", "584607W", "584610W", "584611W",
> "584612W", "584613W", "584614W", "584615W", "584616W", "584617W",
> "584618W", "584619W", "584620W", "584621W", "584622W", "584624W",
> "584625W", "584626W", "584627W", "584628W", "584629W", "584631W",
> "584632W", "584635W", "584636W", "584637W", "584638W", "584639W",
> "584642W", "584643W", "584644W", "584645W", "584647W", "584649W",
> "584650W", "584651W", "584652W", "584653W", "584655W", "584657W",
> "584658W", "584659W", "584660W", "584661W", "584662W", "584663W",
> "584665W", "584666W", "584667W", "584669W", "584670W", "584671W",
> "584672W", "584673W", "584674W", "584675W", "584676W", "584678W",
> "584681W", "584682W", "584683W", "584684W", "584685W", "584687W",
> "584688W", "584689W", "584691W", "584692W", "584693W", "584694W",
> "584695W", "584696W", "584697W", "584699W", "584700W", "584702W",
> "584703W", "584705W", "584706W", "584707W", "584708W", "584709W",
> "584710W", "584711W", "584713W", "584714W", "584715W", "584716W",
> "584717W", "584718W", "584720W", "584721W", "584722W", "584723W",
> "584726W", "584727W", "584728W", "584729W", "584730W", "584731W",
> "584732W", "584733W", "584734W", "584736W", "584737W", "584740W",
> "584741W", "584742W", "584743W", "584744W", "584745W", "584746W",
> "584747W", "584749W", "584751W", "584752W", "584753W", "584754W",
> "584755W", "584756W", "584757W", "584758W", "584759W", "584760W",
> "584762W", "584763W", "584764W", "584765W", "584766W", "584767W",
> "584768W", "584769W", "584772W", "584773W", "584775W", "584777W",
> "584779W", "584780W", "584781W", "584783W", "584784W", "584785W",
> "584786W", "584787W", "584788W", "584789W", "584790W", "584791W",
> "584792W", "584793W", "584795W", "584797W", "584798W", "584800W",
> "584802W", "584803W", "584804W", "584805W", "584806W", "584807W",
> "584808W", "584809W", "584810W", "584811W", "584812W", "584813W",
> "584814W", "584815W", "584816W", "584817W", "584818W", "584820W",
> "584821W", "584822W", "584823W", "584825W", "584826W", "584827W",
> "584828W", "584829W", "584830W", "584832W", "584833W", "584835W",
> "584836W", "584838W", "584839W", "584840W", "584841W", "584842W",
> "584843W", "584844W", "584845W", "584846W", "584847W", "584849W",
> "584850W", "584851W", "584853W", "584854W", "584855W", "584856W",
> "584857W", "584858W", "584859W", "584860W", "584861W", "584862W",
> "584863W", "584864W", "584865W", "584867W", "584868W", "584869W",
> "584871W", "584872W", "584873W", "584874W", "584875W", "584876W",
> "584877W", "584878W", "584880W", "584881W", "584882W", "584883W",
> "584885W", "584886W", "584887W", "584889W", "584891W", "584892W",
> "584893W", "584894W", "584895W", "584896W", "584897W", "584898W",
> "584900W", "584901W", "584903W", "584904W", "584906W", "584907W",
> "584909W", "584911W", "584913W", "584914W", "584915W", "584916W",
> "584918W", "584919W", "584920W", "584921W", "584922W", "584923W",
> "584924W", "584926W", "584928W", "584929W", "584930W", "584931W",
> "584932W", "584933W", "584934W", "584936W", "584937W", "584938W",
> "584939W", "584941W", "584943W", "584944W", "584946W", "584947W",
> "584948W", "584949W", "584950W", "584951W", "584952W", "584953W",
> "584954W", "584955W", "584957W", "584958W", "584960W", "584961W",
> "584963W", "584964W", "584965W", "584967W", "584968W", "584970W",
> "584971W", "584972W", "584973W", "584976W", "584977W", "584978W",
> "584979W", "584980W", "584981W", "584982W", "584983W", "584984W",
> "584985W", "584986W", "584987W", "584988W", "584989W", "584990W",
> "584991W", "584993W", "584994W", "584995W", "584996W", "584997W",
> "584999W", "585000W", "585001W", "585002W", "585003W", "585005W",
> "585006W", "585007W", "585008W", "585011W", "585012W", "585014W",
> "585015W", "585016W", "585017W", "585019W", "585020W", "585021W",
> "585022W", "585023W", "585024W", "585025W", "585026W", "585027W",
> "585028W", "585029W", "585031W", "585033W", "585035W", "585036W",
> "585037W", "585038W", "585039W", "585040W", "585041W", "585043W",
> "585044W", "585045W", "585046W", "585047W", "585049W", "585050W",
> "585051W", "585052W", "585055W", "585056W", "585057W", "585058W",
> "585059W", "585060W", "585061W", "585062W", "585063W", "585064W",
> "585065W", "585067W", "585068W", "585069W", "585070W", "585072W",
> "585073W", "585074W", "585075W", "585076W", "585077W", "585078W",
> "585079W", "585080W", "585082W", "585083W", "585085W", "585086W",
> "585087W", "585088W", "585089W", "585090W", "585092W", "585093W",
> "585094W", "585096W", "585097W", "585098W", "585099W", "585100W",
> "585101W", "585102W", "585104W", "585106W", "585107W", "585108W",
> "585109W", "585111W", "585113W", "585114W", "585116W", "585117W",
> "585118W", "585119W", "585120W", "585121W", "585122W", "585123W",
> "585125W", "585126W", "585127W", "585128W", "585129W", "585131W",
> "585132W", "585133W", "585134W", "585135W", "585136W", "585137W",
> "585139W", "585140W", "585141W", "585142W", "585143W", "585145W",
> "585146W", "585148W", "585149W", "585150W", "585151W", "585152W",
> "585153W", "585154W", "585155W", "585156W", "585158W", "585160W",
> "585161W", "585162W", "585163W", "585165W", "585166W", "585168W",
> "585169W", "585170W", "585171W", "585172W", "585173W", "585174W",
> "585175W", "585177W", "585178W", "585179W", "585180W", "585181W",
> "585182W", "585184W", "585185W", "585186W", "585187W", "585189W",
> "585190W", "585192W", "585193W", "585194W", "585195W", "585197W",
> "585198W", "585199W", "585200W", "585201W", "585202W", "585203W",
> "585204W", "585206W", "585207W", "585208W", "585210W", "585211W",
> "585212W", "585213W", "585214W", "585215W", "585216W", "585217W",
> "585218W", "585219W", "585220W", "585221W", "585222W", "585224W",
> "585226W", "585227W", "585228W", "585229W", "585231W", "585234W",
> "585235W", "585236W", "585237W", "585238W", "585239W", "585241W",
> "585242W", "585243W", "585244W", "585245W", "585247W", "585248W",
> "585249W", "585250W", "585251W", "585252W", "585253W", "585255W",
> "585257W", "585258W", "585259W", "585260W", "585261W", "585262W",
> "585263W", "585265W", "585266W", "585267W", "585269W", "585270W",
> "585271W", "585272W", "585273W", "585274W", "585275W", "585276W",
> "585278W", "585279W", "585280W", "585281W", "585282W", "585283W",
> "585284W", "585285W", "585287W", "585289W", "585291W", "585292W",
> "585293W", "585294W", "585295W", "585299W", "585300W", "585301W",
> "585302W", "585303W", "585305W", "585306W", "585307W", "585308W",
> "585310W", "585311W", "585313W", "585314W", "585315W", "585316W",
> "585317W", "585318W", "585320W", "585321W", "585322W", "585323W",
> "585324W", "585326W", "585327W", "585328W", "585329W", "585330W",
> "585331W", "585332W", "585333W", "585334W", "585336W", "585337W",
> "585339W", "585340W", "585341W", "585342W", "585343W", "585344W",
> "585345W", "585346W", "585347W", "585349W", "585350W", "585351W",
> "585352W", "585354W", "585355W", "585356W", "585357W", "585358W",
> "585359W", "585360W", "585363W", "585364W", "585365W", "585366W",
> "585367W", "585368W", "585371W", "585372W", "585373W", "585375W",
> "585377W", "585378W", "585379W", "585380W", "585381W", "585383W",
> "585384W", "585385W", "585387W", "585388W", "585389W", "585390W",
> "585391W", "585392W", "585395W", "585397W", "585398W", "585399W",
> "585400W", "585402W", "585403W", "585404W", "585405W", "585406W",
> "585407W", "585408W", "585409W", "585410W", "585411W", "585412W",
> "585413W", "585414W", "585415W", "585416W", "585418W", "585420W",
> "585421W", "585423W", "585425W", "585426W", "585427W", "585428W",
> "585429W", "585430W", "585432W", "585435W", "585436W", "585438W",
> "585439W", "585440W", "585441W", "585442W", "585443W", "585444W",
> "585445W", "585446W", "585447W", "585450W", "585451W", "585453W",
> "585454W", "585455W", "585456W", "585457W", "585458W", "585459W",
> "585460W", "585461W", "585462W", "585463W", "585465W", "585467W",
> "585468W", "585469W", "585471W", "585472W", "585473W", "585474W",
> "585475W", "585476W", "585477W", "585478W", "585480W", "585481W",
> "585482W", "585483W", "585485W", "585486W", "585487W", "585490W",
> "585491W", "585492W", "585493W", "585494W", "585495W", "585496W",
> "585497W", "585498W", "585500W", "585501W", "585503W", "585504W",
> "585505W", "585506W", "585507W", "585508W", "585509W", "585511W",
> "585512W", "585513W", "585514W", "585515W", "585516W", "585519W",
> "585520W", "585521W", "585522W", "585523W", "585524W", "585526W",
> "585528W", "585529W", "585530W", "585531W", "585532W", "585533W",
> "585534W", "585536W", "585537W", "585538W", "585539W", "585540W",
> "585541W", "585543W", "585546W", "585547W", "585548W", "585549W",
> "585550W", "585551W", "585552W", "585553W", "585554W", "585557W",
> "585558W", "585560W", "585561W", "585563W", "585564W", "585565W",
> "585566W", "585567W", "585568W", "585570W", "585571W", "585572W",
> "585573W", "585575W", "585576W", "585577W", "585578W", "585579W",
> "585580W", "585581W", "585582W", "585583W", "585584W", "585585W",
> "585586W", "585587W", "585588W", "585589W", "585590W", "585591W",
> "585593W", "585594W", "585595W", "585596W", "585597W", "585599W",
> "585600W", "585601W", "585602W", "585603W", "585605W", "585606W",
> "585607W", "585608W", "585609W", "585611W", "585612W", "585614W",
> "585615W", "585616W", "585617W", "585619W", "585620W", "585621W",
> "585622W", "585623W", "585624W", "585625W", "585626W", "585627W",
> "585628W", "585631W", "585633W", "585635W", "585636W", "585637W",
> "585638W", "585639W", "585640W", "585641W", "585642W", "585643W",
> "585644W", "585645W", "585646W", "585647W", "585649W", "585650W",
> "585651W", "585652W", "585654W", "585656W", "585657W", "585658W",
> "585659W", "585660W", "585661W", "585662W", "585663W", "585664W",
> "585665W", "585667W", "585668W", "585669W", "585670W", "585671W",
> "585672W", "585674W", "585675W", "585676W", "585677W", "585678W",
> "585679W", "585680W", "585682W", "585683W", "585685W", "585686W",
> "585687W", "585688W", "585689W", "585690W", "585692W", "585693W",
> "585694W", "585696W", "585697W", "585698W", "585699W", "585700W",
> "585701W", "585702W", "585704W", "585706W", "585707W", "585708W",
> "585709W", "585710W", "585711W", "585713W", "585714W", "585716W",
> "585717W", "585718W", "585719W", "585720W", "585721W", "585722W",
> "585723W", "585725W", "585726W", "585727W", "585728W", "585729W",
> "585730W", "585731W", "585732W", "585733W", "585734W", "585735W",
> "585736W", "585737W", "585739W", "585740W", "585741W", "585742W",
> "585743W", "585745W", "585746W", "585747W", "585748W", "585749W",
> "585750W", "585751W", "585752W", "585753W", "585754W", "585755W",
> "585756W", "585758W", "585760W", "585761W", "585762W", "585763W",
> "585765W", "585766W", "585768W", "585769W", "585770W", "585771W",
> "585772W", "585773W", "585774W", "585775W", "585777W", "585778W",
> "585779W", "585780W", "585781W", "585782W", "585784W", "585785W",
> "585786W", "585787W", "585788W", "585789W", "585790W", "585791W",
> "585792W", "585793W", "585794W", "585795W", "585797W", "585798W",
> "585799W", "585801W", "585802W", "585803W", "585804W", "585806W",
> "585807W", "585808W", "585810W", "585811W", "585812W", "585813W",
> "585814W", "585815W", "585816W", "585817W", "585818W", "585819W",
> "585820W", "585821W", "585822W", "585824W", "585825W", "585826W",
> "585827W", "585828W", "585829W", "585831W", "585832W", "585834W",
> "585835W", "585836W", "585837W", "585838W", "585839W", "585841W",
> "585842W", "585843W", "585844W", "585845W", "585847W", "585848W",
> "585849W", "585850W", "585851W", "585852W", "585853W", "585855W",
> "585856W", "585857W", "585858W", "585859W", "585860W", "585861W",
> "585862W", "585863W", "585865W", "585866W", "585867W", "585869W",
> "585870W", "585871W", "585872W", "585873W", "585874W", "585875W",
> "585876W", "585878W", "585879W", "585880W", "585881W", "585882W",
> "585883W", "585884W", "585885W", "585887W", "585888W", "585889W",
> "585891W", "585892W", "585893W", "585894W", "585896W", "585897W",
> "585899W", "585900W", "585901W", "585902W", "585903W", "585905W",
> "585906W", "585907W", "585908W", "585909W", "585910W", "585913W",
> "585914W", "585915W", "585916W", "585917W", "585918W", "585920W",
> "585921W", "585922W", "585923W", "585924W", "585926W", "585927W",
> "585928W", "585929W", "585930W", "585931W", "585932W", "585933W",
> "585934W", "585936W", "585937W", "585939W", "585940W", "585941W",
> "585942W", "585943W", "585944W", "585945W", "585946W", "585947W",
> "585949W", "585950W", "585951W", "585952W", "585953W", "585954W",
> "585955W", "585956W", "585957W", "585958W", "585959W", "585960W",
> "585963W", "585964W", "585965W", "585966W", "585967W", "585968W",
> "585969W", "585971W", "585972W", "585973W", "585975W", "585977W",
> "585978W", "585979W", "585980W", "585983W", "585984W", "585985W",
> "585986W", "585987W", "585989W", "585990W", "585991W", "585992W",
> "585993W", "585995W", "585997W", "585998W", "585999W", "586000W",
> "586002W", "586003W", "586004W", "586005W", "586006W", "586007W",
> "586008W", "586009W", "586010W", "586011W", "586012W", "586013W",
> "586014W", "586015W", "586016W", "586017W", "586018W", "586020W",
> "586021W", "586022W", "586023W", "586025W", "586026W", "586027W",
> "586028W", "586029W", "586030W", "586032W", "586033W", "586035W",
> "586036W", "586038W", "586039W", "586040W", "586041W", "586042W",
> "586043W", "586044W", "586045W", "586046W", "586047W", "586049W",
> "586051W", "586053W", "586054W", "586055W", "586057W", "586058W",
> "586059W", "586060W", "586061W", "586062W", "586063W", "586064W",
> "586065W", "586067W", "586068W", "586069W", "586071W", "586072W",
> "586073W", "586074W", "586075W", "586076W", "586077W", "586078W",
> "586080W", "586081W", "586082W", "586083W", "586085W", "586086W",
> "586087W", "586089W", "586090W", "586091W", "586092W", "586093W",
> "586094W", "586095W", "586096W", "586097W", "586098W", "586100W",
> "586101W", "586102W", "586104W", "586105W", "586106W", "586107W",
> "586108W", "586109W", "586111W", "586112W", "586113W", "586114W",
> "586115W", "586116W", "586118W", "586119W", "586121W", "586122W",
> "586123W", "586124W", "586126W", "586128W", "586129W", "586130W",
> "586131W", "586132W", "586134W", "586136W", "586137W", "586138W",
> "586139W", "586140W", "586141W", "586143W", "586144W", "586146W",
> "586147W", "586148W", "586149W", "586150W", "586151W", "586152W",
> "586153W", "586154W", "586155W", "586157W", "586158W", "586160W",
> "586161W", "586163W", "586164W", "586165W", "586166W", "586167W",
> "586170W", "586171W", "586172W", "586173W", "586175W", "586176W",
> "586177W", "586178W", "586179W", "586180W", "586181W", "586184W",
> "586185W", "586186W", "586187W", "586188W", "586189W", "586190W",
> "586191W", "586193W", "586194W", "586195W", "586196W", "586197W",
> "586199W", "586200W", "586201W", "586202W", "586203W", "586205W",
> "586206W", "586207W", "586208W", "586209W", "586211W", "586212W",
> "586214W", "586215W", "586216W", "586217W", "586219W", "586220W",
> "586221W", "586222W", "586223W", "586224W", "586225W", "586226W",
> "586227W", "586228W", "586229W", "586231W", "586233W", "586235W",
> "586236W", "586237W", "586238W", "586239W", "586240W", "586241W",
> "586242W", "586243W", "586244W", "586245W", "586246W", "586247W",
> "586249W", "586250W", "586251W", "586252W", "586254W", "586255W",
> "586256W", "586257W", "586258W", "586259W", "586260W", "586261W",
> "586262W", "586263W", "586264W", "586265W", "586267W", "586268W",
> "586269W", "586270W", "586272W", "586273W", "586274W", "586275W",
> "586276W", "586277W", "586278W", "586279W", "586280W", "586282W",
> "586283W", "586285W", "586286W", "586287W", "586288W", "586289W",
> "586290W", "586292W", "586293W", "586294W", "586296W", "586297W",
> "586298W", "586299W", "586300W", "586301W", "586302W", "586304W",
> "586306W", "586307W", "586308W", "586309W", "586310W", "586311W",
> "586313W", "586314W", "586316W", "586317W", "586318W", "586319W",
> "586320W", "586321W", "586322W", "586323W", "586325W", "586326W",
> "586327W", "586328W", "586329W", "586330W", "586331W", "586332W",
> "586333W", "586334W", "586335W", "586336W", "586339W", "586340W",
> "586341W", "586342W", "586343W", "586345W", "586346W", "586347W",
> "586348W", "586350W", "586351W", "586352W", "586353W", "586355W",
> "586356W", "586358W", "586360W", "586361W", "586362W", "586363W",
> "586365W", "586366W", "586368W", "586369W", "586370W", "586371W",
> "586372W", "586373W", "586374W", "586375W", "586377W", "586378W",
> "586379W", "586380W", "586381W", "586382W", "586384W", "586385W",
> "586386W", "586387W", "586388W", "586389W", "586390W", "586391W",
> "586392W", "586393W", "586394W", "586395W", "586397W", "586398W",
> "586399W", "586400W", "586401W", "586402W", "586403W", "586404W",
> "586406W", "586407W", "586408W", "586410W", "586412W", "586413W",
> "586414W", "586415W", "586416W", "586417W", "586418W", "586419W",
> "586420W", "586421W", "586422W", "586424W", "586425W", "586426W",
> "586427W", "586428W", "586429W", "586431W", "586432W", "586434W",
> "586435W", "586436W", "586437W", "586438W", "586439W", "586441W",
> "586443W", "586444W", "586445W", "586447W", "586448W", "586449W",
> "586450W", "586451W", "586452W", "586453W", "586455W", "586456W",
> "586457W", "586458W", "586459W", "586460W", "586461W", "586462W",
> "586463W", "586465W", "586466W", "586467W", "586469W", "586470W",
> "586471W", "586472W", "586473W", "586475W", "586476W", "586478W",
> "586479W", "586480W", "586481W", "586482W", "586483W", "586484W",
> "586485W", "586487W", "586488W", "586489W", "586491W", "586492W",
> "586493W", "586494W", "586495W", "586496W", "586497W", "586499W",
> "586500W", "586501W", "586502W", "586503W", "586505W", "586506W",
> "586507W", "586508W", "586509W", "586510W", "586511W", "586513W",
> "586514W", "586515W", "586516W", "586517W", "586518W", "586520W",
> "586521W", "586522W", "586523W", "586524W", "586526W", "586527W",
> "586528W", "586529W", "586530W", "586531W", "586532W", "586533W",
> "586534W", "586536W", "586537W", "586539W", "586540W", "586541W",
> "586542W", "586543W", "586544W", "586545W", "586546W", "586547W",
> "586549W", "586550W", "586552W", "586553W", "586554W", "586555W",
> "586556W", "586557W", "586558W", "586559W", "586560W", "586562W",
> "586563W", "586564W", "586565W", "586566W", "586567W", "586568W",
> "586569W", "586571W", "586572W", "586573W", "586575W", "586577W",
> "586578W", "586579W", "586580W", "586581W", "586583W", "586584W",
> "586585W", "586586W", "586587W", "586588W", "586589W", "586590W",
> "586591W", "586592W", "586593W", "586595W", "586597W", "586598W",
> "586599W", "586600W", "586602W", "586603W", "586604W", "586605W",
> "586606W", "586607W", "586608W", "586609W", "586610W", "586611W",
> "586612W", "586613W", "586614W", "586615W", "586616W", "586617W",
> "586618W", "586620W", "586621W", "586622W", "586623W", "586625W",
> "586626W", "586627W", "586628W", "586629W", "586630W", "586632W",
> "586633W", "586635W", "586636W", "586638W", "586639W", "586640W",
> "586641W", "586642W", "586643W", "586644W", "586645W", "586646W",
> "586647W", "586649W", "586650W", "586651W", "586653W", "586654W",
> "586655W", "586656W", "586657W", "586658W", "586659W", "586660W",
> "586661W", "586662W", "586663W", "586664W", "586665W", "586667W",
> "586668W", "586669W", "586671W", "586672W", "586673W", "586674W",
> "586675W", "586676W", "586677W", "586678W", "586680W", "586682W",
> "586683W", "586685W", "586686W", "586687W", "586689W", "586690W",
> "586691W", "586692W", "586693W", "586694W", "586695W", "586696W",
> "586697W", "586698W", "586701W", "586702W", "586703W", "586704W",
> "586705W", "586706W", "586707W", "586708W", "586709W", "586711W",
> "586712W", "586713W", "586714W", "586715W", "586716W", "586718W",
> "586719W", "586720W", "586721W", "586723W", "586724W", "586726W",
> "586728W", "586729W", "586730W", "586731W", "586732W", "586733W",
> "586734W", "586736W", "586737W", "586738W", "586739W", "586740W",
> "586741W", "586743W", "586744W", "586746W", "586747W", "586748W",
> "586749W", "586750W", "586751W", "586752W", "586753W", "586754W",
> "586755W", "586757W", "586758W", "586760W", "586761W", "586763W",
> "586764W", "586765W", "586766W", "586767W", "586768W", "586770W",
> "586771W", "586772W", "586773W", "586775W", "586776W", "586777W",
> "586778W", "586779W", "586780W", "586781W", "586782W", "586783W",
> "586784W", "586785W", "586786W", "586787W", "586788W", "586789W",
> "586790W", "586791W", "586793W", "586795W", "586796W", "586797W",
> "586799W", "586800W", "586801W", "586802W", "586803W", "586805W",
> "586806W", "586807W", "586808W", "586809W", "586811W", "586812W",
> "586814W", "586815W", "586816W", "586817W", "586819W", "586821W",
> "586822W", "586823W", "586824W", "586825W", "586826W", "586827W",
> "586828W", "586829W", "586831W", "586833W", "586835W", "586836W",
> "586837W", "586838W", "586839W", "586840W", "586841W", "586842W",
> "586843W", "586844W", "586845W", "586846W", "586847W", "586849W",
> "586850W", "586851W", "586852W", "586855W", "586856W", "586857W",
> "586858W", "586859W", "586860W", "586861W", "586862W", "586863W",
> "586864W", "586865W", "586867W", "586868W", "586869W", "586870W",
> "586871W", "586872W", "586873W", "586874W", "586875W", "586876W",
> "586877W", "586878W", "586879W", "586880W", "586882W", "586883W",
> "586885W", "586886W", "586887W", "586888W", "586889W", "586890W",
> "586893W", "586894W", "586896W", "586897W", "586898W", "586899W",
> "586900W", "586901W", "586902W", "586904W", "586906W", "586907W",
> "586908W", "586909W", "586910W", "586911W", "586913W", "586914W",
> "586916W", "586917W", "586918W", "586919W", "586920W", "586921W",
> "586922W", "586923W", "586925W", "586926W", "586927W", "586928W",
> "586929W", "586930W", "586931W", "586932W", "586933W", "586934W",
> "586935W", "586937W", "586939W", "586940W", "586941W", "586942W",
> "586943W", "586945W", "586946W", "586947W", "586949W", "586950W",
> "586951W", "586952W", "586953W", "586954W", "586955W", "586956W",
> "586958W", "586960W", "586961W", "586962W", "586963W", "586965W",
> "586966W", "586968W", "586969W", "586970W", "586971W", "586972W",
> "586973W", "586974W", "586975W", "586977W", "586978W", "586979W",
> "586980W", "586981W", "586982W", "586984W", "586985W", "586986W",
> "586987W", "586988W", "586989W", "586990W", "586991W", "586992W",
> "586993W", "586994W", "586995W", "586997W", "586998W", "586999W",
> "587000W", "587001W", "587002W", "587004W", "587006W", "587007W",
> "587008W", "587010W", "587011W", "587012W", "587013W", "587014W",
> "587015W", "587016W", "587017W", "587018W", "587019W", "587020W",
> "587021W", "587022W", "587024W", "587025W", "587026W", "587027W",
> "587028W", "587029W", "587031W", "587032W", "587034W", "587035W",
> "587036W", "587037W", "587038W", "587039W", "587041W", "587042W",
> "587043W", "587044W", "587045W", "587047W", "587048W", "587049W",
> "587050W", "587051W", "587052W", "587053W", "587055W", "587056W",
> "587057W", "587058W", "587059W", "587060W", "587061W", "587062W",
> "587063W", "587065W", "587067W", "587069W", "587070W", "587071W",
> "587072W", "587073W", "587074W", "587075W", "587076W", "587078W",
> "587079W", "587080W", "587081W", "587082W", "587083W", "587085W",
> "587087W", "587088W", "587089W", "587091W", "587092W", "587093W",
> "587094W", "587095W", "587096W", "587097W", "587099W", "587100W",
> "587101W", "587102W", "587103W", "587105W", "587106W", "587107W",
> "587108W", "587109W", "587110W", "587111W", "587113W", "587114W",
> "587115W", "587116W", "587117W", "587118W", "587120W", "587121W",
> "587122W", "587123W", "587124W", "587126W", "587127W", "587128W",
> "587129W", "587130W", "587131W", "587132W", "587133W", "587134W",
> "587136W", "587137W", "587139W", "587140W", "587141W", "587142W",
> "587143W", "587144W", "587145W", "587146W", "587147W", "587149W",
> "587150W", "587151W", "587152W", "587153W", "587154W", "587155W",
> "587156W", "587157W", "587158W", "587159W", "587160W", "587162W",
> "587163W", "587164W", "587165W", "587167W", "587168W", "587169W",
> "587172W", "587173W", "587175W", "587177W", "587178W", "587179W",
> "587180W", "587181W", "587183W", "587184W", "587185W", "587186W",
> "587187W", "587188W", "587189W", "587190W", "587191W", "587192W",
> "587193W", "587195W", "587197W", "587198W", "587199W", "587200W",
> "587202W", "587203W", "587204W", "587205W", "587206W", "587207W",
> "587208W", "587209W", "587210W", "587211W", "587212W", "587213W",
> "587214W", "587215W", "587216W", "587217W", "587218W", "587220W",
> "587221W", "587222W", "587223W", "587225W", "587226W", "587227W",
> "587228W", "587229W", "587230W", "587232W", "587233W", "587235W",
> "587236W", "587238W", "587239W", "587240W", "587241W", "587242W",
> "587243W", "587244W", "587245W", "587246W", "587247W", "587249W",
> "587250W", "587251W", "587253W", "587254W", "587255W", "587256W",
> "587257W", "587258W", "587259W", "587260W", "587261W", "587262W",
> "587263W", "587264W", "587265W", "587267W", "587268W", "587269W",
> "587271W", "587272W", "587273W", "587274W", "587275W", "587276W",
> "587278W", "587280W", "587281W", "587282W", "587283W", "587285W",
> "587286W", "587287W", "587289W", "587290W", "587291W", "587292W",
> "587293W", "587294W", "587295W", "587296W", "587297W", "587298W",
> "587300W", "587301W", "587302W", "587303W", "587304W", "587305W",
> "587306W", "587307W", "587309W", "587311W", "587312W", "587313W",
> "587315W", "587316W", "587318W", "587319W", "587320W", "587321W",
> "587322W", "587323W", "587324W", "587326W", "587328W", "587329W",
> "587330W", "587331W", "587332W", "587333W", "587336W", "587337W",
> "587338W", "587339W", "587340W", "587341W", "587343W", "587344W",
> "587346W", "587347W", "587348W", "587349W", "587350W", "587351W",
> "587352W", "587353W", "587354W", "587355W", "587358W", "587360W",
> "587361W", "587363W", "587364W", "587365W", "587367W", "587368W",
> "587370W", "587371W", "587372W", "587373W", "587375W", "587376W",
> "587377W", "587378W", "587379W", "587380W", "587381W", "587382W",
> "587383W", "587384W", "587385W", "587387W", "587388W", "587389W",
> "587390W", "587391W", "587393W", "587394W", "587395W", "587396W",
> "587397W", "587399W", "587400W", "587401W", "587402W", "587403W",
> "587405W", "587406W", "587407W", "587408W", "587409W", "587411W",
> "587412W", "587414W", "587415W", "587416W", "587417W", "587419W",
> "587420W", "587421W", "587422W", "587423W", "587424W", "587425W",
> "587426W", "587427W", "587428W", "587429W", "587431W", "587433W",
> "587435W", "587436W", "587437W", "587438W", "587439W", "587440W",
> "587441W", "587442W", "587443W", "587444W", "587445W", "587446W",
> "587447W", "587449W", "587450W", "587451W", "587452W", "587454W",
> "587455W", "587456W", "587457W", "587458W", "587459W", "587460W",
> "587461W", "587462W", "587463W", "587464W", "587465W", "587467W",
> "587469W", "587470W", "587471W", "587472W", "587473W", "587474W",
> "587475W", "587476W", "587477W", "587478W", "587479W", "587480W",
> "587482W", "587483W", "587485W", "587486W", "587487W", "587488W",
> "587489W", "587490W", "587492W", "587493W", "587494W", "587496W",
> "587497W", "587498W", "587499W", "587500W", "587501W", "587502W",
> "587506W", "587507W", "587508W", "587509W", "587510W", "587511W",
> "587513W", "587514W", "587516W", "587517W", "587518W", "587519W",
> "587520W", "587521W", "587522W", "587523W", "587525W", "587526W",
> "587527W", "587528W", "587529W", "587530W", "587531W", "587532W",
> "587533W", "587534W", "587537W", "587539W", "587540W", "587541W",
> "587542W", "587543W", "587545W", "587546W", "587547W", "587548W",
> "587549W", "587550W", "587551W", "587552W", "587553W", "587554W",
> "587555W", "587556W", "587558W", "587560W", "587561W", "587562W",
> "587563W", "587565W", "587566W", "587568W", "587569W", "587571W",
> "587572W", "587573W", "587574W", "587575W", "587577W", "587578W",
> "587579W", "587580W", "587581W", "587582W", "587584W", "587585W",
> "587586W", "587587W", "587588W", "587589W", "587590W", "587591W",
> "587592W", "587593W", "587594W", "587595W", "587597W", "587598W",
> "587599W", "587600W", "587601W", "587602W", "587603W", "587604W",
> "587606W", "587607W", "587608W", "587610W", "587611W", "587612W",
> "587613W", "587614W", "587616W", "587617W", "587618W", "587619W",
> "587620W", "587621W", "587622W", "587624W", "587626W", "587627W",
> "587628W", "587629W", "587631W", "587632W", "587634W", "587635W",
> "587636W", "587637W", "587638W", "587639W", "587641W", "587642W",
> "587643W", "587644W", "587645W", "587647W", "587648W", "587649W",
> "587650W", "587651W", "587652W", "587653W"), Tm_ugL = c("0.012526909",
> "0.00524721", "0.008974472", "0.014173771", "0.010261946",
> "0.006209327", "0.006427348", "0.011277134", "0.007188303",
> "0.007920061", "0.006604756", "0.002138549", "0.006412799",
> "0.003809274", "0.00258031", "0.005826568", "0.012608666",
> "0.004640139", "0.005319402", "0.009120296", "0.010841532",
> "0.005542043", "0.009347176", "0.014380953", "0.004871033",
> "0.004714329", "0.009575732", "0.006141329", "0.008756292",
> "0.015346655", "0.007429521", "0.006442689", "0.005501903",
> "0.008070111", "0.019068198", "0.006140656", "0.004317718",
> "0.003718727", "0.004044718", "0.015449818", "0.0084332",
> "0.009670819", "0.001669213", "0.004783213", "0.003404341",
> "0.007230384", "0.017716786", "0.006114732", "0.003629682",
> "0.004236707", "0.006259052", "0.013515521", "0.007139276",
> "0.004256668", "0.005247138", "0.004984855", "0.003879668",
> "0.000693273", "0.004473905", "0.005770609", "0.008615954",
> "0.019118999", "0.006625797", "0.006901367", "0.005772831",
> "0.004440397", "0.003950989", "0.004408009", "0.016313629",
> "0.018295581", "0.004482088", "0.010375151", "0.008956765",
> "0.005987772", "0.023409173", "0.006540896", "0.010740111",
> "0.009647456", "0.003929988", "0.002879241", "0.006664738",
> "0.010107742", "0.002855781", "0.002322324", "0.004469807",
> "0.003727292", "0.006530213", "0.00791199", "0.008722764",
> "0.019761435", "0.0044777", "0.004655689", "0.002153972",
> "0.003250451", "0.009378664", "0.005276846", "0.008247634",
> "0.002433585", "0.004187209", "0.00472907", "0.005241927",
> "0.007775586", "0.003037972", "0.005233932", "0.01878142",
> "0.00410588", "0.005666064", "0.008062636", "0.0062489",
> "0.009019154", "0.003570997", "0.006629886", "0.011058816",
> "0.001979885", "0.002941527", "0.006251154", "0.003072933",
> "0.005736085", "0.008841193", "0.008763499", "0.007221573",
> "0.003765729", "0.005356846", "0.007064965", "0.008571698",
> "0.00455893", "0.0032616", "0.008713323", "0.004074075",
> "0.001143222", "0.005679248", "0.006598114", "0.006193131",
> "0.005219984", "0.004462468", "0.00619499", "0.004129983",
> "0.005652558", "0.010228619", "0.010320457", "0.010966911",
> "0.023724903", "0.005534186", "0.003628177", "0.010590674",
> "0.005661125", "0.005063904", "0.006160644", "0.003499903",
> "0.005946992", "0.003108242", "0.003356377", "0.006943931",
> "0.009771657", "0.009397079", "0.010179125", "0.005096196",
> "0.006411438", "0.007634242", "0.021263574", "0.00335257",
> "0.01628002", "0.00419588", "0.015669182", "0.006572348",
> "0.003603196", "0.002637675", "0.004219162", "0.004343853",
> "0.006888431", "0.005887176", "0.003603652", "0.01252974",
> "0.005101809", "0.003068125", "0.004777023", "0.00189274",
> "0.003484976", "0.006002034", "0.004855751", "0.002779958",
> "0.006717209", "0.001116862", "0.006061243", "0.005632965",
> "0.004339326", "0.002648977", "0.001703184", "0.005310346",
> "0.003453754", "0.000996672", "0.002558453", "0.005375883",
> "0.001720969", "0.003281976", "0.016177406", "0.006860274",
> "0.005246752", "0.001095977", "0.007969571", "0.001122845",
> "0.004682038", "0.008402339", "0.001263145", "0.003866128",
> "0.004706423", "0.011472932", "-0.000965223", "0.010522683",
> "0.001015816", "0.008952635", "0.008219381", "0.005447368",
> "0.002862524", "0.002111277", "0.011379373", "0.001080124",
> "0.000907393", "0.008243656", "0.002716425", "0.00129586",
> "0.005988267", "0.003701525", "0.00154344", "0.003562045",
> "0.004103097", "0.00433579", "0.006868613", "0.003504652",
> "0.001236814", "0.00973152", "0.003779551", "0.004986519",
> "0.007649484", "0.006131166", "0.00129334", "0.012185827",
> "0.000740339", "0.009693549", "0.004989262", "0.00217159",
> "0.00289949", "0.005640732", "0.004469108", "0.008496723",
> "0.002003616", "0.001896912", "0.001620197", "0.0030765",
> "0.001022135", "0.010079904", "0.001482784", "0.009489339",
> "0.005772885", "0.003015524", "0.00067034", "0.007470405",
> "0.002496535", "0.006344776", "0.001165944", "0.014426281",
> "0.002713307", "0.001912026", "0.009576668", "0.000741203",
> "0.006366114", "0.001834612", "0.006300803", "0.001823036",
> "0.003364833", "0.006746047", "0.000802757", "0.007794059",
> "0.001700595", "0.001173412", "0.002066642", "0.006745943",
> "0.006547318", "0.009330829", "0.005193235", "0.011436552",
> "0.002624799", "0.002880703", "0.017986639", "0.006015463",
> "0.000530537", "0.000602789", "0.006180396", "0.002388551",
> "0.014148288", "0.004941805", "0.009949474", "0.001672992",
> "0.010996873", "0.007039351", "0.001490136", "0.004037547",
> "0.001063398", "0.009188556", "0.016980239", "0.005106021",
> "0.006178274", "0.003499607", "0.002544697", "0.001231949",
> "0.004662272", "0.015886709", "0.003086586", "0.000539465",
> "0.003479056", "0.000897406", "0.000962605", "0.002355382",
> "0.000274189", "0.001540451", "0.001255926", "0.000957681",
> "0.002846524", "0.00410014", "0.000797589", "0.007528205",
> "0.001371895", "0.000707452", "0.003948224", "0.001873692",
> "0.000636153", "0.001995548", "0.003618461", "0.00214816",
> "0.003296673", "0.001512562", "0.000311002", "0.014510014",
> "0.003221849", "0.003503587", "0.003542875", "0.003124834",
> "0.007303395", "0.007802568", "0.002702066", "0.00397283",
> "0.006015735", "0.005122858", "0.005532049", "0.005525161",
> "0.00613509", "0.00300218", "0.004412227", "0.003275197",
> "0.004003631", "0.002215088", "0.00584065", "0.012711175",
> "0.003779381", "0.000223868", "0.001953771", "0.012140221",
> "0.009275696", "0.001745251", "0.003159705", "0.006802756",
> "0.004796016", "0.011661546", "0.0092607", "0.012578599",
> "0.005562171", "0.00442101", "0.001562554", "0.003561927",
> "0.003685651", "0.002804282", "0.004492147", "0.004936921",
> "0.007674753", "0.00386058", "0.003376528", "0.001389595",
> "0.003299246", "0.007032604", "0.004386589", "0.006771362",
> "0.000572484", "0.006712266", "0.003898442", "0.001434171",
> "0.003106834", "0.005676694", "0.004939338", "0.007666316",
> "0.004080318", "0.005549484", "0.007699065", "0.000529283",
> "0.006992565", "0.005134453", "0.003002421", "0.009261127",
> "0.004493311", "0.000338283", "0.01131107", "0.010112226",
> "0.002444407", "0.004452528", "0.005453382", "0.008845841",
> "0.001734873", "0.004470331", "0.002201705", "0.005389719",
> "0.004956882", "0.005111852", "0.003572619", "0.003545642",
> "0.004354866", "0.002061634", "0.00811309", "0.007083798",
> "0.002999954", "0.001832538", "0.011549497", "0.005061518",
> "0.009316595", "0.003991814", "0.002861382", "0.004105657",
> "0.002296664", "0.003456477", "0.002261021", "0.006203533",
> "0.002764773", "0.002789349", "0.010631997", "0.004795557",
> "0.002844777", "0.005053105", "0.004978561", "0.003668288",
> "0.002885261", "0.004414269", "0.004583083", "0.011745086",
> "0.003786196", "0.001422543", "0.000870495", "0.002155369",
> "0.00846052", "0.006300383", "0.003517681", "0.003573642",
> "0.003731246", "0.005289539", "0.004252319", "0.004080951",
> "0.001319694", "0.004707826", "0.004099493", "0.00312036",
> "0.003618851", "0.006710461", "0.001610671", "0.002259963",
> "0.004042389", "0.00470838", "0.006533289", "0.006819086",
> "0.008734313", "0.008993864", "0.004648321", "0.005123464",
> "0.010062559", "0.005941191", "0.004586025", "0.006073371",
> "0.004040504", "0.00262404", "0.008146802", "0.009219039",
> "0.008745142", "0.007765847", "0.00575151", "0.004543592",
> "0.005352144", "0.003101024", "0.004176024", "0.017691276",
> "0.017940826", "0.014692", "0.012972434", "0.023527925",
> "0.013830272", "0.012585206", "0.005140034", "0.026267023",
> "0.007217881", "0.004373245", "0.011934211", "0.004653821",
> "0.005563568", "0.007854147", "0.00704775", "0.005819472",
> "0.015995857", "0.006181365", "0.010127657", "0.003627225",
> "0.012709818", "0.012600082", "0.017842015", "0.004550865",
> "0.019301738", "0.007032636", "0.010448506", "0.025213139",
> "0.005173896", "0.003648471", "0.009376725", "0.009395694",
> "0.011678328", "0.017157179", "0.005700391", "0.007887216",
> "0.005347332", "0.021134762", "0.016879745", "0.003602723",
> "0.016026656", "0.017132957", "0.011385071", "0.012258313",
> "0.004590344", "0.010689005", "0.011108691", "0.005776785",
> "0.003062257", "0.008456275", "0.013875346", "0.009196571",
> "0.015734791", "0.012147619", "0.009056842", "0.045055397",
> "0.007846725", "0.003301692", "0.005585407", "0.015991166",
> "0.00607262", "0.013360632", "0.011078396", "0.007874128",
> "0.003263474", "0.010696283", "0.026960067", "0.013937758",
> "0.012980693", "0.013274233", "0.006026727", "0.005807527",
> "0.010149071", "0.011532218", "0.012843804", "0.013545956",
> "0.002776432", "0.008611969", "0.003040787", "0.007443986",
> "0.001312127", "0.0003025", "0.000431156", "0.000224012",
> "0.00494154", "0.004298522", "0.006615671", "0.003321437",
> "0.007991056", "0.011949974", "0.005836289", "0.004665441",
> "0.006252763", "0.00374617", "0.002683033", "0.003340193",
> "0.001925158", "0.003125216", "0.001007901", "0.003903164",
> "0.006226041", "0.001740977", "0.001317314", "0.005100105",
> "0.000593273", "0.008145521", "0.004973538", "0.00068839",
> "0.000732802", "0.000428917", "0.002766103", "0.012660523",
> "0.001645637", "0.00194228", "0.001688429", "0.004141626",
> "0.0041443", "0.003029124", "0.007754908", "0.000996367",
> "0.000991018", "0.005289496", "0.007330816", "0.002571047",
> "0.003490755", "0.001076139", "0.00078712", "0.001583428",
> "0.004340905", "0.002949065", "0.004470728", "0.008602732",
> "0.005311726", "0.002960331", "0.000941386", "0.001882459",
> "0.000123824", "0.00178439", "0.000632667", "0.000429678",
> "0.003095699", "0.000452975", "0.000302891", "0.005672175",
> "0.003646417", "0.00024086", "0.004215561", "0.001111701",
> "0.003519762", "0.001551716", "0.003735266", "0.003006485",
> "0.00930933", "0.001057213", "0.004632536", "0.00294505",
> "0.006906513", "0.003412497", "0.002686386", "0.014712222",
> "0.000761156", "0.00241515", "0.00239045", "0.00238927",
> "0.002321314", "0.004854263", "0.002159585", "0.002665453",
> "0.004460844", "0.000830435", "0.000765838", "0.000212462",
> "0.00443449", "0.00351636", "0.003494146", "0.000119735",
> "0.001635048", "0.002138772", "0.003385075", "0.002765276",
> "0.000731873", "0.003022143", "0.001147037", "0.002694729",
> "0.002468001", "0.003206428", "0.00087695", "0.003926637",
> "0.001024658", "0.022591566", "0.000981569", "0.00106184",
> "0.002951682", "0.002239524", "0.002198322", "0.002392364",
> "0.000200837", "0.000838831", "0.001249875", "0.001854552",
> "0.003678462", "0.00122349", "0.002285418", "0.003499271",
> "0.002212441", "0.003302766", "0.000131422", "0.002778005",
> "0.000689239", "0.003401039", "0.003897639", "0.005810614",
> "0.002817827", "0.001336956", "0.000915215", "0.000138584",
> "0.002092924", "0.001420982", "0.003454715", "0.002319974",
> "0.004241691", "0.000703056", "0.001907522", "0.002750834",
> "0.000927527", "0.005493349", "0.00030797", "0.003348811",
> "0.004398022", "0.000226036", "0.005377186", "0.001611902",
> "0.000349171", "0.000584377", "0.000710851", "0.001203603",
> "0.003217803", "0.000685746", "0.001850594", "0.003607466",
> "0.000585491", "0.000423931", "0.000610301", "0.002233248",
> "0.001244584", "0.002675453", "0.000978359", "0.001184482",
> "0.004059149", "0.00126671", "0.001738712", "0.000651386",
> "0.001975237", "0.001053062", "0.000890737", "0.002071903",
> "0.001803908", "0.001163862", "0.000289041", "0.000776781",
> "0.001570439", "0.000951105", "0.000881612", "0.002155598",
> "0.000451588", "0.002378106", "0.000899796", "0.00108975",
> "0.000811137", "0.001071885", "0.001795971", "0.001271003",
> "0.000957691", "0.000496391", "0.001607021", "0.001612781",
> "0.000588984", "0.000473565", "0.001032657", "0.001606533",
> "0.003887263", "0.00219703", "0.002224258", "0.000803389",
> "0.001158066", "0.001260996", "0.000777962", "0.000519006",
> "0.002674644", "0.00089824", "0.001968543", "0.000793111",
> "0.000838132", "0.000295642", "0.000898893", "0.000618909",
> "0.00094089", "0.002481642", "0.002865756", "0.00212707",
> "0.000814292", "0.000692303", "0.001217371", "0.001547876",
> "0.001889694", "0.000423925", "0.001494921", "0.002256496",
> "0.008533809", "0.00103441", "0.00146961", "0.000321683",
> "0.001205398", "0.001934957", "0.000693342", "0.000723974",
> "0.000823272", "0.000431806", "0.00150659", "0.00485395",
> "0.005568073", "0.00295471", "0.003604626", "0.003186087",
> "0.003888975", "0.002884695", "0.005255963", "0.003253941",
> "0.002825274", "0.002356029", "0.004924949", "0.003473988",
> "0.00199782", "0.00318568", "0.003746233", "0.003637744",
> "0.003983428", "0.003235627", "0.002308502", "0.003991285",
> "0.003343607", "0.002065512", "0.003601773", "0.004931388",
> "0.005011346", "0.002393396", "0.003392815", "0.002426415",
> "0.003920471", "0.001757544", "0.002607264", "0.002349977",
> "0.004420568", "0.004202681", "0.003482522", "0.002276988",
> "0.00070119", "0.001897584", "0.001911513", "0.001838116",
> "0.001968399", "0.002341677", "0.003403627", "0.002415555",
> "0.003050358", "0.002038022", "0.003838283", "0.004053138",
> "0.003659568", "0.003976984", "0.002691909", "0.003232401",
> "0.003172718", "0.002495762", "0.002885779", "0.001910272",
> "0.003682516", "0.000608884", "0.003259595", "0.001808769",
> "0.002652719", "0.003421534", "0.003388999", "0.003178429",
> "0.000131713", "0.002772827", "0.002745533", "0.001687844",
> "0.003835246", "0.001178599", "0.003790402", "0.00306021",
> "0.002547791", "0.003856114", "0.001600552", "0.002385385",
> "0.001446147", "0.003100929", "0.001622527", "0.002198012",
> "0.003880893", "0.001848878", "0.005152942", "0.005524076",
> "0.005839341", "0.007647582", "0.003992075", "0.006334646",
> "0.002723267", "0.002856498", "0.002546458", "0.002539948",
> "0.00298808", "0.002690881", "0.003025162", "0.00411367",
> "0.002830494", "0.002061289", "0.003505905", "0.005743849",
> "0.001363744", "0.004132753", "0.001205898", "0.002471435",
> "0.003904816", "0.002813961", "0.001675182", "0.00112607",
> "0.01050083", "0.003607515", "0.002251644", "0.003635582",
> "0.001814219", "0.000961893", "0.001156666", "0.000993787",
> "0.001679378", "0.000292747", "0.001708425", "0.001397416",
> "0.000672403", "0.00066883", "0.000388092", "0.002085225",
> "0.002628926", "0.0007081", "0.001849466", "0.003126619",
> "0.001124511", "0.000291853", "0.00098991", "0.000869237",
> "0.003016002", "0.000228249", "0.001054935", "0.000565486",
> "0.000980794", "0.001281882", "0.001750751", "2.78E-05",
> "0.001225465", "0.001729677", "0.001967867", "0.000946134",
> "0.001831121", "0.001940498", "0.000491159", "0.002862978",
> "0.003546984", "0.000878387", "0.002351657", "0.001844002",
> "0.002855443", "0.000886189", "0.000769673", "0.004398294",
> "0.000985056", "0.003717415", "0.00211658", "0.001719138",
> "0.005380235", "0.001645296", "0.0066795", "0.001849253",
> "0.002303189", "0.003523623", "0.003384322", "0.007160586",
> "0.002131704", "0.000973316", "0.003329035", "0.001888361",
> "0.003957041", "0.001013554", "0.001992457", "0.00381132",
> "0.000900741", "0.003273894", "0.001541242", "0.00047345",
> "0.002916697", "0.003641086", "0.000551149", "0.000988825",
> "0.002934236", "0.002365281", "0.000582871", "0.0018318",
> "0.000929752", "0.001837291", "0.000924292", "0.001031842",
> "0.000684132", "0.001709506", "0.000981114", "0.003457973",
> "0.001817987", "0.002269985", "0.007918975", "0.006223432",
> "0.00123671", "0.00391469", "0.002255457", "0.004180743",
> "0.00057043", "0.001892729", "0.001912139", "0.00194498",
> "0.001104034", "0.002003286", "0.00036947", "0.002635989",
> "0.001007859", "0.003439656", "0.000805272", "0.005867473",
> "0.004465443", "0.001133879", "0.002842206", "0.003604218",
> "0.001081663", "0.001023529", "0.000400453", "0.001224269",
> "0.00633427", "0.001300423", "0.000522795", "0.002777271",
> "0.000465839", "0.004491359", "0.000650466", "0.007881145",
> "0.002128289", "0.000696387", "0.000687194", "0.008668156",
> "0.001173474", "0.000782956", "0.006217158", "0.001097588",
> "0.003761749", "0.000896479", "0.000612694", "0.00455723",
> "0.001562075", "0.001577265", "0.003530944", "0.000882146",
> "0.004741189", "0.000462436", "0.002423694", "0.001426078",
> "0.001229695", "0.000151495", "0.00074423", "0.00056349",
> "0.000834488", "0.001577975", "0.001176036", "0.000714083",
> "0.002160032", "0.000567437", "0.0022188", "0.000685868",
> "0.000520177", "0.002483573", "0.001544549", "0.002397179",
> "0.000455309", "0.000184648", "0.000753078", "0.001213727",
> "0.000526527", "0.000502182", "0.001300605", "0.000386059",
> "0.000624726", "0.000612817", "0.002137467", "0.000521678",
> "0.000531583", "0.00061902", "0.000737619", "0.000529807",
> "0.000479971", "0.000774262", "0.000298302", "0.001277028",
> "0.003589314", "0.001377721", "0.001120529", "0.000974931",
> "0.001191647", "0.001625546", "0.000410325", "0.003808545",
> "0.000541247", "0.000602081", "0.000931481", "0.00048247",
> "0.001402605", "0.000463932", "0.001620905", "0.000940527",
> "0.005848518", "0.000411341", "0.001161372", "0.00106367",
> "0.000371135", "0.00218473", "0.000826734", "0.000781781",
> "0.000430428", "0.003926327", "0.004253917", "0.004915174",
> "0.002098122", "0.001027593", "0.001891307", "0.001483668",
> "0.001715159", "0.001065548", "0.001054245", "0.001791568",
> "0.00138467", "0.000466776", "0.00054037", "0.000368882",
> "0.003345409", "0.000837835", "0.000453112", "0.001788554",
> "0.000712708", "0.000490224", "0.001499223", "0.001705885",
> "0.000365198", "0.001437334", "0.000480388", "0.000782941",
> "0.001200423", "0.001420415", "0.000557051", "0.001934047",
> "0.002820197", "0.000399331", "0.000712066", "0.000825201",
> "0.001077064", "0.004180338", "0.003478947", "0.000847928",
> "0.001411386", "0.000464363", "0.000787172", "0.000486185",
> "0.001211366", "0.003051988", "0.000202072", "0.00045573",
> "0.001039212", "0.00056067", "0.000838216", "0.000611339",
> "0.001155582", "0.003934398", "0.000446241", "0.000447143",
> "0.000585918", "0.000756123", "0.000208236", "0.000746805",
> "0.000537549", "0.001443552", "0.00052824", "0.002368153",
> "0.000509967", "0.007735125", "0.000985745", "0.000527702",
> "0.000717133", "0.000577142", "0.006871698", "0.001248825",
> "0.001075524", "0.001100964", "0.000529795", "0.000551858",
> "0.000745879", "0.000588481", "0.002622651", "0.00091465",
> "0.004629061", "0.000597808", "0.000765995", "0.001018027",
> "0.000596912", "0.001713204", "0.000438174", "0.000800995",
> "0.000653485", "0.000958346", "0.001217594", "0.00076445",
> "0.001449324", "0.000601024", "0.000552241", "0.000592449",
> "0.000772156", "0.001249651", "0.001668726", "0.000701755",
> "0.000412507", "0.000727716", "0.000574364", "0.001042749",
> "0.000654564", "0.007129834", "0.008426946", "0.005309422",
> "0.005264616", "0.009384992", "0.005010607", "0.007570028",
> "0.009928717", "0.004170362", "0.003675265", "0.004512786",
> "0.005685186", "0.008237337", "0.004367586", "0.00546405",
> "0.003804582", "0.005236974", "0.003851435", "0.003415034",
> "0.003219466", "0.002210227", "0.002468179", "0.006069194",
> "0.002674289", "0.002849557", "0.002874692", "0.004102971",
> "0.003420821", "0.002655607", "0.002715811", "0.001471085",
> "0.001153459", "0.001042614", "0.005116195", "0.004592545",
> "0.001979374", "0.002412844", "0.001775336", "0.002868092",
> "0.001479601", "0.002577762", "0.001726507", "0.008248861",
> "0.001528246", "0.000541653", "0.001046778", "0.001539396",
> "0.001555099", "0.000657847", "0.000701465", "0.000673238",
> "0.000406553", "0.001628931", "0.001364921", "0.001974572",
> "0.001179476", "0.001127028", "0.000544126", "0.003940931",
> "0.001809584", "0.001454501", "0.00055187", "0.002078805",
> "0.003618322", "0.003185248", "0.002108602", "0.003186393",
> "0.001073216", "0.00396052", "0.000564544", "0.000900958",
> "0.002872154", "0.000716866", "0.004465343", "0.00292876",
> "0.000865699", "0.000304731", "0.004025274", "0.000461351",
> "0.000450024", "0.000637492", "0.000844207", "0.000716671",
> "0.00051467", "0.002330396", "0.00321308", "0.000996569",
> "0.002008234", "0.003364558", "0.00295349", "0.002459354",
> "0.001837184", "0.002061878", "0.005708132", "0.001568306",
> "0.002370841", "0.002080082", "0.001691857", "0.003587493",
> "0.003525431", "0.003626336", "0.003275526", "0.001566228",
> "0.002677126", "0.001918935", "0.001267504", "0.006069495",
> "0.003330838", "0.001634574", "0.001656518", "0.001062276",
> "0.00193658", "0.006595035", "0.003701294", "0.002165792",
> "0.002795057", "0.001995466", "0.001001598", "0.004566041",
> "0.00313271", "0.003507699", "0.000874182", "0.001736094",
> "0.004154664", "0.000801187", "0.000273351", "0.001434848",
> "0.000208856", "0.001787169", "0.000660318", "0.000536208",
> "0.000827012", "0.003525523", "0.00568365", "0.003374476",
> "0.000629977", "-0.000122666", "0.005430694", "0.002046878",
> "2.87E-05", "0.001524734", "0.000723769", "0.003064301",
> "0.001821976", "0.001019279", "0.007122004", "0.00251728",
> "0.004342001", "0.002250916", "0.00249346", "0.000239402",
> "0.000206815", "0.000721918", "0.00123834", "0.001185488",
> "0.000602984", "0.002770875", "0.000431782", "0.002377602",
> "0.001150575", "0.00030252", "0.00239937", "0.001526856",
> "-5.32E-05", "0.011119607", "0.006887013", "0.005297693",
> "0.007102272", "0.004629353", "0.006308193", "0.009097256",
> "0.003582059", "0.003171425", "0.004769043", "0.00436875",
> "0.004126409", "0.003745626", "0.006291541", "0.004661988",
> "0.002503414", "0.003738629", "0.002155848", "0.005247106",
> "0.004225906", "0.004314957", "0.002606456", "0.003302233",
> "0.003429194", "0.004433893", "0.004032763", "0.001081671",
> "0.005185865", "0.003343411", "0.001731607", "0.002069157",
> "0.003150157", "0.003945407", "0.01995829", "0.002212524",
> "0.003122456", "0.001172068", "0.003164391", "0.002629812",
> "0.001981082", "0.003262964", "0.002421709", "0.002662325",
> "0.0013619", "0.002562372", "0.004551291", "0.00188528",
> "0.001213029", "0.002043811", "0.0008071", "0.002179448",
> "0.001822949", "0.002814085", "0.001257899", "0.001727223",
> "0.002886211", "0.00489911", "0.001579536", "0.001492332",
> "0.002597319", "0.002747154", "0.001371866", "0.003588882",
> "0.00123881", "0.001751715", "0.001258067", "0.003636411",
> "0.001684895", "0.002349261", "0.000735361", "0.002742615",
> "0.001891355", "0.00265467", "0.003050261", "0.001720556",
> "0.002217222", "0.001980177", "0.001664318", "0.001268427",
> "0.00140942", "0.002315045", "0.001975644", "0.001318715",
> "0.001555535", "0.001038484", "0.000347719", "0.001127557",
> "0.001057505", "0.001268971", "0.001179467", "0.000641593",
> "0.002236545", "0.001624429", "0.000173284", "0.000536243",
> "0.000243979", "0.000909077", "0.000309063", "0.001019427",
> "0.002047875", "0.000790357", "0.000229934", "0.002791066",
> "0.00166546", "0.000248693", "0.001842087", "0.002583505",
> "0.001026626", "0.001041061", "0.002264823", "0.001665034",
> "0.000155991", "0.00259237", "0.001646788", "0.000477204",
> "0.000501514", "0.000163174", "0.002588385", "0.000796153",
> "0.002689299", "0.000684056", "-0.000313278", "0.002198574",
> "0.001088117", "0.000528814", "0.000263083", "0.000776179",
> "0.000794529", "0.000142439", "-0.000647425", "0.00193036",
> "0.000108009", "0.00077782", "-0.000481816", "0.000635381",
> "-0.000449205", "0.000782408", "0.004548418", "0.003280907",
> "0.003329733", "0.002035799", "0.005579869", "0.002560187",
> "0.002545633", "0.005059885", "0.007037327", "0.009001771",
> "0.003558769", "0.0035235", "0.002295552", "0.001286924",
> "0.00167687", "0.002037401", "0.001995618", "0.001726902",
> "0.002502914", "0.001398049", "0.002399104", "0.003860254",
> "0.004806359", "0.004938743", "0.003083788", "0.001515187",
> "0.001466474", "0.001676741", "0.000334469", "0.002167219",
> "0.001649118", "0.007160555", "0.002967383", "0.001113913",
> "0.00174345", "0.001535035", "0.004020107", "0.001171428",
> "0.004565952", "0.001237616", "0.00505863", "0.001154021",
> "0.000653467", "0.005069884", "0.002324774", "0.004645691",
> "0.002761466", "0.001699281", "0.00089456", "0.003129216",
> "8.49E-05", "0.002514879", "0.004329247", "0.00221013",
> "0.002568565", "0.000971213", "0.000821615", "0.001461689",
> "0.002523476", "0.001508604", "0.003036535", "0.002665244",
> "0.001453472", "0.001451201", "0.000477768", "0.002484081",
> "0.001474277", "0.003349971", "0.00103818", "0.002414691",
> "0.001450037", "0.000751229", "0.004421348", "0.001129423",
> "0.003419222", "0.000995329", "0.002445221", "0.000617759",
> "0.002848817", "0.002645904", "0.001645723", "0.0003746",
> "0.000940474", "0.003725902", "0.000392291", "0.001147437",
> "0.001145907", "0.000561023", "0.001381841", "0.001110684",
> "0.000544623", "0.00054095", "0.000448923", "0.000590861",
> "0.002452948", "0.000552008", "0.000610962", "0.001299856",
> "0.001317185", "0.002698184", "0.003493815", "0.003244857",
> "0.00061984", "0.000801545", "0.00149525", "0.000409405",
> "0.003370267", "0.002207745", "0.0011107", "0.002229292",
> "0.000488196", "0.00174331", "0.006678113", "0.002816683",
> "0.000839952", "0.003398768", "0.003672784", "0.003091944",
> "0.006648423", "0.004623602", "0.003195142", "0.0008055",
> "0.00052442", "0.00279123", "0.001106953", "0.001105858",
> "0.004357319", "0.006961374", "0.000439899", "0.00332042",
> "0.000410736", "0.000828855", "0.002473165", "0.001286492",
> "0.001670331", "0.003446209", "0.004968425", "0.001344075",
> "0.000531173", "0.004086341", "0.000888029", "0.007199893",
> "0.009696178", "0.000817644", "0.008603312", "0.000538208",
> "0.000715276", "0.003829826", "0.002665075", "0.000655645",
> "0.004521186", "0.00475768", "0.000681104", "0.003250429",
> "0.001037136", "0.004149464", "0.003025068", "0.000661952",
> "0.001511905", "0.001230574", "0.000855192", "0.001946997",
> "0.002197531", "0.000962446", "0.002434427", "0.001437311",
> "0.001685384", "0.000843318", "0.000597531", "0.003679736",
> "0.00052786", "0.002599698", "0.006638163", "0.000492092",
> "0.003381131", "0.004282117", "0.002772674", "0.001209647",
> "0.005015221", "0.002725676", "0.001817094", "0.004275772",
> "0.006164229", "0.001852464", "0.004668182", "0.00025729",
> "0.000571824", "0.003998807", "0.000310591", "0.003167884",
> "0.001286295", "0.001117448", "0.000285175", "0.002681743",
> "0.002541922", "0.000339817", "0.002717807", "0.003086299",
> "0.003665057", "0.001442348", "0.000133803", "0.004258506",
> "0.004458759", "0.000587058", "0.011033508", "0.000646106",
> "0.003609799", "0.004706507", "0.006409543", "0.000690599",
> "0.002099984", "0.001362624", "0.006168257", "0.000262889",
> "0.000657049", "0.000548061", "0.001194158", "0.00236448",
> "0.000866242", "0.000321134", "0.003252815", "0.000405544",
> "0.003749155", "0.002423416", "0.000715815", "0.002068842",
> "0.000681442", "0.002587891", "0.001318798", "0.002900788",
> "0.006026455", "0.003699808", "0.001977136", "0.000945813",
> "0.001145864", "0.005304798", "0.007237841", "0.002849855",
> "0.000441675", "0.000411287", "0.000768919", "0.00031052",
> "0.012539592", "0.006597502", "0.003484505", "0.013217535",
> "0.006680105", "0.006715462", "0.004410384", "0.006726778",
> "0.003722312", "0.012390133", "0.006711536", "0.004539865",
> "0.006212197", "0.003296238", "0.00495935", "0.007676141",
> "0.005152604", "0.002807202", "0.002521741", "0.003382216",
> "0.005610252", "0.002612738", "0.002026107", "0.001670699",
> "0.001927528", "0.00194118", "0.001634303", "0.009430554",
> "0.001204734", "0.003701371", "0.003278496", "0.003673539",
> "0.001572092", "0.005461998", "0.007659243", "0.000794725",
> "0.003422438", "0.005669143", "0.002985877", "0.000272664",
> "0.002271537", "0.005386226", "0.000931846", "0.001839194",
> "0.002773973", "0.00219973", "0.00264419", "0.002359631",
> "0.003208366", "0.00155871", "0.002459454", "0.002203402",
> "0.004330583", "0.006671027", "0.004574731", "0.001901366",
> "0.002839133", "0.003895146", "0.002403823", "0.002021783",
> "0.002035402", "0.002471519", "0.002258829", "0.000748663",
> "0.003052609", "0.000756361", "0.003848861", "0.002010261",
> "0.002319319", "0.002734265", "0.003931146", "0.004014014",
> "0.001212488", "0.004313271", "0.001803602", "0.000438857",
> "0.003518248", "0.000983077", "0.000536783", "0.001030337",
> "0.005479628", "0.001986754", "0.002075642", "0.000304379",
> "0.001501574", "0.001573557", "0.002023082", "0.003399616",
> "0.003702631", "0.000973154", "0.002929413", "0.003016686",
> "0.001960026", "0.001893558", "0.003439089", "0.001924369",
> "0.007517484", "0.000899346", "0.001569812", "0.002040772",
> "0.003196777", "0.001955455", "0.002831375", "0.002804938",
> "0.001917154", "0.003672333", "0.005551972", "0.002036081",
> "0.001444845", "0.000401853", "0.002284308", "0.002822319",
> "0.000445111", "0.001241386", "0.003884877", "0.00325356",
> "0.00224486", "0.003521492", "0.002886992", "0.003133533",
> "0.002155552", "0.003339618", "0.001423891", "0.009148341",
> "0.002143469", "0.005051723", "0.004020353", "0.003620972",
> "0.003749512", "0.002030368", "0.003850751", "0.003291713",
> "0.003876949", "0.003633955", "0.000600088", "0.002769233",
> "0.000944595", "0.004263147", "0.000596448", "0.002646152",
> "0.001701854", "0.007998223", "0.005154705", "0.00265977",
> "0.001832958", "0.001064938", "0.006562253", "0.004358674",
> "0.000521506", "0.001817005", "0.005737944", "0.000521742",
> "0.00246014", "0.00223602", "0.001456657", "0.004855751",
> "0.003058413", "0.002387861", "0.003210591", "0.002263782",
> "7.37E-05", "0.002971081", "0.001318834", "0.001131532",
> "0.007653804", "0.002033245", "0.007817832", "0.003851958",
> "0.001010928", "0.001083535", "0.000616509", "0.001179324",
> "0.000288743", "0.003962735", "0.001787123", "0.001447554",
> "0.001253004", "0.001528183", "0.003366145", "0.002102381",
> "0.000145862", "0.003494018", "0.002128656", "0.003675162",
> "0.00759652", "0.001250727", "0.001506475", "0.000621707",
> "0.003006809", "0.000996703", "0.001929081", "0.002620048",
> "0.002965278", "0.004220162", "0.004578438", "0.001630116",
> "0.001431606", "0.00541955", "0.002649892", "0.000315404",
> "0.001374571", "0.000853286", "0.003181114", "0.002473225",
> "0.000629849", "0.002496231", "0.001432285", "0.002952843",
> "0.000182705", "0.000259503", "0.001618141", "0.000903009",
> "0.000608267", "0.000449268", "0.001571867", "0.000772154",
> "0.000825798", "0.001579361", "0.016348978", "0.002728901",
> "0.000480176", "0.002312973", "0.001579204", "0.000658368",
> "0.002309267", "0.000496615", "0.000580794", "0.003557672",
> "0.000450865", "0.000478168", "0.001619451", "0.001266267",
> "0.001119731", "0.001307925", "0.000355222", "0.000436949",
> "0.000526895", "0.001205208", "0.000537842", "0.002228826",
> "0.003704735", "0.002574494", "0.00107791", "0.006010363",
> "0.002175136", "0.003591312", "0.001068334", "0.003293846",
> "0.003000628", "0.005299653", "0.003326611", "0.00288343",
> "0.002430028", "0.002559727", "0.00507947", "0.002404173",
> "0.002047677", "0.002077716", "0.002276752", "0.002236428",
> "0.004367058", "0.001876632", "0.000980004", "0.003916822",
> "0.002808333", "0.001898333", "0.001366381", "0.000667145",
> "0.001446287", "0.001100975", "0.004796705", "0.001333197",
> "0.000595446", "0.005502218", "0.000862944", "0.00108622",
> "0.006379905", "0.00070873", "0.000772437", "0.005811963",
> "0.001055143", "0.005369487", "0.005318855", "0.001830795",
> "0.00142247", "0.003741093", "0.000699842", "0.002726698",
> "0.002330577", "0.002526381", "0.000516793", "0.00080217",
> "0.003866176", "0.000479181", "0.001610321", "0.000944431",
> "0.005955068", "0.000938004", "0.005707428", "0.000602962",
> "0.001578971", "0.001504067", "0.00072246", "0.004531777",
> "0.000614755", "0.002103022", "0.005264682", "0.005090387",
> "0.004696797", "0.000460688", "0.000530431", "0.001922937",
> "0.00566926", "0.000388306", "0.004252679", "0.00205673",
> "0.001783312", "0.002651375", "0.003740467", "0.00638282",
> "0.00334707", "0.002155446", "0.002261144", "0.00237246",
> "0.003669549", "0.003744011", "0.001334122", "0.002774739",
> "0.002572677", "0.001193501", "0.002378721", "0.001016823",
> "0.002519132", "0.000936095", "0.005202675", "0.002536735",
> "0.00252089", "0.004389852", "0.002645601", "0.005036094",
> "0.002028686", "0.00287482", "0.00039039", "0.001700629",
> "0.002406003", "0.003000786", "0.000350833", "0.00237079",
> "0.001370358", "0.000281447", "0.001162593", "0.000391126",
> "0.000428876", "0.003587365", "0.001830857", "0.001245239",
> "0.00054402", "0.000786806", "0.000308136", "0.002252348",
> "0.001009821", "0.007197987", "0.003429838", "0.00047818",
> "0.000191829", "0.001469793", "0.000701897", "0.000303383",
> "0.000240607", "0.000367176", "0.000806676", "0.001029976",
> "0.001764326", "0.000586666", "0.001052103", "0.0027832",
> "0.002899223", "0.000535299", "0.000321216", "0.002765093",
> "0.003304198", "0.000928385", "0.003349216", "0.00262997",
> "0.001902671", "0.00740575", "0.001269628", "0.001087366",
> "0.000306576", "0.010979008", "0.000142284", "0.003562197",
> "0.000951849", "0.004738473", "0.001147934", "0.000868998",
> "0.000100094", "0.003396012", "0.001425963", "0.000457682",
> "0.001134672", "0.006125895", "0.001206639", "0.001288869",
> "9.26E-05", "0.000970596", "0.004299361", "0.001365496",
> "0.000252023", "0.000881799", "0.001159217", "0.002769744",
> "0.001347274", "0.002506093", "0.002587892", "0.001760215",
> "0.000200908", "0.000120504", "0.000995343", "0.001956552",
> "0.00396928", "0.001998548", "0.000989844", "0.00182333",
> "0.004934963", "0.005930661", "0.003704832", "0.005100611",
> "0.001174396", "0.001573248", "0.001514134", "0.004770532",
> "0.001596482", "0.002227835", "0.000293322", "0.000765304",
> "0.006579839", "0.002086935", "0.000516124", "0.002598376",
> "0.000677743", "0.001751905", "0.000765355", "0.000851338",
> "0.002038965", "0.002461201", "0.004482297", "0.002665955",
> "0.00053772", "0.0026631", "0.002186892", "0.002164451",
> "0.001769369", "0.000556618", "0.001811205", "0.001436441",
> "0.003730669", "0.000540904", "0.002073718", "0.006881776",
> "0.000504263", "0.011870741", "0.012497633", "0.000723731",
> "0.00138756", "0.000796687", "0.001090998", "0.001702514",
> "0.001459711", "0.002239202", "0.001484793", "0.000216742",
> "0.001406412", "0.000537954", "0.000751007", "0.000141754",
> "0.001252295", "0.001357958", "0.000426315", "0.000396497",
> "0.000712089", "0.001571138", "0.000631633", "0.001320965",
> "0.000791112", "0.001042755", "0.001922778", "0.001338678",
> "0.002061002", "0.001257354", "0.001032697", "0.002156974",
> "0.000758648", "0.00115927", "0.000493399", "0.002868998",
> "0.000644541", "0.000963915", "0.002440877", "0.001530594",
> "0.001660393", "0.001974633", "0.002683663", "0.001027642",
> "0.0013826", "0.001268996", "0.002888161", "0.002042083",
> "0.000275954", "0.000425662", "0.001395292", "0.000698374",
> "0.001280422", "0.000360265", "0.00286505", "0.000657062",
> "0.000832286", "0.001509413", "0.009461693", "0.001173043",
> "0.001320977", "0.000374569", "0.003380137", "0.000648815",
> "0.003506032", "0.007945229", "0.001816186", "0.00593997",
> "0.001615382", "0.000617105", "0.000998473", "0.002682396",
> "0.002608846", "0.001042748", "0.000608391", "0.003155706",
> "0.000350366", "0.011011332", "0.001071085", "0.003032408",
> "0.002362787", "0.000785395", "0.000369495", "0.000729234",
> "0.002874633", "0.001277868", "0.000412434", "0.00337317",
> "0.002100282", "0.00127116", "0.00087507", "0.003909292",
> "0.000809452", "0.003842508", "0.000261334", "0.002695379",
> "0.003381531", "0.000959406", "0.000830514", "0.001417701",
> "0.001216766", "0.000580054", "0.000982322", "0.009152715",
> "0.004942274", "0.002247519", "0.00956424", "0.002955447",
> "0.003146615", "0.001329276", "0.000585691", "0.004521217",
> "0.002996703", "0.000862505", "0.002412426", "0.000249773",
> "0.001064878", "0.00218024", "0.001837315", "0.002573162",
> "0.002837718", "0.001951952", "0.001664727", "0.001366389",
> "0.001962139", "0.001443101", "0.000571743", "0.001736855",
> "0.002811318", "0.001017781", "0.001553503", "0.00431465",
> "0.012072091", "0.002428644", "0.0005115", "0.001977798",
> "0.00024813", "0.005039793", "0.00082675", "0.002480204",
> "0.002225975", "0.001997709", "0.002641843", "0.002820302",
> "0.001707712", "0.00188298", "0.002150676", "0.001328293",
> "0.001405165", "0.00298826", "0.001502586", "0.002395292",
> "0.002796706", "0.005203437", "0.004817151", "0.00030616",
> "0.001322253", "0.00455419", "0.001884207", "0.000751607",
> "0.000622799", "0.003630857", "0.001554908", "0.000384964",
> "0.000696522", "0.000292492", "0.001132897", "0.002078203",
> "0.002657073", "0.000610842", "0.002378412", "0.00083702",
> "0.003651925", "0.001021224", "0.000738553", "0.001776616",
> "0.001427956", "0.001826608", "0.001017576", "0.000523945",
> "0.000729999", "0.000700889", "0.004372708", "0.0010721",
> "0.005203322", "0.00180632", "0.000614454", "0.003935009",
> "0.002946169", "0.001363085", "0.000413364", "0.000394261",
> "0.001080705", "0.003037984", "0.000221178", "0.00079759",
> "0.00162498", "0.002324509", "0.001339628", "0.002972215",
> "0.001966148", "0.0016092", "0.000234344", "0.000993412",
> "0.000937602", "0.000415351", "0.002608404", "0.000564896",
> "0.000999391", "0.001383561", "0.00032661", "0.003116056",
> "0.00269477", "0.001127392", "0.001387888", "0.001568912",
> "0.00199253", "0.000374667", "0.002648756", "0.001985879",
> "0.001983733", "0.000659444", "0.003735928", "0.000649978",
> "0.000531627", "0.004032346", "0.00084578", "0.000707181",
> "0.00176177", "0.000724044", "0.000664402", "0.011373309",
> "0.002388706", "0.000774438", "0.003342828", "0.002197908",
> "0.002795226", "0.000567306", "0.001694292", "0.00166641",
> "0.001945432", "0.002895236", "0.001046278", "0.002323907",
> "0.001420304", "0.001982192", "0.000677479", "0.000491854",
> "0.001486234", "0.001277554", "0.003431615", "0.001142057",
> "0.002065289", "0.000825491", "0.000925508", "0.000913616",
> "0.001868473", "0.001826053", "0.001221936", "0.002615253",
> "0.00198233", "0.000654061", "0.001676624", "0.001221201",
> "0.000456194", "0.000841204", "0.005091102", "0.001521278",
> "0.00140408", "0.00356072", "0.001374545", "0.000975109",
> "0.001850532", "0.000490473", "0.001053579", "0.000547076",
> "0.001429506", "0.000989919", "0.00029281", "0.000864564",
> "0.002571375", "0.001410263", "0.002523124", "0.000843319",
> "0.000788548", "0.000942674", "0.000862536", "0.001145244",
> "0.000731401", "0.000922755", "0.00080113", "0.001147544",
> "0.000999559", "0.001002895", "0.001534572", "0.001124767",
> "0.00055331", "0.001453456", "0.001563662", "0.002073296",
> "0.001865843", "0.001249885", "0.002239018", "0.000909996",
> "0.002121782", "0.002524288", "0.001410567", "0.00208956",
> "0.000853813", "0.003419427", "0.002006391", "0.000549302",
> "0.000902927", "0.001930719", "0.00167763", "0.002530737",
> "0.003240916", "0.001839864", "0.001413561", "0.001725875",
> "0.001846509", "0.003881131", "0.000861918", "0.000663578",
> "0.002255887", "0.000871992", "0.001004718", "0.001688389",
> "0.003073294", "0.000949486", "0.001302246", "0.000464419",
> "0.001215565", "0.003880833", "0.001844661", "0.003083818",
> "0.002076196", "0.003507372", "0.002746735", "0.001611621",
> "0.001053223", "0.001772452", "0.001441064", "0.002639818",
> "0.003257066", "0.002662365", "0.004859482", "0.00349962",
> "0.001242116", "0.002071981", "0.001188572", "0.002338708",
> "0.002206605", "0.001728737", "0.001522004", "0.001383648",
> "0.00098972", "0.004487214", "0.000812133", "0.001113718",
> "0.002843833", "0.001116469", "0.001460217", "0.001338645",
> "0.001437048", "0.003548891", "0.001054238", "0.001435734",
> "0.008424636", "0.003766785", "0.003005459", "0.002083674",
> "0.003384797", "0.001496615", "0.002147265")), .Names = c("Analyte",
> "Tm_ugL" ), na.action = structure(3495L, .Names = "3498", class =
> "omit"), row.names = 4:2603, class = "data.frame")
> 
> This is my matrix for storing the data:
> 
> A_Censored<-matrix(A[,two],nrow(A),two)
> 
> This is my for loop for assessing whether it is above or below a
> certain value (A_LLD<-0.0002):
> 
> for (i in one:nrow(A))
>   if (A[i,two]<=A_LLD)
>   {
>     (A_Censored[i,two]<-"TRUE")
>   }else
>     A_Censored[i,two]<-"FALSE"
> 
> 
> 
> And this is my count function
> 
> LLD_Count<- function(Element_List)
> {Element_List<-na.omit(Element_List)
>  Count<-0
>  for (i in one:nrow(Element_List))
>    if (Element_List[i,two]=="TRUE")
>      Count<-Count+one
>  Count_perc<-(Count/length(Element_List[,two])*hundred)
>  LLD_Output<-data.frame(Count,Count_perc)
>  colnames(LLD_Output)<-c("N below LLD","Pecent below LLD")
>  return(LLD_Output)
> }
> 
> Im really stuck and your help be greatly appreciated.
> Thanks
> 
> -- 
> Shane
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.


-- 
  Olivier Crouzet, PhD
  Laboratoire de Linguistique -- EA3827
  Universit? de Nantes
  Chemin de la Censive du Tertre - BP 81227
  44312 Nantes cedex 3
  France

     phone:        (+33) 02 40 14 14 05 (lab.)
                   (+33) 02 40 14 14 36 (office)
     fax:          (+33) 02 40 14 13 27
     e-mail:       olivier.crouzet at univ-nantes.fr
 		
  http://www.lling.univ-nantes.fr/


From 538280 at gmail.com  Thu Oct  3 18:59:57 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 3 Oct 2013 10:59:57 -0600
Subject: [R] Save intermediate result in a same file
In-Reply-To: <1380636784723-4677350.post@n4.nabble.com>
References: <1380636784723-4677350.post@n4.nabble.com>
Message-ID: <CAFEqCdyUA6RNQh0-fEqv0soasTnM7mno-ogBF3qkyeuc2BMMNA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/e95f07f5/attachment.pl>

From jenny.williams at kew.org  Thu Oct  3 19:00:36 2013
From: jenny.williams at kew.org (Jenny Williams)
Date: Thu, 3 Oct 2013 18:00:36 +0100
Subject: [R] climstats
In-Reply-To: <FE8088E7-5EB5-488B-A8CE-57A05268C4D1@comcast.net>
References: <DEF541F3CB545B4A8BC9A811132359C003697191EFE2@KEXCH00.ad.kew.org>
	<1FB1E28E-2A6E-4474-950A-95C378442109@comcast.net>
	<5249B73C.20901@stats.ox.ac.uk>
	<FE8088E7-5EB5-488B-A8CE-57A05268C4D1@comcast.net>
Message-ID: <DEF541F3CB545B4A8BC9A811132359C003697191F01B@KEXCH00.ad.kew.org>

It seems to load now on 3.0.2 32bit and 64bit but NOT 3.0.1. 
install.packages("climstats", repos="http://R-Forge.R-project.org", type="source")

I did have to manually install some of the dependencies.
There were 2 of us that tried loading climstats on different machines so there must have been a blip with our firewall or something.

Now that I have climstats loaded the function I am trying to use doesn't work. 
I can bring up the help file:
?spatial_sync_raster

but I get this error when I try to use the function:
Error: could not find function "spatial_sync_raster"

On Sep 30, 2013, at 10:39 AM, Prof Brian Ripley wrote:

> On 30/09/2013 18:19, David Winsemius wrote:
>> 
>> On Sep 30, 2013, at 3:25 AM, Jenny Williams wrote:
>> 
>>> I have been trying to download the climstats package:
>>> https://r-forge.r-project.org/R/?group_id=861
>>> 
>>> but it doesn't seem to run on R 3.0.2 or 3.0.1
>> 
>> What makes you say this? What errors are reprorted? ("Doesn't seems to run" is a bit vague.)
>> 
>>> and the zipfile is empty.
>> 
>> I was able to install version 1.0 from sources with:
>> 
>> install.packages("climstats", repos="http://R-Forge.R-project.org", type="source")
>> 
>> (I agree that the zipfile for Windows was not found.)
>> 
>> R version 3.0.1 Patched (2013-07-23 r63392) Running Mac OS 10.7.5. It appears to require a fair number of external package, so you would need to check the Depends in the description file.
>> 
>> Depends: R (>= 2.13), raster, rgdal, chron, zoo, sp, ncdf, R.utils
>> 
>> It did not appear to do any C or Fortran compiling, so I think that means you do not need to have RTools installed on Windows.
>> 
>> But since it requires rgdal, you would need to have GDAL installed if you were to get it to load.
> 
> Why do you say that?  On both Windows and OS X, GDAL is part of the rgdal binary.

My error apparently. I have in the past had incorrect installations of GDAL that prevented rgdal from loading properly and my sometimes fuzzy memory was that I fixed this by reinstalling GDAL. So I thought they were independent installations. Apologies for the noise.

-- 
David.


> 
>> 
>>> 
>>> Does anyone know the status of this package or where I can download it.
>>> 
>>> Thanks
>>> 
>>> ******************
>>> Jenny Williams
>>> Spatial Information Scientist, GIS Unit
>>> Herbarium, Library, Art & Archives Directorate
>>> Royal Botanic Gardens, Kew
>>> Richmond, TW9 3AB, UK
>>> 
>>> Tel: +44 (0)208 332 5277
>>> email: jenny.williams at kew.org<mailto:jenny.williams at kew.org>
>>> ******************
>>> 
>>> Film: The Forgotten Home of Coffee - Beyond the Gardens<http://www.youtube.com/watch?v=-uDtytKMKpA&sns=tw>
>>> Stories: Coffee Expedition - Ethiopia<http://storify.com/KewGIS/coffee-expedition-ethiopia>
>>>             Blog: Discovering Coffee in Ethiopia    <http://www.kew.org/news/kew-blogs/incrEdibles-food-blog/discovering-coffee.htm>
>>>             Kew in Harapan Rainforest Sumatra<http://storify.com/KewGIS/kew-in-harapan-rainforest>
>>> Articles: Seeing the wood for the trees<http://www.kew.org/ucm/groups/public/documents/document/kppcont_060602.pdf>
>>> How Kew's GIS team and South East Asia botanists are working to help conserve and restore a rainforest in Sumatra. Download a pdf of this article here.<http://www.kew.org/ucm/groups/public/documents/document/kppcont_060602.pdf>
>>> 
>>> 
>>> ________________________________
>>> The Royal Botanic Gardens, Kew is a non-departmental public body with exempt charitable status, whose principal place of business is at Royal Botanic Gardens, Kew, Richmond, Surrey TW9 3AB, United Kingdom.
>>> 
>>> The information contained in this email and any attachments is intended solely for the addressee(s) and may contain confidential or legally privileged information. If you have received this message in error, please return it immediately and permanently delete it. Do not use, copy or disclose the information contained in this email or in any attachment.
>>> 
>>> Any views expressed in this email do not necessarily reflect the opinions of RBG Kew.
>>> 
>>> Any files attached to this email have been inspected with virus detection software by RBG Kew before transmission, however you should carry out your own virus checks before opening any attachments. RBG Kew accepts no liability for any loss or damage which may be caused by software viruses.
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Thu Oct  3 19:03:03 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 3 Oct 2013 17:03:03 +0000
Subject: [R] Counting numbers in R
In-Reply-To: <CA+jRDxAQ=StpYU3V47gUQVo8KjYi0B7dSGOAqieynh456GkVoA@mail.gmail.com>
References: <CA+jRDxAQ=StpYU3V47gUQVo8KjYi0B7dSGOAqieynh456GkVoA@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C34869F@PA-MBX01.na.tibco.com>

You are storing the column Tm_ugL as character data instead of numeric:
  > str(A)
  'data.frame':   2600 obs. of  2 variables:
   $ Analyte: chr  "584501W" "584502W" "584504W" "584506W" ...
   $ Tm_ugL : chr  "0.012526909" "0.00524721" "0.008974472" "0.014173771" ...
   - attr(*, "na.action")=Class 'omit'  Named int 3495
    .. ..- attr(*, "names")= chr "3498"
and comparisons work differently for character and numeric data.  You should
probably read in the data again, reading the second column as numeric (e.g.,
with the colClasses argument to read.table), and start the analysis anew.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Shane Carey
> Sent: Thursday, October 03, 2013 9:27 AM
> To: r-help at r-project.org
> Subject: [R] Counting numbers in R
> 
> Hi,
> 
> I have a set of data and I need to find out how many points are below a
> certain value but R will not calculate this properly for me. Negative
> numbers seem to be causing the issue.
> 
> This is my data:
> structure(list(Analyte = c("584501W", "584502W", "584504W", "584506W",
> "584507W", "584508W", "584509W", "584510W", "584511W", "584513W",
> "584514W", "584516W", "584517W", "584518W", "584519W", "584520W",
> "584521W", "584522W", "584523W", "584525W", "584526W", "584527W",
> "584528W", "584529W", "584530W", "584531W", "584532W", "584533W",
> "584534W", "584535W", "584536W", "584537W", "584539W", "584540W",
> "584543W", "584545W", "584546W", "584547W", "584548W", "584549W",
> "584550W", "584551W", "584552W", "584553W", "584554W", "584555W",
> "584556W", "584558W", "584561W", "584562W", "584563W", "584565W",
> "584566W", "584569W", "584570W", "584571W", "584572W", "584573W",
> "584574W", "584575W", "584577W", "584578W", "584579W", "584580W",
> "584581W", "584582W", "584584W", "584585W", "584586W", "584587W",
> "584588W", "584589W", "584590W", "584591W", "584592W", "584594W",
> "584595W", "584597W", "584599W", "584600W", "584601W", "584602W",
> "584603W", "584604W", "584606W", "584607W", "584610W", "584611W",
> "584612W", "584613W", "584614W", "584615W", "584616W", "584617W",
> "584618W", "584619W", "584620W", "584621W", "584622W", "584624W",
> "584625W", "584626W", "584627W", "584628W", "584629W", "584631W",
> "584632W", "584635W", "584636W", "584637W", "584638W", "584639W",
> "584642W", "584643W", "584644W", "584645W", "584647W", "584649W",
> "584650W", "584651W", "584652W", "584653W", "584655W", "584657W",
> "584658W", "584659W", "584660W", "584661W", "584662W", "584663W",
> "584665W", "584666W", "584667W", "584669W", "584670W", "584671W",
> "584672W", "584673W", "584674W", "584675W", "584676W", "584678W",
> "584681W", "584682W", "584683W", "584684W", "584685W", "584687W",
> "584688W", "584689W", "584691W", "584692W", "584693W", "584694W",
> "584695W", "584696W", "584697W", "584699W", "584700W", "584702W",
> "584703W", "584705W", "584706W", "584707W", "584708W", "584709W",
> "584710W", "584711W", "584713W", "584714W", "584715W", "584716W",
> "584717W", "584718W", "584720W", "584721W", "584722W", "584723W",
> "584726W", "584727W", "584728W", "584729W", "584730W", "584731W",
> "584732W", "584733W", "584734W", "584736W", "584737W", "584740W",
> "584741W", "584742W", "584743W", "584744W", "584745W", "584746W",
> "584747W", "584749W", "584751W", "584752W", "584753W", "584754W",
> "584755W", "584756W", "584757W", "584758W", "584759W", "584760W",
> "584762W", "584763W", "584764W", "584765W", "584766W", "584767W",
> "584768W", "584769W", "584772W", "584773W", "584775W", "584777W",
> "584779W", "584780W", "584781W", "584783W", "584784W", "584785W",
> "584786W", "584787W", "584788W", "584789W", "584790W", "584791W",
> "584792W", "584793W", "584795W", "584797W", "584798W", "584800W",
> "584802W", "584803W", "584804W", "584805W", "584806W", "584807W",
> "584808W", "584809W", "584810W", "584811W", "584812W", "584813W",
> "584814W", "584815W", "584816W", "584817W", "584818W", "584820W",
> "584821W", "584822W", "584823W", "584825W", "584826W", "584827W",
> "584828W", "584829W", "584830W", "584832W", "584833W", "584835W",
> "584836W", "584838W", "584839W", "584840W", "584841W", "584842W",
> "584843W", "584844W", "584845W", "584846W", "584847W", "584849W",
> "584850W", "584851W", "584853W", "584854W", "584855W", "584856W",
> "584857W", "584858W", "584859W", "584860W", "584861W", "584862W",
> "584863W", "584864W", "584865W", "584867W", "584868W", "584869W",
> "584871W", "584872W", "584873W", "584874W", "584875W", "584876W",
> "584877W", "584878W", "584880W", "584881W", "584882W", "584883W",
> "584885W", "584886W", "584887W", "584889W", "584891W", "584892W",
> "584893W", "584894W", "584895W", "584896W", "584897W", "584898W",
> "584900W", "584901W", "584903W", "584904W", "584906W", "584907W",
> "584909W", "584911W", "584913W", "584914W", "584915W", "584916W",
> "584918W", "584919W", "584920W", "584921W", "584922W", "584923W",
> "584924W", "584926W", "584928W", "584929W", "584930W", "584931W",
> "584932W", "584933W", "584934W", "584936W", "584937W", "584938W",
> "584939W", "584941W", "584943W", "584944W", "584946W", "584947W",
> "584948W", "584949W", "584950W", "584951W", "584952W", "584953W",
> "584954W", "584955W", "584957W", "584958W", "584960W", "584961W",
> "584963W", "584964W", "584965W", "584967W", "584968W", "584970W",
> "584971W", "584972W", "584973W", "584976W", "584977W", "584978W",
> "584979W", "584980W", "584981W", "584982W", "584983W", "584984W",
> "584985W", "584986W", "584987W", "584988W", "584989W", "584990W",
> "584991W", "584993W", "584994W", "584995W", "584996W", "584997W",
> "584999W", "585000W", "585001W", "585002W", "585003W", "585005W",
> "585006W", "585007W", "585008W", "585011W", "585012W", "585014W",
> "585015W", "585016W", "585017W", "585019W", "585020W", "585021W",
> "585022W", "585023W", "585024W", "585025W", "585026W", "585027W",
> "585028W", "585029W", "585031W", "585033W", "585035W", "585036W",
> "585037W", "585038W", "585039W", "585040W", "585041W", "585043W",
> "585044W", "585045W", "585046W", "585047W", "585049W", "585050W",
> "585051W", "585052W", "585055W", "585056W", "585057W", "585058W",
> "585059W", "585060W", "585061W", "585062W", "585063W", "585064W",
> "585065W", "585067W", "585068W", "585069W", "585070W", "585072W",
> "585073W", "585074W", "585075W", "585076W", "585077W", "585078W",
> "585079W", "585080W", "585082W", "585083W", "585085W", "585086W",
> "585087W", "585088W", "585089W", "585090W", "585092W", "585093W",
> "585094W", "585096W", "585097W", "585098W", "585099W", "585100W",
> "585101W", "585102W", "585104W", "585106W", "585107W", "585108W",
> "585109W", "585111W", "585113W", "585114W", "585116W", "585117W",
> "585118W", "585119W", "585120W", "585121W", "585122W", "585123W",
> "585125W", "585126W", "585127W", "585128W", "585129W", "585131W",
> "585132W", "585133W", "585134W", "585135W", "585136W", "585137W",
> "585139W", "585140W", "585141W", "585142W", "585143W", "585145W",
> "585146W", "585148W", "585149W", "585150W", "585151W", "585152W",
> "585153W", "585154W", "585155W", "585156W", "585158W", "585160W",
> "585161W", "585162W", "585163W", "585165W", "585166W", "585168W",
> "585169W", "585170W", "585171W", "585172W", "585173W", "585174W",
> "585175W", "585177W", "585178W", "585179W", "585180W", "585181W",
> "585182W", "585184W", "585185W", "585186W", "585187W", "585189W",
> "585190W", "585192W", "585193W", "585194W", "585195W", "585197W",
> "585198W", "585199W", "585200W", "585201W", "585202W", "585203W",
> "585204W", "585206W", "585207W", "585208W", "585210W", "585211W",
> "585212W", "585213W", "585214W", "585215W", "585216W", "585217W",
> "585218W", "585219W", "585220W", "585221W", "585222W", "585224W",
> "585226W", "585227W", "585228W", "585229W", "585231W", "585234W",
> "585235W", "585236W", "585237W", "585238W", "585239W", "585241W",
> "585242W", "585243W", "585244W", "585245W", "585247W", "585248W",
> "585249W", "585250W", "585251W", "585252W", "585253W", "585255W",
> "585257W", "585258W", "585259W", "585260W", "585261W", "585262W",
> "585263W", "585265W", "585266W", "585267W", "585269W", "585270W",
> "585271W", "585272W", "585273W", "585274W", "585275W", "585276W",
> "585278W", "585279W", "585280W", "585281W", "585282W", "585283W",
> "585284W", "585285W", "585287W", "585289W", "585291W", "585292W",
> "585293W", "585294W", "585295W", "585299W", "585300W", "585301W",
> "585302W", "585303W", "585305W", "585306W", "585307W", "585308W",
> "585310W", "585311W", "585313W", "585314W", "585315W", "585316W",
> "585317W", "585318W", "585320W", "585321W", "585322W", "585323W",
> "585324W", "585326W", "585327W", "585328W", "585329W", "585330W",
> "585331W", "585332W", "585333W", "585334W", "585336W", "585337W",
> "585339W", "585340W", "585341W", "585342W", "585343W", "585344W",
> "585345W", "585346W", "585347W", "585349W", "585350W", "585351W",
> "585352W", "585354W", "585355W", "585356W", "585357W", "585358W",
> "585359W", "585360W", "585363W", "585364W", "585365W", "585366W",
> "585367W", "585368W", "585371W", "585372W", "585373W", "585375W",
> "585377W", "585378W", "585379W", "585380W", "585381W", "585383W",
> "585384W", "585385W", "585387W", "585388W", "585389W", "585390W",
> "585391W", "585392W", "585395W", "585397W", "585398W", "585399W",
> "585400W", "585402W", "585403W", "585404W", "585405W", "585406W",
> "585407W", "585408W", "585409W", "585410W", "585411W", "585412W",
> "585413W", "585414W", "585415W", "585416W", "585418W", "585420W",
> "585421W", "585423W", "585425W", "585426W", "585427W", "585428W",
> "585429W", "585430W", "585432W", "585435W", "585436W", "585438W",
> "585439W", "585440W", "585441W", "585442W", "585443W", "585444W",
> "585445W", "585446W", "585447W", "585450W", "585451W", "585453W",
> "585454W", "585455W", "585456W", "585457W", "585458W", "585459W",
> "585460W", "585461W", "585462W", "585463W", "585465W", "585467W",
> "585468W", "585469W", "585471W", "585472W", "585473W", "585474W",
> "585475W", "585476W", "585477W", "585478W", "585480W", "585481W",
> "585482W", "585483W", "585485W", "585486W", "585487W", "585490W",
> "585491W", "585492W", "585493W", "585494W", "585495W", "585496W",
> "585497W", "585498W", "585500W", "585501W", "585503W", "585504W",
> "585505W", "585506W", "585507W", "585508W", "585509W", "585511W",
> "585512W", "585513W", "585514W", "585515W", "585516W", "585519W",
> "585520W", "585521W", "585522W", "585523W", "585524W", "585526W",
> "585528W", "585529W", "585530W", "585531W", "585532W", "585533W",
> "585534W", "585536W", "585537W", "585538W", "585539W", "585540W",
> "585541W", "585543W", "585546W", "585547W", "585548W", "585549W",
> "585550W", "585551W", "585552W", "585553W", "585554W", "585557W",
> "585558W", "585560W", "585561W", "585563W", "585564W", "585565W",
> "585566W", "585567W", "585568W", "585570W", "585571W", "585572W",
> "585573W", "585575W", "585576W", "585577W", "585578W", "585579W",
> "585580W", "585581W", "585582W", "585583W", "585584W", "585585W",
> "585586W", "585587W", "585588W", "585589W", "585590W", "585591W",
> "585593W", "585594W", "585595W", "585596W", "585597W", "585599W",
> "585600W", "585601W", "585602W", "585603W", "585605W", "585606W",
> "585607W", "585608W", "585609W", "585611W", "585612W", "585614W",
> "585615W", "585616W", "585617W", "585619W", "585620W", "585621W",
> "585622W", "585623W", "585624W", "585625W", "585626W", "585627W",
> "585628W", "585631W", "585633W", "585635W", "585636W", "585637W",
> "585638W", "585639W", "585640W", "585641W", "585642W", "585643W",
> "585644W", "585645W", "585646W", "585647W", "585649W", "585650W",
> "585651W", "585652W", "585654W", "585656W", "585657W", "585658W",
> "585659W", "585660W", "585661W", "585662W", "585663W", "585664W",
> "585665W", "585667W", "585668W", "585669W", "585670W", "585671W",
> "585672W", "585674W", "585675W", "585676W", "585677W", "585678W",
> "585679W", "585680W", "585682W", "585683W", "585685W", "585686W",
> "585687W", "585688W", "585689W", "585690W", "585692W", "585693W",
> "585694W", "585696W", "585697W", "585698W", "585699W", "585700W",
> "585701W", "585702W", "585704W", "585706W", "585707W", "585708W",
> "585709W", "585710W", "585711W", "585713W", "585714W", "585716W",
> "585717W", "585718W", "585719W", "585720W", "585721W", "585722W",
> "585723W", "585725W", "585726W", "585727W", "585728W", "585729W",
> "585730W", "585731W", "585732W", "585733W", "585734W", "585735W",
> "585736W", "585737W", "585739W", "585740W", "585741W", "585742W",
> "585743W", "585745W", "585746W", "585747W", "585748W", "585749W",
> "585750W", "585751W", "585752W", "585753W", "585754W", "585755W",
> "585756W", "585758W", "585760W", "585761W", "585762W", "585763W",
> "585765W", "585766W", "585768W", "585769W", "585770W", "585771W",
> "585772W", "585773W", "585774W", "585775W", "585777W", "585778W",
> "585779W", "585780W", "585781W", "585782W", "585784W", "585785W",
> "585786W", "585787W", "585788W", "585789W", "585790W", "585791W",
> "585792W", "585793W", "585794W", "585795W", "585797W", "585798W",
> "585799W", "585801W", "585802W", "585803W", "585804W", "585806W",
> "585807W", "585808W", "585810W", "585811W", "585812W", "585813W",
> "585814W", "585815W", "585816W", "585817W", "585818W", "585819W",
> "585820W", "585821W", "585822W", "585824W", "585825W", "585826W",
> "585827W", "585828W", "585829W", "585831W", "585832W", "585834W",
> "585835W", "585836W", "585837W", "585838W", "585839W", "585841W",
> "585842W", "585843W", "585844W", "585845W", "585847W", "585848W",
> "585849W", "585850W", "585851W", "585852W", "585853W", "585855W",
> "585856W", "585857W", "585858W", "585859W", "585860W", "585861W",
> "585862W", "585863W", "585865W", "585866W", "585867W", "585869W",
> "585870W", "585871W", "585872W", "585873W", "585874W", "585875W",
> "585876W", "585878W", "585879W", "585880W", "585881W", "585882W",
> "585883W", "585884W", "585885W", "585887W", "585888W", "585889W",
> "585891W", "585892W", "585893W", "585894W", "585896W", "585897W",
> "585899W", "585900W", "585901W", "585902W", "585903W", "585905W",
> "585906W", "585907W", "585908W", "585909W", "585910W", "585913W",
> "585914W", "585915W", "585916W", "585917W", "585918W", "585920W",
> "585921W", "585922W", "585923W", "585924W", "585926W", "585927W",
> "585928W", "585929W", "585930W", "585931W", "585932W", "585933W",
> "585934W", "585936W", "585937W", "585939W", "585940W", "585941W",
> "585942W", "585943W", "585944W", "585945W", "585946W", "585947W",
> "585949W", "585950W", "585951W", "585952W", "585953W", "585954W",
> "585955W", "585956W", "585957W", "585958W", "585959W", "585960W",
> "585963W", "585964W", "585965W", "585966W", "585967W", "585968W",
> "585969W", "585971W", "585972W", "585973W", "585975W", "585977W",
> "585978W", "585979W", "585980W", "585983W", "585984W", "585985W",
> "585986W", "585987W", "585989W", "585990W", "585991W", "585992W",
> "585993W", "585995W", "585997W", "585998W", "585999W", "586000W",
> "586002W", "586003W", "586004W", "586005W", "586006W", "586007W",
> "586008W", "586009W", "586010W", "586011W", "586012W", "586013W",
> "586014W", "586015W", "586016W", "586017W", "586018W", "586020W",
> "586021W", "586022W", "586023W", "586025W", "586026W", "586027W",
> "586028W", "586029W", "586030W", "586032W", "586033W", "586035W",
> "586036W", "586038W", "586039W", "586040W", "586041W", "586042W",
> "586043W", "586044W", "586045W", "586046W", "586047W", "586049W",
> "586051W", "586053W", "586054W", "586055W", "586057W", "586058W",
> "586059W", "586060W", "586061W", "586062W", "586063W", "586064W",
> "586065W", "586067W", "586068W", "586069W", "586071W", "586072W",
> "586073W", "586074W", "586075W", "586076W", "586077W", "586078W",
> "586080W", "586081W", "586082W", "586083W", "586085W", "586086W",
> "586087W", "586089W", "586090W", "586091W", "586092W", "586093W",
> "586094W", "586095W", "586096W", "586097W", "586098W", "586100W",
> "586101W", "586102W", "586104W", "586105W", "586106W", "586107W",
> "586108W", "586109W", "586111W", "586112W", "586113W", "586114W",
> "586115W", "586116W", "586118W", "586119W", "586121W", "586122W",
> "586123W", "586124W", "586126W", "586128W", "586129W", "586130W",
> "586131W", "586132W", "586134W", "586136W", "586137W", "586138W",
> "586139W", "586140W", "586141W", "586143W", "586144W", "586146W",
> "586147W", "586148W", "586149W", "586150W", "586151W", "586152W",
> "586153W", "586154W", "586155W", "586157W", "586158W", "586160W",
> "586161W", "586163W", "586164W", "586165W", "586166W", "586167W",
> "586170W", "586171W", "586172W", "586173W", "586175W", "586176W",
> "586177W", "586178W", "586179W", "586180W", "586181W", "586184W",
> "586185W", "586186W", "586187W", "586188W", "586189W", "586190W",
> "586191W", "586193W", "586194W", "586195W", "586196W", "586197W",
> "586199W", "586200W", "586201W", "586202W", "586203W", "586205W",
> "586206W", "586207W", "586208W", "586209W", "586211W", "586212W",
> "586214W", "586215W", "586216W", "586217W", "586219W", "586220W",
> "586221W", "586222W", "586223W", "586224W", "586225W", "586226W",
> "586227W", "586228W", "586229W", "586231W", "586233W", "586235W",
> "586236W", "586237W", "586238W", "586239W", "586240W", "586241W",
> "586242W", "586243W", "586244W", "586245W", "586246W", "586247W",
> "586249W", "586250W", "586251W", "586252W", "586254W", "586255W",
> "586256W", "586257W", "586258W", "586259W", "586260W", "586261W",
> "586262W", "586263W", "586264W", "586265W", "586267W", "586268W",
> "586269W", "586270W", "586272W", "586273W", "586274W", "586275W",
> "586276W", "586277W", "586278W", "586279W", "586280W", "586282W",
> "586283W", "586285W", "586286W", "586287W", "586288W", "586289W",
> "586290W", "586292W", "586293W", "586294W", "586296W", "586297W",
> "586298W", "586299W", "586300W", "586301W", "586302W", "586304W",
> "586306W", "586307W", "586308W", "586309W", "586310W", "586311W",
> "586313W", "586314W", "586316W", "586317W", "586318W", "586319W",
> "586320W", "586321W", "586322W", "586323W", "586325W", "586326W",
> "586327W", "586328W", "586329W", "586330W", "586331W", "586332W",
> "586333W", "586334W", "586335W", "586336W", "586339W", "586340W",
> "586341W", "586342W", "586343W", "586345W", "586346W", "586347W",
> "586348W", "586350W", "586351W", "586352W", "586353W", "586355W",
> "586356W", "586358W", "586360W", "586361W", "586362W", "586363W",
> "586365W", "586366W", "586368W", "586369W", "586370W", "586371W",
> "586372W", "586373W", "586374W", "586375W", "586377W", "586378W",
> "586379W", "586380W", "586381W", "586382W", "586384W", "586385W",
> "586386W", "586387W", "586388W", "586389W", "586390W", "586391W",
> "586392W", "586393W", "586394W", "586395W", "586397W", "586398W",
> "586399W", "586400W", "586401W", "586402W", "586403W", "586404W",
> "586406W", "586407W", "586408W", "586410W", "586412W", "586413W",
> "586414W", "586415W", "586416W", "586417W", "586418W", "586419W",
> "586420W", "586421W", "586422W", "586424W", "586425W", "586426W",
> "586427W", "586428W", "586429W", "586431W", "586432W", "586434W",
> "586435W", "586436W", "586437W", "586438W", "586439W", "586441W",
> "586443W", "586444W", "586445W", "586447W", "586448W", "586449W",
> "586450W", "586451W", "586452W", "586453W", "586455W", "586456W",
> "586457W", "586458W", "586459W", "586460W", "586461W", "586462W",
> "586463W", "586465W", "586466W", "586467W", "586469W", "586470W",
> "586471W", "586472W", "586473W", "586475W", "586476W", "586478W",
> "586479W", "586480W", "586481W", "586482W", "586483W", "586484W",
> "586485W", "586487W", "586488W", "586489W", "586491W", "586492W",
> "586493W", "586494W", "586495W", "586496W", "586497W", "586499W",
> "586500W", "586501W", "586502W", "586503W", "586505W", "586506W",
> "586507W", "586508W", "586509W", "586510W", "586511W", "586513W",
> "586514W", "586515W", "586516W", "586517W", "586518W", "586520W",
> "586521W", "586522W", "586523W", "586524W", "586526W", "586527W",
> "586528W", "586529W", "586530W", "586531W", "586532W", "586533W",
> "586534W", "586536W", "586537W", "586539W", "586540W", "586541W",
> "586542W", "586543W", "586544W", "586545W", "586546W", "586547W",
> "586549W", "586550W", "586552W", "586553W", "586554W", "586555W",
> "586556W", "586557W", "586558W", "586559W", "586560W", "586562W",
> "586563W", "586564W", "586565W", "586566W", "586567W", "586568W",
> "586569W", "586571W", "586572W", "586573W", "586575W", "586577W",
> "586578W", "586579W", "586580W", "586581W", "586583W", "586584W",
> "586585W", "586586W", "586587W", "586588W", "586589W", "586590W",
> "586591W", "586592W", "586593W", "586595W", "586597W", "586598W",
> "586599W", "586600W", "586602W", "586603W", "586604W", "586605W",
> "586606W", "586607W", "586608W", "586609W", "586610W", "586611W",
> "586612W", "586613W", "586614W", "586615W", "586616W", "586617W",
> "586618W", "586620W", "586621W", "586622W", "586623W", "586625W",
> "586626W", "586627W", "586628W", "586629W", "586630W", "586632W",
> "586633W", "586635W", "586636W", "586638W", "586639W", "586640W",
> "586641W", "586642W", "586643W", "586644W", "586645W", "586646W",
> "586647W", "586649W", "586650W", "586651W", "586653W", "586654W",
> "586655W", "586656W", "586657W", "586658W", "586659W", "586660W",
> "586661W", "586662W", "586663W", "586664W", "586665W", "586667W",
> "586668W", "586669W", "586671W", "586672W", "586673W", "586674W",
> "586675W", "586676W", "586677W", "586678W", "586680W", "586682W",
> "586683W", "586685W", "586686W", "586687W", "586689W", "586690W",
> "586691W", "586692W", "586693W", "586694W", "586695W", "586696W",
> "586697W", "586698W", "586701W", "586702W", "586703W", "586704W",
> "586705W", "586706W", "586707W", "586708W", "586709W", "586711W",
> "586712W", "586713W", "586714W", "586715W", "586716W", "586718W",
> "586719W", "586720W", "586721W", "586723W", "586724W", "586726W",
> "586728W", "586729W", "586730W", "586731W", "586732W", "586733W",
> "586734W", "586736W", "586737W", "586738W", "586739W", "586740W",
> "586741W", "586743W", "586744W", "586746W", "586747W", "586748W",
> "586749W", "586750W", "586751W", "586752W", "586753W", "586754W",
> "586755W", "586757W", "586758W", "586760W", "586761W", "586763W",
> "586764W", "586765W", "586766W", "586767W", "586768W", "586770W",
> "586771W", "586772W", "586773W", "586775W", "586776W", "586777W",
> "586778W", "586779W", "586780W", "586781W", "586782W", "586783W",
> "586784W", "586785W", "586786W", "586787W", "586788W", "586789W",
> "586790W", "586791W", "586793W", "586795W", "586796W", "586797W",
> "586799W", "586800W", "586801W", "586802W", "586803W", "586805W",
> "586806W", "586807W", "586808W", "586809W", "586811W", "586812W",
> "586814W", "586815W", "586816W", "586817W", "586819W", "586821W",
> "586822W", "586823W", "586824W", "586825W", "586826W", "586827W",
> "586828W", "586829W", "586831W", "586833W", "586835W", "586836W",
> "586837W", "586838W", "586839W", "586840W", "586841W", "586842W",
> "586843W", "586844W", "586845W", "586846W", "586847W", "586849W",
> "586850W", "586851W", "586852W", "586855W", "586856W", "586857W",
> "586858W", "586859W", "586860W", "586861W", "586862W", "586863W",
> "586864W", "586865W", "586867W", "586868W", "586869W", "586870W",
> "586871W", "586872W", "586873W", "586874W", "586875W", "586876W",
> "586877W", "586878W", "586879W", "586880W", "586882W", "586883W",
> "586885W", "586886W", "586887W", "586888W", "586889W", "586890W",
> "586893W", "586894W", "586896W", "586897W", "586898W", "586899W",
> "586900W", "586901W", "586902W", "586904W", "586906W", "586907W",
> "586908W", "586909W", "586910W", "586911W", "586913W", "586914W",
> "586916W", "586917W", "586918W", "586919W", "586920W", "586921W",
> "586922W", "586923W", "586925W", "586926W", "586927W", "586928W",
> "586929W", "586930W", "586931W", "586932W", "586933W", "586934W",
> "586935W", "586937W", "586939W", "586940W", "586941W", "586942W",
> "586943W", "586945W", "586946W", "586947W", "586949W", "586950W",
> "586951W", "586952W", "586953W", "586954W", "586955W", "586956W",
> "586958W", "586960W", "586961W", "586962W", "586963W", "586965W",
> "586966W", "586968W", "586969W", "586970W", "586971W", "586972W",
> "586973W", "586974W", "586975W", "586977W", "586978W", "586979W",
> "586980W", "586981W", "586982W", "586984W", "586985W", "586986W",
> "586987W", "586988W", "586989W", "586990W", "586991W", "586992W",
> "586993W", "586994W", "586995W", "586997W", "586998W", "586999W",
> "587000W", "587001W", "587002W", "587004W", "587006W", "587007W",
> "587008W", "587010W", "587011W", "587012W", "587013W", "587014W",
> "587015W", "587016W", "587017W", "587018W", "587019W", "587020W",
> "587021W", "587022W", "587024W", "587025W", "587026W", "587027W",
> "587028W", "587029W", "587031W", "587032W", "587034W", "587035W",
> "587036W", "587037W", "587038W", "587039W", "587041W", "587042W",
> "587043W", "587044W", "587045W", "587047W", "587048W", "587049W",
> "587050W", "587051W", "587052W", "587053W", "587055W", "587056W",
> "587057W", "587058W", "587059W", "587060W", "587061W", "587062W",
> "587063W", "587065W", "587067W", "587069W", "587070W", "587071W",
> "587072W", "587073W", "587074W", "587075W", "587076W", "587078W",
> "587079W", "587080W", "587081W", "587082W", "587083W", "587085W",
> "587087W", "587088W", "587089W", "587091W", "587092W", "587093W",
> "587094W", "587095W", "587096W", "587097W", "587099W", "587100W",
> "587101W", "587102W", "587103W", "587105W", "587106W", "587107W",
> "587108W", "587109W", "587110W", "587111W", "587113W", "587114W",
> "587115W", "587116W", "587117W", "587118W", "587120W", "587121W",
> "587122W", "587123W", "587124W", "587126W", "587127W", "587128W",
> "587129W", "587130W", "587131W", "587132W", "587133W", "587134W",
> "587136W", "587137W", "587139W", "587140W", "587141W", "587142W",
> "587143W", "587144W", "587145W", "587146W", "587147W", "587149W",
> "587150W", "587151W", "587152W", "587153W", "587154W", "587155W",
> "587156W", "587157W", "587158W", "587159W", "587160W", "587162W",
> "587163W", "587164W", "587165W", "587167W", "587168W", "587169W",
> "587172W", "587173W", "587175W", "587177W", "587178W", "587179W",
> "587180W", "587181W", "587183W", "587184W", "587185W", "587186W",
> "587187W", "587188W", "587189W", "587190W", "587191W", "587192W",
> "587193W", "587195W", "587197W", "587198W", "587199W", "587200W",
> "587202W", "587203W", "587204W", "587205W", "587206W", "587207W",
> "587208W", "587209W", "587210W", "587211W", "587212W", "587213W",
> "587214W", "587215W", "587216W", "587217W", "587218W", "587220W",
> "587221W", "587222W", "587223W", "587225W", "587226W", "587227W",
> "587228W", "587229W", "587230W", "587232W", "587233W", "587235W",
> "587236W", "587238W", "587239W", "587240W", "587241W", "587242W",
> "587243W", "587244W", "587245W", "587246W", "587247W", "587249W",
> "587250W", "587251W", "587253W", "587254W", "587255W", "587256W",
> "587257W", "587258W", "587259W", "587260W", "587261W", "587262W",
> "587263W", "587264W", "587265W", "587267W", "587268W", "587269W",
> "587271W", "587272W", "587273W", "587274W", "587275W", "587276W",
> "587278W", "587280W", "587281W", "587282W", "587283W", "587285W",
> "587286W", "587287W", "587289W", "587290W", "587291W", "587292W",
> "587293W", "587294W", "587295W", "587296W", "587297W", "587298W",
> "587300W", "587301W", "587302W", "587303W", "587304W", "587305W",
> "587306W", "587307W", "587309W", "587311W", "587312W", "587313W",
> "587315W", "587316W", "587318W", "587319W", "587320W", "587321W",
> "587322W", "587323W", "587324W", "587326W", "587328W", "587329W",
> "587330W", "587331W", "587332W", "587333W", "587336W", "587337W",
> "587338W", "587339W", "587340W", "587341W", "587343W", "587344W",
> "587346W", "587347W", "587348W", "587349W", "587350W", "587351W",
> "587352W", "587353W", "587354W", "587355W", "587358W", "587360W",
> "587361W", "587363W", "587364W", "587365W", "587367W", "587368W",
> "587370W", "587371W", "587372W", "587373W", "587375W", "587376W",
> "587377W", "587378W", "587379W", "587380W", "587381W", "587382W",
> "587383W", "587384W", "587385W", "587387W", "587388W", "587389W",
> "587390W", "587391W", "587393W", "587394W", "587395W", "587396W",
> "587397W", "587399W", "587400W", "587401W", "587402W", "587403W",
> "587405W", "587406W", "587407W", "587408W", "587409W", "587411W",
> "587412W", "587414W", "587415W", "587416W", "587417W", "587419W",
> "587420W", "587421W", "587422W", "587423W", "587424W", "587425W",
> "587426W", "587427W", "587428W", "587429W", "587431W", "587433W",
> "587435W", "587436W", "587437W", "587438W", "587439W", "587440W",
> "587441W", "587442W", "587443W", "587444W", "587445W", "587446W",
> "587447W", "587449W", "587450W", "587451W", "587452W", "587454W",
> "587455W", "587456W", "587457W", "587458W", "587459W", "587460W",
> "587461W", "587462W", "587463W", "587464W", "587465W", "587467W",
> "587469W", "587470W", "587471W", "587472W", "587473W", "587474W",
> "587475W", "587476W", "587477W", "587478W", "587479W", "587480W",
> "587482W", "587483W", "587485W", "587486W", "587487W", "587488W",
> "587489W", "587490W", "587492W", "587493W", "587494W", "587496W",
> "587497W", "587498W", "587499W", "587500W", "587501W", "587502W",
> "587506W", "587507W", "587508W", "587509W", "587510W", "587511W",
> "587513W", "587514W", "587516W", "587517W", "587518W", "587519W",
> "587520W", "587521W", "587522W", "587523W", "587525W", "587526W",
> "587527W", "587528W", "587529W", "587530W", "587531W", "587532W",
> "587533W", "587534W", "587537W", "587539W", "587540W", "587541W",
> "587542W", "587543W", "587545W", "587546W", "587547W", "587548W",
> "587549W", "587550W", "587551W", "587552W", "587553W", "587554W",
> "587555W", "587556W", "587558W", "587560W", "587561W", "587562W",
> "587563W", "587565W", "587566W", "587568W", "587569W", "587571W",
> "587572W", "587573W", "587574W", "587575W", "587577W", "587578W",
> "587579W", "587580W", "587581W", "587582W", "587584W", "587585W",
> "587586W", "587587W", "587588W", "587589W", "587590W", "587591W",
> "587592W", "587593W", "587594W", "587595W", "587597W", "587598W",
> "587599W", "587600W", "587601W", "587602W", "587603W", "587604W",
> "587606W", "587607W", "587608W", "587610W", "587611W", "587612W",
> "587613W", "587614W", "587616W", "587617W", "587618W", "587619W",
> "587620W", "587621W", "587622W", "587624W", "587626W", "587627W",
> "587628W", "587629W", "587631W", "587632W", "587634W", "587635W",
> "587636W", "587637W", "587638W", "587639W", "587641W", "587642W",
> "587643W", "587644W", "587645W", "587647W", "587648W", "587649W",
> "587650W", "587651W", "587652W", "587653W"), Tm_ugL = c("0.012526909",
> "0.00524721", "0.008974472", "0.014173771", "0.010261946", "0.006209327",
> "0.006427348", "0.011277134", "0.007188303", "0.007920061", "0.006604756",
> "0.002138549", "0.006412799", "0.003809274", "0.00258031", "0.005826568",
> "0.012608666", "0.004640139", "0.005319402", "0.009120296", "0.010841532",
> "0.005542043", "0.009347176", "0.014380953", "0.004871033", "0.004714329",
> "0.009575732", "0.006141329", "0.008756292", "0.015346655", "0.007429521",
> "0.006442689", "0.005501903", "0.008070111", "0.019068198", "0.006140656",
> "0.004317718", "0.003718727", "0.004044718", "0.015449818", "0.0084332",
> "0.009670819", "0.001669213", "0.004783213", "0.003404341", "0.007230384",
> "0.017716786", "0.006114732", "0.003629682", "0.004236707", "0.006259052",
> "0.013515521", "0.007139276", "0.004256668", "0.005247138", "0.004984855",
> "0.003879668", "0.000693273", "0.004473905", "0.005770609", "0.008615954",
> "0.019118999", "0.006625797", "0.006901367", "0.005772831", "0.004440397",
> "0.003950989", "0.004408009", "0.016313629", "0.018295581", "0.004482088",
> "0.010375151", "0.008956765", "0.005987772", "0.023409173", "0.006540896",
> "0.010740111", "0.009647456", "0.003929988", "0.002879241", "0.006664738",
> "0.010107742", "0.002855781", "0.002322324", "0.004469807", "0.003727292",
> "0.006530213", "0.00791199", "0.008722764", "0.019761435", "0.0044777",
> "0.004655689", "0.002153972", "0.003250451", "0.009378664", "0.005276846",
> "0.008247634", "0.002433585", "0.004187209", "0.00472907", "0.005241927",
> "0.007775586", "0.003037972", "0.005233932", "0.01878142", "0.00410588",
> "0.005666064", "0.008062636", "0.0062489", "0.009019154", "0.003570997",
> "0.006629886", "0.011058816", "0.001979885", "0.002941527", "0.006251154",
> "0.003072933", "0.005736085", "0.008841193", "0.008763499", "0.007221573",
> "0.003765729", "0.005356846", "0.007064965", "0.008571698", "0.00455893",
> "0.0032616", "0.008713323", "0.004074075", "0.001143222", "0.005679248",
> "0.006598114", "0.006193131", "0.005219984", "0.004462468", "0.00619499",
> "0.004129983", "0.005652558", "0.010228619", "0.010320457", "0.010966911",
> "0.023724903", "0.005534186", "0.003628177", "0.010590674", "0.005661125",
> "0.005063904", "0.006160644", "0.003499903", "0.005946992", "0.003108242",
> "0.003356377", "0.006943931", "0.009771657", "0.009397079", "0.010179125",
> "0.005096196", "0.006411438", "0.007634242", "0.021263574", "0.00335257",
> "0.01628002", "0.00419588", "0.015669182", "0.006572348", "0.003603196",
> "0.002637675", "0.004219162", "0.004343853", "0.006888431", "0.005887176",
> "0.003603652", "0.01252974", "0.005101809", "0.003068125", "0.004777023",
> "0.00189274", "0.003484976", "0.006002034", "0.004855751", "0.002779958",
> "0.006717209", "0.001116862", "0.006061243", "0.005632965", "0.004339326",
> "0.002648977", "0.001703184", "0.005310346", "0.003453754", "0.000996672",
> "0.002558453", "0.005375883", "0.001720969", "0.003281976", "0.016177406",
> "0.006860274", "0.005246752", "0.001095977", "0.007969571", "0.001122845",
> "0.004682038", "0.008402339", "0.001263145", "0.003866128", "0.004706423",
> "0.011472932", "-0.000965223", "0.010522683", "0.001015816",
> "0.008952635", "0.008219381", "0.005447368", "0.002862524", "0.002111277",
> "0.011379373", "0.001080124", "0.000907393", "0.008243656", "0.002716425",
> "0.00129586", "0.005988267", "0.003701525", "0.00154344", "0.003562045",
> "0.004103097", "0.00433579", "0.006868613", "0.003504652", "0.001236814",
> "0.00973152", "0.003779551", "0.004986519", "0.007649484", "0.006131166",
> "0.00129334", "0.012185827", "0.000740339", "0.009693549", "0.004989262",
> "0.00217159", "0.00289949", "0.005640732", "0.004469108", "0.008496723",
> "0.002003616", "0.001896912", "0.001620197", "0.0030765", "0.001022135",
> "0.010079904", "0.001482784", "0.009489339", "0.005772885", "0.003015524",
> "0.00067034", "0.007470405", "0.002496535", "0.006344776", "0.001165944",
> "0.014426281", "0.002713307", "0.001912026", "0.009576668", "0.000741203",
> "0.006366114", "0.001834612", "0.006300803", "0.001823036", "0.003364833",
> "0.006746047", "0.000802757", "0.007794059", "0.001700595", "0.001173412",
> "0.002066642", "0.006745943", "0.006547318", "0.009330829", "0.005193235",
> "0.011436552", "0.002624799", "0.002880703", "0.017986639", "0.006015463",
> "0.000530537", "0.000602789", "0.006180396", "0.002388551", "0.014148288",
> "0.004941805", "0.009949474", "0.001672992", "0.010996873", "0.007039351",
> "0.001490136", "0.004037547", "0.001063398", "0.009188556", "0.016980239",
> "0.005106021", "0.006178274", "0.003499607", "0.002544697", "0.001231949",
> "0.004662272", "0.015886709", "0.003086586", "0.000539465", "0.003479056",
> "0.000897406", "0.000962605", "0.002355382", "0.000274189", "0.001540451",
> "0.001255926", "0.000957681", "0.002846524", "0.00410014", "0.000797589",
> "0.007528205", "0.001371895", "0.000707452", "0.003948224", "0.001873692",
> "0.000636153", "0.001995548", "0.003618461", "0.00214816", "0.003296673",
> "0.001512562", "0.000311002", "0.014510014", "0.003221849", "0.003503587",
> "0.003542875", "0.003124834", "0.007303395", "0.007802568", "0.002702066",
> "0.00397283", "0.006015735", "0.005122858", "0.005532049", "0.005525161",
> "0.00613509", "0.00300218", "0.004412227", "0.003275197", "0.004003631",
> "0.002215088", "0.00584065", "0.012711175", "0.003779381", "0.000223868",
> "0.001953771", "0.012140221", "0.009275696", "0.001745251", "0.003159705",
> "0.006802756", "0.004796016", "0.011661546", "0.0092607", "0.012578599",
> "0.005562171", "0.00442101", "0.001562554", "0.003561927", "0.003685651",
> "0.002804282", "0.004492147", "0.004936921", "0.007674753", "0.00386058",
> "0.003376528", "0.001389595", "0.003299246", "0.007032604", "0.004386589",
> "0.006771362", "0.000572484", "0.006712266", "0.003898442", "0.001434171",
> "0.003106834", "0.005676694", "0.004939338", "0.007666316", "0.004080318",
> "0.005549484", "0.007699065", "0.000529283", "0.006992565", "0.005134453",
> "0.003002421", "0.009261127", "0.004493311", "0.000338283", "0.01131107",
> "0.010112226", "0.002444407", "0.004452528", "0.005453382", "0.008845841",
> "0.001734873", "0.004470331", "0.002201705", "0.005389719", "0.004956882",
> "0.005111852", "0.003572619", "0.003545642", "0.004354866", "0.002061634",
> "0.00811309", "0.007083798", "0.002999954", "0.001832538", "0.011549497",
> "0.005061518", "0.009316595", "0.003991814", "0.002861382", "0.004105657",
> "0.002296664", "0.003456477", "0.002261021", "0.006203533", "0.002764773",
> "0.002789349", "0.010631997", "0.004795557", "0.002844777", "0.005053105",
> "0.004978561", "0.003668288", "0.002885261", "0.004414269", "0.004583083",
> "0.011745086", "0.003786196", "0.001422543", "0.000870495", "0.002155369",
> "0.00846052", "0.006300383", "0.003517681", "0.003573642", "0.003731246",
> "0.005289539", "0.004252319", "0.004080951", "0.001319694", "0.004707826",
> "0.004099493", "0.00312036", "0.003618851", "0.006710461", "0.001610671",
> "0.002259963", "0.004042389", "0.00470838", "0.006533289", "0.006819086",
> "0.008734313", "0.008993864", "0.004648321", "0.005123464", "0.010062559",
> "0.005941191", "0.004586025", "0.006073371", "0.004040504", "0.00262404",
> "0.008146802", "0.009219039", "0.008745142", "0.007765847", "0.00575151",
> "0.004543592", "0.005352144", "0.003101024", "0.004176024", "0.017691276",
> "0.017940826", "0.014692", "0.012972434", "0.023527925", "0.013830272",
> "0.012585206", "0.005140034", "0.026267023", "0.007217881", "0.004373245",
> "0.011934211", "0.004653821", "0.005563568", "0.007854147", "0.00704775",
> "0.005819472", "0.015995857", "0.006181365", "0.010127657", "0.003627225",
> "0.012709818", "0.012600082", "0.017842015", "0.004550865", "0.019301738",
> "0.007032636", "0.010448506", "0.025213139", "0.005173896", "0.003648471",
> "0.009376725", "0.009395694", "0.011678328", "0.017157179", "0.005700391",
> "0.007887216", "0.005347332", "0.021134762", "0.016879745", "0.003602723",
> "0.016026656", "0.017132957", "0.011385071", "0.012258313", "0.004590344",
> "0.010689005", "0.011108691", "0.005776785", "0.003062257", "0.008456275",
> "0.013875346", "0.009196571", "0.015734791", "0.012147619", "0.009056842",
> "0.045055397", "0.007846725", "0.003301692", "0.005585407", "0.015991166",
> "0.00607262", "0.013360632", "0.011078396", "0.007874128", "0.003263474",
> "0.010696283", "0.026960067", "0.013937758", "0.012980693", "0.013274233",
> "0.006026727", "0.005807527", "0.010149071", "0.011532218", "0.012843804",
> "0.013545956", "0.002776432", "0.008611969", "0.003040787", "0.007443986",
> "0.001312127", "0.0003025", "0.000431156", "0.000224012", "0.00494154",
> "0.004298522", "0.006615671", "0.003321437", "0.007991056", "0.011949974",
> "0.005836289", "0.004665441", "0.006252763", "0.00374617", "0.002683033",
> "0.003340193", "0.001925158", "0.003125216", "0.001007901", "0.003903164",
> "0.006226041", "0.001740977", "0.001317314", "0.005100105", "0.000593273",
> "0.008145521", "0.004973538", "0.00068839", "0.000732802", "0.000428917",
> "0.002766103", "0.012660523", "0.001645637", "0.00194228", "0.001688429",
> "0.004141626", "0.0041443", "0.003029124", "0.007754908", "0.000996367",
> "0.000991018", "0.005289496", "0.007330816", "0.002571047", "0.003490755",
> "0.001076139", "0.00078712", "0.001583428", "0.004340905", "0.002949065",
> "0.004470728", "0.008602732", "0.005311726", "0.002960331", "0.000941386",
> "0.001882459", "0.000123824", "0.00178439", "0.000632667", "0.000429678",
> "0.003095699", "0.000452975", "0.000302891", "0.005672175", "0.003646417",
> "0.00024086", "0.004215561", "0.001111701", "0.003519762", "0.001551716",
> "0.003735266", "0.003006485", "0.00930933", "0.001057213", "0.004632536",
> "0.00294505", "0.006906513", "0.003412497", "0.002686386", "0.014712222",
> "0.000761156", "0.00241515", "0.00239045", "0.00238927", "0.002321314",
> "0.004854263", "0.002159585", "0.002665453", "0.004460844", "0.000830435",
> "0.000765838", "0.000212462", "0.00443449", "0.00351636", "0.003494146",
> "0.000119735", "0.001635048", "0.002138772", "0.003385075", "0.002765276",
> "0.000731873", "0.003022143", "0.001147037", "0.002694729", "0.002468001",
> "0.003206428", "0.00087695", "0.003926637", "0.001024658", "0.022591566",
> "0.000981569", "0.00106184", "0.002951682", "0.002239524", "0.002198322",
> "0.002392364", "0.000200837", "0.000838831", "0.001249875", "0.001854552",
> "0.003678462", "0.00122349", "0.002285418", "0.003499271", "0.002212441",
> "0.003302766", "0.000131422", "0.002778005", "0.000689239", "0.003401039",
> "0.003897639", "0.005810614", "0.002817827", "0.001336956", "0.000915215",
> "0.000138584", "0.002092924", "0.001420982", "0.003454715", "0.002319974",
> "0.004241691", "0.000703056", "0.001907522", "0.002750834", "0.000927527",
> "0.005493349", "0.00030797", "0.003348811", "0.004398022", "0.000226036",
> "0.005377186", "0.001611902", "0.000349171", "0.000584377", "0.000710851",
> "0.001203603", "0.003217803", "0.000685746", "0.001850594", "0.003607466",
> "0.000585491", "0.000423931", "0.000610301", "0.002233248", "0.001244584",
> "0.002675453", "0.000978359", "0.001184482", "0.004059149", "0.00126671",
> "0.001738712", "0.000651386", "0.001975237", "0.001053062", "0.000890737",
> "0.002071903", "0.001803908", "0.001163862", "0.000289041", "0.000776781",
> "0.001570439", "0.000951105", "0.000881612", "0.002155598", "0.000451588",
> "0.002378106", "0.000899796", "0.00108975", "0.000811137", "0.001071885",
> "0.001795971", "0.001271003", "0.000957691", "0.000496391", "0.001607021",
> "0.001612781", "0.000588984", "0.000473565", "0.001032657", "0.001606533",
> "0.003887263", "0.00219703", "0.002224258", "0.000803389", "0.001158066",
> "0.001260996", "0.000777962", "0.000519006", "0.002674644", "0.00089824",
> "0.001968543", "0.000793111", "0.000838132", "0.000295642", "0.000898893",
> "0.000618909", "0.00094089", "0.002481642", "0.002865756", "0.00212707",
> "0.000814292", "0.000692303", "0.001217371", "0.001547876", "0.001889694",
> "0.000423925", "0.001494921", "0.002256496", "0.008533809", "0.00103441",
> "0.00146961", "0.000321683", "0.001205398", "0.001934957", "0.000693342",
> "0.000723974", "0.000823272", "0.000431806", "0.00150659", "0.00485395",
> "0.005568073", "0.00295471", "0.003604626", "0.003186087", "0.003888975",
> "0.002884695", "0.005255963", "0.003253941", "0.002825274", "0.002356029",
> "0.004924949", "0.003473988", "0.00199782", "0.00318568", "0.003746233",
> "0.003637744", "0.003983428", "0.003235627", "0.002308502", "0.003991285",
> "0.003343607", "0.002065512", "0.003601773", "0.004931388", "0.005011346",
> "0.002393396", "0.003392815", "0.002426415", "0.003920471", "0.001757544",
> "0.002607264", "0.002349977", "0.004420568", "0.004202681", "0.003482522",
> "0.002276988", "0.00070119", "0.001897584", "0.001911513", "0.001838116",
> "0.001968399", "0.002341677", "0.003403627", "0.002415555", "0.003050358",
> "0.002038022", "0.003838283", "0.004053138", "0.003659568", "0.003976984",
> "0.002691909", "0.003232401", "0.003172718", "0.002495762", "0.002885779",
> "0.001910272", "0.003682516", "0.000608884", "0.003259595", "0.001808769",
> "0.002652719", "0.003421534", "0.003388999", "0.003178429", "0.000131713",
> "0.002772827", "0.002745533", "0.001687844", "0.003835246", "0.001178599",
> "0.003790402", "0.00306021", "0.002547791", "0.003856114", "0.001600552",
> "0.002385385", "0.001446147", "0.003100929", "0.001622527", "0.002198012",
> "0.003880893", "0.001848878", "0.005152942", "0.005524076", "0.005839341",
> "0.007647582", "0.003992075", "0.006334646", "0.002723267", "0.002856498",
> "0.002546458", "0.002539948", "0.00298808", "0.002690881", "0.003025162",
> "0.00411367", "0.002830494", "0.002061289", "0.003505905", "0.005743849",
> "0.001363744", "0.004132753", "0.001205898", "0.002471435", "0.003904816",
> "0.002813961", "0.001675182", "0.00112607", "0.01050083", "0.003607515",
> "0.002251644", "0.003635582", "0.001814219", "0.000961893", "0.001156666",
> "0.000993787", "0.001679378", "0.000292747", "0.001708425", "0.001397416",
> "0.000672403", "0.00066883", "0.000388092", "0.002085225", "0.002628926",
> "0.0007081", "0.001849466", "0.003126619", "0.001124511", "0.000291853",
> "0.00098991", "0.000869237", "0.003016002", "0.000228249", "0.001054935",
> "0.000565486", "0.000980794", "0.001281882", "0.001750751", "2.78E-05",
> "0.001225465", "0.001729677", "0.001967867", "0.000946134", "0.001831121",
> "0.001940498", "0.000491159", "0.002862978", "0.003546984", "0.000878387",
> "0.002351657", "0.001844002", "0.002855443", "0.000886189", "0.000769673",
> "0.004398294", "0.000985056", "0.003717415", "0.00211658", "0.001719138",
> "0.005380235", "0.001645296", "0.0066795", "0.001849253", "0.002303189",
> "0.003523623", "0.003384322", "0.007160586", "0.002131704", "0.000973316",
> "0.003329035", "0.001888361", "0.003957041", "0.001013554", "0.001992457",
> "0.00381132", "0.000900741", "0.003273894", "0.001541242", "0.00047345",
> "0.002916697", "0.003641086", "0.000551149", "0.000988825", "0.002934236",
> "0.002365281", "0.000582871", "0.0018318", "0.000929752", "0.001837291",
> "0.000924292", "0.001031842", "0.000684132", "0.001709506", "0.000981114",
> "0.003457973", "0.001817987", "0.002269985", "0.007918975", "0.006223432",
> "0.00123671", "0.00391469", "0.002255457", "0.004180743", "0.00057043",
> "0.001892729", "0.001912139", "0.00194498", "0.001104034", "0.002003286",
> "0.00036947", "0.002635989", "0.001007859", "0.003439656", "0.000805272",
> "0.005867473", "0.004465443", "0.001133879", "0.002842206", "0.003604218",
> "0.001081663", "0.001023529", "0.000400453", "0.001224269", "0.00633427",
> "0.001300423", "0.000522795", "0.002777271", "0.000465839", "0.004491359",
> "0.000650466", "0.007881145", "0.002128289", "0.000696387", "0.000687194",
> "0.008668156", "0.001173474", "0.000782956", "0.006217158", "0.001097588",
> "0.003761749", "0.000896479", "0.000612694", "0.00455723", "0.001562075",
> "0.001577265", "0.003530944", "0.000882146", "0.004741189", "0.000462436",
> "0.002423694", "0.001426078", "0.001229695", "0.000151495", "0.00074423",
> "0.00056349", "0.000834488", "0.001577975", "0.001176036", "0.000714083",
> "0.002160032", "0.000567437", "0.0022188", "0.000685868", "0.000520177",
> "0.002483573", "0.001544549", "0.002397179", "0.000455309", "0.000184648",
> "0.000753078", "0.001213727", "0.000526527", "0.000502182", "0.001300605",
> "0.000386059", "0.000624726", "0.000612817", "0.002137467", "0.000521678",
> "0.000531583", "0.00061902", "0.000737619", "0.000529807", "0.000479971",
> "0.000774262", "0.000298302", "0.001277028", "0.003589314", "0.001377721",
> "0.001120529", "0.000974931", "0.001191647", "0.001625546", "0.000410325",
> "0.003808545", "0.000541247", "0.000602081", "0.000931481", "0.00048247",
> "0.001402605", "0.000463932", "0.001620905", "0.000940527", "0.005848518",
> "0.000411341", "0.001161372", "0.00106367", "0.000371135", "0.00218473",
> "0.000826734", "0.000781781", "0.000430428", "0.003926327", "0.004253917",
> "0.004915174", "0.002098122", "0.001027593", "0.001891307", "0.001483668",
> "0.001715159", "0.001065548", "0.001054245", "0.001791568", "0.00138467",
> "0.000466776", "0.00054037", "0.000368882", "0.003345409", "0.000837835",
> "0.000453112", "0.001788554", "0.000712708", "0.000490224", "0.001499223",
> "0.001705885", "0.000365198", "0.001437334", "0.000480388", "0.000782941",
> "0.001200423", "0.001420415", "0.000557051", "0.001934047", "0.002820197",
> "0.000399331", "0.000712066", "0.000825201", "0.001077064", "0.004180338",
> "0.003478947", "0.000847928", "0.001411386", "0.000464363", "0.000787172",
> "0.000486185", "0.001211366", "0.003051988", "0.000202072", "0.00045573",
> "0.001039212", "0.00056067", "0.000838216", "0.000611339", "0.001155582",
> "0.003934398", "0.000446241", "0.000447143", "0.000585918", "0.000756123",
> "0.000208236", "0.000746805", "0.000537549", "0.001443552", "0.00052824",
> "0.002368153", "0.000509967", "0.007735125", "0.000985745", "0.000527702",
> "0.000717133", "0.000577142", "0.006871698", "0.001248825", "0.001075524",
> "0.001100964", "0.000529795", "0.000551858", "0.000745879", "0.000588481",
> "0.002622651", "0.00091465", "0.004629061", "0.000597808", "0.000765995",
> "0.001018027", "0.000596912", "0.001713204", "0.000438174", "0.000800995",
> "0.000653485", "0.000958346", "0.001217594", "0.00076445", "0.001449324",
> "0.000601024", "0.000552241", "0.000592449", "0.000772156", "0.001249651",
> "0.001668726", "0.000701755", "0.000412507", "0.000727716", "0.000574364",
> "0.001042749", "0.000654564", "0.007129834", "0.008426946", "0.005309422",
> "0.005264616", "0.009384992", "0.005010607", "0.007570028", "0.009928717",
> "0.004170362", "0.003675265", "0.004512786", "0.005685186", "0.008237337",
> "0.004367586", "0.00546405", "0.003804582", "0.005236974", "0.003851435",
> "0.003415034", "0.003219466", "0.002210227", "0.002468179", "0.006069194",
> "0.002674289", "0.002849557", "0.002874692", "0.004102971", "0.003420821",
> "0.002655607", "0.002715811", "0.001471085", "0.001153459", "0.001042614",
> "0.005116195", "0.004592545", "0.001979374", "0.002412844", "0.001775336",
> "0.002868092", "0.001479601", "0.002577762", "0.001726507", "0.008248861",
> "0.001528246", "0.000541653", "0.001046778", "0.001539396", "0.001555099",
> "0.000657847", "0.000701465", "0.000673238", "0.000406553", "0.001628931",
> "0.001364921", "0.001974572", "0.001179476", "0.001127028", "0.000544126",
> "0.003940931", "0.001809584", "0.001454501", "0.00055187", "0.002078805",
> "0.003618322", "0.003185248", "0.002108602", "0.003186393", "0.001073216",
> "0.00396052", "0.000564544", "0.000900958", "0.002872154", "0.000716866",
> "0.004465343", "0.00292876", "0.000865699", "0.000304731", "0.004025274",
> "0.000461351", "0.000450024", "0.000637492", "0.000844207", "0.000716671",
> "0.00051467", "0.002330396", "0.00321308", "0.000996569", "0.002008234",
> "0.003364558", "0.00295349", "0.002459354", "0.001837184", "0.002061878",
> "0.005708132", "0.001568306", "0.002370841", "0.002080082", "0.001691857",
> "0.003587493", "0.003525431", "0.003626336", "0.003275526", "0.001566228",
> "0.002677126", "0.001918935", "0.001267504", "0.006069495", "0.003330838",
> "0.001634574", "0.001656518", "0.001062276", "0.00193658", "0.006595035",
> "0.003701294", "0.002165792", "0.002795057", "0.001995466", "0.001001598",
> "0.004566041", "0.00313271", "0.003507699", "0.000874182", "0.001736094",
> "0.004154664", "0.000801187", "0.000273351", "0.001434848", "0.000208856",
> "0.001787169", "0.000660318", "0.000536208", "0.000827012", "0.003525523",
> "0.00568365", "0.003374476", "0.000629977", "-0.000122666", "0.005430694",
> "0.002046878", "2.87E-05", "0.001524734", "0.000723769", "0.003064301",
> "0.001821976", "0.001019279", "0.007122004", "0.00251728", "0.004342001",
> "0.002250916", "0.00249346", "0.000239402", "0.000206815", "0.000721918",
> "0.00123834", "0.001185488", "0.000602984", "0.002770875", "0.000431782",
> "0.002377602", "0.001150575", "0.00030252", "0.00239937", "0.001526856",
> "-5.32E-05", "0.011119607", "0.006887013", "0.005297693", "0.007102272",
> "0.004629353", "0.006308193", "0.009097256", "0.003582059", "0.003171425",
> "0.004769043", "0.00436875", "0.004126409", "0.003745626", "0.006291541",
> "0.004661988", "0.002503414", "0.003738629", "0.002155848", "0.005247106",
> "0.004225906", "0.004314957", "0.002606456", "0.003302233", "0.003429194",
> "0.004433893", "0.004032763", "0.001081671", "0.005185865", "0.003343411",
> "0.001731607", "0.002069157", "0.003150157", "0.003945407", "0.01995829",
> "0.002212524", "0.003122456", "0.001172068", "0.003164391", "0.002629812",
> "0.001981082", "0.003262964", "0.002421709", "0.002662325", "0.0013619",
> "0.002562372", "0.004551291", "0.00188528", "0.001213029", "0.002043811",
> "0.0008071", "0.002179448", "0.001822949", "0.002814085", "0.001257899",
> "0.001727223", "0.002886211", "0.00489911", "0.001579536", "0.001492332",
> "0.002597319", "0.002747154", "0.001371866", "0.003588882", "0.00123881",
> "0.001751715", "0.001258067", "0.003636411", "0.001684895", "0.002349261",
> "0.000735361", "0.002742615", "0.001891355", "0.00265467", "0.003050261",
> "0.001720556", "0.002217222", "0.001980177", "0.001664318", "0.001268427",
> "0.00140942", "0.002315045", "0.001975644", "0.001318715", "0.001555535",
> "0.001038484", "0.000347719", "0.001127557", "0.001057505", "0.001268971",
> "0.001179467", "0.000641593", "0.002236545", "0.001624429", "0.000173284",
> "0.000536243", "0.000243979", "0.000909077", "0.000309063", "0.001019427",
> "0.002047875", "0.000790357", "0.000229934", "0.002791066", "0.00166546",
> "0.000248693", "0.001842087", "0.002583505", "0.001026626", "0.001041061",
> "0.002264823", "0.001665034", "0.000155991", "0.00259237", "0.001646788",
> "0.000477204", "0.000501514", "0.000163174", "0.002588385", "0.000796153",
> "0.002689299", "0.000684056", "-0.000313278", "0.002198574",
> "0.001088117", "0.000528814", "0.000263083", "0.000776179", "0.000794529",
> "0.000142439", "-0.000647425", "0.00193036", "0.000108009", "0.00077782",
> "-0.000481816", "0.000635381", "-0.000449205", "0.000782408",
> "0.004548418", "0.003280907", "0.003329733", "0.002035799", "0.005579869",
> "0.002560187", "0.002545633", "0.005059885", "0.007037327", "0.009001771",
> "0.003558769", "0.0035235", "0.002295552", "0.001286924", "0.00167687",
> "0.002037401", "0.001995618", "0.001726902", "0.002502914", "0.001398049",
> "0.002399104", "0.003860254", "0.004806359", "0.004938743", "0.003083788",
> "0.001515187", "0.001466474", "0.001676741", "0.000334469", "0.002167219",
> "0.001649118", "0.007160555", "0.002967383", "0.001113913", "0.00174345",
> "0.001535035", "0.004020107", "0.001171428", "0.004565952", "0.001237616",
> "0.00505863", "0.001154021", "0.000653467", "0.005069884", "0.002324774",
> "0.004645691", "0.002761466", "0.001699281", "0.00089456", "0.003129216",
> "8.49E-05", "0.002514879", "0.004329247", "0.00221013", "0.002568565",
> "0.000971213", "0.000821615", "0.001461689", "0.002523476", "0.001508604",
> "0.003036535", "0.002665244", "0.001453472", "0.001451201", "0.000477768",
> "0.002484081", "0.001474277", "0.003349971", "0.00103818", "0.002414691",
> "0.001450037", "0.000751229", "0.004421348", "0.001129423", "0.003419222",
> "0.000995329", "0.002445221", "0.000617759", "0.002848817", "0.002645904",
> "0.001645723", "0.0003746", "0.000940474", "0.003725902", "0.000392291",
> "0.001147437", "0.001145907", "0.000561023", "0.001381841", "0.001110684",
> "0.000544623", "0.00054095", "0.000448923", "0.000590861", "0.002452948",
> "0.000552008", "0.000610962", "0.001299856", "0.001317185", "0.002698184",
> "0.003493815", "0.003244857", "0.00061984", "0.000801545", "0.00149525",
> "0.000409405", "0.003370267", "0.002207745", "0.0011107", "0.002229292",
> "0.000488196", "0.00174331", "0.006678113", "0.002816683", "0.000839952",
> "0.003398768", "0.003672784", "0.003091944", "0.006648423", "0.004623602",
> "0.003195142", "0.0008055", "0.00052442", "0.00279123", "0.001106953",
> "0.001105858", "0.004357319", "0.006961374", "0.000439899", "0.00332042",
> "0.000410736", "0.000828855", "0.002473165", "0.001286492", "0.001670331",
> "0.003446209", "0.004968425", "0.001344075", "0.000531173", "0.004086341",
> "0.000888029", "0.007199893", "0.009696178", "0.000817644", "0.008603312",
> "0.000538208", "0.000715276", "0.003829826", "0.002665075", "0.000655645",
> "0.004521186", "0.00475768", "0.000681104", "0.003250429", "0.001037136",
> "0.004149464", "0.003025068", "0.000661952", "0.001511905", "0.001230574",
> "0.000855192", "0.001946997", "0.002197531", "0.000962446", "0.002434427",
> "0.001437311", "0.001685384", "0.000843318", "0.000597531", "0.003679736",
> "0.00052786", "0.002599698", "0.006638163", "0.000492092", "0.003381131",
> "0.004282117", "0.002772674", "0.001209647", "0.005015221", "0.002725676",
> "0.001817094", "0.004275772", "0.006164229", "0.001852464", "0.004668182",
> "0.00025729", "0.000571824", "0.003998807", "0.000310591", "0.003167884",
> "0.001286295", "0.001117448", "0.000285175", "0.002681743", "0.002541922",
> "0.000339817", "0.002717807", "0.003086299", "0.003665057", "0.001442348",
> "0.000133803", "0.004258506", "0.004458759", "0.000587058", "0.011033508",
> "0.000646106", "0.003609799", "0.004706507", "0.006409543", "0.000690599",
> "0.002099984", "0.001362624", "0.006168257", "0.000262889", "0.000657049",
> "0.000548061", "0.001194158", "0.00236448", "0.000866242", "0.000321134",
> "0.003252815", "0.000405544", "0.003749155", "0.002423416", "0.000715815",
> "0.002068842", "0.000681442", "0.002587891", "0.001318798", "0.002900788",
> "0.006026455", "0.003699808", "0.001977136", "0.000945813", "0.001145864",
> "0.005304798", "0.007237841", "0.002849855", "0.000441675", "0.000411287",
> "0.000768919", "0.00031052", "0.012539592", "0.006597502", "0.003484505",
> "0.013217535", "0.006680105", "0.006715462", "0.004410384", "0.006726778",
> "0.003722312", "0.012390133", "0.006711536", "0.004539865", "0.006212197",
> "0.003296238", "0.00495935", "0.007676141", "0.005152604", "0.002807202",
> "0.002521741", "0.003382216", "0.005610252", "0.002612738", "0.002026107",
> "0.001670699", "0.001927528", "0.00194118", "0.001634303", "0.009430554",
> "0.001204734", "0.003701371", "0.003278496", "0.003673539", "0.001572092",
> "0.005461998", "0.007659243", "0.000794725", "0.003422438", "0.005669143",
> "0.002985877", "0.000272664", "0.002271537", "0.005386226", "0.000931846",
> "0.001839194", "0.002773973", "0.00219973", "0.00264419", "0.002359631",
> "0.003208366", "0.00155871", "0.002459454", "0.002203402", "0.004330583",
> "0.006671027", "0.004574731", "0.001901366", "0.002839133", "0.003895146",
> "0.002403823", "0.002021783", "0.002035402", "0.002471519", "0.002258829",
> "0.000748663", "0.003052609", "0.000756361", "0.003848861", "0.002010261",
> "0.002319319", "0.002734265", "0.003931146", "0.004014014", "0.001212488",
> "0.004313271", "0.001803602", "0.000438857", "0.003518248", "0.000983077",
> "0.000536783", "0.001030337", "0.005479628", "0.001986754", "0.002075642",
> "0.000304379", "0.001501574", "0.001573557", "0.002023082", "0.003399616",
> "0.003702631", "0.000973154", "0.002929413", "0.003016686", "0.001960026",
> "0.001893558", "0.003439089", "0.001924369", "0.007517484", "0.000899346",
> "0.001569812", "0.002040772", "0.003196777", "0.001955455", "0.002831375",
> "0.002804938", "0.001917154", "0.003672333", "0.005551972", "0.002036081",
> "0.001444845", "0.000401853", "0.002284308", "0.002822319", "0.000445111",
> "0.001241386", "0.003884877", "0.00325356", "0.00224486", "0.003521492",
> "0.002886992", "0.003133533", "0.002155552", "0.003339618", "0.001423891",
> "0.009148341", "0.002143469", "0.005051723", "0.004020353", "0.003620972",
> "0.003749512", "0.002030368", "0.003850751", "0.003291713", "0.003876949",
> "0.003633955", "0.000600088", "0.002769233", "0.000944595", "0.004263147",
> "0.000596448", "0.002646152", "0.001701854", "0.007998223", "0.005154705",
> "0.00265977", "0.001832958", "0.001064938", "0.006562253", "0.004358674",
> "0.000521506", "0.001817005", "0.005737944", "0.000521742", "0.00246014",
> "0.00223602", "0.001456657", "0.004855751", "0.003058413", "0.002387861",
> "0.003210591", "0.002263782", "7.37E-05", "0.002971081", "0.001318834",
> "0.001131532", "0.007653804", "0.002033245", "0.007817832", "0.003851958",
> "0.001010928", "0.001083535", "0.000616509", "0.001179324", "0.000288743",
> "0.003962735", "0.001787123", "0.001447554", "0.001253004", "0.001528183",
> "0.003366145", "0.002102381", "0.000145862", "0.003494018", "0.002128656",
> "0.003675162", "0.00759652", "0.001250727", "0.001506475", "0.000621707",
> "0.003006809", "0.000996703", "0.001929081", "0.002620048", "0.002965278",
> "0.004220162", "0.004578438", "0.001630116", "0.001431606", "0.00541955",
> "0.002649892", "0.000315404", "0.001374571", "0.000853286", "0.003181114",
> "0.002473225", "0.000629849", "0.002496231", "0.001432285", "0.002952843",
> "0.000182705", "0.000259503", "0.001618141", "0.000903009", "0.000608267",
> "0.000449268", "0.001571867", "0.000772154", "0.000825798", "0.001579361",
> "0.016348978", "0.002728901", "0.000480176", "0.002312973", "0.001579204",
> "0.000658368", "0.002309267", "0.000496615", "0.000580794", "0.003557672",
> "0.000450865", "0.000478168", "0.001619451", "0.001266267", "0.001119731",
> "0.001307925", "0.000355222", "0.000436949", "0.000526895", "0.001205208",
> "0.000537842", "0.002228826", "0.003704735", "0.002574494", "0.00107791",
> "0.006010363", "0.002175136", "0.003591312", "0.001068334", "0.003293846",
> "0.003000628", "0.005299653", "0.003326611", "0.00288343", "0.002430028",
> "0.002559727", "0.00507947", "0.002404173", "0.002047677", "0.002077716",
> "0.002276752", "0.002236428", "0.004367058", "0.001876632", "0.000980004",
> "0.003916822", "0.002808333", "0.001898333", "0.001366381", "0.000667145",
> "0.001446287", "0.001100975", "0.004796705", "0.001333197", "0.000595446",
> "0.005502218", "0.000862944", "0.00108622", "0.006379905", "0.00070873",
> "0.000772437", "0.005811963", "0.001055143", "0.005369487", "0.005318855",
> "0.001830795", "0.00142247", "0.003741093", "0.000699842", "0.002726698",
> "0.002330577", "0.002526381", "0.000516793", "0.00080217", "0.003866176",
> "0.000479181", "0.001610321", "0.000944431", "0.005955068", "0.000938004",
> "0.005707428", "0.000602962", "0.001578971", "0.001504067", "0.00072246",
> "0.004531777", "0.000614755", "0.002103022", "0.005264682", "0.005090387",
> "0.004696797", "0.000460688", "0.000530431", "0.001922937", "0.00566926",
> "0.000388306", "0.004252679", "0.00205673", "0.001783312", "0.002651375",
> "0.003740467", "0.00638282", "0.00334707", "0.002155446", "0.002261144",
> "0.00237246", "0.003669549", "0.003744011", "0.001334122", "0.002774739",
> "0.002572677", "0.001193501", "0.002378721", "0.001016823", "0.002519132",
> "0.000936095", "0.005202675", "0.002536735", "0.00252089", "0.004389852",
> "0.002645601", "0.005036094", "0.002028686", "0.00287482", "0.00039039",
> "0.001700629", "0.002406003", "0.003000786", "0.000350833", "0.00237079",
> "0.001370358", "0.000281447", "0.001162593", "0.000391126", "0.000428876",
> "0.003587365", "0.001830857", "0.001245239", "0.00054402", "0.000786806",
> "0.000308136", "0.002252348", "0.001009821", "0.007197987", "0.003429838",
> "0.00047818", "0.000191829", "0.001469793", "0.000701897", "0.000303383",
> "0.000240607", "0.000367176", "0.000806676", "0.001029976", "0.001764326",
> "0.000586666", "0.001052103", "0.0027832", "0.002899223", "0.000535299",
> "0.000321216", "0.002765093", "0.003304198", "0.000928385", "0.003349216",
> "0.00262997", "0.001902671", "0.00740575", "0.001269628", "0.001087366",
> "0.000306576", "0.010979008", "0.000142284", "0.003562197", "0.000951849",
> "0.004738473", "0.001147934", "0.000868998", "0.000100094", "0.003396012",
> "0.001425963", "0.000457682", "0.001134672", "0.006125895", "0.001206639",
> "0.001288869", "9.26E-05", "0.000970596", "0.004299361", "0.001365496",
> "0.000252023", "0.000881799", "0.001159217", "0.002769744", "0.001347274",
> "0.002506093", "0.002587892", "0.001760215", "0.000200908", "0.000120504",
> "0.000995343", "0.001956552", "0.00396928", "0.001998548", "0.000989844",
> "0.00182333", "0.004934963", "0.005930661", "0.003704832", "0.005100611",
> "0.001174396", "0.001573248", "0.001514134", "0.004770532", "0.001596482",
> "0.002227835", "0.000293322", "0.000765304", "0.006579839", "0.002086935",
> "0.000516124", "0.002598376", "0.000677743", "0.001751905", "0.000765355",
> "0.000851338", "0.002038965", "0.002461201", "0.004482297", "0.002665955",
> "0.00053772", "0.0026631", "0.002186892", "0.002164451", "0.001769369",
> "0.000556618", "0.001811205", "0.001436441", "0.003730669", "0.000540904",
> "0.002073718", "0.006881776", "0.000504263", "0.011870741", "0.012497633",
> "0.000723731", "0.00138756", "0.000796687", "0.001090998", "0.001702514",
> "0.001459711", "0.002239202", "0.001484793", "0.000216742", "0.001406412",
> "0.000537954", "0.000751007", "0.000141754", "0.001252295", "0.001357958",
> "0.000426315", "0.000396497", "0.000712089", "0.001571138", "0.000631633",
> "0.001320965", "0.000791112", "0.001042755", "0.001922778", "0.001338678",
> "0.002061002", "0.001257354", "0.001032697", "0.002156974", "0.000758648",
> "0.00115927", "0.000493399", "0.002868998", "0.000644541", "0.000963915",
> "0.002440877", "0.001530594", "0.001660393", "0.001974633", "0.002683663",
> "0.001027642", "0.0013826", "0.001268996", "0.002888161", "0.002042083",
> "0.000275954", "0.000425662", "0.001395292", "0.000698374", "0.001280422",
> "0.000360265", "0.00286505", "0.000657062", "0.000832286", "0.001509413",
> "0.009461693", "0.001173043", "0.001320977", "0.000374569", "0.003380137",
> "0.000648815", "0.003506032", "0.007945229", "0.001816186", "0.00593997",
> "0.001615382", "0.000617105", "0.000998473", "0.002682396", "0.002608846",
> "0.001042748", "0.000608391", "0.003155706", "0.000350366", "0.011011332",
> "0.001071085", "0.003032408", "0.002362787", "0.000785395", "0.000369495",
> "0.000729234", "0.002874633", "0.001277868", "0.000412434", "0.00337317",
> "0.002100282", "0.00127116", "0.00087507", "0.003909292", "0.000809452",
> "0.003842508", "0.000261334", "0.002695379", "0.003381531", "0.000959406",
> "0.000830514", "0.001417701", "0.001216766", "0.000580054", "0.000982322",
> "0.009152715", "0.004942274", "0.002247519", "0.00956424", "0.002955447",
> "0.003146615", "0.001329276", "0.000585691", "0.004521217", "0.002996703",
> "0.000862505", "0.002412426", "0.000249773", "0.001064878", "0.00218024",
> "0.001837315", "0.002573162", "0.002837718", "0.001951952", "0.001664727",
> "0.001366389", "0.001962139", "0.001443101", "0.000571743", "0.001736855",
> "0.002811318", "0.001017781", "0.001553503", "0.00431465", "0.012072091",
> "0.002428644", "0.0005115", "0.001977798", "0.00024813", "0.005039793",
> "0.00082675", "0.002480204", "0.002225975", "0.001997709", "0.002641843",
> "0.002820302", "0.001707712", "0.00188298", "0.002150676", "0.001328293",
> "0.001405165", "0.00298826", "0.001502586", "0.002395292", "0.002796706",
> "0.005203437", "0.004817151", "0.00030616", "0.001322253", "0.00455419",
> "0.001884207", "0.000751607", "0.000622799", "0.003630857", "0.001554908",
> "0.000384964", "0.000696522", "0.000292492", "0.001132897", "0.002078203",
> "0.002657073", "0.000610842", "0.002378412", "0.00083702", "0.003651925",
> "0.001021224", "0.000738553", "0.001776616", "0.001427956", "0.001826608",
> "0.001017576", "0.000523945", "0.000729999", "0.000700889", "0.004372708",
> "0.0010721", "0.005203322", "0.00180632", "0.000614454", "0.003935009",
> "0.002946169", "0.001363085", "0.000413364", "0.000394261", "0.001080705",
> "0.003037984", "0.000221178", "0.00079759", "0.00162498", "0.002324509",
> "0.001339628", "0.002972215", "0.001966148", "0.0016092", "0.000234344",
> "0.000993412", "0.000937602", "0.000415351", "0.002608404", "0.000564896",
> "0.000999391", "0.001383561", "0.00032661", "0.003116056", "0.00269477",
> "0.001127392", "0.001387888", "0.001568912", "0.00199253", "0.000374667",
> "0.002648756", "0.001985879", "0.001983733", "0.000659444", "0.003735928",
> "0.000649978", "0.000531627", "0.004032346", "0.00084578", "0.000707181",
> "0.00176177", "0.000724044", "0.000664402", "0.011373309", "0.002388706",
> "0.000774438", "0.003342828", "0.002197908", "0.002795226", "0.000567306",
> "0.001694292", "0.00166641", "0.001945432", "0.002895236", "0.001046278",
> "0.002323907", "0.001420304", "0.001982192", "0.000677479", "0.000491854",
> "0.001486234", "0.001277554", "0.003431615", "0.001142057", "0.002065289",
> "0.000825491", "0.000925508", "0.000913616", "0.001868473", "0.001826053",
> "0.001221936", "0.002615253", "0.00198233", "0.000654061", "0.001676624",
> "0.001221201", "0.000456194", "0.000841204", "0.005091102", "0.001521278",
> "0.00140408", "0.00356072", "0.001374545", "0.000975109", "0.001850532",
> "0.000490473", "0.001053579", "0.000547076", "0.001429506", "0.000989919",
> "0.00029281", "0.000864564", "0.002571375", "0.001410263", "0.002523124",
> "0.000843319", "0.000788548", "0.000942674", "0.000862536", "0.001145244",
> "0.000731401", "0.000922755", "0.00080113", "0.001147544", "0.000999559",
> "0.001002895", "0.001534572", "0.001124767", "0.00055331", "0.001453456",
> "0.001563662", "0.002073296", "0.001865843", "0.001249885", "0.002239018",
> "0.000909996", "0.002121782", "0.002524288", "0.001410567", "0.00208956",
> "0.000853813", "0.003419427", "0.002006391", "0.000549302", "0.000902927",
> "0.001930719", "0.00167763", "0.002530737", "0.003240916", "0.001839864",
> "0.001413561", "0.001725875", "0.001846509", "0.003881131", "0.000861918",
> "0.000663578", "0.002255887", "0.000871992", "0.001004718", "0.001688389",
> "0.003073294", "0.000949486", "0.001302246", "0.000464419", "0.001215565",
> "0.003880833", "0.001844661", "0.003083818", "0.002076196", "0.003507372",
> "0.002746735", "0.001611621", "0.001053223", "0.001772452", "0.001441064",
> "0.002639818", "0.003257066", "0.002662365", "0.004859482", "0.00349962",
> "0.001242116", "0.002071981", "0.001188572", "0.002338708", "0.002206605",
> "0.001728737", "0.001522004", "0.001383648", "0.00098972", "0.004487214",
> "0.000812133", "0.001113718", "0.002843833", "0.001116469", "0.001460217",
> "0.001338645", "0.001437048", "0.003548891", "0.001054238", "0.001435734",
> "0.008424636", "0.003766785", "0.003005459", "0.002083674", "0.003384797",
> "0.001496615", "0.002147265")), .Names = c("Analyte", "Tm_ugL"
> ), na.action = structure(3495L, .Names = "3498", class = "omit"), row.names
> = 4:2603, class = "data.frame")
> 
> This is my matrix for storing the data:
> 
> A_Censored<-matrix(A[,two],nrow(A),two)
> 
> This is my for loop for assessing whether it is above or below a certain
> value (A_LLD<-0.0002):
> 
> for (i in one:nrow(A))
>   if (A[i,two]<=A_LLD)
>   {
>     (A_Censored[i,two]<-"TRUE")
>   }else
>     A_Censored[i,two]<-"FALSE"
> 
> 
> 
> And this is my count function
> 
> LLD_Count<- function(Element_List)
> {Element_List<-na.omit(Element_List)
>  Count<-0
>  for (i in one:nrow(Element_List))
>    if (Element_List[i,two]=="TRUE")
>      Count<-Count+one
>  Count_perc<-(Count/length(Element_List[,two])*hundred)
>  LLD_Output<-data.frame(Count,Count_perc)
>  colnames(LLD_Output)<-c("N below LLD","Pecent below LLD")
>  return(LLD_Output)
> }
> 
> Im really stuck and your help be greatly appreciated.
> Thanks
> 
> --
> Shane
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Jason.Law at portlandoregon.gov  Thu Oct  3 19:06:12 2013
From: Jason.Law at portlandoregon.gov (Law, Jason)
Date: Thu, 3 Oct 2013 10:06:12 -0700
Subject: [R] Counting numbers in R
In-Reply-To: <CA+jRDxAQ=StpYU3V47gUQVo8KjYi0B7dSGOAqieynh456GkVoA@mail.gmail.com>
References: <CA+jRDxAQ=StpYU3V47gUQVo8KjYi0B7dSGOAqieynh456GkVoA@mail.gmail.com>
Message-ID: <0EFBC7C31DB4F24F8CAC48136A1762D70184ECB89C9A@MAIL2.rose.portland.local>

You really need to read to read a tutorial on R.  But here's what I think you're trying to do:

d$censored <- d$Tm_ugL < 0.0002
table(d$censored)

Jason Law

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Shane Carey
Sent: Thursday, October 03, 2013 9:27 AM
To: r-help at r-project.org
Subject: [R] Counting numbers in R

Hi,

I have a set of data and I need to find out how many points are below a
certain value but R will not calculate this properly for me. Negative
numbers seem to be causing the issue.

This is my data:
structure(list(Analyte = c("584501W", "584502W", "584504W", "584506W",
"584507W", "584508W", "584509W", "584510W", "584511W", "584513W",
"584514W", "584516W", "584517W", "584518W", "584519W", "584520W",
"584521W", "584522W", "584523W", "584525W", "584526W", "584527W",
"584528W", "584529W", "584530W", "584531W", "584532W", "584533W",
"584534W", "584535W", "584536W", "584537W", "584539W", "584540W",
"584543W", "584545W", "584546W", "584547W", "584548W", "584549W",
"584550W", "584551W", "584552W", "584553W", "584554W", "584555W",
"584556W", "584558W", "584561W", "584562W", "584563W", "584565W",
"584566W", "584569W", "584570W", "584571W", "584572W", "584573W",
"584574W", "584575W", "584577W", "584578W", "584579W", "584580W",
"584581W", "584582W", "584584W", "584585W", "584586W", "584587W",
"584588W", "584589W", "584590W", "584591W", "584592W", "584594W",
"584595W", "584597W", "584599W", "584600W", "584601W", "584602W",
"584603W", "584604W", "584606W", "584607W", "584610W", "584611W",
"584612W", "584613W", "584614W", "584615W", "584616W", "584617W",
"584618W", "584619W", "584620W", "584621W", "584622W", "584624W",
"584625W", "584626W", "584627W", "584628W", "584629W", "584631W",
"584632W", "584635W", "584636W", "584637W", "584638W", "584639W",
"584642W", "584643W", "584644W", "584645W", "584647W", "584649W",
"584650W", "584651W", "584652W", "584653W", "584655W", "584657W",
"584658W", "584659W", "584660W", "584661W", "584662W", "584663W",
"584665W", "584666W", "584667W", "584669W", "584670W", "584671W",
"584672W", "584673W", "584674W", "584675W", "584676W", "584678W",
"584681W", "584682W", "584683W", "584684W", "584685W", "584687W",
"584688W", "584689W", "584691W", "584692W", "584693W", "584694W",
"584695W", "584696W", "584697W", "584699W", "584700W", "584702W",
"584703W", "584705W", "584706W", "584707W", "584708W", "584709W",
"584710W", "584711W", "584713W", "584714W", "584715W", "584716W",
"584717W", "584718W", "584720W", "584721W", "584722W", "584723W",
"584726W", "584727W", "584728W", "584729W", "584730W", "584731W",
"584732W", "584733W", "584734W", "584736W", "584737W", "584740W",
"584741W", "584742W", "584743W", "584744W", "584745W", "584746W",
"584747W", "584749W", "584751W", "584752W", "584753W", "584754W",
"584755W", "584756W", "584757W", "584758W", "584759W", "584760W",
"584762W", "584763W", "584764W", "584765W", "584766W", "584767W",
"584768W", "584769W", "584772W", "584773W", "584775W", "584777W",
"584779W", "584780W", "584781W", "584783W", "584784W", "584785W",
"584786W", "584787W", "584788W", "584789W", "584790W", "584791W",
"584792W", "584793W", "584795W", "584797W", "584798W", "584800W",
"584802W", "584803W", "584804W", "584805W", "584806W", "584807W",
"584808W", "584809W", "584810W", "584811W", "584812W", "584813W",
"584814W", "584815W", "584816W", "584817W", "584818W", "584820W",
"584821W", "584822W", "584823W", "584825W", "584826W", "584827W",
"584828W", "584829W", "584830W", "584832W", "584833W", "584835W",
"584836W", "584838W", "584839W", "584840W", "584841W", "584842W",
"584843W", "584844W", "584845W", "584846W", "584847W", "584849W",
"584850W", "584851W", "584853W", "584854W", "584855W", "584856W",
"584857W", "584858W", "584859W", "584860W", "584861W", "584862W",
"584863W", "584864W", "584865W", "584867W", "584868W", "584869W",
"584871W", "584872W", "584873W", "584874W", "584875W", "584876W",
"584877W", "584878W", "584880W", "584881W", "584882W", "584883W",
"584885W", "584886W", "584887W", "584889W", "584891W", "584892W",
"584893W", "584894W", "584895W", "584896W", "584897W", "584898W",
"584900W", "584901W", "584903W", "584904W", "584906W", "584907W",
"584909W", "584911W", "584913W", "584914W", "584915W", "584916W",
"584918W", "584919W", "584920W", "584921W", "584922W", "584923W",
"584924W", "584926W", "584928W", "584929W", "584930W", "584931W",
"584932W", "584933W", "584934W", "584936W", "584937W", "584938W",
"584939W", "584941W", "584943W", "584944W", "584946W", "584947W",
"584948W", "584949W", "584950W", "584951W", "584952W", "584953W",
"584954W", "584955W", "584957W", "584958W", "584960W", "584961W",
"584963W", "584964W", "584965W", "584967W", "584968W", "584970W",
"584971W", "584972W", "584973W", "584976W", "584977W", "584978W",
"584979W", "584980W", "584981W", "584982W", "584983W", "584984W",
"584985W", "584986W", "584987W", "584988W", "584989W", "584990W",
"584991W", "584993W", "584994W", "584995W", "584996W", "584997W",
"584999W", "585000W", "585001W", "585002W", "585003W", "585005W",
"585006W", "585007W", "585008W", "585011W", "585012W", "585014W",
"585015W", "585016W", "585017W", "585019W", "585020W", "585021W",
"585022W", "585023W", "585024W", "585025W", "585026W", "585027W",
"585028W", "585029W", "585031W", "585033W", "585035W", "585036W",
"585037W", "585038W", "585039W", "585040W", "585041W", "585043W",
"585044W", "585045W", "585046W", "585047W", "585049W", "585050W",
"585051W", "585052W", "585055W", "585056W", "585057W", "585058W",
"585059W", "585060W", "585061W", "585062W", "585063W", "585064W",
"585065W", "585067W", "585068W", "585069W", "585070W", "585072W",
"585073W", "585074W", "585075W", "585076W", "585077W", "585078W",
"585079W", "585080W", "585082W", "585083W", "585085W", "585086W",
"585087W", "585088W", "585089W", "585090W", "585092W", "585093W",
"585094W", "585096W", "585097W", "585098W", "585099W", "585100W",
"585101W", "585102W", "585104W", "585106W", "585107W", "585108W",
"585109W", "585111W", "585113W", "585114W", "585116W", "585117W",
"585118W", "585119W", "585120W", "585121W", "585122W", "585123W",
"585125W", "585126W", "585127W", "585128W", "585129W", "585131W",
"585132W", "585133W", "585134W", "585135W", "585136W", "585137W",
"585139W", "585140W", "585141W", "585142W", "585143W", "585145W",
"585146W", "585148W", "585149W", "585150W", "585151W", "585152W",
"585153W", "585154W", "585155W", "585156W", "585158W", "585160W",
"585161W", "585162W", "585163W", "585165W", "585166W", "585168W",
"585169W", "585170W", "585171W", "585172W", "585173W", "585174W",
"585175W", "585177W", "585178W", "585179W", "585180W", "585181W",
"585182W", "585184W", "585185W", "585186W", "585187W", "585189W",
"585190W", "585192W", "585193W", "585194W", "585195W", "585197W",
"585198W", "585199W", "585200W", "585201W", "585202W", "585203W",
"585204W", "585206W", "585207W", "585208W", "585210W", "585211W",
"585212W", "585213W", "585214W", "585215W", "585216W", "585217W",
"585218W", "585219W", "585220W", "585221W", "585222W", "585224W",
"585226W", "585227W", "585228W", "585229W", "585231W", "585234W",
"585235W", "585236W", "585237W", "585238W", "585239W", "585241W",
"585242W", "585243W", "585244W", "585245W", "585247W", "585248W",
"585249W", "585250W", "585251W", "585252W", "585253W", "585255W",
"585257W", "585258W", "585259W", "585260W", "585261W", "585262W",
"585263W", "585265W", "585266W", "585267W", "585269W", "585270W",
"585271W", "585272W", "585273W", "585274W", "585275W", "585276W",
"585278W", "585279W", "585280W", "585281W", "585282W", "585283W",
"585284W", "585285W", "585287W", "585289W", "585291W", "585292W",
"585293W", "585294W", "585295W", "585299W", "585300W", "585301W",
"585302W", "585303W", "585305W", "585306W", "585307W", "585308W",
"585310W", "585311W", "585313W", "585314W", "585315W", "585316W",
"585317W", "585318W", "585320W", "585321W", "585322W", "585323W",
"585324W", "585326W", "585327W", "585328W", "585329W", "585330W",
"585331W", "585332W", "585333W", "585334W", "585336W", "585337W",
"585339W", "585340W", "585341W", "585342W", "585343W", "585344W",
"585345W", "585346W", "585347W", "585349W", "585350W", "585351W",
"585352W", "585354W", "585355W", "585356W", "585357W", "585358W",
"585359W", "585360W", "585363W", "585364W", "585365W", "585366W",
"585367W", "585368W", "585371W", "585372W", "585373W", "585375W",
"585377W", "585378W", "585379W", "585380W", "585381W", "585383W",
"585384W", "585385W", "585387W", "585388W", "585389W", "585390W",
"585391W", "585392W", "585395W", "585397W", "585398W", "585399W",
"585400W", "585402W", "585403W", "585404W", "585405W", "585406W",
"585407W", "585408W", "585409W", "585410W", "585411W", "585412W",
"585413W", "585414W", "585415W", "585416W", "585418W", "585420W",
"585421W", "585423W", "585425W", "585426W", "585427W", "585428W",
"585429W", "585430W", "585432W", "585435W", "585436W", "585438W",
"585439W", "585440W", "585441W", "585442W", "585443W", "585444W",
"585445W", "585446W", "585447W", "585450W", "585451W", "585453W",
"585454W", "585455W", "585456W", "585457W", "585458W", "585459W",
"585460W", "585461W", "585462W", "585463W", "585465W", "585467W",
"585468W", "585469W", "585471W", "585472W", "585473W", "585474W",
"585475W", "585476W", "585477W", "585478W", "585480W", "585481W",
"585482W", "585483W", "585485W", "585486W", "585487W", "585490W",
"585491W", "585492W", "585493W", "585494W", "585495W", "585496W",
"585497W", "585498W", "585500W", "585501W", "585503W", "585504W",
"585505W", "585506W", "585507W", "585508W", "585509W", "585511W",
"585512W", "585513W", "585514W", "585515W", "585516W", "585519W",
"585520W", "585521W", "585522W", "585523W", "585524W", "585526W",
"585528W", "585529W", "585530W", "585531W", "585532W", "585533W",
"585534W", "585536W", "585537W", "585538W", "585539W", "585540W",
"585541W", "585543W", "585546W", "585547W", "585548W", "585549W",
"585550W", "585551W", "585552W", "585553W", "585554W", "585557W",
"585558W", "585560W", "585561W", "585563W", "585564W", "585565W",
"585566W", "585567W", "585568W", "585570W", "585571W", "585572W",
"585573W", "585575W", "585576W", "585577W", "585578W", "585579W",
"585580W", "585581W", "585582W", "585583W", "585584W", "585585W",
"585586W", "585587W", "585588W", "585589W", "585590W", "585591W",
"585593W", "585594W", "585595W", "585596W", "585597W", "585599W",
"585600W", "585601W", "585602W", "585603W", "585605W", "585606W",
"585607W", "585608W", "585609W", "585611W", "585612W", "585614W",
"585615W", "585616W", "585617W", "585619W", "585620W", "585621W",
"585622W", "585623W", "585624W", "585625W", "585626W", "585627W",
"585628W", "585631W", "585633W", "585635W", "585636W", "585637W",
"585638W", "585639W", "585640W", "585641W", "585642W", "585643W",
"585644W", "585645W", "585646W", "585647W", "585649W", "585650W",
"585651W", "585652W", "585654W", "585656W", "585657W", "585658W",
"585659W", "585660W", "585661W", "585662W", "585663W", "585664W",
"585665W", "585667W", "585668W", "585669W", "585670W", "585671W",
"585672W", "585674W", "585675W", "585676W", "585677W", "585678W",
"585679W", "585680W", "585682W", "585683W", "585685W", "585686W",
"585687W", "585688W", "585689W", "585690W", "585692W", "585693W",
"585694W", "585696W", "585697W", "585698W", "585699W", "585700W",
"585701W", "585702W", "585704W", "585706W", "585707W", "585708W",
"585709W", "585710W", "585711W", "585713W", "585714W", "585716W",
"585717W", "585718W", "585719W", "585720W", "585721W", "585722W",
"585723W", "585725W", "585726W", "585727W", "585728W", "585729W",
"585730W", "585731W", "585732W", "585733W", "585734W", "585735W",
"585736W", "585737W", "585739W", "585740W", "585741W", "585742W",
"585743W", "585745W", "585746W", "585747W", "585748W", "585749W",
"585750W", "585751W", "585752W", "585753W", "585754W", "585755W",
"585756W", "585758W", "585760W", "585761W", "585762W", "585763W",
"585765W", "585766W", "585768W", "585769W", "585770W", "585771W",
"585772W", "585773W", "585774W", "585775W", "585777W", "585778W",
"585779W", "585780W", "585781W", "585782W", "585784W", "585785W",
"585786W", "585787W", "585788W", "585789W", "585790W", "585791W",
"585792W", "585793W", "585794W", "585795W", "585797W", "585798W",
"585799W", "585801W", "585802W", "585803W", "585804W", "585806W",
"585807W", "585808W", "585810W", "585811W", "585812W", "585813W",
"585814W", "585815W", "585816W", "585817W", "585818W", "585819W",
"585820W", "585821W", "585822W", "585824W", "585825W", "585826W",
"585827W", "585828W", "585829W", "585831W", "585832W", "585834W",
"585835W", "585836W", "585837W", "585838W", "585839W", "585841W",
"585842W", "585843W", "585844W", "585845W", "585847W", "585848W",
"585849W", "585850W", "585851W", "585852W", "585853W", "585855W",
"585856W", "585857W", "585858W", "585859W", "585860W", "585861W",
"585862W", "585863W", "585865W", "585866W", "585867W", "585869W",
"585870W", "585871W", "585872W", "585873W", "585874W", "585875W",
"585876W", "585878W", "585879W", "585880W", "585881W", "585882W",
"585883W", "585884W", "585885W", "585887W", "585888W", "585889W",
"585891W", "585892W", "585893W", "585894W", "585896W", "585897W",
"585899W", "585900W", "585901W", "585902W", "585903W", "585905W",
"585906W", "585907W", "585908W", "585909W", "585910W", "585913W",
"585914W", "585915W", "585916W", "585917W", "585918W", "585920W",
"585921W", "585922W", "585923W", "585924W", "585926W", "585927W",
"585928W", "585929W", "585930W", "585931W", "585932W", "585933W",
"585934W", "585936W", "585937W", "585939W", "585940W", "585941W",
"585942W", "585943W", "585944W", "585945W", "585946W", "585947W",
"585949W", "585950W", "585951W", "585952W", "585953W", "585954W",
"585955W", "585956W", "585957W", "585958W", "585959W", "585960W",
"585963W", "585964W", "585965W", "585966W", "585967W", "585968W",
"585969W", "585971W", "585972W", "585973W", "585975W", "585977W",
"585978W", "585979W", "585980W", "585983W", "585984W", "585985W",
"585986W", "585987W", "585989W", "585990W", "585991W", "585992W",
"585993W", "585995W", "585997W", "585998W", "585999W", "586000W",
"586002W", "586003W", "586004W", "586005W", "586006W", "586007W",
"586008W", "586009W", "586010W", "586011W", "586012W", "586013W",
"586014W", "586015W", "586016W", "586017W", "586018W", "586020W",
"586021W", "586022W", "586023W", "586025W", "586026W", "586027W",
"586028W", "586029W", "586030W", "586032W", "586033W", "586035W",
"586036W", "586038W", "586039W", "586040W", "586041W", "586042W",
"586043W", "586044W", "586045W", "586046W", "586047W", "586049W",
"586051W", "586053W", "586054W", "586055W", "586057W", "586058W",
"586059W", "586060W", "586061W", "586062W", "586063W", "586064W",
"586065W", "586067W", "586068W", "586069W", "586071W", "586072W",
"586073W", "586074W", "586075W", "586076W", "586077W", "586078W",
"586080W", "586081W", "586082W", "586083W", "586085W", "586086W",
"586087W", "586089W", "586090W", "586091W", "586092W", "586093W",
"586094W", "586095W", "586096W", "586097W", "586098W", "586100W",
"586101W", "586102W", "586104W", "586105W", "586106W", "586107W",
"586108W", "586109W", "586111W", "586112W", "586113W", "586114W",
"586115W", "586116W", "586118W", "586119W", "586121W", "586122W",
"586123W", "586124W", "586126W", "586128W", "586129W", "586130W",
"586131W", "586132W", "586134W", "586136W", "586137W", "586138W",
"586139W", "586140W", "586141W", "586143W", "586144W", "586146W",
"586147W", "586148W", "586149W", "586150W", "586151W", "586152W",
"586153W", "586154W", "586155W", "586157W", "586158W", "586160W",
"586161W", "586163W", "586164W", "586165W", "586166W", "586167W",
"586170W", "586171W", "586172W", "586173W", "586175W", "586176W",
"586177W", "586178W", "586179W", "586180W", "586181W", "586184W",
"586185W", "586186W", "586187W", "586188W", "586189W", "586190W",
"586191W", "586193W", "586194W", "586195W", "586196W", "586197W",
"586199W", "586200W", "586201W", "586202W", "586203W", "586205W",
"586206W", "586207W", "586208W", "586209W", "586211W", "586212W",
"586214W", "586215W", "586216W", "586217W", "586219W", "586220W",
"586221W", "586222W", "586223W", "586224W", "586225W", "586226W",
"586227W", "586228W", "586229W", "586231W", "586233W", "586235W",
"586236W", "586237W", "586238W", "586239W", "586240W", "586241W",
"586242W", "586243W", "586244W", "586245W", "586246W", "586247W",
"586249W", "586250W", "586251W", "586252W", "586254W", "586255W",
"586256W", "586257W", "586258W", "586259W", "586260W", "586261W",
"586262W", "586263W", "586264W", "586265W", "586267W", "586268W",
"586269W", "586270W", "586272W", "586273W", "586274W", "586275W",
"586276W", "586277W", "586278W", "586279W", "586280W", "586282W",
"586283W", "586285W", "586286W", "586287W", "586288W", "586289W",
"586290W", "586292W", "586293W", "586294W", "586296W", "586297W",
"586298W", "586299W", "586300W", "586301W", "586302W", "586304W",
"586306W", "586307W", "586308W", "586309W", "586310W", "586311W",
"586313W", "586314W", "586316W", "586317W", "586318W", "586319W",
"586320W", "586321W", "586322W", "586323W", "586325W", "586326W",
"586327W", "586328W", "586329W", "586330W", "586331W", "586332W",
"586333W", "586334W", "586335W", "586336W", "586339W", "586340W",
"586341W", "586342W", "586343W", "586345W", "586346W", "586347W",
"586348W", "586350W", "586351W", "586352W", "586353W", "586355W",
"586356W", "586358W", "586360W", "586361W", "586362W", "586363W",
"586365W", "586366W", "586368W", "586369W", "586370W", "586371W",
"586372W", "586373W", "586374W", "586375W", "586377W", "586378W",
"586379W", "586380W", "586381W", "586382W", "586384W", "586385W",
"586386W", "586387W", "586388W", "586389W", "586390W", "586391W",
"586392W", "586393W", "586394W", "586395W", "586397W", "586398W",
"586399W", "586400W", "586401W", "586402W", "586403W", "586404W",
"586406W", "586407W", "586408W", "586410W", "586412W", "586413W",
"586414W", "586415W", "586416W", "586417W", "586418W", "586419W",
"586420W", "586421W", "586422W", "586424W", "586425W", "586426W",
"586427W", "586428W", "586429W", "586431W", "586432W", "586434W",
"586435W", "586436W", "586437W", "586438W", "586439W", "586441W",
"586443W", "586444W", "586445W", "586447W", "586448W", "586449W",
"586450W", "586451W", "586452W", "586453W", "586455W", "586456W",
"586457W", "586458W", "586459W", "586460W", "586461W", "586462W",
"586463W", "586465W", "586466W", "586467W", "586469W", "586470W",
"586471W", "586472W", "586473W", "586475W", "586476W", "586478W",
"586479W", "586480W", "586481W", "586482W", "586483W", "586484W",
"586485W", "586487W", "586488W", "586489W", "586491W", "586492W",
"586493W", "586494W", "586495W", "586496W", "586497W", "586499W",
"586500W", "586501W", "586502W", "586503W", "586505W", "586506W",
"586507W", "586508W", "586509W", "586510W", "586511W", "586513W",
"586514W", "586515W", "586516W", "586517W", "586518W", "586520W",
"586521W", "586522W", "586523W", "586524W", "586526W", "586527W",
"586528W", "586529W", "586530W", "586531W", "586532W", "586533W",
"586534W", "586536W", "586537W", "586539W", "586540W", "586541W",
"586542W", "586543W", "586544W", "586545W", "586546W", "586547W",
"586549W", "586550W", "586552W", "586553W", "586554W", "586555W",
"586556W", "586557W", "586558W", "586559W", "586560W", "586562W",
"586563W", "586564W", "586565W", "586566W", "586567W", "586568W",
"586569W", "586571W", "586572W", "586573W", "586575W", "586577W",
"586578W", "586579W", "586580W", "586581W", "586583W", "586584W",
"586585W", "586586W", "586587W", "586588W", "586589W", "586590W",
"586591W", "586592W", "586593W", "586595W", "586597W", "586598W",
"586599W", "586600W", "586602W", "586603W", "586604W", "586605W",
"586606W", "586607W", "586608W", "586609W", "586610W", "586611W",
"586612W", "586613W", "586614W", "586615W", "586616W", "586617W",
"586618W", "586620W", "586621W", "586622W", "586623W", "586625W",
"586626W", "586627W", "586628W", "586629W", "586630W", "586632W",
"586633W", "586635W", "586636W", "586638W", "586639W", "586640W",
"586641W", "586642W", "586643W", "586644W", "586645W", "586646W",
"586647W", "586649W", "586650W", "586651W", "586653W", "586654W",
"586655W", "586656W", "586657W", "586658W", "586659W", "586660W",
"586661W", "586662W", "586663W", "586664W", "586665W", "586667W",
"586668W", "586669W", "586671W", "586672W", "586673W", "586674W",
"586675W", "586676W", "586677W", "586678W", "586680W", "586682W",
"586683W", "586685W", "586686W", "586687W", "586689W", "586690W",
"586691W", "586692W", "586693W", "586694W", "586695W", "586696W",
"586697W", "586698W", "586701W", "586702W", "586703W", "586704W",
"586705W", "586706W", "586707W", "586708W", "586709W", "586711W",
"586712W", "586713W", "586714W", "586715W", "586716W", "586718W",
"586719W", "586720W", "586721W", "586723W", "586724W", "586726W",
"586728W", "586729W", "586730W", "586731W", "586732W", "586733W",
"586734W", "586736W", "586737W", "586738W", "586739W", "586740W",
"586741W", "586743W", "586744W", "586746W", "586747W", "586748W",
"586749W", "586750W", "586751W", "586752W", "586753W", "586754W",
"586755W", "586757W", "586758W", "586760W", "586761W", "586763W",
"586764W", "586765W", "586766W", "586767W", "586768W", "586770W",
"586771W", "586772W", "586773W", "586775W", "586776W", "586777W",
"586778W", "586779W", "586780W", "586781W", "586782W", "586783W",
"586784W", "586785W", "586786W", "586787W", "586788W", "586789W",
"586790W", "586791W", "586793W", "586795W", "586796W", "586797W",
"586799W", "586800W", "586801W", "586802W", "586803W", "586805W",
"586806W", "586807W", "586808W", "586809W", "586811W", "586812W",
"586814W", "586815W", "586816W", "586817W", "586819W", "586821W",
"586822W", "586823W", "586824W", "586825W", "586826W", "586827W",
"586828W", "586829W", "586831W", "586833W", "586835W", "586836W",
"586837W", "586838W", "586839W", "586840W", "586841W", "586842W",
"586843W", "586844W", "586845W", "586846W", "586847W", "586849W",
"586850W", "586851W", "586852W", "586855W", "586856W", "586857W",
"586858W", "586859W", "586860W", "586861W", "586862W", "586863W",
"586864W", "586865W", "586867W", "586868W", "586869W", "586870W",
"586871W", "586872W", "586873W", "586874W", "586875W", "586876W",
"586877W", "586878W", "586879W", "586880W", "586882W", "586883W",
"586885W", "586886W", "586887W", "586888W", "586889W", "586890W",
"586893W", "586894W", "586896W", "586897W", "586898W", "586899W",
"586900W", "586901W", "586902W", "586904W", "586906W", "586907W",
"586908W", "586909W", "586910W", "586911W", "586913W", "586914W",
"586916W", "586917W", "586918W", "586919W", "586920W", "586921W",
"586922W", "586923W", "586925W", "586926W", "586927W", "586928W",
"586929W", "586930W", "586931W", "586932W", "586933W", "586934W",
"586935W", "586937W", "586939W", "586940W", "586941W", "586942W",
"586943W", "586945W", "586946W", "586947W", "586949W", "586950W",
"586951W", "586952W", "586953W", "586954W", "586955W", "586956W",
"586958W", "586960W", "586961W", "586962W", "586963W", "586965W",
"586966W", "586968W", "586969W", "586970W", "586971W", "586972W",
"586973W", "586974W", "586975W", "586977W", "586978W", "586979W",
"586980W", "586981W", "586982W", "586984W", "586985W", "586986W",
"586987W", "586988W", "586989W", "586990W", "586991W", "586992W",
"586993W", "586994W", "586995W", "586997W", "586998W", "586999W",
"587000W", "587001W", "587002W", "587004W", "587006W", "587007W",
"587008W", "587010W", "587011W", "587012W", "587013W", "587014W",
"587015W", "587016W", "587017W", "587018W", "587019W", "587020W",
"587021W", "587022W", "587024W", "587025W", "587026W", "587027W",
"587028W", "587029W", "587031W", "587032W", "587034W", "587035W",
"587036W", "587037W", "587038W", "587039W", "587041W", "587042W",
"587043W", "587044W", "587045W", "587047W", "587048W", "587049W",
"587050W", "587051W", "587052W", "587053W", "587055W", "587056W",
"587057W", "587058W", "587059W", "587060W", "587061W", "587062W",
"587063W", "587065W", "587067W", "587069W", "587070W", "587071W",
"587072W", "587073W", "587074W", "587075W", "587076W", "587078W",
"587079W", "587080W", "587081W", "587082W", "587083W", "587085W",
"587087W", "587088W", "587089W", "587091W", "587092W", "587093W",
"587094W", "587095W", "587096W", "587097W", "587099W", "587100W",
"587101W", "587102W", "587103W", "587105W", "587106W", "587107W",
"587108W", "587109W", "587110W", "587111W", "587113W", "587114W",
"587115W", "587116W", "587117W", "587118W", "587120W", "587121W",
"587122W", "587123W", "587124W", "587126W", "587127W", "587128W",
"587129W", "587130W", "587131W", "587132W", "587133W", "587134W",
"587136W", "587137W", "587139W", "587140W", "587141W", "587142W",
"587143W", "587144W", "587145W", "587146W", "587147W", "587149W",
"587150W", "587151W", "587152W", "587153W", "587154W", "587155W",
"587156W", "587157W", "587158W", "587159W", "587160W", "587162W",
"587163W", "587164W", "587165W", "587167W", "587168W", "587169W",
"587172W", "587173W", "587175W", "587177W", "587178W", "587179W",
"587180W", "587181W", "587183W", "587184W", "587185W", "587186W",
"587187W", "587188W", "587189W", "587190W", "587191W", "587192W",
"587193W", "587195W", "587197W", "587198W", "587199W", "587200W",
"587202W", "587203W", "587204W", "587205W", "587206W", "587207W",
"587208W", "587209W", "587210W", "587211W", "587212W", "587213W",
"587214W", "587215W", "587216W", "587217W", "587218W", "587220W",
"587221W", "587222W", "587223W", "587225W", "587226W", "587227W",
"587228W", "587229W", "587230W", "587232W", "587233W", "587235W",
"587236W", "587238W", "587239W", "587240W", "587241W", "587242W",
"587243W", "587244W", "587245W", "587246W", "587247W", "587249W",
"587250W", "587251W", "587253W", "587254W", "587255W", "587256W",
"587257W", "587258W", "587259W", "587260W", "587261W", "587262W",
"587263W", "587264W", "587265W", "587267W", "587268W", "587269W",
"587271W", "587272W", "587273W", "587274W", "587275W", "587276W",
"587278W", "587280W", "587281W", "587282W", "587283W", "587285W",
"587286W", "587287W", "587289W", "587290W", "587291W", "587292W",
"587293W", "587294W", "587295W", "587296W", "587297W", "587298W",
"587300W", "587301W", "587302W", "587303W", "587304W", "587305W",
"587306W", "587307W", "587309W", "587311W", "587312W", "587313W",
"587315W", "587316W", "587318W", "587319W", "587320W", "587321W",
"587322W", "587323W", "587324W", "587326W", "587328W", "587329W",
"587330W", "587331W", "587332W", "587333W", "587336W", "587337W",
"587338W", "587339W", "587340W", "587341W", "587343W", "587344W",
"587346W", "587347W", "587348W", "587349W", "587350W", "587351W",
"587352W", "587353W", "587354W", "587355W", "587358W", "587360W",
"587361W", "587363W", "587364W", "587365W", "587367W", "587368W",
"587370W", "587371W", "587372W", "587373W", "587375W", "587376W",
"587377W", "587378W", "587379W", "587380W", "587381W", "587382W",
"587383W", "587384W", "587385W", "587387W", "587388W", "587389W",
"587390W", "587391W", "587393W", "587394W", "587395W", "587396W",
"587397W", "587399W", "587400W", "587401W", "587402W", "587403W",
"587405W", "587406W", "587407W", "587408W", "587409W", "587411W",
"587412W", "587414W", "587415W", "587416W", "587417W", "587419W",
"587420W", "587421W", "587422W", "587423W", "587424W", "587425W",
"587426W", "587427W", "587428W", "587429W", "587431W", "587433W",
"587435W", "587436W", "587437W", "587438W", "587439W", "587440W",
"587441W", "587442W", "587443W", "587444W", "587445W", "587446W",
"587447W", "587449W", "587450W", "587451W", "587452W", "587454W",
"587455W", "587456W", "587457W", "587458W", "587459W", "587460W",
"587461W", "587462W", "587463W", "587464W", "587465W", "587467W",
"587469W", "587470W", "587471W", "587472W", "587473W", "587474W",
"587475W", "587476W", "587477W", "587478W", "587479W", "587480W",
"587482W", "587483W", "587485W", "587486W", "587487W", "587488W",
"587489W", "587490W", "587492W", "587493W", "587494W", "587496W",
"587497W", "587498W", "587499W", "587500W", "587501W", "587502W",
"587506W", "587507W", "587508W", "587509W", "587510W", "587511W",
"587513W", "587514W", "587516W", "587517W", "587518W", "587519W",
"587520W", "587521W", "587522W", "587523W", "587525W", "587526W",
"587527W", "587528W", "587529W", "587530W", "587531W", "587532W",
"587533W", "587534W", "587537W", "587539W", "587540W", "587541W",
"587542W", "587543W", "587545W", "587546W", "587547W", "587548W",
"587549W", "587550W", "587551W", "587552W", "587553W", "587554W",
"587555W", "587556W", "587558W", "587560W", "587561W", "587562W",
"587563W", "587565W", "587566W", "587568W", "587569W", "587571W",
"587572W", "587573W", "587574W", "587575W", "587577W", "587578W",
"587579W", "587580W", "587581W", "587582W", "587584W", "587585W",
"587586W", "587587W", "587588W", "587589W", "587590W", "587591W",
"587592W", "587593W", "587594W", "587595W", "587597W", "587598W",
"587599W", "587600W", "587601W", "587602W", "587603W", "587604W",
"587606W", "587607W", "587608W", "587610W", "587611W", "587612W",
"587613W", "587614W", "587616W", "587617W", "587618W", "587619W",
"587620W", "587621W", "587622W", "587624W", "587626W", "587627W",
"587628W", "587629W", "587631W", "587632W", "587634W", "587635W",
"587636W", "587637W", "587638W", "587639W", "587641W", "587642W",
"587643W", "587644W", "587645W", "587647W", "587648W", "587649W",
"587650W", "587651W", "587652W", "587653W"), Tm_ugL = c("0.012526909",
"0.00524721", "0.008974472", "0.014173771", "0.010261946", "0.006209327",
"0.006427348", "0.011277134", "0.007188303", "0.007920061", "0.006604756",
"0.002138549", "0.006412799", "0.003809274", "0.00258031", "0.005826568",
"0.012608666", "0.004640139", "0.005319402", "0.009120296", "0.010841532",
"0.005542043", "0.009347176", "0.014380953", "0.004871033", "0.004714329",
"0.009575732", "0.006141329", "0.008756292", "0.015346655", "0.007429521",
"0.006442689", "0.005501903", "0.008070111", "0.019068198", "0.006140656",
"0.004317718", "0.003718727", "0.004044718", "0.015449818", "0.0084332",
"0.009670819", "0.001669213", "0.004783213", "0.003404341", "0.007230384",
"0.017716786", "0.006114732", "0.003629682", "0.004236707", "0.006259052",
"0.013515521", "0.007139276", "0.004256668", "0.005247138", "0.004984855",
"0.003879668", "0.000693273", "0.004473905", "0.005770609", "0.008615954",
"0.019118999", "0.006625797", "0.006901367", "0.005772831", "0.004440397",
"0.003950989", "0.004408009", "0.016313629", "0.018295581", "0.004482088",
"0.010375151", "0.008956765", "0.005987772", "0.023409173", "0.006540896",
"0.010740111", "0.009647456", "0.003929988", "0.002879241", "0.006664738",
"0.010107742", "0.002855781", "0.002322324", "0.004469807", "0.003727292",
"0.006530213", "0.00791199", "0.008722764", "0.019761435", "0.0044777",
"0.004655689", "0.002153972", "0.003250451", "0.009378664", "0.005276846",
"0.008247634", "0.002433585", "0.004187209", "0.00472907", "0.005241927",
"0.007775586", "0.003037972", "0.005233932", "0.01878142", "0.00410588",
"0.005666064", "0.008062636", "0.0062489", "0.009019154", "0.003570997",
"0.006629886", "0.011058816", "0.001979885", "0.002941527", "0.006251154",
"0.003072933", "0.005736085", "0.008841193", "0.008763499", "0.007221573",
"0.003765729", "0.005356846", "0.007064965", "0.008571698", "0.00455893",
"0.0032616", "0.008713323", "0.004074075", "0.001143222", "0.005679248",
"0.006598114", "0.006193131", "0.005219984", "0.004462468", "0.00619499",
"0.004129983", "0.005652558", "0.010228619", "0.010320457", "0.010966911",
"0.023724903", "0.005534186", "0.003628177", "0.010590674", "0.005661125",
"0.005063904", "0.006160644", "0.003499903", "0.005946992", "0.003108242",
"0.003356377", "0.006943931", "0.009771657", "0.009397079", "0.010179125",
"0.005096196", "0.006411438", "0.007634242", "0.021263574", "0.00335257",
"0.01628002", "0.00419588", "0.015669182", "0.006572348", "0.003603196",
"0.002637675", "0.004219162", "0.004343853", "0.006888431", "0.005887176",
"0.003603652", "0.01252974", "0.005101809", "0.003068125", "0.004777023",
"0.00189274", "0.003484976", "0.006002034", "0.004855751", "0.002779958",
"0.006717209", "0.001116862", "0.006061243", "0.005632965", "0.004339326",
"0.002648977", "0.001703184", "0.005310346", "0.003453754", "0.000996672",
"0.002558453", "0.005375883", "0.001720969", "0.003281976", "0.016177406",
"0.006860274", "0.005246752", "0.001095977", "0.007969571", "0.001122845",
"0.004682038", "0.008402339", "0.001263145", "0.003866128", "0.004706423",
"0.011472932", "-0.000965223", "0.010522683", "0.001015816",
"0.008952635", "0.008219381", "0.005447368", "0.002862524", "0.002111277",
"0.011379373", "0.001080124", "0.000907393", "0.008243656", "0.002716425",
"0.00129586", "0.005988267", "0.003701525", "0.00154344", "0.003562045",
"0.004103097", "0.00433579", "0.006868613", "0.003504652", "0.001236814",
"0.00973152", "0.003779551", "0.004986519", "0.007649484", "0.006131166",
"0.00129334", "0.012185827", "0.000740339", "0.009693549", "0.004989262",
"0.00217159", "0.00289949", "0.005640732", "0.004469108", "0.008496723",
"0.002003616", "0.001896912", "0.001620197", "0.0030765", "0.001022135",
"0.010079904", "0.001482784", "0.009489339", "0.005772885", "0.003015524",
"0.00067034", "0.007470405", "0.002496535", "0.006344776", "0.001165944",
"0.014426281", "0.002713307", "0.001912026", "0.009576668", "0.000741203",
"0.006366114", "0.001834612", "0.006300803", "0.001823036", "0.003364833",
"0.006746047", "0.000802757", "0.007794059", "0.001700595", "0.001173412",
"0.002066642", "0.006745943", "0.006547318", "0.009330829", "0.005193235",
"0.011436552", "0.002624799", "0.002880703", "0.017986639", "0.006015463",
"0.000530537", "0.000602789", "0.006180396", "0.002388551", "0.014148288",
"0.004941805", "0.009949474", "0.001672992", "0.010996873", "0.007039351",
"0.001490136", "0.004037547", "0.001063398", "0.009188556", "0.016980239",
"0.005106021", "0.006178274", "0.003499607", "0.002544697", "0.001231949",
"0.004662272", "0.015886709", "0.003086586", "0.000539465", "0.003479056",
"0.000897406", "0.000962605", "0.002355382", "0.000274189", "0.001540451",
"0.001255926", "0.000957681", "0.002846524", "0.00410014", "0.000797589",
"0.007528205", "0.001371895", "0.000707452", "0.003948224", "0.001873692",
"0.000636153", "0.001995548", "0.003618461", "0.00214816", "0.003296673",
"0.001512562", "0.000311002", "0.014510014", "0.003221849", "0.003503587",
"0.003542875", "0.003124834", "0.007303395", "0.007802568", "0.002702066",
"0.00397283", "0.006015735", "0.005122858", "0.005532049", "0.005525161",
"0.00613509", "0.00300218", "0.004412227", "0.003275197", "0.004003631",
"0.002215088", "0.00584065", "0.012711175", "0.003779381", "0.000223868",
"0.001953771", "0.012140221", "0.009275696", "0.001745251", "0.003159705",
"0.006802756", "0.004796016", "0.011661546", "0.0092607", "0.012578599",
"0.005562171", "0.00442101", "0.001562554", "0.003561927", "0.003685651",
"0.002804282", "0.004492147", "0.004936921", "0.007674753", "0.00386058",
"0.003376528", "0.001389595", "0.003299246", "0.007032604", "0.004386589",
"0.006771362", "0.000572484", "0.006712266", "0.003898442", "0.001434171",
"0.003106834", "0.005676694", "0.004939338", "0.007666316", "0.004080318",
"0.005549484", "0.007699065", "0.000529283", "0.006992565", "0.005134453",
"0.003002421", "0.009261127", "0.004493311", "0.000338283", "0.01131107",
"0.010112226", "0.002444407", "0.004452528", "0.005453382", "0.008845841",
"0.001734873", "0.004470331", "0.002201705", "0.005389719", "0.004956882",
"0.005111852", "0.003572619", "0.003545642", "0.004354866", "0.002061634",
"0.00811309", "0.007083798", "0.002999954", "0.001832538", "0.011549497",
"0.005061518", "0.009316595", "0.003991814", "0.002861382", "0.004105657",
"0.002296664", "0.003456477", "0.002261021", "0.006203533", "0.002764773",
"0.002789349", "0.010631997", "0.004795557", "0.002844777", "0.005053105",
"0.004978561", "0.003668288", "0.002885261", "0.004414269", "0.004583083",
"0.011745086", "0.003786196", "0.001422543", "0.000870495", "0.002155369",
"0.00846052", "0.006300383", "0.003517681", "0.003573642", "0.003731246",
"0.005289539", "0.004252319", "0.004080951", "0.001319694", "0.004707826",
"0.004099493", "0.00312036", "0.003618851", "0.006710461", "0.001610671",
"0.002259963", "0.004042389", "0.00470838", "0.006533289", "0.006819086",
"0.008734313", "0.008993864", "0.004648321", "0.005123464", "0.010062559",
"0.005941191", "0.004586025", "0.006073371", "0.004040504", "0.00262404",
"0.008146802", "0.009219039", "0.008745142", "0.007765847", "0.00575151",
"0.004543592", "0.005352144", "0.003101024", "0.004176024", "0.017691276",
"0.017940826", "0.014692", "0.012972434", "0.023527925", "0.013830272",
"0.012585206", "0.005140034", "0.026267023", "0.007217881", "0.004373245",
"0.011934211", "0.004653821", "0.005563568", "0.007854147", "0.00704775",
"0.005819472", "0.015995857", "0.006181365", "0.010127657", "0.003627225",
"0.012709818", "0.012600082", "0.017842015", "0.004550865", "0.019301738",
"0.007032636", "0.010448506", "0.025213139", "0.005173896", "0.003648471",
"0.009376725", "0.009395694", "0.011678328", "0.017157179", "0.005700391",
"0.007887216", "0.005347332", "0.021134762", "0.016879745", "0.003602723",
"0.016026656", "0.017132957", "0.011385071", "0.012258313", "0.004590344",
"0.010689005", "0.011108691", "0.005776785", "0.003062257", "0.008456275",
"0.013875346", "0.009196571", "0.015734791", "0.012147619", "0.009056842",
"0.045055397", "0.007846725", "0.003301692", "0.005585407", "0.015991166",
"0.00607262", "0.013360632", "0.011078396", "0.007874128", "0.003263474",
"0.010696283", "0.026960067", "0.013937758", "0.012980693", "0.013274233",
"0.006026727", "0.005807527", "0.010149071", "0.011532218", "0.012843804",
"0.013545956", "0.002776432", "0.008611969", "0.003040787", "0.007443986",
"0.001312127", "0.0003025", "0.000431156", "0.000224012", "0.00494154",
"0.004298522", "0.006615671", "0.003321437", "0.007991056", "0.011949974",
"0.005836289", "0.004665441", "0.006252763", "0.00374617", "0.002683033",
"0.003340193", "0.001925158", "0.003125216", "0.001007901", "0.003903164",
"0.006226041", "0.001740977", "0.001317314", "0.005100105", "0.000593273",
"0.008145521", "0.004973538", "0.00068839", "0.000732802", "0.000428917",
"0.002766103", "0.012660523", "0.001645637", "0.00194228", "0.001688429",
"0.004141626", "0.0041443", "0.003029124", "0.007754908", "0.000996367",
"0.000991018", "0.005289496", "0.007330816", "0.002571047", "0.003490755",
"0.001076139", "0.00078712", "0.001583428", "0.004340905", "0.002949065",
"0.004470728", "0.008602732", "0.005311726", "0.002960331", "0.000941386",
"0.001882459", "0.000123824", "0.00178439", "0.000632667", "0.000429678",
"0.003095699", "0.000452975", "0.000302891", "0.005672175", "0.003646417",
"0.00024086", "0.004215561", "0.001111701", "0.003519762", "0.001551716",
"0.003735266", "0.003006485", "0.00930933", "0.001057213", "0.004632536",
"0.00294505", "0.006906513", "0.003412497", "0.002686386", "0.014712222",
"0.000761156", "0.00241515", "0.00239045", "0.00238927", "0.002321314",
"0.004854263", "0.002159585", "0.002665453", "0.004460844", "0.000830435",
"0.000765838", "0.000212462", "0.00443449", "0.00351636", "0.003494146",
"0.000119735", "0.001635048", "0.002138772", "0.003385075", "0.002765276",
"0.000731873", "0.003022143", "0.001147037", "0.002694729", "0.002468001",
"0.003206428", "0.00087695", "0.003926637", "0.001024658", "0.022591566",
"0.000981569", "0.00106184", "0.002951682", "0.002239524", "0.002198322",
"0.002392364", "0.000200837", "0.000838831", "0.001249875", "0.001854552",
"0.003678462", "0.00122349", "0.002285418", "0.003499271", "0.002212441",
"0.003302766", "0.000131422", "0.002778005", "0.000689239", "0.003401039",
"0.003897639", "0.005810614", "0.002817827", "0.001336956", "0.000915215",
"0.000138584", "0.002092924", "0.001420982", "0.003454715", "0.002319974",
"0.004241691", "0.000703056", "0.001907522", "0.002750834", "0.000927527",
"0.005493349", "0.00030797", "0.003348811", "0.004398022", "0.000226036",
"0.005377186", "0.001611902", "0.000349171", "0.000584377", "0.000710851",
"0.001203603", "0.003217803", "0.000685746", "0.001850594", "0.003607466",
"0.000585491", "0.000423931", "0.000610301", "0.002233248", "0.001244584",
"0.002675453", "0.000978359", "0.001184482", "0.004059149", "0.00126671",
"0.001738712", "0.000651386", "0.001975237", "0.001053062", "0.000890737",
"0.002071903", "0.001803908", "0.001163862", "0.000289041", "0.000776781",
"0.001570439", "0.000951105", "0.000881612", "0.002155598", "0.000451588",
"0.002378106", "0.000899796", "0.00108975", "0.000811137", "0.001071885",
"0.001795971", "0.001271003", "0.000957691", "0.000496391", "0.001607021",
"0.001612781", "0.000588984", "0.000473565", "0.001032657", "0.001606533",
"0.003887263", "0.00219703", "0.002224258", "0.000803389", "0.001158066",
"0.001260996", "0.000777962", "0.000519006", "0.002674644", "0.00089824",
"0.001968543", "0.000793111", "0.000838132", "0.000295642", "0.000898893",
"0.000618909", "0.00094089", "0.002481642", "0.002865756", "0.00212707",
"0.000814292", "0.000692303", "0.001217371", "0.001547876", "0.001889694",
"0.000423925", "0.001494921", "0.002256496", "0.008533809", "0.00103441",
"0.00146961", "0.000321683", "0.001205398", "0.001934957", "0.000693342",
"0.000723974", "0.000823272", "0.000431806", "0.00150659", "0.00485395",
"0.005568073", "0.00295471", "0.003604626", "0.003186087", "0.003888975",
"0.002884695", "0.005255963", "0.003253941", "0.002825274", "0.002356029",
"0.004924949", "0.003473988", "0.00199782", "0.00318568", "0.003746233",
"0.003637744", "0.003983428", "0.003235627", "0.002308502", "0.003991285",
"0.003343607", "0.002065512", "0.003601773", "0.004931388", "0.005011346",
"0.002393396", "0.003392815", "0.002426415", "0.003920471", "0.001757544",
"0.002607264", "0.002349977", "0.004420568", "0.004202681", "0.003482522",
"0.002276988", "0.00070119", "0.001897584", "0.001911513", "0.001838116",
"0.001968399", "0.002341677", "0.003403627", "0.002415555", "0.003050358",
"0.002038022", "0.003838283", "0.004053138", "0.003659568", "0.003976984",
"0.002691909", "0.003232401", "0.003172718", "0.002495762", "0.002885779",
"0.001910272", "0.003682516", "0.000608884", "0.003259595", "0.001808769",
"0.002652719", "0.003421534", "0.003388999", "0.003178429", "0.000131713",
"0.002772827", "0.002745533", "0.001687844", "0.003835246", "0.001178599",
"0.003790402", "0.00306021", "0.002547791", "0.003856114", "0.001600552",
"0.002385385", "0.001446147", "0.003100929", "0.001622527", "0.002198012",
"0.003880893", "0.001848878", "0.005152942", "0.005524076", "0.005839341",
"0.007647582", "0.003992075", "0.006334646", "0.002723267", "0.002856498",
"0.002546458", "0.002539948", "0.00298808", "0.002690881", "0.003025162",
"0.00411367", "0.002830494", "0.002061289", "0.003505905", "0.005743849",
"0.001363744", "0.004132753", "0.001205898", "0.002471435", "0.003904816",
"0.002813961", "0.001675182", "0.00112607", "0.01050083", "0.003607515",
"0.002251644", "0.003635582", "0.001814219", "0.000961893", "0.001156666",
"0.000993787", "0.001679378", "0.000292747", "0.001708425", "0.001397416",
"0.000672403", "0.00066883", "0.000388092", "0.002085225", "0.002628926",
"0.0007081", "0.001849466", "0.003126619", "0.001124511", "0.000291853",
"0.00098991", "0.000869237", "0.003016002", "0.000228249", "0.001054935",
"0.000565486", "0.000980794", "0.001281882", "0.001750751", "2.78E-05",
"0.001225465", "0.001729677", "0.001967867", "0.000946134", "0.001831121",
"0.001940498", "0.000491159", "0.002862978", "0.003546984", "0.000878387",
"0.002351657", "0.001844002", "0.002855443", "0.000886189", "0.000769673",
"0.004398294", "0.000985056", "0.003717415", "0.00211658", "0.001719138",
"0.005380235", "0.001645296", "0.0066795", "0.001849253", "0.002303189",
"0.003523623", "0.003384322", "0.007160586", "0.002131704", "0.000973316",
"0.003329035", "0.001888361", "0.003957041", "0.001013554", "0.001992457",
"0.00381132", "0.000900741", "0.003273894", "0.001541242", "0.00047345",
"0.002916697", "0.003641086", "0.000551149", "0.000988825", "0.002934236",
"0.002365281", "0.000582871", "0.0018318", "0.000929752", "0.001837291",
"0.000924292", "0.001031842", "0.000684132", "0.001709506", "0.000981114",
"0.003457973", "0.001817987", "0.002269985", "0.007918975", "0.006223432",
"0.00123671", "0.00391469", "0.002255457", "0.004180743", "0.00057043",
"0.001892729", "0.001912139", "0.00194498", "0.001104034", "0.002003286",
"0.00036947", "0.002635989", "0.001007859", "0.003439656", "0.000805272",
"0.005867473", "0.004465443", "0.001133879", "0.002842206", "0.003604218",
"0.001081663", "0.001023529", "0.000400453", "0.001224269", "0.00633427",
"0.001300423", "0.000522795", "0.002777271", "0.000465839", "0.004491359",
"0.000650466", "0.007881145", "0.002128289", "0.000696387", "0.000687194",
"0.008668156", "0.001173474", "0.000782956", "0.006217158", "0.001097588",
"0.003761749", "0.000896479", "0.000612694", "0.00455723", "0.001562075",
"0.001577265", "0.003530944", "0.000882146", "0.004741189", "0.000462436",
"0.002423694", "0.001426078", "0.001229695", "0.000151495", "0.00074423",
"0.00056349", "0.000834488", "0.001577975", "0.001176036", "0.000714083",
"0.002160032", "0.000567437", "0.0022188", "0.000685868", "0.000520177",
"0.002483573", "0.001544549", "0.002397179", "0.000455309", "0.000184648",
"0.000753078", "0.001213727", "0.000526527", "0.000502182", "0.001300605",
"0.000386059", "0.000624726", "0.000612817", "0.002137467", "0.000521678",
"0.000531583", "0.00061902", "0.000737619", "0.000529807", "0.000479971",
"0.000774262", "0.000298302", "0.001277028", "0.003589314", "0.001377721",
"0.001120529", "0.000974931", "0.001191647", "0.001625546", "0.000410325",
"0.003808545", "0.000541247", "0.000602081", "0.000931481", "0.00048247",
"0.001402605", "0.000463932", "0.001620905", "0.000940527", "0.005848518",
"0.000411341", "0.001161372", "0.00106367", "0.000371135", "0.00218473",
"0.000826734", "0.000781781", "0.000430428", "0.003926327", "0.004253917",
"0.004915174", "0.002098122", "0.001027593", "0.001891307", "0.001483668",
"0.001715159", "0.001065548", "0.001054245", "0.001791568", "0.00138467",
"0.000466776", "0.00054037", "0.000368882", "0.003345409", "0.000837835",
"0.000453112", "0.001788554", "0.000712708", "0.000490224", "0.001499223",
"0.001705885", "0.000365198", "0.001437334", "0.000480388", "0.000782941",
"0.001200423", "0.001420415", "0.000557051", "0.001934047", "0.002820197",
"0.000399331", "0.000712066", "0.000825201", "0.001077064", "0.004180338",
"0.003478947", "0.000847928", "0.001411386", "0.000464363", "0.000787172",
"0.000486185", "0.001211366", "0.003051988", "0.000202072", "0.00045573",
"0.001039212", "0.00056067", "0.000838216", "0.000611339", "0.001155582",
"0.003934398", "0.000446241", "0.000447143", "0.000585918", "0.000756123",
"0.000208236", "0.000746805", "0.000537549", "0.001443552", "0.00052824",
"0.002368153", "0.000509967", "0.007735125", "0.000985745", "0.000527702",
"0.000717133", "0.000577142", "0.006871698", "0.001248825", "0.001075524",
"0.001100964", "0.000529795", "0.000551858", "0.000745879", "0.000588481",
"0.002622651", "0.00091465", "0.004629061", "0.000597808", "0.000765995",
"0.001018027", "0.000596912", "0.001713204", "0.000438174", "0.000800995",
"0.000653485", "0.000958346", "0.001217594", "0.00076445", "0.001449324",
"0.000601024", "0.000552241", "0.000592449", "0.000772156", "0.001249651",
"0.001668726", "0.000701755", "0.000412507", "0.000727716", "0.000574364",
"0.001042749", "0.000654564", "0.007129834", "0.008426946", "0.005309422",
"0.005264616", "0.009384992", "0.005010607", "0.007570028", "0.009928717",
"0.004170362", "0.003675265", "0.004512786", "0.005685186", "0.008237337",
"0.004367586", "0.00546405", "0.003804582", "0.005236974", "0.003851435",
"0.003415034", "0.003219466", "0.002210227", "0.002468179", "0.006069194",
"0.002674289", "0.002849557", "0.002874692", "0.004102971", "0.003420821",
"0.002655607", "0.002715811", "0.001471085", "0.001153459", "0.001042614",
"0.005116195", "0.004592545", "0.001979374", "0.002412844", "0.001775336",
"0.002868092", "0.001479601", "0.002577762", "0.001726507", "0.008248861",
"0.001528246", "0.000541653", "0.001046778", "0.001539396", "0.001555099",
"0.000657847", "0.000701465", "0.000673238", "0.000406553", "0.001628931",
"0.001364921", "0.001974572", "0.001179476", "0.001127028", "0.000544126",
"0.003940931", "0.001809584", "0.001454501", "0.00055187", "0.002078805",
"0.003618322", "0.003185248", "0.002108602", "0.003186393", "0.001073216",
"0.00396052", "0.000564544", "0.000900958", "0.002872154", "0.000716866",
"0.004465343", "0.00292876", "0.000865699", "0.000304731", "0.004025274",
"0.000461351", "0.000450024", "0.000637492", "0.000844207", "0.000716671",
"0.00051467", "0.002330396", "0.00321308", "0.000996569", "0.002008234",
"0.003364558", "0.00295349", "0.002459354", "0.001837184", "0.002061878",
"0.005708132", "0.001568306", "0.002370841", "0.002080082", "0.001691857",
"0.003587493", "0.003525431", "0.003626336", "0.003275526", "0.001566228",
"0.002677126", "0.001918935", "0.001267504", "0.006069495", "0.003330838",
"0.001634574", "0.001656518", "0.001062276", "0.00193658", "0.006595035",
"0.003701294", "0.002165792", "0.002795057", "0.001995466", "0.001001598",
"0.004566041", "0.00313271", "0.003507699", "0.000874182", "0.001736094",
"0.004154664", "0.000801187", "0.000273351", "0.001434848", "0.000208856",
"0.001787169", "0.000660318", "0.000536208", "0.000827012", "0.003525523",
"0.00568365", "0.003374476", "0.000629977", "-0.000122666", "0.005430694",
"0.002046878", "2.87E-05", "0.001524734", "0.000723769", "0.003064301",
"0.001821976", "0.001019279", "0.007122004", "0.00251728", "0.004342001",
"0.002250916", "0.00249346", "0.000239402", "0.000206815", "0.000721918",
"0.00123834", "0.001185488", "0.000602984", "0.002770875", "0.000431782",
"0.002377602", "0.001150575", "0.00030252", "0.00239937", "0.001526856",
"-5.32E-05", "0.011119607", "0.006887013", "0.005297693", "0.007102272",
"0.004629353", "0.006308193", "0.009097256", "0.003582059", "0.003171425",
"0.004769043", "0.00436875", "0.004126409", "0.003745626", "0.006291541",
"0.004661988", "0.002503414", "0.003738629", "0.002155848", "0.005247106",
"0.004225906", "0.004314957", "0.002606456", "0.003302233", "0.003429194",
"0.004433893", "0.004032763", "0.001081671", "0.005185865", "0.003343411",
"0.001731607", "0.002069157", "0.003150157", "0.003945407", "0.01995829",
"0.002212524", "0.003122456", "0.001172068", "0.003164391", "0.002629812",
"0.001981082", "0.003262964", "0.002421709", "0.002662325", "0.0013619",
"0.002562372", "0.004551291", "0.00188528", "0.001213029", "0.002043811",
"0.0008071", "0.002179448", "0.001822949", "0.002814085", "0.001257899",
"0.001727223", "0.002886211", "0.00489911", "0.001579536", "0.001492332",
"0.002597319", "0.002747154", "0.001371866", "0.003588882", "0.00123881",
"0.001751715", "0.001258067", "0.003636411", "0.001684895", "0.002349261",
"0.000735361", "0.002742615", "0.001891355", "0.00265467", "0.003050261",
"0.001720556", "0.002217222", "0.001980177", "0.001664318", "0.001268427",
"0.00140942", "0.002315045", "0.001975644", "0.001318715", "0.001555535",
"0.001038484", "0.000347719", "0.001127557", "0.001057505", "0.001268971",
"0.001179467", "0.000641593", "0.002236545", "0.001624429", "0.000173284",
"0.000536243", "0.000243979", "0.000909077", "0.000309063", "0.001019427",
"0.002047875", "0.000790357", "0.000229934", "0.002791066", "0.00166546",
"0.000248693", "0.001842087", "0.002583505", "0.001026626", "0.001041061",
"0.002264823", "0.001665034", "0.000155991", "0.00259237", "0.001646788",
"0.000477204", "0.000501514", "0.000163174", "0.002588385", "0.000796153",
"0.002689299", "0.000684056", "-0.000313278", "0.002198574",
"0.001088117", "0.000528814", "0.000263083", "0.000776179", "0.000794529",
"0.000142439", "-0.000647425", "0.00193036", "0.000108009", "0.00077782",
"-0.000481816", "0.000635381", "-0.000449205", "0.000782408",
"0.004548418", "0.003280907", "0.003329733", "0.002035799", "0.005579869",
"0.002560187", "0.002545633", "0.005059885", "0.007037327", "0.009001771",
"0.003558769", "0.0035235", "0.002295552", "0.001286924", "0.00167687",
"0.002037401", "0.001995618", "0.001726902", "0.002502914", "0.001398049",
"0.002399104", "0.003860254", "0.004806359", "0.004938743", "0.003083788",
"0.001515187", "0.001466474", "0.001676741", "0.000334469", "0.002167219",
"0.001649118", "0.007160555", "0.002967383", "0.001113913", "0.00174345",
"0.001535035", "0.004020107", "0.001171428", "0.004565952", "0.001237616",
"0.00505863", "0.001154021", "0.000653467", "0.005069884", "0.002324774",
"0.004645691", "0.002761466", "0.001699281", "0.00089456", "0.003129216",
"8.49E-05", "0.002514879", "0.004329247", "0.00221013", "0.002568565",
"0.000971213", "0.000821615", "0.001461689", "0.002523476", "0.001508604",
"0.003036535", "0.002665244", "0.001453472", "0.001451201", "0.000477768",
"0.002484081", "0.001474277", "0.003349971", "0.00103818", "0.002414691",
"0.001450037", "0.000751229", "0.004421348", "0.001129423", "0.003419222",
"0.000995329", "0.002445221", "0.000617759", "0.002848817", "0.002645904",
"0.001645723", "0.0003746", "0.000940474", "0.003725902", "0.000392291",
"0.001147437", "0.001145907", "0.000561023", "0.001381841", "0.001110684",
"0.000544623", "0.00054095", "0.000448923", "0.000590861", "0.002452948",
"0.000552008", "0.000610962", "0.001299856", "0.001317185", "0.002698184",
"0.003493815", "0.003244857", "0.00061984", "0.000801545", "0.00149525",
"0.000409405", "0.003370267", "0.002207745", "0.0011107", "0.002229292",
"0.000488196", "0.00174331", "0.006678113", "0.002816683", "0.000839952",
"0.003398768", "0.003672784", "0.003091944", "0.006648423", "0.004623602",
"0.003195142", "0.0008055", "0.00052442", "0.00279123", "0.001106953",
"0.001105858", "0.004357319", "0.006961374", "0.000439899", "0.00332042",
"0.000410736", "0.000828855", "0.002473165", "0.001286492", "0.001670331",
"0.003446209", "0.004968425", "0.001344075", "0.000531173", "0.004086341",
"0.000888029", "0.007199893", "0.009696178", "0.000817644", "0.008603312",
"0.000538208", "0.000715276", "0.003829826", "0.002665075", "0.000655645",
"0.004521186", "0.00475768", "0.000681104", "0.003250429", "0.001037136",
"0.004149464", "0.003025068", "0.000661952", "0.001511905", "0.001230574",
"0.000855192", "0.001946997", "0.002197531", "0.000962446", "0.002434427",
"0.001437311", "0.001685384", "0.000843318", "0.000597531", "0.003679736",
"0.00052786", "0.002599698", "0.006638163", "0.000492092", "0.003381131",
"0.004282117", "0.002772674", "0.001209647", "0.005015221", "0.002725676",
"0.001817094", "0.004275772", "0.006164229", "0.001852464", "0.004668182",
"0.00025729", "0.000571824", "0.003998807", "0.000310591", "0.003167884",
"0.001286295", "0.001117448", "0.000285175", "0.002681743", "0.002541922",
"0.000339817", "0.002717807", "0.003086299", "0.003665057", "0.001442348",
"0.000133803", "0.004258506", "0.004458759", "0.000587058", "0.011033508",
"0.000646106", "0.003609799", "0.004706507", "0.006409543", "0.000690599",
"0.002099984", "0.001362624", "0.006168257", "0.000262889", "0.000657049",
"0.000548061", "0.001194158", "0.00236448", "0.000866242", "0.000321134",
"0.003252815", "0.000405544", "0.003749155", "0.002423416", "0.000715815",
"0.002068842", "0.000681442", "0.002587891", "0.001318798", "0.002900788",
"0.006026455", "0.003699808", "0.001977136", "0.000945813", "0.001145864",
"0.005304798", "0.007237841", "0.002849855", "0.000441675", "0.000411287",
"0.000768919", "0.00031052", "0.012539592", "0.006597502", "0.003484505",
"0.013217535", "0.006680105", "0.006715462", "0.004410384", "0.006726778",
"0.003722312", "0.012390133", "0.006711536", "0.004539865", "0.006212197",
"0.003296238", "0.00495935", "0.007676141", "0.005152604", "0.002807202",
"0.002521741", "0.003382216", "0.005610252", "0.002612738", "0.002026107",
"0.001670699", "0.001927528", "0.00194118", "0.001634303", "0.009430554",
"0.001204734", "0.003701371", "0.003278496", "0.003673539", "0.001572092",
"0.005461998", "0.007659243", "0.000794725", "0.003422438", "0.005669143",
"0.002985877", "0.000272664", "0.002271537", "0.005386226", "0.000931846",
"0.001839194", "0.002773973", "0.00219973", "0.00264419", "0.002359631",
"0.003208366", "0.00155871", "0.002459454", "0.002203402", "0.004330583",
"0.006671027", "0.004574731", "0.001901366", "0.002839133", "0.003895146",
"0.002403823", "0.002021783", "0.002035402", "0.002471519", "0.002258829",
"0.000748663", "0.003052609", "0.000756361", "0.003848861", "0.002010261",
"0.002319319", "0.002734265", "0.003931146", "0.004014014", "0.001212488",
"0.004313271", "0.001803602", "0.000438857", "0.003518248", "0.000983077",
"0.000536783", "0.001030337", "0.005479628", "0.001986754", "0.002075642",
"0.000304379", "0.001501574", "0.001573557", "0.002023082", "0.003399616",
"0.003702631", "0.000973154", "0.002929413", "0.003016686", "0.001960026",
"0.001893558", "0.003439089", "0.001924369", "0.007517484", "0.000899346",
"0.001569812", "0.002040772", "0.003196777", "0.001955455", "0.002831375",
"0.002804938", "0.001917154", "0.003672333", "0.005551972", "0.002036081",
"0.001444845", "0.000401853", "0.002284308", "0.002822319", "0.000445111",
"0.001241386", "0.003884877", "0.00325356", "0.00224486", "0.003521492",
"0.002886992", "0.003133533", "0.002155552", "0.003339618", "0.001423891",
"0.009148341", "0.002143469", "0.005051723", "0.004020353", "0.003620972",
"0.003749512", "0.002030368", "0.003850751", "0.003291713", "0.003876949",
"0.003633955", "0.000600088", "0.002769233", "0.000944595", "0.004263147",
"0.000596448", "0.002646152", "0.001701854", "0.007998223", "0.005154705",
"0.00265977", "0.001832958", "0.001064938", "0.006562253", "0.004358674",
"0.000521506", "0.001817005", "0.005737944", "0.000521742", "0.00246014",
"0.00223602", "0.001456657", "0.004855751", "0.003058413", "0.002387861",
"0.003210591", "0.002263782", "7.37E-05", "0.002971081", "0.001318834",
"0.001131532", "0.007653804", "0.002033245", "0.007817832", "0.003851958",
"0.001010928", "0.001083535", "0.000616509", "0.001179324", "0.000288743",
"0.003962735", "0.001787123", "0.001447554", "0.001253004", "0.001528183",
"0.003366145", "0.002102381", "0.000145862", "0.003494018", "0.002128656",
"0.003675162", "0.00759652", "0.001250727", "0.001506475", "0.000621707",
"0.003006809", "0.000996703", "0.001929081", "0.002620048", "0.002965278",
"0.004220162", "0.004578438", "0.001630116", "0.001431606", "0.00541955",
"0.002649892", "0.000315404", "0.001374571", "0.000853286", "0.003181114",
"0.002473225", "0.000629849", "0.002496231", "0.001432285", "0.002952843",
"0.000182705", "0.000259503", "0.001618141", "0.000903009", "0.000608267",
"0.000449268", "0.001571867", "0.000772154", "0.000825798", "0.001579361",
"0.016348978", "0.002728901", "0.000480176", "0.002312973", "0.001579204",
"0.000658368", "0.002309267", "0.000496615", "0.000580794", "0.003557672",
"0.000450865", "0.000478168", "0.001619451", "0.001266267", "0.001119731",
"0.001307925", "0.000355222", "0.000436949", "0.000526895", "0.001205208",
"0.000537842", "0.002228826", "0.003704735", "0.002574494", "0.00107791",
"0.006010363", "0.002175136", "0.003591312", "0.001068334", "0.003293846",
"0.003000628", "0.005299653", "0.003326611", "0.00288343", "0.002430028",
"0.002559727", "0.00507947", "0.002404173", "0.002047677", "0.002077716",
"0.002276752", "0.002236428", "0.004367058", "0.001876632", "0.000980004",
"0.003916822", "0.002808333", "0.001898333", "0.001366381", "0.000667145",
"0.001446287", "0.001100975", "0.004796705", "0.001333197", "0.000595446",
"0.005502218", "0.000862944", "0.00108622", "0.006379905", "0.00070873",
"0.000772437", "0.005811963", "0.001055143", "0.005369487", "0.005318855",
"0.001830795", "0.00142247", "0.003741093", "0.000699842", "0.002726698",
"0.002330577", "0.002526381", "0.000516793", "0.00080217", "0.003866176",
"0.000479181", "0.001610321", "0.000944431", "0.005955068", "0.000938004",
"0.005707428", "0.000602962", "0.001578971", "0.001504067", "0.00072246",
"0.004531777", "0.000614755", "0.002103022", "0.005264682", "0.005090387",
"0.004696797", "0.000460688", "0.000530431", "0.001922937", "0.00566926",
"0.000388306", "0.004252679", "0.00205673", "0.001783312", "0.002651375",
"0.003740467", "0.00638282", "0.00334707", "0.002155446", "0.002261144",
"0.00237246", "0.003669549", "0.003744011", "0.001334122", "0.002774739",
"0.002572677", "0.001193501", "0.002378721", "0.001016823", "0.002519132",
"0.000936095", "0.005202675", "0.002536735", "0.00252089", "0.004389852",
"0.002645601", "0.005036094", "0.002028686", "0.00287482", "0.00039039",
"0.001700629", "0.002406003", "0.003000786", "0.000350833", "0.00237079",
"0.001370358", "0.000281447", "0.001162593", "0.000391126", "0.000428876",
"0.003587365", "0.001830857", "0.001245239", "0.00054402", "0.000786806",
"0.000308136", "0.002252348", "0.001009821", "0.007197987", "0.003429838",
"0.00047818", "0.000191829", "0.001469793", "0.000701897", "0.000303383",
"0.000240607", "0.000367176", "0.000806676", "0.001029976", "0.001764326",
"0.000586666", "0.001052103", "0.0027832", "0.002899223", "0.000535299",
"0.000321216", "0.002765093", "0.003304198", "0.000928385", "0.003349216",
"0.00262997", "0.001902671", "0.00740575", "0.001269628", "0.001087366",
"0.000306576", "0.010979008", "0.000142284", "0.003562197", "0.000951849",
"0.004738473", "0.001147934", "0.000868998", "0.000100094", "0.003396012",
"0.001425963", "0.000457682", "0.001134672", "0.006125895", "0.001206639",
"0.001288869", "9.26E-05", "0.000970596", "0.004299361", "0.001365496",
"0.000252023", "0.000881799", "0.001159217", "0.002769744", "0.001347274",
"0.002506093", "0.002587892", "0.001760215", "0.000200908", "0.000120504",
"0.000995343", "0.001956552", "0.00396928", "0.001998548", "0.000989844",
"0.00182333", "0.004934963", "0.005930661", "0.003704832", "0.005100611",
"0.001174396", "0.001573248", "0.001514134", "0.004770532", "0.001596482",
"0.002227835", "0.000293322", "0.000765304", "0.006579839", "0.002086935",
"0.000516124", "0.002598376", "0.000677743", "0.001751905", "0.000765355",
"0.000851338", "0.002038965", "0.002461201", "0.004482297", "0.002665955",
"0.00053772", "0.0026631", "0.002186892", "0.002164451", "0.001769369",
"0.000556618", "0.001811205", "0.001436441", "0.003730669", "0.000540904",
"0.002073718", "0.006881776", "0.000504263", "0.011870741", "0.012497633",
"0.000723731", "0.00138756", "0.000796687", "0.001090998", "0.001702514",
"0.001459711", "0.002239202", "0.001484793", "0.000216742", "0.001406412",
"0.000537954", "0.000751007", "0.000141754", "0.001252295", "0.001357958",
"0.000426315", "0.000396497", "0.000712089", "0.001571138", "0.000631633",
"0.001320965", "0.000791112", "0.001042755", "0.001922778", "0.001338678",
"0.002061002", "0.001257354", "0.001032697", "0.002156974", "0.000758648",
"0.00115927", "0.000493399", "0.002868998", "0.000644541", "0.000963915",
"0.002440877", "0.001530594", "0.001660393", "0.001974633", "0.002683663",
"0.001027642", "0.0013826", "0.001268996", "0.002888161", "0.002042083",
"0.000275954", "0.000425662", "0.001395292", "0.000698374", "0.001280422",
"0.000360265", "0.00286505", "0.000657062", "0.000832286", "0.001509413",
"0.009461693", "0.001173043", "0.001320977", "0.000374569", "0.003380137",
"0.000648815", "0.003506032", "0.007945229", "0.001816186", "0.00593997",
"0.001615382", "0.000617105", "0.000998473", "0.002682396", "0.002608846",
"0.001042748", "0.000608391", "0.003155706", "0.000350366", "0.011011332",
"0.001071085", "0.003032408", "0.002362787", "0.000785395", "0.000369495",
"0.000729234", "0.002874633", "0.001277868", "0.000412434", "0.00337317",
"0.002100282", "0.00127116", "0.00087507", "0.003909292", "0.000809452",
"0.003842508", "0.000261334", "0.002695379", "0.003381531", "0.000959406",
"0.000830514", "0.001417701", "0.001216766", "0.000580054", "0.000982322",
"0.009152715", "0.004942274", "0.002247519", "0.00956424", "0.002955447",
"0.003146615", "0.001329276", "0.000585691", "0.004521217", "0.002996703",
"0.000862505", "0.002412426", "0.000249773", "0.001064878", "0.00218024",
"0.001837315", "0.002573162", "0.002837718", "0.001951952", "0.001664727",
"0.001366389", "0.001962139", "0.001443101", "0.000571743", "0.001736855",
"0.002811318", "0.001017781", "0.001553503", "0.00431465", "0.012072091",
"0.002428644", "0.0005115", "0.001977798", "0.00024813", "0.005039793",
"0.00082675", "0.002480204", "0.002225975", "0.001997709", "0.002641843",
"0.002820302", "0.001707712", "0.00188298", "0.002150676", "0.001328293",
"0.001405165", "0.00298826", "0.001502586", "0.002395292", "0.002796706",
"0.005203437", "0.004817151", "0.00030616", "0.001322253", "0.00455419",
"0.001884207", "0.000751607", "0.000622799", "0.003630857", "0.001554908",
"0.000384964", "0.000696522", "0.000292492", "0.001132897", "0.002078203",
"0.002657073", "0.000610842", "0.002378412", "0.00083702", "0.003651925",
"0.001021224", "0.000738553", "0.001776616", "0.001427956", "0.001826608",
"0.001017576", "0.000523945", "0.000729999", "0.000700889", "0.004372708",
"0.0010721", "0.005203322", "0.00180632", "0.000614454", "0.003935009",
"0.002946169", "0.001363085", "0.000413364", "0.000394261", "0.001080705",
"0.003037984", "0.000221178", "0.00079759", "0.00162498", "0.002324509",
"0.001339628", "0.002972215", "0.001966148", "0.0016092", "0.000234344",
"0.000993412", "0.000937602", "0.000415351", "0.002608404", "0.000564896",
"0.000999391", "0.001383561", "0.00032661", "0.003116056", "0.00269477",
"0.001127392", "0.001387888", "0.001568912", "0.00199253", "0.000374667",
"0.002648756", "0.001985879", "0.001983733", "0.000659444", "0.003735928",
"0.000649978", "0.000531627", "0.004032346", "0.00084578", "0.000707181",
"0.00176177", "0.000724044", "0.000664402", "0.011373309", "0.002388706",
"0.000774438", "0.003342828", "0.002197908", "0.002795226", "0.000567306",
"0.001694292", "0.00166641", "0.001945432", "0.002895236", "0.001046278",
"0.002323907", "0.001420304", "0.001982192", "0.000677479", "0.000491854",
"0.001486234", "0.001277554", "0.003431615", "0.001142057", "0.002065289",
"0.000825491", "0.000925508", "0.000913616", "0.001868473", "0.001826053",
"0.001221936", "0.002615253", "0.00198233", "0.000654061", "0.001676624",
"0.001221201", "0.000456194", "0.000841204", "0.005091102", "0.001521278",
"0.00140408", "0.00356072", "0.001374545", "0.000975109", "0.001850532",
"0.000490473", "0.001053579", "0.000547076", "0.001429506", "0.000989919",
"0.00029281", "0.000864564", "0.002571375", "0.001410263", "0.002523124",
"0.000843319", "0.000788548", "0.000942674", "0.000862536", "0.001145244",
"0.000731401", "0.000922755", "0.00080113", "0.001147544", "0.000999559",
"0.001002895", "0.001534572", "0.001124767", "0.00055331", "0.001453456",
"0.001563662", "0.002073296", "0.001865843", "0.001249885", "0.002239018",
"0.000909996", "0.002121782", "0.002524288", "0.001410567", "0.00208956",
"0.000853813", "0.003419427", "0.002006391", "0.000549302", "0.000902927",
"0.001930719", "0.00167763", "0.002530737", "0.003240916", "0.001839864",
"0.001413561", "0.001725875", "0.001846509", "0.003881131", "0.000861918",
"0.000663578", "0.002255887", "0.000871992", "0.001004718", "0.001688389",
"0.003073294", "0.000949486", "0.001302246", "0.000464419", "0.001215565",
"0.003880833", "0.001844661", "0.003083818", "0.002076196", "0.003507372",
"0.002746735", "0.001611621", "0.001053223", "0.001772452", "0.001441064",
"0.002639818", "0.003257066", "0.002662365", "0.004859482", "0.00349962",
"0.001242116", "0.002071981", "0.001188572", "0.002338708", "0.002206605",
"0.001728737", "0.001522004", "0.001383648", "0.00098972", "0.004487214",
"0.000812133", "0.001113718", "0.002843833", "0.001116469", "0.001460217",
"0.001338645", "0.001437048", "0.003548891", "0.001054238", "0.001435734",
"0.008424636", "0.003766785", "0.003005459", "0.002083674", "0.003384797",
"0.001496615", "0.002147265")), .Names = c("Analyte", "Tm_ugL"
), na.action = structure(3495L, .Names = "3498", class = "omit"), row.names
= 4:2603, class = "data.frame")

This is my matrix for storing the data:

A_Censored<-matrix(A[,two],nrow(A),two)

This is my for loop for assessing whether it is above or below a certain
value (A_LLD<-0.0002):

for (i in one:nrow(A))
  if (A[i,two]<=A_LLD)
  {
    (A_Censored[i,two]<-"TRUE")
  }else
    A_Censored[i,two]<-"FALSE"



And this is my count function

LLD_Count<- function(Element_List)
{Element_List<-na.omit(Element_List)
 Count<-0
 for (i in one:nrow(Element_List))
   if (Element_List[i,two]=="TRUE")
     Count<-Count+one
 Count_perc<-(Count/length(Element_List[,two])*hundred)
 LLD_Output<-data.frame(Count,Count_perc)
 colnames(LLD_Output)<-c("N below LLD","Pecent below LLD")
 return(LLD_Output)
}

Im really stuck and your help be greatly appreciated.
Thanks

--
Shane

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Oct  3 19:22:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 3 Oct 2013 10:22:38 -0700 (PDT)
Subject: [R] vif
In-Reply-To: <BLU170-W530A0B4F57F313FAC511B789170@phx.gbl>
References: <BLU170-W802FE25B05F0A1E7CED77B89170@phx.gbl>,
	<1380816113.92158.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<BLU170-W530A0B4F57F313FAC511B789170@phx.gbl>
Message-ID: <1380820958.97817.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi Eliza,

Then, "res" needs a slight modification


library(car)
?res<- lapply(colnames(h),function(x) {x1<- h[,x];dat1<- do.call(rbind,lapply(seq_len(ncol(mat1)),function(i){ x2<- m[,mat1[,i]];GG<- lm(x1~x2[,1]+x2[,2]+x2[,3]+x2[,4]);GGsum<- summary(GG); data.frame( Models=paste(colnames(x2),collapse=","), Multiple_Rsq= GGsum$r.squared, Adjusted_Rsq = GGsum$adj.r.squared, Pval = paste(GGsum$coef[-1,4],collapse=","),Vif=paste(vif(GG),collapse=","),stringsAsFactors=FALSE)? })); dat1[rev(order(dat1[,3])),][1:10,]})

names(res)<- colnames(h)
A.K.





________________________________
From: eliza botto <eliza_botto at hotmail.com>
To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
Sent: Thursday, October 3, 2013 12:42 PM
Subject: vif



Dear Arun,
There is one small question however.?
what if i also want in the table a column for "vif" values of each model.?
vif values can be generated for any model in the following way

GG<-lm(h[,any column]~m[,any column]+m[,any other column] +m[,any other column] +m[,any other column])
library(car)
vif(GG)

Here will be get 4 "vif" values. I want to make a new column which could contain these values seperated by comma, very much similar to the way we did with?Pr(>|t|) values.

thanks in advance

elisa


> Date: Thu, 3 Oct 2013 09:01:53 -0700
> From: smartpink111 at yahoo.com
> To: r-help at r-project.org
> Subject: Re: [R] a simple question
> 
> Hi,
> Try:
> 
> 
> set.seed(494)
> ?h<- matrix(sample(1:40,4*124,replace=TRUE),ncol=4)
> 
> ?set.seed(39)
> ?m<- matrix(sample(1:100,10*124,replace=TRUE),ncol=10)
> ?colnames(h)<- paste0("h",1:4)
> ?colnames(m)<- paste0("m",1:10)
> mat1<-combn(colnames(m),4)
> 
> ?res<- lapply(colnames(h),function(x) {x1<- h[,x];dat1<- do.call(rbind,lapply(seq_len(ncol(mat1)),function(i){ x2<- m[,mat1[,i]];GG<- lm(x1~x2[,1]+x2[,2]+x2[,3]+x2[,4]);GGsum<- summary(GG); data.frame( Models=paste(colnames(x2),collapse=","), Multiple_Rsq= GGsum$r.squared, Adjusted_Rsq = GGsum$adj.r.squared, Pval = paste(GGsum$coef[-1,4],collapse=","),stringsAsFactors=FALSE)? })); dat1[rev(order(dat1[,3])),][1:10,]})
> 
> names(res)<- colnames(h)
> 
> 
> A.K.
> 
> 
> 
> 
> 
> ________________________________
> From: eliza botto <eliza_botto at hotmail.com>
> To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
> Sent: Thursday, October 3, 2013 11:07 AM
> Subject: a simple question
> 
> 
> 
> 
> Dear Arun,
> I hope you are fine. I actually
> wanted to discuss the following problem.
> I have a linear model of the
> following form. 
> GG<-lm(h[,any column]~m[,any
> column]+m[,any other column] +m[,any other column] +m[,any other column])
> where,
> h is matrix with 4 columns and
> 124 rows
> m is matrix with 10 columns and
> 124 rows
> what I want is the following
> make a loop command to run the
> linear model of all the possible combinations of columns of ?m? with each
> column of ?h?. 
> more precisely, if i take column
> 1 of matrix ?h?, it should be linear modeled with every combination of 10 (210
> combinations) columns of ?m?.
> All the columns of ?h? & ?m?
> have certain names (you can suppose any). ?The summary(GG) will give Multiple R-squared,??? Adjusted R-squared ?and 4 values of Pr(>|t|). 
> I want in the end a table in the
> following format.
> 
> Models ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Multiple R-squared ? ? ? ?Adjusted R-squared ? ? ? Pr(>|t|)
> Name of columns of m separated by
> comma????? Multiple R-squared???????? Adjusted R-squared?????? Pr(>|t|) separated by comma
> 
> For Example?
> 
> Models ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Multiple R-squared ? ? ? ?Adjusted R-squared ? ? ??Pr(>|t|)
> eliza, allen, murphy, jack ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.544 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.56 ? ? ? ? ? ? ? ? ? ? ? ? 0.000114,0.000112,0.01114,0.002114
> 
> where,
> eliza, allen, murphy, jack are column names.
> 
> The models are to be enlisted in the order of their Adjusted R-squared values. The models with highest?Adjusted R-squared value should be on the top and so on. i m only interested in top 10 models. so the remaining should be ignored.?
> 
> I tried to put in my question everything but if there is anything wrong plz inform me.
> 
> Thankyou very much in advance,
> 
> Eliza
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Thu Oct  3 19:47:27 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 3 Oct 2013 11:47:27 -0600
Subject: [R] text position with offset
In-Reply-To: <524D9FE1.6070205@yeah.net>
References: <524D9FE1.6070205@yeah.net>
Message-ID: <CAFEqCdy_NETMi5OsivRCfAvhG0VR9ns+ETV9zx_dKNeYfHBuPw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/04b0ef25/attachment.pl>

From hb at biostat.ucsf.edu  Thu Oct  3 19:47:52 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 3 Oct 2013 10:47:52 -0700
Subject: [R] When to use RProfile.site or .Rprofile
In-Reply-To: <774131953.2069487.1380816648137.JavaMail.root@comcast.net>
References: <1050148361.2065851.1380816428893.JavaMail.root@comcast.net>
	<774131953.2069487.1380816648137.JavaMail.root@comcast.net>
Message-ID: <CAFDcVCTYCaB8xZRpTtP1QefWZu5HBbA6Zm8qGqLpEYb34_cvuw@mail.gmail.com>

Unless you're trying to provide your startup settings to multiple
users (typically only sysadms do this), stick with .Rprofile (in your
home directory).  There is no need to have one per working directory,
unless they differ, cf. ?Startup ["...a file called ?.Rprofile? is
searched for in the current directory or in the user's home directory
(in that order)."].  Also, RProfile.site resides where R is installed
(e.g. R_HOME/etc/).  Maintaining that one requires updates when the R
version/installation location is updated, whereas the one in you home
directory will always be found regardless of R version.

My $.02

/Henrik

On Thu, Oct 3, 2013 at 9:10 AM,  <jroyrobertson at comcast.net> wrote:
> I would appreciate some advice on what the preferred contents of RProfile.site vs. .Rprofile should be. A .First() function can reside in either one, but is it preferred to place it in .Rprofile? I currently use .First() in .Rprofile files placed in separate directories used for different RStudio projects.
>
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From aline.frank at wsl.ch  Thu Oct  3 20:49:36 2013
From: aline.frank at wsl.ch (aline.frank at wsl.ch)
Date: Thu, 3 Oct 2013 20:49:36 +0200
Subject: [R] SSweibull() : problems with step factor and singular gradient
Message-ID: <OF669FA420.9EF643ED-ONC1257BF9.00676B04-C1257BF9.00676B07@wsl.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/4342120a/attachment.pl>

From murdoch.duncan at gmail.com  Thu Oct  3 21:16:53 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 03 Oct 2013 15:16:53 -0400
Subject: [R] text position with offset
In-Reply-To: <524D9FE1.6070205@yeah.net>
References: <524D9FE1.6070205@yeah.net>
Message-ID: <524DC2A5.1030709@gmail.com>

On 03/10/2013 12:48 PM, Jinsong Zhao wrote:
> Hi there,
>
> I have draw a scatter plot. Now, I hope to label the points in the plot.
> For example:
>
> plot(1:10)
> text(1:10, 1:10, LETTERS[1:10])
>
> In the above line, I can set position for each labels with pos, e.g.:
>
> text(1:10, 1:10, LETTERS[1:10], pos = sample(1:4, 10, replace = TRUE))
>
> as what you have seen, the length of pos can be longer than 1. in the
> above case, it has the length 10.
>
> However, I can not set offset with length longer than 1. The following
> code always set the offset to 0.1 rather than 0.1, 0.2, ..., 1 for the
> 10 labels.
>
> text(1:10, 1:10, LETTERS[1:10], pos = sample(1:4, 10, replace = TRUE),
> offset = seq(0.1, 1, 0.1))
>
> it seems that adj also can not be set for multiple points with different
> values.
>
> Any hints? Thanks in advance.

See ?text:  those parameters apply to all text.  To get what you want, 
call text() 10 times (e.g. in a loop, or in lapply).

Duncan Murdoch


From dwinsemius at comcast.net  Thu Oct  3 21:39:01 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 3 Oct 2013 12:39:01 -0700
Subject: [R] time series has no or less than 2 periods
In-Reply-To: <BAY403-EAS621ABB2212BCD6AA9ADEB0ED170@phx.gbl>
References: <BAY403-EAS621ABB2212BCD6AA9ADEB0ED170@phx.gbl>
Message-ID: <67EEC2C0-CCD6-4113-9ED2-6BB7D3DD81A2@comcast.net>


On Oct 3, 2013, at 8:32 AM, Daniel Hickman wrote:

> Hello,
> 
> 
> 
> I have been tasked with taking an excel file that my colleague had implemented Triple Exponential Smoothing and recreate using R. 
> 
> The following image shows the before and after of smoothing out a fixed interval time series data using Triple Exponential Smoothing inside of Excel.
> 
> enter image description here

The image file formats that I know are acceptable are .ps, .pdf or .png. Not sure about jpeg.

> 
> I am trying to perform the same triple exponential smoothing in R.  I created a csv file with the before smoothing data.  The csv file is attached and can also be found here.

Need to send with .txt extension.

> 
> I found the HoltWinters method but I keep getting an error when I try to apply HoltWinters against the csv.
> setwd("C:/temp")
> data <- read.table("TripleExpSmoothingXLS.csv", header=TRUE, sep=",")
> ts <- ts(data$QtyPerWeek, frequency=52)
> HoltWinters(ts,0.46924,0.05,0.2)
> 
> This results in the following error. "Error in decompose(ts(x[1L:wind], start = start(x), frequency = f), seasonal) : time series has no or less than 2 periods"

Perhaps a data entry problem. We would need to see either the file or output of str(data).
> 
> In case it helps,  excel file with the triple exponential smoothing formulas and original data can be found here.

Again.... there is no here here.

> 
> Any advice? 
> 
> Thanks, Dan______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Oct  3 21:45:13 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 3 Oct 2013 12:45:13 -0700
Subject: [R] climstats
In-Reply-To: <DEF541F3CB545B4A8BC9A811132359C003697191F01B@KEXCH00.ad.kew.org>
References: <DEF541F3CB545B4A8BC9A811132359C003697191EFE2@KEXCH00.ad.kew.org>
	<1FB1E28E-2A6E-4474-950A-95C378442109@comcast.net>
	<5249B73C.20901@stats.ox.ac.uk>
	<FE8088E7-5EB5-488B-A8CE-57A05268C4D1@comcast.net>
	<DEF541F3CB545B4A8BC9A811132359C003697191F01B@KEXCH00.ad.kew.org>
Message-ID: <F790EF15-F8E0-406A-A121-76514C7C6785@comcast.net>


On Oct 3, 2013, at 10:00 AM, Jenny Williams wrote:

> It seems to load now on 3.0.2 32bit and 64bit but NOT 3.0.1. 
> install.packages("climstats", repos="http://R-Forge.R-project.org", type="source")
> 
> I did have to manually install some of the dependencies.
> There were 2 of us that tried loading climstats on different machines so there must have been a blip with our firewall or something.
> 
> Now that I have climstats loaded the function I am trying to use doesn't work. 
> I can bring up the help file:
> ?spatial_sync_raster
> 
> but I get this error when I try to use the function:
> Error: could not find function "spatial_sync_raster"

I was going to say a case offailing to load the package but you say that you got information from 

?spatial_sync_raster   # be sure to check exact spelling

.. so that seems unlikely. (You are asked to show sessionInfor and the exact code which you have failed to provide.) Maybe you should ask the package maintainer. Type:

maintainer("climstats")

-- 
David
> 
> On Sep 30, 2013, at 10:39 AM, Prof Brian Ripley wrote:
> 
>> On 30/09/2013 18:19, David Winsemius wrote:
>>> 
>>> On Sep 30, 2013, at 3:25 AM, Jenny Williams wrote:
>>> 
>>>> I have been trying to download the climstats package:
>>>> https://r-forge.r-project.org/R/?group_id=861
>>>> 
>>>> but it doesn't seem to run on R 3.0.2 or 3.0.1
>>> 
>>> What makes you say this? What errors are reprorted? ("Doesn't seems to run" is a bit vague.)
>>> 
>>>> and the zipfile is empty.
>>> 
>>> I was able to install version 1.0 from sources with:
>>> 
>>> install.packages("climstats", repos="http://R-Forge.R-project.org", type="source")
>>> 
>>> (I agree that the zipfile for Windows was not found.)
>>> 
>>> R version 3.0.1 Patched (2013-07-23 r63392) Running Mac OS 10.7.5. It appears to require a fair number of external package, so you would need to check the Depends in the description file.
>>> 
>>> Depends: R (>= 2.13), raster, rgdal, chron, zoo, sp, ncdf, R.utils
>>> 
>>> It did not appear to do any C or Fortran compiling, so I think that means you do not need to have RTools installed on Windows.
>>> 
>>> But since it requires rgdal, you would need to have GDAL installed if you were to get it to load.
>> 
>> Why do you say that?  On both Windows and OS X, GDAL is part of the rgdal binary.
> 
> My error apparently. I have in the past had incorrect installations of GDAL that prevented rgdal from loading properly and my sometimes fuzzy memory was that I fixed this by reinstalling GDAL. So I thought they were independent installations. Apologies for the noise.
> 
> -- 
> David.
> 
> 
>> 
>>> 
>>>> 
>>>> Does anyone know the status of this package or where I can download it.
>>>> 
>>>> Thanks
>>>> 
>>>> ******************
>>>> Jenny Williams
>>>> Spatial Information Scientist, GIS Unit
>>>> Herbarium, Library, Art & Archives Directorate
>>>> Royal Botanic Gardens, Kew
>>>> Richmond, TW9 3AB, UK
>>>> 
>>>> Tel: +44 (0)208 332 5277
>>>> email: jenny.williams at kew.org<mailto:jenny.williams at kew.org>
>>>> ******************
>>>> 
>>>> Film: The Forgotten Home of Coffee - Beyond the Gardens<http://www.youtube.com/watch?v=-uDtytKMKpA&sns=tw>
>>>> Stories: Coffee Expedition - Ethiopia<http://storify.com/KewGIS/coffee-expedition-ethiopia>
>>>>            Blog: Discovering Coffee in Ethiopia    <http://www.kew.org/news/kew-blogs/incrEdibles-food-blog/discovering-coffee.htm>
>>>>            Kew in Harapan Rainforest Sumatra<http://storify.com/KewGIS/kew-in-harapan-rainforest>
>>>> Articles: Seeing the wood for the trees<http://www.kew.org/ucm/groups/public/documents/document/kppcont_060602.pdf>
>>>> How Kew's GIS team and South East Asia botanists are working to help conserve and restore a rainforest in Sumatra. Download a pdf of this article here.<http://www.kew.org/ucm/groups/public/documents/document/kppcont_060602.pdf>
>>>> 
>>>> 
> 

David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Thu Oct  3 21:57:14 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 3 Oct 2013 19:57:14 +0000
Subject: [R] time series has no or less than 2 periods
In-Reply-To: <67EEC2C0-CCD6-4113-9ED2-6BB7D3DD81A2@comcast.net>
References: <BAY403-EAS621ABB2212BCD6AA9ADEB0ED170@phx.gbl>
	<67EEC2C0-CCD6-4113-9ED2-6BB7D3DD81A2@comcast.net>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3487CC@PA-MBX01.na.tibco.com>

> > ts <- ts(data$QtyPerWeek, frequency=52)
> > HoltWinters(ts,0.46924,0.05,0.2)
> >
> > This results in the following error. "Error in decompose(ts(x[1L:wind], start = start(x),
> frequency = f), seasonal) : time series has no or less than 2 periods"

Since you have set the frequency of the time series to 52, you need
to have 104 observations to get the initial estimate of the seasonal
pattern.  How many observations are in 'ts'?  If you don't have enough
you can omit the seaonal component (HoltWinters(gamma=FALSE,...)),
change start.periods from the default 2 to 1, or supply a 52-long vector
of the initial seasonal pattern as the s.start argument.

If you do have more than 104 observations then you will have to tell
us more about the data.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of David Winsemius
> Sent: Thursday, October 03, 2013 12:39 PM
> To: Daniel Hickman
> Cc: r-help at r-project.org
> Subject: Re: [R] time series has no or less than 2 periods
> 
> 
> On Oct 3, 2013, at 8:32 AM, Daniel Hickman wrote:
> 
> > Hello,
> >
> >
> >
> > I have been tasked with taking an excel file that my colleague had implemented Triple
> Exponential Smoothing and recreate using R.
> >
> > The following image shows the before and after of smoothing out a fixed interval time
> series data using Triple Exponential Smoothing inside of Excel.
> >
> > enter image description here
> 
> The image file formats that I know are acceptable are .ps, .pdf or .png. Not sure about
> jpeg.
> 
> >
> > I am trying to perform the same triple exponential smoothing in R.  I created a csv file
> with the before smoothing data.  The csv file is attached and can also be found here.
> 
> Need to send with .txt extension.
> 
> >
> > I found the HoltWinters method but I keep getting an error when I try to apply
> HoltWinters against the csv.
> > setwd("C:/temp")
> > data <- read.table("TripleExpSmoothingXLS.csv", header=TRUE, sep=",")
> > ts <- ts(data$QtyPerWeek, frequency=52)
> > HoltWinters(ts,0.46924,0.05,0.2)
> >
> > This results in the following error. "Error in decompose(ts(x[1L:wind], start = start(x),
> frequency = f), seasonal) : time series has no or less than 2 periods"
> 
> Perhaps a data entry problem. We would need to see either the file or output of
> str(data).
> >
> > In case it helps,  excel file with the triple exponential smoothing formulas and original
> data can be found here.
> 
> Again.... there is no here here.
> 
> >
> > Any advice?
> >
> > Thanks, Dan______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jgervais89 at gmail.com  Fri Oct  4 00:42:04 2013
From: jgervais89 at gmail.com (Jesse Gervais)
Date: Thu, 3 Oct 2013 18:42:04 -0400
Subject: [R] (sans objet)
Message-ID: <CADfL=7ZYGZTjJ=E3ht_3xy0Qgx9RovsJio2vdtD0vhBL+xNY2g@mail.gmail.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/e1fb7f66/attachment.pl>

From xchen at dr.com  Fri Oct  4 00:43:18 2013
From: xchen at dr.com (Xianwen Chen)
Date: Fri, 04 Oct 2013 00:43:18 +0200
Subject: [R] [sm.density.compare] scale up y-axis and additional line
 type
In-Reply-To: <524B75C3.9020603@bitwrit.com.au>
References: <5249F891.5000001@dr.com> <524A48F2.8030205@bitwrit.com.au>
	<524B17CB.9010903@dr.com> <524B75C3.9020603@bitwrit.com.au>
Message-ID: <524DF306.8080109@dr.com>

Hi Jim,

Thanks a lot for your help!

Kind regards,

Xianwen

On 10/02/2013 03:24 AM, Jim Lemon wrote:
> On 10/02/2013 04:43 AM, Xianwen Chen wrote:
>> Thanks Jim,
>>
>> The picture width is adjusted. That was great help! I really 
>> appreciate it.
>>
>> Does lwd mean 'line width'? I'm not exactly sure how that will help. Can
>> you please explain the intuition behind it?
>>
> Yes, "lwd" refers to line width. The combination lty=3,lwd=3 should 
> give you a thick dotted line.
>
>> Can I also ask another question? My graph is made from 7 plots from
>> sm.density.compare(). These 7 plots are put together by:
>>
>> par(mfrow=c(4,2))
>>
>> To make all 7 plots comparable, I specify y- and x-axis ranges. Here is
>> the sample code for one of the plots:
>>
>> sm.density.compare(
>> c(sample_1, sample_2), # sample_1 and sample_2 are two vectors, each
>> corresponding to a sample
>> rep(1:2, rep(140, 2)),
>> lty = c(1, 3),
>> lwd = c(1, 3), # This change was made by taking your suggestion.
>> col = c("black", "black"),
>> xlab="Sample",
>> xlim=c(-40, 60),
>> ylim=c(0, 0.15)
>> )
>>
>> legend("topright", c("MMNL", "GMNL"), lty = c(1, 3), cex = 1)
>>
>> Somehow, xlim and ylim do not have an effect. I did not have this
>> problem when I was running R in Arch Linux; but now I'm using Debian 
>> Linux.
>>
> xlim and ylim seem to work correctly when I tried this:
>
> sample_1<-runif(280,-20,40)
> sample_2<-runif(280,0,0.1)
>
> sm.density.compare(c(sample_1, sample_2),
>             rep(1:2, rep(140, 2)),
>             lty = c(1, 3),
>             lwd = c(1, 3),
>             col = c("black", "black"),
>             xlab="Sample",
>             xlim=c(-40, 60),
>             ylim=c(0, 0.15)
>     )
>
> However, while the lty=3 worked correctly, the lwd=3 didn't. I think 
> that this function does not pass all of the graphics parameters to the 
> plot function - see the help page on sm.options.
>
> Jim


From murdoch.duncan at gmail.com  Fri Oct  4 00:53:16 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 03 Oct 2013 18:53:16 -0400
Subject: [R] (sans objet)
In-Reply-To: <CADfL=7ZYGZTjJ=E3ht_3xy0Qgx9RovsJio2vdtD0vhBL+xNY2g@mail.gmail.com>
References: <CADfL=7ZYGZTjJ=E3ht_3xy0Qgx9RovsJio2vdtD0vhBL+xNY2g@mail.gmail.com>
Message-ID: <524DF55C.4010702@gmail.com>

On 13-10-03 6:42 PM, Jesse Gervais wrote:
> Hello there,
>
> I try to construct a variable with R, but I have some difficulties.
>
> Assume that I use a data set named = mydata. I want to create a variable
> that is the mean (totmean) or the sum (totsum) of 6 variables (var1, var2,
> var3, var4, var5, var6). However, I want only participants who have
> responded to at least 4 items to be include. Those who have one or two
> missing for var1-var6 should be coded NA for totmean and totsum.
>
> How I do that?
>

Write a function that computes what you want for a vector of 6 values. 
Then put the data into an array, and use apply( the_array, 1, 
your_function) to compute it for the full dataset.

Duncan Murdoch


From jwiley.psych at gmail.com  Fri Oct  4 00:54:45 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 3 Oct 2013 15:54:45 -0700
Subject: [R] (sans objet)
In-Reply-To: <CADfL=7ZYGZTjJ=E3ht_3xy0Qgx9RovsJio2vdtD0vhBL+xNY2g@mail.gmail.com>
References: <CADfL=7ZYGZTjJ=E3ht_3xy0Qgx9RovsJio2vdtD0vhBL+xNY2g@mail.gmail.com>
Message-ID: <CANz9Z_+jZuSfcAFfOij+29bXZvUN_BZMh1Yt7e1p+xEqO0s+RQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/80c2756d/attachment.pl>

From jim at bitwrit.com.au  Fri Oct  4 01:14:24 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 04 Oct 2013 09:14:24 +1000
Subject: [R] (sans objet)
In-Reply-To: <CADfL=7ZYGZTjJ=E3ht_3xy0Qgx9RovsJio2vdtD0vhBL+xNY2g@mail.gmail.com>
References: <CADfL=7ZYGZTjJ=E3ht_3xy0Qgx9RovsJio2vdtD0vhBL+xNY2g@mail.gmail.com>
Message-ID: <524DFA50.2070608@bitwrit.com.au>

On 10/04/2013 08:42 AM, Jesse Gervais wrote:
> Hello there,
>
> I try to construct a variable with R, but I have some difficulties.
>
> Assume that I use a data set named = mydata. I want to create a variable
> that is the mean (totmean) or the sum (totsum) of 6 variables (var1, var2,
> var3, var4, var5, var6). However, I want only participants who have
> responded to at least 4 items to be include. Those who have one or two
> missing for var1-var6 should be coded NA for totmean and totsum.
>
> How I do that?
>
Hi Jesse,
Say your data looks like this:

mydata<-data.frame(var1=rnorm(100),var2=rnorm(100),
  var3=rnorm(100),var4=rnorm(100),
  var5=rnorm(100),var6=rnorm(100))
mydata$var1[sample(1:100,20)]<-NA
mydata$var2[sample(1:100,20)]<-NA
mydata$var3[sample(1:100,20)]<-NA
mydata$var4[sample(1:100,20)]<-NA
mydata$var5[sample(1:100,20)]<-NA
mydata$var6[sample(1:100,20)]<-NA
valid.n<-function(x) return(sum(!is.na(x)))
gt4<-unlist(apply(as.matrix(mydata),1,FUN=valid.n))<=4
totmean<-mean(unlist(mydata[gt4,]),na.rm=TRUE)
totsum<-sum(unlist(mydata[gt4,]),na.rm=TRUE)

Jim


From dulcalma at bigpond.com  Fri Oct  4 01:35:48 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 4 Oct 2013 09:35:48 +1000
Subject: [R] lattice multi-panel layout
In-Reply-To: <1380806708263-4677500.post@n4.nabble.com>
References: <1380806708263-4677500.post@n4.nabble.com>
Message-ID: <000c01cec091$4b05b820$e1112860$@bigpond.com>

Hi  
Have a look at ?print.trellis. Lattice (xyplot) is not like plot

Untested.

starting at bottom left going across the rows

print(plott[[4]], position = c(0,0,1/3,0.5), more = T)
print(plott[[5]], position = c(1/3,0,2/3,0.5), more = T)
print(plott[[6]], position = c(2/3,0,1,0.5), more = T)
print(plott[[1]], position = c(0,0.5,1/3,1), more = T)
print(plott[[2]], position = c(1/3,0.5,2/3,1), more = T)
print(plott[[3]], position = c(2/3,0.5,1,1), more = T)

or you could go into viewports  ?viewport

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of efx
Sent: Thursday, 3 October 2013 23:25
To: r-help at r-project.org
Subject: [R] lattice multi-panel layout

Dear,
I seem to be unable to work out a solution for multi-panel layout using
xyplot. I have tried with layout, grid.layout (latticeExtra), but
unsuccessfully. I can produce all plots individually, but just can't figure
out how to put them all in the same panel! Here is a piece of the code. 

vlayout <- grid.layout(2,3,widths=unit(2,"inches"), heights=unit(1.5,
"inches")) 

lapply(seq(vh), function(i) {
                 for (k in 1:num_bins){
                 indexx <- which(vh[[i]]$dist<= (k*radius/num_bins) &
vh[[i]]$dist> ((k-1)*radius/num_bins))
                 bin_avg[k]<-mean(vh[[i]]$gamma[indexx])      } 
              
  plott[[i]] <- xyplot(   bin_avg ~ dist , type=("p"),  layout= vlayout) 
) } )

 - If I use grid.layout I got the error: "Error in panel.layout[1] *
panel.layout[2] : 
  non-numeric argument to binary operator"
 - If set just layout as c(2,3) all plots are drawn in the bottom left of
the panel!!!
 - If layout is not set at all, all plots are produced in different pages.

I would be grateful if you could help me out.
Regards





--
View this message in context:
http://r.789695.n4.nabble.com/lattice-multi-panel-layout-tp4677500.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Oct  4 04:36:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 3 Oct 2013 19:36:09 -0700 (PDT)
Subject: [R] Divide a Time column each K seconds
Message-ID: <1380854169.13344.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
?set.seed(45)
?df1<- data.frame(datetime=as.POSIXct("2011-05-25",tz="GMT")+1:200,value=sample(1:40,200,replace=TRUE),value2= sample(45:90,200,replace=TRUE))

res<-? with(df1,aggregate(cbind(value,value2),list(as.POSIXct(cut(datetime,breaks="5 sec"))+4),mean))
colnames(res)[1]<- colnames(df1)[1]
?head(res)
#???????????? datetime value value2
#1 2011-05-25 00:00:05? 16.0?? 67.4
#2 2011-05-25 00:00:10? 10.8?? 60.0
#3 2011-05-25 00:00:15? 20.2?? 65.2
#4 2011-05-25 00:00:20? 17.8?? 65.2
#5 2011-05-25 00:00:25? 21.2?? 81.6
#6 2011-05-25 00:00:30? 21.4?? 56.2


#or
library(plyr)
res2<- ddply(df1,.(datetime=as.POSIXct(cut(df1$datetime,breaks="5 sec"))+4
),numcolwise(mean))
?head(res2)
#???????????? datetime value value2
#1 2011-05-25 00:00:05? 16.0?? 67.4
#2 2011-05-25 00:00:10? 10.8?? 60.0
#3 2011-05-25 00:00:15? 20.2?? 65.2
#4 2011-05-25 00:00:20? 17.8?? 65.2
#5 2011-05-25 00:00:25? 21.2?? 81.6
#6 2011-05-25 00:00:30? 21.4?? 56.2



#or
library(xts)
originalTZ <- Sys.getenv("TZ")
Sys.setenv(TZ = "GMT")

xt1<- xts(df1[,2:3],order.by=df1[,1])
indx<-endpoints(xt1,'secs',5)
?res3<-period.apply(xt1,c(0,indx[-c(1,length(indx))]+1),FUN=mean)
?head(res3)
#??????????????????? value value2
#2011-05-25 00:00:05? 16.0?? 67.4
#2011-05-25 00:00:10? 10.8?? 60.0
#2011-05-25 00:00:15? 20.2?? 65.2
#2011-05-25 00:00:20? 17.8?? 65.2
#2011-05-25 00:00:25? 21.2?? 81.6
#2011-05-25 00:00:30? 21.4?? 56.2

Sys.setenv(TZ = originalTZ)

A.K.


Hi, I am new to R and to this forum. 
I have to do a project for school and I have to calculate the mean 
of a set of values corresponding to certain times (in two columns). 
I will need to calculate the mean of the values every K seconds and I
 dont know how to divide my Time column or to link the values to their 
corresponding period. 
Could you give me a hand on this? 

Cheers!


From pmaclean2011 at yahoo.com  Fri Oct  4 06:57:32 2013
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Thu, 3 Oct 2013 21:57:32 -0700 (PDT)
Subject: [R] Importing odf file into R
Message-ID: <1380862652.22798.YahooMailNeo@web121703.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/ac3d475d/attachment.pl>

From DMonaghan at gc.cuny.edu  Thu Oct  3 22:39:58 2013
From: DMonaghan at gc.cuny.edu (Monaghan, David)
Date: Thu, 3 Oct 2013 16:39:58 -0400
Subject: [R] Random Projection
Message-ID: <76C496901E46C14899C1D32504ED54778B55E9D446@MAILBOX.gc.cuny.edu>

Hello:

I was wondering, has anyone has encountered an R package that performs random projection/random mapping?  RP is a procedure that is akin to Principal Components Analysis in that it accomplishes dimensionality reduction, but is far more computationally efficient.  I have been searching for some time, but haven't seen anything on CRAN-r yet.  


David Monaghan
Sociology Ph.D. Candidate, CUNY Graduate Center

From smartpink111 at yahoo.com  Thu Oct  3 22:49:56 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 3 Oct 2013 13:49:56 -0700 (PDT)
Subject: [R] String substitution
Message-ID: <1380833396.66540.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
dat$y<- as.character(dat$y)
dat1<- dat
dat2<- dat
library(stringr)
?dat$y[NET]<- substr(word(dat$y[NET],2),1,1)
?dat$y
#[1] "n"???? "n"???? "house" "n"???? "tree" 

#or
for(i in 1:length(NET)){dat1$y[NET[i]]<- "n"}
?dat1$y
#[1] "n"???? "n"???? "house" "n"???? "tree" 
#or
dat2$y[NET]<- gsub(".*(n).*","\\1",dat2$y[NET])
?dat2$y
#[1] "n"???? "n"???? "house" "n"???? "tree" 


A.K.


Hello, 

I am trying to replace strings containing a certain word, I 
first identified the word (in this example "net") with grep, and then I 
need to replace those string with "n". It should be very simple but I 
don't seem to find the solution. 
? 
Example: 

x<-c(5:9) 
y<- c("with net", "with nets", "house", "no nets", "tree") 
dat<-as.data.frame(cbind(x, y) ) 
NET<-grep("net", dat$y) 

# I want y to become ("n", "n", "house", "n", "tree") # 

# I have tried several ways including the following but without success # 

for (i in 1: length(NET)) { 
dat$y[NET[i]]<- "n" } 


Thank you for your help!


From andrew.kemp at sydney.edu.au  Fri Oct  4 00:07:01 2013
From: andrew.kemp at sydney.edu.au (Andrew Kemp)
Date: Thu, 3 Oct 2013 19:07:01 -0300
Subject: [R] How to obtain "doubly robust" means and SEs for different
 levels of a factor in R?
Message-ID: <CAJzS7y5ENC-=QCo8T-MZ=W0cv=xhb8oyDrnG-tLwqfY33EoN0g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131003/b13ab73b/attachment.pl>

From mary.kindall at gmail.com  Fri Oct  4 00:07:24 2013
From: mary.kindall at gmail.com (Mary Kindall)
Date: Thu, 3 Oct 2013 18:07:24 -0400
Subject: [R] Not getting any result from 'gbm'?
Message-ID: <CANStr54zF4cYiw+M+QB1iPtOi_Akx2izAdaTB-H6Lb9fOYLQxA@mail.gmail.com>

In the reproducible example given below, why I am not getting any result
with generalized boosted model (gbm).  Other methods does show me the
desired result.
In the example data file (attached) example.txt, the predictors x3 and x4
are correlated with response Y.



tmpData = read.table("Desktop/example.txt", sep="\t",header=TRUE)
head(tmpData)
fmla = getTheFormulaFromDataFrame(tmpData)
fmla
gbm(fmla, distribution = "bernoulli", data = tmpData) #doesn't work

#All the following works
bagging(fmla,  data=tmpData, control=control, coob=TRUE)
rpart(fmla,  dat=tmpData, method = "class", control=control )
glm(fmla, family="binomial", data = tmpData)


Thanks



-- 
-------------
Mary Kindall
Yorktown Heights, NY
USA
-------------- next part --------------
"x1"	"x2"	"x3"	"x4"	"x5"	"x6"	"x7"	"x8"	"Y"
2.2	9.8	2.9	NA	99	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
0.3	9.5	1.5	NA	100	NA	0	0	0
0.2	NA	1.4	16	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.3	15	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.4	9.8	NA	NA	96	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
NA	8.7	1.7	NA	103	NA	0	0	0
5.8	8	6.7	NA	105	NA	1	0	1
NA	NA	1.3	15	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
1.3	9.1	NA	NA	97	NA	0	0	0
0.4	NA	NA	NA	NA	185	0	0	0
0.9	8.7	4.5	NA	104	NA	0	0	0
1.9	9.1	6.9	NA	98	NA	0	0	0
NA	NA	NA	NA	97	NA	0	0	1
0.9	9.5	NA	NA	98	NA	0	0	1
1.1	9.2	NA	NA	97	NA	0	0	1
0.8	8.9	NA	NA	97	NA	0	0	1
0.6	9.5	NA	NA	102	NA	0	0	1
0.8	NA	691	NA	101	NA	0	0	1
1	NA	603	NA	97	NA	0	0	1
0.4	NA	2.3	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
3.5	9.5	2.3	NA	103	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	NA	1	NA	NA	NA	0	0	0
NA	NA	NA	5.1	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	3.4	11	103	NA	0	0	0
NA	8.6	1.2	1449	92	NA	0	0	1
1.4	9.8	1.5	NA	102	226	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
NA	9.4	2.5	NA	107	NA	0	0	0
0.3	9.2	2	NA	NA	NA	0	0	0
0.4	9.5	1.6	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.3	9.4	1	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	8.8	6.8	NA	101	NA	0	0	1
0.7	8.4	NA	NA	113	NA	0	0	1
0.2	9.1	2.4	15	100	NA	0	0	1
0.5	9.1	3	14	104	NA	0	0	1
NA	8.8	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	8.9	NA	13	NA	NA	0	0	0
0.5	NA	2.5	NA	104	NA	0	0	0
0.3	9.4	2	NA	105	NA	0	0	0
0.3	9	2	NA	105	NA	0	0	0
0.4	9.8	2.2	NA	NA	NA	0	0	0
0.5	9.4	2.7	NA	104	NA	0	0	0
1	9.4	1.6	NA	91	123	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
8.4	NA	NA	NA	104	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	1	0	0
1.5	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.8	NA	NA	NA	NA	NA	1	0	0
0.9	NA	NA	NA	NA	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.6	NA	NA	NA	98	NA	1	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.9	NA	NA	NA	0	0	1
0.4	10.4	NA	NA	93	NA	0	0	0
0.4	9.8	NA	NA	105	NA	0	0	1
0.2	NA	NA	NA	106	NA	0	0	1
0.3	9.3	NA	NA	105	NA	0	0	1
0.5	8.6	NA	NA	98	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	167	0	0	0
NA	NA	NA	NA	NA	173	0	0	0
0.6	9.7	2.4	NA	NA	181	0	0	0
0.9	NA	NA	NA	NA	174	0	0	0
NA	NA	NA	NA	105	170	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.2	14	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	10.3	1.3	NA	NA	280	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
NA	NA	9.4	NA	101	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	1
0.3	NA	2.8	NA	NA	NA	0	0	1
0.3	NA	3.2	NA	NA	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	1
0.2	NA	2.3	12	NA	NA	0	0	1
0.4	NA	2.1	NA	NA	NA	0	0	1
0.3	NA	2.4	NA	NA	NA	0	0	1
0.3	NA	2.3	NA	NA	NA	0	0	1
0.3	9.4	2.6	NA	NA	NA	0	0	1
0.3	NA	3	NA	NA	NA	0	0	1
0.4	NA	3.3	NA	NA	NA	0	0	1
0.5	NA	4.6	NA	NA	NA	0	0	1
0.4	NA	9.3	NA	NA	NA	0	0	1
NA	NA	6.3	NA	NA	NA	0	0	1
0.4	NA	3.8	NA	NA	NA	0	0	1
0.3	NA	2.5	NA	NA	NA	0	0	1
0.6	NA	2.1	NA	NA	NA	0	0	1
0.3	NA	2	NA	104	NA	0	0	1
0.7	NA	2.4	NA	101	NA	0	0	1
0.3	9.1	3.2	NA	NA	NA	0	0	1
NA	NA	3	NA	NA	NA	0	0	1
NA	8.3	3.1	NA	107	NA	0	0	1
NA	9.1	2.6	NA	105	NA	0	0	1
0.3	NA	3.3	NA	NA	NA	0	0	1
NA	9.2	3.6	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	6.2	NA	NA	NA	0	0	1
0.3	NA	6.5	28	97	NA	0	0	1
0.3	9	5.1	NA	98	NA	0	0	1
NA	NA	5.5	NA	104	NA	0	0	1
0.9	8.6	8.7	NA	NA	NA	0	0	1
0.5	NA	2.2	NA	NA	NA	0	0	0
0.7	NA	2.2	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	221	0	0	1
0.8	NA	3	NA	NA	NA	0	0	0
0.6	NA	2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	3.3	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.7	NA	5.7	NA	94	NA	0	0	1
NA	NA	6.8	NA	NA	NA	0	0	1
0.4	NA	10	NA	NA	NA	0	0	1
NA	NA	7.1	NA	NA	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
NA	NA	NA	NA	95	172	0	0	0
0.7	9.1	3.7	NA	107	NA	0	0	1
0.9	9.4	6.1	NA	92	NA	0	1	1
1	9	10	NA	91	NA	0	1	1
NA	NA	4.3	290	101	NA	0	0	0
NA	NA	18	NA	NA	NA	0	0	1
NA	NA	28	NA	NA	NA	0	0	1
0.5	NA	26	NA	NA	NA	0	0	1
0.5	NA	30	NA	NA	NA	0	0	1
0.4	NA	8.6	NA	NA	NA	0	0	1
0.5	NA	7.3	NA	NA	NA	0	0	1
NA	NA	8.8	NA	NA	NA	0	0	1
0.4	NA	10	NA	NA	NA	0	0	1
NA	NA	13	NA	NA	NA	0	0	0
NA	NA	16	NA	NA	NA	0	0	1
NA	NA	17	NA	NA	NA	0	0	1
NA	NA	20	NA	NA	NA	0	0	1
NA	NA	21	NA	NA	NA	0	0	1
0.6	10.1	43	NA	101	210	0	0	1
0.3	10.6	NA	NA	99	318	0	0	0
8.2	9.5	2.8	NA	103	NA	0	0	1
0.3	9.6	NA	NA	106	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	104	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.4	9.1	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	106	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	107	NA	0	0	1
0.3	9.4	NA	NA	104	NA	0	0	1
0.2	9.2	NA	NA	103	NA	0	0	1
0.2	8.9	NA	NA	102	NA	0	0	1
0.3	9.3	NA	NA	104	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.1	9.1	NA	NA	104	NA	0	0	1
0.3	8.4	NA	NA	105	NA	0	0	1
0.2	8.6	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.6	NA	1.7	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	194	0	0	0
2.9	NA	NA	NA	102	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.3	9.3	2.3	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.4	9.8	2.3	NA	NA	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.7	10.2	NA	NA	101	134	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	9.9	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
1	NA	1.8	NA	NA	NA	0	0	0
0.3	9.7	27	NA	100	NA	0	0	0
0.6	9.4	1.6	10	99	NA	0	0	0
1.2	NA	1.5	NA	NA	NA	0	0	0
1.1	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.8	NA	1.7	NA	NA	NA	0	0	0
1.1	NA	1.5	NA	NA	NA	0	0	0
1	NA	1.7	NA	NA	NA	0	0	0
NA	NA	1.7	NA	105	188	0	0	0
0.5	9.7	23	NA	100	NA	0	0	0
0.5	9.6	2.1	NA	94	NA	0	0	0
NA	NA	1.4	11	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.5	9.2	2.2	NA	102	NA	0	0	0
0.4	NA	NA	63	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	1	0	1
NA	9.1	NA	NA	100	NA	0	0	1
0.6	9.1	2	NA	94	NA	0	0	1
0.5	NA	2.3	NA	NA	NA	0	0	0
0.5	9.7	2.1	24	NA	214	0	0	0
0.2	NA	2.8	23	NA	272	0	0	0
0.4	9.4	2.9	16	NA	220	0	0	0
0.3	NA	2.4	29	NA	295	0	0	0
0.2	NA	2	49	NA	NA	0	0	1
NA	NA	NA	37	NA	271	0	0	0
0.4	NA	2.4	103	NA	208	0	0	0
0.3	NA	1.8	42	NA	NA	0	0	0
0.3	9.7	2.9	23	NA	264	0	0	0
0.3	NA	3.7	23	NA	236	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.7	NA	3.1	15	NA	NA	0	0	0
3.7	NA	NA	NA	100	NA	0	0	0
2.6	9.3	NA	NA	102	NA	0	0	0
5.9	NA	NA	NA	103	NA	0	0	0
0.5	NA	NA	32	105	NA	0	0	0
NA	9.5	3.5	NA	NA	NA	0	0	0
NA	9.7	5.4	NA	98	NA	0	0	0
0.5	10.4	NA	294	99	NA	0	0	0
NA	NA	NA	104	NA	NA	0	0	0
NA	9.7	NA	146	104	NA	0	0	0
NA	10.4	108	NA	NA	NA	0	0	0
NA	10	111	NA	NA	NA	0	0	1
NA	9.5	175	NA	NA	NA	0	0	1
NA	NA	184	204	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.4	9	1.7	NA	98	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.7	NA	NA	105	NA	0	0	0
0.3	8.9	NA	NA	108	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	1.9	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	1.7	NA	NA	NA	0	0	1
NA	8.8	NA	NA	105	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	9	NA	NA	104	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	9.5	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	9.4	NA	NA	101	NA	0	0	1
0.4	NA	NA	NA	102	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.2	9	NA	NA	101	NA	0	0	1
0.4	9.8	NA	NA	100	NA	0	0	1
0.4	NA	NA	NA	100	NA	0	0	1
0.3	9.2	NA	NA	98	NA	0	0	1
0.3	9.6	NA	NA	99	NA	0	0	1
0.8	NA	2	NA	NA	NA	0	0	0
0.7	NA	2.2	NA	NA	NA	0	0	0
0.9	NA	2.4	NA	NA	NA	0	0	1
1.2	10.9	2.1	NA	101	192	0	0	0
0.7	NA	2.1	NA	NA	NA	0	0	0
0.6	NA	2.5	NA	NA	NA	0	0	0
1	NA	1.1	NA	NA	NA	0	0	0
1.4	NA	1.3	NA	NA	NA	0	0	0
1.2	NA	1	NA	NA	NA	0	0	0
0.9	NA	1	NA	NA	NA	0	0	0
0.3	10	1.3	1761	97	NA	0	0	0
0.2	NA	1.4	5.8	NA	NA	0	0	0
0.3	NA	NA	8.7	NA	NA	0	0	0
0.4	NA	1.2	10	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.2	9.1	NA	NA	0	0	0
0.3	NA	1.5	7.5	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
1.2	8.3	2.6	NA	95	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	1	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
1.3	8.3	3.6	NA	96	NA	0	0	1
NA	NA	6.6	NA	NA	NA	0	0	0
0.3	8.6	24	NA	103	NA	0	0	0
0.3	9.8	1.5	NA	101	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	3.4	NA	NA	NA	0	0	0
0.7	9.3	7.2	NA	103	NA	0	0	1
0.3	8.7	1.8	NA	105	NA	0	0	0
0.4	9.1	1.4	NA	NA	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	0
0.3	9.4	2.3	NA	104	NA	0	0	1
0.4	8.9	1.8	NA	103	NA	0	0	0
0.3	9.2	1.7	NA	NA	NA	0	0	0
0.3	8.8	2.2	NA	104	NA	0	0	0
0.4	8.8	2.2	NA	107	NA	0	0	1
0.4	8.3	2.1	NA	106	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.4	8.9	2.5	NA	102	NA	0	0	1
0.3	8.6	2.6	NA	106	NA	0	0	1
0.5	8.9	2.8	NA	108	NA	0	0	1
0.3	NA	2.5	NA	NA	NA	0	0	1
0.4	NA	2.8	NA	NA	NA	0	0	1
NA	8.9	2.5	NA	106	NA	0	0	1
0.6	NA	2.3	NA	106	NA	0	0	1
0.6	8.8	2.3	NA	107	NA	0	0	1
0.7	8.6	2.3	NA	105	NA	0	0	1
0.8	8.7	2.1	NA	NA	NA	0	0	1
1	8.8	2.5	NA	NA	NA	0	0	1
0.8	8.7	NA	95	NA	NA	0	0	1
0.9	NA	2.6	NA	106	NA	0	0	1
0.9	NA	3.1	NA	NA	NA	0	0	1
0.9	8.6	3.1	NA	NA	NA	0	0	1
NA	8.8	3.6	NA	105	NA	0	0	1
0.8	NA	3.9	NA	NA	NA	0	0	1
NA	8.7	3.7	NA	106	NA	0	0	1
0.9	8.9	4.2	NA	104	NA	0	0	1
NA	8.7	4.4	NA	105	NA	0	0	1
NA	NA	4.5	NA	NA	NA	0	0	1
1.2	NA	4.4	NA	NA	NA	0	0	1
0.9	8.6	4.8	NA	104	NA	0	0	1
1	8.8	4.5	NA	104	NA	0	0	1
1.1	8.7	4.9	NA	104	NA	0	0	1
1.2	NA	4.9	NA	NA	NA	0	0	1
0.9	NA	4.9	NA	NA	NA	0	0	1
NA	NA	5.2	NA	108	NA	0	0	1
NA	8.7	5.3	NA	106	NA	0	0	1
NA	NA	5.2	NA	107	NA	0	0	1
0.4	NA	4.4	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	0
0.7	8.9	9.1	NA	105	NA	0	0	0
0.9	8.8	NA	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	9.3	2.4	NA	NA	NA	0	0	0
0.9	NA	5	NA	NA	NA	0	0	1
NA	NA	7	NA	NA	NA	0	0	1
1.7	8.8	2.9	NA	NA	NA	0	0	0
1.2	9.2	3.2	NA	NA	227	0	0	0
0.4	10.5	1.7	NA	102	NA	0	0	0
0.3	10	1.3	8.3	NA	NA	0	0	0
4.4	9	NA	NA	103	NA	0	0	1
1.3	10	NA	NA	95	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	3.6	NA	NA	NA	0	0	0
0.4	NA	4.4	NA	102	NA	0	0	0
0.4	NA	4.3	NA	NA	NA	0	0	0
NA	NA	3.8	NA	NA	NA	0	0	0
0.5	9.3	4.1	NA	NA	NA	0	0	0
0.6	NA	4.5	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	9.4	4.6	NA	NA	NA	0	0	0
0.4	9.4	NA	NA	NA	NA	0	0	0
0.4	NA	5.1	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	101	NA	0	0	0
0.3	NA	NA	9.6	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2.3	10	101	NA	0	0	0
0.4	10.4	2.4	20	NA	NA	0	0	0
0.5	10.4	2.3	NA	NA	NA	0	0	0
0.5	9.2	2.2	NA	NA	NA	0	0	0
0.5	9.5	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	8.6	NA	NA	NA	NA	0	0	0
1.1	NA	45	NA	NA	NA	0	1	0
NA	9.2	1	NA	105	NA	0	0	0
NA	NA	1.9	264	NA	NA	0	0	1
0.3	NA	1.7	8.9	NA	201	0	0	0
0.7	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	99	NA	0	0	0
0.5	NA	2.1	NA	NA	NA	0	0	0
0.5	9.8	2.4	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	105	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	3.1	NA	101	NA	0	0	0
0.3	9.3	NA	NA	101	NA	0	0	0
0.5	9.9	11	NA	105	NA	0	0	0
0.5	10	3	NA	101	NA	0	0	1
0.3	9.7	1.7	NA	103	NA	0	0	1
NA	9.2	2.6	NA	NA	NA	0	0	1
NA	9	NA	NA	NA	NA	0	0	1
NA	9	NA	NA	NA	NA	0	0	1
NA	8.7	5.3	NA	NA	NA	0	0	1
0.8	8.5	5.6	NA	101	NA	0	0	1
NA	9.1	5.8	NA	NA	NA	0	0	1
0.9	NA	3.2	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	1
0.2	NA	1.8	NA	NA	NA	0	0	1
0.5	NA	1.5	NA	NA	NA	0	0	1
0.3	9.4	1.7	NA	NA	NA	0	0	1
0.3	NA	1.9	NA	100	NA	0	0	0
0.3	NA	1.7	19	NA	NA	0	0	1
0.6	NA	3.1	NA	NA	NA	0	0	0
0.4	NA	4.2	16	NA	NA	0	0	0
0.5	NA	15	NA	NA	NA	0	0	0
0.6	NA	237	NA	NA	NA	0	0	1
0.7	NA	232	NA	NA	NA	0	0	1
0.6	NA	217	NA	NA	NA	0	0	1
0.8	NA	418	NA	NA	NA	0	0	1
0.7	NA	118	NA	NA	NA	0	0	1
0.8	9	32	NA	NA	NA	0	0	1
0.5	NA	53	NA	NA	NA	0	0	1
0.4	NA	51	NA	NA	NA	0	0	1
0.5	NA	82	NA	NA	NA	0	0	1
1.3	NA	149	NA	NA	NA	0	0	1
4.3	NA	233	NA	91	NA	0	0	1
1.4	8.7	2.3	NA	102	NA	0	0	0
0.6	NA	1	NA	92	NA	0	0	1
NA	NA	NA	NA	103	NA	0	0	0
0.1	NA	1.2	14	NA	NA	0	0	0
0.4	NA	1.9	12.6	NA	NA	0	0	0
0.3	NA	1.5	19	NA	NA	0	0	0
0.4	NA	1.5	16	NA	NA	0	0	0
0.3	NA	1.4	15	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.6	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.7	NA	9.6	NA	101	NA	0	0	0
0.6	NA	1.1	NA	NA	NA	0	0	0
17.9	7.5	3.2	NA	108	NA	0	0	0
NA	NA	4	NA	NA	NA	0	0	0
0.3	NA	4	NA	NA	NA	0	0	0
0.4	NA	3.7	NA	NA	NA	0	0	0
0.2	9.7	66	NA	96	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.4	10.4	2.6	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	2.8	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.3	9.4	NA	54	96	NA	0	0	0
0.2	10.1	NA	NA	95	NA	0	0	1
0.2	9.8	NA	NA	106	NA	0	0	1
NA	9.5	1.1	NA	104	NA	0	0	0
0.3	NA	NA	NA	102	NA	0	0	0
0.5	9.7	1	NA	NA	NA	0	0	0
0.6	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.8	10	1.4	14	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	NA	17	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.6	NA	NA	12	NA	NA	0	0	0
0.6	9.8	NA	NA	NA	NA	0	0	0
0.4	10.1	1.2	NA	NA	NA	0	0	0
0.5	10.2	NA	22	NA	NA	0	0	0
NA	9.7	1	24	NA	NA	0	0	0
NA	NA	NA	28	NA	NA	0	0	0
NA	NA	NA	23	NA	NA	0	0	0
0.8	9.4	NA	NA	100	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	6	NA	NA	NA	0	0	0
0.4	NA	5	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.4	NA	3.1	NA	NA	247	0	0	0
0.4	9.3	1.9	NA	NA	NA	0	0	0
0.5	NA	2.7	NA	NA	243	0	0	0
0.5	NA	2.8	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
17	9.5	7.1	NA	94	NA	1	0	1
0.4	NA	1.6	NA	99	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	1
0.3	9.2	2.4	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	5	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.4	9.3	1.1	NA	NA	NA	0	0	0
0.2	9.3	NA	NA	NA	NA	0	0	0
0.3	9.9	1	NA	NA	NA	0	0	0
0.9	NA	1.2	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	3.6	NA	NA	NA	0	0	0
0.4	NA	5.6	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.6	8.7	1.9	5.4	105	NA	0	0	0
0.2	9	2.2	NA	104	NA	0	0	0
0.5	NA	1.9	NA	103	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.2	9.3	3.1	NA	NA	NA	0	0	0
0.3	NA	3.8	NA	NA	NA	0	0	0
0.2	NA	3.1	NA	NA	NA	0	0	0
0.4	NA	3.5	NA	NA	NA	0	0	0
0.4	NA	3.2	NA	NA	NA	0	0	0
0.4	NA	3.2	NA	NA	NA	0	0	0
NA	NA	4.5	NA	NA	NA	0	0	0
0.3	NA	6.8	NA	NA	NA	0	0	0
0.2	NA	6.3	NA	NA	NA	0	0	0
0.3	NA	6.8	NA	NA	NA	0	0	0
0.3	NA	4.9	NA	NA	NA	0	0	0
0.3	NA	5.5	NA	NA	NA	0	0	0
0.2	NA	6.9	NA	NA	NA	0	0	0
0.2	NA	6.9	NA	NA	NA	0	0	0
0.3	NA	6.8	NA	NA	NA	0	0	0
0.4	NA	7	13	NA	NA	0	0	0
0.5	10.8	7.6	NA	102	240	0	0	0
0.5	NA	6.9	29	NA	NA	0	0	0
NA	NA	7.6	NA	NA	225	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	7.2	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.4	NA	13	NA	NA	NA	0	0	1
NA	NA	NA	NA	104	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
NA	9	NA	NA	109	NA	0	0	0
0.4	NA	NA	NA	99	NA	0	0	0
0.3	NA	NA	NA	99	NA	0	0	0
1.7	9.8	3.1	NA	105	NA	0	0	0
0.6	NA	3	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.7	NA	2.6	NA	NA	NA	0	0	0
0.5	NA	2.9	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
5.6	NA	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	233	0	0	1
NA	NA	NA	NA	NA	204	0	0	0
0.4	9.6	1.5	NA	98	245	0	0	1
NA	NA	1.2	NA	95	202	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	1
0.5	NA	4.3	NA	NA	NA	0	0	0
NA	NA	1.2	NA	103	NA	0	0	0
0.3	NA	1.1	NA	104	NA	0	0	0
1.3	9.4	NA	NA	101	NA	0	0	0
0.2	NA	NA	74	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.4	25	NA	NA	0	0	0
0.6	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	105	NA	0	0	1
0.5	7.4	NA	NA	103	NA	0	0	1
0.7	8.7	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	9.5	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.6	8.7	6.8	NA	103	162	0	0	1
16.6	9.2	7892	NA	93	NA	0	1	1
0.4	NA	NA	14	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
NA	8.3	NA	445	107	NA	0	0	1
0.6	NA	2.2	NA	106	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	9.7	6.8	NA	101	NA	0	0	0
0.4	8.8	1.7	NA	105	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.8	9.6	1.4	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	1
0.4	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.5	NA	3.1	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
1.8	9	7	NA	109	151	0	0	0
0.3	NA	1.1	15	NA	271	0	0	0
0.4	NA	NA	21	NA	NA	0	0	0
0.4	NA	NA	NA	NA	237	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
11.1	8.7	NA	NA	106	NA	0	0	0
0.6	9.8	NA	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	9	NA	NA	103	NA	0	0	0
NA	NA	NA	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	9.3	NA	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	8.6	NA	NA	102	NA	0	0	0
0.5	8.3	NA	NA	104	NA	0	0	0
0.7	8.3	NA	NA	107	NA	0	0	0
3.3	NA	4.9	NA	103	NA	0	0	0
0.8	9.4	NA	NA	98	NA	0	0	1
0.8	9.2	NA	NA	104	NA	0	0	1
9	NA	NA	NA	NA	NA	0	0	1
0.8	9	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	8.7	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	8.9	NA	NA	99	NA	0	0	1
0.9	8.5	NA	NA	95	NA	0	0	1
4.1	8.5	NA	NA	94	NA	0	1	1
0.5	NA	NA	NA	103	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.3	9.3	4.1	NA	NA	435	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.5	9.6	2.2	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	NA	209	103	NA	0	0	0
NA	8	5.5	NA	108	NA	0	0	1
0.3	NA	NA	NA	100	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.4	NA	1.4	NA	96	NA	0	0	0
0.3	8.5	1.5	NA	108	NA	0	0	0
0.5	10.6	NA	NA	NA	NA	0	0	0
7.7	10.2	NA	NA	98	NA	1	0	1
0.3	9.7	23	NA	NA	NA	0	0	1
0.2	9.6	65	NA	NA	NA	0	0	1
0.3	8.9	141	NA	NA	NA	0	0	1
0.3	NA	179	NA	NA	NA	0	0	1
0.4	10	240	NA	100	NA	0	0	1
0.3	NA	234	NA	NA	NA	0	0	1
0.6	NA	2.2	NA	NA	NA	0	0	0
0.8	9.2	NA	9.2	98	312	0	0	0
0.4	NA	3.1	6	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.8	NA	1.9	NA	NA	NA	0	0	0
1	NA	1.1	NA	NA	NA	0	0	0
0.8	8.9	1.2	NA	NA	NA	0	0	0
14.8	NA	3.4	NA	99	NA	0	0	1
0.3	8.6	NA	NA	107	NA	0	0	0
NA	NA	5.4	NA	108	NA	0	0	0
2.3	8.7	NA	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	103	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.6	8.8	2.7	NA	NA	202	0	0	0
0.3	9.6	NA	NA	NA	NA	0	0	0
0.3	9.6	1.9	NA	NA	NA	0	0	0
0.3	9.4	1.7	NA	NA	NA	0	0	0
0.2	10.8	15	NA	99	NA	0	0	0
0.9	9.9	10	NA	99	NA	0	0	1
NA	9.6	5.9	NA	NA	NA	0	0	0
NA	9.1	4.8	NA	106	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.3	NA	3.8	NA	NA	NA	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
NA	9.2	3.5	9.5	100	NA	0	0	0
NA	NA	24	NA	NA	NA	0	0	0
NA	NA	49	NA	NA	NA	0	0	1
2.7	NA	NA	NA	107	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.7	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.8	NA	NA	NA	103	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	106	NA	0	0	0
0.9	NA	1	NA	NA	NA	0	0	0
0.8	NA	NA	12	105	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	101	NA	0	0	0
0.5	9.4	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.2	9.5	1.6	NA	107	NA	0	0	0
0.3	9	2.1	NA	NA	NA	0	0	1
0.2	8.7	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	9.1	NA	NA	NA	NA	0	0	1
NA	9.2	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	102	NA	0	0	1
0.3	9.1	NA	NA	103	NA	0	0	1
0.2	8.9	NA	NA	105	NA	0	0	1
0.3	9.1	NA	NA	105	NA	0	0	1
0.2	NA	NA	NA	105	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	104	NA	0	0	1
0.3	9.3	NA	NA	106	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.1	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	107	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	9.8	1.3	NA	103	231	0	0	0
NA	9	1.3	NA	104	235	0	0	0
0.7	NA	NA	10	NA	NA	0	0	0
0.6	NA	NA	9.1	NA	NA	0	0	0
0.4	NA	NA	11	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.6	10.4	NA	NA	NA	NA	0	0	0
0.4	9.6	NA	9.6	NA	NA	0	0	0
0.2	9.4	38	NA	105	218	0	0	0
NA	NA	59	NA	NA	NA	0	0	0
NA	NA	69	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.6	9.9	1	NA	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
0.2	9.4	NA	NA	NA	NA	0	0	0
0.3	9.9	NA	NA	NA	NA	0	0	0
NA	9.2	4.8	NA	NA	NA	0	0	0
1.4	9.1	NA	NA	105	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	2.5	19	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
0.3	9.9	1	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
NA	9.7	2	NA	105	229	0	0	0
NA	9.5	1.6	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	1	0	0
4.6	NA	NA	NA	101	NA	0	0	0
0.9	NA	NA	NA	102	NA	1	0	0
15.1	9.8	1.4	NA	101	264	1	0	1
1	9.5	NA	NA	98	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
NA	9	NA	NA	106	NA	0	0	0
NA	9.7	NA	NA	105	NA	0	0	0
0.5	9.7	NA	NA	NA	NA	0	0	0
0.4	8.1	NA	NA	105	NA	0	0	0
0.5	NA	3.4	NA	99	NA	0	0	0
0.3	NA	1.1	NA	NA	265	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	103	242	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
NA	9.3	1.2	NA	NA	NA	0	0	0
0.5	9.2	3546	1094	97	NA	0	0	0
NA	NA	2.2	20	NA	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	165	0	0	0
0.3	NA	639	NA	101	NA	0	0	1
NA	NA	513	NA	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	107	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	2.2	NA	NA	NA	0	0	0
0.7	9.5	NA	NA	99	NA	0	0	0
0.5	9.8	1.1	29	NA	NA	0	0	0
0.5	9.5	NA	NA	NA	NA	0	0	0
NA	NA	3.9	NA	NA	NA	0	0	0
1.5	9.6	9.8	NA	96	NA	0	0	1
NA	NA	1	NA	NA	NA	0	0	0
NA	NA	1.1	27	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	101	NA	0	0	0
0.4	9.9	2.3	NA	103	NA	0	0	0
0.3	NA	NA	NA	104	197	0	0	0
NA	11.1	NA	NA	NA	NA	0	0	0
0.4	10.8	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.1	NA	NA	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	9.2	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	9.1	NA	NA	105	NA	0	1	0
NA	8	1.2	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	106	NA	0	0	1
0.4	8.6	NA	NA	103	NA	0	0	1
0.5	NA	1.3	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	9.6	NA	NA	105	NA	0	0	1
0.6	10.3	NA	NA	105	NA	0	0	1
0.4	9.4	1.6	NA	103	NA	0	0	1
0.5	9.9	NA	NA	101	NA	0	0	1
0.4	9.3	NA	NA	109	NA	0	0	1
0.3	9.1	NA	NA	108	212	0	0	0
0.2	9.4	NA	NA	107	214	0	0	0
0.3	NA	NA	NA	108	NA	0	0	0
0.2	9.7	NA	NA	106	NA	0	0	0
0.2	10	NA	NA	105	NA	0	0	0
0.2	9.2	NA	NA	108	NA	0	0	0
0.2	9.3	NA	NA	107	NA	0	0	0
0.2	9.3	NA	NA	105	NA	0	0	0
0.2	NA	NA	NA	108	NA	0	0	0
0.3	9.1	NA	NA	109	NA	0	0	0
NA	9.3	NA	NA	107	NA	0	0	1
0.3	9.2	NA	NA	107	NA	0	0	1
NA	9.1	NA	NA	107	NA	0	0	1
0.2	9.6	NA	NA	104	NA	0	0	1
0.3	9.2	NA	NA	107	NA	0	0	1
0.4	9.1	NA	NA	106	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	9.3	NA	NA	107	NA	0	0	1
0.5	9.3	NA	NA	108	NA	0	0	1
0.5	9.1	NA	NA	108	NA	0	0	1
0.4	9.6	NA	NA	104	NA	0	0	1
0.4	9.4	NA	NA	107	NA	0	0	1
0.9	9.3	NA	NA	103	NA	0	0	1
0.5	NA	NA	NA	103	NA	0	0	1
0.4	9.4	NA	NA	107	NA	0	0	1
0.3	9.5	NA	NA	104	NA	0	0	1
0.3	9	NA	NA	110	NA	0	0	1
0.3	NA	NA	NA	107	NA	0	0	1
0.4	8.6	NA	NA	NA	NA	0	0	1
0.7	8.7	NA	NA	104	NA	0	0	1
5.6	8.8	NA	NA	100	NA	0	0	1
0.3	NA	NA	NA	105	NA	0	0	0
0.4	9.1	2.5	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	8.5	NA	NA	103	NA	0	0	0
0.4	8.5	NA	8.3	104	NA	0	0	0
0.7	7.7	6.7	NA	99	NA	0	0	0
0.4	7.3	5.4	NA	103	NA	0	0	0
0.6	8.6	2.9	NA	100	NA	0	0	0
0.4	8.7	1.9	NA	102	NA	0	0	1
0.4	9.4	2	NA	105	NA	0	0	0
0.6	8.9	1.5	NA	96	NA	0	0	0
NA	NA	NA	NA	95	NA	0	0	0
0.7	8.8	2	NA	103	NA	0	0	0
0.4	8.9	1.7	NA	99	NA	0	0	0
0.5	8	1.6	NA	94	NA	0	0	0
0.4	9.4	NA	NA	100	NA	0	0	0
0.6	9.5	1.8	NA	97	NA	0	0	0
0.3	9.1	2.4	NA	103	187	0	0	0
NA	NA	NA	NA	102	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
NA	8.8	2.1	NA	98	88	0	0	0
0.3	NA	2.5	NA	102	NA	0	0	0
0.7	NA	2.4	NA	NA	NA	0	0	0
NA	NA	2.3	NA	NA	222	0	0	0
0.3	7.5	66	NA	98	NA	0	0	0
2.1	NA	2	NA	101	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	9.6	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	1
1	NA	2.7	NA	NA	NA	0	1	1
0.7	NA	2.2	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.4	NA	NA	NA	0	0	0
NA	NA	2.7	15	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	1
0.1	NA	2.3	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	0
NA	9.9	1.9	NA	NA	NA	0	0	0
21.2	9.8	14	NA	97	NA	0	0	1
0.4	9.1	1.6	NA	102	NA	0	0	1
0.3	9.4	1.7	NA	102	NA	0	0	1
0.3	NA	1.7	25	101	NA	0	0	1
0.3	8.9	2	NA	NA	NA	0	0	0
0.3	9.1	4	18	105	NA	0	0	1
0.4	9.1	5.8	NA	104	NA	0	0	1
0.4	9.2	7.5	NA	NA	NA	0	0	1
0.3	9.1	12	NA	103	NA	0	0	1
0.3	9.5	21	NA	NA	NA	0	0	1
0.4	9.4	32	NA	NA	NA	0	0	1
0.4	9	52	122	NA	NA	0	0	1
0.4	9.6	79	NA	NA	NA	0	0	1
0.6	NA	92	NA	NA	NA	0	0	1
0.5	10	96	280	NA	NA	0	0	1
0.7	NA	63	154	NA	NA	0	0	1
0.5	9.3	42	69	NA	NA	0	0	1
0.3	NA	31	38	NA	NA	0	0	1
0.5	10	54	55	NA	NA	0	0	1
0.6	NA	82	78	NA	NA	0	0	1
0.7	NA	93	101	NA	NA	0	0	1
0.5	NA	107	141	NA	NA	0	0	1
0.7	9.1	147	218	NA	NA	0	0	1
1.4	9.4	222	307	100	NA	0	0	1
1.7	NA	259	392	98	NA	0	0	1
4.4	9.1	641	885	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	13	NA	NA	0	0	0
0.8	NA	1	NA	NA	NA	0	0	0
1.1	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
1.2	NA	1.5	NA	NA	NA	0	0	0
1.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.8	NA	1.5	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	1
0.4	NA	2	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
1.8	8.9	1.9	NA	107	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.1	NA	NA	NA	105	NA	0	0	0
0.4	NA	NA	NA	NA	130	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
0.3	NA	1.9	21	NA	NA	0	0	0
0.2	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	2	NA	102	214	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.3	8.8	2	NA	NA	NA	0	0	0
0.2	NA	1.8	NA	NA	NA	0	0	0
NA	8.3	NA	NA	NA	164	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	9.7	1	NA	102	NA	0	0	0
1.5	8.6	4.6	NA	109	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	3.2	NA	NA	NA	0	0	1
0.5	NA	2.2	NA	NA	NA	0	0	0
4.7	NA	4.5	NA	NA	NA	0	0	0
7.5	NA	4.8	NA	101	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	2.7	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	3.8	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
NA	NA	4	NA	NA	NA	0	0	0
1.2	NA	NA	NA	NA	NA	1	0	0
0.3	9.9	NA	NA	104	NA	0	1	0
0.3	NA	NA	NA	NA	NA	1	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.5	9.2	NA	NA	107	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.4	9.2	NA	NA	106	NA	0	1	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.2	8	NA	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	101	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	10	NA	NA	0	0	0
NA	9	1.4	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.2	8.8	1.1	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.4	8.6	1.6	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	9.7	1.4	NA	103	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	NA	11	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.2	9	1.5	NA	103	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	9	NA	NA	NA	NA	0	0	0
0.3	10.1	3.5	NA	NA	NA	0	0	1
0.3	NA	3.4	NA	NA	NA	0	0	1
NA	NA	3.3	NA	NA	NA	0	0	1
NA	NA	2.8	NA	NA	NA	0	0	0
0.4	9.4	3.3	NA	NA	NA	0	0	0
0.6	NA	3.4	NA	NA	NA	0	0	0
0.5	NA	3.2	NA	NA	NA	0	0	0
0.6	NA	3.9	NA	NA	NA	0	0	0
0.6	NA	4.3	NA	NA	NA	0	0	1
0.4	NA	4.1	NA	NA	NA	0	0	1
0.1	9.9	NA	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
0.3	9.9	1.1	NA	NA	NA	0	0	0
0.3	10.2	NA	NA	NA	NA	0	0	0
0.2	9.7	1.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	8.8	23	NA	107	218	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	171	0	0	0
0.6	NA	3.1	NA	NA	NA	0	0	0
0.7	NA	4	NA	NA	NA	0	0	0
0.6	NA	3.2	NA	NA	NA	0	0	0
0.7	NA	2.7	NA	NA	NA	0	0	0
NA	10.4	2.4	NA	NA	NA	0	0	0
0.7	NA	2.1	NA	NA	NA	0	0	0
0.8	NA	2.3	NA	NA	NA	0	0	0
0.8	NA	2.4	NA	NA	NA	0	0	1
0.8	NA	3.7	NA	NA	NA	0	0	1
0.7	NA	2.9	NA	NA	NA	0	0	1
0.8	NA	2.9	NA	NA	NA	0	0	0
0.9	NA	2.7	NA	NA	NA	0	0	0
0.3	9.5	NA	NA	103	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	8.4	NA	101	NA	0	0	1
2	10	5.6	NA	100	NA	0	0	1
0.8	NA	1.5	NA	NA	NA	0	0	0
0.7	8.8	2.2	NA	108	NA	0	0	0
0.3	NA	7.3	11	NA	NA	0	0	0
0.4	NA	6.5	NA	NA	NA	0	0	1
0.5	NA	5	9.9	NA	NA	0	0	0
NA	10.5	NA	16	NA	NA	0	0	1
0.9	9	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.7	9.9	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	NA	5.6	NA	NA	195	0	0	1
1.2	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	155	0	0	0
0.6	7.6	3.9	NA	97	NA	0	0	1
0.3	9.4	NA	10	107	NA	0	0	0
0.6	NA	NA	8.9	NA	NA	0	0	0
0.6	NA	1.7	NA	NA	NA	0	0	0
0.6	NA	1.7	22	103	NA	0	0	0
0.3	NA	1.6	14	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
NA	NA	NA	5.2	NA	NA	0	0	0
0.3	NA	10	NA	NA	NA	0	0	0
NA	NA	2	NA	106	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.7	12	NA	NA	0	0	0
0.4	NA	2.4	7.4	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.3	13	NA	NA	0	0	0
0.4	NA	1.9	16	NA	NA	0	0	0
NA	NA	2.4	NA	NA	292	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	2.5	6.8	NA	NA	0	0	0
0.2	NA	2	8.7	NA	NA	0	0	0
0.1	NA	1.9	NA	NA	NA	0	0	0
0.3	9.6	NA	217	98	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
1.7	8.7	4	NA	102	NA	0	0	1
0.5	NA	4	NA	104	NA	0	0	1
2	8.3	NA	NA	NA	NA	0	0	1
3.3	8.6	NA	NA	102	NA	0	0	1
4.9	9.6	NA	NA	94	NA	0	0	1
0.7	9.1	4.2	NA	100	175	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
1.2	9.9	7.2	NA	102	139	0	0	0
NA	NA	NA	8.4	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	105	NA	1	0	1
0.5	7.8	3.2	NA	108	NA	0	0	1
0.5	8.2	3.2	NA	110	NA	0	0	1
1.4	8.5	3.2	NA	100	NA	0	0	1
0.3	NA	2.9	NA	101	NA	0	0	0
0.4	9.4	11	NA	104	284	0	0	0
0.2	NA	57	NA	NA	NA	0	0	1
NA	NA	NA	NA	103	NA	0	0	0
NA	NA	2.3	7.5	NA	NA	0	0	0
0.3	8.8	15	NA	100	NA	0	0	1
0.2	NA	1.8	NA	101	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
NA	10.5	NA	NA	NA	NA	0	0	0
NA	10.4	NA	NA	101	NA	0	0	0
NA	10.1	NA	NA	99	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	8.6	2.4	NA	107	NA	0	0	0
0.6	NA	6.9	NA	NA	NA	0	0	0
0.5	NA	6.4	NA	NA	NA	0	0	0
NA	NA	7.3	NA	NA	NA	0	0	0
NA	8.8	5.2	NA	NA	NA	0	0	0
0.5	9.6	1.7	NA	NA	NA	0	0	0
0.8	NA	1.7	NA	NA	NA	0	0	0
0.8	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.7	NA	1.8	NA	NA	NA	0	0	0
0.8	NA	6.4	NA	NA	NA	0	0	0
0.7	NA	6.5	NA	NA	NA	0	0	0
1.8	8.8	8.6	NA	93	67	0	0	0
0.4	NA	2.5	15	NA	NA	0	0	1
0.1	NA	5.2	28	NA	NA	0	0	1
0.4	NA	2.3	NA	NA	NA	0	0	1
0.3	NA	2.8	NA	NA	NA	0	0	1
0.4	NA	5.3	NA	NA	NA	0	0	1
NA	NA	6.9	NA	NA	NA	0	0	1
0.5	NA	5.9	NA	NA	NA	0	0	1
0.7	NA	6.2	NA	NA	NA	0	0	1
0.9	NA	7	NA	NA	NA	0	0	1
NA	NA	6.8	NA	NA	NA	0	0	1
0.4	NA	10	NA	NA	NA	0	0	1
0.4	NA	13	NA	NA	NA	0	0	1
0.4	NA	8.8	NA	NA	NA	0	0	1
0.4	NA	4.7	NA	NA	NA	0	0	1
0.4	NA	4.3	NA	NA	NA	0	0	1
NA	NA	5.5	NA	NA	NA	0	0	1
0.3	NA	6.4	NA	NA	NA	0	0	1
0.2	NA	7.9	NA	NA	NA	0	0	1
0.3	NA	6.7	NA	NA	NA	0	0	1
0.3	NA	6.3	NA	NA	NA	0	0	1
0.3	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	141	0	0	0
0.6	NA	2.6	NA	NA	NA	0	0	0
0.4	9.9	2.8	NA	NA	NA	0	0	0
0.7	9.8	3.2	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.2	8.1	1.1	158	110	NA	0	0	1
0.2	NA	NA	319	104	NA	0	0	1
0.9	8.9	35	NA	95	NA	0	0	1
0.4	NA	NA	NA	104	NA	0	0	1
0.3	9.1	NA	NA	103	NA	0	0	1
NA	NA	17	NA	NA	NA	0	0	1
NA	8.9	NA	NA	104	NA	0	0	1
NA	NA	47	NA	NA	NA	0	0	1
NA	9.3	39	NA	NA	NA	0	0	1
0.4	9.6	26	NA	NA	NA	0	0	1
NA	9.4	22	NA	NA	NA	0	0	1
NA	9.6	NA	NA	NA	NA	0	0	1
NA	9.9	27	NA	NA	NA	0	0	1
NA	9.8	NA	NA	NA	NA	0	0	1
NA	9.7	37	NA	NA	NA	0	0	1
NA	9.8	45	NA	NA	NA	0	0	1
0.3	NA	73	NA	NA	NA	0	0	1
NA	8.9	59	NA	NA	NA	0	0	1
0.4	9.7	53	NA	NA	NA	0	0	1
0.3	NA	43	NA	NA	NA	0	0	1
0.3	NA	38	NA	NA	NA	0	0	1
0.3	NA	45	NA	NA	NA	0	0	1
0.4	9.3	48	NA	NA	NA	0	0	1
NA	9.6	49	NA	NA	NA	0	0	1
NA	9.1	41	NA	105	NA	0	0	1
NA	8.8	23	NA	NA	NA	0	0	1
NA	NA	21	NA	NA	NA	0	0	1
NA	NA	27	NA	NA	NA	0	0	1
NA	NA	31	NA	NA	NA	0	0	1
NA	NA	39	NA	NA	NA	0	0	1
0.4	NA	50	NA	NA	NA	0	0	1
0.7	8.4	8.6	NA	95	NA	0	0	0
NA	NA	8	NA	100	NA	0	0	1
0.5	9.4	NA	NA	97	NA	0	0	0
NA	8.6	NA	NA	97	NA	0	0	1
0.3	NA	2.2	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	9.9	5.1	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.5	9.5	2.2	NA	NA	NA	0	0	0
0.7	9.8	1.9	NA	104	NA	0	0	0
0.6	NA	2	NA	NA	NA	0	0	0
0.6	NA	2.2	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
0.5	10.1	1.3	6.4	105	242	0	0	0
0.5	9.9	1.5	NA	105	231	0	0	0
0.4	9.8	1.2	NA	105	208	0	0	0
0.3	NA	1.2	NA	104	211	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
NA	10.1	NA	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.8	9.8	1.4	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
NA	8.5	NA	NA	101	NA	0	0	0
0.2	NA	1.8	NA	NA	NA	0	0	0
1	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	9.6	2	NA	101	NA	0	0	0
NA	9.3	5.2	7.5	NA	NA	0	0	0
1.2	8.6	8.2	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	8.4	NA	NA	98	NA	1	0	0
0.5	NA	NA	NA	99	NA	0	0	0
0.3	NA	2.3	12	NA	NA	1	0	0
0.3	9	1.6	NA	102	NA	0	0	0
0.4	9.6	NA	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	100	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.7	NA	3.1	NA	NA	NA	0	0	0
0.5	NA	NA	NA	103	NA	0	0	0
0.4	8.9	NA	NA	108	NA	0	0	0
1.6	8.2	NA	201	100	NA	0	0	0
0.3	9.1	1.6	NA	103	NA	0	0	0
0.3	9.3	1.6	NA	NA	NA	0	0	0
0.4	NA	290	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	9.4	1.5	NA	103	229	0	0	0
0.5	NA	1.3	17	NA	NA	0	0	0
0.5	NA	1.7	16	NA	192	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	14	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	5.6	NA	NA	NA	0	0	0
NA	NA	7	NA	NA	NA	0	0	1
NA	NA	6.1	NA	NA	176	0	0	1
0.2	9	4.6	NA	NA	NA	0	0	1
NA	9.1	5.3	NA	NA	NA	0	0	0
NA	NA	5.1	NA	NA	NA	0	0	0
NA	9.1	5.1	NA	NA	NA	0	0	0
NA	NA	5.1	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.3	9.9	2	NA	105	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.3	9.7	2.9	NA	NA	NA	0	0	0
0.4	9.8	2.9	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	101	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	8	NA	9.5	109	NA	0	0	0
2.6	NA	171	NA	NA	NA	0	0	1
0.4	10.5	2.7	NA	NA	NA	0	0	0
0.5	NA	2.8	NA	NA	280	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	3.2	NA	NA	NA	0	0	0
0.5	9.5	NA	NA	NA	NA	0	0	1
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	9.6	1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	192	0	0	1
0.5	NA	NA	NA	NA	185	0	0	1
0.3	NA	NA	NA	104	NA	0	0	0
0.3	NA	NA	NA	104	NA	0	0	1
0.3	9.2	NA	19	NA	195	0	0	0
0.5	NA	NA	24	NA	188	0	0	0
5.1	9.6	NA	NA	99	NA	0	0	1
0.4	8.9	NA	NA	99	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	8.3	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	8.9	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	102	NA	1	0	1
0.6	NA	NA	NA	110	NA	0	0	1
NA	NA	NA	NA	102	NA	0	0	1
0.7	NA	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	102	NA	0	0	1
0.5	NA	1.4	NA	NA	NA	0	0	0
9.4	8.7	2.1	NA	112	NA	0	0	1
0.4	NA	NA	NA	102	206	0	0	0
1.2	NA	NA	NA	95	NA	0	0	1
0.7	8.5	NA	NA	99	NA	0	0	1
0.3	NA	4.8	NA	NA	NA	0	0	0
0.4	NA	3.6	NA	NA	NA	0	0	1
0.2	NA	3.8	NA	NA	NA	0	0	0
0.3	NA	1	NA	105	NA	0	0	0
0.4	9.7	NA	NA	NA	NA	0	0	0
NA	NA	1.1	29	NA	NA	0	0	0
0.3	9.3	1.2	NA	NA	NA	0	0	0
0.3	9.2	1.6	NA	102	NA	0	0	0
0.6	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	1.6	NA	NA	NA	0	0	0
2.4	9.3	6.2	NA	109	182	0	0	1
1.7	NA	1	NA	NA	NA	0	0	0
1.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.1	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	3.8	9.6	NA	NA	0	0	0
0.4	NA	3.9	NA	NA	NA	0	0	0
0.9	8.7	NA	NA	105	NA	0	0	0
0.7	NA	5	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	3.8	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	3.5	NA	NA	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
0.4	NA	3.6	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	4.3	NA	NA	NA	0	0	0
0.3	NA	4.2	NA	NA	NA	0	0	0
NA	NA	5.3	NA	NA	NA	0	0	1
0.3	8.8	10	NA	106	NA	0	0	1
0.4	8.2	NA	NA	102	NA	0	0	0
1.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
NA	9.1	1.8	NA	NA	166	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
0.2	9.8	2.7	NA	101	NA	0	0	0
0.3	9.3	3	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.5	9.1	1.7	NA	NA	NA	0	0	0
0.5	NA	1.1	5.8	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	1	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	11	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	5	NA	NA	NA	0	0	0
0.3	NA	4.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	3.9	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	10.3	1.4	NA	NA	150	0	0	0
0.3	9.4	1.1	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
NA	9.8	NA	NA	NA	NA	0	0	0
0.6	9.4	NA	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.4	9.2	1.6	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	1
0.6	8.6	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	9.9	NA	NA	99	NA	0	0	1
0.5	9.6	NA	NA	97	NA	0	0	1
0.5	9.1	NA	NA	98	NA	0	0	1
0.5	8.3	NA	NA	106	NA	0	0	1
NA	NA	3	NA	NA	NA	0	0	0
0.4	9.6	3.5	NA	NA	NA	0	0	0
0.3	9.6	2.1	NA	103	NA	0	0	1
0.4	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	NA	NA	102	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	17	NA	NA	0	0	0
0.5	NA	NA	NA	101	NA	0	0	0
NA	NA	1.5	18	101	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.3	9.5	1.2	NA	NA	NA	0	0	0
0.5	9.5	3.6	NA	NA	NA	0	0	1
0.3	8.4	NA	NA	94	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
9.4	7.9	2.2	146	108	NA	0	0	1
1	9.8	NA	231	87	NA	0	0	1
0.5	9.4	NA	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	248	0	0	0
0.6	NA	1.1	NA	NA	292	0	0	0
0.5	NA	1.3	NA	NA	268	0	0	1
0.7	NA	NA	NA	NA	293	0	0	0
0.8	NA	1.1	NA	NA	210	0	0	0
0.7	NA	1.1	NA	105	210	0	0	0
0.5	NA	NA	NA	99	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.8	9.4	2.3	30	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.6	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	250	0	0	0
0.6	NA	1.7	NA	NA	234	0	0	0
0.6	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	251	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	NA	12	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.2	9.2	2.1	NA	103	NA	0	0	0
0.2	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	5.3	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	3.7	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.5	NA	2	16	NA	196	0	0	0
0.5	NA	4.9	44	NA	201	0	0	1
0.4	NA	NA	28	NA	NA	0	0	1
0.4	9.7	1.3	20	102	NA	0	0	1
0.5	NA	1.7	28	102	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	9.3	11	39	106	NA	0	0	1
0.3	NA	2	NA	NA	NA	0	0	0
0.4	NA	2	30	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	3.1	NA	NA	NA	0	0	0
0.4	NA	2	NA	96	NA	0	0	0
0.2	8.8	3.2	31	NA	NA	0	0	1
0.2	8.4	5.9	NA	102	NA	0	0	1
0.2	NA	4.8	NA	NA	NA	0	0	1
NA	NA	3.7	NA	NA	NA	0	0	0
NA	NA	5.7	NA	NA	NA	0	0	1
0.4	NA	2.1	NA	NA	NA	0	0	0
0.5	NA	2.8	NA	100	NA	0	0	0
0.6	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.5	NA	3	NA	NA	NA	0	0	0
1.8	9.5	4.3	NA	103	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1	NA	100	181	0	0	0
0.6	NA	9.3	NA	106	NA	0	0	0
0.9	NA	4.5	NA	NA	223	0	0	0
0.8	10	4.6	NA	NA	NA	0	0	0
0.7	NA	4.5	NA	NA	NA	0	0	0
1.1	8.7	1.1	NA	101	NA	0	0	1
0.4	9.1	1.7	NA	102	NA	0	0	1
0.4	NA	1.3	11	NA	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.9	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1.1	NA	NA	NA	0	0	0
0.7	NA	1.3	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	1
0.4	NA	1.8	NA	NA	NA	0	0	1
0.4	NA	1.9	NA	NA	NA	0	0	1
0.3	NA	2.2	NA	NA	NA	0	0	1
NA	9.6	NA	NA	102	202	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	205	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
NA	8.8	NA	NA	104	218	0	0	0
0.2	NA	1.5	19	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
NA	9.4	1.5	NA	102	160	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
0.2	NA	NA	NA	100	NA	0	1	0
0.2	NA	NA	NA	101	NA	1	1	0
0.2	NA	NA	NA	98	NA	0	1	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
1.2	8.7	4.2	NA	107	NA	0	0	1
0.4	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
0.3	9.7	2.1	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	1
0.2	NA	2	NA	NA	NA	0	0	1
0.9	NA	3.4	NA	97	NA	0	0	0
0.3	8.9	2.5	10	97	NA	0	0	0
0.3	NA	10	NA	NA	NA	0	0	1
0.3	8.7	5.7	NA	103	NA	0	0	1
0.2	NA	4.2	13	NA	NA	0	0	1
NA	NA	7.8	NA	NA	NA	0	0	1
0.4	NA	6.7	NA	NA	NA	0	0	0
0.3	NA	6.8	NA	NA	NA	0	0	0
0.3	7.9	4.9	NA	102	NA	0	0	1
17.1	8.9	1.8	NA	104	NA	1	0	1
1.1	9.3	2.8	NA	95	NA	0	0	1
0.4	9.1	1.8	NA	103	NA	0	0	1
0.6	8.7	1.7	NA	101	NA	0	0	1
0.4	9.1	2.2	NA	100	NA	0	0	1
0.4	9.2	2.2	NA	100	NA	0	0	1
0.5	9.2	4.3	NA	96	NA	0	0	1
0.4	8.7	7.2	NA	100	NA	0	0	1
0.4	8.5	8.7	NA	96	NA	0	0	1
0.4	8.2	13	NA	95	NA	0	0	1
NA	NA	14	NA	NA	NA	0	0	1
0.2	8.7	11	NA	98	NA	0	0	1
0.2	8.4	9.9	NA	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	8.5	2.2	NA	101	NA	0	0	0
0.5	NA	1.3	NA	NA	184	0	0	0
0.4	NA	1.1	NA	NA	200	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	216	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.5	8.5	1.9	NA	94	166	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.1	NA	1.8	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
NA	NA	3.2	NA	NA	NA	1	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	243	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	7	NA	NA	322	0	0	0
0.4	NA	7.3	NA	NA	NA	0	0	0
0.6	9.6	NA	NA	103	149	0	0	0
0.2	10.3	4.1	NA	103	NA	0	0	0
NA	10	8	NA	NA	NA	0	0	0
0.2	9.5	NA	NA	NA	NA	0	0	0
0.7	NA	6.8	NA	NA	NA	0	0	0
0.5	NA	7.9	NA	100	NA	0	0	0
0.6	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	266	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	222	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
1	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	0	0	0
1.3	NA	2.5	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	105	NA	0	0	0
0.3	NA	NA	NA	109	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	1
0.4	NA	1.8	NA	NA	NA	0	0	1
0.3	NA	2.4	NA	NA	NA	0	0	1
0.3	8.7	1.5	NA	102	NA	0	0	1
0.3	NA	1.2	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	9.1	NA	NA	100	NA	0	0	1
0.4	NA	NA	NA	98	NA	0	0	1
0.7	NA	NA	NA	96	NA	0	0	1
0.2	9.2	3.5	NA	NA	NA	0	0	0
0.5	9.2	2.6	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	4	NA	103	NA	0	0	0
0.6	NA	3.6	NA	105	NA	0	0	0
2.3	7.5	NA	NA	99	NA	0	0	1
0.2	NA	6.1	NA	NA	NA	0	0	0
0.7	7.3	NA	14	111	NA	0	0	0
0.7	7.8	NA	14	112	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	2.2	4.2	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	3.7	NA	NA	NA	0	0	0
0.3	NA	2.7	6.2	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
NA	9.3	1.1	NA	101	193	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
NA	9.5	NA	22	103	NA	0	0	0
0.4	NA	2.1	NA	102	NA	0	0	1
0.4	NA	NA	NA	104	NA	0	1	1
0.3	NA	2.6	NA	105	NA	0	0	1
0.5	9.9	2.5	NA	106	NA	0	0	1
0.4	NA	3.1	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	1	1
0.5	NA	2.8	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	95	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.5	7.3	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.6	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.5	9.7	NA	NA	89	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	282	0	0	0
0.9	NA	1	NA	NA	NA	0	0	0
0.7	NA	1.1	8.1	NA	NA	0	0	0
0.4	NA	1.4	8	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
8.7	8.6	9.3	NA	84	NA	0	0	0
0.6	8.7	NA	NA	101	NA	0	0	0
0.4	9.8	1.6	NA	99	225	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	205	0	0	0
18.1	9.6	12	561	98	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.7	NA	1.4	NA	NA	NA	0	0	0
1.1	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	203	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	37	NA	98	NA	0	0	0
NA	NA	24	NA	NA	NA	0	1	0
0.9	12.6	NA	NA	96	NA	0	0	0
0.2	9.4	92	NA	98	NA	0	0	1
0.3	8.8	57	NA	102	NA	0	0	1
0.3	8.7	NA	NA	100	NA	0	0	1
0.5	9.3	NA	NA	100	NA	0	0	1
0.5	NA	NA	NA	96	NA	0	0	1
0.5	NA	NA	NA	100	NA	0	0	1
0.6	NA	1.2	NA	104	NA	0	0	0
NA	NA	4.4	NA	104	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
NA	9.7	NA	NA	NA	NA	0	0	1
0.6	9.4	NA	NA	105	185	1	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.2	NA	NA	12	NA	200	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.8	8.9	NA	NA	91	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	10	NA	NA	91	NA	0	0	0
NA	NA	NA	NA	104	NA	0	0	1
0.3	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
0.5	NA	3.3	NA	NA	NA	0	0	0
0.5	NA	3.8	NA	NA	NA	0	0	0
0.6	NA	3.1	NA	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
4.4	8.6	3.1	NA	91	NA	0	0	1
0.2	NA	2	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.5	NA	3.2	3.8	NA	NA	0	0	0
0.5	NA	4.5	NA	NA	NA	0	0	0
0.3	NA	4.4	NA	NA	NA	0	0	1
0.8	NA	2.3	NA	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
11.3	9.2	1346	NA	101	NA	1	0	1
0.5	9.8	1.3	NA	102	203	0	0	0
NA	NA	2.2	NA	104	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	98	NA	0	0	0
0.7	8.6	NA	NA	98	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	4.8	17	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	30	NA	201	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	8.8	NA	NA	0	0	0
0.4	9.4	NA	9.9	101	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	8.7	3.7	31	107	NA	0	0	0
0.5	9	NA	NA	105	130	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.3	9.5	2.4	NA	108	NA	0	0	0
0.4	9	123	NA	104	NA	0	0	0
NA	9.2	1.2	NA	101	207	0	0	0
0.7	9.5	NA	NA	103	NA	0	0	0
0.5	NA	NA	NA	104	NA	1	0	0
0.4	8.1	4.2	NA	105	NA	0	0	0
NA	7.9	3.8	26	103	NA	0	0	1
0.5	10	1.2	NA	100	NA	0	0	0
NA	NA	20	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	1.8	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	200	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	4.6	NA	NA	NA	0	0	1
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.1	NA	NA	NA	NA	NA	0	0	0
0.3	NA	3.2	NA	105	NA	1	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
1.8	9	16	NA	97	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.2	NA	1.1	NA	97	174	0	0	0
NA	NA	2	NA	110	NA	0	0	0
0.7	NA	1.7	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	41	NA	NA	NA	0	0	0
0.3	NA	NA	1183	NA	NA	0	0	1
0.4	NA	NA	833	NA	NA	0	0	1
0.3	NA	57	716	NA	NA	0	0	1
0.1	NA	43	452	NA	NA	0	0	1
0.2	9	77	544	NA	NA	0	0	1
0.2	9.2	79	419	98	NA	0	0	1
0.4	NA	NA	NA	NA	196	0	0	0
0.3	9.1	1.4	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	219	0	0	0
0.4	NA	1.9	NA	NA	196	0	0	0
0.3	NA	1.8	NA	NA	202	0	0	0
0.3	9.3	1.5	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	1.1	NA	NA	NA	0	0	0
2	8.3	4.8	NA	100	72	0	0	0
0.2	8.4	120	47	106	NA	0	0	1
0.3	NA	1.1	NA	NA	NA	0	0	1
0.4	NA	1.3	NA	NA	NA	0	0	1
0.3	9	2.3	NA	100	NA	0	0	1
0.3	NA	2.2	NA	NA	NA	0	0	1
0.2	NA	2.4	14	NA	NA	0	0	1
0.4	NA	2.1	NA	102	NA	0	0	1
0.2	NA	2.1	NA	NA	NA	0	0	1
0.3	NA	2.8	NA	NA	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	1
0.3	NA	2.5	NA	NA	NA	0	0	1
NA	NA	2.2	NA	NA	NA	0	0	1
NA	NA	1.5	NA	NA	NA	0	0	1
0.4	9.3	1.4	NA	NA	NA	0	0	1
NA	NA	1.4	NA	NA	NA	0	0	1
0.3	NA	1.8	NA	NA	NA	0	0	1
NA	NA	1.7	NA	NA	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	1
0.3	NA	1.8	NA	105	NA	0	0	1
NA	NA	1.7	NA	NA	NA	0	0	1
0.4	NA	1.7	NA	NA	NA	0	0	1
0.4	9.2	1.7	NA	101	NA	0	0	1
0.3	NA	1.7	NA	103	NA	0	0	1
0.3	8.9	2.3	NA	102	NA	0	0	1
NA	NA	2.3	NA	NA	NA	0	0	1
0.3	9.3	1.1	NA	NA	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	1
NA	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	1
0.2	NA	1.3	NA	NA	NA	0	0	1
0.2	NA	1.5	NA	NA	NA	0	0	1
0.3	NA	1.3	NA	101	NA	0	0	1
0.3	NA	1.6	NA	NA	NA	0	0	1
NA	NA	1.6	NA	NA	NA	0	0	1
NA	NA	1.7	NA	NA	NA	0	0	1
NA	NA	1.7	NA	NA	NA	0	0	1
0.2	NA	1.8	NA	NA	NA	0	0	1
0.4	NA	1.3	12	NA	NA	0	0	0
0.5	10.2	1.2	16	NA	NA	0	0	0
0.5	10.3	1.1	NA	NA	233	0	0	0
0.5	NA	3.1	23	NA	235	0	0	0
0.3	NA	8.4	NA	99	NA	0	0	0
0.3	NA	12	NA	NA	NA	0	0	0
0.4	NA	9.6	NA	NA	NA	0	0	0
0.4	NA	7.7	NA	NA	NA	0	0	0
0.4	NA	7.9	NA	NA	NA	0	0	0
0.5	NA	9.5	NA	NA	NA	0	0	1
NA	NA	5.1	NA	NA	NA	0	0	1
NA	NA	8.8	NA	NA	NA	0	0	0
0.6	9.2	6.7	NA	NA	NA	0	0	1
NA	NA	7.3	NA	NA	NA	0	0	1
NA	NA	7.5	NA	NA	NA	0	0	0
0.4	NA	NA	NA	99	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	209	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	9.6	NA	NA	100	NA	0	0	0
NA	NA	NA	NA	99	184	0	0	0
0.5	NA	6	17	NA	NA	0	0	0
0.4	NA	3.1	12	NA	NA	0	0	1
0.4	NA	2.9	11	NA	NA	0	0	1
0.4	8.9	2.6	12	NA	NA	0	0	0
0.4	8.7	5	14	100	NA	0	0	0
0.5	NA	14	31	NA	NA	0	0	0
1	NA	23	141	NA	NA	0	0	1
2.4	8.5	18	51	94	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
11.7	8	32	NA	92	NA	0	0	1
0.4	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	3.5	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	9.1	NA	NA	98	NA	0	0	0
0.3	NA	NA	NA	98	NA	0	0	0
0.3	9.4	NA	NA	98	NA	0	0	0
0.4	NA	29	NA	NA	NA	0	0	0
0.3	9	18	NA	101	NA	0	0	0
0.4	NA	17	NA	106	NA	0	0	0
0.5	9.9	5.5	NA	NA	NA	0	0	0
0.4	NA	5.1	NA	NA	NA	0	0	0
0.6	NA	2.4	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	9.1	1.6	701	103	NA	0	0	0
0.4	9	4.4	401	94	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.7	9.5	2.1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.1	22	NA	NA	0	0	0
0.7	NA	1	26	NA	NA	0	0	0
0.7	NA	1.3	NA	NA	NA	0	0	0
0.6	10.1	NA	NA	NA	NA	0	0	0
0.5	10.3	NA	17	NA	NA	0	0	0
1.1	9.1	3.1	NA	107	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	8.6	NA	NA	NA	NA	0	0	1
0.8	9.2	NA	NA	103	NA	0	0	1
0.7	NA	2.2	NA	NA	NA	0	0	1
0.3	9.7	2.4	NA	104	NA	0	0	0
NA	9.3	3.6	NA	NA	NA	0	0	0
0.7	9.3	3.7	NA	90	NA	0	0	1
0.3	NA	1.8	NA	103	NA	0	0	0
NA	9.2	6	NA	101	NA	0	0	1
NA	9	16	NA	NA	NA	0	0	1
0.7	NA	3.6	NA	NA	NA	0	0	0
1.3	NA	4.6	NA	NA	NA	0	0	0
0.9	NA	3.9	NA	NA	NA	0	0	0
1	NA	4.1	NA	NA	NA	0	0	0
1	NA	4.1	NA	NA	229	0	0	0
1.4	NA	4	NA	NA	NA	0	0	0
1.1	NA	4	NA	NA	NA	0	0	0
NA	9.1	100	NA	93	NA	0	1	1
0.7	8	85	NA	100	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.7	8.6	93	NA	NA	NA	0	1	1
0.8	8.4	117	NA	104	NA	0	1	1
0.8	7.8	NA	NA	104	NA	0	1	1
0.9	8.1	NA	NA	102	NA	0	1	1
0.9	NA	163	NA	NA	NA	0	1	1
1	NA	NA	NA	104	NA	0	1	1
1.3	7.3	NA	NA	102	NA	0	1	1
0.5	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.6	6.3	NA	NA	0	0	0
0.7	NA	1.3	NA	NA	NA	0	0	0
0.7	NA	1.3	NA	NA	NA	0	0	0
0.6	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.2	9.3	NA	NA	0	0	0
0.2	9.2	1	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.2	10.2	1.3	NA	103	NA	0	0	0
0.4	NA	6	NA	101	NA	0	0	0
NA	9.8	3.2	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	5.5	NA	NA	0	0	0
NA	NA	1.2	NA	102	NA	0	0	0
0.7	7.7	44	354	108	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	0
0.4	10	1.9	494	104	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	228	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.6	NA	3.4	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.8	NA	3.4	NA	NA	207	0	0	0
0.6	NA	3.7	NA	NA	NA	0	0	0
0.5	NA	3.2	NA	NA	NA	0	0	0
0.6	NA	3.3	NA	NA	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	3.9	NA	NA	NA	0	0	0
0.5	NA	5.5	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
0.7	8.7	NA	NA	NA	NA	0	0	1
0.7	9.3	NA	NA	NA	NA	0	0	1
0.8	9.1	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.5	8.7	NA	NA	NA	NA	0	0	1
NA	9.7	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	2.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
2.1	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
1.3	NA	NA	NA	NA	NA	0	0	0
0.8	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.3	9.3	8	NA	103	231	0	0	0
0.2	8.8	33	NA	NA	NA	0	0	1
1.1	NA	1.6	NA	97	NA	0	0	1
0.3	NA	30	NA	NA	NA	0	0	0
0.3	9.5	1.5	10	NA	246	0	0	0
0.2	NA	1.5	18	NA	NA	0	0	0
0.3	NA	1.3	16	NA	NA	0	0	0
0.3	NA	1.1	14	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	207	0	0	0
6.7	8.9	NA	NA	111	NA	1	1	1
11.8	8.1	2.2	705	101	NA	0	0	0
0.2	NA	NA	NA	101	158	0	0	0
1.1	9.3	2.4	NA	98	NA	0	0	0
0.3	NA	3.7	NA	NA	NA	0	0	0
0.3	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	1
0.4	9.4	NA	NA	NA	NA	0	0	0
0.6	NA	1.3	NA	NA	149	0	0	0
0.7	NA	2.1	NA	NA	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.6	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.3	9.6	3.6	NA	NA	NA	0	0	1
0.4	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	2.1	8.2	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.7	NA	5.1	NA	NA	NA	0	0	0
0.4	NA	27	NA	NA	NA	0	0	0
1	NA	64	NA	NA	NA	0	0	1
0.3	NA	102	NA	NA	NA	0	0	1
NA	NA	100	NA	NA	NA	0	0	1
0.9	10.8	220	NA	NA	NA	0	0	1
0.7	NA	380	NA	NA	NA	0	0	1
0.6	10	281	NA	NA	NA	0	0	1
0.5	NA	1.9	NA	NA	NA	0	0	0
NA	9.4	1.4	NA	103	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	9.5	1.8	NA	NA	NA	0	0	0
0.5	9.7	1.6	NA	NA	NA	0	0	0
0.4	10	1.6	NA	NA	NA	0	0	0
0.4	10	1.1	NA	NA	NA	0	0	0
0.3	9.7	1.5	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	103	NA	0	0	0
0.3	9	NA	NA	103	232	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	4.6	NA	NA	NA	0	0	1
0.2	9.8	4.8	NA	NA	NA	0	0	0
0.2	NA	5.3	NA	NA	NA	0	0	1
NA	NA	3.9	38	NA	NA	0	0	0
0.7	NA	3.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	8.4	1.8	NA	101	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	NA	8.3	106	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	8.8	NA	NA	104	NA	0	0	0
0.4	8.5	NA	NA	92	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
0.3	9.7	2.1	NA	NA	NA	0	0	1
0.3	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.2	NA	2.1	NA	NA	198	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	2.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	340	NA	NA	NA	0	0	0
NA	NA	NA	NA	107	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	9.7	NA	NA	NA	NA	0	0	0
0.5	9.4	1.4	NA	NA	NA	0	0	0
0.4	NA	NA	NA	106	NA	0	0	0
0.4	9.1	4.8	NA	107	NA	0	0	0
NA	NA	4.9	NA	NA	NA	0	0	0
NA	NA	5.5	NA	NA	NA	0	0	1
NA	NA	6.4	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	10.1	7.8	NA	NA	NA	0	0	0
0.4	9.8	7.6	61	NA	NA	0	0	1
0.6	9.4	NA	60	NA	NA	0	0	1
NA	NA	6.7	NA	NA	NA	0	0	1
NA	NA	7.7	NA	NA	NA	0	0	0
0.4	9	1.8	NA	106	NA	0	0	0
4.4	9.6	8.6	NA	109	123	0	0	0
1.4	9.2	5.4	NA	106	118	0	0	0
0.2	12.5	5.4	NA	NA	NA	0	0	0
2.2	7.4	6.8	NA	95	NA	0	0	0
NA	NA	2.5	6.8	NA	NA	0	0	0
0.7	9.9	2.1	NA	NA	NA	0	0	0
0.1	NA	299	NA	NA	NA	0	0	1
0.4	NA	3.9	NA	NA	NA	0	0	0
NA	9.2	2.8	NA	101	177	0	0	0
0.2	NA	2.7	NA	NA	NA	0	0	0
0.1	NA	4.1	NA	NA	NA	0	0	0
0.3	NA	5.2	NA	NA	NA	0	0	0
0.4	9.7	4.2	NA	NA	NA	0	0	0
0.2	9.4	4.6	NA	101	NA	0	0	0
0.3	NA	4.6	NA	NA	NA	0	0	0
NA	NA	6.8	NA	NA	NA	1	0	1
NA	8.9	4.7	NA	103	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.6	8.7	2.1	23	106	NA	0	0	0
0.3	9.3	2.1	NA	NA	NA	0	0	1
0.4	9.5	2.3	NA	106	NA	0	0	1
0.2	NA	5.7	NA	NA	NA	0	0	1
0.3	NA	4.8	NA	NA	NA	0	0	0
0.3	NA	5.4	NA	NA	NA	0	0	0
NA	NA	5.6	NA	NA	NA	0	0	0
0.3	NA	5.3	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	1.2	17	NA	195	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	1	NA	104	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	273	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	9.1	1	NA	104	NA	0	0	0
NA	9.4	NA	NA	101	NA	0	0	0
0.3	9.4	2.3	NA	101	NA	0	0	0
0.3	9.4	3.3	NA	102	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	8.6	4.4	NA	105	NA	0	0	0
0.7	NA	NA	NA	101	NA	0	0	0
0.9	9	9.6	NA	97	NA	0	0	0
1.2	9.3	NA	NA	97	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
0.2	9.8	1.3	NA	101	NA	0	0	0
0.2	NA	1.6	NA	96	160	0	0	0
1	NA	NA	NA	105	169	0	0	0
NA	NA	NA	NA	104	193	0	0	0
NA	NA	3.5	NA	106	NA	0	0	0
0.3	NA	2.2	9.2	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.2	9.6	NA	NA	102	187	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
0.2	9.5	3.2	NA	NA	NA	0	0	0
0.3	NA	3.9	NA	NA	NA	0	0	0
0.3	NA	3.5	NA	101	NA	0	0	0
0.3	NA	3.4	NA	NA	NA	0	0	0
NA	NA	4.9	NA	100	NA	0	0	0
0.6	NA	5.2	NA	NA	NA	0	0	0
0.6	NA	5.2	NA	90	NA	0	0	1
1.3	10.1	5	NA	89	NA	0	0	1
0.5	9.7	5.2	NA	98	NA	0	0	1
NA	9	6.3	NA	101	NA	0	0	1
0.6	NA	2.6	11	NA	NA	0	0	0
0.4	NA	3	NA	101	NA	0	0	0
0.6	10.2	3.1	NA	NA	NA	0	0	0
0.4	NA	3.2	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
0.5	NA	5.7	NA	NA	NA	0	0	0
2.3	NA	10	NA	96	NA	0	0	1
NA	NA	10	NA	NA	NA	0	0	0
0.6	NA	7.7	NA	102	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	8.6	17	NA	101	NA	0	0	0
1.2	NA	22	NA	91	NA	0	0	1
1.1	NA	26	NA	92	NA	0	0	1
NA	NA	2	NA	NA	NA	0	0	0
0.2	NA	NA	761	NA	NA	0	0	1
NA	8.5	1.6	446	105	NA	0	0	1
NA	NA	NA	122	NA	NA	0	0	1
NA	NA	NA	157	104	NA	0	0	1
0.6	NA	NA	NA	NA	NA	1	0	0
0.6	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	9.9	NA	NA	NA	NA	0	0	0
0.6	9.3	NA	NA	NA	NA	0	0	0
0.2	NA	14	57	NA	NA	0	0	1
0.1	9.2	10	97	101	NA	0	0	1
0.2	NA	11	208	NA	NA	0	0	1
0.2	NA	17	660	NA	NA	0	0	1
0.2	9.6	32	527	104	NA	0	0	1
NA	NA	76	270	NA	NA	0	0	1
0.3	NA	80	100	NA	NA	0	0	1
0.3	9.3	35	63	NA	NA	0	0	1
0.2	NA	30	88	NA	NA	0	0	1
NA	NA	37	225	NA	NA	0	0	1
0.2	NA	44	554	NA	NA	0	0	1
0.3	NA	54	1221	NA	NA	0	0	1
0.2	9.1	55	1500	104	NA	0	0	1
NA	9.3	100	771	NA	NA	0	0	1
0.4	NA	154	473	NA	NA	0	0	1
0.3	NA	180	524	NA	NA	0	0	1
0.3	NA	54	1248	101	NA	0	0	1
2.9	NA	9.2	38	106	NA	0	0	0
0.3	7.8	3.2	NA	109	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.5	9.6	1.6	NA	NA	NA	0	0	0
0.3	7.6	1.1	218	104	NA	0	0	1
NA	NA	NA	NA	108	NA	0	0	0
0.5	9.3	1.1	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	2.8	NA	NA	NA	0	0	0
3.2	8.9	4.1	NA	93	93	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
1.2	NA	NA	NA	NA	NA	0	0	0
0.6	NA	2	NA	NA	NA	0	1	0
0.4	9.9	NA	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	10.2	NA	NA	NA	NA	0	0	1
0.4	10	NA	NA	104	NA	0	0	1
0.5	10	NA	NA	101	NA	0	0	1
0.4	10.4	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.5	10	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	10.6	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.9	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	11.2	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.7	NA	NA	103	NA	0	0	1
0.4	9.9	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	11.8	NA	NA	NA	NA	0	0	1
NA	10.5	NA	NA	NA	NA	0	0	1
0.6	NA	113	NA	NA	NA	0	0	1
0.8	NA	2.2	NA	NA	138	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	14	NA	NA	NA	0	0	0
NA	NA	54	NA	NA	NA	0	0	1
NA	NA	71	NA	NA	NA	0	0	1
NA	NA	71	NA	NA	NA	0	0	1
NA	NA	49	NA	NA	NA	0	0	1
0.3	NA	50	NA	NA	NA	0	0	0
0.3	NA	47	NA	99	NA	0	0	1
NA	NA	47	NA	NA	NA	0	0	1
0.5	NA	37	NA	NA	NA	0	0	0
0.2	NA	32	NA	NA	NA	0	0	0
0.4	NA	30	NA	NA	NA	0	0	0
0.3	NA	31	NA	NA	NA	0	0	1
0.3	NA	29	NA	105	NA	0	0	0
0.2	9.5	19	NA	102	NA	0	0	0
NA	NA	12	NA	NA	NA	0	0	0
0.4	NA	10	NA	NA	NA	0	0	0
NA	NA	11	NA	NA	NA	0	0	0
0.3	9	14	NA	101	NA	0	0	0
0.2	NA	17	NA	NA	NA	0	0	0
0.2	NA	18	NA	NA	NA	0	0	0
0.4	NA	26	NA	NA	NA	0	0	0
0.4	NA	31	NA	NA	NA	0	0	0
2.1	9.2	11	NA	107	NA	0	0	0
1.7	8.6	NA	NA	107	NA	1	0	0
0.9	NA	19	NA	106	NA	0	1	0
0.8	NA	NA	NA	NA	NA	0	1	0
1.9	NA	NA	NA	NA	NA	0	1	0
1.4	NA	NA	NA	NA	NA	0	1	0
1.3	NA	NA	NA	103	NA	0	1	0
NA	NA	1.1	NA	99	NA	0	1	0
0.5	NA	1.1	NA	99	NA	0	1	0
0.8	NA	1.1	NA	99	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
9.3	NA	11	NA	NA	NA	0	0	1
11.4	NA	18	NA	NA	NA	0	1	1
14.8	8.7	27	NA	96	493	0	1	1
1	8.7	6.2	NA	102	147	0	0	1
1.2	8.8	9.8	NA	94	135	0	0	0
0.5	10.1	1.6	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	182	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.2	10.8	2.5	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
19.1	7.9	1.5	NA	98	NA	0	0	1
0.3	9.6	2.7	15	105	NA	0	0	0
NA	NA	NA	NA	NA	152	0	0	0
0.8	NA	NA	NA	103	160	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.4	NA	5.5	NA	111	NA	0	0	1
NA	NA	5.3	NA	102	NA	0	0	1
0.2	NA	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.6	9.6	2.2	NA	106	194	0	0	0
0.3	9.7	2.2	NA	105	NA	0	0	0
23.7	NA	NA	NA	103	NA	0	0	1
0.7	8.2	NA	NA	106	NA	0	0	0
NA	9.9	4.1	NA	NA	NA	0	0	1
2.2	8.4	7	NA	102	NA	0	0	1
6.1	7.9	2.1	NA	107	NA	0	0	1
1.5	NA	NA	NA	103	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
NA	NA	2	NA	102	NA	0	0	0
0.3	10	114	423	97	NA	0	0	1
0.6	NA	1.6	NA	NA	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	1
0.6	NA	1.8	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.6	11	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	177	0	0	1
0.4	NA	1.5	NA	NA	177	0	0	1
NA	NA	NA	NA	NA	159	0	0	1
0.7	NA	1.4	9.1	NA	139	0	0	0
0.5	NA	NA	7.6	NA	NA	0	0	0
0.7	NA	1.2	7.5	NA	NA	0	0	0
0.7	NA	5	NA	NA	NA	0	0	1
0.9	NA	4.3	NA	NA	NA	0	0	1
0.8	NA	7.2	NA	NA	NA	0	0	1
0.4	NA	10	NA	NA	NA	0	0	1
0.4	NA	11	NA	NA	NA	0	0	1
0.3	NA	22	NA	NA	NA	0	0	1
0.3	9.7	23	NA	102	NA	0	0	1
0.3	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.3	10.2	1.8	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.4	10.1	NA	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.7	NA	3.3	NA	NA	NA	0	0	0
0.4	NA	3.2	NA	NA	NA	0	0	0
0.4	NA	3.2	NA	NA	NA	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
0.5	NA	2.7	31	NA	217	0	0	0
NA	NA	NA	NA	NA	263	0	0	1
0.4	NA	4	NA	NA	NA	0	0	1
1.5	8.8	5.4	NA	95	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	2.3	9.1	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.2	NA	2.2	NA	NA	NA	0	0	0
0.5	8.8	NA	8.1	99	NA	0	0	0
0.7	NA	1.5	NA	NA	NA	0	0	0
1.2	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	3.2	NA	NA	NA	0	0	0
0.2	NA	4.6	NA	NA	NA	0	0	0
0.3	NA	4.6	NA	NA	NA	0	0	0
0.4	NA	4	NA	NA	NA	0	0	0
NA	NA	NA	NA	97	NA	0	0	0
0.3	9.6	2.5	NA	105	174	0	0	0
1.3	9.1	4.2	NA	106	NA	1	0	0
0.4	NA	3.8	NA	NA	NA	0	0	0
0.4	NA	4.9	NA	NA	NA	0	0	1
0.4	NA	4.8	NA	NA	NA	0	0	1
0.3	8.6	NA	NA	96	NA	0	0	1
0.5	8.1	7.9	NA	92	91	0	0	1
0.3	7.4	NA	NA	96	NA	0	0	1
1.5	NA	23	27	99	NA	0	0	1
NA	NA	3	NA	NA	NA	0	0	0
NA	9.1	3	NA	101	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
0.6	10.7	1.2	9.9	100	NA	0	0	0
NA	NA	11	NA	NA	NA	0	0	0
0.3	8.5	11	NA	104	NA	0	0	0
0.3	8.5	12	NA	NA	NA	0	0	0
0.4	NA	12	NA	NA	NA	0	0	0
0.4	9	13	NA	NA	NA	0	0	0
0.4	NA	8.9	NA	NA	NA	0	0	0
0.3	8.5	7.7	NA	107	NA	0	0	0
0.3	NA	7	NA	NA	NA	0	0	1
0.4	9.8	6.4	NA	102	NA	0	0	1
0.8	9.1	8.7	NA	105	NA	0	0	1
0.5	8.7	10	NA	NA	NA	0	0	0
0.5	9	9.1	NA	NA	NA	0	0	1
0.3	9.2	14	NA	104	NA	0	0	1
0.3	8.1	12	NA	NA	NA	0	0	1
1	8.3	26	NA	104	NA	0	0	1
0.6	8.4	21	NA	107	NA	0	0	1
0.4	NA	25	NA	NA	NA	0	0	1
0.5	NA	42	NA	NA	NA	0	0	1
1.3	8.9	48	NA	NA	NA	0	0	1
NA	9.1	37	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	9.3	30	NA	106	NA	0	0	1
0.3	NA	26	NA	NA	NA	0	0	1
0.4	9	46	NA	104	NA	0	0	1
NA	9	72	NA	105	NA	0	0	1
0.7	9.1	84	NA	99	NA	0	0	1
0.5	8.5	125	NA	101	NA	0	0	1
NA	9.3	170	NA	100	NA	0	0	1
NA	8.1	161	NA	NA	NA	0	0	1
0.4	8.2	157	NA	NA	NA	0	0	1
0.3	NA	147	NA	107	NA	0	0	1
0.5	NA	1.3	NA	NA	NA	0	0	1
0.4	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	1
0.5	NA	2.2	NA	NA	NA	0	0	1
0.5	NA	1.8	NA	NA	NA	0	0	1
0.6	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	1
NA	NA	1.9	NA	NA	NA	0	0	1
0.6	9.6	1.7	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	1
NA	NA	2.3	NA	NA	NA	0	0	1
NA	NA	2.6	NA	NA	NA	0	0	1
NA	NA	2.5	NA	NA	NA	0	0	1
0.7	NA	2.6	NA	NA	NA	0	0	1
0.6	NA	2	NA	NA	NA	0	0	1
0.6	NA	1.9	NA	NA	NA	0	0	1
0.6	NA	1.8	134	NA	NA	0	0	1
NA	NA	2.1	173	NA	NA	0	0	1
0.6	8.6	1.9	200	NA	NA	0	0	1
NA	NA	1.9	231	NA	NA	0	0	1
0.8	NA	2.5	228	NA	NA	0	0	1
0.8	NA	2.5	225	NA	NA	0	0	1
0.6	NA	2.3	253	NA	NA	0	0	1
0.5	NA	2	256	NA	NA	0	0	1
NA	NA	1.9	NA	NA	NA	0	0	1
0.5	9.9	1.9	NA	102	NA	0	0	1
0.5	NA	2.6	NA	105	NA	0	0	1
0.6	9.2	2.2	NA	NA	NA	0	0	1
0.7	NA	2.4	34	NA	NA	0	0	1
0.5	NA	2.1	49	NA	NA	0	0	1
NA	NA	2.7	77	NA	NA	0	0	1
NA	NA	2.7	103	NA	NA	0	0	1
0.5	9.3	3	NA	NA	NA	0	0	1
0.6	NA	2.5	NA	NA	NA	0	0	1
NA	NA	3.1	NA	NA	NA	0	0	1
NA	NA	3.2	NA	NA	NA	0	0	1
0.4	8.7	NA	NA	NA	NA	0	0	0
1	8.1	4.9	15	108	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
0.4	9.4	2.5	NA	NA	NA	0	0	1
0.5	9.8	2.6	NA	NA	NA	0	0	0
NA	NA	2.4	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	4	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	2.4	6	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
0.5	NA	2.7	NA	NA	NA	0	0	0
0.4	9.7	2.9	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
0.4	9.1	36	NA	104	NA	0	0	1
NA	NA	29	NA	NA	NA	0	0	1
0.4	9.6	13	NA	108	NA	0	0	1
NA	NA	9.6	NA	NA	NA	0	0	1
0.4	NA	9.7	NA	NA	NA	0	0	1
0.4	9.7	11	NA	NA	NA	0	0	1
0.4	NA	1.9	NA	NA	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	9.5	NA	NA	96	NA	0	0	0
0.7	NA	8.1	NA	NA	NA	0	0	0
NA	NA	3.9	NA	NA	NA	1	0	1
0.4	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.2	NA	3.9	NA	NA	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
NA	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	3.4	NA	NA	NA	0	0	0
0.2	NA	3.5	NA	NA	NA	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
0.4	NA	5.7	NA	NA	NA	0	0	0
0.4	10.5	4	NA	104	217	0	0	1
NA	10	NA	NA	100	NA	0	0	1
0.2	NA	NA	3.3	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	15	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	3.5	NA	NA	NA	0	0	0
0.3	NA	5	NA	NA	NA	0	0	0
0.3	NA	5	NA	NA	NA	0	0	0
NA	NA	4.3	NA	NA	NA	0	0	0
NA	NA	4.3	NA	NA	NA	0	0	0
NA	NA	4.4	NA	NA	NA	0	0	0
NA	NA	4.7	NA	NA	NA	0	0	0
2.3	NA	NA	NA	NA	NA	1	1	1
1	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	1	1
8.4	NA	17	NA	88	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
1.2	NA	2.7	NA	NA	NA	0	0	0
NA	NA	5	NA	NA	NA	0	0	0
0.3	8.5	4.5	NA	106	NA	1	0	0
NA	NA	5.4	NA	NA	NA	0	0	0
9.8	NA	NA	NA	NA	NA	0	0	0
1.6	8.5	NA	NA	NA	NA	0	0	0
1	8.4	16	NA	101	NA	0	0	0
0.6	8.4	17	NA	106	NA	0	0	0
2.7	8.8	72	NA	105	NA	0	0	1
1.4	8.4	NA	13	100	NA	0	0	0
0.7	8.3	2.2	NA	103	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	12.1	2.6	10	103	NA	0	0	0
1.8	7.5	NA	NA	88	NA	0	0	1
1.4	9.1	7.3	NA	104	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	1
1.2	9	NA	NA	100	NA	0	0	1
0.3	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	5	NA	NA	NA	0	0	1
NA	NA	2.6	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.7	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.8	9.4	NA	NA	NA	NA	0	0	1
0.6	9.3	NA	NA	NA	NA	0	1	1
2.7	NA	NA	NA	NA	NA	0	1	1
6	NA	NA	NA	NA	NA	0	0	1
1.8	NA	NA	NA	NA	NA	0	1	1
NA	9.2	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	9.2	NA	NA	107	NA	0	0	1
0.5	9.3	NA	NA	NA	NA	0	0	1
0.5	9.1	NA	NA	103	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
1.5	7.6	NA	NA	111	NA	0	1	1
0.9	8.7	NA	NA	98	NA	0	1	1
1.9	9.1	NA	NA	93	NA	0	0	1
1.5	8.8	NA	NA	98	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.2	13	NA	NA	0	0	0
0.4	NA	2.4	11	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	230	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	1
0.4	NA	4.5	NA	NA	NA	0	0	0
0.5	NA	15	NA	NA	NA	0	0	0
0.5	NA	15	NA	NA	NA	0	0	1
0.4	NA	12	NA	NA	NA	0	0	1
0.4	NA	3.4	NA	NA	NA	0	0	1
0.5	NA	7.2	NA	NA	NA	0	0	1
0.8	NA	9.5	NA	NA	NA	0	0	1
0.4	NA	12	NA	NA	NA	0	0	1
3.4	NA	2.7	NA	100	NA	0	0	0
NA	NA	3.2	NA	104	NA	0	0	1
2.3	NA	10936	NA	99	NA	0	0	1
0.6	NA	3.4	NA	NA	NA	0	0	0
0.5	NA	3.6	NA	NA	NA	0	0	0
0.7	NA	3.1	NA	NA	NA	0	0	0
0.8	NA	3	NA	NA	NA	0	0	0
0.7	NA	3.9	NA	NA	NA	0	0	0
0.6	NA	3.3	NA	NA	NA	0	0	0
0.4	NA	3.6	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.5	NA	3.7	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	9.6	1.1	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	38	NA	NA	NA	0	0	1
0.2	7.7	23	NA	NA	NA	0	0	1
0.3	7.7	29	NA	NA	NA	0	0	1
0.3	NA	25	NA	NA	NA	0	0	1
0.3	NA	23	NA	NA	NA	0	0	1
0.2	NA	20	NA	NA	NA	0	0	1
0.3	NA	19	NA	NA	NA	0	0	1
0.3	NA	26	NA	NA	NA	0	0	1
0.3	NA	34	NA	NA	NA	0	0	1
0.3	9.3	49	NA	104	NA	0	0	1
0.3	9.3	60	NA	NA	NA	0	0	1
0.4	NA	88	NA	NA	NA	0	0	1
0.5	NA	161	NA	NA	NA	0	0	1
0.7	NA	255	NA	NA	NA	0	0	1
0.9	NA	368	NA	NA	NA	0	0	1
1.8	7.3	447	NA	NA	NA	0	0	1
NA	NA	NA	7.7	NA	NA	0	0	0
NA	9.6	NA	NA	NA	233	0	0	0
1.1	9.1	NA	NA	103	NA	0	0	0
0.6	8.4	NA	NA	101	NA	0	0	0
0.6	8.4	NA	NA	101	NA	0	0	0
NA	NA	NA	NA	103	NA	0	0	0
0.4	9.4	6.1	NA	NA	NA	0	0	0
NA	NA	4.2	NA	NA	NA	0	0	0
NA	NA	11	NA	NA	NA	0	0	0
NA	NA	9.3	NA	NA	NA	0	0	0
0.3	NA	10	NA	NA	NA	0	0	0
NA	NA	10	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	12	NA	NA	NA	0	0	0
0.2	9.3	1.8	38	108	NA	0	0	0
0.3	10.1	41	NA	103	NA	0	0	1
0.3	10.4	43	NA	105	NA	0	0	1
0.3	NA	44	NA	NA	NA	0	0	1
0.2	NA	67	NA	NA	NA	0	0	1
NA	NA	112	NA	NA	NA	0	0	1
0.2	9.3	71	NA	NA	NA	0	0	1
0.2	9.6	41	NA	NA	NA	0	0	1
0.3	10.3	31	NA	NA	NA	0	0	0
0.3	9.4	20	NA	NA	NA	0	0	0
0.3	9.7	24	NA	NA	NA	0	0	1
0.4	NA	58	NA	100	NA	0	0	1
NA	8.4	52	NA	102	NA	0	0	1
0.2	NA	74	NA	NA	NA	0	0	1
0.3	9.3	88	NA	97	NA	0	0	1
NA	9.3	NA	NA	NA	NA	0	0	0
0.6	9.8	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.7	NA	2.7	NA	102	NA	0	0	0
0.2	NA	3.1	NA	NA	NA	0	0	0
0.2	NA	3.1	NA	NA	NA	0	0	0
0.2	NA	3.2	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
0.4	NA	6.6	NA	NA	NA	0	0	0
0.4	NA	11	NA	NA	NA	0	0	0
0.3	NA	30	NA	NA	NA	0	0	0
0.4	NA	4.2	NA	NA	NA	0	0	0
0.4	NA	4.9	NA	NA	NA	0	0	0
0.3	NA	4.7	NA	NA	NA	0	0	0
NA	NA	4.8	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.9	NA	1.7	NA	104	NA	0	1	0
0.3	NA	NA	NA	107	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.5	9.9	17	NA	94	NA	0	0	0
0.5	9.4	20	NA	103	NA	0	0	0
0.7	9.4	16	NA	98	NA	0	0	0
0.4	9.5	15	NA	97	NA	0	0	1
0.4	9.7	40	NA	95	NA	0	0	1
0.4	9.3	50	NA	98	NA	0	0	1
0.3	10	68	NA	97	NA	0	0	1
0.5	11	148	NA	95	NA	0	0	1
0.7	11.6	276	NA	90	NA	0	0	1
0.7	9.5	323	NA	87	NA	0	0	1
0.5	9.5	1.6	NA	NA	NA	0	0	0
0.5	9.5	NA	NA	101	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	9.8	NA	NA	105	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	288	0	0	0
0.3	NA	2	NA	103	283	0	0	0
0.5	NA	1.6	NA	NA	303	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.7	8.2	2.6	NA	98	201	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	3.6	NA	106	NA	0	0	0
1.7	9.5	4.7	NA	103	160	0	0	0
NA	NA	NA	4.6	94	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	13	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.9	NA	NA	NA	0	0	0
0.7	9.6	2.2	NA	NA	NA	0	0	0
NA	NA	73	NA	NA	NA	0	0	1
0.6	NA	102	NA	NA	NA	0	0	1
1.1	8.9	NA	NA	97	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.4	9	NA	NA	102	NA	0	0	1
0.4	9	NA	NA	102	NA	0	0	1
0.5	9.2	NA	NA	101	NA	0	0	1
0.6	9.3	50	NA	100	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	91	NA	0	0	1
0.3	NA	1.7	30	NA	NA	0	0	1
NA	7.8	NA	81	97	NA	0	0	0
0.8	NA	2	NA	NA	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	1
4.7	NA	NA	NA	NA	NA	1	0	0
2.2	10.3	NA	NA	104	NA	0	0	1
6.3	9	NA	NA	104	NA	1	0	0
5.3	9.3	NA	NA	104	NA	1	0	0
10.3	9.9	NA	NA	104	NA	1	0	0
6.5	9.1	NA	NA	102	NA	0	0	0
5.9	NA	NA	NA	101	NA	0	0	0
5.3	NA	NA	NA	104	NA	1	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	2.5	NA	NA	NA	0	0	0
0.4	8.5	NA	NA	100	NA	0	0	0
0.7	8.7	1.5	NA	97	NA	0	0	0
3.7	9.4	3.7	NA	97	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	106	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	1
0.3	NA	3.1	NA	NA	NA	0	0	1
0.6	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.6	NA	2.9	NA	NA	NA	0	0	1
0.4	9.7	8.8	NA	103	283	0	0	0
0.5	NA	19	NA	NA	NA	0	0	1
0.5	9.2	14	NA	NA	214	0	0	0
0.5	NA	10	NA	NA	205	0	0	1
0.6	NA	12	NA	NA	NA	0	0	1
NA	NA	3.4	NA	103	183	0	0	1
NA	NA	9.1	NA	NA	NA	0	0	1
NA	NA	10	NA	NA	NA	0	0	1
0.3	NA	9.7	NA	NA	NA	0	0	1
0.3	NA	12	NA	104	206	0	0	1
0.4	NA	15	NA	NA	NA	0	0	1
NA	NA	9.3	NA	NA	NA	0	0	1
NA	NA	4.5	NA	NA	NA	0	0	0
0.3	NA	4.5	NA	NA	NA	0	0	0
NA	NA	5.9	NA	NA	NA	0	0	1
0.3	NA	7.1	NA	NA	NA	0	0	1
NA	NA	9.4	NA	NA	NA	0	0	1
0.4	8.9	16	NA	102	NA	0	0	1
0.4	NA	22	NA	103	189	0	0	1
NA	NA	33	137	NA	NA	0	0	1
NA	8.7	41	NA	NA	NA	0	0	1
0.3	8.7	50	NA	NA	NA	0	0	1
0.3	NA	57	NA	NA	NA	0	0	1
0.3	NA	81	NA	NA	NA	0	0	1
NA	NA	98	NA	NA	NA	0	0	1
0.7	NA	1.9	NA	NA	NA	0	0	0
0.8	NA	1.9	NA	NA	NA	0	0	0
1	11.4	NA	NA	NA	NA	0	0	0
0.6	10.3	2.2	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
NA	9.3	2.2	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	1
NA	NA	1.6	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	220	0	0	1
13.7	8.8	5	NA	106	NA	1	0	1
10	8.7	NA	NA	105	NA	1	1	1
2.1	NA	NA	NA	106	NA	0	1	1
4.7	NA	NA	NA	NA	NA	0	1	1
0.7	8.8	1.4	NA	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	96	NA	0	0	1
NA	9.2	1.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	2	NA	NA	NA	0	0	1
0.5	NA	2.2	NA	NA	NA	0	0	1
0.4	8.9	3.4	NA	102	NA	0	0	1
0.6	NA	2	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.2	NA	2.8	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	NA	NA	101	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
1.1	10.1	1	NA	102	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	140	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	9.1	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
7	9.4	12	NA	106	NA	0	0	1
3.8	8.5	NA	NA	110	NA	0	0	1
0.2	NA	1.4	31	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
0.2	9.5	4.1	NA	99	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	1	0	0
0.5	NA	3	NA	102	NA	0	0	1
3.5	9.3	923	NA	101	NA	1	0	1
NA	8.5	NA	NA	NA	NA	0	0	1
2.5	9	NA	NA	95	NA	0	0	1
0.3	NA	1.2	NA	NA	NA	0	0	1
0.4	NA	2	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	106	172	0	0	0
NA	NA	6.4	332	NA	NA	0	0	1
NA	10.1	2.1	NA	100	213	0	0	0
0.4	NA	2.4	NA	102	204	0	0	0
0.9	NA	2.9	NA	NA	NA	0	0	1
0.9	8	NA	NA	108	NA	0	0	1
4.6	NA	NA	NA	NA	NA	0	0	1
4.2	NA	NA	NA	NA	NA	0	0	1
0.4	NA	3.8	NA	NA	NA	0	0	0
0.3	NA	4.7	NA	NA	198	0	0	0
0.3	NA	3.3	NA	NA	194	0	0	0
0.3	NA	3.8	NA	NA	NA	0	0	0
0.4	NA	3.8	NA	NA	NA	0	0	0
0.3	NA	3.7	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.3	7.9	1.3	NA	105	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
0.2	NA	1.9	14	NA	NA	0	0	0
0.4	NA	2.3	25	NA	NA	0	0	0
0.2	9	6.6	145	NA	NA	0	0	1
0.2	NA	NA	NA	105	NA	0	0	0
0.7	NA	2.2	NA	NA	NA	0	0	0
0.7	NA	2.2	NA	NA	127	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.3	9.2	1.6	NA	NA	NA	0	0	0
0.3	9.6	1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.8	NA	9.9	NA	102	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.1	10	NA	NA	0	0	0
0.5	9.6	1.8	97	NA	NA	0	0	1
0.2	NA	11	925	NA	NA	0	0	1
NA	NA	29	2082	NA	NA	0	0	1
NA	NA	29	2082	NA	NA	0	0	1
0.4	NA	36	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.6	NA	7.2	NA	NA	NA	0	0	1
0.3	8.9	NA	NA	NA	NA	0	0	1
1	9.1	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	107	213	0	0	0
1.7	8.8	NA	NA	109	NA	0	0	1
2.3	8.2	NA	NA	105	NA	0	0	1
1.7	8.6	NA	NA	100	NA	0	0	1
0.3	NA	4.7	NA	NA	NA	0	0	1
0.3	NA	4.9	NA	NA	NA	0	0	0
0.4	NA	4.5	NA	NA	NA	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
NA	9.3	9.3	NA	NA	NA	0	0	0
0.3	9.3	6.7	NA	NA	NA	0	0	0
0.7	9	1.4	NA	104	NA	0	0	0
11.3	9	NA	NA	84	100	0	0	0
1.5	11.3	3.6	NA	103	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	3.2	NA	NA	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
0.7	9.6	6.1	NA	NA	261	0	0	0
0.5	9.7	6	NA	NA	NA	0	0	0
NA	9.9	NA	NA	106	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.7	NA	2	16	NA	239	0	0	0
0.3	NA	NA	18	NA	NA	0	0	0
0.3	NA	4.6	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.7	9	NA	NA	96	NA	0	1	1
0.6	8.8	NA	NA	97	NA	0	1	1
0.8	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
1	NA	NA	NA	100	NA	0	1	1
NA	9.7	5.5	NA	NA	NA	0	0	0
NA	9.8	6.8	NA	NA	NA	0	0	0
0.4	9.8	5.6	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	11	NA	NA	NA	0	0	1
0.6	9.7	12	NA	NA	NA	0	0	1
0.3	NA	11	NA	NA	NA	0	0	1
0.3	9.3	12	NA	105	NA	0	0	1
0.6	NA	5.6	NA	105	NA	0	0	1
0.8	NA	4.8	NA	103	NA	0	0	0
0.3	8.7	10	NA	NA	NA	0	0	0
NA	NA	4.6	NA	NA	NA	0	0	1
NA	NA	4.3	NA	NA	NA	0	0	1
0.4	NA	4.5	NA	105	NA	0	0	1
0.5	9.3	4.6	NA	104	NA	0	0	0
NA	9	4.6	NA	106	NA	0	0	0
0.5	9.5	4.5	NA	107	NA	0	0	0
0.3	9.2	52	NA	104	NA	0	0	1
0.3	9.5	41	NA	107	NA	0	0	0
0.5	9.5	41	NA	102	NA	0	0	1
0.4	8.9	43	NA	98	NA	0	0	1
NA	9.3	NA	NA	97	NA	0	0	0
0.3	NA	NA	NA	99	NA	1	0	0
0.4	NA	5	NA	101	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	7.2	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.9	7.5	NA	NA	0	0	0
0.5	NA	1.9	8.9	NA	NA	0	0	0
0.5	NA	2.5	9.6	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	13	NA	NA	NA	0	0	0
0.3	NA	72	11	NA	NA	0	0	1
0.5	NA	184	NA	NA	NA	0	0	1
1.4	9.7	2.31	NA	99	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.4	9.9	2.8	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	9.9	NA	NA	103	NA	0	0	0
0.3	10.1	1.6	NA	104	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	0	0	1
0.3	9.6	2.3	NA	104	NA	0	0	1
0.7	9.6	4.1	NA	NA	NA	0	0	1
0.3	9.2	3.5	NA	NA	NA	0	0	1
0.5	8.5	6.2	NA	104	NA	0	0	1
NA	9.5	4.6	13	101	NA	0	0	0
0.5	8.1	NA	NA	103	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	1
0.4	NA	2.4	NA	NA	NA	0	0	1
0.5	NA	2.3	NA	NA	NA	0	0	1
0.7	NA	1.9	NA	NA	NA	0	0	1
0.7	NA	2.1	NA	NA	202	0	0	0
NA	NA	4.9	NA	NA	NA	0	0	0
0.5	NA	3.4	3.6	96	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.6	NA	2	NA	NA	NA	0	1	0
0.3	NA	1.7	NA	103	161	0	0	0
NA	9.1	1.8	NA	103	NA	0	0	0
0.2	NA	NA	NA	103	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.4	9.6	1.7	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	106	NA	0	0	0
0.4	10.3	2	NA	108	NA	0	0	1
0.2	NA	2.4	NA	NA	NA	0	0	0
0.1	NA	2.6	NA	NA	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
0.1	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	2	NA	NA	NA	0	0	0
0.1	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
2.4	8.8	3	NA	99	NA	0	0	1
1.1	8.8	3.6	NA	95	NA	1	0	1
0.3	8.9	NA	NA	96	NA	0	0	0
0.4	NA	NA	NA	99	NA	0	0	0
NA	NA	NA	NA	NA	123	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
NA	NA	13	NA	NA	NA	0	0	0
0.3	NA	4.2	NA	NA	NA	0	0	0
0.3	NA	3.9	NA	NA	NA	0	0	0
0.2	NA	4.2	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.3	9.4	1.4	NA	NA	NA	0	0	0
0.3	11.2	NA	NA	98	NA	0	1	1
21.4	9.6	7	NA	97	NA	1	0	0
5.4	10.1	NA	NA	106	NA	0	0	0
NA	9.5	3.2	NA	106	NA	0	0	0
10.9	NA	3.6	NA	106	NA	1	0	1
NA	NA	NA	NA	NA	219	0	0	1
0.7	NA	NA	NA	99	NA	0	0	1
0.5	NA	NA	NA	102	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	104	NA	0	0	1
0.5	NA	NA	89	NA	NA	0	0	1
0.6	NA	NA	78	NA	NA	0	0	1
0.6	NA	NA	55	108	244	0	0	1
0.8	NA	NA	57	NA	241	0	0	0
NA	NA	NA	NA	NA	254	0	0	0
0.7	9	NA	NA	107	146	0	0	0
0.6	NA	NA	NA	NA	180	0	0	0
1.6	9.1	1.4	NA	105	NA	0	0	0
0.5	NA	4	NA	NA	NA	0	0	1
0.4	9.3	2.9	NA	107	NA	0	0	0
0.4	NA	4.2	NA	NA	NA	0	0	0
NA	NA	4.8	NA	NA	NA	0	0	0
0.4	9.7	4	NA	NA	NA	0	0	0
NA	NA	4.5	NA	NA	NA	0	0	0
NA	NA	5.4	NA	NA	NA	0	0	1
6.8	9.6	NA	NA	96	NA	0	0	1
1.1	8.8	11	NA	100	NA	0	0	1
NA	NA	6.3	NA	NA	NA	0	0	1
0.5	9	3.5	NA	108	NA	0	0	1
0.6	9.4	4.2	NA	NA	NA	0	0	1
0.9	9.4	5.2	NA	NA	NA	0	0	1
0.7	8.8	7.1	NA	95	NA	0	0	1
0.9	NA	11	NA	98	NA	0	0	1
0.2	8.1	NA	NA	105	NA	0	0	1
0.5	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.3	9.8	1.6	NA	NA	216	0	0	1
0.3	9.5	1.5	NA	NA	NA	0	0	0
0.2	NA	1.6	23	NA	NA	0	0	0
0.3	9.5	1.6	NA	NA	NA	0	0	0
0.2	9.5	NA	NA	104	NA	0	0	1
NA	NA	42	NA	NA	NA	0	0	1
NA	NA	26	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	9.5	22	NA	NA	NA	0	0	1
NA	NA	28	NA	NA	NA	0	0	1
NA	9.7	NA	NA	NA	NA	0	0	1
0.3	NA	36	NA	NA	NA	0	0	1
0.4	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
0.2	NA	4.3	NA	NA	NA	0	0	1
0.4	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	3.5	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.5	9.8	NA	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	9.5	NA	NA	101	NA	0	0	1
0.4	9.1	NA	NA	105	NA	0	0	1
0.5	9.1	NA	NA	101	NA	0	0	1
0.3	8.5	NA	NA	104	NA	0	0	1
0.3	8.9	NA	NA	97	NA	0	0	1
0.2	8.8	NA	NA	103	NA	0	0	1
0.4	8.6	NA	NA	96	NA	0	0	1
0.4	8.8	NA	NA	100	NA	0	0	1
NA	9.1	NA	NA	104	NA	0	0	1
0.3	9.4	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	1.3	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	9	NA	NA	NA	NA	0	0	1
0.3	NA	1.3	NA	NA	NA	0	0	1
0.2	NA	1.3	NA	NA	NA	0	0	1
NA	NA	1.4	NA	NA	NA	0	0	1
0.4	NA	1.3	NA	NA	NA	0	0	1
0.3	NA	1.2	NA	NA	NA	0	0	1
NA	NA	1.5	NA	NA	NA	0	0	1
0.4	NA	1.5	NA	NA	NA	0	0	1
0.3	NA	1.7	NA	NA	NA	0	0	1
0.4	NA	1.5	NA	NA	NA	0	0	1
NA	NA	1.2	NA	NA	NA	0	0	1
0.3	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	1
NA	NA	1.5	NA	NA	NA	0	0	1
0.3	NA	1.3	NA	NA	NA	0	0	1
0.2	NA	1.3	NA	NA	NA	0	0	1
0.4	NA	1.4	NA	NA	NA	0	0	1
0.4	NA	1.4	NA	NA	NA	0	0	1
0.6	NA	1.2	NA	NA	NA	0	0	1
0.5	NA	1.4	NA	NA	NA	0	0	1
0.5	NA	1.6	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	2	NA	NA	NA	0	0	1
0.4	NA	1.8	NA	NA	NA	0	0	1
0.3	NA	1.7	NA	NA	NA	0	0	1
0.4	NA	1.1	NA	NA	NA	0	0	1
0.4	9.3	1.3	NA	105	NA	0	0	1
0.3	NA	1.5	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	3.3	NA	NA	NA	0	0	0
0.6	10	3.4	NA	101	216	0	0	0
0.6	NA	4.9	NA	NA	NA	0	0	0
0.5	NA	4.5	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1	NA	103	298	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
0.3	9.5	1	8.9	NA	NA	0	0	0
NA	10	40	77	101	NA	0	0	0
0.2	9.4	17	NA	101	NA	0	0	0
NA	NA	NA	12	106	NA	0	0	0
6.9	8	NA	NA	104	NA	0	0	1
1.8	NA	NA	NA	96	NA	1	0	0
0.3	NA	2.5	NA	101	NA	1	0	1
0.3	8.4	NA	NA	103	NA	0	0	1
0.4	NA	NA	59	NA	NA	0	0	1
0.4	9.4	NA	24	104	NA	0	0	1
NA	NA	NA	12	NA	NA	0	0	1
NA	NA	NA	7.8	NA	NA	0	0	0
NA	NA	NA	13	NA	NA	0	0	0
NA	NA	NA	11	NA	NA	0	0	0
NA	NA	NA	9.4	NA	NA	0	0	0
NA	NA	NA	8.4	NA	NA	0	0	0
NA	NA	NA	9.6	NA	NA	0	0	0
NA	NA	NA	8.8	NA	NA	0	0	0
NA	NA	NA	10	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	220	0	0	0
0.5	NA	2.1	NA	105	NA	0	0	0
0.5	NA	1.6	NA	104	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.3	9	1.2	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
1.1	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	106	NA	0	0	1
0.6	NA	NA	NA	103	NA	0	0	1
NA	8.9	1.7	NA	107	NA	0	0	0
0.5	NA	1.4	NA	104	NA	0	0	0
0.6	NA	2	NA	NA	NA	0	0	0
0.7	9.1	1.4	NA	106	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	9.6	1.7	NA	107	NA	0	0	0
1	9.1	1.6	NA	107	NA	0	0	0
0.6	NA	1.7	NA	NA	NA	0	0	0
0.6	9	1.8	NA	108	NA	0	0	0
1.1	NA	1.9	NA	105	NA	0	0	0
0.6	8.7	1.5	NA	106	NA	0	0	0
0.7	9.1	1.3	NA	NA	NA	0	0	1
0.8	NA	1.3	NA	109	NA	0	0	0
1	NA	1.3	NA	104	NA	0	0	0
0.6	NA	1	NA	NA	NA	0	0	0
0.7	9.3	1.2	NA	109	NA	0	0	0
0.8	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	105	NA	0	0	0
0.7	NA	NA	NA	109	NA	0	0	0
0.9	8.5	NA	NA	108	NA	0	0	0
0.9	8.8	NA	NA	106	189	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.6	8.5	NA	NA	105	NA	0	0	0
0.6	9.3	NA	NA	104	NA	0	0	0
NA	9.3	NA	NA	108	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	9.3	NA	14	107	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	9.4	NA	NA	105	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
NA	9.5	1.1	16	NA	NA	0	0	0
0.5	9.2	1.3	NA	108	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
NA	NA	NA	NA	96	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.1	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
NA	10.5	2.9	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	9.5	3.2	NA	NA	NA	0	0	1
0.3	NA	3.2	NA	NA	NA	0	0	1
0.6	NA	1.2	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.7	NA	2.4	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	223	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
1.1	9.6	7	NA	103	NA	0	0	1
1.2	NA	NA	NA	108	NA	0	0	1
0.3	NA	1.2	NA	110	NA	0	0	0
0.7	NA	1.2	NA	103	NA	0	0	0
0.5	NA	NA	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9.4	NA	NA	103	NA	0	0	0
NA	NA	1.9	NA	NA	188	0	0	0
0.2	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	1
0.4	NA	1.7	NA	NA	NA	0	0	1
0.3	NA	6.4	NA	NA	NA	0	0	1
0.3	9.2	18	NA	103	NA	0	0	1
NA	NA	28	28	NA	NA	0	0	1
0.3	9.4	32	NA	NA	NA	0	0	1
0.3	9	40	NA	NA	NA	0	0	1
0.2	NA	51	NA	NA	NA	0	0	1
0.2	9.8	49	NA	NA	NA	0	0	1
0.4	NA	40	NA	NA	NA	0	0	1
0.5	NA	45	NA	NA	NA	0	0	1
0.6	NA	54	NA	NA	NA	0	0	1
0.4	8.8	47	NA	106	NA	0	0	1
0.4	NA	34	NA	NA	NA	0	0	1
NA	NA	45	NA	NA	NA	0	0	1
0.7	NA	76	NA	107	NA	0	0	1
NA	NA	110	NA	102	NA	0	0	1
0.2	NA	2.8	NA	NA	NA	0	0	0
0.5	8.5	1.6	NA	105	NA	0	0	0
0.5	NA	6.3	NA	NA	NA	0	0	1
12.6	NA	2.3	NA	NA	NA	1	0	1
1.9	NA	4.8	NA	99	NA	0	0	1
0.9	NA	8.2	NA	87	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
5	8.2	18	NA	84	NA	0	0	1
3.3	7.1	19	NA	97	NA	0	0	1
1.7	NA	18	NA	93	NA	0	0	1
1	NA	14	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.4	7.5	14	NA	101	NA	0	0	1
NA	7.7	NA	NA	93	NA	0	0	1
4.7	NA	30	NA	NA	NA	0	0	1
2.7	8.6	3.7	NA	96	77	0	0	0
1	NA	1.4	NA	101	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.8	NA	4.5	NA	NA	NA	0	0	0
0.6	NA	3.5	NA	NA	NA	0	0	0
0.7	NA	9	NA	NA	NA	0	0	0
0.7	NA	9.2	NA	NA	NA	0	0	0
1.2	NA	8.5	NA	NA	NA	0	0	0
0.6	NA	9.4	NA	NA	NA	0	0	0
0.8	8.7	9.6	NA	NA	NA	0	0	0
1.1	8.8	10	NA	NA	NA	0	0	0
1.7	8.4	9.5	NA	NA	NA	0	0	0
1.2	NA	9.8	NA	NA	NA	0	0	0
1.1	NA	9.6	NA	106	NA	0	0	0
1.4	NA	10	NA	NA	NA	0	0	0
1.7	NA	12	NA	NA	NA	0	0	1
1.4	8.8	10	NA	NA	NA	0	0	1
NA	8	NA	NA	NA	NA	0	0	1
1.5	8	11	NA	NA	NA	0	0	0
1.1	NA	12	NA	NA	NA	0	0	0
1.2	NA	9.6	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	9.6	1	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	237	0	0	0
NA	NA	3.4	NA	NA	NA	0	0	0
0.6	8.8	NA	12	102	161	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	10	2.6	NA	100	NA	0	0	0
0.4	10	2.8	NA	97	NA	0	0	0
0.7	9.7	NA	NA	95	NA	0	0	0
0.5	NA	NA	NA	95	NA	0	0	0
NA	10.2	NA	NA	92	NA	0	0	0
0.3	8.9	NA	NA	104	NA	0	0	0
NA	NA	NA	NA	104	NA	0	0	0
0.3	9.1	NA	NA	97	NA	0	0	0
NA	8.8	NA	NA	103	NA	0	0	0
0.5	9.9	3.5	NA	104	NA	0	0	0
1.3	8.6	2.7	NA	96	NA	0	0	0
0.3	NA	3.9	9.2	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
0.4	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
NA	NA	3.2	NA	NA	NA	0	0	0
0.5	9.2	2.9	NA	NA	175	0	0	0
0.4	9.1	2.8	NA	NA	NA	0	0	0
NA	NA	3.2	NA	105	153	0	0	0
2	NA	NA	NA	NA	NA	0	0	0
0.4	9.8	1.7	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	154	0	0	0
1.9	9.4	6.6	NA	106	101	0	0	0
NA	NA	2.4	NA	93	NA	0	0	0
0.3	9.3	NA	NA	105	181	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
NA	NA	4.8	NA	NA	NA	0	0	1
0.4	8.8	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	100	NA	0	0	1
1	NA	NA	NA	94	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
0.6	NA	27	NA	100	NA	0	0	0
0.7	9	NA	NA	100	NA	0	0	0
6.7	9.2	NA	NA	102	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
3.9	8.7	396	NA	104	NA	0	0	1
8.9	8.7	NA	NA	103	NA	0	0	1
0.6	8.8	4.7	NA	106	NA	0	0	1
0.3	9.6	NA	NA	101	NA	0	0	0
0.3	9.5	NA	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	9.4	NA	NA	101	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	102	NA	0	0	0
0.3	9.9	NA	NA	103	NA	0	0	0
0.2	9.9	NA	NA	101	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
6.4	NA	NA	NA	101	NA	0	0	1
4	NA	NA	NA	NA	NA	0	0	1
2.6	NA	NA	NA	105	NA	0	0	1
1.3	10.1	NA	NA	105	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	105	NA	0	0	1
0.6	NA	NA	NA	106	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	109	NA	0	0	1
0.3	9.7	NA	NA	106	NA	0	0	1
0.4	9.6	NA	NA	108	NA	0	0	0
0.5	9.8	NA	NA	107	NA	0	0	0
0.3	9.6	NA	NA	107	NA	0	0	0
0.4	NA	NA	NA	108	NA	0	0	0
0.5	9.5	NA	NA	106	NA	0	0	1
0.9	9.5	NA	NA	106	NA	0	0	1
0.7	10	NA	NA	108	NA	0	0	1
0.3	9.7	NA	NA	108	NA	0	0	1
0.4	9.6	NA	NA	107	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.9	NA	NA	108	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	10.1	NA	NA	108	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	10	NA	NA	109	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	10.1	NA	NA	100	NA	0	0	1
NA	9.5	NA	NA	100	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	1
0.5	8.9	2.4	NA	103	NA	0	0	1
0.6	NA	1.7	NA	NA	NA	0	0	1
0.7	NA	1.6	NA	NA	NA	0	0	1
0.5	NA	1.9	NA	NA	NA	0	0	1
NA	NA	2.8	79	NA	NA	0	0	1
0.3	NA	3.1	NA	NA	NA	0	0	1
0.5	NA	3	NA	NA	NA	0	0	1
0.4	NA	3	NA	NA	NA	0	0	1
NA	8.7	2.5	NA	NA	NA	0	0	1
2.1	NA	NA	NA	94	155	0	0	0
0.3	10.2	48	NA	107	NA	0	0	1
0.3	10.1	82	NA	109	NA	0	0	1
NA	NA	138	NA	NA	NA	0	0	1
NA	NA	385	NA	NA	NA	0	0	1
0.5	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
0.6	NA	2.8	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
NA	9.9	2.2	NA	NA	NA	0	0	0
0.8	9.2	2.2	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.7	10.3	1.9	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.7	9.5	2	NA	NA	NA	0	0	0
0.4	9.7	NA	NA	NA	NA	0	0	1
0.5	8.6	NA	17	108	NA	0	0	0
0.3	9.8	1.6	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	101	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	NA	NA	100	NA	0	0	0
0.4	9.7	3	NA	NA	NA	0	0	0
0.3	9.3	3	NA	NA	NA	0	0	0
0.4	9.2	3.2	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.2	8.9	1.5	NA	NA	NA	0	0	0
0.4	8.1	6.9	642	96	NA	0	0	0
0.3	9.2	NA	NA	107	NA	0	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.3	8.9	1.2	21	NA	NA	0	0	0
0.3	9.4	1.7	NA	104	NA	0	0	1
1.6	8.4	1.1	NA	105	NA	0	0	1
0.5	10	1	NA	103	180	0	0	1
1.5	NA	NA	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	1	0	0
1.6	NA	NA	NA	101	NA	0	0	0
1.4	NA	NA	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	1	0	0
1.5	NA	NA	NA	NA	NA	1	0	0
1.5	NA	NA	NA	NA	NA	1	0	0
1.1	NA	NA	NA	103	NA	1	0	0
0.5	NA	3.5	NA	NA	NA	0	0	0
0.3	8.9	2.5	NA	106	NA	0	0	0
0.4	9.6	3	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.5	NA	2.7	NA	NA	NA	0	0	0
1	8.9	NA	NA	106	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.5	9.1	1.3	NA	103	NA	0	0	0
0.4	7.8	2.5	NA	105	NA	0	0	0
0.3	10.4	19	NA	NA	NA	0	0	1
0.6	10.6	26	NA	NA	NA	0	0	1
NA	NA	22	NA	NA	NA	0	0	1
NA	NA	18	NA	NA	NA	0	0	1
NA	10.2	15	NA	NA	NA	0	0	1
NA	9.5	28	NA	NA	NA	0	0	0
NA	9.7	25	NA	NA	NA	0	0	1
0.4	NA	35	NA	NA	NA	0	0	1
0.3	9.9	39	NA	NA	NA	0	0	1
0.3	8.8	2.4	8.3	105	NA	0	0	0
0.2	9.1	NA	NA	NA	NA	0	0	0
0.8	8.9	3.2	NA	92	NA	0	0	0
0.2	9.6	3.3	NA	102	NA	0	0	1
0.2	9.8	3	NA	100	NA	0	0	1
0.4	8.9	2.7	NA	96	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	4.7	NA	NA	NA	0	0	1
0.2	9.4	5.1	NA	102	NA	0	0	1
0.3	NA	4.4	NA	NA	NA	0	0	1
0.4	9.9	4.1	NA	105	NA	0	0	1
0.3	9.8	3.9	NA	NA	NA	0	0	1
0.2	9.4	4.8	NA	104	NA	0	0	1
NA	9.1	4.3	NA	104	NA	0	0	1
0.2	9.6	5.1	NA	102	NA	0	0	1
NA	NA	5.1	NA	102	NA	0	0	1
0.4	9.6	3.8	NA	104	NA	0	0	1
0.4	9.4	3.6	NA	103	NA	0	0	1
0.3	NA	3.6	NA	102	NA	0	0	1
0.2	9.2	3.7	NA	101	NA	0	0	1
0.4	8.8	4.9	NA	101	NA	0	0	1
0.7	7.5	NA	NA	99	NA	0	0	1
0.3	9.1	3.6	NA	NA	NA	0	0	1
0.4	9.8	4.9	NA	NA	NA	0	0	1
0.2	9.6	6.3	NA	NA	NA	0	0	1
0.5	9.6	9.1	NA	NA	NA	0	0	1
0.3	9.8	10	NA	103	NA	0	0	1
0.3	NA	11	NA	NA	NA	0	0	1
0.9	NA	29	NA	107	NA	0	0	1
1.8	8.1	81	NA	116	NA	0	0	1
0.9	8	NA	NA	109	NA	0	0	1
0.6	NA	1.3	268	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	10.8	1.2	NA	100	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
1.1	8.5	4.6	NA	109	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	0
1.1	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	99	NA	0	0	0
0.6	NA	NA	NA	109	165	0	0	0
1.2	NA	4	NA	103	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
1.2	NA	NA	NA	NA	NA	1	0	0
0.9	NA	4.2	NA	NA	NA	0	0	0
1.2	NA	NA	NA	NA	NA	0	0	0
0.6	8.5	NA	NA	104	NA	0	0	0
12.1	8.2	3.2	NA	110	NA	0	0	1
1.4	8.7	NA	NA	94	NA	0	0	0
NA	8.8	3.6	NA	NA	NA	0	0	1
NA	NA	7.6	NA	99	NA	0	0	1
0.4	NA	1.6	NA	NA	NA	1	0	0
3.4	10.4	269	NA	98	NA	0	0	1
0.6	NA	2.7	NA	NA	NA	0	0	0
0.7	NA	2.7	NA	NA	NA	0	0	0
0.8	NA	2.4	NA	NA	NA	0	0	0
0.9	NA	2.2	NA	NA	NA	0	0	0
0.9	NA	3.1	NA	NA	NA	0	0	0
0.9	NA	2.4	NA	NA	NA	0	0	0
1	8.7	5.7	NA	105	NA	0	0	0
1.6	8.9	NA	NA	102	NA	0	0	0
0.4	8.9	NA	NA	105	NA	0	0	0
0.2	NA	2	6	NA	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
NA	NA	2.5	16	NA	NA	0	0	0
1.1	NA	1.2	NA	NA	NA	0	0	0
0.5	10	2.9	NA	104	154	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	15	NA	102	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.4	NA	5.5	NA	NA	NA	0	0	1
0.4	NA	4.7	NA	NA	NA	0	0	0
0.4	NA	4.7	NA	NA	NA	0	0	1
0.2	NA	4	NA	104	NA	0	0	0
0.2	NA	4.4	NA	NA	NA	0	0	0
0.3	NA	6	NA	NA	NA	0	0	1
0.3	NA	4.5	NA	NA	NA	0	0	0
NA	8.7	3.3	NA	100	NA	0	0	0
0.3	NA	4	NA	NA	NA	0	0	1
0.3	NA	4.8	NA	NA	NA	0	0	1
0.3	NA	4.7	NA	NA	NA	0	0	0
0.3	NA	4.4	NA	NA	NA	0	0	0
0.4	NA	4.5	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	10.1	2.1	NA	100	NA	0	0	0
3.6	NA	NA	NA	99	NA	1	1	1
1.2	8.6	NA	NA	102	NA	0	0	1
5.2	9.1	NA	126	100	NA	0	0	1
0.3	NA	2.4	NA	103	156	0	0	0
0.2	9.2	2.5	NA	NA	NA	0	0	0
0.2	8.9	1.9	NA	NA	NA	0	0	0
0.3	8.5	2.2	NA	NA	NA	0	0	0
NA	8.7	2.5	NA	NA	NA	0	0	0
0.2	8.6	2	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.3	8.7	2.4	NA	NA	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
2.5	8.4	5.7	NA	103	NA	0	0	1
2	NA	4.3	NA	105	120	0	0	1
0.4	NA	2.3	NA	NA	184	0	0	0
0.6	NA	2.5	23	NA	NA	0	0	0
0.5	10.1	2	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.6	9.1	2.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	9.3	NA	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	1.4	9.4	NA	NA	0	0	0
0.4	10.6	NA	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.3	12	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	8.4	NA	2748	102	NA	0	0	1
0.3	NA	1	NA	NA	NA	0	0	0
0.1	NA	NA	25	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	262	0	0	0
0.5	9.2	NA	NA	103	230	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.8	9.7	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	1	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.8	NA	2.3	NA	NA	NA	0	0	1
0.8	NA	NA	NA	107	NA	0	0	1
3.6	NA	3.6	NA	101	NA	0	0	1
2.1	8.5	NA	NA	106	NA	0	0	1
4.2	8.7	2.7	NA	107	97	0	0	1
2.4	8.9	NA	NA	105	NA	0	0	1
2.7	NA	NA	NA	105	NA	0	0	1
2.2	NA	NA	NA	105	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	9.3	22	NA	99	NA	0	0	0
NA	NA	3.4	NA	NA	NA	0	0	0
1.2	8.7	1.5	NA	101	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	1
0.4	NA	1.9	NA	NA	NA	0	0	1
0.4	NA	2.3	NA	NA	NA	0	0	1
0.4	NA	2.6	NA	NA	NA	0	0	1
0.3	NA	1.2	NA	NA	NA	0	0	1
NA	8.2	1.1	NA	108	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	8.9	NA	NA	108	NA	0	0	0
0.3	9.3	NA	NA	106	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	8.9	NA	NA	NA	NA	0	0	0
0.3	10.3	1	NA	104	NA	0	0	1
0.3	9.1	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	9.2	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.1	15	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.4	8.8	NA	NA	105	NA	0	0	0
NA	8.8	NA	NA	105	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	9	NA	17	NA	NA	0	0	1
0.4	8.8	1	NA	105	NA	0	0	1
NA	NA	1.3	18	NA	NA	0	0	0
NA	9	NA	NA	107	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	9.3	NA	NA	104	NA	0	0	0
0.4	8.9	1.2	NA	107	NA	0	0	0
NA	NA	1.4	NA	107	NA	0	0	1
0.4	9.4	1.1	NA	105	NA	0	0	1
0.2	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	NA	NA	105	NA	0	0	1
0.4	9.3	1.7	NA	104	NA	0	0	0
0.4	NA	1.8	NA	105	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	1
NA	9.1	2.3	NA	105	NA	0	0	1
0.3	9.1	2.6	NA	107	NA	0	0	1
0.4	8	7	NA	103	NA	0	0	0
0.8	9.4	4.1	11	104	NA	0	0	0
0.5	NA	1.8	NA	105	NA	0	0	0
0.8	9.4	1.6	16	105	NA	0	0	0
0.8	10	2.6	16	105	NA	0	0	0
0.4	9.8	1.8	16	103	NA	0	0	0
0.7	9.4	1.9	16	104	NA	0	0	0
1.4	9	2.1	NA	104	NA	0	0	0
NA	NA	NA	NA	96	NA	0	0	1
1.9	NA	2.4	NA	NA	NA	0	0	0
0.4	9.8	1.7	NA	100	154	0	0	0
0.5	NA	2.8	NA	103	NA	0	0	0
0.5	NA	2.9	NA	101	NA	0	0	0
0.6	10.1	3.1	13	101	NA	0	0	0
4.3	9.6	9	NA	101	NA	0	0	1
0.3	NA	1	NA	NA	NA	0	0	0
0.1	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
NA	NA	4.3	8	92	NA	0	0	1
NA	8.2	NA	NA	111	NA	0	0	1
0.4	8.8	NA	NA	106	NA	0	0	1
0.4	NA	2.2	4.4	NA	NA	0	0	1
0.4	8.9	NA	NA	107	NA	0	0	1
0.3	8.9	NA	NA	107	NA	0	0	1
NA	NA	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	8.6	NA	NA	107	NA	0	0	1
0.4	8.2	NA	NA	105	NA	0	0	1
1.4	8.9	5.4	NA	103	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	4.5	NA	NA	NA	0	0	0
NA	NA	3.9	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.6	NA	NA	NA	105	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	101	NA	0	0	0
NA	10.8	NA	NA	NA	NA	0	0	0
0.6	10.2	NA	NA	NA	239	0	0	0
0.4	9.8	NA	NA	NA	226	0	0	0
0.4	9.4	1.1	NA	NA	NA	0	0	0
0.6	NA	11	NA	NA	NA	0	0	1
NA	NA	21	NA	NA	NA	0	0	1
NA	8.2	63	NA	105	NA	0	0	1
0.4	NA	64	NA	105	NA	0	0	1
0.5	NA	1.3	NA	107	NA	0	0	0
NA	9.9	NA	NA	NA	NA	0	0	0
0.3	9.9	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.9	9.4	6.3	NA	92	154	0	0	0
0.6	8.9	63	NA	98	NA	0	0	1
0.5	NA	11	NA	NA	NA	0	0	0
0.2	NA	4	NA	NA	NA	0	0	0
0.2	NA	4.3	NA	NA	NA	0	0	0
0.2	NA	3.8	NA	NA	NA	0	0	0
0.2	NA	3.2	NA	NA	NA	0	0	1
0.4	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.1	3.5	106	200	0	0	0
0.5	NA	1.2	NA	NA	251	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
0.7	NA	NA	28	NA	NA	0	0	0
0.6	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
0.5	9.6	1.5	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
1.9	8.8	7.5	NA	100	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.2	9.4	2.9	NA	97	NA	0	0	0
0.3	9.1	2.4	NA	NA	NA	0	0	0
0.3	9.7	2	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	101	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	8.8	NA	NA	94	NA	0	0	0
0.6	NA	2.2	NA	NA	NA	0	0	0
NA	9.9	1.7	NA	103	222	0	0	0
0.5	9.7	NA	NA	99	241	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	9.3	NA	NA	NA	242	0	0	1
0.6	10.1	172	NA	NA	NA	0	0	1
NA	NA	267	NA	NA	NA	0	0	1
0.6	9.5	235	NA	NA	NA	0	0	1
0.7	9.3	305	NA	100	NA	0	0	1
NA	NA	424	NA	NA	NA	0	0	1
NA	NA	342	NA	NA	NA	0	0	1
NA	NA	244	NA	NA	NA	0	0	1
NA	NA	268	NA	NA	NA	0	0	1
1.3	8.6	259	NA	NA	NA	0	0	1
NA	NA	361	NA	NA	NA	0	0	1
NA	NA	182	NA	NA	NA	0	0	1
0.5	NA	138	NA	NA	NA	0	0	1
NA	NA	49	NA	NA	NA	0	0	1
0.5	NA	39	NA	NA	NA	0	0	1
1	NA	33	NA	NA	NA	0	0	1
0.2	NA	6.7	NA	NA	NA	0	0	0
2.5	8.1	6.7	NA	105	110	0	0	0
0.7	NA	3.7	NA	NA	NA	1	0	0
1.8	9.5	NA	52	100	NA	0	0	1
0.7	8.9	NA	NA	101	NA	0	0	1
1.8	NA	NA	NA	NA	NA	0	0	1
1.8	NA	NA	NA	102	NA	0	0	1
1.7	NA	NA	NA	NA	NA	0	0	1
1.3	NA	NA	NA	NA	NA	0	0	1
1.4	NA	NA	NA	NA	NA	0	0	1
1.6	9.4	NA	NA	98	NA	0	0	1
2.8	NA	NA	NA	NA	NA	0	0	1
3	NA	NA	NA	NA	NA	0	0	1
14.3	9.3	NA	NA	119	NA	0	0	0
1	9	3.1	NA	101	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.7	9.6	NA	NA	99	NA	0	0	0
4.1	8.8	15	NA	102	NA	0	0	0
0.5	NA	3.4	NA	NA	NA	0	0	1
0.5	NA	3.7	16	NA	NA	0	0	1
0.6	NA	3.6	18	NA	NA	0	0	1
0.6	NA	3.7	NA	NA	NA	0	0	1
NA	NA	4.1	NA	NA	NA	0	0	1
0.5	NA	3.4	NA	NA	NA	0	0	1
0.6	NA	3.1	22	NA	NA	0	0	1
0.4	NA	3.6	NA	NA	NA	0	0	1
0.4	NA	3.6	NA	NA	NA	0	0	1
0.5	NA	4.1	NA	NA	NA	0	0	1
0.4	NA	3.8	NA	NA	NA	0	0	1
0.4	NA	4	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	10	NA	NA	102	NA	0	0	1
0.5	NA	4.1	NA	NA	NA	0	0	1
0.4	10.3	4	NA	NA	NA	0	0	1
0.4	NA	4.4	NA	NA	NA	0	0	1
0.4	NA	4.8	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	9.1	2.9	NA	NA	NA	0	0	0
NA	9.6	3.7	NA	NA	NA	0	0	0
NA	NA	3.6	NA	NA	NA	0	0	0
0.3	NA	6.8	NA	NA	NA	0	0	0
0.2	9.3	9.4	NA	NA	NA	0	0	0
0.4	NA	14	NA	NA	NA	0	0	0
0.5	7.1	3971	NA	95	NA	0	0	1
NA	NA	2.3	NA	NA	NA	0	0	0
0.8	8.2	1.4	NA	105	NA	0	0	0
0.3	NA	10	NA	NA	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	1
0.3	NA	NA	NA	100	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	5.9	NA	NA	NA	0	0	0
0.4	10.1	6	NA	104	246	0	0	0
0.5	NA	6.8	NA	NA	NA	0	0	0
0.3	NA	5.8	NA	NA	NA	0	0	0
0.2	NA	5.9	NA	NA	NA	0	0	0
0.2	NA	5.2	NA	NA	NA	0	0	0
0.3	9.9	5.6	NA	NA	NA	0	0	0
0.3	9.8	5.3	NA	103	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.5	NA	3.2	NA	104	NA	0	0	0
0.4	NA	3.7	NA	NA	NA	0	0	0
0.5	NA	2.9	NA	NA	NA	0	0	0
0.2	NA	2.7	NA	NA	203	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	3.1	NA	NA	NA	0	0	0
NA	8.3	2.5	NA	104	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.9	NA	1.1	6.2	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
4.3	NA	4.1	NA	99	NA	1	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	101	NA	0	0	1
0.1	NA	NA	NA	98	NA	0	0	1
0.3	8.9	NA	NA	102	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.5	8.3	NA	NA	105	NA	0	0	1
0.4	NA	NA	NA	106	NA	0	0	1
NA	9.1	NA	NA	103	NA	0	0	1
0.7	8.8	NA	NA	103	NA	0	0	1
1.1	8.4	NA	NA	99	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	8	NA	NA	NA	NA	0	0	1
0.8	8.3	8.6	NA	NA	NA	0	0	1
0.6	8.1	8.6	NA	104	NA	0	0	1
0.6	NA	1.6	23	NA	NA	0	0	0
NA	NA	4.5	NA	NA	NA	0	0	0
0.3	8.4	2.9	NA	117	NA	1	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	1
NA	9.4	1.9	4210	NA	NA	0	0	1
0.5	NA	2	81	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.7	NA	3.3	NA	NA	NA	0	0	0
NA	10.3	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	101	NA	0	0	0
1	NA	NA	NA	100	214	0	0	0
0.4	NA	NA	NA	98	NA	0	0	0
0.3	9.3	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.7	NA	3	NA	103	NA	0	0	0
NA	NA	3.5	NA	NA	NA	0	0	0
0.7	7.9	17	NA	109	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.7	9.4	3	NA	NA	NA	0	0	0
NA	NA	3.6	NA	NA	NA	0	0	0
NA	NA	3.6	NA	NA	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
0.3	8.9	3.6	NA	104	NA	0	0	0
0.4	NA	3.5	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
NA	NA	2.2	NA	103	NA	0	0	0
3.6	9.4	5.9	NA	105	NA	0	0	0
14.5	9.1	4.5	NA	102	NA	0	0	1
NA	8.9	NA	NA	100	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	4.2	NA	107	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	1
0.5	9.7	NA	NA	101	NA	0	0	1
0.6	9.4	2	NA	100	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	9.1	NA	NA	NA	NA	0	0	1
0.9	9.6	3.1	NA	NA	NA	0	0	1
NA	NA	2.8	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.6	9.5	NA	NA	NA	NA	0	0	1
0.6	9.6	NA	NA	NA	NA	0	0	1
NA	NA	9.7	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	1
1	NA	15	NA	NA	NA	0	0	1
NA	9.1	12	NA	108	NA	0	0	1
1.1	NA	12	NA	NA	NA	0	0	1
1	9.2	2.5	NA	104	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	103	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	5.9	NA	222	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2.4	9.4	NA	NA	0	0	0
0.6	NA	NA	NA	103	NA	0	0	1
1	10.8	4.1	NA	98	134	0	0	0
7.3	NA	4.7	NA	96	NA	0	0	0
NA	NA	3.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	9.6	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
5.1	8.4	7.4	NA	102	NA	0	0	1
0.4	10.1	NA	NA	NA	218	0	0	0
NA	10.1	2.3	NA	NA	NA	0	0	1
0.4	10	2.2	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.3	NA	NA	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	1
NA	NA	2.3	NA	NA	NA	0	0	1
0.2	9.8	3.4	NA	100	NA	0	0	0
0.5	9.4	2.8	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.7	NA	1.1	16	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.9	NA	99	NA	0	0	0
10.2	NA	8.9	NA	97	NA	0	0	0
0.3	10.3	NA	NA	93	NA	0	0	1
0.6	NA	2.2	NA	NA	NA	0	0	0
0.4	9.7	703	NA	102	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	7.3	13	NA	108	NA	0	0	0
NA	9.4	NA	NA	NA	NA	0	0	1
0.4	NA	1.6	NA	NA	NA	0	0	1
0.3	NA	2	NA	NA	NA	0	0	1
0.3	NA	1	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	8.8	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	15	NA	NA	0	0	0
0.3	NA	0.7	NA	NA	NA	0	0	0
0.3	NA	NA	13	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	13	NA	NA	0	0	0
0.4	9.1	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9.6	0.6	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	9.3	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.1	NA	1.7	NA	NA	NA	0	0	0
0.4	8.7	2.6	NA	NA	NA	0	0	0
0.4	NA	4	NA	NA	NA	0	0	1
0.4	NA	5.7	NA	NA	186	0	0	1
0.5	9.1	8.2	NA	NA	NA	0	0	1
NA	NA	10	13	NA	NA	0	0	1
0.3	NA	14	NA	NA	NA	0	0	1
NA	NA	20	NA	NA	NA	0	0	1
0.4	NA	12	NA	NA	NA	0	0	1
0.4	NA	5	NA	NA	NA	0	0	1
NA	NA	4.4	NA	NA	NA	0	0	1
NA	NA	5.4	NA	NA	NA	0	0	1
0.4	NA	6.9	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	7.1	NA	NA	NA	0	0	1
NA	NA	11	NA	NA	NA	0	0	1
0.3	NA	14	NA	NA	NA	0	0	1
NA	NA	18	NA	NA	NA	0	0	1
0.4	NA	17	NA	NA	NA	0	0	1
NA	NA	20	NA	NA	NA	0	0	1
0.3	NA	2.4	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.2	10.1	2.4	NA	NA	NA	0	0	0
0.2	9.7	2.6	NA	NA	NA	0	0	0
0.4	10	1.4	NA	NA	NA	0	0	0
0.4	9.9	1.5	NA	NA	NA	0	0	0
0.4	9.9	1.4	NA	NA	205	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
NA	10.2	1.4	NA	NA	NA	0	0	0
0.3	9.3	1.5	NA	NA	NA	0	0	0
0.3	NA	NA	NA	104	267	0	0	0
1.3	9.3	NA	NA	108	195	0	0	0
0.2	NA	NA	NA	104	NA	0	0	0
0.6	NA	3.1	NA	NA	NA	0	0	0
0.5	NA	2.9	NA	NA	NA	0	0	0
0.7	NA	3	NA	NA	NA	0	0	0
1.1	8.4	1.5	NA	99	167	0	0	0
11.6	8.6	32	NA	103	124	0	0	1
0.5	NA	2.6	10	NA	NA	0	0	0
0.5	NA	3.7	NA	NA	NA	0	0	0
0.6	NA	3	NA	NA	NA	0	0	0
0.6	NA	3.1	NA	NA	NA	0	0	0
0.2	10.2	3.6	NA	NA	NA	0	0	1
0.3	9.6	3.1	16	NA	NA	0	0	0
0.2	8.9	3.1	98	NA	NA	0	0	1
NA	9.1	5	NA	100	NA	0	0	1
0.5	NA	1.8	16	NA	249	0	0	0
0.5	NA	3.3	NA	NA	NA	0	0	0
0.5	NA	3	26	NA	NA	0	0	0
0.4	NA	2.5	21	NA	266	0	0	0
0.4	NA	1.9	NA	102	153	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	3.6	20	NA	166	0	0	0
NA	NA	NA	341	NA	NA	0	0	0
NA	8.3	4.3	25	101	NA	0	0	0
0.3	9.6	2.6	NA	105	NA	0	0	0
0.8	NA	2	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	103	NA	0	0	1
0.4	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	2.1	12	NA	NA	0	0	0
0.4	NA	1.7	12	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.9	13	NA	NA	0	0	0
0.4	NA	1.6	15	NA	NA	0	0	0
0.3	9.6	2	15	NA	NA	0	0	0
0.5	9.7	2.3	9.7	NA	NA	0	0	0
0.2	NA	4.4	NA	94	NA	0	0	0
0.3	9.1	1.1	13	NA	NA	0	0	0
0.2	NA	1.6	13	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	9	NA	NA	NA	NA	0	0	0
0.3	10.3	1.5	NA	NA	184	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
NA	9.2	NA	NA	107	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	8.7	NA	NA	107	NA	0	0	0
1.2	8.9	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.9	9.1	NA	NA	109	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	108	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1	8.9	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
1	8.7	NA	NA	108	NA	0	0	1
1.5	NA	NA	NA	NA	NA	0	0	1
0.8	8.9	NA	NA	105	NA	0	0	1
0.9	8.9	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	8.8	NA	NA	103	NA	0	0	1
1.3	8.9	NA	NA	106	NA	0	0	1
NA	8.6	NA	NA	103	NA	0	0	1
2.3	8.5	NA	NA	109	NA	0	0	1
0.5	7.9	NA	NA	NA	NA	0	0	1
0.6	7.7	NA	NA	105	NA	0	0	1
1.2	8	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
NA	NA	1.1	NA	102	NA	0	0	0
NA	NA	NA	NA	101	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	2	5.9	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2	5.6	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.6	9.3	1.4	NA	102	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	2	10	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.2	9.3	3.2	NA	NA	NA	0	0	0
NA	NA	3.2	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	251	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	8.9	NA	NA	99	NA	0	0	0
0.5	NA	3.8	NA	NA	NA	0	0	0
0.7	9.3	NA	NA	NA	NA	0	0	0
0.4	9	4.4	NA	NA	NA	0	0	0
0.6	9.4	5.6	NA	NA	NA	0	0	0
8.8	9.9	453	NA	98	NA	0	0	1
0.3	9.2	5.5	NA	95	NA	0	0	0
2	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	112	NA	0	0	0
1.3	8.7	NA	NA	105	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
NA	NA	3.1	NA	101	NA	0	0	0
NA	9.8	3.3	NA	102	NA	0	0	0
0.3	9.3	3.4	NA	97	NA	0	0	0
0.2	NA	2.1	NA	96	NA	0	0	0
0.4	9.4	2	NA	NA	NA	0	0	1
0.6	NA	2.6	NA	NA	NA	0	0	1
0.5	9.4	NA	NA	NA	NA	0	0	1
0.5	NA	3	NA	NA	NA	0	0	1
0.4	9.8	4.9	NA	NA	NA	0	0	1
0.5	9.3	4.8	NA	102	NA	0	0	1
0.5	NA	4.3	NA	NA	NA	0	0	1
0.3	9.8	NA	NA	101	NA	0	0	0
0.5	9.6	NA	NA	102	268	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
NA	9.4	1.5	NA	NA	NA	0	0	0
NA	9.5	1.1	NA	NA	NA	0	0	1
0.3	NA	1.1	30	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.7	8.8	2.7	NA	NA	NA	0	0	0
0.7	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
0.6	NA	1.3	8.4	NA	NA	0	0	0
0.7	NA	1.4	NA	NA	NA	0	0	1
0.7	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	1
0.5	NA	1.5	11	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.2	NA	1.4	NA	NA	NA	0	0	0
1.3	NA	2	NA	NA	NA	0	0	0
0.9	NA	1.4	NA	NA	NA	0	0	0
0.9	NA	1.1	NA	NA	NA	0	0	0
1.3	NA	1.2	NA	NA	NA	0	0	0
1.2	NA	1.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.2	NA	1	NA	NA	NA	0	0	0
1	NA	1.1	NA	NA	NA	0	0	0
0.8	NA	1.1	NA	NA	NA	0	0	0
1.2	NA	NA	NA	NA	206	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
2.4	8.7	4.8	NA	102	158	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	9.5	2.5	NA	104	NA	0	0	1
0.4	8.9	2.9	NA	103	NA	0	0	1
0.3	8.9	2.4	NA	104	NA	0	0	1
0.4	9.3	3.2	NA	103	NA	0	0	1
0.4	10.3	5.5	NA	NA	NA	0	0	1
0.3	9.2	6.3	NA	107	NA	0	0	1
0.5	9.4	6.1	NA	104	NA	0	0	1
0.6	9.2	5.2	NA	105	NA	0	0	1
0.5	NA	6.5	NA	103	NA	0	0	1
0.6	9.3	5.6	NA	105	NA	0	0	1
0.6	9.6	6.4	NA	103	NA	0	0	1
NA	10.3	5.8	NA	103	NA	0	0	1
0.5	8.9	5.9	NA	106	NA	0	0	1
0.5	9.6	5.7	NA	102	NA	0	0	1
0.4	9.4	6	NA	NA	NA	0	0	1
0.4	9.7	5.9	NA	104	NA	0	0	1
0.2	9.3	4.6	NA	NA	NA	0	0	1
0.3	9.4	3	NA	NA	NA	0	0	0
0.3	9.3	3.7	NA	NA	NA	0	0	1
0.3	9.6	3.1	NA	NA	NA	0	0	0
0.3	9.5	3.1	NA	NA	NA	0	0	1
0.3	NA	3	NA	NA	NA	0	0	0
0.3	9.9	3.1	NA	NA	NA	0	0	1
0.3	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	1
NA	NA	2.6	NA	NA	NA	0	0	1
NA	NA	2.6	NA	NA	NA	0	0	0
0.2	9.6	2.8	NA	NA	NA	0	0	1
0.3	9.1	2.7	NA	102	NA	0	0	0
0.2	9.2	3	NA	NA	NA	0	0	1
0.2	NA	3.1	NA	NA	NA	0	0	1
0.5	10	2.6	NA	NA	NA	0	0	1
0.3	NA	3	NA	NA	NA	0	0	1
0.3	NA	2.7	NA	NA	NA	0	0	1
0.3	9	3	NA	106	NA	0	0	1
0.3	10.1	2.7	NA	NA	NA	0	0	1
0.3	9.5	2.5	NA	NA	NA	0	0	1
0.3	NA	3	NA	NA	NA	0	0	1
0.3	NA	2.8	NA	NA	NA	0	0	1
0.3	NA	3.8	NA	NA	NA	0	0	1
0.4	9.7	4.1	NA	NA	NA	0	0	1
0.2	9	4	36	NA	NA	0	0	1
0.3	NA	5.3	NA	NA	NA	0	0	1
0.3	NA	3.8	NA	NA	NA	0	0	1
NA	9.7	4.2	NA	102	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	0
NA	NA	3.6	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.8	NA	NA	NA	102	NA	0	0	0
0.8	NA	NA	NA	103	NA	0	0	0
0.7	NA	NA	NA	100	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	1	0
1.1	NA	NA	NA	99	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
10	7.8	6.8	157	94	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	65	31	NA	NA	0	0	1
4.1	NA	4	NA	107	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	9.7	4.5	276	102	NA	0	0	1
1.8	9.3	8.4	NA	104	173	0	0	1
1.2	NA	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.6	NA	NA	NA	103	NA	0	0	1
1.9	NA	NA	NA	103	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.2	9.1	13	NA	NA	NA	0	0	1
0.2	8.4	21	NA	108	NA	0	0	1
0.1	8.8	21	NA	NA	NA	0	0	1
0.2	10.3	24	NA	NA	NA	0	0	1
0.3	9.2	31	NA	NA	NA	0	0	1
0.3	NA	35	NA	NA	NA	0	0	1
NA	NA	27	NA	NA	NA	0	0	1
0.4	NA	25	NA	NA	NA	0	0	1
0.2	NA	23	NA	NA	NA	0	0	1
0.3	9.1	31	NA	NA	NA	0	0	1
0.4	9.7	NA	NA	NA	NA	0	0	1
0.3	9.4	38	NA	105	NA	0	0	1
0.3	9.1	26	NA	95	NA	0	0	1
0.3	9.2	21	NA	106	NA	0	0	1
0.3	9.4	25	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	9.4	72	NA	105	NA	0	0	1
0.5	9.5	69	NA	106	NA	0	0	1
0.6	9.1	45	NA	108	NA	0	0	1
0.4	9.5	46	NA	105	NA	0	0	1
0.6	9.2	82	NA	107	NA	0	0	1
0.4	9.5	146	NA	105	NA	0	0	1
0.4	NA	230	NA	NA	NA	0	0	1
0.4	NA	197	NA	NA	NA	0	0	1
0.4	8	191	NA	109	NA	0	0	1
0.9	8.5	233	NA	107	NA	0	0	1
3.2	8.4	355	NA	109	NA	0	0	1
8.3	8.4	489	NA	109	NA	0	0	1
0.4	9.7	3.4	NA	NA	NA	0	0	0
0.5	9.4	2.9	NA	NA	NA	0	0	0
0.4	NA	3.1	NA	NA	NA	0	0	0
0.2	NA	4.6	NA	NA	NA	0	0	0
NA	NA	3.6	NA	NA	NA	0	0	0
0.3	NA	4.3	NA	NA	NA	0	0	0
NA	9.8	NA	NA	100	184	0	0	0
0.2	NA	NA	NA	105	NA	0	0	1
0.2	9.3	1.7	NA	96	NA	0	0	1
0.2	NA	NA	NA	98	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	9	1	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	157	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.8	NA	1.2	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.8	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	NA	14	NA	NA	0	0	0
0.2	NA	NA	NA	103	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.3	9	2.5	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
17	NA	6.4	NA	NA	NA	1	0	1
1.1	NA	6.7	NA	96	NA	0	0	1
0.9	NA	NA	NA	93	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	9.5	NA	NA	0	0	0
0.4	NA	1	6.2	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
2.2	9.3	9.2	NA	104	NA	0	0	1
0.7	10.1	NA	16	NA	250	0	0	1
0.4	9.8	NA	23	93	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	9.8	NA	NA	0	0	0
NA	NA	NA	13	NA	NA	0	0	0
NA	NA	NA	12	NA	NA	0	0	0
0.4	NA	NA	13	NA	NA	0	0	0
0.4	NA	NA	12	97	NA	0	0	0
0.3	9.5	2	16	93	NA	0	0	0
NA	9.8	NA	13	97	NA	0	0	0
0.6	10	NA	13	NA	NA	0	0	0
0.4	9.8	NA	16	95	NA	0	0	0
NA	9.4	NA	14	96	NA	0	0	0
0.4	NA	NA	18	97	NA	0	0	0
0.4	NA	NA	14	NA	NA	0	0	1
0.3	NA	NA	14	NA	NA	0	0	1
0.4	NA	NA	26	96	NA	0	0	1
0.3	NA	NA	33	NA	NA	0	0	1
0.3	NA	NA	37	NA	NA	0	0	1
0.4	NA	NA	40	98	NA	0	0	1
0.7	9.4	NA	45	99	NA	0	0	1
0.3	NA	NA	34	NA	NA	0	0	1
0.6	NA	NA	30	94	NA	0	0	1
0.4	9.3	NA	29	95	NA	0	0	1
0.3	9.5	NA	21	97	NA	0	0	1
0.2	8.9	NA	24	93	NA	0	0	1
0.2	9	NA	29	92	NA	0	0	1
0.2	9.6	NA	27	93	NA	0	0	1
0.3	9.7	NA	29	98	NA	0	0	1
0.4	NA	NA	32	NA	NA	0	0	1
0.3	9	NA	30	98	NA	0	0	1
0.4	9.7	NA	40	93	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.2	NA	42	92	NA	0	0	1
0.3	9.4	NA	NA	95	NA	0	0	1
0.2	9.3	NA	NA	97	NA	0	0	0
NA	NA	NA	86	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	95	170	0	0	1
0.5	NA	NA	107	98	NA	0	0	1
0.3	8.8	NA	NA	101	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
14.5	8.3	7.7	NA	93	NA	0	0	0
1.8	9.4	9.4	NA	98	NA	0	0	0
0.6	9	12	NA	93	NA	0	0	0
12.5	8.6	NA	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	169	0	0	0
NA	9.4	NA	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.3	9.4	1.7	NA	NA	NA	0	0	0
0.3	9.2	1.9	NA	105	NA	0	0	1
0.4	NA	5.4	NA	NA	NA	0	0	1
0.7	NA	3.9	NA	NA	NA	0	0	0
1	NA	3.7	NA	NA	NA	0	0	0
1	NA	3.3	NA	NA	NA	0	0	0
1	NA	3.5	NA	NA	NA	0	0	0
1.5	NA	NA	13	NA	NA	0	0	1
1.1	NA	3.4	NA	NA	NA	0	0	0
0.9	NA	3.5	NA	NA	NA	0	0	0
0.3	8.7	5.3	NA	96	NA	0	0	0
NA	10.3	1.4	NA	NA	NA	0	0	0
0.1	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	NA	NA	102	NA	1	0	1
1.2	NA	NA	NA	104	NA	0	0	1
1.8	NA	NA	NA	105	160	0	0	1
1.5	8.1	1.8	44	96	NA	0	0	1
0.8	NA	2.6	NA	105	NA	1	0	1
1.2	NA	NA	NA	96	NA	1	0	1
0.4	10	28	NA	100	NA	0	0	1
0.5	10.1	NA	NA	100	NA	0	0	1
0.4	NA	2.2	NA	106	NA	0	0	0
0.6	NA	3.2	NA	NA	NA	0	0	0
0.9	NA	3.3	NA	NA	NA	0	0	0
0.5	NA	3.1	NA	NA	NA	0	0	0
0.5	NA	2.9	NA	NA	NA	0	0	0
NA	NA	1.1	NA	99	NA	0	0	0
0.5	NA	NA	NA	101	NA	0	0	0
0.2	NA	1.8	NA	102	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
0.2	NA	3.7	NA	NA	NA	0	0	0
0.3	NA	3.2	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.2	NA	2.8	NA	NA	NA	0	0	0
0.3	9.2	6.8	NA	101	NA	0	0	0
0.2	10	NA	NA	NA	NA	0	0	0
0.5	NA	3.3	12	NA	NA	0	0	0
0.8	NA	3.6	10	NA	NA	0	0	0
0.9	9.6	3.3	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.9	NA	3.1	NA	NA	NA	0	0	0
0.4	NA	3.9	NA	NA	NA	0	0	0
0.9	9.5	NA	NA	99	NA	1	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	97	NA	1	0	0
0.2	9.2	59	195	107	NA	0	0	1
0.3	NA	1.4	NA	101	NA	0	1	0
0.2	NA	NA	NA	106	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	1	0
0.3	10.5	71	NA	105	NA	0	0	0
0.2	NA	16	NA	102	NA	1	0	1
0.4	NA	21	NA	NA	NA	0	0	1
NA	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	1
0.3	NA	2.2	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	NA	NA	91	NA	0	0	0
NA	8.3	2.3	22	97	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
NA	NA	1.6	11	NA	NA	0	0	0
2.2	NA	1.6	NA	NA	NA	0	0	0
0.3	10.3	1.8	NA	94	NA	0	0	1
0.6	9	3.8	NA	95	NA	0	0	1
0.3	10.4	2	NA	103	NA	0	0	1
0.3	9.6	2.1	NA	NA	NA	0	0	1
0.5	7.9	2.5	NA	NA	NA	0	0	1
NA	9.6	2.6	NA	NA	NA	0	0	1
0.4	NA	2.2	NA	NA	NA	0	0	1
0.4	NA	NA	11	NA	NA	0	0	0
1.2	8.4	NA	NA	102	NA	0	0	1
0.5	NA	NA	NA	97	140	0	0	1
0.8	NA	1.9	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
1.5	10.2	NA	NA	102	177	0	0	1
NA	NA	NA	NA	102	NA	0	0	1
0.6	7.9	NA	NA	101	NA	0	0	1
0.7	NA	NA	NA	95	140	0	0	1
0.4	7.5	NA	NA	107	NA	0	0	1
0.3	9.7	NA	NA	108	NA	0	0	1
0.2	10.8	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9.7	NA	NA	106	NA	0	0	1
0.4	9.8	NA	NA	105	175	0	0	1
0.5	9.5	NA	NA	107	NA	0	0	1
0.4	9.5	NA	NA	104	NA	0	0	1
0.3	NA	6.5	NA	103	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	8	NA	NA	NA	0	0	1
NA	NA	5.5	NA	NA	NA	0	0	1
0.3	NA	6	NA	NA	NA	0	0	1
0.3	9.4	NA	NA	109	NA	0	0	1
0.3	9	NA	NA	103	NA	0	0	1
0.3	9.1	NA	NA	NA	NA	0	0	1
0.3	NA	4.4	NA	NA	NA	0	0	0
0.4	9.7	NA	NA	106	NA	0	0	1
0.3	9.3	NA	NA	104	179	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	9.1	NA	NA	104	NA	0	0	1
0.3	9.2	NA	NA	105	NA	0	0	1
0.7	9.2	NA	NA	101	NA	0	0	1
0.4	8.9	NA	NA	105	NA	0	0	1
0.7	8.6	NA	NA	105	NA	0	0	1
8.5	9.1	NA	NA	98	NA	0	0	1
0.2	8.7	NA	NA	98	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.4	5.9	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
0.4	NA	2.6	8	NA	NA	0	0	0
0.4	10.4	2.6	NA	NA	NA	0	0	0
0.5	NA	3	NA	NA	188	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.6	NA	3.5	NA	NA	169	0	0	0
0.4	NA	6	NA	NA	175	0	0	0
NA	NA	3.6	NA	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
NA	8.2	1.2	11	105	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	9.9	1.5	NA	93	NA	0	0	0
NA	8.9	NA	NA	NA	NA	0	0	0
NA	9.8	NA	NA	NA	NA	0	0	0
0.3	10.1	NA	NA	NA	NA	0	0	0
0.3	9.5	NA	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.3	8.7	2	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.2	NA	4.4	NA	99	NA	0	0	0
NA	NA	4.5	NA	NA	NA	0	0	0
NA	NA	4.5	NA	NA	NA	0	0	0
NA	NA	4.8	NA	NA	NA	0	0	0
0.2	NA	3.3	NA	NA	NA	0	0	0
1.4	NA	1.1	NA	NA	NA	0	0	0
NA	9.7	1.8	NA	NA	NA	0	0	0
1.1	9	1.5	NA	NA	NA	0	0	0
2	NA	1.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	10.5	2.9	NA	106	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	105	NA	0	0	0
0.5	NA	3.4	NA	103	NA	0	0	0
0.5	NA	4.5	NA	105	NA	0	1	0
0.4	NA	4.6	NA	99	NA	0	0	0
0.3	NA	3.6	NA	NA	NA	0	0	0
0.7	9.5	NA	NA	99	NA	0	1	0
NA	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.5	9	1.7	NA	NA	NA	0	0	0
0.5	NA	2	NA	104	NA	0	0	1
0.4	8.6	NA	NA	104	NA	0	0	0
0.4	9.1	NA	NA	NA	NA	0	0	0
0.2	9.3	NA	NA	105	NA	0	0	0
0.4	NA	4.4	NA	NA	NA	0	0	0
0.4	8.9	3.4	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.6	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.3	9.8	2.2	NA	105	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
0.3	9.5	3.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
0.2	9.7	3.3	NA	105	NA	0	0	0
0.2	9.6	3.3	NA	NA	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
0.3	9.7	4.9	NA	103	NA	0	0	0
NA	NA	5.1	NA	NA	NA	0	0	0
0.3	9.6	5.5	NA	103	270	0	0	0
NA	NA	5.7	NA	NA	NA	0	0	0
0.3	NA	6.4	NA	NA	NA	0	0	0
NA	NA	7.1	NA	NA	NA	0	0	0
NA	NA	6.8	NA	NA	NA	0	0	0
0.2	NA	7	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	10.2	NA	NA	100	NA	0	0	0
NA	NA	NA	NA	99	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	3.3	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.7	8.8	4.8	NA	103	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
NA	9.7	NA	13	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.8	8.1	NA	NA	96	NA	0	0	0
0.4	NA	9	NA	100	NA	0	0	1
0.4	8.2	7.1	NA	110	NA	0	0	1
0.3	8.7	1.6	NA	103	NA	0	0	1
0.3	8.6	5.5	NA	101	NA	0	0	1
NA	8.4	8.5	NA	105	NA	0	0	1
0.2	8.7	10	NA	107	NA	0	0	1
NA	9.4	9	NA	106	NA	0	0	1
NA	8.9	NA	NA	107	NA	0	0	1
0.6	NA	12	NA	102	NA	0	0	0
0.5	8.5	14	NA	NA	NA	0	0	1
0.3	9.1	16	NA	106	NA	0	0	1
0.4	8.9	20	NA	NA	NA	0	0	1
0.3	8.3	20	NA	105	NA	0	0	1
0.3	8.8	21	NA	NA	NA	0	0	1
0.2	9	26	NA	104	NA	0	0	1
0.1	8.4	22	NA	100	NA	0	0	1
0.4	8.3	26	NA	105	NA	0	0	1
0.3	NA	24	NA	104	NA	0	0	1
0.3	9.2	26	NA	105	NA	0	0	1
0.2	NA	28	NA	102	NA	0	0	1
0.3	NA	25	NA	NA	NA	0	0	1
0.3	8.9	23	NA	NA	NA	0	0	1
0.5	8.7	25	NA	NA	NA	0	0	1
0.2	9.1	26	NA	NA	NA	0	0	1
0.2	8.2	28	NA	NA	NA	0	0	1
0.2	8.8	29	NA	102	NA	0	0	1
0.3	9.1	24	NA	NA	NA	0	0	1
0.3	8.3	19	NA	103	NA	0	0	1
0.2	8.7	20	NA	104	NA	0	0	1
0.2	8.7	20	NA	104	NA	0	0	1
0.3	8.1	27	NA	103	NA	0	0	1
0.2	9	27	NA	101	NA	0	0	1
0.3	NA	4.7	NA	NA	NA	0	0	0
NA	9	4.5	NA	107	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	NA	1.9	NA	NA	NA	0	0	0
1.3	NA	2.2	NA	NA	NA	0	0	0
1.1	NA	1.6	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.7	NA	1.6	NA	NA	NA	0	0	0
0.9	NA	1.5	NA	NA	NA	0	0	0
1.3	NA	1.8	20	NA	NA	0	0	0
4.2	8.8	49	57	106	NA	0	0	1
NA	NA	2.5	16	96	NA	0	0	0
0.2	NA	5.1	NA	NA	NA	0	0	0
0.2	NA	8.4	NA	NA	NA	0	0	1
0.2	9.7	7.4	NA	NA	NA	0	0	1
0.2	NA	9.9	NA	NA	NA	0	0	1
0.2	NA	9.7	NA	NA	NA	0	0	1
0.2	9.6	15	NA	NA	NA	0	0	1
0.3	NA	14	NA	NA	NA	0	0	1
NA	NA	14	NA	NA	NA	0	0	1
0.3	NA	18	NA	NA	NA	0	0	1
0.2	NA	24	NA	NA	NA	0	0	1
0.3	NA	31	NA	NA	NA	0	0	1
0.2	NA	33	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	57	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	8.5	149	NA	105	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.5	NA	277	NA	NA	NA	0	0	1
2.8	NA	497	NA	NA	NA	0	0	1
0.5	NA	2.2	NA	NA	NA	0	0	1
NA	NA	2.5	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9.1	NA	NA	97	NA	0	0	0
0.8	NA	4.1	NA	97	201	0	0	0
0.5	NA	3.2	NA	97	NA	0	0	0
NA	NA	NA	NA	NA	153	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.7	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.7	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	102	NA	0	0	0
0.5	NA	4.6	NA	NA	NA	0	0	0
0.4	NA	4.4	NA	NA	NA	0	0	0
0.4	NA	5.3	NA	NA	NA	0	0	0
3.7	NA	NA	NA	103	NA	0	0	0
4.9	NA	NA	NA	NA	NA	0	0	0
2.8	9	6.5	NA	103	108	0	0	0
4.9	8.4	19	NA	97	139	0	0	0
1.1	7.2	NA	NA	107	NA	0	0	0
0.5	10.2	1.7	NA	104	NA	0	0	0
0.3	10	2.1	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	100	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.5	9.4	2.9	NA	102	220	0	0	0
0.5	NA	4	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	10.3	1	NA	99	232	0	0	0
NA	9.9	NA	NA	100	235	0	0	0
6.5	9.5	1.2	NA	101	NA	1	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	4.3	NA	NA	NA	0	0	1
0.3	10.7	5.1	NA	102	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	0
0.8	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	1.8	NA	NA	NA	0	0	0
1	NA	1.8	NA	NA	212	0	0	0
0.6	NA	1.9	NA	NA	NA	0	0	0
0.7	NA	2	NA	NA	NA	0	0	0
0.7	NA	2.3	NA	NA	NA	0	0	1
0.4	9.6	NA	NA	96	NA	0	0	1
0.4	8.5	NA	NA	105	NA	0	0	0
0.8	8.1	1.4	NA	102	NA	0	0	0
0.8	8.3	1.4	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
NA	NA	1.5	NA	99	NA	0	0	0
0.5	NA	NA	NA	100	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
1.9	8.9	6.3	NA	95	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	96	NA	0	0	1
1.4	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	9.4	1.2	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	104	NA	0	0	0
0.4	9.9	3.8	NA	NA	NA	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.4	9.4	2.4	NA	103	NA	0	0	0
0.4	9.6	2.8	NA	NA	NA	0	0	0
0.2	NA	3.5	NA	NA	NA	0	0	0
0.4	9.8	5.2	NA	104	NA	0	0	0
0.3	NA	5.1	NA	NA	NA	0	0	0
0.5	9.1	5.7	NA	104	NA	0	0	0
NA	9.5	7.8	NA	104	NA	0	0	0
0.4	NA	13	NA	104	179	0	0	0
0.3	NA	15	NA	NA	NA	0	0	0
0.4	10.1	25	NA	102	204	0	0	0
0.4	NA	37	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2.5	670	NA	NA	0	0	0
NA	8.8	3.3	NA	98	NA	0	0	0
0.3	NA	1.3	16	NA	239	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.7	NA	1.2	NA	NA	NA	0	0	0
0.9	9.2	1.5	NA	NA	NA	0	0	0
0.7	9.4	NA	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.8	10.5	1.1	NA	98	217	0	0	1
5.9	8.9	2.7	NA	104	NA	0	0	1
0.3	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.8	10	2.4	NA	105	NA	0	0	1
NA	NA	1.5	NA	NA	NA	0	0	0
NA	NA	1.7	NA	103	162	0	0	0
0.6	9.1	1.2	8.7	98	NA	0	0	0
0.6	NA	1.9	NA	105	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.4	10.2	1.9	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	8.5	NA	NA	110	NA	0	0	0
0.6	NA	4.9	11	NA	NA	0	0	0
0.6	NA	5.6	9.2	NA	NA	0	0	0
0.3	9.8	2.9	NA	NA	NA	0	0	0
0.3	9.7	NA	NA	NA	NA	0	0	0
0.4	9.3	3.7	NA	NA	NA	0	0	0
NA	9.7	4.5	NA	NA	NA	0	0	0
0.3	9.6	4.7	13	NA	NA	0	0	0
0.3	10	4.8	NA	NA	NA	0	0	0
0.6	8.5	4.8	NA	105	NA	0	0	1
NA	NA	9.5	NA	NA	NA	0	0	0
NA	NA	9.5	NA	NA	NA	0	0	1
0.3	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	0	0	0
NA	NA	3.1	NA	99	NA	0	0	0
0.3	9.4	3	NA	NA	NA	0	0	0
1.2	9.3	NA	NA	107	234	0	0	1
0.3	NA	3.7	NA	NA	NA	0	0	0
0.3	NA	4.4	NA	NA	NA	0	0	0
0.3	NA	3.7	NA	NA	NA	0	0	0
0.5	NA	4.2	NA	NA	NA	0	0	0
0.3	NA	3.8	NA	NA	NA	0	0	0
0.3	NA	3.7	NA	NA	NA	0	0	0
0.3	NA	3.9	NA	NA	NA	0	0	0
0.3	9.4	4.1	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	225	0	0	0
NA	10.7	6.9	16	105	NA	0	0	1
0.8	8.6	4.2	NA	NA	NA	0	0	1
1.1	NA	5.6	NA	104	NA	0	0	0
0.4	NA	NA	11	104	NA	0	0	0
1.3	9	12	NA	104	NA	0	0	0
1.3	NA	3.3	NA	NA	NA	0	0	1
0.5	NA	3.4	NA	NA	NA	0	0	1
1	11	3.4	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	0
0.8	NA	3.1	NA	NA	NA	0	0	1
0.7	NA	3.6	NA	NA	NA	0	0	0
0.4	NA	6.3	NA	NA	NA	0	0	0
NA	10.8	5.3	NA	NA	NA	0	0	0
NA	9.9	6.5	NA	NA	NA	0	0	0
1.3	9	2.5	NA	109	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.8	8.2	2.1	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.4	18	NA	NA	0	0	0
0.6	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	183	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	4.7	NA	NA	NA	0	0	0
0.3	NA	4.6	NA	NA	NA	0	0	0
0.5	10.2	5.2	NA	NA	NA	0	0	0
0.4	10.2	4.6	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.5	9.1	NA	NA	105	NA	0	0	0
0.8	8.4	112	NA	99	NA	0	0	1
NA	NA	2.5	NA	NA	NA	0	0	0
0.7	10.1	4.1	NA	NA	NA	0	0	0
0.7	NA	3.9	NA	NA	229	0	0	0
0.7	NA	4.3	NA	NA	230	0	0	1
NA	NA	4.2	NA	NA	NA	0	0	0
0.6	NA	4.3	NA	NA	NA	0	0	1
0.6	NA	3.7	24	NA	NA	0	0	1
0.8	NA	4.9	NA	NA	NA	0	0	1
0.6	NA	4.7	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.3	8.9	1.7	NA	100	NA	0	0	0
2.9	NA	NA	NA	105	NA	0	0	0
0.2	NA	1.6	NA	106	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.3	8.7	2.5	NA	103	NA	1	0	0
0.6	9.2	NA	NA	103	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	43	NA	NA	NA	0	0	0
1.8	NA	NA	NA	NA	NA	0	0	0
0.5	7.7	5.2	NA	105	NA	0	0	0
0.6	8.9	4.1	NA	104	NA	0	0	0
0.7	9.4	1.8	NA	103	NA	0	0	0
NA	9.2	1.4	NA	102	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.6	9.6	3.3	NA	103	NA	0	0	0
0.6	8.6	2.8	NA	103	NA	0	0	0
0.6	9.2	3	NA	104	NA	0	0	0
0.6	8.9	2.6	NA	104	NA	0	0	0
0.4	9.1	2.4	NA	102	NA	0	0	0
0.3	9.3	2.5	NA	106	NA	0	0	0
0.5	9.1	3.6	NA	107	NA	0	0	0
NA	9.2	2.3	NA	102	NA	0	0	0
0.2	9.2	2	NA	106	NA	0	0	0
0.3	9.5	2.3	NA	103	NA	0	0	0
0.4	9.2	2.4	NA	102	NA	0	0	0
0.4	NA	2.1	NA	102	NA	0	0	0
0.6	9.6	2.3	NA	104	NA	0	0	0
0.3	9.1	2	NA	103	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
0.6	9.1	2.3	NA	101	NA	0	0	0
NA	9.3	2.8	NA	101	NA	0	0	0
0.8	9.2	3.1	NA	101	NA	0	0	0
0.5	9.2	2.4	NA	105	NA	0	0	0
0.5	9.3	2.1	NA	106	NA	0	0	0
NA	9.3	2.4	NA	103	161	0	0	0
0.3	9	2.1	NA	104	NA	0	0	0
0.7	9	2.4	NA	98	NA	0	0	0
0.6	9	2.7	NA	103	NA	0	0	0
NA	NA	3.2	NA	105	NA	0	0	0
0.2	8.6	3	NA	NA	NA	0	0	0
NA	9.2	2.6	NA	102	NA	0	0	0
0.5	9	NA	NA	105	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
8.2	9.1	8.7	NA	94	NA	0	0	1
1.4	8.6	8.7	NA	99	NA	0	0	1
11.6	9.2	8	NA	96	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.3	8.1	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.5	11.1	1.8	NA	100	NA	0	0	0
0.6	NA	NA	NA	NA	137	0	0	0
0.3	NA	4.1	NA	NA	NA	0	0	0
0.3	NA	4.3	NA	NA	NA	0	0	1
0.2	NA	4.9	NA	NA	NA	0	0	1
0.3	8.8	3.9	NA	100	NA	0	0	0
0.4	NA	3	NA	105	NA	0	0	0
0.3	NA	3.2	NA	NA	NA	0	0	0
0.4	NA	3.6	NA	NA	224	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
0.3	NA	3.1	NA	106	NA	0	0	1
0.5	NA	3	10	NA	NA	0	0	0
0.3	NA	3.2	NA	NA	NA	0	0	1
NA	NA	3.2	NA	NA	NA	0	0	1
NA	NA	3.3	NA	NA	NA	0	0	1
0.3	NA	3.4	NA	NA	NA	0	0	1
0.3	NA	3.8	NA	NA	NA	0	0	1
0.3	9.2	2.6	NA	NA	NA	0	0	0
0.3	8.9	3.8	NA	106	NA	0	0	1
NA	NA	3.9	NA	NA	NA	0	0	1
0.3	8.8	4.8	NA	106	NA	0	0	1
0.1	NA	5.7	NA	NA	NA	0	0	1
NA	NA	6.3	NA	NA	NA	0	0	1
0.2	NA	5.7	NA	NA	NA	0	0	1
0.3	NA	6	NA	NA	NA	0	0	1
0.3	NA	4.5	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
NA	8.6	2.8	NA	NA	NA	0	0	0
0.4	10	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
2.2	9.3	2.8	NA	103	188	0	0	0
3.3	7.6	NA	NA	102	NA	0	0	0
0.2	NA	2.8	NA	NA	NA	0	0	0
0.4	9.3	NA	NA	NA	NA	0	0	1
0.4	9	NA	NA	91	NA	0	0	1
0.4	8.4	NA	NA	103	NA	0	0	1
0.5	9.3	NA	NA	NA	NA	0	0	1
0.4	9.4	622	NA	NA	NA	0	0	1
NA	9.4	1.5	NA	NA	182	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	2.8	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	4.4	NA	NA	285	0	0	0
0.3	NA	4.4	NA	NA	NA	0	0	0
0.4	NA	4.3	NA	NA	246	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	NA	NA	107	NA	0	0	1
0.3	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.4	11.3	3.4	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.5	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.8	NA	3	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	101	NA	0	0	0
0.2	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.6	NA	1.8	21	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.8	NA	1.1	NA	NA	NA	0	0	0
0.7	NA	1.2	NA	NA	NA	0	0	0
0.6	10.1	1.1	NA	NA	NA	0	0	0
0.9	8.9	2	844	97	NA	0	0	0
0.9	8.7	2	844	99	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.1	6.4	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	1
0.4	NA	2.7	NA	NA	NA	0	0	1
0.4	NA	2.8	NA	NA	NA	0	0	1
0.4	NA	2.2	NA	NA	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
16	9.4	5.4	NA	102	324	0	0	0
NA	NA	5.5	NA	NA	NA	0	0	0
0.3	8.5	NA	43	111	NA	0	0	0
0.3	NA	5.5	NA	NA	NA	0	0	0
0.2	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
0.2	NA	2.6	NA	NA	NA	0	0	0
0.2	NA	2.6	NA	NA	206	0	0	0
0.2	9.4	3.4	NA	NA	NA	0	0	0
11.5	8.7	1.9	NA	101	NA	1	0	0
0.5	NA	5.6	NA	NA	NA	0	0	0
0.5	NA	5.5	NA	NA	NA	0	0	0
NA	NA	5.9	NA	NA	209	0	0	0
0.3	NA	NA	6.6	NA	198	0	0	0
0.3	8.9	13	NA	104	NA	0	0	1
NA	NA	3.4	NA	NA	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
NA	NA	3.2	NA	NA	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
NA	NA	4	NA	NA	NA	0	0	0
0.6	8.9	4.5	NA	100	138	0	0	1
0.2	9.5	NA	NA	106	NA	0	0	0
0.6	NA	NA	7.9	NA	NA	0	0	0
NA	9.7	2.5	NA	99	216	0	0	0
NA	NA	1.9	NA	101	NA	0	0	0
NA	9.2	1.6	NA	105	197	0	0	0
NA	NA	1.4	NA	NA	239	0	0	0
NA	9.5	1.1	NA	101	225	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	3.4	NA	NA	NA	0	0	0
0.4	NA	3.6	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.3	9.5	1.7	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
2.8	8.7	5	NA	101	NA	0	0	1
2.6	NA	NA	NA	98	NA	0	0	1
0.5	9	2	NA	96	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	105	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	95	NA	0	0	1
1.2	NA	NA	NA	95	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	9	NA	NA	NA	NA	0	0	1
NA	NA	4.4	496	NA	NA	0	0	0
0.6	8.9	NA	NA	91	NA	0	0	1
NA	NA	1	NA	NA	NA	0	0	1
NA	NA	2.5	NA	104	227	0	0	1
0.3	NA	NA	NA	107	NA	0	0	1
NA	NA	NA	NA	109	NA	0	0	1
NA	NA	NA	NA	110	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	8.3	NA	NA	94	NA	0	0	1
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.1	13	NA	NA	0	0	0
0.4	9.1	NA	16	NA	236	0	0	0
0.4	NA	NA	15	NA	NA	0	0	0
0.3	NA	NA	13	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.2	9.7	NA	19	NA	NA	0	0	0
0.1	NA	2.7	19	NA	NA	0	0	0
0.3	NA	2.8	26	NA	NA	0	0	0
0.1	NA	2.1	23	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
0.3	9.3	NA	25	NA	NA	0	0	0
0.3	8.9	2.3	24	NA	NA	0	0	0
NA	9.2	NA	23	104	NA	0	0	0
0.7	7.6	2.1	NA	101	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	1
NA	NA	1.2	NA	NA	NA	0	0	1
NA	NA	2.3	NA	NA	NA	0	0	1
NA	9.7	3	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2.1	6.5	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.3	9.3	1.3	NA	102	NA	0	0	0
0.2	NA	2.8	NA	NA	NA	0	0	1
0.3	NA	2.9	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	NA	14	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	2.2	65	NA	NA	0	0	0
NA	NA	9.4	NA	NA	NA	0	0	1
0.3	10.3	10	NA	101	NA	0	0	1
0.4	9.5	2.7	NA	NA	NA	0	0	1
0.3	NA	1.6	NA	NA	NA	0	0	0
0.2	9.3	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	102	NA	0	0	0
0.2	10.2	NA	NA	NA	NA	0	0	0
0.2	9.9	1.2	NA	NA	NA	0	0	0
NA	9.7	1.3	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.2	9.1	2.6	NA	NA	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	0
0.1	10.2	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	4.8	NA	107	NA	0	0	1
0.3	9.1	6.2	NA	104	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	4.4	NA	NA	NA	0	0	0
0.3	NA	4.5	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	9.7	2.9	NA	103	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.8	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.8	NA	1.6	NA	NA	NA	0	0	0
0.7	NA	1.4	NA	NA	NA	0	0	0
0.8	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.3	9.6	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	9.5	4.4	NA	NA	NA	0	0	0
NA	NA	8.6	NA	106	NA	0	0	0
0.5	NA	4.7	NA	NA	NA	0	0	0
0.4	NA	5.9	NA	NA	NA	0	0	0
NA	9.1	7.1	NA	NA	160	0	0	1
NA	NA	5.4	NA	NA	NA	0	0	1
0.3	NA	6.8	NA	NA	NA	0	0	1
NA	NA	7	NA	NA	NA	0	0	1
0.3	NA	7.1	NA	NA	NA	0	0	1
0.4	NA	10	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
NA	NA	7.5	NA	NA	144	0	0	1
0.5	NA	6.3	NA	NA	NA	0	0	1
NA	8.7	4.1	NA	103	NA	0	0	1
0.5	NA	9.8	NA	NA	NA	0	0	1
0.4	NA	8.8	NA	NA	NA	0	0	1
0.4	NA	6.5	NA	NA	NA	0	0	0
0.5	NA	6	NA	NA	NA	0	0	0
0.4	NA	7	NA	NA	NA	0	0	1
0.5	NA	5.4	NA	NA	NA	0	0	1
0.4	NA	5.7	NA	NA	NA	0	0	1
0.3	8.6	6.3	NA	111	162	0	0	0
0.3	NA	5.2	NA	NA	NA	0	0	1
0.3	NA	5.9	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	215	0	0	0
NA	NA	NA	431	NA	NA	0	0	1
5.9	8.9	35	NA	100	NA	0	0	1
NA	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.4	9.4	1.6	24	NA	NA	0	0	0
0.5	NA	2.2	19	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	4.7	NA	NA	NA	0	0	0
0.3	NA	6.9	NA	NA	NA	0	0	0
NA	NA	NA	50	NA	NA	0	0	0
0.4	NA	6.3	48	NA	NA	0	0	0
0.2	NA	5.9	45	NA	NA	0	0	0
0.3	NA	5.8	NA	NA	NA	0	0	0
0.3	10.1	6.7	NA	NA	NA	0	0	0
0.4	10.3	7	53	NA	NA	0	0	0
0.4	NA	6.8	NA	NA	NA	0	0	0
0.3	NA	6.4	NA	NA	NA	0	0	0
0.5	10.4	7.6	NA	NA	NA	0	0	0
0.4	NA	8.3	NA	NA	NA	0	0	0
0.4	10.1	7.5	NA	NA	NA	0	0	0
0.4	NA	7.4	NA	NA	NA	0	0	0
0.8	9	2.1	NA	112	NA	0	0	1
0.6	NA	2.7	NA	NA	NA	0	0	1
NA	NA	2.4	NA	NA	NA	1	0	1
0.6	NA	2.4	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	105	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
0.5	10.2	NA	NA	NA	186	0	0	0
0.9	NA	3.5	NA	102	NA	0	0	0
1.5	8.9	11	NA	97	NA	0	0	0
0.6	NA	1.7	14	NA	NA	0	0	0
0.4	9.7	1.7	NA	104	183	0	0	0
0.4	NA	1.6	16	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
0.7	NA	NA	15	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
18.3	9.4	1.7	NA	99	NA	1	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.3	9	1.7	NA	105	171	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.8	NA	110	NA	0	0	0
1.3	NA	1.3	NA	105	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
0.5	NA	2.7	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	173	0	0	0
NA	9.5	NA	NA	NA	189	0	0	1
NA	NA	24	NA	NA	NA	0	0	1
0.4	9.7	25	NA	104	NA	0	0	1
NA	9.3	16	NA	100	NA	0	0	1
NA	NA	8.6	NA	NA	NA	0	0	1
0.2	9.2	6.3	NA	106	NA	0	0	0
0.3	NA	7.6	NA	NA	NA	0	0	0
NA	9.6	147	NA	NA	NA	0	0	1
0.3	NA	104	NA	NA	NA	0	0	1
NA	8.7	62	NA	NA	NA	0	0	1
0.5	9.4	16	NA	NA	NA	0	0	1
0.3	9.9	8.4	NA	107	NA	0	0	0
0.5	NA	8.6	NA	NA	NA	0	0	0
0.5	9.5	7.9	NA	NA	NA	0	0	0
0.4	8.1	7.7	NA	105	NA	0	0	0
0.3	9.3	11	NA	104	NA	0	0	0
0.3	9.1	11	NA	103	NA	0	0	0
0.2	9.4	10	NA	107	NA	0	0	0
NA	NA	15	NA	104	NA	0	0	1
NA	9.1	17	NA	105	NA	0	0	1
0.3	9.6	28	NA	103	NA	0	0	1
0.4	9.4	50	NA	104	NA	0	0	1
0.3	8.9	125	NA	105	NA	0	0	1
0.5	9.1	273	NA	107	NA	0	0	1
0.5	9.3	441	NA	104	NA	0	0	1
NA	10.2	NA	NA	102	NA	0	0	0
0.5	9.9	NA	NA	104	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	NA	9.3	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
NA	9.4	1.8	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	1
0.3	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
NA	9.1	NA	37	NA	NA	0	0	1
0.3	NA	NA	NA	104	NA	0	0	0
1.4	9.6	2.1	14	105	161	0	0	1
NA	NA	2.3	NA	NA	165	0	0	1
0.9	9.7	1.9	NA	103	149	0	0	1
NA	NA	2.1	NA	NA	161	0	0	1
1.4	9.9	1.8	NA	104	157	0	0	1
1	9.4	2.3	NA	105	164	0	0	1
0.3	NA	3	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.2	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
NA	10.4	1.6	NA	NA	NA	0	0	0
0.8	NA	1.4	76	NA	NA	0	0	0
NA	9.2	1.2	NA	103	162	0	0	0
0.4	NA	1.8	13	NA	NA	0	0	0
0.4	NA	1.5	18	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
5.1	8.9	NA	NA	100	NA	0	0	1
0.5	9.8	1.2	NA	103	NA	0	0	0
2.3	8.8	5.5	NA	96	45	0	0	0
0.6	9.5	NA	NA	104	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.4	9.7	NA	NA	103	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.4	9.5	NA	NA	101	NA	0	1	0
NA	NA	1.8	NA	101	NA	0	0	1
0.4	7.9	82	NA	106	NA	0	0	1
3.4	8.3	4.9	NA	96	NA	0	0	0
1.8	NA	NA	NA	95	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.9	9.2	NA	1147	106	NA	0	0	1
0.7	9.2	NA	NA	105	NA	0	0	0
0.4	8.5	16	NA	103	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	1
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
NA	9.8	3.1	NA	NA	178	0	0	0
0.4	9.8	3.5	NA	110	NA	0	0	0
NA	NA	4.3	NA	105	179	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	7.7	NA	475	100	NA	0	0	0
0.4	8.4	NA	475	103	NA	0	0	0
NA	NA	2.8	8.2	NA	NA	0	0	0
0.2	NA	2.7	11	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.3	9.7	3.1	NA	NA	NA	0	0	0
0.3	NA	2.4	11	NA	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
NA	10	2.7	9	105	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
0.5	NA	3.1	NA	NA	NA	0	0	0
NA	NA	3.2	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
NA	NA	3	NA	NA	NA	0	0	0
0.3	NA	5.7	NA	NA	NA	0	0	0
NA	NA	6.4	NA	NA	NA	0	0	0
0.3	NA	5.7	19	NA	NA	0	0	0
0.3	NA	5.7	19	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	8.7	6.3	NA	NA	NA	0	0	1
0.3	NA	12	NA	NA	NA	0	0	1
0.2	NA	20	NA	NA	NA	0	0	1
0.4	NA	2.2	NA	NA	NA	0	0	1
0.4	8.3	2	NA	NA	NA	0	0	1
0.3	9	2.7	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	1
0.5	NA	2.7	NA	NA	NA	0	0	1
0.4	NA	3.4	NA	NA	NA	0	0	1
0.4	NA	6.6	NA	103	NA	0	0	0
0.3	NA	21	NA	NA	NA	0	0	1
0.3	NA	29	NA	NA	NA	0	0	1
0.3	NA	37	NA	NA	NA	0	0	1
0.4	NA	42	NA	NA	NA	0	0	1
0.4	8.4	30	NA	95	NA	0	0	1
0.4	NA	35	NA	102	NA	0	0	1
0.3	NA	7.6	NA	NA	NA	0	0	1
0.3	NA	5.4	NA	NA	NA	0	0	1
0.3	NA	9.5	NA	NA	NA	0	0	1
0.2	NA	5	NA	NA	NA	0	0	0
0.3	7.9	5.6	NA	107	NA	0	0	1
0.1	NA	8.8	NA	NA	NA	0	0	1
0.2	NA	20	NA	NA	NA	0	0	1
NA	NA	NA	NA	100	210	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	2.3	40	NA	NA	0	0	1
0.8	10.1	2	47	93	NA	0	0	1
0.8	NA	NA	NA	100	NA	0	0	0
0.8	9.8	2.5	NA	97	187	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	8.3	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	2.4	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
NA	NA	NA	6.4	NA	NA	0	0	0
0.3	NA	4.6	NA	NA	NA	0	0	0
0.5	NA	5.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	9.3	NA	NA	NA	175	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	240	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	9.2	NA	NA	110	NA	0	0	1
NA	8.9	NA	NA	NA	NA	0	0	1
0.3	8.9	1.8	NA	107	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	1
0.3	8.7	2	NA	107	NA	0	0	0
0.3	9.5	NA	NA	NA	NA	0	0	0
NA	NA	2.5	NA	101	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	9.7	2.5	NA	NA	187	0	0	0
0.2	9.7	NA	NA	103	153	0	0	1
0.3	9.4	NA	NA	104	NA	0	0	0
0.3	9.6	1.6	4.6	105	186	0	0	0
0.2	NA	2.1	NA	105	NA	0	0	0
0.4	NA	2	NA	104	NA	0	0	0
0.2	NA	1.9	10	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	1
0.3	NA	2.6	NA	NA	NA	0	0	1
0.2	NA	2.7	NA	NA	NA	0	0	1
0.2	NA	2.8	NA	NA	NA	0	0	1
0.3	NA	3.3	NA	NA	NA	0	0	1
NA	NA	4.2	NA	NA	NA	0	0	1
0.3	NA	6.8	NA	NA	NA	0	0	1
0.2	9.8	12	NA	103	NA	0	0	1
0.3	9.1	24	NA	104	NA	0	0	1
0.3	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
0.1	NA	2.1	NA	NA	NA	0	0	0
0.1	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.6	NA	2.8	NA	NA	NA	0	0	0
0.4	NA	3.2	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.2	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
NA	NA	2.9	NA	NA	NA	0	0	0
0.4	NA	8.1	12	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	9.8	7.3	NA	NA	NA	0	0	0
0.5	10	2.8	NA	101	NA	0	0	0
0.3	9.6	NA	18	101	NA	0	0	0
1.6	8.3	1	NA	100	138	0	0	1
7.6	NA	3.7	NA	96	NA	0	0	1
0.3	NA	5.2	NA	NA	NA	0	0	1
0.9	NA	4.8	NA	NA	NA	0	0	1
0.5	NA	5.5	NA	NA	NA	0	0	1
0.6	NA	4.8	NA	NA	NA	0	0	1
0.8	NA	5.4	NA	NA	NA	0	0	0
0.4	NA	15	NA	NA	NA	0	0	1
0.3	13.3	13	NA	NA	NA	0	0	1
0.5	NA	5.5	NA	NA	NA	0	0	1
0.2	9.8	6	NA	NA	223	0	0	1
0.4	NA	5.5	NA	NA	NA	0	0	1
0.4	NA	6.6	NA	NA	NA	0	0	0
0.4	NA	6.3	NA	NA	NA	0	0	0
0.3	9.3	5.7	NA	NA	NA	0	0	0
0.3	NA	5.8	NA	NA	NA	0	0	0
0.2	NA	5.5	NA	NA	NA	0	0	0
0.2	NA	5.8	NA	NA	NA	0	0	0
0.3	NA	5.9	NA	NA	NA	0	0	0
0.3	NA	6.2	NA	NA	NA	0	0	0
0.2	NA	5.6	NA	NA	NA	0	0	0
0.4	9.7	2.1	NA	101	NA	0	0	0
0.3	10	5	NA	NA	NA	0	0	0
NA	NA	7.8	NA	NA	NA	0	0	0
0.3	NA	6.9	NA	NA	NA	0	0	0
NA	NA	7.2	NA	NA	NA	0	0	0
0.2	NA	7.2	NA	101	208	0	0	0
NA	NA	6.5	NA	NA	NA	0	0	0
NA	NA	6.2	NA	NA	NA	0	0	0
0.3	NA	4.9	NA	NA	NA	0	0	0
NA	NA	5.9	NA	NA	NA	0	0	0
NA	NA	6	NA	NA	NA	0	0	0
NA	10.1	5.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.2	9.7	NA	NA	0	0	0
0.4	NA	1.6	NA	106	NA	0	0	0
0.4	10.1	1.6	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
2.8	9	30	NA	105	NA	0	0	1
NA	NA	NA	NA	102	NA	0	0	1
0.4	NA	NA	NA	107	NA	0	0	1
0.4	NA	NA	NA	104	NA	0	0	1
0.3	NA	9.5	NA	111	NA	0	0	1
0.3	NA	12	NA	106	NA	0	0	1
0.3	NA	7.8	NA	106	NA	0	0	1
0.3	NA	19	NA	104	NA	0	0	1
0.4	NA	2.5	NA	NA	NA	0	0	1
0.4	NA	2.8	NA	NA	NA	0	0	1
0.4	NA	6.2	NA	NA	NA	0	0	1
0.4	NA	6.8	NA	NA	NA	0	0	1
NA	NA	9.2	NA	NA	NA	0	0	1
NA	NA	7.2	NA	NA	NA	0	0	1
NA	NA	6.6	NA	NA	NA	0	0	1
0.3	NA	5.1	NA	NA	NA	0	0	1
0.2	NA	3.4	NA	NA	NA	0	0	1
0.4	9	4.3	NA	73	NA	0	0	1
0.4	NA	3.7	NA	NA	NA	0	0	1
0.3	NA	3.4	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	4	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	1
0.4	NA	4.6	NA	101	171	0	0	1
0.3	NA	5.7	NA	NA	NA	0	0	1
NA	NA	5.6	NA	NA	NA	0	0	1
0.3	NA	5.7	NA	NA	NA	0	0	1
0.3	NA	6.4	NA	NA	NA	0	0	1
0.3	NA	8.8	NA	NA	NA	0	0	1
NA	NA	9.4	NA	100	NA	0	0	0
NA	NA	9.4	NA	100	NA	0	0	1
0.4	NA	9.1	NA	NA	NA	0	0	1
0.3	NA	9.6	NA	NA	NA	0	0	1
0.6	NA	8.8	NA	98	NA	0	0	1
0.4	NA	11	NA	NA	NA	0	0	1
0.3	NA	13	NA	NA	NA	0	0	1
0	NA	12	NA	NA	NA	0	0	1
0.3	NA	13	NA	NA	NA	0	0	1
NA	NA	15	NA	NA	NA	0	0	1
0.3	NA	14	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	17	NA	NA	NA	0	0	1
0.2	8.6	38	NA	NA	NA	0	0	0
NA	NA	2.5	13	NA	NA	0	0	0
NA	NA	NA	NA	105	NA	0	0	0
0.5	NA	3.1	NA	NA	NA	0	0	1
0.4	8.9	3.9	NA	106	NA	0	0	1
0.4	8.8	5	NA	NA	NA	0	0	1
0.4	6.4	5.4	NA	NA	NA	0	0	0
0.6	9.3	8.7	NA	101	NA	0	0	1
0.7	9.6	10	NA	NA	NA	0	0	1
0.5	8.5	11	NA	NA	NA	0	0	1
0.6	9.4	11	NA	NA	NA	0	0	1
NA	9.6	13	NA	102	255	0	0	1
0.7	9.4	11	NA	NA	NA	0	0	1
0.5	9.7	12	NA	NA	NA	0	0	1
0.5	NA	12	NA	NA	NA	0	0	1
0.7	8.9	11	NA	NA	NA	0	0	1
0.7	NA	14	NA	NA	NA	0	0	1
0.5	9.7	26	NA	NA	NA	0	0	1
0.6	NA	20	NA	104	NA	0	0	1
0.6	NA	13	NA	NA	NA	0	0	1
0.5	NA	12	NA	NA	NA	0	0	1
0.6	9.2	15	NA	101	NA	0	0	1
0.6	8.2	12	NA	103	NA	0	0	1
0.5	8.5	12	NA	97	NA	0	0	1
0.3	7.8	13	NA	103	NA	0	0	1
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	9.7	NA	NA	NA	NA	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	6.1	NA	NA	NA	0	0	1
NA	NA	6.8	NA	NA	NA	0	0	1
NA	NA	7.2	NA	NA	NA	0	0	1
0.4	NA	5.9	NA	NA	NA	0	0	1
0.3	NA	5.8	NA	NA	NA	0	0	1
NA	NA	4.5	NA	NA	NA	0	0	1
0.4	NA	8.1	NA	NA	NA	0	0	1
NA	NA	15	NA	NA	NA	0	0	1
0.4	9.3	14	NA	NA	NA	0	0	1
0.5	NA	3.5	NA	NA	NA	0	0	1
0.4	NA	3.1	NA	NA	NA	0	0	1
0.3	NA	4.9	NA	NA	NA	0	0	1
NA	NA	6	NA	NA	NA	0	0	1
NA	NA	6.8	NA	NA	NA	0	0	1
0.3	NA	12	NA	NA	NA	0	0	1
0.4	NA	26	NA	NA	NA	0	0	1
0.6	NA	63	NA	NA	NA	0	0	1
NA	NA	76	NA	NA	NA	0	0	1
0.5	NA	111	NA	NA	NA	0	0	1
NA	NA	2.7	NA	NA	NA	0	0	1
0.3	9.7	4	NA	102	NA	0	0	1
0.3	9.4	4.6	NA	100	NA	0	0	1
0.3	NA	3.3	NA	NA	NA	0	0	0
0.2	9.6	3.1	NA	102	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	1
0.2	9.3	4	NA	103	NA	0	0	1
0.3	10.5	5.3	NA	106	NA	0	0	1
0.2	9.6	5.4	NA	102	NA	0	0	0
0.2	NA	7.7	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	7.4	NA	NA	NA	0	0	1
0.4	9.5	9.1	NA	NA	NA	0	0	1
0.5	NA	13	NA	NA	NA	0	0	1
0.3	9.3	12	NA	103	NA	0	0	1
0.3	NA	3.5	NA	NA	NA	0	0	1
NA	NA	4.1	NA	NA	NA	0	0	1
0.3	NA	6.1	NA	NA	NA	0	0	1
NA	8.9	6.4	NA	106	NA	0	0	1
0.3	10.2	6.6	NA	NA	NA	0	0	1
NA	10.2	5	NA	NA	NA	0	0	1
NA	10.1	6.2	NA	NA	NA	0	0	1
0.2	NA	6.6	NA	NA	NA	0	0	1
0.2	9.5	11	NA	NA	NA	0	0	1
0.3	9.5	11	NA	NA	NA	0	0	1
NA	9.4	1.8	NA	103	189	0	0	0
NA	9.6	3	NA	104	205	0	0	0
1	NA	2.8	NA	NA	NA	0	0	0
0.6	NA	2.7	NA	NA	NA	0	0	0
NA	NA	3.1	NA	102	198	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
NA	8.6	1.9	82	107	NA	0	0	0
0.4	8.1	13	NA	104	NA	0	1	1
0.8	NA	NA	NA	NA	NA	0	1	1
NA	8.8	9.6	NA	100	NA	0	0	1
0.3	7.9	1	NA	107	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	8.9	5.6	NA	105	NA	0	0	1
NA	NA	NA	NA	103	NA	0	0	1
NA	NA	6	NA	NA	NA	0	0	1
0.2	9.1	6.2	NA	NA	NA	0	0	1
0.2	8.1	6.2	NA	NA	NA	0	0	1
0.2	8.6	7.1	NA	NA	NA	0	0	1
0.2	9	9.1	NA	NA	NA	0	0	1
0.2	8.7	10	NA	NA	NA	0	0	1
0.3	8.6	12	NA	NA	NA	0	0	1
NA	8.7	13	NA	101	NA	0	0	1
NA	8.7	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
1	NA	25	NA	NA	NA	0	0	0
NA	NA	14	NA	NA	NA	0	0	0
1.3	NA	9.5	NA	NA	NA	0	0	0
1	NA	8.6	NA	NA	NA	0	0	0
1.3	NA	12	NA	NA	NA	0	0	0
1.6	NA	12	NA	NA	NA	0	0	0
1.4	NA	14	NA	105	NA	0	0	0
1.1	NA	15	NA	NA	NA	0	0	0
0.9	NA	19	NA	NA	NA	0	0	0
1.6	NA	37	NA	NA	NA	0	0	0
1	NA	68	NA	NA	NA	0	0	0
1.7	NA	143	NA	NA	NA	0	0	0
1.1	NA	367	NA	NA	NA	0	0	0
0.6	9.9	789	NA	104	NA	0	0	0
0.6	9.7	1391	NA	101	NA	0	0	0
0.9	10.1	NA	NA	91	NA	0	0	0
0.3	NA	NA	NA	101	NA	0	0	0
NA	NA	NA	NA	101	NA	0	0	1
0.5	NA	1.4	41	NA	NA	0	0	1
0.4	NA	1.4	44	NA	NA	0	0	1
0.3	NA	1.2	42	NA	NA	0	0	1
NA	NA	NA	NA	106	NA	0	0	1
0.6	NA	1.9	56	104	NA	0	0	1
0.4	NA	2.1	50	NA	NA	0	0	1
0.6	NA	2.2	58	NA	NA	0	0	1
0.7	NA	2.7	69	NA	NA	0	0	1
1	9	2	82	103	NA	0	0	1
NA	NA	1.7	79	NA	NA	0	0	1
0.4	8.7	NA	56	102	NA	0	0	1
0.2	7.8	NA	48	105	NA	0	0	1
0.4	8.3	NA	52	104	NA	0	0	1
NA	8.6	NA	53	102	NA	0	0	1
0.3	NA	NA	48	104	NA	0	0	1
0.4	NA	NA	49	NA	NA	0	0	1
0.3	8.8	NA	50	102	NA	0	0	1
0.4	8.8	NA	NA	104	NA	0	0	1
0.3	8.8	NA	NA	100	NA	0	0	1
0.3	8.7	NA	NA	104	NA	0	0	1
0.3	8.5	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	8.7	NA	NA	102	NA	0	0	1
0.1	8.5	NA	NA	103	NA	0	0	1
0.2	8.2	NA	NA	102	NA	0	0	1
0.3	8.8	NA	NA	103	NA	0	0	1
0.3	8.9	NA	NA	103	NA	0	0	1
0.3	8.5	NA	NA	101	NA	0	0	1
0.3	8.6	NA	NA	102	NA	0	0	1
0.2	8.7	NA	NA	99	NA	0	0	1
0.4	8.8	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	8.4	NA	NA	105	NA	0	0	1
0.5	8	NA	NA	102	NA	0	0	1
0.5	7.9	NA	NA	107	NA	0	0	1
0.3	8.5	NA	NA	104	NA	0	0	1
0.3	8.4	NA	NA	107	NA	0	0	1
0.5	NA	4.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	102	NA	0	0	0
0.3	NA	5.5	NA	NA	NA	0	0	1
NA	7.7	5.5	NA	NA	NA	0	0	1
0.4	10.6	4.4	15	103	NA	0	0	0
0.1	NA	1.8	NA	NA	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
0.1	NA	2.2	NA	NA	NA	0	0	0
0.2	8.4	2.3	NA	106	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	101	NA	0	0	0
0.3	NA	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
0.7	9.2	1.2	NA	103	NA	0	0	0
0.7	8.2	NA	NA	112	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
2.2	8	15	NA	94	NA	0	0	1
0.5	NA	4.1	NA	NA	NA	0	0	0
NA	NA	4.3	NA	NA	NA	0	0	0
NA	NA	3.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	4.6	NA	NA	NA	0	0	0
NA	NA	4	17	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	9.5	NA	21	101	NA	0	0	0
0.3	10	NA	NA	102	NA	0	0	0
0.6	9.4	NA	NA	102	NA	0	0	0
NA	NA	1.1	12	102	NA	0	0	0
0.3	9.1	NA	NA	106	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	9.4	NA	NA	104	NA	0	0	0
0.3	9.4	NA	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	215	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	9.3	10	NA	103	NA	0	0	0
0.5	9.2	13	NA	104	NA	0	0	0
0.9	9.5	18	NA	98	NA	0	0	0
1	NA	NA	NA	102	NA	0	0	0
1.1	9.1	NA	NA	102	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	106	NA	0	0	1
0.4	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.1	NA	NA	NA	NA	NA	0	0	0
NA	9	NA	NA	98	183	0	0	0
NA	NA	NA	22	NA	NA	0	0	1
0.4	9.4	1.5	NA	NA	NA	0	0	1
0.3	NA	1.3	NA	105	NA	0	0	0
0.4	NA	2.3	NA	102	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
0.3	8.4	1.8	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.4	9.5	1.5	NA	104	NA	0	0	0
0.3	9.7	1.4	NA	105	NA	0	0	0
0.4	9.8	1.4	NA	103	NA	0	0	0
0.4	9.6	1.5	NA	104	NA	0	0	0
0.4	9.7	1.5	NA	105	NA	0	0	0
0.3	9.3	1.4	NA	105	NA	0	0	0
0.3	9.1	1.5	NA	107	NA	0	0	0
NA	9.3	1.5	NA	103	NA	0	0	0
0.3	9.5	2.2	NA	104	NA	0	0	0
NA	9.3	2.3	NA	103	NA	0	0	1
0.8	8	5.6	NA	NA	NA	0	0	0
0.5	10.3	NA	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	9.4	1.3	8.3	100	194	0	0	1
0.5	10	2.9	NA	103	217	0	0	0
1.8	NA	5.8	NA	NA	NA	0	0	1
0.7	NA	4.6	NA	NA	NA	0	0	1
0.8	9.7	4.7	NA	NA	NA	0	0	1
0.8	NA	5.2	NA	NA	NA	0	0	0
1	NA	5	NA	NA	NA	0	0	1
0.7	NA	4.8	NA	NA	NA	0	0	1
1.1	NA	4.8	NA	NA	NA	0	0	1
0.8	NA	4.3	NA	NA	NA	0	0	0
1.3	NA	4.3	NA	NA	NA	0	0	1
1	NA	4.6	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
1.7	8.8	1.9	NA	102	NA	0	0	0
0.4	9.8	NA	6.8	NA	NA	0	0	0
0.3	9.4	2.6	5.2	NA	NA	0	0	0
0.3	NA	2.3	8.8	NA	NA	0	0	0
0.4	9.7	2.5	NA	NA	256	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
2.2	NA	6.1	NA	NA	NA	1	0	0
0.8	NA	6	NA	NA	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.8	NA	NA	NA	NA	187	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.9	NA	NA	NA	104	NA	1	0	0
0.8	NA	NA	NA	103	NA	0	0	0
0.7	9.5	7.1	NA	105	NA	0	1	0
1.4	NA	6.2	NA	106	NA	1	1	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	99	NA	0	0	0
NA	9.3	NA	NA	99	NA	0	0	0
0.2	9.6	1.9	NA	NA	NA	0	0	0
0.2	NA	2	NA	NA	NA	0	0	0
0.3	NA	4.8	NA	NA	NA	0	0	0
0.5	NA	2.2	19	NA	267	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	2	21	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
0.4	9.6	1.8	NA	NA	NA	0	0	0
NA	NA	1.6	NA	103	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.8	NA	2.4	NA	NA	NA	0	0	0
1	NA	2.8	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.5	10.7	2.3	5.3	100	229	0	0	0
0.4	NA	2.3	9.7	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	1.8	9.5	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.8	7.3	NA	202	0	0	0
0.4	NA	1.7	8.9	NA	NA	0	0	0
0.3	NA	NA	NA	NA	244	0	0	0
0.3	NA	2.8	NA	103	NA	0	0	1
0.9	7.8	1.3	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	200	1	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	105	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.5	NA	2.3	NA	106	181	0	0	0
1.2	10.2	2.7	NA	NA	NA	0	0	0
0.6	NA	2.8	NA	NA	NA	0	0	0
NA	9.6	NA	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
1.3	8	2.9	NA	107	135	0	0	0
0.4	9.3	2.1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	101	NA	0	0	0
0.3	NA	NA	NA	100	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	1
0.5	9.9	NA	NA	103	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.4	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
NA	NA	NA	NA	103	NA	0	0	0
0.3	10.3	1.1	NA	NA	NA	0	0	0
0.4	10.6	2.1	NA	104	NA	0	0	1
0.4	NA	2.5	NA	NA	NA	0	0	1
0.6	10.3	NA	NA	NA	NA	0	0	0
0.3	10	1.8	NA	104	NA	0	0	1
0.4	NA	2	NA	NA	202	0	0	1
0.4	10.3	1.9	NA	105	NA	0	0	0
0.4	9.9	2.2	NA	NA	248	0	0	1
NA	9.4	1.9	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.4	10	1.6	NA	97	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
0.6	NA	3.6	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	4.3	NA	NA	NA	0	0	0
0.3	NA	3.8	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	3.2	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.6	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.7	NA	NA	NA	105	NA	0	0	0
1.2	NA	NA	NA	102	NA	0	0	0
1	9.9	NA	NA	NA	NA	0	0	1
NA	9.5	NA	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	103	NA	0	0	0
0.2	NA	2.3	132	NA	NA	0	0	0
0.7	NA	1.1	13	NA	269	0	0	0
0.7	NA	2.9	NA	NA	NA	0	0	1
0.7	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
0.7	NA	3	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
NA	NA	4	NA	NA	NA	0	0	1
0.2	NA	1.6	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.4	8.9	NA	NA	NA	NA	0	0	0
NA	9.4	NA	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
NA	NA	11	NA	NA	NA	0	0	1
0.3	NA	12	NA	NA	NA	0	0	1
0.3	NA	11	NA	NA	NA	0	0	1
0.3	NA	13	NA	NA	NA	0	0	1
0.3	NA	14	NA	NA	NA	0	0	1
NA	NA	11	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	NA	102	NA	0	0	0
0.6	NA	1.3	NA	103	NA	0	0	1
0.2	9.2	NA	NA	NA	NA	0	0	0
NA	NA	NA	13	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
NA	NA	11	NA	NA	NA	0	0	1
0.7	NA	1.8	13	98	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	7.6	219	698	95	182	0	0	1
0.4	NA	2	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
7.2	NA	10	NA	107	NA	0	0	1
1.1	8.9	27	NA	104	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.2	9.3	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
2.5	8.9	NA	NA	108	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	7.3	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
1.4	9.4	4.7	NA	102	NA	0	0	0
0.3	NA	3.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	10	NA	NA	101	NA	0	0	0
0.5	9.1	1.9	36	106	NA	0	0	0
0.2	9.2	NA	NA	NA	NA	0	0	1
0.3	NA	4.4	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	8.9	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	8	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	1.8	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.6	42	NA	NA	0	0	1
0.5	9.9	2.4	NA	NA	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	1
0.2	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	3.2	32	NA	228	0	0	1
0.3	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	8.2	NA	NA	NA	0	0	0
0.2	NA	10	NA	NA	NA	0	0	0
NA	NA	9	NA	NA	NA	0	0	0
0.2	NA	8.4	NA	NA	NA	0	0	0
0.3	NA	10	NA	NA	NA	0	0	0
0.3	NA	3.9	NA	NA	NA	0	0	0
0.2	NA	4	NA	NA	NA	0	0	0
0.2	NA	3.6	NA	NA	NA	0	0	0
0.2	NA	4.1	NA	NA	NA	0	0	0
0.1	NA	4.3	NA	NA	NA	0	0	0
1.7	9.2	9	NA	98	255	0	0	1
0.4	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2.1	18	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.3	17	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	1
0.6	NA	2.6	NA	NA	NA	0	0	1
0.4	NA	2.5	NA	NA	NA	0	0	0
0.3	9.2	3.9	NA	NA	NA	0	0	0
0.4	NA	13	NA	NA	NA	0	0	1
0.2	8.8	11	NA	106	NA	0	0	1
NA	8.6	6.4	NA	109	NA	0	0	0
0.2	9	8.9	NA	NA	NA	0	0	0
NA	NA	16	NA	NA	NA	0	0	0
0.3	NA	22	NA	NA	NA	0	0	1
0.4	NA	11	NA	NA	NA	0	0	1
0.3	NA	6.6	NA	NA	NA	0	0	1
0.3	NA	8.6	NA	NA	NA	0	0	1
0.4	NA	13	NA	NA	NA	0	0	1
0.4	9.2	16.8	NA	106	NA	0	0	1
0.2	NA	31	NA	NA	NA	0	0	1
0.3	NA	27	NA	NA	NA	0	0	0
0.4	8.7	42	NA	108	NA	0	0	1
NA	NA	45	NA	NA	NA	0	0	1
0.6	NA	50	NA	NA	NA	0	0	1
0.4	8.8	67	NA	NA	NA	0	0	1
NA	NA	96	NA	NA	NA	0	0	1
0.4	NA	116	NA	NA	NA	0	0	1
NA	9.3	120	NA	104	NA	0	0	1
0.6	9.2	135	NA	101	NA	0	0	1
0.4	NA	127	NA	NA	NA	0	0	1
0.3	NA	159	NA	NA	NA	0	0	1
0.4	NA	189	NA	NA	NA	0	0	1
0.3	NA	342	NA	NA	NA	0	0	1
0.3	NA	379	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.4	9.3	2.9	7	NA	166	0	0	0
0.4	NA	2.7	14	NA	NA	0	0	0
0.4	NA	3.1	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
0.6	9.2	2.6	NA	NA	NA	0	0	0
NA	9.1	5.3	46	91	234	0	0	0
0.3	9.7	NA	NA	103	NA	0	0	1
0.2	10	NA	NA	101	NA	0	0	1
0.4	9.3	NA	35	98	NA	0	0	1
0.2	7.9	NA	NA	103	NA	0	0	1
0.2	8.7	NA	NA	98	146	0	0	1
0.2	9.3	NA	NA	96	211	0	0	1
0.3	NA	NA	NA	100	NA	0	0	1
0.3	8.6	NA	NA	101	NA	0	0	1
0.3	8.8	NA	NA	105	NA	0	0	1
0.3	8.7	NA	NA	104	NA	0	0	1
0.2	8.7	NA	NA	106	NA	0	0	1
0.2	8.8	NA	NA	103	NA	0	0	1
0.2	9.3	NA	NA	97	NA	0	0	1
0.2	8.5	NA	NA	104	NA	0	0	1
0.1	8.6	NA	NA	103	NA	0	0	1
0.4	9	NA	NA	103	NA	0	0	1
0.3	8.7	NA	NA	105	NA	0	0	1
0.5	8.9	NA	NA	109	NA	0	0	1
0.6	8.9	NA	NA	105	NA	0	0	1
0.7	8.5	NA	NA	105	NA	0	0	1
1.6	9.7	3.8	NA	102	244	0	0	0
0.3	9.5	1.6	NA	87	NA	0	0	1
NA	NA	3.8	45	NA	NA	0	0	1
0.5	9.1	NA	NA	89	NA	0	0	1
0.5	9	NA	NA	93	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.7	NA	NA	95	NA	0	0	1
NA	9.1	NA	NA	96	NA	0	0	1
0.3	8.8	NA	NA	93	NA	0	0	1
NA	NA	7.2	NA	NA	NA	0	0	0
0.6	NA	3.6	NA	NA	NA	0	0	1
0.6	NA	1.1	9.5	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.3	9	2.2	40	102	NA	0	0	0
0.1	10.1	NA	48	95	NA	0	0	0
0.2	9.2	NA	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	9.9	NA	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	96	NA	0	0	1
0.4	NA	1.2	NA	NA	NA	0	0	0
NA	NA	5.7	66	NA	NA	0	0	0
0.5	9.6	1.1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
0.9	NA	NA	NA	102	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.2	NA	1	NA	NA	NA	0	0	0
0.5	9.9	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	18	NA	NA	0	0	0
NA	NA	1.7	7.3	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.7	10.2	3.6	NA	90	NA	0	0	0
1	NA	4	NA	101	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
4.4	10.2	NA	NA	99	230	1	0	1
0.4	10	NA	NA	97	NA	0	0	1
0.4	9.2	NA	NA	102	NA	0	0	1
0.3	NA	NA	NA	105	NA	1	0	1
0.4	9.4	NA	NA	105	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	9.6	NA	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	10	NA	NA	97	NA	0	0	1
0.4	9.4	NA	NA	95	131	0	0	1
0.4	NA	NA	NA	96	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	7	NA	NA	120	NA	0	0	0
NA	NA	NA	NA	105	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
NA	NA	4.2	NA	NA	NA	0	0	0
0.5	NA	5.9	NA	NA	NA	0	0	0
0.5	NA	6.8	NA	NA	NA	0	0	0
0.6	NA	1.1	NA	103	NA	1	0	0
0.8	NA	NA	NA	108	NA	1	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
3.6	NA	2.2	NA	NA	NA	0	0	0
0.6	NA	2	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
NA	9.1	2.6	NA	104	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	3.7	NA	NA	NA	0	0	1
0.3	NA	2.8	NA	NA	NA	0	0	1
0.1	NA	2.5	NA	NA	NA	0	0	1
0.2	NA	4.2	NA	NA	NA	0	0	1
0.4	8.8	NA	NA	102	NA	0	0	1
0.3	NA	3.1	NA	NA	NA	0	0	0
0.2	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	3.8	NA	NA	NA	0	0	1
0.4	NA	3.5	NA	NA	NA	0	0	0
0.4	10.1	4.8	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.5	NA	3.4	NA	NA	NA	0	0	1
0.5	NA	4.9	NA	NA	NA	0	0	1
0.3	NA	7.2	NA	NA	NA	0	0	1
0.3	NA	2.3	NA	NA	NA	1	0	0
2.1	NA	4.1	NA	105	173	0	0	1
0.4	NA	74	NA	103	186	0	0	1
NA	NA	29	NA	NA	NA	0	0	1
0.2	NA	41	NA	NA	NA	0	0	1
0.1	9.4	44	NA	98	NA	0	0	1
NA	NA	79	NA	101	NA	0	0	1
0.2	NA	77	NA	NA	NA	0	0	1
0.3	NA	63	NA	NA	NA	0	0	1
0.3	NA	48	NA	NA	NA	0	0	1
0.2	8.8	14	NA	106	NA	0	0	1
0.2	8.1	13	NA	104	NA	0	0	1
0.3	9.5	30	NA	106	220	0	0	1
0.5	NA	65	NA	NA	NA	0	0	1
0.3	8.9	93	NA	102	NA	0	0	1
0.3	NA	155	NA	NA	NA	0	0	1
0.4	9.5	264	NA	97	NA	0	0	1
0.5	8.7	243	NA	98	NA	0	0	1
0.3	NA	2.7	NA	NA	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.4	9.2	NA	NA	99	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.9	79	101	NA	0	0	0
NA	NA	NA	16	NA	NA	0	0	0
0.5	9	2.1	NA	107	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
1.1	10.2	1.6	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.7	NA	1.5	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.7	NA	1.3	NA	NA	NA	0	0	0
0.6	NA	1.8	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.7	9.6	1.4	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.1	10	NA	NA	0	0	0
0.3	NA	1.7	9.7	NA	180	0	0	0
0.4	NA	2	13	NA	NA	0	0	0
0.4	NA	1.3	13	NA	NA	0	0	0
0.3	NA	1.5	14	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	NA	8.9	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.1	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
0.2	8.8	1.7	NA	106	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	1
NA	NA	1.9	18	NA	NA	0	0	0
0.3	9.2	1.4	22	101	NA	0	0	0
0.3	NA	1.4	NA	NA	182	0	0	0
0.2	NA	1.4	23	NA	NA	0	0	0
0.2	NA	1.4	15	NA	NA	0	0	1
NA	8.2	1.7	15	105	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.3	16	NA	NA	0	0	0
0.3	NA	1.3	19	NA	NA	0	0	0
0.4	NA	NA	15	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.6	NA	1.8	16	NA	NA	0	0	0
0.7	NA	2.3	29	NA	NA	0	0	0
0.6	NA	3.9	31	NA	NA	0	0	0
0.4	NA	6.4	37	NA	NA	0	0	0
0.4	9.7	13	68	NA	NA	0	0	1
0.5	9.3	25	123	NA	NA	0	0	1
0.8	9.4	19	89	NA	NA	0	0	1
NA	NA	16	NA	NA	NA	0	0	1
0.7	9.4	13	65	NA	NA	0	0	1
NA	9.2	8.8	61	NA	129	0	0	1
0.8	NA	10	71	NA	NA	0	0	1
NA	NA	12	NA	NA	NA	0	0	1
0.7	8.2	14	NA	NA	NA	0	0	1
1	9.1	12	32	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	7.9	23	NA	NA	0	0	0
1.2	8.9	7.2	24	106	NA	0	0	0
1	8.6	7.1	22	102	NA	0	0	0
0.8	9.2	4.7	27	101	NA	0	0	0
NA	NA	5.1	25	99	NA	0	0	0
1.1	9.7	3.9	25	99	NA	0	0	0
0.8	9.2	4.7	22	NA	NA	0	0	0
0.6	9.7	8.7	34	93	NA	0	0	0
0.7	9.4	14	48	97	NA	0	0	1
1	9	21	NA	96	NA	0	0	1
1.3	NA	23	82	NA	NA	0	0	1
0.5	9.3	28	101	NA	NA	0	0	1
0.8	NA	13	87	98	NA	0	0	1
1.1	NA	11	93	NA	NA	0	0	1
0.7	NA	11	93	NA	NA	0	0	1
0.3	NA	1.1	NA	NA	NA	0	0	0
0.5	9.3	1.2	40	NA	NA	0	0	0
0.5	NA	1.1	39	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	3.1	NA	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	198	0	0	0
0.4	NA	5	NA	NA	NA	0	0	0
0.5	NA	6.4	NA	NA	NA	0	0	1
NA	NA	5.1	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
2.3	8.3	NA	NA	102	NA	0	0	0
2	NA	NA	NA	NA	197	0	0	0
1.7	NA	1.3	NA	NA	NA	0	0	0
1.3	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	1
0.5	NA	2.1	NA	NA	NA	0	0	1
0.4	NA	2.6	NA	NA	NA	0	0	1
0.2	NA	2	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	1
0.8	10.1	NA	NA	98	143	0	0	0
0.5	8.9	NA	1654	103	NA	0	0	0
0.4	8.5	2.8	NA	98	NA	0	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	9.5	NA	NA	102	NA	0	0	0
3.5	8.8	14	NA	90	71	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
0.6	NA	5.4	NA	NA	NA	0	0	0
0.5	NA	3.8	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	9.2	1	15	104	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.4	9.7	1.2	NA	106	NA	0	0	0
0.2	9.5	NA	NA	106	NA	0	0	0
0.3	9.9	NA	NA	103	NA	0	0	0
2.4	9.3	9	NA	101	NA	0	0	1
0.5	NA	2.6	NA	NA	NA	0	0	0
1.2	NA	2.1	NA	NA	NA	0	0	1
1.7	8.5	NA	NA	NA	NA	1	0	1
11.7	NA	3.1	NA	NA	NA	1	0	1
8.7	NA	NA	NA	NA	NA	1	0	1
4.1	8	NA	NA	100	NA	1	0	1
3.1	NA	NA	NA	102	NA	0	0	1
0.3	NA	2.7	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	1
NA	9.7	3.3	NA	NA	NA	0	0	0
NA	NA	3.3	NA	106	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
0.6	NA	NA	NA	104	NA	0	0	1
0.3	NA	1.4	NA	99	NA	0	0	0
0.5	8.8	2.1	NA	103	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	9.9	1	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	101	NA	0	0	0
0.4	10.1	2.1	NA	NA	206	0	0	0
0.2	9.6	1.8	NA	NA	217	0	0	0
0.4	NA	2.1	NA	NA	221	0	0	0
0.3	NA	1.7	NA	NA	223	0	0	0
0.2	NA	1.8	NA	NA	214	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
10.1	10.2	NA	NA	94	NA	1	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
6.1	7.8	2.8	NA	112	NA	0	0	1
0.2	10.7	3.4	NA	NA	NA	0	0	0
0.6	9.8	1.1	11	101	155	0	0	1
0.2	9.3	2.2	NA	NA	NA	0	0	0
0.9	NA	3.1	NA	NA	NA	1	0	0
1.4	NA	3.2	NA	NA	NA	0	0	0
1.1	NA	NA	NA	NA	163	1	0	0
1.2	NA	NA	NA	104	155	1	0	0
0.8	NA	NA	NA	NA	NA	1	0	0
1.2	NA	NA	NA	103	182	0	0	0
1.3	NA	NA	NA	NA	159	1	0	0
0.9	NA	NA	NA	104	164	0	0	0
1.2	NA	NA	NA	103	173	1	0	0
0.9	NA	NA	NA	NA	NA	1	0	0
1.3	NA	NA	NA	NA	177	1	0	0
1.2	NA	NA	NA	102	167	1	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.5	14.9	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	105	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	3.5	NA	NA	NA	0	0	0
0.5	NA	3.5	NA	NA	NA	0	0	0
0.3	NA	4.4	NA	NA	NA	0	0	0
0.4	NA	3.5	NA	NA	NA	0	0	0
NA	NA	3	NA	106	247	0	0	0
0.5	NA	3.4	NA	NA	NA	0	0	0
0.5	NA	6.2	NA	NA	254	0	0	0
0.7	NA	3.6	NA	NA	NA	0	0	0
0.3	NA	4	NA	100	NA	0	0	1
NA	NA	1.1	NA	NA	256	0	0	0
NA	NA	1.1	4.6	NA	NA	0	0	0
NA	NA	1.5	3.2	NA	NA	0	0	0
0.6	NA	1.5	7.6	NA	NA	0	0	0
0.7	NA	1.4	6.8	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.3	10	NA	13	103	177	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	9.6	NA	NA	105	NA	0	0	0
1.3	9.2	1.3	NA	106	200	0	0	0
1.3	9.2	1.3	NA	106	200	0	0	0
NA	NA	1	NA	NA	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
0.9	NA	1.9	NA	NA	NA	0	0	0
0.7	NA	2.3	NA	NA	NA	0	0	0
22.4	7.4	NA	NA	103	NA	0	0	1
0.4	NA	NA	NA	102	NA	0	0	0
0.4	NA	1.2	12	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.2	NA	4.8	NA	NA	NA	0	0	1
0.2	NA	4	NA	NA	NA	0	0	1
NA	NA	4.8	NA	NA	NA	0	0	0
0.4	NA	7	NA	NA	NA	0	0	1
0.4	NA	8.1	NA	NA	NA	0	0	0
0.4	NA	16	NA	NA	NA	0	0	1
0.4	NA	27	NA	NA	NA	0	0	1
0.5	NA	2.1	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.4	9.4	2.2	NA	106	NA	0	0	0
1.4	9	7.7	NA	94	133	0	0	1
0.6	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.5	9.7	2.1	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.4	9.2	1.7	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	9	1.7	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.3	9.3	1.7	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	9.2	1.4	NA	NA	NA	0	0	0
NA	9.1	1.5	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.3	9	1.9	NA	104	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.6	9	2	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	106	NA	0	0	0
0.6	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	9.3	1.7	NA	NA	NA	0	0	0
0.4	8.9	1.7	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	NA	25	NA	259	0	0	0
0.2	NA	1.8	17	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.3	8.5	1.5	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
1.6	8.9	NA	NA	100	191	0	0	0
NA	NA	6	NA	NA	NA	0	0	1
0.3	NA	NA	NA	101	NA	0	0	1
0.3	9.4	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.2	NA	NA	105	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	102	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.2	NA	2.9	NA	NA	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	1
12.5	NA	NA	NA	NA	NA	0	0	1
2.8	NA	2	NA	NA	NA	0	1	1
1.9	NA	NA	NA	NA	NA	0	1	0
NA	NA	2.1	NA	NA	NA	0	0	0
1.1	9.7	4.9	NA	96	249	0	0	1
0.3	9.6	1.3	NA	105	243	0	0	0
NA	NA	9	39	108	NA	0	0	0
0.4	NA	1.8	39	NA	158	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.5	21	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.6	31	NA	NA	0	0	1
0.2	NA	NA	NA	102	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.4	8.9	1.8	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.9	9.6	NA	NA	100	NA	0	0	0
0.5	8.9	NA	164	104	NA	0	0	0
4.9	10	29	NA	92	NA	1	0	0
0.2	8.9	2.7	NA	108	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.7	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
0.7	9.4	1.4	NA	NA	NA	0	0	0
0.9	NA	1.1	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
0.8	9.7	1.4	NA	NA	NA	0	0	0
0.7	NA	1.3	NA	NA	NA	0	0	0
NA	9.2	NA	NA	104	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	11	NA	NA	97	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	98	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	8.7	32	NA	105	NA	0	0	1
0.2	8.9	38	NA	101	NA	0	0	1
0.4	NA	4.9	NA	NA	NA	0	0	0
0.4	NA	4.6	NA	NA	NA	0	0	0
0.6	NA	4.4	NA	NA	NA	0	0	0
0.5	NA	3.5	NA	NA	NA	0	0	0
0.4	9.5	3.4	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.5	9.8	2.9	NA	NA	NA	0	0	1
0.6	NA	3.3	NA	NA	NA	0	0	1
0.3	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	5.1	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	107	NA	0	0	0
0.3	NA	5.1	NA	102	NA	0	0	1
0.5	9.8	4.7	NA	105	NA	0	0	0
NA	NA	5.5	NA	NA	NA	0	0	0
NA	8.8	12	NA	103	NA	0	0	1
0.3	9	15	NA	105	NA	0	0	1
0.3	NA	1.4	27	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.9	NA	NA	NA	0	0	1
0.4	NA	2.4	NA	NA	NA	0	0	1
0.4	NA	8.1	NA	NA	NA	0	0	1
0.3	8.6	12	NA	NA	NA	0	0	1
0.3	8.9	11	NA	NA	NA	0	0	1
0.2	8.7	13	NA	NA	NA	0	0	1
0.3	9.2	19	NA	NA	NA	0	0	1
0.4	9.4	31	NA	NA	NA	0	0	1
0.4	NA	35	NA	NA	NA	0	0	1
0.4	NA	39	NA	NA	NA	0	0	1
0.4	9.8	62	NA	NA	NA	0	0	1
0.4	NA	52	NA	104	NA	0	0	1
0.4	9.2	26	NA	103	NA	0	0	1
NA	NA	23	NA	NA	NA	0	0	1
NA	NA	14	NA	NA	187	0	0	1
0.4	9.2	14	NA	NA	NA	0	0	1
NA	NA	15	NA	NA	NA	0	0	1
NA	NA	17	NA	NA	NA	0	0	1
0.6	NA	17	NA	NA	NA	0	0	1
NA	NA	19	NA	NA	NA	0	0	1
0.8	9.2	23	NA	98	NA	0	0	1
NA	NA	22	NA	NA	NA	0	0	1
0.3	NA	2.4	16	102	NA	0	0	0
NA	8.9	1.3	13	107	NA	0	0	0
2.7	8.1	NA	NA	108	NA	0	0	1
1.2	NA	NA	NA	NA	NA	0	0	0
1.4	NA	1.3	NA	NA	NA	0	0	0
1.4	NA	NA	NA	NA	NA	0	0	0
1.8	NA	NA	NA	NA	NA	0	0	0
2	NA	NA	NA	NA	NA	0	0	0
0.9	NA	1.1	NA	NA	NA	0	0	0
1.4	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
0.6	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.2	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	96	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	99	NA	0	0	0
28.4	8.1	3.2	NA	103	NA	0	0	0
6.5	NA	2.1	NA	NA	NA	1	0	1
0.5	9.2	NA	NA	104	NA	0	0	1
0.3	9.1	NA	NA	NA	NA	0	0	1
0.5	NA	2.3	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	2.9	NA	NA	203	1	0	0
0.4	NA	NA	NA	99	214	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	98	172	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.6	NA	NA	NA	103	NA	0	0	1
1.9	9.6	1.6	NA	105	91	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
1.5	NA	NA	NA	NA	65	0	0	1
0.4	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2.1	31	NA	NA	0	0	0
0.3	9.2	1.8	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	100	NA	0	0	0
0.7	NA	NA	39	100	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	232	0	0	0
0.8	NA	1.2	NA	NA	NA	0	0	0
0.7	10.1	1.1	NA	NA	NA	0	0	0
0.4	9.3	2.8	NA	105	NA	0	0	0
0.3	9.3	3.7	NA	108	NA	0	0	0
0.4	NA	7.6	NA	107	NA	0	0	0
0.5	10	3.8	NA	NA	NA	0	0	0
1.7	NA	2.6	NA	101	NA	0	0	1
1.9	9.1	4.8	NA	99	NA	0	0	1
0	NA	NA	NA	103	NA	0	0	0
0.4	NA	2	NA	99	NA	0	0	0
0.3	NA	4.2	NA	NA	NA	0	0	1
0.2	NA	5.8	NA	NA	NA	0	0	1
NA	NA	5.7	NA	NA	NA	0	0	1
0.5	11.9	NA	NA	106	203	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	9	NA	NA	98	NA	0	0	0
0.3	8.6	1.6	NA	101	NA	0	0	0
0.5	8.8	NA	NA	101	NA	0	0	0
0.5	9.3	NA	NA	97	NA	0	0	0
0.4	NA	NA	NA	96	NA	1	0	0
NA	NA	NA	NA	NA	110	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	140	0	0	0
NA	NA	1.6	NA	NA	118	1	0	1
NA	NA	NA	NA	NA	NA	0	0	1
2.3	8.2	NA	NA	97	NA	1	0	1
1	8.9	NA	NA	100	NA	0	0	1
0.7	8.4	NA	NA	100	NA	0	0	1
0.6	9.6	1.4	NA	NA	NA	0	0	0
0.8	9.2	1.1	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
0.7	NA	1.6	NA	NA	NA	0	0	0
NA	NA	1.3	3.8	NA	NA	0	0	0
1.2	NA	NA	6	NA	NA	0	0	0
1.4	NA	NA	7.3	NA	NA	0	0	0
1.4	NA	NA	6.1	NA	NA	0	0	0
NA	10.4	NA	5.1	NA	NA	0	0	0
NA	NA	NA	5.5	NA	NA	0	0	0
NA	NA	NA	7.1	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.7	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.6	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.4	9.1	2.9	NA	104	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.2	NA	1	NA	NA	NA	0	0	0
0.4	NA	NA	11	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	NA	9.3	NA	NA	0	0	0
0.3	NA	NA	9.3	NA	NA	0	0	1
1.5	9.4	2.8	NA	99	NA	0	0	1
0.6	NA	NA	NA	101	NA	0	0	1
0.5	NA	NA	17	104	226	0	0	0
0.5	NA	2.2	23	NA	229	0	0	0
0.5	9.7	2.1	NA	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	224	0	0	0
0.3	9.5	1.8	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	4.5	NA	NA	NA	0	0	0
NA	NA	4.4	NA	NA	NA	0	0	0
0.5	NA	4.8	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
0.3	9.7	NA	NA	103	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	6.7	NA	NA	NA	0	0	1
0.4	NA	12	27	NA	NA	0	0	1
0.3	9.4	23	NA	NA	NA	0	0	1
NA	NA	26	61	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	8.2	NA	NA	NA	0	0	1
0.4	9.7	6.2	NA	NA	NA	0	0	0
0.4	NA	6.9	NA	NA	NA	0	0	1
0.4	NA	7.4	23	NA	NA	0	0	1
0.4	NA	8.5	NA	NA	NA	0	0	1
0.4	NA	11	NA	NA	NA	0	0	1
0.4	NA	11	NA	NA	NA	0	0	1
0.4	9.4	15	NA	NA	NA	0	0	1
0.4	NA	15	NA	102	NA	0	0	1
0.5	NA	18	NA	NA	NA	0	0	1
0.5	NA	23	NA	NA	NA	0	0	1
0.3	NA	25	NA	NA	NA	0	0	1
0.5	NA	37	NA	NA	NA	0	0	1
NA	NA	27	NA	NA	NA	0	0	1
NA	NA	15	NA	NA	NA	0	0	1
0.4	9	10	NA	NA	NA	0	0	1
0.3	NA	12	NA	NA	NA	0	0	1
0.4	NA	17	NA	NA	NA	0	0	1
NA	9.5	22	NA	NA	NA	0	0	1
0.5	NA	38	NA	NA	NA	0	0	1
NA	11.1	53	NA	NA	NA	0	0	1
NA	NA	68	NA	NA	NA	0	0	1
1.2	NA	85	462	NA	NA	0	0	1
2.8	NA	127	NA	102	NA	0	0	1
0.7	NA	NA	NA	106	NA	0	0	1
0.7	NA	NA	NA	104	NA	0	0	0
NA	NA	4.4	NA	NA	NA	0	0	1
NA	NA	3.8	NA	NA	NA	0	0	1
0.6	NA	NA	NA	103	NA	0	0	1
0.8	9.2	NA	NA	95	NA	0	0	1
0.4	9.5	10	NA	101	NA	0	0	1
0.7	9.5	18	NA	98	NA	0	0	1
0.3	9.4	18	NA	100	NA	0	0	1
1.8	10.1	39	NA	98	NA	0	0	1
7.8	NA	50	NA	NA	NA	0	0	1
NA	9.6	2.4	NA	98	NA	0	0	1
NA	9	2.5	NA	103	NA	0	0	0
NA	10.4	3.7	NA	98	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.2	10.4	2.3	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.7	NA	1.3	16	92	NA	0	0	0
0.1	NA	2.6	NA	NA	NA	0	0	0
0.2	9.3	1.9	NA	103	NA	0	0	0
0.2	9.2	2.2	NA	103	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.1	9.4	1.6	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	9.7	1.5	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.1	NA	2.9	26	NA	NA	0	0	0
0.6	9.4	1.9	NA	99	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
9.8	8.2	NA	NA	99	NA	0	0	0
0.5	NA	1.9	12	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
2.2	9.1	4.5	NA	92	242	0	0	0
0.5	8.4	4.1	NA	102	NA	1	0	0
0.5	NA	1	NA	NA	NA	0	0	0
0.7	10	1	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.7	NA	1.4	NA	NA	NA	0	0	0
NA	NA	2.8	NA	NA	106	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	9.7	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	97	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
2.7	9	NA	NA	90	NA	0	0	1
NA	NA	1.7	17	106	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
NA	NA	1.2	17	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.8	NA	1.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	13	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	179	0	0	0
0.3	8.9	NA	NA	107	NA	0	0	0
0.5	NA	4.8	NA	NA	NA	0	0	0
0.4	8.9	1.7	NA	108	NA	0	0	0
24.2	8.6	4.1	NA	92	NA	0	0	1
0.3	NA	NA	NA	98	224	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	11	1.5	NA	NA	NA	0	0	0
NA	NA	1.3	NA	99	NA	0	0	0
0.4	10.1	1.1	NA	101	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.3	10.3	1.5	NA	NA	NA	0	0	0
0.3	10.1	1.1	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
5	6.9	5.5	NA	110	NA	0	0	0
0.5	8.2	NA	52	117	94	0	0	1
0.4	NA	3.9	NA	NA	NA	0	0	0
0.5	NA	4.6	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	209	0	0	0
4.4	9	15	NA	94	NA	0	0	0
NA	NA	1.1	38	NA	NA	0	0	0
NA	NA	5.9	NA	NA	NA	0	0	0
NA	NA	7.2	NA	NA	NA	0	0	0
NA	NA	6.5	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.2	NA	1	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
NA	8.9	NA	NA	NA	NA	0	0	0
0.5	NA	4.2	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	7.8	24	NA	NA	0	0	0
NA	NA	7.9	NA	NA	NA	0	0	0
NA	NA	7.5	NA	NA	NA	0	0	0
NA	NA	7.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	9.3	1.6	2972	101	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	NA	NA	104	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
0.5	NA	3.2	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.5	8.4	2.2	NA	NA	NA	0	0	0
0.6	8.8	3.5	NA	NA	251	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.7	NA	2.3	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	NA	153	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.6	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.2	7.8	NA	NA	111	NA	0	0	0
0.6	NA	1.6	10	NA	216	0	0	0
0.7	NA	1.7	NA	NA	199	0	0	0
0.6	NA	1.1	NA	NA	155	0	0	0
0.5	9	1.1	11	NA	153	0	0	0
0.6	NA	1.6	NA	NA	160	0	0	0
0.4	9.7	NA	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	102	NA	0	0	0
0.4	NA	3.2	NA	NA	NA	0	0	0
0.5	9.5	NA	NA	NA	NA	0	0	0
1.8	NA	NA	NA	105	NA	0	0	0
0.4	NA	2.6	NA	102	NA	0	0	0
0.6	NA	2.6	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
14.2	8.4	NA	NA	101	NA	1	0	1
0.5	9.1	1.9	NA	100	NA	0	1	0
NA	NA	2	NA	NA	NA	0	1	0
0.3	9.5	2	NA	100	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.6	9.3	NA	NA	97	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.3	8.2	4.3	NA	108	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	9.3	1.4	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.7	8.2	2.9	NA	103	NA	0	0	0
0.8	NA	2.5	NA	102	NA	0	0	0
0.9	9.6	5.9	NA	102	NA	0	0	0
0.8	NA	6.7	6.7	NA	NA	0	0	0
0.6	9.6	5.7	NA	104	NA	0	0	0
0.7	NA	4.3	NA	101	NA	0	0	0
0.6	8.8	4.6	NA	105	NA	0	0	0
NA	9.7	4.8	NA	104	NA	0	0	0
0.5	NA	5.5	NA	NA	NA	0	0	0
0.6	8.4	7.5	NA	102	NA	0	0	0
0.6	NA	6.7	NA	104	NA	0	0	0
1.1	NA	16	NA	NA	NA	0	0	0
0.9	9.3	14	NA	NA	NA	0	0	1
0.8	8.6	11	12	104	NA	0	0	1
0.5	NA	6.9	NA	NA	NA	0	0	1
0.6	8.5	11	NA	NA	NA	0	0	1
0.7	8.9	14	NA	NA	NA	0	0	1
0.7	9.4	17	NA	NA	NA	0	0	1
0.4	8.9	18	NA	NA	NA	0	0	1
NA	NA	2.6	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.6	8.2	NA	NA	101	96	0	0	1
0.5	8.7	124	NA	NA	NA	0	0	1
1	NA	4.45	NA	106	NA	0	0	1
0.4	9.5	1.5	NA	97	NA	0	0	0
1.5	NA	NA	NA	NA	NA	1	0	0
1.4	9.8	NA	NA	99	NA	0	0	0
1.7	9.6	NA	NA	100	241	0	0	0
1.9	NA	NA	NA	NA	259	1	0	0
2	NA	NA	NA	NA	NA	0	0	0
1.7	NA	NA	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	1	0	0
12.2	NA	NA	NA	NA	NA	1	0	0
0.7	NA	NA	NA	100	NA	1	1	0
0.7	NA	NA	NA	100	NA	0	1	0
NA	9.4	116	NA	101	NA	0	0	0
0.8	8.8	84	NA	103	NA	0	1	0
NA	NA	3.4	NA	NA	NA	0	0	0
1.2	9.1	7.8	NA	103	NA	0	0	1
1.1	9.7	8.1	NA	103	NA	0	0	1
0.9	NA	NA	NA	108	NA	0	0	1
0.7	8	2.8	NA	100	NA	0	0	0
0.3	8.5	2	69	99	NA	0	0	0
0.4	9.2	3.1	68	97	NA	0	0	0
2.6	8.4	6	NA	94	108	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
0.3	9.9	1.4	10	95	265	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.8	NA	6.1	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.7	NA	1.1	NA	NA	NA	0	0	0
0.6	NA	1.9	NA	102	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	9.1	NA	NA	105	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
1.6	NA	NA	NA	NA	NA	0	0	1
0.6	10	NA	NA	NA	NA	0	0	1
0.5	NA	1.3	162	104	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	9.6	NA	NA	NA	NA	0	0	0
0.4	NA	18	NA	NA	NA	0	0	1
0.4	NA	8.9	NA	NA	NA	0	0	1
0.4	NA	3.5	NA	NA	NA	0	0	1
0.3	10	3.3	NA	99	NA	0	0	1
0.5	NA	3.5	NA	NA	NA	0	0	1
0.4	NA	3.2	NA	NA	NA	0	0	1
0.4	NA	3.8	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	3.6	NA	NA	NA	0	0	1
0.4	NA	4.2	NA	NA	NA	0	0	1
0.4	NA	5.9	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	9.2	1.1	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
1.3	10	NA	NA	NA	167	0	0	0
1.5	NA	1.3	NA	NA	162	0	0	0
1.2	10.4	1.4	NA	NA	NA	0	0	0
1.1	8.4	40	NA	103	NA	0	0	0
0.6	9.3	NA	NA	103	NA	0	0	0
0.8	9	NA	NA	98	NA	0	0	1
0.7	NA	NA	NA	99	NA	0	0	1
0.6	9.1	1.4	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
0.3	9.3	1.4	NA	NA	NA	0	0	0
0.5	9.5	2	NA	NA	NA	0	0	1
0.6	8.6	1.7	NA	NA	NA	0	0	0
0.6	9.4	2	NA	100	NA	0	0	1
0.7	9.2	1.5	NA	105	NA	0	0	0
0.6	8.8	1.7	NA	104	NA	0	0	1
0.5	8.7	1.6	NA	104	NA	0	0	1
0.3	8.8	1.4	NA	101	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	1
0.4	NA	1.8	NA	NA	NA	0	0	1
0.3	NA	1.6	NA	NA	NA	0	0	1
0.6	9.1	2.1	NA	NA	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	1
NA	9.2	2.5	NA	104	NA	0	0	1
NA	NA	1.7	NA	NA	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	1
NA	NA	2.4	NA	NA	NA	0	0	1
NA	NA	2.2	NA	NA	NA	0	0	1
0.9	NA	2.1	NA	NA	NA	0	0	1
0.6	8.8	2.6	NA	NA	NA	0	0	1
0.4	NA	3.6	NA	NA	NA	0	0	1
0.5	NA	4.2	NA	NA	NA	0	0	1
NA	NA	5.9	NA	NA	NA	0	0	1
0.5	NA	7.7	NA	NA	NA	0	0	1
NA	NA	9	NA	NA	NA	0	0	1
NA	NA	10	NA	NA	NA	0	0	1
NA	9.1	11	NA	103	NA	0	0	1
0.5	8.6	13	NA	NA	NA	0	0	1
NA	NA	1.2	NA	NA	NA	0	0	0
1.1	8.4	NA	13	105	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
14.6	8.7	16	NA	105	NA	1	0	0
1.3	NA	12	63	100	NA	0	0	1
0.4	9.3	8.1	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9	NA	NA	96	NA	1	1	1
0.5	NA	NA	NA	NA	NA	1	0	1
0.5	6.8	NA	NA	98	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	0
2.1	9.3	1.4	NA	101	NA	1	0	0
NA	NA	NA	NA	NA	NA	1	0	0
1.2	NA	2	NA	NA	NA	1	0	0
0.3	10.1	1.3	NA	103	NA	0	0	0
0.3	7.9	332	413	100	NA	0	0	0
4.2	8.2	3.2	NA	102	217	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	10.1	1.2	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
1.2	10.2	3.2	NA	99	107	0	0	0
NA	NA	1.9	14	NA	NA	0	0	0
0.2	9.7	13	NA	NA	NA	0	0	0
NA	NA	12	NA	NA	NA	0	0	0
0.3	9.5	12	NA	NA	NA	0	0	1
0.3	10.2	9.6	NA	103	NA	0	0	0
0.4	NA	16	NA	106	167	0	0	0
1.4	9.1	NA	NA	104	161	0	0	1
1	NA	5.3	NA	102	NA	0	0	0
1.7	8	NA	NA	101	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	214	0	0	0
NA	9.1	NA	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.6	NA	NA	NA	0	0	0
0.3	9.7	1.9	NA	NA	NA	0	0	0
0.5	9.6	2.2	NA	NA	NA	0	0	0
0.6	9.8	1.6	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.9	NA	2.1	NA	NA	161	0	0	0
0.9	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	1.8	NA	NA	NA	0	0	0
0.8	NA	1.8	NA	NA	NA	0	0	0
0.8	NA	1.8	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.4	8.9	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	165	0	0	0
0.4	NA	NA	NA	NA	161	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
NA	NA	8.5	NA	NA	NA	0	0	1
NA	NA	9	NA	NA	NA	0	0	1
NA	NA	10	NA	NA	NA	0	0	1
0.2	9.8	6	NA	NA	NA	0	0	1
0.3	NA	5.9	NA	NA	NA	0	0	1
NA	NA	5.3	NA	NA	NA	0	0	1
0.4	NA	1.5	NA	NA	182	0	0	0
0.4	9.6	1.9	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	211	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	103	NA	0	0	0
4	8.2	4860	NA	105	NA	0	0	1
2.1	8.1	NA	NA	94	NA	0	0	1
0.3	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	NA	129	102	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	9.7	2.7	NA	102	291	0	0	0
0.5	9.2	2.5	NA	101	NA	0	0	1
0.6	NA	3.2	NA	NA	NA	0	0	0
0.6	NA	4.1	NA	NA	NA	0	0	1
0.6	9.2	3.4	NA	107	214	0	0	1
NA	NA	2.8	NA	NA	NA	0	0	1
0.5	9.4	3.2	NA	107	NA	0	0	1
0.5	9.1	3.4	NA	108	NA	0	0	0
1.6	NA	1.2	NA	104	NA	1	0	0
NA	9.5	1.1	NA	104	NA	0	0	0
1.6	NA	NA	NA	NA	NA	1	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
1.4	9.9	NA	NA	101	NA	0	0	1
0.2	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.8	8.3	1	NA	102	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.4	NA	2	12	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.5	8.7	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
NA	9.6	1.5	NA	99	NA	0	0	0
2.5	7.8	4.1	NA	105	NA	0	0	0
1.3	10	170	NA	104	NA	0	1	1
1.9	NA	2.9	NA	101	NA	0	0	0
0.4	10.1	3	NA	104	NA	0	0	0
0.4	NA	4	17	NA	NA	0	0	0
3	7.8	10	NA	102	NA	0	0	0
NA	NA	4	NA	NA	NA	0	0	0
0.4	9.6	4.7	NA	102	NA	0	0	0
0.6	9.9	4.7	NA	88	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.7	9.2	1.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	10.2	1.6	NA	102	221	0	0	0
NA	NA	1	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	9.5	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.3	9	NA	NA	NA	NA	0	0	0
0.2	9	NA	NA	NA	NA	0	0	1
0.5	NA	2	NA	NA	NA	0	0	0
0.3	NA	NA	NA	104	NA	0	0	0
0.3	9	2.9	NA	102	NA	0	0	1
NA	NA	8.5	NA	NA	199	0	0	0
0.4	NA	4.6	NA	NA	NA	0	0	0
NA	9.8	NA	NA	NA	NA	0	0	0
0.1	9.6	NA	NA	NA	NA	0	0	0
0.2	9.5	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	10.1	NA	NA	97	NA	0	0	0
0.5	9.9	2.9	NA	106	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
NA	NA	NA	NA	98	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
0.9	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
1	NA	1.9	NA	NA	NA	0	0	0
1	NA	1.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	102	197	0	0	0
0.4	9.8	NA	NA	100	274	0	0	0
8.1	8.7	5.3	NA	99	NA	0	0	1
1.9	8.7	7.7	NA	97	NA	0	0	0
0.3	NA	31	NA	100	NA	0	0	0
0.4	NA	NA	NA	101	NA	0	0	0
0.4	NA	NA	NA	92	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.4	9.2	2.2	NA	NA	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.3	8.6	6.7	912	98	NA	0	0	1
NA	NA	1.7	NA	NA	NA	0	0	0
NA	NA	1.7	NA	102	183	0	0	0
0.9	9.2	3	612	97	NA	0	0	0
0.4	8.9	115	527	94	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
0.2	9.8	2.8	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.3	9.9	2.3	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.3	9.3	416	NA	102	NA	0	0	0
0.6	9.3	1	174	97	NA	0	0	1
3.9	8.9	4.6	NA	100	NA	0	0	1
0.2	NA	11	NA	NA	NA	0	0	0
NA	NA	11	NA	104	NA	0	0	1
0.2	NA	13	NA	NA	NA	0	0	1
0.3	NA	13	NA	NA	NA	0	0	1
0.2	NA	20	NA	NA	NA	0	0	1
0.2	9.3	20	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
1.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1	18	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
NA	NA	2.4	22	107	NA	0	0	1
NA	NA	2.3	24	105	NA	0	0	1
0.2	8.7	2.8	24	106	NA	0	0	1
0.3	NA	3.2	NA	NA	NA	0	0	1
NA	9	3	NA	NA	NA	0	0	1
NA	9	3.3	23	101	NA	0	0	1
NA	NA	2.5	NA	NA	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	1
0.3	NA	2.6	32	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	131	0	0	1
0.3	NA	2.5	NA	106	NA	0	0	1
0.3	9.4	NA	NA	97	171	0	0	1
0.4	NA	2	NA	NA	NA	0	0	1
0.2	NA	2.3	NA	NA	NA	0	0	1
0.4	8.6	2.5	NA	NA	NA	0	0	1
0.6	NA	2.6	NA	97	NA	0	0	1
0.3	NA	2.6	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	6.4	NA	NA	NA	0	0	1
NA	NA	NA	59	104	140	0	0	1
NA	NA	NA	NA	105	164	0	0	1
0.6	9.1	NA	48	104	NA	0	0	1
1.1	NA	4.7	NA	NA	NA	0	0	1
1	NA	4.2	NA	NA	NA	0	0	1
1.3	NA	4.5	NA	NA	NA	0	0	1
1.6	NA	4	NA	NA	NA	0	0	1
1	NA	4.1	NA	NA	NA	0	0	1
0.9	NA	4.8	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.6	9.7	1.4	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.7	16	NA	NA	0	0	0
NA	NA	18	88	106	NA	0	0	1
0.6	NA	NA	NA	104	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	94	NA	0	0	0
1	9.5	4.8	NA	103	245	1	0	0
1.1	10	NA	NA	104	NA	1	0	0
1.2	9.2	NA	NA	104	NA	1	0	0
0.5	NA	5.1	NA	NA	NA	0	0	0
0.3	9.1	7.5	NA	NA	NA	0	0	0
NA	NA	6	NA	NA	NA	0	0	0
0.2	9.1	6.6	NA	NA	NA	0	0	0
NA	NA	1	NA	NA	NA	0	0	0
0.7	9.6	124	NA	102	NA	0	0	1
0.4	NA	NA	NA	97	NA	0	0	1
0.5	9.5	NA	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.6	NA	2.7	7.4	NA	NA	0	0	0
0.7	NA	3	NA	104	209	0	0	0
NA	NA	NA	8.3	NA	NA	0	0	0
0.8	NA	2.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.6	8.7	13	NA	103	NA	0	0	1
0.5	NA	21	NA	NA	NA	0	0	1
0.3	9.7	5.6	NA	NA	NA	0	0	1
0.4	9.5	3.9	NA	NA	NA	0	0	1
0.3	9.6	2.6	NA	NA	NA	0	0	1
0.3	9.9	NA	NA	NA	NA	0	0	1
0.8	NA	1.6	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	1	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	9.5	1.8	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
1.3	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	231	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
22.3	9.9	41	NA	110	NA	1	0	1
0.5	NA	NA	NA	NA	205	0	0	0
0.4	NA	2.6	NA	NA	260	0	0	0
0.5	NA	2.6	NA	104	229	0	0	0
0.3	9.2	2.7	NA	105	200	0	0	0
0.6	NA	2.3	NA	NA	197	0	0	0
0.5	9.4	2.5	NA	NA	195	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	106	NA	0	0	1
NA	NA	NA	NA	104	186	0	0	0
NA	NA	NA	NA	NA	260	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	2.2	6.9	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	150	0	0	0
NA	9.3	1.6	10	106	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	1
NA	NA	3.6	NA	NA	162	0	0	1
0.3	NA	2.8	NA	NA	NA	0	0	1
NA	NA	3.1	NA	NA	165	0	0	1
NA	NA	2.9	NA	NA	164	0	0	1
NA	NA	1.1	NA	NA	NA	1	0	0
0.3	NA	4.1	NA	NA	NA	0	0	0
0.5	NA	4.2	NA	NA	NA	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.6	9.4	1	13	99	172	0	0	0
0.5	9.7	NA	8.1	NA	NA	0	0	0
0.3	NA	2	14	NA	NA	0	0	0
NA	NA	1.8	13	NA	NA	0	0	0
0.6	NA	1.8	14	NA	NA	0	0	0
0.5	NA	2	16	NA	NA	0	0	0
0.8	9.7	2	14	NA	194	0	0	0
0.3	NA	1.7	13	NA	NA	0	0	0
0.5	NA	2	14	NA	NA	0	0	0
4.2	8.9	1.6	NA	101	NA	0	1	1
0.5	10	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	1	1	1
0.2	9.3	NA	NA	102	NA	1	1	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.3	9.6	14	NA	95	NA	0	1	1
0.2	8.9	9.9	NA	104	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.9	NA	4.5	NA	NA	NA	0	0	1
4	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
5.9	8.9	NA	NA	97	NA	1	0	1
0.6	NA	3.7	NA	NA	NA	0	0	0
0.6	NA	5	NA	NA	NA	0	0	0
0.7	NA	5.1	NA	NA	NA	0	0	0
0.5	NA	4.7	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	8.9	4	NA	100	NA	0	0	0
0.4	9.1	3.5	NA	101	NA	0	0	0
0.3	9	2.3	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	6	NA	NA	NA	0	0	0
0.3	NA	2.6	14	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	1.9	15	NA	NA	0	0	0
0.3	NA	1.9	14	NA	NA	0	0	0
0.3	NA	1.6	16	NA	NA	0	0	0
0.3	9.5	2.2	NA	NA	NA	0	0	0
0.4	9.1	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.4	4.6	NA	NA	NA	0	0	1
0.3	9	5.9	NA	NA	NA	0	0	1
NA	NA	6.5	NA	NA	NA	0	0	1
0.4	9.6	NA	NA	97	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	101	NA	0	0	1
NA	NA	4.9	NA	NA	NA	0	0	1
0.5	8.9	NA	NA	104	NA	0	0	1
0.6	8.6	4.1	NA	103	NA	0	0	1
0.6	9	3.5	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	8.7	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	9	3.6	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	10	NA	NA	97	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.4	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	9.1	NA	NA	98	NA	0	0	1
0.5	9.3	NA	NA	101	NA	0	0	1
0.6	NA	6.4	NA	99	NA	0	0	1
0.2	8.8	NA	NA	96	NA	0	0	1
0.3	8.6	NA	NA	98	NA	0	0	1
0.3	8.8	NA	NA	98	NA	0	0	1
0.3	9.5	NA	NA	101	NA	0	0	1
0.4	NA	NA	NA	102	NA	0	0	1
0.5	9	NA	NA	101	NA	0	0	1
NA	9.3	NA	NA	102	NA	0	0	1
0.5	9.2	NA	NA	99	NA	0	0	1
0.4	9.1	NA	NA	101	NA	0	0	1
0.5	NA	5.6	NA	97	NA	0	0	1
0.6	9.4	NA	NA	103	NA	0	0	1
0.5	9.3	NA	NA	98	NA	0	0	1
1.9	9.4	6.2	NA	100	NA	0	0	1
14.2	8.6	NA	9.8	102	NA	0	0	1
0.4	9.1	NA	NA	102	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
0.5	9.3	2.2	NA	101	NA	0	0	0
1.4	NA	NA	NA	NA	NA	0	0	0
1.2	NA	NA	NA	93	148	1	0	0
1.1	NA	NA	NA	97	NA	1	0	0
1	NA	NA	NA	94	NA	0	0	0
1.2	NA	NA	NA	NA	NA	1	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	1
0.3	NA	2	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.2	8.8	9.3	335	100	NA	0	0	1
0.4	NA	3.6	NA	NA	NA	0	0	0
4.2	NA	NA	NA	NA	NA	0	0	1
6	8	NA	NA	102	NA	1	0	1
5.6	NA	NA	NA	NA	NA	0	0	1
6.1	NA	NA	NA	NA	NA	1	0	1
2.9	8.2	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	100	201	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.2	NA	2.2	NA	NA	NA	0	0	0
0.3	9.2	1.8	NA	99	168	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.4	9.7	3.4	18	96	NA	0	0	1
0.8	8.6	NA	NA	98	NA	0	0	0
2.7	8.1	7	NA	98	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	1.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	1.3	NA	NA	NA	0	0	1
0.3	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	314	0	0	1
0.5	NA	1.5	NA	NA	335	0	0	1
1.8	9.6	NA	NA	98	126	0	0	0
3.7	9.2	8.7	NA	106	26	0	0	0
0.3	7.8	NA	NA	106	NA	0	0	0
0.6	9.4	1.1	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
7.4	10.1	2.6	NA	99	NA	1	0	1
2.2	NA	NA	NA	99	NA	1	0	1
NA	NA	NA	NA	101	NA	1	0	1
NA	NA	NA	NA	105	NA	0	1	1
1	NA	NA	NA	104	NA	0	0	1
0.6	9.1	NA	NA	NA	NA	0	1	1
0.8	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.7	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
1.2	NA	NA	NA	NA	NA	0	1	1
0.8	NA	NA	NA	NA	137	0	1	1
1.1	9.3	NA	NA	NA	NA	1	1	1
0.8	9.3	NA	NA	105	NA	1	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	104	NA	0	1	1
0.7	NA	NA	NA	105	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.7	NA	NA	NA	NA	NA	0	1	1
1	NA	NA	NA	101	NA	0	1	1
1.3	8.9	NA	NA	NA	NA	0	1	1
1	NA	65	NA	NA	NA	0	0	1
0.9	NA	8.8	NA	NA	NA	0	0	1
1	9.3	89	NA	101	NA	0	0	1
1.3	NA	210	NA	NA	NA	0	0	1
2.5	NA	312	NA	NA	NA	0	0	1
0.2	9.1	2.7	NA	104	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.3	9.1	2.6	NA	106	NA	0	0	0
0.2	NA	2.7	NA	NA	NA	0	0	0
0.2	NA	2.9	NA	NA	NA	0	0	0
0.2	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	4.2	NA	NA	NA	0	0	0
0.5	NA	3.7	NA	NA	NA	0	0	0
0.5	NA	3.3	NA	104	NA	0	0	0
0.8	8.8	1.4	NA	110	NA	0	0	0
1.3	NA	2.6	NA	98	NA	0	0	0
1.3	NA	NA	NA	102	NA	0	0	0
0.4	NA	6.8	19	101	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	0
0.9	NA	1.2	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
1.2	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
0.3	9.4	1.2	13	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.6	9.9	NA	NA	107	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1	NA	98	140	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	1.2	38	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
NA	NA	1.4	18	106	NA	0	0	0
0.5	NA	6.2	NA	103	NA	0	0	1
0.4	9.4	5.8	NA	NA	NA	0	0	1
0.3	NA	4.4	NA	NA	NA	0	0	1
0.5	NA	4.5	39	NA	NA	0	0	0
0.3	NA	4.2	NA	NA	NA	0	0	1
0.3	NA	4.1	NA	NA	NA	0	0	1
0.3	NA	4.2	NA	NA	NA	0	0	1
0.3	NA	3.7	NA	NA	NA	0	0	1
0.4	NA	3.3	NA	NA	NA	0	0	1
0.4	NA	5.4	NA	NA	NA	0	0	1
0.4	NA	4.1	NA	NA	NA	0	0	1
0.4	NA	5.8	NA	NA	NA	0	0	1
0.3	8.4	3.3	NA	NA	NA	0	0	1
0.4	NA	4.3	NA	NA	NA	0	0	1
0.3	NA	6.1	NA	NA	NA	0	0	1
0.3	NA	8.9	NA	NA	NA	0	0	1
0.3	NA	15	NA	NA	NA	0	0	1
0.3	NA	29	NA	98	NA	0	0	1
1.8	NA	51	NA	NA	NA	0	0	1
0.6	NA	2	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.4	8.6	1.8	NA	100	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	10.9	1.1	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	97	210	0	0	0
NA	10.5	1.4	NA	98	NA	0	0	0
0.3	9.5	1.5	NA	92	200	0	0	0
0.4	9.2	1	NA	98	167	0	0	0
0.4	9.3	1.1	NA	96	167	0	0	0
0.4	9.7	1.1	NA	98	167	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.3	10.1	NA	NA	105	197	0	0	0
0.3	10	NA	NA	NA	NA	0	0	0
0.2	9.7	NA	NA	NA	NA	0	0	0
0.5	NA	NA	12	NA	NA	0	0	0
0.3	NA	1.3	16	NA	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	101	NA	0	0	1
1.7	NA	NA	NA	104	NA	1	0	0
0.4	NA	3.1	NA	NA	NA	0	0	0
0.2	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	3.6	NA	NA	NA	0	0	0
0.3	NA	3.9	NA	NA	NA	0	0	0
0.5	NA	3.1	NA	NA	NA	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	3.7	NA	NA	NA	0	0	0
0.5	NA	9	NA	NA	NA	0	0	0
0.7	NA	9.8	NA	NA	NA	0	0	0
0.9	NA	1.2	NA	101	NA	1	0	0
2.8	7.4	NA	NA	106	NA	1	0	0
1.1	NA	NA	NA	103	NA	0	0	1
0.4	NA	3.5	NA	NA	NA	0	0	1
0.4	NA	2.6	NA	NA	NA	0	0	1
0.4	NA	4.3	NA	NA	NA	0	0	0
0.3	NA	4.8	NA	NA	NA	0	0	0
0.4	NA	4.4	NA	NA	NA	0	0	0
0.5	NA	4.2	NA	NA	NA	0	0	0
NA	9.6	3.3	NA	101	NA	0	0	0
0.4	NA	3.2	NA	103	NA	0	0	0
0.4	9.4	2.9	NA	101	NA	0	0	0
0.3	NA	3.1	NA	102	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
0.3	8.8	2.6	NA	100	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.3	9	2.2	NA	99	NA	0	0	0
0.3	9	2.6	NA	101	NA	0	0	0
0.3	NA	2.4	NA	NA	236	0	0	0
0.4	NA	2.5	NA	NA	227	0	0	1
0.3	NA	3	NA	NA	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
0.9	8.1	4.1	NA	92	NA	0	0	1
0.8	8	6.5	NA	NA	NA	0	0	0
0.5	8	5.1	66	101	NA	0	0	0
0.3	8	3.9	NA	104	NA	0	0	0
0.2	8.5	3	NA	102	NA	0	0	1
0.4	8.6	2.5	NA	101	NA	0	0	1
0.3	8.7	2.9	NA	NA	NA	0	0	1
0.4	8.9	3	NA	103	NA	0	0	1
0.5	9.2	3.4	NA	103	NA	0	0	1
0.4	8.8	4.2	NA	NA	NA	0	0	1
0.5	NA	5.8	NA	NA	NA	0	0	1
0.2	9.4	5.8	NA	NA	NA	0	0	1
0.3	8.5	6.5	NA	98	NA	0	0	1
0.2	8.5	11	NA	NA	NA	0	0	1
0.2	8.8	15	NA	100	NA	0	0	1
0.3	8.1	15	NA	97	NA	0	0	1
0.2	8.9	16	NA	101	NA	0	0	1
0.2	9.2	23	NA	NA	NA	0	0	1
0.6	9.5	NA	NA	107	NA	0	0	0
0.6	8.7	25	NA	106	NA	0	0	0
0.8	NA	1.6	NA	105	NA	0	0	0
0.5	NA	2.1	NA	103	NA	0	0	0
0.4	NA	2.9	NA	106	NA	0	0	0
0.7	8.7	2.9	NA	104	NA	0	0	0
0.8	8.6	3.3	NA	104	NA	0	0	0
0.4	NA	NA	973	99	NA	0	0	0
0.2	9.4	1.3	NA	NA	NA	0	0	0
0.2	NA	2.2	NA	105	NA	0	0	0
0.2	NA	2	NA	NA	NA	0	0	0
0.2	NA	2	NA	NA	188	0	0	0
0.1	NA	2.1	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	1.8	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
0.9	10.2	2.1	31	NA	NA	0	0	0
1.3	NA	1.9	NA	NA	NA	0	0	0
1.2	NA	2.6	NA	NA	NA	0	0	0
0.8	10	2.1	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.9	NA	2.2	NA	NA	NA	0	0	0
0.8	NA	NA	5.5	NA	NA	0	0	0
0.8	NA	NA	7.2	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.1	8.5	NA	201	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	11	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
0.6	NA	NA	11	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.8	NA	NA	10	NA	NA	0	0	0
NA	NA	3.1	29	NA	123	0	0	0
NA	9.7	2.9	23	106	120	0	0	0
0.7	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
1.5	9.8	3.9	NA	98	NA	0	0	1
0.3	NA	1.2	NA	NA	NA	0	0	0
0.1	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.8	9.9	1.8	NA	101	NA	0	0	0
0.5	NA	3.7	NA	103	NA	0	0	0
0.6	9.1	2.1	NA	107	NA	0	0	1
NA	NA	3.9	NA	102	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.3	20	NA	NA	0	0	0
0.2	10.1	10	NA	NA	NA	0	0	0
0.6	9.5	2.1	NA	100	NA	0	0	0
0.4	9.6	3.8	NA	91	NA	0	0	0
0.4	9.6	3.8	NA	93	NA	0	0	0
NA	9.2	NA	NA	90	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.6	9.1	1.8	9.2	NA	NA	0	0	0
0.6	NA	2	7.3	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
3.4	9.1	NA	NA	82	NA	0	0	1
28.2	8.8	NA	NA	84	NA	0	0	1
12.7	NA	3.3	NA	106	NA	1	0	1
0.4	9.7	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	NA	1.5	NA	NA	NA	0	0	0
0.7	9.7	2.9	NA	107	NA	0	0	0
16	8.9	46	NA	104	NA	0	0	1
0.5	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.5	10.6	NA	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
0.4	NA	NA	7.5	NA	NA	0	0	0
0.2	NA	1.9	13	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	2.1	1372	NA	NA	0	0	1
0.2	NA	3.7	545	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	52	NA	NA	0	0	1
0.2	NA	1.6	72	NA	NA	0	0	0
0.1	NA	1.9	24	NA	NA	0	0	0
NA	NA	2.1	21	NA	NA	0	0	0
0.2	NA	1.5	517	NA	NA	0	0	1
0.1	NA	1.9	1216	NA	NA	0	0	1
0.2	NA	2.2	1689	NA	NA	0	0	1
NA	NA	2.3	2259	NA	NA	0	0	1
NA	NA	2.2	3235	NA	NA	0	0	1
0.4	NA	1.2	NA	NA	212	0	0	0
NA	NA	1	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	204	0	0	0
0.4	NA	3.2	NA	NA	NA	0	0	0
0.3	NA	3.6	NA	NA	NA	0	0	1
0.4	NA	3.4	NA	NA	NA	0	0	1
0.4	NA	4.6	NA	NA	NA	0	0	1
0.4	NA	3.5	NA	NA	NA	0	0	1
0.5	NA	2.6	NA	NA	NA	0	0	0
0.5	9.9	3.2	NA	103	NA	0	0	1
0.4	10.3	2.6	NA	NA	NA	0	0	1
0.4	10.4	3.5	NA	NA	NA	0	0	1
0.3	9.7	NA	NA	NA	NA	0	0	1
0.6	NA	5.3	NA	NA	NA	0	0	1
0.6	NA	9.9	NA	NA	NA	0	0	0
0.5	9.2	10	NA	NA	NA	0	0	0
0.6	9.9	7.2	NA	NA	NA	0	0	0
0.5	NA	6.4	NA	NA	NA	0	0	0
0.4	8.9	7.8	NA	NA	NA	0	0	0
0.6	8.8	6.7	NA	NA	NA	0	0	0
0.6	9.4	7.2	NA	NA	NA	0	0	0
0.5	9.1	6.2	NA	104	NA	0	0	0
0.6	9.2	4.4	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
NA	8	2.4	NA	108	NA	0	0	0
0.8	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1	12	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.2	NA	2.2	NA	NA	NA	0	0	0
0.2	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
NA	NA	3.3	NA	NA	NA	0	0	0
0.2	10.4	1.8	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
0.2	10.1	2.2	NA	NA	NA	0	0	0
0.3	9.1	2.1	NA	NA	NA	0	0	0
NA	NA	NA	12	NA	NA	0	0	0
0.2	NA	2	3.5	NA	NA	0	0	0
0.2	NA	1.8	7.1	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	8.8	5.5	NA	100	NA	0	0	1
0.3	9.1	5.5	NA	105	NA	0	0	1
0.2	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	3	NA	101	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	9.5	1.2	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.5	9.7	1.2	NA	NA	NA	0	0	0
0.5	9.7	2.9	NA	103	196	0	0	0
0.2	8.4	NA	NA	96	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	10.8	NA	NA	NA	NA	0	0	0
0.3	11	1.4	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	4.6	NA	NA	NA	0	0	0
0.5	NA	3.5	NA	NA	NA	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
0.6	NA	2.8	NA	NA	NA	0	0	0
0.5	9.9	3.1	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
NA	NA	1.8	11	NA	NA	0	0	0
NA	NA	6.7	NA	NA	NA	0	0	1
NA	9.4	5.5	NA	101	NA	0	0	1
NA	NA	NA	NA	101	NA	0	0	1
NA	10	NA	NA	101	NA	0	0	1
0.3	10.1	6.2	NA	101	238	0	0	1
0.4	9.6	5.9	NA	99	NA	0	0	1
0.2	9.4	NA	NA	NA	NA	0	0	1
0.2	8.9	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.9	9.7	1.7	NA	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	2.2	16	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.5	9.2	2.5	NA	NA	NA	0	0	0
0.6	10.1	12	NA	NA	NA	0	0	0
0.6	NA	17	NA	NA	NA	0	0	1
0.6	NA	17	11	NA	284	0	0	1
NA	NA	13	NA	NA	NA	0	0	1
0.5	9.7	10	NA	NA	NA	0	0	1
0.8	NA	6.9	NA	NA	NA	0	0	1
0.9	NA	6.3	NA	NA	NA	0	0	1
0.7	9.7	5.5	NA	NA	NA	0	0	1
NA	NA	5.7	NA	NA	NA	0	0	1
NA	NA	4.7	NA	NA	NA	0	0	1
0.6	10.2	3.6	NA	NA	NA	0	0	1
0.6	9.6	3.1	NA	NA	NA	0	0	0
0.6	10	2.9	NA	NA	NA	0	0	0
0.7	9.8	3.1	NA	NA	NA	0	0	0
0.6	10	3.4	NA	NA	NA	0	0	0
0.8	9.7	3.3	NA	104	NA	0	0	0
0.7	9.4	3.9	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
1.3	NA	5.2	NA	105	NA	0	0	1
NA	NA	5.3	NA	NA	130	0	0	1
1.1	9.6	4.1	NA	NA	NA	0	0	1
0.9	9.6	4.1	NA	NA	152	0	0	1
0.8	9.3	4.4	NA	NA	NA	0	0	1
0.4	9.3	4.7	NA	NA	NA	0	0	1
0.5	9.9	6.5	NA	NA	NA	0	0	1
0.7	NA	5.8	NA	NA	303	0	0	1
1.6	8	12	NA	106	NA	0	0	0
0.9	8.5	14	NA	100	281	0	0	0
0.5	9.1	8.8	NA	106	NA	0	0	1
0.6	8.7	6.3	NA	106	245	0	0	1
0.7	NA	5.3	NA	NA	NA	0	0	1
0.6	9.9	7.2	NA	NA	NA	0	0	0
0.7	NA	8.4	NA	NA	NA	0	0	1
0.5	9.3	12	NA	NA	NA	0	0	1
0.4	NA	12	NA	NA	NA	0	0	1
0.4	8.6	7.8	NA	102	NA	0	0	1
0.6	NA	9.6	NA	99	NA	0	0	1
0.6	NA	14	NA	97	NA	0	0	1
NA	NA	15	NA	NA	NA	0	0	1
0.9	NA	17	NA	NA	NA	0	0	1
0.6	NA	18	NA	NA	NA	0	0	1
4.7	8.5	4.4	NA	101	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	1
NA	NA	1.3	NA	NA	NA	0	0	1
NA	NA	1.6	NA	NA	NA	0	0	1
NA	9.7	1	NA	NA	NA	0	0	0
NA	NA	9.6	NA	NA	NA	0	0	0
0.6	NA	9.5	NA	NA	NA	0	0	0
0.5	NA	8.3	NA	NA	NA	0	0	1
NA	NA	10	NA	NA	NA	0	0	1
0.5	9.4	6.5	NA	NA	238	0	0	0
0.5	9.8	6.4	NA	NA	NA	0	0	0
0.4	9.5	7.3	NA	NA	NA	0	0	0
NA	9.3	1.1	19	106	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	10.7	2	NA	101	NA	0	0	0
NA	NA	3.7	6.5	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.5	10.6	2.5	NA	NA	NA	0	0	0
0.3	NA	NA	3.7	NA	NA	0	0	0
0.2	9.4	3.3	NA	102	175	0	0	0
NA	10.1	1	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
NA	NA	2.2	NA	99	185	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.6	NA	2	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	NA	4322	NA	NA	NA	0	0	1
0.3	NA	8200	NA	NA	NA	0	0	1
0.5	NA	10800	2940	NA	NA	0	0	1
0.4	NA	9410	3114	NA	NA	0	0	1
0.6	NA	10104	4160	NA	NA	0	0	1
22.3	NA	1.1	NA	NA	NA	0	0	0
26.2	8.9	1.1	NA	100	NA	1	0	0
0.4	9.2	1.6	6.4	NA	213	0	0	0
0.8	NA	2.7	11	NA	253	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	246	0	0	0
0.7	NA	2.6	NA	NA	NA	0	0	0
NA	NA	2.2	NA	103	221	0	0	0
0.6	NA	2	NA	NA	220	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	10.1	NA	NA	NA	NA	0	0	1
NA	9.7	1.4	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
0.9	NA	2.4	NA	NA	NA	0	0	0
1	NA	2.4	NA	NA	NA	0	0	0
0.8	NA	2.6	NA	NA	NA	0	0	0
0.9	NA	2.8	NA	NA	NA	0	0	0
0.8	NA	2.7	NA	NA	NA	0	0	0
0.8	NA	2.4	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
NA	9	2	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.7	NA	2.4	NA	NA	NA	0	0	0
NA	9.7	2.4	NA	105	218	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.9	NA	2.1	NA	NA	NA	0	0	0
2.7	NA	2	NA	101	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.6	10.3	2.2	NA	103	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1.4	13	NA	NA	0	0	0
0.8	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.3	NA	1.4	31	NA	NA	0	0	0
0.2	NA	1.4	23	NA	187	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
4.8	8.8	17	NA	107	NA	0	0	1
4.9	NA	17	NA	105	NA	0	0	1
NA	NA	3.3	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	222	0	0	0
NA	9.6	1.7	NA	102	215	0	0	0
0.3	NA	12	NA	97	NA	0	0	0
0.9	NA	2.8	NA	NA	NA	0	0	0
0.7	9.9	4.9	14	103	198	0	0	0
NA	NA	5	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	9.6	1.6	NA	107	251	0	0	0
0.5	NA	1.7	7.6	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	NA	12	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
7.1	8.8	4	NA	100	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.4	10	1.3	NA	NA	NA	0	0	0
0.4	9.6	1.5	NA	NA	NA	0	0	0
0.2	9.8	1.6	NA	NA	NA	0	0	0
6.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	101	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	100	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
0.4	9.9	1.5	NA	NA	NA	0	0	0
NA	9.1	4	4405	85	NA	0	0	0
0.4	NA	NA	NA	NA	186	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	4.5	NA	NA	NA	0	0	0
0.3	NA	3.6	NA	NA	NA	0	0	0
0.4	NA	5.1	NA	NA	NA	0	0	0
0.4	NA	4.1	NA	NA	NA	0	0	0
0.5	NA	4.9	NA	NA	NA	0	0	0
0.3	NA	4.9	NA	NA	NA	0	0	0
0.5	8.7	NA	30	100	NA	0	0	0
NA	NA	1.8	NA	NA	241	0	0	0
0.4	8.5	3.5	NA	106	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	1
NA	NA	1.6	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	10.1	3.2	NA	NA	NA	0	0	1
0.4	9.7	3.6	NA	NA	NA	0	0	1
0.5	9.8	3.4	NA	NA	NA	0	0	1
0.3	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	2.9	NA	NA	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.2	NA	17	NA	108	NA	0	0	0
NA	NA	3.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
0.3	8.9	3	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	1
0.2	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.2	NA	2.7	16	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1	7.8	2.1	NA	108	NA	1	0	1
0.4	NA	4.3	6.7	NA	NA	0	0	0
0.3	NA	3.8	NA	NA	NA	0	0	0
NA	NA	3.8	NA	104	NA	0	0	0
0.3	NA	3.5	NA	NA	NA	0	0	0
0.3	7.7	NA	NA	111	NA	0	0	0
0.3	8.6	NA	10	105	NA	0	0	0
0.4	9.4	2.9	NA	103	NA	0	0	0
0.3	9.2	1.7	NA	103	NA	0	0	0
0.4	NA	NA	NA	NA	224	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	185	0	0	0
1.7	9.1	3.6	NA	103	NA	0	0	1
0.3	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	9.3	1.5	NA	NA	NA	0	0	0
0.3	9.5	1.8	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	204	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	7	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	6.7	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	10.4	NA	NA	100	NA	0	0	0
0.2	NA	4.4	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.3	10.2	20	NA	106	NA	0	0	0
0.3	9.5	15	NA	NA	NA	0	0	0
NA	9.5	15	NA	NA	NA	0	0	0
NA	NA	32	NA	NA	NA	0	0	0
NA	NA	20	NA	NA	NA	0	0	0
NA	NA	15	NA	NA	NA	0	0	0
0.5	NA	8.8	NA	NA	NA	0	0	0
0.2	NA	5.8	NA	NA	NA	0	0	0
0.5	NA	7.9	NA	NA	NA	0	0	0
NA	NA	11	NA	NA	NA	0	0	0
NA	NA	16	NA	NA	NA	0	0	0
NA	NA	15	NA	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
NA	NA	2.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1	NA	NA	NA	0	0	0
0.6	9.8	NA	NA	NA	NA	0	0	0
0.5	10.2	NA	NA	NA	NA	0	0	0
0.5	9.8	NA	NA	NA	NA	0	0	0
NA	10.2	NA	NA	NA	223	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.1	9	NA	NA	104	NA	0	0	0
0.1	9.1	NA	NA	99	NA	0	0	0
0.1	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.3	8.6	67	NA	105	NA	0	0	1
0.8	8.3	1.8	NA	103	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	4.5	NA	NA	NA	0	0	0
NA	NA	4.4	NA	NA	NA	0	0	0
0.6	9.3	3.9	NA	NA	NA	0	0	0
0.7	NA	4.5	NA	NA	NA	0	0	0
0.5	NA	5	NA	NA	NA	0	0	0
0.3	NA	1.6	16	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	0
0.4	10.3	1.7	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.6	NA	1.6	17	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
4.1	8.3	NA	NA	102	NA	0	0	1
16.2	8.3	NA	NA	97	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	1.7	NA	NA	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	1
0.3	NA	1.5	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	10	1.6	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	1
0.4	9.4	3.3	NA	103	NA	0	0	1
0.4	NA	5.8	NA	NA	NA	0	0	1
0.3	NA	7.2	NA	NA	NA	0	0	1
NA	NA	10	NA	NA	NA	0	0	1
0.3	NA	13	NA	NA	NA	0	0	1
0.3	NA	16	NA	NA	NA	0	0	1
0.3	9.4	20	NA	NA	NA	0	0	1
0.2	NA	29	NA	NA	NA	0	0	1
0.6	NA	NA	48	NA	NA	0	0	1
0.4	9.5	32	NA	NA	NA	0	0	1
0.5	NA	11	NA	NA	NA	0	0	1
0.5	NA	12	NA	NA	NA	0	0	1
0.6	NA	15	NA	NA	NA	0	0	1
NA	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	12	NA	102	191	0	0	0
1.8	8.9	32	NA	97	NA	0	0	1
NA	NA	5.8	NA	NA	NA	0	0	0
NA	NA	6.6	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
2	NA	7	NA	99	123	0	0	0
10.3	10.1	NA	NA	103	NA	0	0	1
4.9	NA	NA	NA	105	NA	0	0	1
0.4	9.5	NA	NA	104	NA	0	0	0
16.7	NA	NA	NA	103	NA	1	0	1
2.8	9.3	NA	NA	97	NA	1	0	1
1.9	NA	NA	NA	NA	NA	0	1	1
NA	NA	3.1	NA	NA	NA	0	0	0
0.5	NA	2.9	NA	NA	NA	0	0	0
0.4	NA	2.9	23	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
0.5	NA	2.7	14	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	2.6	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	9.9	1.9	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.2	NA	1.8	NA	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
1.5	NA	NA	NA	93	NA	0	1	1
0.7	NA	NA	NA	NA	NA	0	0	0
1.1	NA	NA	NA	NA	NA	0	0	0
1.1	9.7	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
1.1	NA	NA	NA	NA	229	0	0	0
NA	NA	NA	10	NA	NA	0	0	0
NA	NA	NA	19	NA	NA	0	0	0
NA	NA	NA	19	NA	NA	0	0	0
0.5	NA	NA	31	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.7	NA	1.4	NA	NA	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
0.4	9	NA	NA	107	NA	0	0	0
NA	NA	NA	NA	107	NA	0	0	0
0.6	NA	1	NA	NA	NA	0	0	0
0.6	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
1.1	9.1	4.9	NA	99	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	102	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	1
NA	NA	1.7	NA	109	NA	0	0	1
0.4	9	2.1	NA	NA	NA	0	0	1
0.2	NA	NA	12	NA	NA	0	0	0
0.6	9.8	4.4	NA	106	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
NA	9.7	4.3	NA	NA	NA	0	0	0
0.3	9.3	4.5	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
0.8	10.2	1.5	NA	108	NA	0	0	0
0.4	9.6	1.5	NA	109	NA	0	0	0
0.4	NA	2	NA	105	NA	0	0	1
NA	NA	1.7	NA	NA	NA	0	0	1
0.3	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
0.3	NA	3.4	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	7.9	5.6	NA	NA	NA	0	0	1
NA	NA	4.6	NA	NA	NA	0	0	1
0.3	NA	4.7	NA	NA	NA	0	0	1
0.3	NA	3.3	NA	NA	NA	0	0	1
0.2	8.2	7.4	NA	NA	NA	0	0	1
0.5	8.4	3.4	NA	NA	NA	0	0	1
NA	NA	4.7	NA	NA	NA	0	0	1
NA	NA	6.4	NA	NA	NA	0	0	1
0.2	9.2	2.2	NA	NA	NA	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	211	0	0	0
NA	10.5	NA	NA	105	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1	9.2	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	7.8	NA	104	NA	0	0	1
0.4	NA	5.1	NA	NA	NA	0	0	0
NA	10.3	NA	NA	NA	NA	0	0	1
NA	10	NA	NA	NA	NA	0	0	0
0.4	9.7	9	NA	98	NA	0	0	1
NA	NA	2.2	NA	NA	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
0.5	NA	4.2	NA	NA	NA	0	0	0
0.5	NA	5.2	10	99	244	0	0	0
0.5	NA	6.5	NA	NA	NA	0	0	0
0.5	NA	32	NA	NA	NA	0	0	1
NA	NA	16	NA	NA	NA	0	0	1
NA	NA	17	NA	NA	NA	0	0	1
NA	NA	18	NA	NA	NA	0	0	0
0.7	NA	NA	NA	97	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	10.6	9	NA	99	NA	0	0	0
0.4	NA	2.3	11	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	2.9	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
NA	8.9	NA	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	1
0.3	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	NA	NA	105	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.3	260	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.3	10.1	1.8	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9.4	3.9	NA	NA	NA	0	0	0
0.4	9.3	5.2	NA	107	NA	0	0	0
0.3	NA	4.4	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.7	NA	1.8	NA	NA	NA	0	0	0
0.6	8.3	32	NA	103	175	0	0	1
0.4	8.6	1.7	NA	108	NA	0	0	1
0.3	NA	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.8	NA	1.6	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.5	10.6	2.1	NA	98	NA	0	0	0
NA	9.1	5.6	12	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
0.4	7.7	1	244	102	NA	0	0	0
0.3	10.3	4.9	NA	NA	NA	0	0	0
0.2	10.5	4.4	NA	NA	NA	0	0	0
0.3	9.5	3.7	NA	NA	NA	0	0	0
NA	NA	4.1	NA	NA	NA	0	0	0
NA	NA	4.4	NA	NA	NA	0	0	0
NA	NA	5.2	NA	NA	NA	0	0	0
0.2	9	3.4	NA	105	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.7	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	100	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	8.7	1.3	NA	109	NA	0	0	1
NA	8.9	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	93	NA	0	0	1
0.2	NA	NA	NA	97	NA	0	0	1
0.3	NA	NA	NA	93	NA	0	0	1
0.3	NA	NA	NA	94	NA	0	0	1
0.5	NA	2.8	NA	95	NA	0	0	1
0.3	NA	NA	NA	96	NA	0	0	1
0.3	NA	NA	NA	93	NA	0	0	1
0.4	NA	NA	NA	93	NA	0	0	1
0.3	NA	NA	NA	93	NA	0	0	1
0.3	NA	9.4	NA	93	NA	0	0	1
0.7	NA	3.1	22	NA	NA	0	0	0
0.7	NA	2.9	NA	NA	NA	0	0	0
0.8	NA	2.6	NA	NA	NA	0	0	0
0.9	NA	3.2	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.7	NA	3	NA	NA	NA	0	0	0
0.6	NA	3.3	NA	NA	NA	0	0	0
1.4	8.8	4.5	NA	97	95	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.4	9	1.1	NA	NA	161	0	0	0
0.8	9	NA	NA	107	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	4.6	NA	NA	NA	0	0	0
0.4	9.6	13	NA	NA	NA	0	0	0
NA	NA	4.3	NA	NA	NA	0	0	0
1	NA	NA	NA	100	NA	0	0	1
1	NA	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	105	NA	0	0	1
NA	8.5	NA	NA	103	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	8.5	392	NA	100	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	0
0.2	NA	2	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
1.5	8.9	3.8	NA	107	NA	0	0	0
0.2	9.5	NA	NA	101	NA	0	0	1
0.3	NA	5.4	NA	NA	NA	0	0	0
0.2	NA	5.4	NA	NA	NA	0	0	0
0.2	8.9	NA	11	105	NA	0	0	0
0.3	NA	1.2	NA	NA	196	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
1.5	9.4	NA	NA	101	NA	0	0	0
0.8	10.4	NA	NA	103	NA	0	1	0
0.4	NA	2.9	NA	NA	NA	0	0	0
NA	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	7.4	NA	NA	NA	0	0	0
0.3	NA	8.3	NA	NA	NA	0	0	0
0.3	NA	7	NA	NA	NA	0	0	0
0.3	NA	7.6	NA	NA	NA	0	0	0
0.2	NA	8.8	NA	NA	NA	0	0	0
0.2	NA	7.6	NA	NA	NA	0	0	0
0.3	NA	6.2	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	NA	19	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
3.6	NA	NA	NA	NA	NA	0	0	0
3.9	NA	NA	NA	NA	NA	1	0	0
1.3	NA	1	NA	NA	NA	0	0	0
1.4	NA	1.1	NA	NA	NA	0	0	0
1.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.2	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.2	8.7	1.9	NA	105	NA	0	0	1
0.2	NA	2.4	NA	NA	NA	0	0	1
0.4	8.6	2.3	NA	NA	NA	0	0	1
0.3	8.5	2.2	NA	NA	NA	0	0	1
0.3	NA	3	NA	NA	NA	0	0	1
0.2	NA	1.7	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	1
0.3	NA	1.9	NA	NA	NA	0	0	1
0.4	NA	1.4	NA	NA	NA	0	0	1
0.2	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	19	NA	NA	NA	0	0	0
0.5	NA	22	NA	NA	NA	0	0	0
0.6	NA	23	NA	NA	NA	0	0	0
0.4	NA	19	NA	NA	NA	0	0	0
0.4	NA	13	NA	NA	NA	0	0	0
NA	9.4	14	NA	NA	NA	0	0	0
0.5	8.8	13	NA	NA	NA	0	0	0
NA	9.4	13	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
12.8	9.5	6.8	NA	103	NA	0	0	1
0.4	9	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.3	NA	NA	94	NA	0	0	1
0.3	7.9	NA	NA	98	NA	0	0	1
0.3	8.3	NA	NA	98	NA	0	0	1
1	7.8	NA	NA	98	NA	0	0	1
NA	NA	1.5	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.9	NA	2.3	NA	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
0.5	9	NA	NA	104	NA	0	0	0
0.6	NA	2.1	NA	NA	182	0	0	0
0.4	NA	2	13	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.3	10.4	3.5	NA	NA	NA	0	0	1
0.4	9.7	3.3	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.3	9.2	2.6	NA	NA	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.6	NA	2.8	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.3	8.5	2.6	NA	NA	NA	0	0	0
0.5	NA	NA	9.8	NA	NA	0	0	0
0.3	NA	NA	11	NA	NA	0	0	0
0.4	NA	NA	11	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.8	2.9	NA	NA	0	0	0
0.7	10.1	1.5	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.8	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	1
0.4	9.1	71	628	96	NA	0	0	1
0.4	NA	3.9	NA	NA	NA	0	0	0
0.3	NA	4.9	NA	NA	NA	0	0	0
0.4	NA	4.3	NA	NA	NA	0	0	0
0.4	NA	5	NA	NA	NA	0	0	0
0.4	NA	4.4	NA	NA	NA	0	0	0
0.3	NA	4.5	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.7	NA	3.2	14	NA	279	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
0.4	9.6	3.1	NA	NA	NA	0	0	0
0.4	NA	4.1	NA	NA	NA	0	0	0
0.3	NA	3.5	NA	NA	NA	0	0	0
0.3	8.9	3.8	NA	NA	NA	0	0	0
NA	9	180	NA	95	NA	0	0	1
0.4	9.4	NA	NA	101	NA	0	0	0
0.7	NA	3.4	NA	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
3.3	NA	2.5	NA	99	NA	0	0	0
0.9	10.1	1.9	NA	NA	239	0	0	0
0.7	9.4	1.6	NA	NA	228	0	0	0
0.8	NA	1.9	13	NA	225	0	0	0
NA	10.1	1.6	14	104	207	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	3199	NA	NA	0	0	0
0.4	NA	NA	NA	109	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
0.3	9.4	1.1	NA	NA	NA	0	0	0
0.3	9.1	1.7	NA	NA	NA	0	0	0
1	11	2	NA	104	NA	0	0	0
0.6	10.9	2.2	NA	103	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
6	8.9	8.3	NA	102	NA	0	0	1
NA	NA	1.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	9.4	2608	76	91	NA	0	0	1
1	NA	2	NA	NA	NA	0	0	0
0.8	NA	2.6	NA	NA	NA	0	0	0
1.2	10.1	2.9	NA	NA	NA	0	0	0
0.7	9.3	NA	NA	NA	NA	0	0	0
0.6	NA	3.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.6	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	2.2	3.6	101	NA	0	0	0
0.4	NA	1.7	NA	102	NA	0	0	1
0.6	NA	1.9	NA	NA	NA	0	0	1
NA	NA	10	NA	108	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.9	NA	NA	NA	0	1	0
0.4	NA	4.6	NA	NA	NA	0	1	1
0.3	8.6	3.7	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.4	9.1	4.7	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	9.1	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	0
0.5	NA	7.6	NA	NA	NA	0	0	0
NA	9.5	1.1	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.7	NA	68	NA	NA	NA	0	0	1
1.2	NA	79	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	192	0	0	0
0.2	9.5	1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	204	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
1.1	NA	2.4	NA	94	NA	0	0	0
NA	9.3	NA	3.6	NA	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
NA	9.6	4.2	NA	107	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.7	NA	1.4	NA	NA	NA	0	0	0
0.8	NA	1.1	9.3	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	1
NA	NA	1.9	NA	NA	NA	0	0	1
0.3	NA	1.8	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	3.3	NA	NA	NA	0	0	0
NA	10	2.2	NA	NA	NA	0	0	1
NA	10.2	2.8	NA	NA	NA	0	0	1
NA	NA	2	NA	NA	NA	0	0	1
0.2	NA	2.4	NA	NA	NA	0	0	1
0.4	10.5	2	NA	NA	NA	0	0	1
0.2	10.4	2.1	NA	106	NA	0	0	1
0.4	NA	1.9	NA	NA	NA	0	0	1
0.3	10.7	2.5	NA	104	NA	0	0	1
0.4	NA	2.3	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	1.9	NA	NA	NA	0	0	1
NA	10.6	2.2	NA	NA	NA	0	0	1
NA	NA	2	NA	NA	NA	0	0	1
0.3	10.2	1.6	NA	106	NA	0	0	1
0.5	NA	1.5	NA	NA	NA	0	0	1
0.3	10.6	2.1	NA	NA	NA	0	0	1
0.3	NA	1.8	NA	NA	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.3	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	1
0.5	11.6	2.1	NA	NA	247	0	0	1
0.3	10.8	1.5	NA	106	NA	0	0	1
0.5	10.4	1.7	NA	NA	220	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	9.6	2.5	NA	NA	221	0	0	0
0.6	9	34	NA	104	NA	0	0	1
0.7	9.5	NA	NA	103	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	103	NA	0	0	0
0.3	NA	1.5	18	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
5.5	7.6	1.9	NA	107	NA	0	0	0
0.4	9.5	1.9	NA	104	128	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
0.6	NA	2.2	NA	NA	152	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	1
0.2	NA	2.1	17	NA	NA	0	0	0
0.4	9.2	3.2	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.7	NA	NA	NA	0	0	1
0.8	NA	1.9	NA	NA	NA	0	0	1
0.8	NA	2.2	NA	NA	NA	0	0	1
0.6	NA	2.3	NA	NA	NA	0	0	1
0.7	NA	2.4	NA	NA	NA	0	0	1
NA	NA	2.4	NA	NA	NA	0	0	1
0.7	NA	2	NA	NA	NA	0	0	1
0.8	NA	2.1	NA	NA	NA	0	0	1
0.9	NA	1.9	NA	NA	NA	0	0	1
0.7	NA	2.4	NA	NA	NA	0	0	1
0.7	NA	2.6	NA	NA	NA	0	0	1
0.8	NA	3.2	NA	NA	NA	0	0	1
NA	NA	3.5	NA	NA	NA	0	0	1
0.6	NA	3.4	NA	NA	NA	0	0	1
0.5	NA	3.5	NA	NA	NA	0	0	1
1	9.4	3.7	NA	NA	NA	0	0	1
1	NA	3.6	NA	NA	NA	0	0	1
0.8	9.6	3.6	NA	101	NA	0	0	1
NA	9.4	4.3	NA	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	4.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
1.2	NA	3.9	NA	NA	NA	0	0	1
1	NA	3.1	NA	NA	NA	0	0	1
NA	NA	2.6	NA	NA	NA	0	0	1
NA	NA	3.4	NA	NA	NA	0	0	1
1	NA	4.3	NA	NA	NA	0	0	1
0.8	NA	4	NA	NA	NA	0	0	1
0.8	NA	4.3	NA	NA	NA	0	0	1
NA	NA	5.1	NA	NA	NA	0	0	1
0.7	NA	5.7	NA	NA	NA	0	0	1
0.6	NA	5.9	NA	NA	NA	0	0	1
NA	NA	6.5	NA	NA	NA	0	0	1
1	NA	6.9	NA	NA	NA	0	0	1
0.9	NA	8.9	NA	NA	NA	0	0	1
1	NA	7.8	NA	NA	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.6	NA	102	NA	0	0	0
1.3	9	2.8	NA	101	151	0	0	0
4.7	9.8	1.4	24	NA	NA	0	0	0
0.5	NA	5.9	NA	103	NA	0	0	1
NA	9.2	2.5	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.3	9.5	1.4	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	102	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	NA	8.9	NA	233	0	0	0
NA	NA	2	NA	103	222	0	0	0
0.4	NA	1.1	16	104	193	0	0	0
0.3	NA	1.5	NA	NA	169	0	0	0
0.4	9.6	NA	NA	96	NA	0	0	1
0.4	9.1	NA	NA	96	NA	0	0	1
0.6	9.4	NA	NA	100	NA	0	0	1
0.4	8.7	NA	NA	99	NA	0	0	1
NA	8.6	NA	NA	100	158	0	0	1
0.5	NA	1.1	NA	NA	NA	0	0	0
0.6	NA	2.5	6.6	NA	NA	0	0	0
NA	NA	2.2	NA	NA	228	0	0	0
0.3	NA	2.9	7.3	NA	188	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	238	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	9.5	4	NA	102	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	0	0	0
32.6	8.5	NA	NA	108	NA	0	0	0
1.4	8.7	NA	NA	103	NA	1	0	1
0.3	NA	4	NA	NA	NA	1	0	0
0.1	8.2	2.4	NA	110	129	0	0	0
0.6	NA	1.8	10	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.7	8.6	1.3	NA	102	NA	0	0	1
0.4	NA	2.7	NA	NA	NA	1	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	110	NA	0	0	0
NA	8.4	1.3	33	105	NA	0	0	0
0.3	9.6	1.9	NA	104	NA	0	0	0
0.3	9	1.9	NA	103	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.3	8.4	NA	NA	0	0	0
0.1	NA	1.9	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.8	NA	1.5	NA	NA	NA	0	0	0
0.6	9.9	1.6	NA	NA	NA	0	0	0
NA	NA	1.5	NA	102	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.2	NA	1.5	9.6	NA	NA	0	0	0
0.2	NA	NA	12	NA	NA	0	0	0
0.2	NA	1.5	9.8	NA	NA	0	0	0
0.5	9.5	2.2	NA	105	107	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	4.5	NA	NA	NA	0	0	0
0.4	NA	4	NA	NA	NA	0	0	0
0.4	NA	4.1	NA	NA	NA	0	0	0
0.4	NA	4.4	NA	NA	NA	0	0	0
0.4	NA	4.4	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.2	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	9.6	NA	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	201	0	0	0
8.4	8	213	NA	105	NA	0	0	1
0.5	8.5	2	103	105	NA	0	0	0
NA	NA	4.7	NA	NA	NA	0	0	1
NA	NA	4.1	NA	NA	NA	0	0	1
NA	NA	5.1	NA	NA	NA	0	0	1
NA	NA	11	NA	NA	NA	0	0	1
0.3	10.3	NA	NA	104	NA	0	0	1
0.3	9.7	14	NA	103	NA	0	0	1
0.2	9.4	20	NA	105	NA	0	0	1
0.4	9.6	20	NA	104	NA	0	0	1
0.2	9.9	23	NA	107	NA	0	0	1
0.2	NA	27	NA	104	NA	0	0	1
0.3	9.3	23	NA	108	NA	0	0	1
NA	NA	24	NA	NA	NA	0	0	1
0.3	NA	63	NA	97	NA	0	0	1
NA	NA	66	NA	NA	NA	0	0	1
0.2	NA	84	NA	NA	NA	0	0	1
NA	NA	95	NA	NA	NA	0	0	1
NA	NA	131	NA	NA	NA	0	0	1
0.3	9.8	206	NA	NA	NA	0	0	1
0.3	10.3	187	NA	NA	NA	0	0	1
0.4	NA	233	NA	NA	NA	0	0	1
NA	NA	242	NA	NA	NA	0	0	1
0.5	9.9	313	NA	105	NA	0	0	1
NA	NA	263	NA	NA	NA	0	0	1
NA	NA	278	NA	NA	NA	0	0	1
0.4	NA	256	NA	NA	NA	0	0	1
0.5	9.6	250	NA	NA	NA	0	0	1
0.4	NA	263	NA	NA	NA	0	0	1
NA	10	279	NA	NA	NA	0	0	1
NA	9.6	328	NA	NA	NA	0	0	1
NA	NA	185	NA	NA	NA	0	0	1
NA	10.1	106	NA	NA	NA	0	0	1
0.3	10.3	75	NA	NA	NA	0	0	1
0.3	NA	58	NA	NA	NA	0	0	1
NA	NA	49	NA	NA	NA	0	0	1
NA	10.2	52	NA	NA	NA	0	0	1
NA	10.1	52	NA	107	NA	0	0	1
NA	9.8	51	NA	NA	NA	0	0	1
NA	10.3	52	NA	NA	NA	0	0	1
NA	NA	46	NA	NA	NA	0	0	1
NA	NA	59	NA	NA	NA	0	0	1
0.3	9.7	69	NA	NA	NA	0	0	1
0.4	NA	99	NA	NA	NA	0	0	1
0.2	NA	87	NA	NA	NA	0	0	1
NA	NA	95	NA	NA	NA	0	0	1
NA	NA	86	NA	NA	NA	0	0	1
0.3	NA	60	NA	NA	NA	0	0	1
NA	NA	49	NA	NA	NA	0	0	1
0.5	NA	57	NA	NA	NA	0	0	1
NA	NA	60	NA	NA	NA	0	0	1
0.3	NA	64	NA	NA	NA	0	0	1
0.6	NA	1.1	NA	NA	NA	0	0	0
8.7	8.5	1.4	NA	104	NA	0	0	0
0.4	NA	3.2	NA	NA	NA	0	0	0
0.3	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
1.1	NA	1.6	NA	102	NA	0	0	0
NA	9.5	32	NA	105	NA	0	0	1
NA	NA	74	NA	98	NA	0	0	1
1.1	NA	3.8	NA	NA	NA	1	0	1
0.8	9.2	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.5	9.1	NA	NA	109	NA	0	0	0
1.7	NA	NA	NA	106	NA	0	0	0
NA	NA	NA	NA	104	NA	1	0	0
1.8	9.2	NA	NA	101	NA	1	0	0
1.7	9.3	4.2	NA	105	NA	1	0	0
1.2	9.4	NA	NA	106	NA	0	0	0
2.8	9.5	NA	NA	107	NA	0	0	1
1.4	NA	NA	NA	106	NA	1	0	1
NA	NA	NA	NA	NA	NA	1	0	1
1.2	9.1	NA	NA	106	NA	1	0	1
1.4	9.2	NA	NA	104	NA	0	0	1
1.8	9.3	NA	NA	106	NA	0	0	1
1.8	NA	NA	NA	101	NA	1	0	1
1.5	9.3	8.2	NA	107	NA	1	0	0
1.9	9.4	10	NA	103	NA	0	0	0
1.9	9.8	NA	NA	106	NA	0	0	0
1.9	NA	7.5	NA	112	NA	0	0	1
2.3	NA	NA	NA	NA	NA	1	0	1
1.7	9.2	NA	NA	106	NA	1	0	0
1.7	9.2	NA	NA	109	184	0	0	0
2.2	NA	NA	NA	109	NA	1	0	0
2.4	NA	NA	NA	108	NA	0	0	0
1.5	NA	NA	NA	111	NA	1	0	0
0.8	9.6	NA	NA	NA	NA	0	0	0
NA	9.8	2.4	NA	NA	NA	0	0	0
0.2	NA	2.8	NA	NA	NA	0	0	0
0.2	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	4	NA	NA	NA	0	0	0
0.2	NA	3.9	13	NA	NA	0	0	0
NA	NA	2.9	NA	NA	NA	0	0	0
0.6	10.4	2.2	NA	104	NA	0	0	1
0.5	NA	1.9	NA	NA	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
NA	NA	2.2	27	102	NA	0	0	0
0.4	8.7	1.9	NA	100	NA	0	0	0
2.3	NA	4.5	NA	99	NA	0	0	0
NA	8.1	NA	NA	106	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	13	NA	NA	NA	0	0	1
0.4	8.9	13	NA	NA	NA	0	0	1
0.6	9.4	18	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	8.8	71	NA	NA	NA	0	0	1
0.5	9.2	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	8.4	NA	NA	NA	NA	0	0	1
0.3	8.4	17	32	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	8.5	NA	NA	NA	NA	0	0	1
0.6	8.6	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	8.8	NA	NA	NA	NA	0	0	1
0.5	8.9	NA	NA	96	NA	0	0	1
0.2	NA	2	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	104	156	0	0	0
1	NA	1.7	NA	NA	178	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	250	NA	NA	NA	0	0	1
0.5	NA	578	NA	NA	NA	0	0	1
0.6	NA	1078	NA	NA	NA	0	0	1
0.5	NA	745	NA	NA	NA	0	0	1
0.6	NA	2	NA	NA	NA	0	0	0
0.3	NA	9.5	NA	NA	NA	0	0	0
NA	NA	12	NA	NA	NA	0	0	0
0.3	NA	3.5	NA	NA	NA	0	0	0
0.4	NA	4.1	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
NA	NA	3.3	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.6	8	NA	NA	105	NA	0	0	0
0.3	NA	3.5	NA	NA	NA	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	1
0.4	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	3.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.9	NA	1.4	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	3.6	NA	NA	NA	0	0	0
0.4	NA	1.7	24	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	NA	12	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	4.8	NA	NA	NA	0	0	0
0.2	9.1	3.8	NA	NA	NA	0	0	0
0.3	10.3	3	NA	NA	NA	0	0	0
NA	9.4	1.2	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.3	8.8	1.3	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
1.6	7.9	4.8	NA	110	NA	0	0	1
0.7	NA	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	103	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
NA	NA	1	NA	NA	NA	0	0	0
0.8	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.5	NA	3	NA	NA	NA	0	0	0
NA	NA	1.4	11	NA	NA	0	0	0
2.5	NA	15	NA	111	NA	0	0	0
0.3	NA	4.5	NA	NA	NA	0	0	0
1.6	10.5	8	5.7	102	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	5	NA	NA	NA	0	0	0
0.3	NA	5	NA	NA	NA	0	0	0
0.2	NA	6.1	NA	NA	NA	0	0	0
0.3	NA	5.4	10	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.9	NA	1.1	NA	NA	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
3.7	9.1	2.7	NA	100	NA	0	0	0
NA	9.4	NA	NA	NA	212	0	0	0
NA	7.9	61	64	107	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	32	401	99	NA	1	0	1
0.5	8.9	NA	NA	102	NA	0	1	1
0.3	9.4	NA	NA	105	NA	0	1	1
0.3	8.9	NA	121	104	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	8.8	NA	NA	101	NA	0	1	1
0.3	8.9	NA	NA	97	NA	0	0	0
0.2	9.1	NA	NA	97	NA	0	1	0
0.2	9.1	NA	NA	97	NA	0	1	0
NA	8.4	NA	NA	110	NA	0	1	0
0.1	9.5	NA	NA	100	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	9.3	NA	NA	101	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	8.9	NA	NA	104	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.2	9.3	NA	NA	102	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.2	9.6	NA	NA	101	NA	0	1	0
0.3	9.9	NA	NA	105	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.2	10	NA	NA	99	NA	0	1	0
0.3	9.4	NA	NA	100	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.5	9.4	NA	NA	98	NA	0	1	0
0.2	8.6	NA	33	103	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	103	NA	0	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
0.4	9.3	NA	NA	103	NA	0	0	0
0.3	NA	NA	NA	NA	NA	1	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.2	18	NA	NA	0	0	0
NA	10.4	NA	12	101	216	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	12	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	15	NA	195	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1	NA	NA	NA	0	0	0
0.2	NA	NA	31	NA	NA	0	0	1
0.4	NA	1.2	NA	NA	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	1
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	9.8	1.4	NA	NA	NA	0	0	0
0.3	10.3	1.9	20	NA	NA	0	0	0
0.3	NA	7.2	NA	NA	NA	0	0	1
NA	NA	10	NA	NA	NA	0	0	1
NA	NA	5.7	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	6.5	NA	NA	NA	0	0	1
0.2	9.2	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	9.1	NA	NA	NA	0	0	1
0.6	NA	16	NA	104	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.8	NA	104	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
1.5	8.6	1251	NA	91	NA	0	0	1
3	NA	1.8	229	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.7	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.8	NA	2	NA	NA	NA	0	0	0
0.6	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	2.2	NA	NA	NA	0	0	0
0.6	NA	2	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
NA	9.2	2.2	NA	100	NA	0	0	0
NA	NA	13	NA	100	NA	0	0	1
1.1	9.1	1203	71	102	NA	0	0	1
0.7	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
3.8	7.8	2.2	NA	112	NA	0	0	0
0.6	NA	2.9	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
NA	NA	16	NA	NA	NA	0	0	0
0.4	10.7	2.1	NA	NA	NA	0	0	0
0.6	NA	1.7	8.3	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
1.6	NA	17	NA	101	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
1	9.4	NA	NA	NA	NA	0	0	0
0.7	9.4	NA	NA	NA	NA	0	0	0
0.4	NA	9.4	NA	103	NA	0	0	0
NA	10	5.9	NA	NA	NA	0	0	1
4.3	9.4	2.5	NA	102	149	0	0	0
0.3	NA	NA	NA	101	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2	NA	105	NA	0	0	0
0.5	NA	2.7	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.7	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.7	NA	2.3	NA	104	NA	0	0	0
0.5	NA	3.6	NA	NA	NA	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.6	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.8	7.5	1.8	NA	97	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
1.1	NA	3.1	4.3	NA	195	0	0	0
1.1	9.4	3	10	NA	215	0	0	0
1.4	NA	3.1	9.2	NA	221	0	0	0
3.4	NA	NA	NA	NA	NA	1	0	0
1.6	NA	NA	NA	NA	NA	0	0	0
3.6	NA	NA	NA	NA	NA	1	0	0
4.5	NA	NA	NA	NA	NA	0	0	0
5.7	NA	NA	NA	NA	NA	1	0	0
5.7	NA	NA	NA	NA	NA	1	0	0
1.9	7.5	NA	NA	116	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
NA	NA	2.9	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	9.1	1	NA	NA	NA	0	0	0
0.4	9.1	1.2	NA	108	NA	0	0	0
0.3	8.6	1.3	NA	NA	NA	0	0	0
0.5	8.5	1.3	NA	NA	NA	0	0	0
0.3	8.9	1.4	NA	NA	NA	0	0	1
0.4	8.8	1.4	NA	NA	NA	0	0	1
0.2	9.3	1.3	NA	NA	NA	0	0	1
0.6	8.9	3.1	NA	105	NA	0	0	1
0.5	8.8	3	NA	NA	NA	0	0	1
0.5	8.6	2.4	NA	NA	NA	0	0	0
0.4	8.6	2.2	NA	NA	229	0	0	0
0.5	8.6	2.1	NA	NA	NA	0	0	0
0.4	8.2	2.4	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.2	8.2	1.9	NA	NA	NA	0	0	0
0.3	8.5	2	NA	NA	NA	0	0	0
0.4	8.9	2.4	NA	102	NA	0	0	0
0.3	8.7	2.4	NA	NA	NA	0	0	1
0.3	9.2	NA	NA	105	NA	0	0	1
4.3	9.4	7.3	NA	99	NA	0	0	1
NA	NA	6.4	NA	NA	NA	0	0	0
NA	NA	4.6	NA	NA	NA	0	0	0
NA	NA	9.7	NA	NA	NA	0	0	0
0.2	9.6	5.9	NA	NA	NA	0	0	0
0.1	NA	6	NA	NA	NA	0	0	0
0.3	8.7	2.9	NA	102	NA	0	0	0
0.3	9	NA	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
0.2	9.4	NA	NA	103	NA	0	0	0
0.2	9.4	NA	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	10	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	9.8	NA	NA	103	NA	0	0	1
0.2	9.4	NA	NA	107	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	9.8	NA	NA	104	NA	0	0	1
0.3	10.1	NA	NA	103	NA	0	0	1
0.4	10.3	NA	NA	96	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.2	8.4	2.9	NA	97	NA	0	0	0
0.2	NA	4.7	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.8	NA	108	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
NA	9.8	1.1	NA	107	NA	0	0	0
0.7	10.3	1.1	NA	NA	NA	0	0	0
0.5	NA	3.9	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	2.9	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.3	9.6	NA	NA	NA	195	0	0	0
0.3	9.2	2.8	NA	NA	NA	0	0	0
0.3	10	2.6	NA	NA	NA	0	0	0
0.3	10	2.3	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	212	0	0	0
2.6	8.3	NA	NA	106	NA	0	0	1
2.6	8.2	NA	NA	100	NA	0	0	1
7	8	NA	NA	103	NA	0	0	1
0.3	NA	3.9	NA	NA	NA	0	0	0
0.2	NA	3.6	NA	NA	NA	0	0	0
0.3	NA	3.8	NA	NA	NA	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
13.2	9.5	4.1	NA	106	138	0	0	0
0.7	NA	NA	NA	103	NA	1	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	1	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.2	NA	2.6	NA	NA	NA	0	0	0
0.2	NA	2.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	1
0.5	9.7	1.6	NA	NA	NA	0	0	1
0.6	10.2	1.1	NA	NA	212	0	0	1
0.4	10	1.2	NA	NA	NA	0	0	1
0.5	9.9	NA	NA	NA	NA	0	0	1
0.4	9.9	NA	NA	NA	NA	0	0	1
0.4	9.7	NA	NA	NA	NA	0	0	1
0.4	9.7	NA	NA	NA	NA	0	0	1
0.6	9.7	1	NA	100	NA	0	0	1
0.6	9.9	NA	NA	NA	NA	0	0	1
0.6	9.5	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	9.2	1.2	NA	NA	NA	0	0	1
0.7	9.5	NA	NA	NA	NA	0	0	1
0.7	9.5	1.2	NA	NA	NA	0	0	1
0.4	9.3	1.5	NA	NA	NA	0	0	1
0.4	9.2	2.1	NA	NA	NA	0	0	1
0.4	8.9	2.9	NA	NA	NA	0	0	1
0.2	9.2	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	100	NA	0	0	1
0.6	NA	7.7	287	97	NA	0	0	1
0.5	NA	15	285	98	NA	0	0	1
0.8	8.6	NA	NA	99	NA	0	0	1
0.7	8.2	11	295	100	NA	0	0	1
0.3	8.1	NA	NA	108	NA	0	0	1
0.3	9.5	NA	NA	100	NA	0	0	1
0.4	NA	NA	NA	97	NA	0	0	1
0.3	10.6	NA	NA	92	NA	0	0	1
0.6	9.9	NA	NA	95	NA	0	0	1
1	9.9	NA	NA	96	NA	0	0	1
0.3	NA	1.6	NA	NA	NA	0	0	0
0.3	9.1	1.4	NA	NA	NA	0	0	0
0.2	8.8	1.7	NA	NA	NA	0	0	0
0.3	9.3	1.6	NA	NA	NA	0	0	0
NA	9.4	1.6	NA	NA	NA	0	0	0
0.3	9.2	1.8	NA	NA	NA	0	0	0
0.3	9.5	1.8	NA	NA	NA	0	0	0
0.3	8.9	1.6	NA	NA	NA	0	0	0
0.2	8.9	1.7	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	9	1.9	NA	103	191	0	0	1
0.6	9.2	2.2	NA	105	NA	0	0	1
0.3	NA	5.4	NA	104	NA	0	0	1
NA	NA	2.7	NA	108	NA	0	0	1
NA	NA	3	NA	105	NA	0	0	1
NA	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	2.8	NA	105	197	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.6	NA	2.9	NA	NA	NA	0	0	0
0.5	NA	2.7	NA	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
0.3	9.8	1.3	NA	NA	NA	0	0	0
0.3	9.6	1.2	NA	101	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
NA	NA	4.2	NA	NA	NA	0	0	0
NA	NA	3.2	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	3.5	NA	NA	NA	0	0	1
0.4	NA	2.7	NA	NA	NA	0	0	0
0.2	NA	3.5	NA	NA	NA	0	0	1
0.3	NA	6.6	NA	NA	NA	0	0	1
0.4	NA	6.8	NA	NA	NA	0	0	1
NA	NA	NA	7.7	NA	NA	0	0	0
0.6	9	NA	NA	101	NA	0	1	1
0.5	8.5	NA	NA	96	NA	0	1	1
0.3	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	4.5	NA	NA	NA	0	0	0
0.3	NA	6	NA	NA	NA	0	0	0
0.4	NA	6	NA	NA	NA	0	0	0
0.4	NA	9.6	NA	NA	NA	0	0	0
NA	NA	21	NA	NA	NA	0	0	0
0.5	NA	32	NA	NA	NA	0	0	1
0.7	9.5	38	NA	NA	NA	0	0	1
NA	NA	33	NA	NA	NA	0	0	1
NA	NA	25	NA	NA	NA	0	0	0
0.4	9.4	28	NA	NA	NA	0	0	1
0.4	9.7	34	NA	NA	NA	0	0	1
NA	NA	36	NA	NA	NA	0	0	1
NA	NA	40	NA	NA	NA	0	0	1
0.4	9.7	39	NA	NA	NA	0	0	1
0.4	NA	38	NA	NA	NA	0	0	1
0.4	NA	45	NA	NA	NA	0	0	1
0.4	9.4	45	NA	NA	NA	0	0	1
0.4	9.6	37	NA	NA	NA	0	0	1
0.5	NA	40	NA	NA	NA	0	0	1
0.6	9.4	39	32	NA	NA	0	0	1
0.5	NA	43	NA	NA	NA	0	0	1
NA	NA	3.4	NA	102	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
1.1	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	102	NA	0	0	1
1.5	NA	NA	NA	NA	NA	0	0	1
0.3	8.1	NA	NA	96	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.3	NA	NA	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
0.2	8.7	NA	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
1.1	8.7	NA	11	107	NA	0	0	0
NA	NA	2.5	17	94	NA	0	0	0
1.6	NA	NA	NA	107	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
0.2	9.3	2.5	12	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
6.3	9.6	8.2	NA	101	NA	0	0	1
NA	NA	3.5	NA	NA	NA	0	0	1
2.6	9.5	18	NA	104	202	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	NA	NA	107	NA	0	0	0
0.5	9.9	NA	NA	104	NA	0	0	1
0.3	7.1	5.4	NA	107	NA	0	0	0
NA	7.8	1	NA	107	NA	0	0	0
0.7	8.3	NA	87	106	NA	0	0	1
0.7	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.2	9.8	3.5	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	8.4	NA	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
10.7	8.9	1.9	NA	101	NA	1	0	0
4.6	9.2	NA	NA	102	NA	0	0	0
1.3	NA	2.2	NA	NA	NA	0	0	1
1.8	NA	NA	NA	100	NA	0	1	1
6.9	9.3	NA	NA	98	NA	0	1	1
18.6	9	NA	NA	92	NA	1	0	1
0.6	9.1	NA	NA	103	NA	1	0	1
0.6	NA	NA	NA	102	NA	1	0	1
0.5	NA	NA	NA	NA	NA	1	0	1
0.2	NA	8.5	NA	NA	NA	0	0	1
NA	9	3.3	NA	NA	NA	0	0	0
NA	10.2	3.2	NA	NA	NA	0	0	0
2.9	7.6	11	NA	103	NA	0	0	1
0.3	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
0.2	NA	3.9	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.2	NA	3.1	NA	NA	NA	0	0	0
0.2	NA	2.6	NA	NA	NA	0	0	0
NA	9.6	21	NA	101	NA	0	0	0
NA	8.8	3.6	68	104	NA	0	0	0
1.1	9.1	6	NA	90	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
NA	NA	9.3	NA	NA	NA	0	0	0
NA	NA	9.7	NA	NA	NA	0	0	0
0.3	8.7	NA	NA	99	NA	0	0	0
0.5	NA	1.9	NA	NA	258	0	0	0
0.5	NA	3.2	8.9	NA	NA	0	0	0
NA	10.1	1.5	NA	104	215	0	0	0
NA	9.4	1.4	NA	106	177	0	0	0
NA	NA	1.4	NA	NA	197	0	0	0
NA	NA	1.3	NA	NA	225	0	0	0
1.2	9.4	NA	NA	100	169	1	0	0
2.2	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	99	229	1	0	0
2.1	8.9	NA	NA	98	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	1
0.5	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1	NA	NA	NA	0	0	1
0.5	NA	1.3	NA	105	203	0	0	0
0.5	NA	1.3	NA	NA	193	0	0	0
0.3	NA	3.8	NA	NA	NA	0	0	0
0.6	NA	2.3	NA	95	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.7	NA	2.6	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	11	NA	NA	NA	0	0	1
0.7	NA	79	34	NA	NA	0	0	1
NA	NA	113	NA	NA	NA	0	0	1
NA	NA	11	NA	NA	NA	0	0	1
NA	NA	6.8	NA	NA	NA	0	0	0
0.5	NA	6.6	NA	NA	NA	0	0	1
0.7	NA	8.8	NA	NA	NA	0	0	1
NA	NA	9.5	NA	NA	NA	0	0	1
0.5	NA	12	NA	NA	NA	0	0	1
NA	NA	15	NA	NA	NA	0	0	1
0.4	NA	18	NA	NA	NA	0	0	1
0.5	NA	24	NA	NA	NA	0	0	1
NA	NA	21	NA	NA	NA	0	0	1
0.8	NA	33	53	NA	NA	0	0	1
0.8	NA	8.6	NA	NA	NA	0	0	1
0.7	NA	7.9	NA	NA	NA	0	0	1
0.9	NA	7.8	NA	103	NA	0	0	1
0.2	NA	12	NA	NA	NA	0	0	1
0.8	NA	11	NA	NA	NA	0	0	1
0.5	NA	11	NA	NA	NA	0	0	1
0.8	NA	12	NA	NA	NA	0	0	1
0.9	NA	13	NA	105	NA	0	0	1
1.2	NA	15	NA	NA	NA	0	0	1
1.1	NA	14	NA	NA	NA	0	0	1
0.8	NA	20	NA	NA	NA	0	0	1
0.3	9.6	22	NA	NA	NA	0	0	1
0.7	9.4	19	NA	99	NA	0	0	1
NA	NA	NA	26	NA	NA	0	0	1
NA	NA	22	26	104	NA	0	0	1
1	8.9	22	NA	NA	NA	0	0	1
0.6	8.9	17	NA	107	NA	0	0	1
0.4	NA	21	NA	NA	NA	0	0	1
NA	NA	19	NA	100	200	0	0	1
0.4	NA	11	NA	NA	NA	0	0	1
0.3	NA	7.4	NA	97	NA	0	0	1
0.2	NA	8.2	NA	NA	NA	0	0	1
NA	NA	9.7	NA	NA	NA	0	0	1
NA	NA	9.7	NA	NA	NA	0	0	1
0.5	NA	13	NA	NA	NA	0	0	1
0.3	NA	15	NA	NA	NA	0	0	1
NA	NA	21	NA	NA	NA	0	0	1
0.7	NA	29	NA	NA	NA	0	0	1
0.7	NA	34	NA	NA	NA	0	0	1
0.5	8.7	25	NA	104	NA	0	0	1
NA	NA	32	NA	NA	NA	0	0	1
0.4	NA	47	NA	NA	NA	0	0	1
NA	NA	60	NA	NA	NA	0	0	1
0.8	8.7	21	NA	105	160	0	0	1
0.4	8.6	10	NA	104	169	0	0	1
0.4	8.9	NA	NA	102	164	0	0	1
0.4	8.6	13	NA	103	141	0	0	1
0.6	9	13	NA	102	177	0	0	1
0.3	8.8	16	NA	103	170	0	0	1
0.5	NA	21	NA	99	206	0	0	1
0.6	9.4	3.2	NA	102	NA	1	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	2	47	NA	NA	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.2	NA	2.7	41	NA	NA	0	0	0
0.3	NA	2.5	46	NA	NA	0	0	0
0.3	NA	2.7	41	NA	NA	0	0	0
0.4	NA	3.4	NA	105	200	0	0	0
NA	9	NA	909	107	181	0	0	0
0.7	9.7	NA	NA	101	NA	0	0	0
0.2	9.6	1.8	NA	106	NA	0	0	1
0.3	10.1	1.9	NA	106	NA	0	0	1
0.3	9.4	2.3	NA	NA	NA	0	0	1
NA	9.6	3.1	NA	NA	NA	0	0	1
0.2	9.3	3.2	NA	NA	NA	0	0	1
0.4	NA	2.8	NA	NA	NA	0	0	1
0.3	10	2.9	NA	NA	NA	0	0	1
0.4	9.4	3.4	NA	108	NA	0	0	1
0.3	9.8	3.3	NA	NA	NA	0	0	1
0.3	10.2	2.9	NA	NA	NA	0	0	1
0.3	10.2	3.3	NA	NA	NA	0	0	1
0.2	9.3	3	NA	NA	NA	0	0	1
0.3	NA	3.5	NA	NA	NA	0	0	1
0.1	NA	5	NA	NA	NA	0	0	1
0.4	9.9	4.6	NA	NA	NA	0	0	1
0.4	NA	4.1	NA	NA	NA	0	0	1
0.3	NA	4.2	NA	NA	NA	0	0	1
0.4	9.3	4.8	NA	NA	NA	0	0	1
0.2	10.1	5.1	NA	NA	NA	0	0	1
0.2	9.4	5.3	NA	107	NA	0	0	1
0.4	9.7	5.9	NA	NA	NA	0	0	1
0.3	NA	6.6	NA	NA	NA	0	0	1
0.3	10.4	6.5	NA	NA	NA	0	0	1
NA	NA	6.7	NA	NA	NA	0	0	1
0.2	10.1	7.4	NA	NA	NA	0	0	1
0.2	10.3	10	NA	NA	NA	0	0	1
0.2	10.3	9.3	NA	NA	NA	0	0	1
NA	NA	11	NA	NA	NA	0	0	1
0.3	NA	11	NA	110	NA	0	0	1
NA	NA	11	NA	NA	NA	0	0	1
0.5	NA	13	NA	NA	NA	0	0	1
0.4	9.5	12	NA	NA	NA	0	0	1
0.4	9.4	13	NA	NA	NA	0	0	1
0.3	NA	14	NA	NA	NA	0	0	1
0.2	NA	18	NA	NA	NA	0	0	1
0.2	8.7	22	NA	NA	NA	0	0	1
0.2	NA	14	NA	NA	NA	0	0	1
0.2	8.8	16	NA	NA	NA	0	0	1
0.2	10.2	18	NA	NA	NA	0	0	1
0.2	NA	18	NA	NA	NA	0	0	1
0.3	NA	18	NA	NA	NA	0	0	1
NA	NA	18	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	10.5	2.7	NA	NA	NA	0	0	0
0.5	9.8	2.1	NA	NA	NA	0	0	0
0.4	8.8	NA	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	304	0	0	0
0.4	9.4	1.9	NA	NA	NA	0	0	0
0.3	9.2	2.5	NA	NA	NA	0	0	0
0.5	8.8	2.3	NA	NA	NA	0	0	0
0.4	9.4	2.1	NA	NA	NA	0	0	0
1.4	9.1	1.9	NA	103	NA	0	0	0
0.5	9.8	NA	NA	107	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	9.7	NA	NA	107	NA	0	1	0
0.8	9.8	NA	NA	108	NA	0	1	0
0.9	9.6	NA	NA	108	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	107	NA	0	0	0
0.8	9.9	NA	NA	106	NA	0	0	0
0.7	NA	25	NA	NA	NA	0	0	0
1	10.1	33	NA	106	NA	0	0	0
0.7	9.7	60	NA	101	NA	0	0	0
NA	NA	117	NA	NA	NA	0	0	0
NA	NA	156	NA	NA	NA	0	1	1
0.9	9.7	172	NA	102	NA	0	0	0
1.1	9.4	105	NA	102	NA	0	0	0
0.8	9.2	44	NA	104	NA	0	0	0
0.7	9.2	23	NA	107	NA	0	1	0
1.3	NA	9.2	NA	NA	NA	0	0	0
1.4	9.4	7.5	NA	106	NA	0	0	0
NA	NA	8.3	NA	NA	NA	0	0	0
1.3	NA	8.6	NA	102	NA	0	1	0
1.8	NA	12	NA	102	NA	0	0	0
1.5	NA	26	NA	107	NA	0	0	0
1	NA	53	NA	105	NA	0	0	0
NA	NA	437	NA	NA	NA	0	1	1
NA	NA	1.3	NA	NA	NA	0	0	0
NA	9.8	3.9	NA	NA	NA	0	0	0
0.3	NA	NA	NA	103	NA	1	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.2	9.5	1.4	NA	105	NA	0	0	0
0.6	NA	2.4	NA	107	NA	0	0	0
0.4	NA	3.5	NA	NA	NA	0	0	0
0.3	NA	5.1	NA	104	NA	0	0	0
0.7	NA	3.8	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.5	10.5	1.2	NA	99	NA	0	0	1
0.3	10	NA	NA	NA	NA	0	0	1
NA	9.9	1.2	NA	NA	NA	0	0	1
0.5	10.5	NA	NA	NA	NA	0	0	1
0.8	9.8	NA	NA	NA	NA	0	0	1
0.5	10.3	1.1	NA	NA	NA	0	0	1
0.6	9.2	1.1	NA	NA	NA	0	0	0
0.5	9.9	1.1	NA	NA	NA	0	0	0
0.7	9.8	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	9.3	NA	NA	NA	NA	0	0	0
0.6	10.2	NA	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.5	10	NA	NA	NA	NA	0	0	0
0.5	9.3	NA	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	104	191	0	0	0
0.3	8.9	1.3	NA	95	NA	0	0	0
1.3	NA	NA	NA	NA	NA	0	0	0
7.1	8.2	2.1	NA	107	167	0	0	0
4	NA	7.4	NA	103	NA	0	0	1
0.7	NA	NA	NA	100	NA	0	0	0
1.3	10.8	NA	NA	94	NA	0	0	0
1.2	9.8	NA	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	5.2	NA	102	NA	0	0	1
0.5	NA	5	NA	NA	NA	0	0	1
0.5	NA	3.6	NA	NA	NA	0	0	1
0.3	NA	4.8	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
1.1	NA	NA	NA	101	NA	1	0	0
0.4	NA	1.3	14	NA	NA	0	0	0
NA	NA	1.2	NA	NA	193	0	0	0
0.2	9.1	1.6	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.6	NA	3	NA	NA	NA	1	0	0
NA	NA	NA	NA	103	NA	0	0	0
0.4	NA	7.4	NA	105	NA	0	0	0
NA	9.2	10	NA	NA	NA	0	0	0
NA	NA	20	NA	NA	NA	0	0	1
0.3	9.3	64	NA	NA	NA	0	0	1
0.4	8.9	145	NA	NA	NA	0	0	1
NA	NA	30	NA	NA	NA	0	0	1
NA	NA	11	NA	NA	NA	0	0	1
0.4	9.3	14	NA	NA	NA	0	0	1
0.6	NA	17	NA	NA	NA	0	0	1
0.4	NA	32	NA	NA	NA	0	0	1
NA	NA	62	NA	NA	NA	0	0	1
0.5	8.8	68	NA	101	157	0	0	1
0.5	10	57	NA	97	140	0	0	1
0.4	9.3	61	NA	99	151	0	0	1
0.6	9.4	79	NA	104	158	0	0	1
0.5	8.9	48	NA	102	171	0	0	1
NA	NA	23	NA	NA	NA	0	0	1
0.3	NA	8.8	NA	NA	NA	0	0	0
NA	NA	12	NA	NA	NA	0	0	1
NA	NA	19	NA	NA	NA	0	0	1
0.3	NA	4	NA	NA	NA	0	0	0
NA	NA	NA	NA	102	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	9.8	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	9.7	1.2	NA	105	NA	0	0	1
0.5	9.2	1.2	NA	102	NA	0	0	1
0.3	NA	2	NA	NA	NA	0	0	0
0.2	9.3	1.3	NA	NA	203	0	0	0
2.3	9.5	NA	NA	103	NA	0	0	0
0.4	9.3	25	NA	98	NA	0	0	1
NA	NA	3	161	NA	NA	0	0	1
0.1	9.8	5.2	95	NA	NA	0	0	1
0.1	9.8	5.2	95	NA	NA	0	1	1
0.2	9.9	NA	NA	NA	NA	0	0	1
5	9.6	3.5	NA	97	134	0	0	0
0.3	9.3	NA	NA	101	162	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
0.5	NA	4.1	NA	NA	NA	1	0	1
0.9	9.3	2.6	NA	103	NA	0	0	0
2.7	NA	10	NA	96	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
29.3	8.5	NA	NA	104	NA	0	0	0
0.3	NA	5.1	NA	NA	NA	0	0	0
0.3	NA	4.8	NA	NA	NA	0	0	0
0.2	9.8	4.6	NA	NA	NA	0	0	0
0.3	NA	4.3	NA	NA	NA	0	0	0
NA	NA	4.3	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	8.8	1.1	NA	104	NA	0	0	0
0.4	8.4	1.4	NA	105	NA	0	0	1
0.7	8.5	2.5	NA	105	NA	0	0	0
1	8.2	3.7	NA	108	NA	0	0	0
1.2	8.3	NA	NA	106	NA	0	0	0
0.2	NA	NA	NA	103	NA	0	0	1
10.3	8.8	3.8	NA	102	NA	1	0	1
NA	NA	1.2	20	NA	NA	0	0	0
0.5	7.8	NA	NA	112	NA	0	0	0
0.4	8.9	2.2	NA	NA	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
4.4	NA	3.2	NA	NA	NA	0	0	1
0.2	9.9	NA	NA	102	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.3	9.3	2.1	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
NA	NA	3	NA	NA	NA	0	0	0
0.2	NA	4.1	NA	NA	NA	0	0	0
0.4	9.8	12	NA	103	NA	0	0	0
NA	NA	12	NA	NA	NA	0	0	0
NA	8.8	9.7	NA	NA	NA	0	0	0
0.3	9.4	8.6	NA	NA	NA	0	0	0
NA	NA	7.2	NA	NA	NA	0	0	0
0.4	8.7	7	NA	NA	NA	0	0	0
0.5	9.2	4.9	NA	106	NA	0	0	0
0.4	9.4	3.3	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
0.7	NA	2.4	NA	NA	NA	0	0	0
0.6	NA	4.6	NA	NA	NA	0	0	0
0.7	NA	2	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.7	NA	4.4	NA	NA	NA	0	0	0
0.8	10.7	3.9	NA	105	156	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
0.4	8.5	2.2	91	101	NA	0	0	0
7.9	8.2	1.4	NA	94	NA	1	0	0
NA	NA	2.7	NA	NA	NA	1	0	0
0.4	9	NA	NA	99	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	8.9	NA	NA	101	NA	0	0	0
0.6	8.2	NA	NA	100	NA	0	0	1
0.8	NA	NA	NA	96	NA	0	0	1
0.7	8.6	NA	NA	95	NA	0	0	1
0.8	8.3	NA	NA	92	NA	0	0	1
0.5	8.8	NA	NA	96	NA	0	0	1
0.7	7.9	NA	NA	97	NA	0	0	1
0.5	NA	5.1	NA	NA	NA	0	0	0
0.3	NA	4.5	NA	NA	NA	0	0	0
0.4	NA	5.4	NA	NA	NA	0	0	0
0.3	NA	6.8	NA	NA	NA	0	0	0
0.4	NA	6.7	NA	NA	NA	0	0	0
0.3	NA	5.7	NA	NA	NA	0	0	0
0.2	NA	5.7	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	9.8	1.6	NA	101	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.3	10.8	1.6	NA	NA	NA	0	0	0
NA	10.2	1.5	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.7	NA	2.6	NA	NA	NA	0	0	0
1.1	NA	2.8	NA	NA	NA	0	0	0
0.9	NA	2.7	NA	NA	NA	0	0	0
1.1	9.9	2.2	NA	NA	NA	0	0	0
0.9	9.7	NA	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	1.7	NA	NA	NA	0	0	0
0.2	9.1	NA	NA	100	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	105	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.4	9.3	1.3	NA	NA	136	0	0	0
0.4	10.6	1.3	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	103	NA	0	0	0
0.4	9.3	1.4	80	NA	NA	0	0	0
0.5	9.4	1.1	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.3	8.9	1.4	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	106	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	1
0.5	9.5	1.8	NA	NA	NA	0	0	1
0.8	9.4	3.3	NA	94	NA	0	0	1
0.4	NA	1.9	NA	NA	NA	0	0	1
0.7	NA	NA	NA	101	NA	0	0	0
0.9	NA	NA	NA	106	NA	0	0	0
0.5	NA	3.5	NA	104	NA	0	0	0
1	NA	NA	NA	103	NA	0	0	0
0.7	NA	NA	NA	100	NA	0	0	0
0.7	NA	NA	NA	101	NA	0	0	0
0.8	NA	NA	NA	100	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	5.9	2	108	NA	0	0	1
3.7	9	NA	NA	91	NA	1	0	1
0.4	NA	1.8	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	198	0	0	0
NA	9.7	3.4	NA	NA	NA	0	0	0
0.4	NA	NA	NA	99	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	9.2	3.4	NA	96	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	1	1
0.2	NA	NA	NA	96	NA	0	1	1
0.4	9.7	NA	NA	94	NA	0	1	1
0.4	8.9	NA	NA	97	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
1	9.1	NA	NA	92	NA	0	1	1
0.6	8.4	NA	NA	94	NA	0	1	1
0.9	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	100	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
0.4	9.8	1.7	NA	101	NA	0	0	0
0.3	NA	7.4	NA	NA	NA	0	0	1
0.2	9.6	7.6	NA	97	NA	0	0	1
NA	NA	5	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	103	NA	0	0	0
0.1	9.1	1.3	NA	110	119	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
0.6	NA	3.2	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
0.2	9.5	2.1	NA	NA	NA	0	0	0
0.5	10.1	1.6	NA	NA	NA	0	0	0
2.3	9.5	17	NA	106	NA	0	0	1
1	NA	NA	NA	95	NA	0	0	0
0.7	10.1	NA	NA	103	NA	0	0	1
4.2	NA	4.3	NA	103	139	0	0	0
0.3	8.1	2.9	NA	98	NA	0	0	0
0.2	NA	NA	NA	102	NA	0	0	0
NA	NA	8.1	NA	NA	NA	0	0	1
0.7	NA	30	NA	NA	NA	0	0	1
NA	NA	35	NA	NA	NA	0	0	1
NA	NA	46	NA	NA	NA	0	0	1
1.7	7.8	43	NA	107	NA	0	0	1
0.8	9.5	49	NA	NA	NA	0	0	1
1	9.8	65	NA	NA	NA	0	0	1
NA	NA	94	NA	NA	NA	0	0	1
1	NA	141	NA	NA	NA	0	0	1
0.9	NA	156	NA	NA	NA	0	0	1
0.7	NA	139	NA	NA	NA	0	0	1
0.6	NA	123	NA	NA	NA	0	0	1
0.5	NA	133	NA	NA	NA	0	0	1
0.4	NA	116	NA	NA	NA	0	0	1
0.6	9.3	141	NA	NA	NA	0	0	1
0.9	NA	173	NA	NA	NA	0	0	1
NA	NA	296	NA	NA	NA	0	0	1
NA	NA	254	NA	NA	NA	0	0	1
3.1	NA	232	NA	NA	NA	0	0	1
0.4	8.5	7.3	NA	104	NA	0	0	1
1.8	8.5	NA	NA	105	NA	1	0	0
0.2	8.8	NA	NA	104	NA	0	0	1
NA	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	NA	NA	103	NA	0	0	0
0.4	NA	3.9	NA	NA	NA	0	0	0
0.4	NA	NA	NA	103	NA	0	0	0
0.6	9.2	1.5	NA	104	NA	0	0	0
0.6	9.4	1.8	NA	94	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.6	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	100	118	0	0	0
0.6	NA	NA	NA	NA	NA	0	1	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	8.9	NA	NA	104	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
1.3	NA	NA	NA	NA	NA	0	0	0
0.7	8.3	3.3	NA	95	NA	0	0	0
0.4	NA	NA	NA	96	NA	0	0	0
NA	NA	2.9	NA	NA	NA	0	0	0
0.6	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	4.3	NA	NA	NA	0	0	0
0.6	NA	4.4	NA	NA	NA	0	0	0
0.3	9.7	1.3	NA	105	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
1	NA	1.1	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.3	3.5	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9.2	3.8	NA	NA	NA	0	0	1
NA	NA	4.5	NA	NA	NA	0	0	1
0.5	8.6	4.6	NA	NA	NA	0	0	1
0.5	8.6	4.6	NA	NA	NA	0	0	1
0.2	8.2	5.7	NA	NA	NA	0	0	1
NA	NA	5.6	NA	NA	NA	0	0	1
NA	NA	6.6	NA	NA	NA	0	0	1
0.7	NA	6.1	NA	108	NA	0	0	1
0.2	NA	3.3	NA	106	NA	0	0	1
NA	NA	3.5	22	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	4.1	NA	105	NA	0	0	1
0.4	9	4.4	NA	NA	NA	0	0	1
0.4	9	5.5	NA	103	NA	0	0	1
0.4	9	8.9	NA	103	NA	0	0	1
1.6	8.4	9.7	NA	102	NA	1	0	1
1.2	8.1	15	NA	NA	NA	0	0	1
1.6	8.7	17	NA	101	NA	0	0	1
1.1	7.3	21	NA	108	NA	0	0	1
0.6	NA	2.7	NA	96	NA	0	0	0
0.6	NA	7.2	NA	NA	NA	0	0	0
0.3	NA	3.4	NA	NA	NA	0	0	0
0.5	10.1	4.1	NA	NA	NA	0	0	0
0.2	NA	5.7	NA	NA	NA	0	0	0
0.5	NA	4.8	NA	NA	238	0	0	0
0.4	NA	5	NA	NA	260	0	0	0
0.4	NA	5.5	NA	NA	NA	0	0	0
0.2	8.7	NA	NA	98	NA	0	0	0
0.2	NA	4.5	NA	NA	NA	0	0	0
0.5	9.1	3	NA	102	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.9	NA	1.9	NA	NA	NA	0	0	0
0.9	NA	1.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.4	8.3	NA	NA	112	NA	0	0	0
0.3	NA	3.5	NA	NA	NA	0	0	0
0.3	NA	4.6	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.3	NA	3.4	NA	NA	NA	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	3.9	NA	NA	NA	0	0	0
0.3	9.4	3.5	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	164	0	0	0
0.6	NA	NA	NA	102	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	17	347	NA	NA	0	0	0
NA	10.3	17	NA	NA	NA	0	0	1
NA	9.7	14	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	11	NA	NA	187	0	0	0
NA	NA	9.7	NA	NA	NA	0	0	1
NA	9.8	8.6	NA	105	180	0	0	0
0.5	NA	8.7	NA	NA	NA	0	0	0
0.6	NA	6.8	NA	NA	NA	0	0	0
0.5	NA	6.7	NA	NA	NA	0	0	1
0.5	NA	6.4	78	NA	NA	0	0	1
NA	NA	6.3	NA	NA	174	0	0	1
NA	NA	6.6	NA	NA	NA	0	0	0
0.5	9.4	14	82	NA	NA	0	0	0
0.3	NA	32	125	NA	NA	0	0	1
0.5	NA	54	NA	NA	NA	0	0	1
NA	NA	59	271	NA	NA	0	0	0
NA	NA	51	309	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	28	482	NA	NA	0	0	1
0.5	NA	32	NA	NA	243	0	0	1
NA	NA	27	NA	NA	NA	0	0	1
0.5	NA	24	NA	NA	NA	0	0	1
0.3	8.1	11	NA	NA	NA	0	0	1
NA	NA	15	203	NA	NA	0	0	1
0.4	NA	16	NA	104	NA	0	0	1
0.5	NA	13	NA	NA	NA	0	0	1
0.5	NA	13	NA	NA	NA	0	0	1
0.4	NA	16	359	107	162	0	0	1
NA	7.9	21	555	103	167	0	0	1
0.5	NA	31	1008	NA	NA	0	0	1
0.5	9.9	1.4	NA	104	NA	0	0	0
0.4	NA	3.5	NA	106	NA	0	0	0
0.3	9.5	2.5	NA	105	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.2	NA	8.4	NA	NA	NA	0	0	1
0.4	NA	9	NA	NA	NA	0	0	1
0.3	NA	17	NA	103	NA	1	0	0
0.3	NA	6.9	NA	NA	NA	1	0	1
0.4	NA	11	NA	NA	NA	0	0	0
0.4	NA	14	NA	NA	NA	0	0	1
0.3	NA	14	NA	NA	NA	0	0	1
0.3	NA	10	NA	NA	NA	0	0	1
0.4	NA	13	NA	NA	NA	0	0	1
0.5	NA	18	NA	NA	NA	0	0	1
0.3	NA	19	NA	NA	NA	0	0	1
0.4	NA	20	NA	NA	NA	0	0	1
0.3	NA	21	NA	NA	NA	0	0	1
NA	NA	18	NA	NA	NA	0	0	1
0.3	NA	17	NA	NA	NA	0	0	1
0.3	NA	18	NA	NA	NA	0	0	1
0.4	NA	19	NA	NA	NA	0	0	1
NA	NA	19	NA	NA	NA	0	0	1
NA	NA	22	NA	NA	NA	0	0	1
NA	NA	19	NA	NA	NA	0	0	1
NA	NA	18	NA	NA	NA	0	0	1
NA	NA	19	NA	NA	NA	0	0	1
0.4	NA	24	NA	NA	NA	0	0	1
0.3	NA	15	NA	NA	NA	0	0	1
NA	NA	13	NA	NA	NA	0	0	1
0.2	NA	13	NA	NA	NA	0	0	1
NA	NA	13	NA	NA	NA	0	0	1
NA	NA	15	NA	NA	NA	0	0	1
NA	NA	13	NA	NA	NA	0	0	1
NA	NA	15	NA	NA	NA	0	0	1
0.8	10.3	NA	NA	106	178	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	101	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	NA	2.6	NA	NA	NA	0	0	0
0.6	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	3	NA	NA	NA	0	0	0
0.6	9.1	2.5	NA	NA	NA	0	0	0
0.9	NA	2	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
2.1	NA	27	NA	99	NA	0	0	1
0.6	8.6	16	NA	107	283	1	0	0
0.1	NA	15	NA	99	NA	1	0	0
2.3	NA	203	NA	94	NA	0	0	0
0.5	8.3	2.5	NA	108	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	76	NA	NA	NA	0	0	1
0.8	NA	3.4	NA	NA	NA	0	0	0
0.5	NA	2.8	NA	NA	NA	0	0	0
0.3	7.9	1.3	NA	102	NA	0	0	0
0.2	9.1	NA	NA	103	NA	0	0	0
1.7	9.4	NA	NA	NA	NA	0	0	0
1.9	NA	NA	NA	NA	NA	0	0	0
1.8	NA	NA	NA	NA	NA	1	0	0
0.3	9.2	10	NA	91	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.2	NA	NA	2.7	NA	NA	0	0	0
0.3	10.6	1.9	7	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	1.4	6.8	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.4	7.1	NA	NA	0	0	0
0.3	10	1.6	NA	NA	NA	0	0	1
0.6	10.4	5.1	NA	NA	NA	0	0	1
0.6	10	6.7	NA	NA	NA	0	0	1
0.7	10.2	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.7	9	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
11.9	NA	2.1	NA	NA	NA	1	0	1
15.1	NA	2.1	NA	NA	NA	1	0	1
NA	NA	2.4	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	NA	1.9	12	NA	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	1
0.2	NA	1.3	NA	NA	NA	0	0	1
0.5	NA	1.4	NA	NA	NA	0	0	1
0.3	NA	1.3	NA	NA	NA	0	0	1
0.4	NA	1.4	NA	NA	206	0	0	1
0.3	NA	1.5	NA	NA	NA	0	0	1
0.6	9.5	NA	NA	NA	NA	0	0	1
0.6	9.9	6.3	NA	99	NA	0	0	1
0.8	10.1	5	NA	99	NA	0	0	1
1	10.3	5.4	NA	99	NA	0	0	1
1.3	10.2	6.4	NA	98	NA	0	0	1
1.5	10.6	7.3	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.8	NA	6.7	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.8	NA	9.4	NA	NA	NA	0	0	1
NA	NA	16	NA	101	NA	0	0	1
0.5	10.4	29	NA	102	NA	0	0	1
NA	NA	41	NA	NA	NA	0	0	1
NA	NA	NA	18	NA	159	0	0	1
0.6	9.4	41	NA	NA	NA	0	0	1
0.7	9.8	NA	NA	102	NA	0	0	1
0.6	10.1	58	NA	NA	NA	0	0	0
0.7	9.7	57	NA	NA	NA	0	0	1
0.8	8.5	66	NA	102	NA	0	0	1
1.2	NA	48	NA	NA	NA	0	0	1
1.5	NA	57	NA	NA	NA	0	0	1
0.3	NA	2	8.9	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
NA	NA	NA	16	NA	280	0	0	0
0.4	NA	1.7	NA	NA	229	0	0	0
0.3	9.6	1.7	NA	NA	NA	0	0	0
0.2	9	2	NA	NA	NA	0	0	0
0.9	9.5	20	NA	104	NA	0	0	1
0.6	10.1	3.1	NA	NA	NA	0	0	0
0.9	9.2	NA	NA	99	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.2	NA	1	10	103	NA	0	0	0
1.6	8.2	16	NA	105	NA	0	0	1
NA	NA	3.1	NA	NA	NA	0	0	1
NA	NA	NA	258	NA	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.8	NA	2.4	18	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	17	NA	NA	0	0	0
0.2	NA	NA	24	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	1
0.2	NA	1.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	1.5	NA	NA	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	1
0.8	8.5	193	NA	98	NA	0	0	1
0.3	NA	NA	NA	103	NA	0	0	0
0.5	8.9	NA	NA	NA	NA	0	0	0
NA	9.6	NA	NA	NA	NA	0	0	0
1.4	8.3	1.9	NA	103	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
5.2	9	2.6	NA	106	NA	1	0	1
0.4	9.1	2.3	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	4.8	NA	95	NA	0	1	1
NA	NA	NA	NA	100	NA	0	1	1
NA	9.1	NA	NA	NA	NA	0	0	1
3.5	8.7	18	NA	NA	NA	0	0	1
NA	NA	3.6	NA	NA	NA	0	0	1
1.3	9.2	NA	NA	115	NA	0	0	0
NA	10.6	3.7	NA	101	NA	0	0	0
NA	10.2	NA	NA	102	NA	0	0	0
NA	9.4	3	NA	NA	NA	0	0	0
NA	NA	3.9	NA	106	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
5.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	114	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	107	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.2	9.3	NA	1034	103	NA	0	0	0
0.9	NA	5.5	NA	NA	NA	1	0	0
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	1	1
NA	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	1.9	25	NA	NA	0	0	0
0.5	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.7	24	NA	215	0	0	0
0.5	NA	1.8	29	NA	186	0	0	0
0.5	8.6	1.7	NA	NA	198	0	0	0
0.5	8.9	1.8	32	NA	273	0	0	0
0.4	NA	1.4	35	NA	NA	0	0	0
NA	NA	NA	52	NA	NA	0	0	0
1	8.8	5.9	NA	92	NA	0	0	1
NA	NA	7.5	NA	NA	NA	0	0	1
NA	NA	1.6	NA	NA	NA	0	0	0
0.4	9.8	NA	NA	97	NA	0	0	0
0.4	NA	1	2865	NA	NA	0	0	1
NA	NA	2.1	120	NA	NA	0	0	1
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	10.4	2	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	3.5	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.4	9.4	5.3	NA	104	NA	0	0	0
0.4	NA	4	NA	101	NA	0	0	0
0.7	9.5	NA	NA	91	NA	0	0	0
NA	NA	NA	6284	NA	NA	0	0	1
0.5	9.2	106	NA	105	NA	0	0	0
1	NA	NA	NA	90	NA	0	1	0
NA	NA	NA	34	NA	NA	0	0	0
0.4	9.4	NA	6	103	NA	0	0	0
0.5	9.3	1.4	17	102	NA	0	0	0
1.3	7.8	10	NA	98	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	4.2	NA	NA	NA	0	0	0
0.6	9.5	NA	NA	100	NA	0	0	1
1.5	8.6	NA	NA	103	NA	0	0	1
4.4	8.3	NA	20	106	NA	1	0	0
3.3	8.5	1.8	20	110	NA	1	0	0
0.4	NA	NA	NA	106	NA	0	0	0
0.5	9.7	7.7	NA	101	NA	0	0	1
0.6	9.8	8.2	NA	96	NA	0	0	1
0.8	9.3	6.8	NA	100	NA	0	0	1
0.9	9.7	5.5	NA	98	NA	0	0	1
0.8	9.9	6.8	NA	98	NA	0	0	1
0.8	9.4	5.9	NA	100	NA	0	0	1
0.8	NA	5.1	NA	99	NA	0	0	1
0.6	9.8	4.9	NA	98	NA	0	0	1
0.7	9.8	5	NA	97	NA	0	0	1
0.5	10	5.9	NA	NA	NA	0	0	1
0.4	NA	4.2	NA	102	NA	0	0	1
0.5	9.4	4.4	NA	100	NA	0	0	1
NA	NA	NA	NA	102	NA	0	0	1
0.3	9.1	5	NA	100	NA	0	0	1
NA	NA	3.6	NA	NA	NA	0	0	1
0.4	9	3.2	NA	100	NA	0	0	1
0.5	NA	3.1	NA	101	NA	0	0	1
NA	NA	4.1	NA	NA	NA	0	0	1
NA	NA	3.5	NA	NA	NA	0	0	1
0.3	NA	4.8	NA	NA	NA	0	0	1
0.5	9	2.3	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	1
0.5	8.7	2.5	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	9.8	3	NA	100	NA	0	0	1
NA	NA	2.8	NA	NA	NA	0	0	1
0.3	NA	3.4	NA	NA	NA	0	0	1
0.5	9.6	3.9	NA	NA	NA	0	0	1
0.4	NA	4.7	NA	NA	NA	0	0	1
0.6	8.7	3.9	NA	NA	NA	0	0	1
0.4	8.9	4.7	NA	NA	NA	0	0	1
0.4	NA	5.4	NA	NA	NA	0	0	1
0.6	NA	4.1	NA	NA	NA	0	0	1
0.4	9.4	NA	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	1
0.3	NA	1.6	NA	NA	NA	0	0	1
0.4	NA	1.5	57	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	3.4	NA	NA	NA	0	0	0
NA	NA	5.6	NA	NA	241	0	0	0
NA	NA	3.9	NA	NA	NA	0	0	0
NA	NA	3.8	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.5	9	2	NA	105	161	0	0	0
NA	8.9	2.1	NA	105	NA	0	0	0
0.4	9.6	1.9	NA	104	NA	0	0	0
0.7	NA	2	NA	NA	NA	0	0	0
0.6	8.7	2	NA	106	NA	0	0	0
0.6	9.4	2.3	NA	NA	NA	0	0	0
0.5	9.3	2.2	NA	NA	NA	0	0	0
16.3	9.1	3.4	NA	93	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
NA	11.1	2.1	NA	NA	NA	0	0	0
NA	NA	34	NA	NA	NA	0	0	1
0.5	9.9	22	NA	NA	NA	0	0	1
NA	NA	14	NA	105	NA	0	0	1
0.6	NA	9.5	NA	NA	NA	0	0	1
0.4	NA	6.9	NA	NA	NA	0	0	0
0.3	NA	20	NA	NA	NA	0	0	1
0.5	NA	23	NA	NA	NA	0	0	1
0.5	NA	30	NA	NA	NA	0	0	1
4.9	8.6	53	NA	99	NA	0	0	1
0.3	NA	2.3	NA	NA	NA	0	0	0
0.8	9.3	2.1	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
NA	9.2	2	NA	NA	NA	0	0	0
0.5	NA	3.9	NA	NA	NA	0	0	1
0.6	NA	3.6	NA	NA	NA	0	0	1
0.5	NA	3.6	NA	NA	NA	0	0	1
0.6	NA	10	NA	NA	NA	0	0	1
0.4	NA	18	NA	NA	NA	0	0	1
0.5	7.7	29	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
1.2	9.1	1	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	133	0	0	0
0.4	9.3	1.5	NA	102	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	0
NA	NA	3.9	NA	94	NA	0	0	0
NA	10.2	NA	77	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.2	9.4	3.4	127	97	NA	0	0	0
0.2	9.6	NA	126	NA	NA	0	0	1
NA	NA	NA	203	NA	NA	0	0	1
0.2	9.8	8.3	207	NA	NA	0	0	1
NA	NA	12	129	NA	NA	0	0	1
NA	NA	8.2	NA	NA	NA	0	0	0
NA	NA	NA	41	NA	NA	0	0	0
NA	NA	NA	35	NA	NA	0	0	0
NA	NA	NA	30	NA	NA	0	0	0
NA	10.1	4.3	25	96	NA	0	0	0
NA	NA	4.6	24	NA	NA	0	0	0
NA	NA	NA	21	NA	NA	0	0	0
NA	NA	NA	21	NA	NA	0	0	0
0.2	NA	NA	25	91	NA	0	0	0
NA	9.8	NA	51	96	NA	0	0	0
0.2	NA	NA	68	99	NA	0	0	0
0.3	NA	12	101	100	NA	0	0	0
0.6	NA	NA	NA	NA	270	0	0	0
0.4	NA	NA	NA	NA	247	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
0.3	9.4	3.8	NA	104	NA	0	0	0
NA	NA	3.6	NA	NA	NA	0	0	0
0.4	10	2.8	NA	103	NA	0	0	0
0.4	NA	4.1	NA	NA	NA	0	0	0
0.4	9.3	4.5	NA	100	177	0	0	0
0.4	NA	4.2	NA	NA	NA	0	0	0
NA	NA	4.9	NA	NA	NA	0	0	0
0.5	NA	7.3	NA	NA	NA	0	0	1
NA	NA	7	NA	NA	NA	0	0	1
0.6	NA	7.4	NA	NA	NA	0	0	1
0.3	9.2	9.1	NA	NA	NA	0	0	1
0.6	9.9	13	NA	99	178	0	0	1
0.6	9.6	11	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	0
0.9	NA	1.6	NA	NA	NA	0	0	0
0.7	9.2	1.4	NA	NA	NA	0	0	0
1.1	NA	1.8	NA	NA	NA	0	0	0
1.1	9.7	4.5	NA	107	125	0	0	0
12	NA	3.2	NA	100	NA	0	0	0
0.6	NA	2.8	NA	98	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
2.4	8.4	9.9	NA	109	NA	0	0	0
0.8	NA	2.7	NA	105	NA	0	0	0
1.7	NA	NA	NA	NA	NA	0	0	0
0.8	8.3	3.5	NA	99	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	1
0.8	NA	4.6	NA	NA	NA	0	0	1
0.4	8.7	4	NA	107	NA	0	0	1
0.5	NA	1.7	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.4	9.3	1.5	NA	105	NA	0	0	1
4.7	7.9	4.7	NA	99	NA	0	0	1
1	NA	1.8	NA	NA	NA	0	0	0
1	NA	1.8	NA	NA	NA	0	0	0
1.1	9.5	1.5	NA	NA	NA	0	0	0
1.3	NA	2	NA	NA	NA	0	0	0
1.2	NA	1.3	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.9	NA	1.5	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.9	6.9	NA	NA	NA	0	0	1
0.4	NA	4.9	10	NA	NA	0	0	0
NA	NA	4.4	NA	NA	NA	0	0	0
NA	NA	3	NA	NA	NA	0	0	0
0.2	9.4	2.8	NA	101	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.5	9.7	2.4	NA	103	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.2	9.5	3.2	NA	99	NA	0	0	0
NA	NA	7	NA	NA	NA	0	0	0
NA	NA	13	NA	NA	NA	0	0	1
NA	NA	20	NA	NA	NA	0	0	1
NA	NA	28	NA	NA	NA	0	0	1
0.3	9.7	38	NA	104	NA	0	0	1
0.3	9.3	63	NA	101	NA	0	0	1
NA	NA	87	NA	NA	NA	0	0	1
0.3	9.4	108	NA	NA	NA	0	0	1
NA	NA	126	NA	NA	NA	0	0	1
NA	NA	158	NA	103	NA	0	0	1
0.4	9.3	193	NA	NA	NA	0	0	1
NA	NA	247	NA	NA	NA	0	0	1
0.5	NA	3.5	NA	NA	NA	0	0	0
0.7	NA	4.2	NA	NA	NA	0	0	0
0.7	NA	3.6	NA	NA	NA	0	0	0
0.6	NA	3.7	NA	NA	NA	0	0	0
0.7	NA	3.3	NA	NA	NA	0	0	0
0.9	9.1	5.8	NA	102	200	0	0	1
NA	9.2	1.8	NA	102	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	2	NA	NA	NA	0	0	0
0.8	NA	2	NA	NA	NA	0	0	0
0.6	NA	2	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
2.1	NA	1.1	NA	105	NA	1	0	0
0.3	9	1.1	NA	103	NA	0	0	0
0.3	NA	5.8	NA	NA	NA	0	0	0
0.4	NA	9.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	96	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
1.1	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
1.1	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
1.7	9.4	NA	NA	104	NA	0	0	1
0.2	NA	6.1	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	106	NA	0	1	0
0.3	8.8	2.4	NA	104	NA	0	0	0
0.6	9.1	2.6	NA	103	NA	0	0	0
0.4	NA	3.5	NA	102	NA	0	0	0
0.5	9.1	3.1	NA	100	NA	0	1	0
NA	NA	3.6	NA	102	124	0	0	0
0.4	8.9	4	NA	100	NA	0	0	0
0.4	9.4	3.8	NA	101	NA	0	0	0
NA	NA	3.3	NA	NA	NA	0	0	0
NA	9.6	NA	NA	103	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	5.2	NA	103	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.2	NA	NA	NA	106	NA	0	0	0
0.2	NA	NA	NA	NA	NA	1	0	1
0.3	NA	NA	NA	NA	NA	1	0	1
0.2	NA	NA	NA	NA	NA	1	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
1.6	8.5	NA	NA	100	NA	0	0	0
NA	9.5	NA	NA	99	199	0	0	0
0.3	9.5	3.8	NA	101	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	12	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	101	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.6	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	104	27	NA	NA	0	0	1
NA	9.3	4.9	NA	NA	NA	0	0	1
0.3	9.6	1.7	NA	NA	NA	0	0	1
0.3	NA	1.5	NA	NA	NA	0	0	1
0.5	9.4	1.8	NA	NA	NA	0	0	1
NA	9.4	1.6	NA	NA	NA	0	0	1
0.4	NA	1.5	NA	NA	NA	0	0	1
0.3	NA	2.4	NA	NA	NA	0	0	0
0.4	8.6	NA	563	102	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	10.2	NA	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	0
0.5	NA	19	17	NA	241	0	0	1
0.3	NA	13	10	101	NA	0	0	1
0.5	NA	11	NA	98	NA	0	0	0
0.3	8.5	NA	NA	104	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.1	34	NA	NA	0	0	0
0.3	NA	1.2	63	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
NA	NA	3.2	NA	NA	NA	0	0	0
0.5	NA	31	NA	NA	NA	0	0	0
0.6	9.3	7.3	NA	NA	NA	0	0	0
0.6	NA	12	NA	NA	NA	0	0	0
NA	NA	9.3	NA	NA	NA	0	0	0
NA	9.1	42	NA	NA	NA	0	0	1
NA	NA	71	NA	NA	NA	0	0	1
1.3	NA	31	NA	NA	NA	0	0	1
0.8	9.3	111	NA	NA	NA	0	0	1
NA	NA	450	NA	96	NA	0	0	1
1.5	9	630	NA	92	NA	0	0	1
0.6	NA	1.1	NA	NA	NA	0	0	1
0.4	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	1
0.6	NA	22	NA	NA	NA	0	0	1
0.7	NA	54	NA	NA	NA	0	0	1
1.6	NA	120	NA	NA	NA	0	0	1
1.2	7.9	120	NA	105	NA	0	0	1
0.8	9.7	3.5	NA	101	145	0	0	1
NA	NA	1.7	NA	NA	NA	0	0	0
NA	NA	2.4	NA	100	NA	0	0	0
0.3	9.5	NA	NA	100	NA	0	1	1
0.2	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.3	NA	1.9	NA	NA	NA	0	1	0
0.3	NA	1.7	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
3	NA	NA	NA	NA	NA	0	0	0
5.8	8.2	NA	NA	109	NA	0	0	1
14	9.3	2.9	NA	107	NA	0	0	0
0.6	8.1	1.7	NA	104	NA	0	0	0
1.8	8.8	6.1	NA	103	174	0	0	0
0.4	8.8	2.4	NA	106	NA	0	0	1
0.4	8.8	NA	NA	107	NA	0	0	1
0.6	8.9	2.8	NA	104	NA	0	1	1
0.5	9.1	4.8	NA	105	NA	0	0	1
0.6	8.9	4.9	NA	106	NA	0	0	1
0.5	8.9	7.6	NA	107	NA	0	0	1
0.6	8.6	3.9	NA	108	NA	0	0	1
0.5	8.6	NA	NA	108	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	8.7	NA	NA	107	NA	0	0	1
NA	8.4	NA	NA	108	NA	0	0	1
NA	8.8	NA	NA	108	NA	0	1	1
NA	8.8	NA	NA	106	NA	0	0	1
NA	8.4	NA	NA	104	NA	0	0	1
NA	8.6	8.2	NA	106	NA	0	1	1
0.3	8.5	7.1	NA	108	NA	0	0	1
0.3	8.3	5.9	NA	109	NA	0	0	1
0.3	8.3	NA	NA	106	NA	0	1	1
0.8	8.5	NA	NA	106	NA	0	1	1
13.3	7.8	NA	NA	101	NA	0	0	1
0.3	NA	2.5	NA	NA	356	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
NA	NA	1	NA	NA	NA	0	0	0
2.2	NA	NA	NA	102	NA	0	0	0
1.9	9.7	7.1	NA	103	154	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.6	NA	NA	NA	0	0	1
NA	NA	2.6	NA	NA	NA	0	0	1
0.4	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	9.6	NA	NA	NA	0	0	0
NA	9.4	NA	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	5.7	NA	NA	273	0	0	0
0.3	9.5	4.5	NA	104	292	0	0	0
NA	9.8	5.5	NA	NA	NA	0	0	1
0.4	9.3	1.2	NA	101	201	0	0	0
13.2	8.7	31	NA	106	NA	0	0	0
NA	NA	3.2	NA	NA	NA	0	0	0
0.3	8.9	7	NA	NA	NA	0	0	1
0.3	8.7	7	NA	105	NA	0	0	1
0.4	9	15	33	NA	NA	0	0	1
NA	NA	19	NA	NA	NA	0	0	1
0.4	NA	18	NA	100	NA	0	0	1
0.3	NA	16	NA	106	NA	0	0	1
0.3	NA	12	NA	NA	NA	0	0	1
0.4	NA	6.9	NA	NA	NA	0	0	1
0.3	NA	5.9	NA	105	NA	0	0	1
NA	NA	5.3	NA	NA	NA	0	0	1
0.3	NA	3.3	NA	NA	NA	0	0	1
0.3	NA	4.8	NA	NA	NA	0	0	0
NA	NA	6.4	NA	NA	NA	0	0	1
0.3	NA	9.8	NA	NA	NA	0	0	1
0.3	8.5	10	NA	100	NA	0	0	1
0.8	NA	12	NA	NA	NA	0	0	1
NA	7.9	15	NA	NA	NA	0	0	1
1.7	7.8	165	NA	109	NA	1	0	1
NA	NA	1.4	NA	NA	NA	0	0	0
NA	9.8	NA	NA	NA	NA	0	0	0
0.2	NA	1	NA	NA	NA	0	0	0
0.4	NA	3.1	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
NA	8.7	NA	NA	NA	NA	0	0	0
0.4	9	2.2	NA	NA	NA	0	0	0
0.5	9.1	1.8	NA	100	NA	0	0	0
0.5	9.1	2.9	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	9.7	1.1	NA	NA	NA	0	0	0
0.7	NA	1.4	NA	NA	NA	0	0	0
0.9	NA	10	NA	105	211	0	0	1
1.4	8.6	21	NA	106	NA	0	0	1
1.3	8.6	23	NA	86	NA	0	0	1
1.2	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	9	NA	NA	NA	0	0	0
0.5	9.5	16	NA	105	NA	0	0	0
0.7	9.7	23	NA	NA	NA	0	0	0
1.1	NA	25	NA	NA	NA	0	0	1
0.9	9.6	59	NA	NA	NA	0	0	1
0.7	9.4	48	NA	97	NA	0	0	1
1	9.5	8.5	NA	102	NA	0	0	0
0.8	9.3	3.1	NA	102	NA	0	0	0
1.1	10.5	3.4	NA	NA	NA	0	0	0
0.9	9.4	NA	NA	NA	NA	0	0	0
NA	9.8	6.3	NA	100	NA	0	0	0
0.6	NA	7.7	NA	NA	NA	0	0	0
0.7	NA	8.1	NA	NA	NA	0	0	0
0.8	9.6	11	NA	NA	NA	0	0	0
0.7	NA	1.5	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	107	NA	0	0	1
0.3	NA	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	2.5	71	NA	NA	0	0	0
0.6	10	1.5	72	NA	NA	0	0	1
NA	10.1	10	NA	96	235	0	0	0
NA	NA	9.5	NA	NA	NA	0	0	0
0.5	8.7	NA	NA	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	9.4	186	NA	95	NA	0	0	1
0.5	9.1	188	NA	96	NA	0	0	1
0.4	9.6	19	31	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	104	NA	0	0	1
NA	NA	19	NA	NA	NA	0	0	1
NA	NA	20	NA	NA	NA	0	0	1
NA	NA	27	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9.8	1.6	NA	105	NA	0	0	0
0.3	9.1	1.4	NA	NA	NA	0	0	0
0.9	NA	3	NA	NA	NA	0	0	0
NA	NA	3	NA	NA	NA	0	0	0
0.5	NA	4.7	NA	NA	NA	0	0	0
0.3	NA	4.3	NA	100	178	0	0	0
0.5	NA	2.3	NA	101	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	0
0.8	8.9	NA	NA	101	NA	1	0	1
10.5	8.6	11	NA	95	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
3.7	9.3	3.4	NA	104	NA	0	0	0
2.7	NA	NA	NA	105	NA	0	0	0
4.2	8.9	8.3	NA	92	NA	0	0	1
1.5	9	NA	NA	97	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
5.1	NA	2.6	NA	106	153	0	0	1
2.2	10	3.2	NA	102	199	0	0	1
NA	NA	21	NA	NA	NA	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
0.9	NA	NA	NA	105	NA	0	0	0
NA	9.1	2.1	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	97	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	1	0	0
0.6	NA	NA	NA	NA	NA	1	0	0
2.3	8	NA	NA	106	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	0
1.1	NA	1.5	NA	NA	NA	0	0	0
1.6	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.5	25	NA	NA	0	0	0
0.7	NA	1.5	NA	NA	NA	0	0	0
0.9	NA	1.3	NA	NA	NA	0	0	0
1.2	NA	1.6	NA	NA	NA	0	0	0
1.3	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
0.4	9.1	1.7	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	178	0	0	0
NA	8.9	1.2	NA	99	NA	0	0	0
0.4	NA	1.6	NA	100	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
NA	NA	6.9	20	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.7	10.2	NA	NA	91	NA	0	1	1
0.7	10.2	58	NA	91	NA	0	1	1
0.6	NA	NA	NA	96	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	91	NA	0	1	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
1.2	NA	NA	NA	100	NA	0	1	0
0.8	NA	NA	NA	NA	NA	0	1	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	1	0
0.8	NA	NA	NA	99	NA	0	1	0
0.8	NA	NA	NA	NA	NA	0	0	0
1.2	NA	NA	NA	NA	NA	0	1	1
1.2	9.8	NA	NA	98	NA	0	1	1
1.4	NA	NA	NA	NA	NA	0	1	1
7.4	NA	NA	NA	NA	NA	0	1	1
NA	9.7	NA	NA	NA	NA	0	0	0
0.5	9.8	2.4	NA	NA	NA	0	0	0
0.5	9.5	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	106	NA	0	0	0
NA	9.5	5.5	NA	NA	NA	0	0	0
0.5	9.9	5	NA	109	NA	0	0	0
0.4	NA	3.5	NA	NA	NA	0	0	0
0.3	8.8	2.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	9.7	NA	NA	104	NA	0	0	0
0.3	9.3	2.5	NA	108	NA	0	0	0
0.2	NA	NA	28	NA	NA	0	0	0
0.2	NA	NA	13	NA	NA	0	0	0
1	NA	2	NA	NA	NA	0	0	0
2.5	9	1.4	NA	99	152	0	0	1
0.5	NA	1.4	NA	102	116	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	109	NA	0	0	0
0.3	8.1	NA	NA	107	NA	0	0	0
0.3	8.1	NA	NA	107	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	8.4	NA	NA	106	NA	0	0	0
0.3	8.2	NA	NA	106	NA	0	0	0
0.4	8	NA	NA	106	NA	0	0	0
0.8	8	NA	NA	106	NA	0	0	1
0.5	7.7	3.6	NA	106	NA	0	0	1
0.4	7.6	5.5	NA	NA	NA	0	0	1
0.3	NA	29	NA	NA	NA	0	0	1
NA	NA	61	NA	NA	NA	0	0	1
NA	NA	382	NA	NA	NA	0	0	1
0.5	NA	2487	NA	99	NA	0	0	1
0.5	7.1	NA	NA	101	NA	0	0	1
0.5	7.8	3349	NA	100	NA	0	0	1
0.6	9.1	2.7	NA	109	NA	0	0	0
0.6	9.3	9.8	NA	97	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.6	NA	1.6	NA	NA	NA	0	0	0
0.7	NA	2	18	NA	NA	0	0	0
0.5	NA	NA	16	NA	NA	0	0	0
0.7	NA	4.7	NA	106	209	0	0	0
0.3	NA	5.6	NA	NA	NA	0	0	0
0.7	NA	4.3	NA	NA	NA	0	0	0
0.3	NA	4.4	NA	NA	NA	0	0	0
0.5	NA	4.1	NA	NA	NA	0	0	0
0.5	NA	4.7	NA	NA	NA	0	0	0
0.8	10	4.2	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
NA	9.1	NA	NA	105	NA	0	0	0
0.2	9.2	1.1	NA	NA	197	0	0	0
NA	9	1.1	NA	105	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	0
NA	NA	1.1	10	NA	NA	0	0	0
NA	10.2	20	NA	NA	NA	0	0	1
11.1	8.4	3.8	NA	95	NA	1	0	1
0.3	NA	14	NA	103	NA	0	0	1
0.3	NA	14	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
1.2	8.9	5.1	NA	102	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.3	9.1	1.5	NA	NA	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	NA	38	NA	NA	0	0	1
0.2	NA	2.2	NA	NA	NA	0	0	0
0.8	NA	10	NA	99	NA	0	0	0
0.6	NA	1.4	299	104	NA	0	0	1
NA	9.2	NA	NA	105	NA	0	0	1
0.3	9.5	NA	NA	108	NA	0	0	1
NA	8.8	NA	NA	NA	NA	0	0	1
0.3	9	NA	NA	106	NA	0	0	1
0.4	9.6	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.4	NA	NA	104	NA	0	0	1
0.4	9.3	NA	NA	103	NA	0	0	1
1.4	NA	NA	NA	100	NA	1	0	0
1	NA	NA	NA	106	NA	0	0	0
1	NA	NA	NA	100	NA	0	0	0
0.7	NA	NA	NA	103	NA	1	0	0
0.8	NA	NA	NA	101	NA	1	0	0
0.9	9.8	NA	NA	102	NA	1	0	0
1.8	9.6	NA	NA	101	NA	1	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.6	9.8	1.3	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.2	NA	102	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
1.6	9.8	NA	NA	107	NA	0	0	0
16.9	8.7	NA	NA	108	126	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	9.1	NA	102	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	106	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.2	NA	7.3	NA	NA	NA	0	0	1
NA	NA	12	NA	NA	NA	0	0	1
NA	NA	11	NA	NA	NA	0	0	1
0.1	NA	8.9	NA	NA	NA	0	0	1
NA	NA	6.8	NA	NA	NA	0	0	1
NA	NA	3.6	NA	NA	NA	0	0	1
NA	NA	3.5	NA	NA	NA	0	0	1
NA	NA	3.3	NA	NA	NA	0	0	1
0.2	8.9	6.5	NA	105	NA	0	0	1
0.3	NA	2.8	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.2	9.3	2	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.3	9.2	1.3	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	9.4	NA	NA	96	NA	0	0	0
NA	9.3	NA	NA	99	NA	0	0	0
5.8	9.2	38	NA	102	NA	0	1	0
NA	NA	NA	NA	101	NA	1	0	0
0.2	8.9	21	NA	107	NA	0	0	0
NA	NA	18	NA	NA	NA	0	0	1
0.1	8.4	14	NA	108	NA	0	0	0
NA	NA	16	NA	NA	NA	0	0	0
0.1	NA	10	NA	NA	NA	0	0	0
NA	NA	9.5	NA	NA	NA	0	0	0
0.1	9	11	NA	98	NA	0	0	0
0.1	9.1	38	NA	100	NA	0	0	1
0.6	9	156	NA	98	116	0	0	1
0.9	NA	NA	NA	103	NA	0	0	1
0.4	NA	6.2	NA	NA	NA	0	0	1
0.6	NA	2.4	NA	NA	NA	0	0	0
0.6	NA	5.1	11	NA	NA	0	0	0
0.6	NA	5.2	NA	NA	NA	0	0	0
0.5	NA	6.8	NA	NA	NA	0	0	0
0.5	NA	4.8	NA	NA	NA	0	0	0
0.5	NA	2.9	NA	NA	NA	0	0	0
0.8	NA	3.4	37	102	NA	0	0	1
NA	9.6	NA	12	NA	174	0	0	0
0.3	NA	NA	18	NA	223	0	0	0
0.3	NA	NA	15	99	188	0	0	0
0.3	8.3	NA	NA	101	NA	0	0	0
0.2	NA	NA	NA	98	NA	0	0	0
0.3	9.2	NA	NA	NA	NA	0	0	1
5	8.3	NA	NA	96	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	1	1
0.3	NA	54	NA	NA	NA	0	0	1
NA	9.3	NA	NA	101	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	8.6	95	NA	NA	NA	0	0	1
2.3	NA	9	NA	NA	NA	1	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	2.2	NA	107	NA	0	0	0
0.3	NA	2.1	NA	106	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	9	NA	NA	105	NA	0	0	0
0.3	9.1	2.2	NA	104	NA	0	0	0
0.4	NA	2.1	NA	103	NA	0	0	1
0.5	9.5	2	NA	105	NA	0	0	1
NA	NA	2.3	NA	NA	NA	0	0	1
0.4	9.4	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	8.4	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9.3	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	103	NA	0	0	1
0.3	8.4	NA	NA	106	NA	0	0	1
0.2	8.7	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	8.4	NA	NA	101	NA	0	0	1
0.3	8.7	NA	NA	105	NA	0	0	1
2.5	9.3	3.8	NA	98	NA	0	0	0
2.5	8.6	8.5	NA	98	NA	0	0	0
1.5	9.1	NA	NA	100	NA	0	0	0
2.2	9.2	3.4	NA	102	96	0	0	0
0.3	9.6	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.8	NA	2	NA	NA	236	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	101	NA	0	0	0
NA	NA	3.4	NA	NA	NA	0	0	0
0.7	9.1	NA	NA	106	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.7	8.2	NA	NA	106	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
NA	NA	NA	719	103	NA	0	0	0
3.6	8	NA	NA	99	NA	0	0	1
0.4	8.2	21	NA	93	NA	0	0	0
0.3	10.1	12	NA	NA	NA	0	0	1
0.5	9.3	6.7	NA	NA	NA	0	0	1
0.3	9.6	3.8	NA	NA	NA	0	0	1
0.4	NA	2.7	NA	NA	NA	0	0	1
0.4	9.4	2.6	NA	NA	NA	0	0	1
0.5	9.3	2.1	NA	NA	NA	0	0	0
0.3	8.6	2.1	NA	NA	NA	0	0	0
0.3	9.2	2	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.3	9.5	2.5	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	4.9	NA	NA	NA	0	0	0
0.2	9.3	3.7	NA	NA	NA	0	0	0
0.3	NA	4.4	NA	NA	NA	0	0	0
0.3	NA	4.7	NA	NA	NA	0	0	0
0.3	NA	4.4	NA	NA	NA	0	0	0
0.3	NA	4.5	NA	NA	NA	0	0	0
0.2	NA	3.7	NA	NA	NA	0	0	1
0.2	NA	26	NA	NA	NA	0	0	1
NA	NA	23	NA	NA	NA	0	0	1
0.3	NA	15	NA	NA	NA	0	0	1
0.3	NA	14	NA	NA	NA	0	0	1
0.3	NA	24	NA	NA	NA	0	0	1
0.3	NA	68	NA	NA	NA	0	0	1
0.7	NA	125	NA	NA	NA	0	0	1
NA	NA	34	NA	NA	NA	0	0	1
1	NA	16	NA	NA	NA	0	0	1
NA	NA	11	NA	NA	236	0	0	1
NA	NA	NA	16	NA	NA	0	0	1
0.6	9.3	6.8	NA	103	NA	0	0	1
0.4	NA	5.5	NA	NA	NA	0	0	1
0.5	NA	5.7	NA	NA	NA	0	0	1
0.4	NA	4.4	NA	NA	NA	0	0	1
NA	NA	4.6	NA	NA	NA	0	0	1
0.4	NA	4.3	NA	NA	NA	0	0	1
0.6	NA	3.8	NA	NA	NA	0	0	1
0.5	NA	3.9	NA	NA	NA	0	0	1
0.5	NA	3.5	NA	NA	NA	0	0	1
3	NA	NA	NA	106	NA	0	0	0
0.6	NA	1.8	NA	95	NA	0	0	0
0.5	NA	1.2	10	NA	NA	0	0	1
0.4	NA	1.2	NA	NA	NA	0	0	1
0.4	9.7	1	9.7	NA	NA	0	0	1
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	10	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	1
0.4	10.3	1.3	NA	NA	NA	0	0	1
0.5	NA	1.8	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	4.6	NA	NA	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.2	7.7	NA	NA	0	0	0
NA	NA	NA	12	102	NA	0	0	0
0.4	NA	1	9.9	NA	NA	0	0	0
0.4	NA	NA	15	NA	229	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	224	0	0	0
0.3	NA	NA	NA	NA	161	0	0	0
0.3	NA	1.4	NA	106	NA	0	0	0
0.5	NA	2.7	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	1
0.7	9.9	NA	NA	100	244	0	0	1
1	9.9	1	NA	100	214	0	0	0
25.5	NA	3.1	NA	101	NA	1	0	0
NA	9	NA	NA	104	NA	0	0	1
0.4	8.6	7.1	NA	99	NA	0	0	1
0.5	8.7	7.9	NA	102	NA	0	0	1
0.3	NA	3	NA	NA	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	9.2	1.6	NA	108	NA	0	0	0
0.3	9	1.8	NA	107	NA	0	0	0
0.3	9.3	1.5	NA	107	171	1	0	0
0.3	9.5	NA	NA	110	NA	0	0	0
0.4	9.4	NA	NA	104	173	0	0	0
0.3	8.9	NA	NA	102	NA	0	0	0
0.3	9.6	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	209	0	0	0
0.4	9.8	NA	NA	101	199	0	0	1
NA	9	NA	NA	100	NA	0	0	1
0.4	9.3	1	NA	100	NA	0	0	1
0.3	NA	NA	NA	100	NA	0	0	1
0.4	9.5	NA	NA	100	NA	0	0	1
0.3	NA	NA	NA	102	NA	0	0	0
1	8.1	86	NA	104	NA	0	0	1
NA	NA	1.3	NA	NA	NA	0	0	1
0.6	10	1.2	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	102	NA	0	0	0
1	9.6	NA	NA	104	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.8	9.4	NA	NA	104	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	105	NA	0	0	1
0.6	9	NA	NA	103	NA	0	0	1
0.9	8.9	NA	NA	103	NA	0	0	1
0.6	9.1	NA	NA	104	NA	0	0	1
0.9	NA	NA	NA	103	NA	0	0	1
1.2	8.8	NA	NA	105	NA	0	0	1
NA	7.8	NA	NA	105	NA	0	0	1
0.8	8.2	NA	NA	105	NA	0	0	1
0.9	8.3	NA	NA	104	NA	0	0	1
0.9	8.3	NA	NA	102	NA	0	0	1
1.1	8.1	NA	NA	103	NA	0	0	1
1.4	7.8	NA	NA	97	NA	0	1	1
0.3	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	8	13	NA	108	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	2.9	NA	NA	NA	0	0	0
NA	NA	1	NA	NA	NA	0	0	0
0.7	NA	NA	NA	101	NA	0	0	0
NA	NA	NA	30	NA	203	0	0	0
NA	NA	1.4	NA	105	NA	0	0	1
0.9	9.6	1.6	17	98	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
NA	10.3	3.2	NA	NA	170	0	0	0
6.9	8	1.9	NA	107	114	0	0	1
1.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
8.9	NA	3	NA	NA	NA	1	0	1
0.3	9.4	7.6	NA	NA	NA	0	0	1
0.2	NA	3.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
1.8	NA	NA	NA	111	NA	0	0	1
2.5	7.7	NA	NA	107	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.6	8.2	NA	NA	108	NA	1	0	1
1.1	8.4	NA	NA	104	NA	1	0	0
1.1	8.6	NA	NA	109	NA	0	0	1
1.1	NA	NA	NA	106	NA	1	0	1
1.6	NA	NA	NA	103	NA	1	0	1
NA	10	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	100	NA	1	0	0
NA	NA	NA	NA	99	NA	1	0	0
0.3	NA	NA	NA	97	NA	1	0	0
0.2	NA	NA	NA	98	NA	1	0	0
0.3	NA	NA	NA	99	NA	1	0	0
0.3	NA	NA	NA	93	231	1	0	0
0.3	NA	NA	NA	100	NA	1	0	0
0.3	NA	NA	NA	100	NA	1	0	0
0.1	NA	NA	NA	NA	NA	1	0	0
0.2	NA	NA	NA	99	NA	1	0	1
0.1	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	1
0.4	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	1
NA	NA	2.5	NA	NA	NA	0	0	0
NA	NA	4.7	NA	NA	NA	0	0	0
0.5	11.1	NA	NA	102	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.4	9.6	1.8	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.4	9.2	1.9	NA	NA	NA	0	0	0
12.8	7.9	118	NA	114	NA	0	0	0
15	7.6	118	NA	105	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	4.3	NA	NA	NA	0	0	0
0.4	NA	4.4	NA	NA	NA	0	0	0
0.4	NA	6.1	NA	NA	NA	0	0	0
0.4	NA	4.6	NA	NA	NA	0	0	0
0.6	NA	4	NA	NA	NA	0	0	0
0.6	NA	4.6	NA	NA	NA	0	0	0
0.6	NA	5.4	NA	NA	NA	0	0	0
0.5	NA	7.2	NA	NA	NA	0	0	0
0.3	9.4	11	NA	NA	NA	0	0	0
0.6	NA	44	NA	NA	NA	0	0	1
0.5	8.9	33	NA	NA	NA	0	0	1
0.4	9.3	29	NA	NA	NA	0	0	0
0.5	9.6	109	NA	NA	NA	0	0	1
NA	NA	64	NA	NA	NA	0	0	1
0.5	9	56	NA	NA	NA	0	0	1
0.4	NA	64	NA	102	NA	0	0	1
0.4	9.2	71	NA	104	NA	0	0	1
0.5	NA	87	NA	NA	NA	0	0	1
0.4	8.6	NA	NA	104	NA	0	0	1
0.5	NA	3.2	NA	NA	NA	0	0	1
0.9	10.1	3.3	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.5	9.7	2.5	NA	101	NA	0	0	1
0.4	NA	33	NA	NA	NA	0	0	1
0.4	9.8	NA	NA	102	144	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	9.3	NA	NA	0	0	0
0.3	9.5	NA	NA	104	254	0	0	0
0.6	10.9	1.2	16	104	NA	0	0	0
NA	9.6	1.3	28	108	NA	0	0	0
NA	NA	3	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.5	11.3	NA	NA	0	0	0
0.2	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	5.6	NA	98	NA	0	0	0
15.9	9.5	2.8	NA	98	NA	0	0	1
4.2	NA	NA	NA	98	NA	0	1	1
0.2	NA	7	NA	NA	NA	0	0	0
0.3	NA	8.4	NA	NA	NA	0	0	0
0.4	NA	7.9	NA	NA	NA	0	0	0
0.4	8.3	8.2	NA	107	NA	0	0	1
0.8	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	4.1	NA	NA	NA	0	0	0
1.2	NA	3.1	NA	NA	NA	0	0	0
1.2	NA	3.3	NA	NA	NA	0	0	0
0.8	9.4	3	NA	NA	NA	0	0	0
1.2	9.5	2.6	NA	NA	NA	0	0	0
0.9	9.6	2.1	NA	NA	NA	0	0	0
1.3	NA	2.4	NA	NA	NA	0	0	0
0.6	NA	3	NA	NA	NA	0	0	0
0.7	NA	4.2	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	1
0.3	NA	7.8	NA	94	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	1	0
3.9	8	5.7	NA	102	NA	0	0	0
0.4	9.6	3.3	NA	104	NA	0	0	0
NA	NA	NA	10	NA	NA	0	0	0
0.5	10.2	2	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.6	NA	NA	NA	0	0	1
NA	NA	1.6	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	NA	3.1	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.4	NA	NA	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	1
0.5	NA	2.4	NA	NA	NA	0	0	1
NA	10	2.4	NA	NA	NA	0	0	1
0.4	9.5	2.9	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.9	4.9	NA	103	NA	0	0	1
NA	NA	6	NA	NA	NA	0	0	1
0.4	9	3.7	NA	NA	NA	0	0	1
13.3	8.2	3.6	NA	102	NA	1	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.7	NA	11	NA	102	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	NA	18	NA	NA	NA	0	0	1
NA	NA	1	7.2	105	224	0	0	0
1.8	NA	1.1	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
4.6	NA	1.3	NA	97	NA	0	0	0
0.4	8.9	3.5	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
3.2	9.3	4.3	NA	104	NA	0	0	0
8.9	9.1	5.5	NA	105	97	0	0	0
5.4	10.5	9	NA	101	119	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	9.4	NA	NA	107	199	0	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.3	7.2	NA	NA	0	0	0
0.7	10	3.7	NA	91	160	0	0	0
NA	9.5	3.2	NA	NA	NA	0	0	0
NA	9.6	4.7	NA	99	NA	0	0	0
NA	NA	4.4	NA	NA	NA	0	0	0
4.3	10.2	NA	NA	100	279	1	0	0
3	NA	NA	NA	101	NA	0	0	0
4.5	9.9	NA	NA	99	NA	0	0	0
7	10.5	2.8	NA	100	NA	0	0	0
5.6	9.6	2.6	NA	101	NA	0	0	0
4.9	NA	2.6	NA	NA	NA	0	0	0
10.2	9.4	NA	NA	102	NA	0	0	0
1.5	8.5	1.9	NA	98	103	0	0	0
0.9	9.5	1.7	NA	97	NA	0	0	0
1.8	9.1	1.8	NA	103	NA	0	0	0
NA	NA	NA	12	NA	NA	0	0	0
0.5	9.2	NA	9.4	105	NA	0	0	0
0.4	NA	NA	14	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	8.2	27	61	100	NA	0	0	0
NA	9.6	2.5	NA	NA	NA	0	0	0
0.2	NA	2.6	NA	NA	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
0.1	NA	2	NA	NA	NA	0	0	0
0.2	NA	2	NA	NA	NA	0	0	0
0.5	9	2	NA	101	NA	0	0	1
0.2	9	1.4	NA	103	NA	0	0	1
0.4	NA	3	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	134	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	291	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	1
0.2	NA	NA	269	NA	NA	0	0	1
0.3	NA	NA	163	NA	NA	0	0	1
0.3	NA	NA	355	NA	NA	0	0	1
1.1	7.7	NA	781	104	NA	0	0	0
0.5	NA	3.4	NA	NA	NA	0	0	0
0.2	NA	3.6	NA	106	NA	0	0	0
1	NA	37	113	104	NA	0	0	1
1	8.9	3.2	NA	102	NA	0	0	0
1	9	2.2	NA	107	NA	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
0.3	9.4	1.6	NA	NA	NA	0	0	1
0.2	NA	1.5	NA	NA	NA	0	0	1
0.3	9.1	1.7	NA	104	NA	0	0	1
NA	9.3	2.4	NA	NA	NA	0	0	0
0.2	9	2.3	NA	NA	NA	0	0	1
NA	9	2.9	NA	NA	NA	0	0	1
0.3	NA	2.9	NA	NA	NA	0	0	1
0.2	9	2.5	NA	NA	NA	0	0	1
NA	8.5	3	NA	105	NA	0	0	1
NA	9	3.4	NA	105	NA	0	0	1
0.2	8.8	3	NA	NA	NA	0	0	1
0.2	9.4	3.3	NA	103	NA	0	0	1
0.2	NA	2.5	NA	NA	NA	0	0	1
0.2	10.4	3.5	NA	105	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	9.1	3.8	NA	104	NA	0	0	1
0.2	9.1	3.9	NA	104	NA	0	0	1
0.1	10.6	4.8	NA	NA	NA	0	0	1
0.2	8.6	5	NA	107	NA	0	0	1
0.2	8.3	6.7	NA	108	NA	0	0	1
0.2	9.1	7.6	NA	106	NA	0	0	1
0.2	8.7	5.8	NA	101	NA	0	0	1
0.3	9.1	5.8	NA	NA	NA	0	0	1
0.3	8.6	3.5	NA	NA	NA	0	0	1
0.3	8.9	2.7	NA	101	NA	0	0	1
0.3	8.6	2.5	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	1
0.4	8.7	2.5	NA	103	NA	0	0	0
0.3	8.6	2.4	NA	NA	NA	0	0	1
0.2	8	2.1	NA	102	NA	0	0	0
0.5	8.4	2.9	NA	NA	NA	0	0	1
0.3	NA	1.8	NA	105	NA	0	0	1
0.4	NA	1.5	NA	NA	NA	0	0	1
0.3	NA	1.4	NA	NA	NA	0	0	1
0.4	8.7	1.6	NA	NA	NA	0	0	1
0.5	8.3	2	NA	NA	NA	0	0	1
0.6	8	2.2	NA	102	NA	0	0	1
1.7	9.3	6.1	NA	105	NA	0	0	1
1.5	NA	8.5	NA	106	NA	0	0	0
17.1	NA	2.4	NA	NA	NA	0	0	1
4.2	NA	2.1	NA	NA	NA	0	0	0
0.8	NA	1.7	NA	NA	NA	1	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	1
NA	9.4	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	75	NA	NA	0	0	1
0.4	NA	410	NA	NA	NA	0	0	1
1.3	8.6	876	NA	97	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1.7	6.7	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	1.7	18	NA	233	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.2	NA	83	NA	NA	NA	0	0	0
0.2	NA	19	NA	NA	NA	0	0	0
0.2	NA	3.2	NA	NA	NA	0	0	0
0.2	9.1	3	NA	NA	NA	0	0	0
0.3	9.7	2.5	14	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
12.6	7.3	NA	NA	104	NA	0	0	0
0.3	9.6	5	12	100	NA	0	0	0
6.1	8.8	5	NA	103	NA	0	0	1
0.3	10.1	NA	NA	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
0.3	8.7	NA	NA	98	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.1	NA	1.2	NA	NA	NA	0	0	0
0.2	9.5	NA	NA	NA	313	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	9.5	1.3	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	9.7	1.3	NA	NA	NA	0	0	0
0.6	9.5	2.2	NA	NA	196	0	0	0
1.1	9.3	NA	NA	101	NA	0	1	1
0.4	NA	NA	NA	107	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	102	NA	0	0	1
1.2	NA	NA	NA	104	NA	1	1	1
0.5	9.4	NA	NA	102	NA	1	0	1
0.2	9.2	NA	NA	104	NA	0	1	1
0.2	NA	NA	NA	106	NA	0	1	1
0.2	9.1	NA	NA	100	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	0
0.5	8.9	2.5	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.7	NA	NA	327	0	0	1
0.5	NA	2.3	NA	NA	NA	0	0	1
0.3	NA	1.4	NA	NA	NA	0	0	0
1	NA	NA	NA	107	NA	0	0	0
0.4	9.2	1.6	NA	NA	NA	0	0	1
0.3	NA	1.4	NA	NA	NA	0	0	1
0.3	NA	1.6	NA	NA	NA	0	0	1
0.4	NA	1.6	NA	NA	NA	0	0	1
0.4	NA	1.2	18	NA	NA	0	0	1
NA	NA	9.3	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	1
1	9.3	131	NA	99	NA	0	0	1
1	9.7	70	NA	106	NA	0	0	1
NA	8.6	3.3	NA	93	NA	0	0	0
0.6	NA	1.7	NA	NA	NA	0	0	0
0.4	9	NA	NA	104	NA	0	0	1
0.2	NA	NA	NA	116	NA	0	0	0
NA	NA	NA	NA	111	NA	0	0	0
0.1	NA	24	21	114	57	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.6	8.1	NA	NA	89	NA	0	0	0
23.3	NA	7	NA	NA	NA	1	0	1
4	NA	11	NA	102	NA	1	0	1
0.9	NA	NA	NA	105	NA	1	0	1
0.7	9.4	NA	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
1.5	NA	NA	NA	NA	NA	0	0	1
1.2	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.6	9.1	NA	NA	NA	NA	0	0	1
0.5	NA	1.1	NA	101	227	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.6	NA	1.6	11	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.6	NA	2	NA	100	NA	0	0	0
NA	10.3	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	NA	1.9	NA	NA	NA	0	0	0
1.1	NA	1.8	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.3	12	99	192	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	4.5	NA	NA	NA	0	0	1
NA	NA	4.6	NA	98	166	0	0	1
NA	NA	5.2	NA	100	166	0	0	0
NA	NA	4.6	NA	102	173	0	0	0
0.3	NA	5.1	NA	103	NA	0	0	0
NA	NA	5.4	NA	102	187	0	0	1
NA	NA	5.6	NA	NA	NA	0	0	1
0.8	NA	3.5	NA	NA	NA	0	0	0
0.8	NA	3.4	NA	NA	NA	0	0	0
0.8	9.3	3.4	NA	NA	NA	0	0	0
0.8	8.8	3.2	NA	NA	NA	0	0	0
1.2	NA	3.3	NA	NA	NA	0	0	0
0.6	8.8	1797	NA	NA	NA	0	0	1
NA	NA	2.9	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
NA	9.7	1.4	NA	NA	NA	0	0	0
0.5	10.3	4.9	25	102	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	98	NA	0	0	1
0.5	9	1.8	NA	99	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
NA	NA	3.9	NA	106	NA	0	0	0
0.3	10.2	1.6	NA	110	NA	0	0	0
0.4	8.9	2.4	NA	98	NA	0	0	1
0.3	9	2.4	NA	NA	NA	0	0	1
NA	8.4	2.4	NA	104	NA	0	0	1
0.3	8.8	4.2	NA	104	NA	0	0	1
0.3	8.7	3.3	NA	105	NA	0	0	1
0.2	8.8	3	NA	101	NA	0	0	0
0.5	8.8	3.2	NA	104	NA	0	0	0
0.5	8.8	3.7	NA	101	NA	0	0	0
0.4	8.7	3.2	NA	104	NA	0	0	1
0.3	8.1	4.2	NA	108	NA	0	0	0
0.4	8.6	4.6	NA	104	NA	0	0	1
0.4	8.7	5.1	NA	103	NA	0	0	1
0.4	8.3	6.7	NA	105	NA	0	0	1
0.2	8.7	8.1	NA	102	NA	0	0	1
0.2	9	16	NA	102	NA	0	0	1
0.2	8.5	17	NA	NA	NA	0	0	1
0.2	8.7	21	NA	NA	NA	0	0	1
0.3	9	25	NA	NA	NA	0	0	1
0.4	8.4	21	NA	NA	NA	0	0	1
0.4	8.7	30	NA	NA	NA	0	0	1
0.3	NA	62	NA	NA	NA	0	0	0
0.3	9.2	70	NA	NA	NA	0	0	1
0.3	8.5	77	NA	NA	NA	0	0	1
0.3	7.9	74	NA	NA	NA	0	0	1
0.5	8.3	76	NA	109	NA	0	0	1
0.3	9	100	NA	NA	NA	0	0	1
0.2	8.6	106	NA	NA	NA	0	0	1
0.2	8.3	104	NA	NA	NA	0	0	1
0.2	8.3	131	NA	NA	NA	0	0	1
0.4	8.3	167	NA	NA	NA	0	0	1
0.4	8.3	187	NA	NA	NA	0	0	1
NA	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	4.6	NA	NA	NA	0	0	0
0.3	NA	3.6	NA	NA	NA	0	0	0
0.5	NA	2.9	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.5	9.6	2.6	NA	101	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	3.5	NA	NA	NA	0	0	0
1	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.9	NA	2.5	NA	NA	NA	0	0	0
0.9	NA	1.9	NA	NA	NA	0	0	0
1.1	NA	NA	NA	97	NA	0	0	0
0.4	9.3	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.7	9.4	4.8	NA	102	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	1	0	0
0.7	NA	1.8	NA	NA	NA	0	0	0
1	NA	2.3	NA	101	NA	0	0	0
NA	7.7	NA	NA	101	NA	0	0	1
24.1	NA	2.5	NA	94	NA	1	0	1
13.2	8.7	NA	NA	95	NA	0	0	1
7.2	8.5	NA	NA	93	NA	1	0	1
0.4	NA	NA	NA	99	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.3	NA	3.5	NA	NA	NA	0	0	0
0.4	NA	3.6	NA	NA	NA	0	0	0
0.3	9.5	3.3	NA	103	269	0	0	0
0.4	NA	3.8	NA	NA	NA	0	0	0
0.3	NA	16	NA	NA	NA	0	0	0
0.3	NA	6.4	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	1
0.3	9.4	2.1	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.3	9.3	2.6	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.3	9	2.8	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
NA	NA	2.9	NA	NA	NA	0	0	0
0.4	NA	6.5	NA	NA	NA	0	0	0
0.3	8.9	1.3	NA	NA	NA	0	0	0
1.5	8	5.9	NA	101	NA	0	0	1
NA	8.2	3.2	NA	114	NA	0	1	1
0.3	8.6	4.6	NA	NA	NA	0	0	1
0.2	8.7	14	NA	103	NA	0	0	1
NA	8.7	130	NA	106	NA	0	0	1
NA	8.7	172	NA	97	NA	0	0	1
0.4	8.1	245	NA	99	NA	0	0	1
1.3	8.3	6.1	NA	100	NA	0	0	1
NA	NA	3.5	17	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	8.9	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	8.4	3.2	NA	NA	NA	0	0	1
NA	8.8	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
2.1	9.3	4.9	NA	104	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	106	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
NA	10.4	1.2	NA	NA	NA	0	0	0
1.4	9.6	3.4	30	104	NA	1	1	1
0.7	NA	3.2	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	9.2	1.6	NA	NA	NA	0	0	0
0.3	NA	1.4	14	NA	NA	0	0	0
0.3	9.7	1.4	NA	106	NA	0	0	0
0.4	9.2	1.7	NA	107	153	0	0	0
0.2	NA	2	NA	NA	NA	0	0	0
0.2	NA	2.1	21	NA	NA	0	0	0
NA	8.9	NA	NA	NA	NA	0	0	0
13.8	8.9	4.8	39	105	NA	0	0	0
1	NA	3.3	NA	NA	NA	0	1	0
0.5	NA	3.9	NA	NA	NA	0	0	0
1.7	8.4	5.1	NA	103	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	4	NA	NA	NA	0	0	0
0.2	NA	4.2	NA	NA	NA	0	0	0
0.4	NA	3.5	NA	NA	NA	0	0	0
0.2	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	3.5	NA	NA	NA	0	0	0
0.2	NA	3.5	NA	NA	NA	0	0	0
4.7	NA	2.3	NA	104	NA	1	0	0
NA	NA	2.2	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	232	0	0	0
0.6	NA	1.6	NA	NA	NA	0	0	0
0.1	7.5	NA	NA	95	NA	0	0	0
0.3	7	8.7	51	105	NA	0	0	0
0.6	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	5.6	NA	NA	0	0	0
0.6	NA	NA	7	NA	NA	0	0	0
NA	NA	1.7	NA	103	178	0	0	0
NA	NA	2	NA	103	NA	0	0	0
NA	9.7	3	NA	107	157	0	0	0
0.2	NA	2.8	NA	NA	NA	0	0	0
NA	9.7	2.7	NA	100	161	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	3.1	NA	NA	NA	0	0	0
NA	10.5	3.2	NA	102	172	0	0	0
0.3	NA	3.2	NA	NA	NA	0	0	0
0.2	9	4.4	NA	116	NA	0	0	0
NA	NA	1	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	38	NA	NA	0	1	1
0.2	NA	NA	31	NA	NA	0	1	1
0.2	NA	NA	38	101	NA	0	0	0
0.2	NA	2.6	60	105	NA	0	1	1
0.2	NA	4.4	92	NA	NA	0	1	1
0.2	NA	NA	101	104	NA	0	1	1
0.2	9.1	13	184	102	NA	0	1	1
0.2	10	27	304	102	NA	0	1	1
0.2	NA	16	288	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.2	NA	2.1	9.9	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
NA	NA	1.4	12	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.1	12	NA	NA	0	0	0
0.5	9.1	6.8	NA	101	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	9.5	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	5.6	NA	NA	NA	0	0	0
0.2	NA	7.4	NA	NA	NA	0	0	0
0.2	NA	7	2.5	NA	NA	0	0	0
0.4	NA	6.3	NA	NA	NA	0	0	0
0.4	NA	5.9	NA	NA	NA	0	0	0
0.2	NA	5.5	NA	NA	NA	0	0	0
0.3	NA	5.8	NA	NA	NA	0	0	0
0.1	NA	2.1	NA	NA	NA	0	0	0
0.2	NA	2	NA	NA	NA	0	0	0
0.2	9.9	1.8	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	10.9	3.1	NA	94	NA	0	0	0
0.5	8.8	NA	NA	100	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.5	9.2	NA	NA	102	NA	0	0	1
3	8.9	12	NA	106	NA	0	0	0
NA	9.7	NA	NA	102	221	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.7	NA	2.7	NA	NA	NA	0	0	0
0.5	NA	3.4	NA	NA	NA	0	0	0
NA	8.8	4.5	NA	106	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	4	15	103	NA	0	0	0
0.8	NA	4.2	NA	NA	NA	0	0	1
0.3	NA	4.2	NA	NA	NA	0	0	1
0.5	NA	4.3	NA	NA	NA	0	0	1
0.5	NA	3.2	NA	NA	NA	0	0	1
0.3	NA	2.7	NA	NA	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	0
NA	9.6	2.8	NA	106	196	0	0	0
0.5	NA	3.2	NA	106	240	0	0	0
NA	NA	2.7	NA	NA	253	0	0	0
NA	NA	NA	15	NA	NA	0	0	1
NA	9.7	NA	NA	NA	195	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
2.2	8.8	2.1	NA	93	NA	0	0	1
1.7	NA	NA	NA	NA	NA	0	0	1
0.4	9.7	3.1	NA	101	NA	0	0	0
0.5	NA	2.4	NA	100	NA	0	0	0
1	NA	NA	NA	104	NA	0	0	1
6.4	8.7	7.4	NA	99	NA	0	0	1
1.2	9.2	NA	NA	105	NA	0	0	0
NA	NA	NA	NA	104	NA	0	0	0
NA	NA	1.9	17	NA	NA	0	0	0
0.4	NA	3.8	NA	NA	NA	0	0	0
0.3	9.5	2	NA	107	NA	0	0	0
0.3	NA	1.9	NA	NA	204	0	0	0
0.6	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.5	10.1	1.7	NA	104	177	0	0	0
0.3	8.7	2.2	9.3	98	NA	0	0	1
0.4	NA	1.8	NA	NA	NA	0	0	0
7.1	8.3	NA	NA	104	NA	1	0	1
1.3	8.8	NA	NA	103	NA	1	0	1
0.3	8.9	NA	NA	105	NA	0	0	1
0.3	8.9	NA	NA	105	NA	0	0	1
0.2	9.6	NA	NA	103	NA	0	0	1
0.2	NA	NA	NA	104	NA	0	0	1
0.2	NA	NA	NA	102	NA	0	0	1
0.3	9.1	NA	NA	105	NA	0	0	1
0.3	9.4	NA	NA	106	NA	0	0	1
0.2	9.1	NA	NA	103	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	8.8	NA	NA	103	NA	0	0	1
0.2	NA	NA	NA	106	NA	0	0	1
0.2	NA	NA	NA	107	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.6	8.6	NA	NA	106	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.7	9.7	NA	NA	109	NA	0	0	1
0.7	9.6	4.8	NA	99	NA	0	1	1
2	8.7	3.2	NA	105	NA	1	0	1
0.6	NA	NA	NA	109	NA	0	0	0
0.8	8.2	NA	NA	94	NA	0	0	1
1.7	NA	2.2	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	232	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.7	NA	1.2	NA	NA	NA	0	0	1
NA	NA	5.8	NA	NA	NA	0	0	1
0.3	9.1	NA	NA	100	NA	0	0	0
0.4	NA	8.7	NA	NA	NA	0	0	1
0.5	NA	5.9	NA	NA	NA	0	0	1
0.5	NA	4.1	NA	NA	NA	0	0	0
0.5	10.4	80	NA	NA	NA	0	0	1
3.5	9.8	353	NA	NA	NA	0	0	1
1.1	NA	NA	NA	103	630	0	0	0
8.2	11.2	583	NA	100	NA	0	0	1
0.3	NA	3.3	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
NA	9.7	2	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.6	8.6	6.9	NA	106	NA	0	0	0
0.4	8.8	NA	NA	106	NA	0	0	1
0.5	NA	1.6	NA	NA	NA	0	0	0
NA	9.9	1.6	NA	NA	NA	0	0	0
0.4	9.3	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	107	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
1.1	9.3	NA	NA	NA	NA	0	0	0
0.5	NA	146	NA	90	NA	0	0	1
5.4	8.2	44	NA	94	89	0	0	0
16.8	8.1	18	502	105	NA	0	0	0
0.6	NA	2.9	NA	NA	NA	0	0	0
0.6	NA	2.4	NA	NA	NA	0	0	0
0.6	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
NA	9.5	1.5	NA	100	242	0	0	0
NA	NA	1.6	NA	NA	182	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
NA	9.4	1.7	NA	102	188	0	0	0
NA	9.5	1.3	NA	102	203	0	0	0
3	8.3	3.5	NA	NA	NA	0	0	0
0.2	NA	1	NA	NA	NA	0	0	0
NA	9.4	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.2	NA	3.6	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.3	NA	3.7	NA	NA	NA	0	0	0
0.3	NA	3.9	NA	NA	NA	0	0	0
4.1	NA	14	NA	98	NA	0	0	1
NA	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.4	9.6	2.6	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	9.1	NA	NA	109	NA	0	0	1
0.5	9.1	NA	NA	103	NA	1	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	199	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
5.3	8.5	2.4	21	104	NA	0	0	1
0.4	NA	2.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	1	0	1
0.4	NA	NA	NA	NA	NA	1	0	1
2.2	NA	NA	NA	NA	NA	1	0	1
0.3	NA	NA	NA	NA	NA	1	0	1
0.5	8.9	2.4	NA	NA	NA	0	0	1
NA	NA	4.5	NA	NA	NA	0	0	1
NA	NA	5.8	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.6	9.4	NA	NA	103	NA	0	1	1
1.3	NA	NA	NA	101	NA	0	0	1
0.4	9.3	NA	NA	104	NA	0	1	1
0.6	8.1	NA	NA	106	NA	0	1	1
NA	NA	6	NA	NA	NA	0	1	1
0.5	NA	5.1	NA	NA	NA	0	0	1
0.6	NA	5.7	NA	NA	NA	0	0	1
0.4	NA	6.3	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
2.2	8.5	NA	NA	103	NA	1	0	1
1.1	9.2	NA	NA	104	NA	0	0	1
0.4	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
21.6	7.6	2.6	NA	97	NA	0	0	1
18.7	9.3	48	NA	102	NA	0	0	1
6.4	NA	7.4	NA	97	NA	0	0	1
0.5	NA	3.4	NA	NA	NA	0	0	0
NA	9.5	3.4	NA	104	169	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.5	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1.6	12	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.3	8.6	1.1	NA	110	NA	0	0	0
0.3	9.1	1.2	NA	100	NA	0	0	0
1.4	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	240	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.2	9	NA	NA	0	0	0
0.5	9.6	2.2	NA	NA	NA	0	0	0
0.5	10.4	2.4	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	108	186	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
3.7	8.8	5.3	NA	103	NA	0	0	0
NA	NA	NA	NA	102	NA	0	0	0
1.1	9.1	2.6	NA	100	228	0	0	0
1.1	8.8	NA	NA	100	NA	0	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
1.1	NA	NA	NA	102	NA	0	0	0
0.8	NA	NA	NA	NA	NA	1	0	0
0.7	NA	NA	NA	101	NA	0	0	0
1.1	NA	NA	NA	101	NA	1	0	0
0.5	NA	NA	NA	102	NA	1	0	0
0.8	NA	NA	NA	NA	NA	1	0	0
0.8	8.8	1.1	NA	101	NA	1	0	0
0.7	NA	NA	NA	102	NA	1	0	0
0.4	NA	2	5.4	NA	NA	0	0	0
NA	NA	2.2	NA	NA	181	0	0	0
0.3	NA	2.7	9.6	NA	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	3.1	NA	NA	NA	0	0	0
0.5	NA	3	9.4	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
NA	NA	2.2	8.5	NA	NA	0	0	0
0.2	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	2.4	8.3	NA	NA	0	0	0
NA	7.9	NA	225	104	NA	0	0	1
0.5	NA	7.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	96	NA	0	0	0
NA	8.9	4.9	NA	107	NA	0	0	1
0.4	NA	2	NA	99	NA	0	0	0
0.4	NA	5.2	NA	NA	NA	0	0	1
NA	NA	5.1	NA	NA	NA	0	0	1
0.6	NA	7.1	NA	103	200	0	0	1
7.5	9.1	NA	NA	104	NA	0	0	0
4.1	9.8	11	NA	104	NA	1	0	1
2	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.1	NA	NA	NA	104	NA	0	0	0
0.4	8.8	NA	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
13.6	10	2.4	NA	103	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	105	173	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	102	215	0	0	1
0.5	9.9	NA	NA	105	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	103	NA	0	0	0
0.4	NA	NA	NA	102	NA	0	0	0
0.5	NA	NA	NA	102	143	0	0	0
0.4	NA	NA	NA	107	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	165	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	132	207	NA	NA	0	1	0
0.3	NA	3.3	NA	104	NA	0	0	0
0.5	9.4	1.8	NA	108	232	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
2.5	NA	NA	NA	110	NA	0	0	1
0.4	8.8	3.8	NA	100	NA	0	0	0
0.9	NA	1.6	NA	NA	NA	0	0	0
0.9	NA	1.4	NA	NA	NA	0	0	0
0.9	NA	2	NA	NA	NA	0	0	0
0.9	NA	21	NA	NA	NA	0	0	1
0.9	9.9	25	NA	NA	NA	0	0	1
1.1	NA	12	NA	NA	NA	0	0	1
1.7	9.5	2.4	NA	NA	NA	0	0	1
2.4	NA	1.9	NA	NA	NA	0	0	1
1.8	NA	1.5	NA	NA	NA	0	0	1
2	9.4	1.2	NA	NA	NA	0	0	1
1.7	NA	1.2	NA	NA	NA	0	0	0
1.8	9.1	2.1	NA	NA	NA	0	0	0
1.3	9	1.6	NA	NA	NA	0	0	0
1.3	9.3	1.7	NA	NA	NA	0	0	0
1.3	NA	1.8	NA	NA	NA	0	0	0
2.1	9.8	1.8	NA	NA	NA	0	0	0
1.9	NA	1.8	NA	NA	NA	0	0	0
2.1	9.9	1.9	NA	NA	NA	0	0	0
2.4	NA	2.5	NA	NA	NA	0	0	0
1.4	NA	2.4	NA	NA	NA	0	0	0
1	9.3	2.6	NA	NA	NA	0	0	0
1.7	9.4	2.9	NA	NA	NA	0	0	0
1.6	NA	2.9	NA	NA	NA	0	0	0
1.9	NA	2.7	NA	NA	NA	0	0	0
0.9	NA	2.6	NA	NA	NA	0	0	0
1.4	NA	2.9	NA	NA	NA	0	0	0
1.3	NA	2.7	NA	NA	NA	0	0	0
2.3	NA	3.2	NA	NA	NA	0	0	0
1.2	NA	3	NA	NA	NA	0	0	0
1.5	NA	2.8	NA	NA	NA	0	0	0
1.2	NA	2.8	NA	NA	NA	0	0	0
8.8	9.2	1	NA	99	NA	1	1	1
0.9	NA	NA	NA	100	NA	0	0	0
2.1	NA	2.9	NA	104	NA	0	0	1
1.9	NA	NA	NA	98	NA	0	0	0
1.4	NA	NA	NA	NA	NA	0	0	0
1.3	9.9	NA	NA	NA	NA	0	0	1
0.7	9.6	NA	NA	99	NA	0	0	0
0.6	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.1	NA	NA	254	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.8	NA	1.2	NA	NA	NA	0	0	0
0.8	NA	1	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
0.3	8.4	NA	NA	98	NA	0	1	0
0.4	9.4	14	NA	NA	NA	0	1	0
0.3	NA	21	NA	NA	NA	0	1	0
0.4	9.6	28	NA	NA	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	1	0
0.1	NA	NA	NA	98	NA	0	1	0
1.6	NA	NA	NA	NA	NA	0	1	0
0.4	9.1	2.4	NA	100	NA	0	0	1
0.2	NA	2.2	NA	NA	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
0.3	9.2	1.9	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	5.4	NA	98	NA	0	0	0
NA	NA	NA	NA	101	NA	0	0	0
NA	9.3	3.8	NA	105	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	99	193	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	104	192	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
2.3	9	17	NA	89	69	0	0	0
0.8	10.9	1.6	NA	103	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	1
0.3	NA	1.5	NA	NA	NA	0	0	1
0.3	NA	1.5	NA	NA	NA	0	0	1
0.4	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	1
0.4	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.4	NA	3.2	NA	NA	NA	0	0	0
0.3	NA	4.4	NA	NA	NA	0	0	0
0.2	NA	4.3	NA	NA	NA	0	0	0
0.4	NA	5.4	NA	NA	NA	0	0	0
0.4	NA	5.1	NA	NA	NA	0	0	0
0.6	NA	5.3	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.8	7.7	174	NA	117	NA	0	0	1
2.1	8.1	4.6	NA	105	NA	0	0	0
1.4	NA	3.5	NA	103	NA	0	0	0
0.6	NA	4.6	NA	101	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.1	NA	NA	NA	NA	157	0	0	0
1.9	NA	NA	NA	NA	152	0	0	0
1.2	9.1	NA	NA	NA	139	0	0	0
NA	9.9	NA	NA	100	NA	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.9	8.4	2.1	NA	103	NA	0	0	0
NA	NA	3.9	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
1.1	8.8	NA	NA	NA	NA	0	0	0
NA	NA	99	3702	100	NA	0	0	1
0.4	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	3	NA	NA	NA	0	0	0
0.6	NA	2.9	NA	NA	NA	0	0	0
0.6	NA	3.2	NA	NA	NA	0	0	0
NA	NA	3.4	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
35.1	NA	3.1	NA	NA	NA	1	0	1
0.3	9.1	1.8	NA	NA	NA	0	0	0
0.4	NA	5.1	NA	NA	NA	0	0	0
0.5	NA	5.4	NA	NA	NA	0	0	0
0.5	NA	6.2	NA	NA	NA	0	0	0
0.5	9.3	4.7	NA	NA	NA	0	0	0
0.5	9	4.9	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.4	NA	3.9	NA	NA	NA	0	0	0
0.5	NA	4.2	NA	NA	NA	0	0	0
0.9	NA	8.2	NA	NA	NA	0	0	0
0.8	NA	12	NA	103	NA	0	0	0
NA	NA	14	NA	NA	NA	0	0	0
NA	NA	22	NA	NA	NA	0	0	0
NA	9.4	1.7	NA	103	NA	0	0	0
NA	9.2	1.9	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	102	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
6.5	NA	24	NA	100	221	0	0	1
3	8.6	NA	NA	105	NA	0	0	1
2.3	NA	NA	275	101	NA	0	0	1
1.7	NA	7.6	140	98	NA	0	0	1
1.6	NA	NA	NA	101	NA	0	0	1
1	NA	NA	NA	100	NA	0	0	1
1.4	NA	NA	129	104	NA	0	0	0
0.8	NA	NA	110	105	NA	0	0	1
0.4	NA	NA	NA	103	NA	0	0	0
0.6	9.5	3.5	NA	105	NA	0	0	1
NA	9.3	NA	NA	102	NA	0	0	0
0.6	9.8	NA	NA	100	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	139	0	0	0
0.3	7.4	33	NA	108	NA	0	0	1
0.6	NA	1.9	17	103	129	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	1
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
7.2	NA	4.6	NA	NA	NA	1	0	1
0.3	NA	NA	NA	102	NA	0	0	0
0.3	NA	5477	NA	92	NA	0	0	1
1.1	NA	13167	NA	NA	NA	0	0	1
0.3	NA	NA	NA	102	NA	0	0	0
0.6	8.5	NA	NA	92	NA	0	0	1
0.6	NA	2.4	NA	NA	NA	0	0	0
0.8	8.9	5.7	NA	105	NA	1	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	102	NA	0	0	0
0.5	NA	NA	NA	102	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.5	9.3	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	100	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.9	NA	NA	NA	99	NA	1	0	0
6.4	NA	2.1	NA	101	NA	1	0	1
8.5	9.8	NA	NA	101	NA	0	1	1
0.6	NA	NA	NA	100	135	0	0	1
0.6	NA	NA	NA	NA	204	1	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
1	NA	NA	NA	NA	NA	0	0	0
0.8	9	NA	NA	103	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	100	NA	0	0	0
0.6	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.6	NA	NA	NA	NA	NA	1	0	0
2.7	NA	NA	NA	95	NA	1	0	0
0.6	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
1.4	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.8	NA	NA	NA	NA	NA	1	0	0
0.6	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	NA	306	57	97	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	9.8	1.6	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.5	10.2	2	NA	NA	NA	0	0	0
0.2	9.7	2	NA	NA	NA	0	0	0
NA	9.7	NA	NA	NA	NA	0	0	0
0.4	8.6	1.2	907	94	NA	0	0	0
7	8.8	47	NA	97	NA	0	0	1
13.1	9.1	NA	NA	95	NA	0	1	1
NA	9.5	2	NA	99	233	0	0	1
1.2	8.9	NA	NA	105	NA	0	0	0
0.6	9.1	2.1	NA	104	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	9.4	NA	NA	104	NA	0	0	1
0.4	9.2	NA	NA	103	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.3	8.8	NA	7.7	NA	NA	0	0	0
0.6	10.2	NA	NA	98	NA	0	0	1
NA	NA	1.2	NA	NA	NA	0	0	0
0.6	NA	1.9	NA	103	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	1	0	0
0.7	NA	1.2	NA	102	NA	0	0	0
0.4	8.6	15	NA	100	NA	0	0	1
0.3	9.1	15	NA	98	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	9.5	NA	NA	99	NA	0	0	1
0.1	9.3	NA	NA	98	NA	0	0	1
0.2	NA	NA	NA	102	NA	0	0	1
0.2	9.2	NA	NA	101	NA	0	0	1
NA	NA	NA	NA	99	NA	0	0	1
0.2	9.7	NA	NA	97	NA	0	0	1
0.2	9	NA	NA	105	NA	0	0	1
0.4	NA	NA	NA	100	NA	0	0	1
0.4	9.4	NA	NA	102	NA	0	0	1
0.3	9.5	NA	NA	104	129	0	0	1
0.5	9.5	NA	NA	104	129	0	0	1
0.5	9.1	NA	NA	105	NA	0	0	1
0.5	NA	NA	NA	103	NA	0	0	1
0.5	NA	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	102	NA	0	0	1
0.4	9.5	NA	NA	101	NA	0	0	1
0.3	8.9	NA	NA	100	NA	0	0	1
0.3	9.1	NA	NA	103	NA	0	0	1
0.4	NA	NA	NA	103	NA	0	0	1
0.4	9	NA	NA	101	NA	0	0	1
0.4	9.4	NA	NA	101	NA	0	0	1
0.5	9.3	NA	NA	104	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	8.7	NA	NA	100	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.7	8.9	NA	NA	102	NA	0	0	1
0.3	8.6	NA	NA	103	NA	0	0	1
0.3	8.2	NA	NA	105	NA	0	0	1
0.5	8.4	NA	NA	102	NA	0	0	1
0.5	8.8	NA	NA	102	NA	0	0	1
0.6	8.3	NA	NA	105	NA	0	0	1
0.5	8.2	NA	NA	104	NA	0	0	1
0.6	9.2	45	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
30.8	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1	NA	7.6	NA	NA	NA	0	0	1
NA	NA	10	NA	NA	NA	0	0	1
1	NA	5.9	NA	NA	NA	0	0	1
1.5	NA	7.1	NA	NA	NA	0	0	1
0.9	NA	16	NA	NA	NA	0	0	1
0.9	NA	NA	431	NA	NA	0	0	1
NA	9.8	35	NA	NA	NA	0	0	1
1.3	NA	33	NA	NA	NA	0	0	1
1.3	NA	20	NA	NA	NA	0	0	1
1.4	NA	11	NA	NA	NA	0	0	1
2.5	NA	9.1	NA	NA	NA	0	0	1
1.3	NA	6.3	NA	NA	NA	0	0	1
NA	NA	6.4	NA	NA	NA	0	0	1
1.6	NA	7.4	NA	NA	NA	0	0	1
1.2	NA	6.4	58	NA	NA	0	0	1
1.2	NA	5.5	NA	NA	NA	0	0	1
1.2	NA	6	NA	NA	NA	0	0	1
1.1	NA	6.6	NA	NA	NA	0	0	1
1.5	NA	8.1	NA	NA	NA	0	0	1
1.1	NA	12	NA	NA	NA	0	0	1
0.9	NA	9.8	NA	NA	NA	0	0	1
1.2	9.3	6.1	NA	106	NA	0	0	1
1.2	NA	7.2	NA	NA	NA	0	0	1
1	8.8	7.8	NA	98	141	0	0	1
1.3	9.4	8.7	NA	95	140	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	1
0.4	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.8	23	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	214	0	0	1
0.5	NA	1.4	NA	95	NA	0	0	1
NA	NA	NA	12	94	NA	0	0	0
0.7	8.8	3.8	NA	106	NA	0	0	0
0.4	9.6	NA	18	NA	NA	0	0	0
0.4	NA	NA	26	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	3.5	NA	NA	NA	0	0	0
1	8.4	1.3	NA	99	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
0.4	10.1	1.7	NA	NA	NA	0	0	0
0.3	9.1	NA	NA	101	NA	0	0	0
0.3	NA	1.3	6.8	100	NA	0	0	0
0.3	NA	1.5	17	103	NA	0	0	0
0.5	9.3	NA	NA	97	NA	0	0	0
0.3	9.3	NA	NA	95	NA	0	0	0
0.2	8.7	NA	NA	102	NA	0	0	0
0.3	11.6	NA	NA	95	NA	0	0	1
0.3	8.9	NA	185	104	NA	0	0	1
0.7	8.1	NA	356	103	NA	0	0	1
0.3	9.5	NA	238	102	NA	0	0	1
0.5	9.2	3.3	259	100	NA	0	0	1
0.6	NA	3.6	568	101	NA	0	0	1
0.8	8.9	11	NA	NA	NA	0	0	0
NA	9.7	1.6	NA	107	NA	0	0	0
NA	8.6	1.9	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	4.9	NA	NA	NA	0	0	0
0.3	NA	3.9	NA	NA	NA	0	0	0
0.3	9.4	4.1	NA	NA	NA	0	0	0
0.2	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
NA	8.7	1.5	NA	102	NA	0	0	0
4.4	7.1	NA	NA	110	NA	0	0	1
0.6	8.7	2.2	NA	107	NA	0	0	0
NA	9.4	1.4	NA	100	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
0.4	9.3	2.7	NA	103	NA	0	0	1
0.6	NA	NA	NA	99	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	9.2	NA	NA	104	NA	0	0	0
0.5	8.8	NA	NA	109	NA	0	0	0
1	NA	NA	NA	107	NA	0	0	0
0.5	NA	NA	NA	105	NA	0	0	0
1.3	9.5	NA	NA	NA	NA	0	0	0
0.6	9.9	5.8	NA	NA	NA	0	0	1
0.4	NA	NA	NA	100	NA	0	0	1
0.3	NA	NA	NA	102	NA	0	0	1
0.3	NA	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	101	NA	0	0	1
0.3	NA	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	8.8	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.3	NA	NA	101	NA	0	0	1
0.3	NA	1.1	NA	NA	NA	0	0	0
6.9	8.4	2.8	NA	106	NA	0	0	0
0.5	9.8	NA	NA	104	137	0	0	0
0.6	NA	2	NA	102	NA	0	0	0
NA	9.2	1.7	109	102	NA	0	0	0
0.8	NA	2	NA	NA	NA	0	0	0
1	NA	2.5	NA	NA	NA	0	0	0
1.6	11.4	3.2	NA	97	NA	0	1	0
NA	NA	4.6	NA	91	NA	0	1	1
0.7	7.4	2.6	NA	106	NA	0	0	0
1.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	9.2	1.1	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	9.6	NA	NA	103	NA	0	0	0
4.9	8.9	11	NA	89	181	0	0	1
6.3	8.7	12	NA	89	148	0	0	0
NA	9.3	2.1	NA	102	195	0	0	0
NA	9.2	2.3	NA	NA	NA	0	0	0
NA	9.4	2.1	NA	103	198	0	0	0
NA	10.2	2.1	NA	101	224	0	0	0
2.7	9	2.3	NA	102	NA	0	0	1
0.3	NA	127	NA	NA	NA	0	0	0
0.4	NA	70	NA	NA	NA	0	0	1
0.7	NA	24	NA	NA	NA	0	0	1
0.7	NA	17	NA	NA	NA	0	0	1
0.6	NA	14	NA	NA	NA	0	0	1
0.6	NA	11	NA	NA	NA	0	0	1
1	10.1	11	NA	98	167	0	0	1
0.6	NA	9	NA	NA	NA	0	0	1
0.4	NA	8.2	NA	NA	NA	0	0	0
0.7	NA	6.2	NA	NA	NA	0	0	0
0.7	NA	4.9	NA	NA	NA	0	0	0
0.6	NA	4.1	NA	NA	NA	0	0	0
0.6	NA	4.4	NA	NA	NA	0	0	1
0.3	NA	4.4	NA	NA	NA	0	0	0
0.3	NA	4.2	NA	NA	NA	0	0	0
0.5	NA	5.5	NA	NA	NA	0	0	0
0.6	NA	5.4	NA	NA	NA	0	0	1
NA	NA	5.5	NA	NA	NA	0	0	1
0.8	NA	6.7	NA	NA	NA	0	0	1
0.4	NA	6.7	NA	NA	NA	0	0	0
0.6	NA	8.7	NA	NA	NA	0	0	0
0.6	NA	8.4	NA	NA	NA	0	0	0
0.7	NA	10	NA	NA	NA	0	0	0
0.6	NA	9.8	NA	NA	NA	0	0	1
0.2	NA	11	NA	NA	NA	0	0	0
0.6	NA	12	NA	NA	NA	0	0	0
0.5	NA	16	NA	NA	NA	0	0	0
0.6	NA	16	NA	NA	NA	0	0	0
NA	NA	17	NA	NA	NA	0	0	0
0.5	10.1	20	NA	NA	NA	0	0	0
0.5	9.8	23	NA	NA	NA	0	0	0
0.3	NA	34	NA	NA	NA	0	0	0
0.5	9.4	38	NA	103	NA	0	0	1
0.3	9.4	31	NA	NA	NA	0	0	1
0.3	9.6	33	NA	NA	NA	0	0	1
0.3	9.2	43	NA	NA	NA	0	0	0
0.5	9.8	53	NA	NA	NA	0	0	0
0.3	8.8	53	NA	NA	NA	0	0	0
0.3	9.6	59	NA	NA	NA	0	0	0
0.2	9.1	53	NA	108	NA	0	0	0
0.3	NA	57	NA	NA	NA	0	0	1
0.3	9.5	45	NA	100	NA	0	0	0
0.8	8.2	NA	NA	109	NA	0	0	1
1.2	NA	9	25	NA	NA	0	0	1
NA	8.5	11	NA	102	NA	0	1	1
NA	NA	14	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
26.4	NA	5.8	NA	95	NA	1	0	1
2.8	9.4	NA	NA	90	NA	0	0	1
2.1	9.1	NA	NA	91	121	0	1	1
20.6	10.5	NA	NA	111	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
0.2	NA	2.7	NA	NA	NA	0	0	0
0.3	10.3	3	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	102	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.3	12	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
0.5	8.8	97	NA	104	147	0	0	1
0.4	NA	3.7	NA	103	NA	0	0	0
0.5	NA	4.1	NA	NA	NA	0	0	0
1.1	8.5	1.6	NA	103	NA	0	0	0
NA	NA	1.7	NA	100	NA	0	0	0
1.3	8.5	1.4	NA	102	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.4	10	NA	NA	101	208	0	0	1
0.5	9.5	NA	NA	107	NA	1	0	1
0.4	9.1	NA	NA	101	NA	0	0	1
0.3	9.4	1.9	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
NA	NA	1	NA	NA	NA	0	0	0
0.4	9.7	1.1	NA	102	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1.9	NA	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	5.3	NA	NA	NA	0	0	0
0.4	NA	6.7	NA	NA	NA	0	0	0
NA	NA	8.1	NA	NA	NA	0	0	0
NA	NA	9.3	NA	NA	NA	0	0	0
0.3	9.4	15	NA	106	NA	0	0	0
NA	NA	27	NA	NA	NA	0	1	1
0.5	NA	NA	NA	103	NA	0	0	0
0.4	NA	NA	NA	101	NA	0	0	0
6.5	8.7	NA	NA	107	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	3	NA	NA	NA	0	0	0
NA	9.3	2.1	NA	106	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	1
0.6	NA	2.1	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	1
0.6	NA	1.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.5	8.5	3.3	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
NA	NA	3.1	33	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
28.6	9.1	NA	NA	101	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	0
2.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	105	121	0	0	0
0.3	NA	NA	NA	114	113	0	0	0
0.3	9.7	3.2	NA	NA	NA	0	0	0
0.3	9.2	2.3	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.5	NA	3	NA	NA	228	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	1
NA	9.6	3.3	NA	103	NA	0	0	1
0.3	NA	2.4	NA	NA	NA	0	0	1
NA	NA	3.3	NA	NA	NA	0	0	1
0.2	9	3.2	NA	102	NA	0	0	1
0.3	NA	2.6	NA	NA	NA	0	0	1
0.3	NA	2.6	NA	NA	NA	0	0	0
0.2	NA	3.9	NA	NA	NA	0	0	0
NA	9.3	3.2	NA	NA	194	0	0	0
0.2	NA	3.1	NA	NA	NA	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
NA	9.3	3.5	NA	NA	182	0	0	0
0.6	NA	3.6	NA	NA	NA	0	0	0
0.5	9.1	2.8	NA	101	NA	0	0	0
0.4	8.4	51	NA	105	NA	0	0	1
0.6	8.4	16	NA	107	NA	0	0	0
0.9	8.6	10	NA	108	NA	0	0	1
3.5	8.8	1.7	NA	101	NA	0	0	1
0.3	NA	1	NA	106	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.5	NA	4.7	NA	NA	NA	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	3.7	NA	NA	NA	0	0	0
0.5	NA	3.1	NA	NA	NA	0	0	0
0.5	NA	NA	7	NA	NA	0	0	0
0.4	NA	3.6	NA	NA	NA	0	0	0
NA	8.4	3	NA	99	NA	0	0	0
0.3	7.2	2.3	NA	111	NA	0	0	0
0.7	9	2.2	NA	114	133	0	0	0
NA	9.8	64	NA	105	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.2	NA	2	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
NA	NA	NA	16	NA	NA	0	0	0
0.4	9.6	27	NA	102	NA	0	0	1
0.2	9.3	42	NA	100	NA	0	0	1
0.3	8.9	48	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	7.3	NA	NA	113	NA	0	0	0
1.9	8.7	3.9	NA	94	NA	0	0	0
2	NA	2.2	NA	100	NA	0	0	1
1.9	8.7	3.4	NA	98	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	152	0	0	0
18.3	NA	4.6	NA	NA	NA	1	0	1
0.9	NA	3.7	NA	NA	NA	0	0	0
0.4	9.1	2.7	NA	103	182	0	0	0
1.2	7.3	1.8	NA	107	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.3	9	1.6	22	NA	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
NA	9.6	NA	1694	98	NA	0	0	0
0.4	8.9	NA	46	100	NA	0	0	0
9.7	8	4.1	NA	107	NA	1	0	0
0.4	9.2	4.6	250	104	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	199	0	1	1
0.8	9.7	6.9	NA	NA	NA	0	1	1
0.5	NA	NA	24	NA	NA	0	0	0
0.6	NA	NA	19	NA	204	0	0	0
0.6	NA	NA	78	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	36	NA	NA	0	0	0
0.6	NA	1.6	NA	101	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
2.8	8.7	NA	NA	102	171	0	0	1
0.1	8.4	2.3	NA	113	NA	0	0	0
1.6	NA	2	NA	102	NA	0	1	1
3.1	8.8	6.3	45	103	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	11	103	NA	0	0	0
0.4	8.5	128	NA	87	NA	0	0	0
0.4	NA	NA	NA	100	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
0.6	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	1.1	NA	NA	NA	0	0	0
0.8	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	1.8	NA	NA	NA	0	0	0
0.5	9.7	1.6	NA	102	NA	0	0	0
0.8	NA	2	NA	NA	NA	0	0	0
0.6	9.8	1.5	NA	102	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
2.5	9.4	1.5	NA	104	151	0	0	0
0.3	NA	3.4	NA	109	NA	0	0	0
0.6	7.7	NA	NA	107	NA	0	0	0
5.8	9.1	9.5	NA	95	NA	0	0	1
2.2	8.2	5.3	NA	105	65	0	0	1
8.5	8.6	15	NA	101	NA	0	0	1
0.8	9.2	2	NA	NA	NA	0	0	1
NA	7.5	NA	NA	111	NA	0	0	1
0.8	9	NA	NA	106	NA	0	0	1
0.3	NA	5.3	NA	109	NA	0	1	1
NA	NA	4	NA	110	NA	0	0	1
0.2	NA	5	NA	NA	NA	0	0	1
NA	NA	7.6	NA	NA	NA	0	0	1
NA	NA	11	NA	NA	NA	0	0	1
0.4	NA	11	NA	102	NA	0	0	1
NA	8.3	7.2	NA	115	NA	0	0	1
NA	8.3	8.1	NA	111	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	6.3	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1	NA	NA	NA	0	0	0
1.1	NA	3	10	NA	NA	0	0	0
NA	NA	37	NA	NA	NA	0	0	0
0.3	9.2	NA	NA	98	NA	0	0	0
NA	NA	NA	NA	100	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	7.9	3	NA	98	91	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	16	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.6	NA	1.3	21	NA	NA	0	0	0
0.6	NA	1	NA	NA	NA	0	0	0
5.5	8.4	6	NA	108	97	0	0	0
12.4	9.4	3	NA	103	35	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
9.4	NA	NA	NA	NA	NA	1	0	1
5.3	NA	29	NA	100	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	1.9	NA	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
0.3	8.5	5.5	45	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	1
0.6	9.5	1.6	NA	NA	NA	0	0	1
0.5	9.9	1.6	NA	NA	NA	0	0	1
0.6	NA	1.8	NA	NA	NA	0	0	1
0.8	10.1	1.9	NA	NA	NA	0	0	1
0.7	NA	1.9	NA	NA	NA	0	0	1
0.5	10.3	1.8	NA	NA	NA	0	0	1
0.7	10	1.9	NA	NA	NA	0	0	0
NA	NA	23	272	NA	NA	0	0	1
NA	10	NA	NA	97	NA	0	0	1
0.3	8.5	19	414	96	NA	0	0	1
0.8	8.9	NA	NA	NA	NA	0	0	0
0.6	8.7	NA	NA	NA	NA	0	0	0
NA	8.6	NA	NA	NA	NA	0	0	0
0.4	NA	16	NA	NA	NA	1	0	0
0.5	8.8	29	NA	NA	NA	0	0	0
0.5	8.3	27	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	NA	15	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	2.8	NA	NA	NA	0	0	0
0.3	NA	3.2	NA	NA	NA	0	0	0
NA	NA	3.4	NA	NA	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	0
NA	NA	3.6	NA	NA	NA	0	0	0
1.1	10	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	10	NA	NA	NA	NA	0	0	1
0.4	9.9	NA	NA	92	209	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	9.5	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1	9.1	NA	NA	106	NA	0	0	0
0.9	9.1	NA	NA	106	NA	1	0	0
1.2	NA	NA	NA	109	169	0	0	0
0.8	9.9	1.2	NA	100	138	0	0	0
1.2	7.8	1.8	32	103	NA	0	0	1
0.4	NA	NA	5.2	101	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.7	8.4	11	NA	104	104	0	0	1
1.4	8.9	1	NA	102	NA	1	1	1
1.1	NA	NA	NA	102	NA	0	1	1
0.2	NA	1.5	NA	NA	NA	0	1	1
0.3	NA	1.2	NA	NA	NA	0	1	1
0.2	NA	1.5	NA	NA	NA	0	1	1
0.4	8.3	2.3	NA	104	NA	0	1	1
NA	NA	1.8	NA	NA	NA	0	0	0
3.8	8.3	42	NA	106	NA	1	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
2.6	NA	NA	NA	96	NA	0	0	0
1.4	8.4	4	NA	103	59	0	0	0
0.6	NA	1	NA	105	NA	0	0	0
0.5	8.2	1	NA	104	NA	0	0	0
0.8	NA	3.4	NA	99	NA	0	0	0
0.7	9.6	3.7	NA	99	169	0	0	0
1	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	10	NA	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	98	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
1.3	NA	NA	NA	NA	NA	0	0	0
1.5	8.9	NA	NA	98	235	0	0	0
0.6	NA	6.3	NA	105	NA	0	0	1
0.2	7.8	1.6	NA	110	NA	0	0	0
0.4	NA	166	NA	NA	NA	0	0	1
0.7	10	572	NA	101	219	0	0	1
0.5	9.3	1538	NA	103	NA	0	0	1
0.3	NA	1.4	NA	NA	NA	0	0	0
NA	8.5	NA	NA	101	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	1	0	1
0.4	NA	4.3	NA	NA	NA	0	0	0
0.3	9.4	4.9	NA	NA	NA	0	0	0
0.5	NA	3.9	NA	NA	NA	0	0	0
0.3	NA	4.1	NA	NA	NA	0	0	0
0.2	NA	4	NA	NA	NA	0	0	0
0.2	NA	3.4	NA	NA	NA	0	0	0
0.7	NA	3.6	NA	100	NA	0	0	0
0.5	NA	116	NA	NA	NA	0	0	1
0.5	NA	35	NA	NA	NA	0	0	1
0.4	NA	44	NA	NA	NA	0	0	1
0.5	NA	69	NA	NA	NA	0	0	1
0.4	9.3	77	NA	NA	NA	0	0	1
0.4	NA	110	NA	NA	NA	0	0	1
0.5	NA	124	NA	NA	NA	0	0	1
0.5	8.8	156	NA	NA	NA	0	0	1
2.2	8.8	NA	NA	95	NA	0	0	1
0.4	8.9	15	NA	105	200	0	0	0
0.2	9.4	2	NA	93	NA	0	0	1
NA	NA	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	106	157	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	101	NA	0	0	0
NA	9.5	NA	NA	103	190	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	9.4	NA	NA	NA	NA	0	0	0
NA	8.7	2.3	NA	103	NA	0	0	1
0.2	NA	3.5	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.4	9.9	1.8	NA	104	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
NA	9.9	1.3	NA	NA	NA	0	0	0
NA	10.6	1.5	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.2	9.7	1.6	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	10	NA	NA	104	NA	0	0	1
0.4	9.5	NA	NA	NA	NA	0	0	0
0.5	9.7	NA	NA	103	NA	0	0	1
1.4	NA	6.6	NA	NA	NA	0	0	1
1.1	NA	6.3	NA	NA	NA	0	0	1
0.8	NA	7.5	NA	NA	NA	0	0	1
1.5	NA	7.7	NA	NA	NA	0	0	1
0.9	NA	8.2	NA	NA	NA	0	0	1
0.9	NA	6.5	NA	NA	NA	1	0	1
1.8	NA	NA	NA	NA	NA	1	0	1
3.2	NA	NA	NA	NA	NA	1	0	1
NA	NA	NA	NA	NA	NA	1	0	1
10	9.4	NA	NA	97	NA	1	0	1
11.9	NA	6.1	NA	NA	NA	0	0	1
13.3	8.9	8.2	NA	99	NA	1	0	1
11.7	8.5	NA	NA	105	NA	1	0	1
7	8.8	NA	NA	103	NA	1	1	1
4.8	NA	NA	NA	95	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	9.6	NA	NA	102	NA	0	0	1
22.1	NA	NA	NA	98	NA	0	0	1
1.3	8.6	NA	NA	101	NA	0	0	1
0.7	NA	NA	NA	102	NA	0	0	1
0.5	NA	NA	NA	102	NA	0	0	1
0.7	NA	NA	NA	103	NA	0	0	1
4.6	8.3	3.6	NA	NA	NA	0	0	0
4.2	8.2	NA	NA	103	NA	1	0	1
16.3	8.5	2.6	NA	108	NA	1	1	1
0.5	8.7	2.3	NA	102	NA	0	0	0
0.4	8.8	NA	NA	105	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	0	0	0
1.3	8.4	NA	NA	100	NA	0	1	1
1.3	7.6	NA	NA	115	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	1
NA	NA	1.3	NA	NA	NA	0	0	1
NA	NA	2.4	NA	NA	NA	0	0	1
NA	8	3.1	NA	106	NA	0	0	1
NA	NA	3.1	NA	NA	NA	0	0	1
NA	8.6	3.1	NA	103	NA	0	0	1
NA	11.2	4.1	NA	NA	NA	0	0	1
0.4	16.8	5.6	NA	NA	NA	0	0	1
0.2	7.1	6.7	NA	104	NA	0	0	1
0.4	8.4	5.8	NA	NA	NA	0	0	1
NA	10.2	10	NA	95	NA	0	0	1
1.3	NA	1	NA	NA	NA	0	0	0
0.6	NA	2.2	7.9	NA	NA	0	0	0
3	8.8	7	NA	106	NA	0	0	0
22.5	9.1	NA	NA	103	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
2.9	8.5	4.6	NA	102	103	0	0	1
5.1	NA	3.2	NA	100	NA	0	0	1
2.6	NA	NA	NA	100	NA	0	0	1
3.1	8.6	NA	NA	102	NA	0	0	0
3.2	NA	3.9	NA	NA	NA	0	0	0
3	9.1	NA	NA	109	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.3	NA	NA	103	NA	0	0	1
0.4	9.3	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.1	NA	NA	104	NA	0	0	1
0.5	NA	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	9.4	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	9.2	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	8.9	NA	NA	103	NA	0	0	1
0.5	8.9	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	8.9	NA	NA	107	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	106	NA	0	0	0
10.5	8.3	4	NA	99	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	9	2.9	NA	102	NA	0	0	0
0.4	NA	11	NA	NA	NA	0	0	1
0.7	NA	8.8	NA	NA	NA	0	0	0
0.3	NA	21	NA	NA	NA	0	0	1
0.4	NA	9.6	NA	NA	NA	0	0	1
NA	NA	1.5	NA	NA	NA	0	0	0
0.5	9	2.9	NA	NA	NA	0	0	0
0.6	NA	2.9	NA	NA	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.6	9.8	3	NA	104	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	9.4	1.8	NA	NA	NA	0	0	0
0.7	NA	1.4	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.5	9.2	50	NA	106	NA	0	0	1
0.7	NA	50	NA	NA	NA	0	0	1
0.9	9	17	NA	NA	NA	0	0	1
0.8	9.2	13	NA	NA	NA	0	0	1
0.9	NA	25	NA	NA	NA	0	0	1
0.8	NA	69	NA	NA	NA	0	0	1
0.8	NA	133	NA	NA	NA	0	0	1
1	8.9	80	NA	103	NA	0	0	1
0.3	8.4	40	NA	107	NA	0	0	1
NA	NA	96	NA	NA	NA	0	0	1
NA	8.2	85	NA	106	NA	0	0	1
0.3	NA	NA	NA	100	NA	0	0	0
0.5	9.3	NA	NA	104	NA	0	0	0
0.8	NA	1.5	NA	NA	NA	0	0	0
2	8.5	NA	NA	NA	NA	0	0	0
2.1	NA	NA	NA	NA	NA	0	0	0
2.8	NA	NA	NA	NA	NA	0	0	0
2.3	NA	NA	NA	NA	NA	0	0	0
3.5	NA	NA	NA	NA	NA	0	0	0
2.2	NA	4.4	NA	NA	264	0	0	0
1.9	NA	NA	NA	NA	268	0	0	0
1.3	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	106	NA	0	0	0
2.4	NA	NA	NA	NA	NA	0	0	0
2.3	10	4.3	30	103	NA	0	0	0
2.6	NA	NA	NA	NA	NA	0	1	0
1.5	NA	4.5	NA	NA	NA	0	1	0
1.7	NA	4.6	73	NA	NA	0	0	0
1	9.4	2.9	NA	NA	NA	0	1	0
5.1	NA	2.6	39	NA	NA	0	0	0
1.7	NA	2.4	26	NA	NA	0	0	0
1.8	9.3	3.1	27	NA	NA	0	1	0
4.4	8.3	NA	NA	114	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	0	0
5.3	7.1	5.2	NA	103	117	0	0	1
0.6	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	NA	NA	102	NA	1	0	0
0.3	NA	NA	NA	101	NA	1	0	0
0.3	NA	NA	NA	105	NA	1	0	0
0.6	NA	1.1	NA	103	NA	1	0	0
NA	NA	1.1	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	11.2	NA	NA	NA	NA	0	0	1
NA	9.9	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	10.3	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9	NA	NA	103	NA	0	0	1
0.4	10.4	NA	NA	106	NA	0	0	1
0.3	9.7	NA	NA	106	NA	0	0	1
NA	9.3	57	NA	NA	NA	0	0	1
0.9	10.4	1.6	NA	102	NA	0	0	1
10	10	1.1	NA	103	NA	1	0	1
0.4	9.4	NA	NA	102	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
2.8	9.1	3.6	NA	101	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.7	9.3	1.7	NA	108	NA	0	0	0
0.7	9.3	1.8	NA	107	NA	0	0	0
0.3	9.1	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	2.6	24	NA	197	0	0	0
0.3	NA	2.1	24	NA	NA	0	0	0
0.4	NA	NA	26	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	1	0	1
NA	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	103	NA	0	0	0
0.4	9.2	NA	NA	105	155	0	0	0
0.9	9.6	2.7	NA	103	NA	0	0	0
NA	9.2	1.5	NA	101	NA	0	0	0
NA	NA	2	29	95	NA	0	0	0
0.5	9.5	16	NA	NA	NA	0	0	1
0.7	9.7	22	NA	NA	NA	0	0	1
5.8	8.1	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	104	216	0	0	0
0.2	9.3	NA	NA	106	NA	0	0	1
1.9	9.9	4.9	NA	NA	NA	0	0	0
0.5	10.4	NA	NA	NA	221	0	0	0
0.5	9.5	NA	NA	NA	283	0	0	1
7.8	8.7	NA	NA	108	NA	1	0	1
0.3	NA	2.4	10	NA	NA	0	0	0
0.3	NA	2.6	18	103	NA	0	0	0
0.3	NA	3.2	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.2	NA	2.9	NA	NA	242	0	0	0
1.8	9.5	38	NA	110	NA	0	0	0
0.7	NA	1.4	NA	NA	210	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
0.6	9.3	3.9	NA	100	220	1	0	0
0.6	9.8	NA	NA	102	NA	0	0	1
3	8.7	1.8	NA	97	NA	0	0	1
0.5	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	2	30	NA	NA	0	0	0
NA	NA	1.1	NA	104	NA	0	0	0
1.2	8.9	NA	NA	100	NA	0	0	1
0.3	NA	2.2	NA	103	NA	0	0	1
0.2	NA	NA	NA	97	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.7	9.1	31	43	101	NA	0	0	1
0.5	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.6	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.7	NA	NA	13	NA	NA	0	0	0
0.5	NA	3.2	NA	103	224	0	0	0
0.5	NA	3.5	NA	NA	NA	0	0	0
NA	NA	4.2	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	101	NA	0	0	1
0.4	NA	2.2	NA	NA	NA	0	0	1
0.4	NA	2.2	9.8	107	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.6	9.8	NA	NA	NA	NA	0	0	0
0.7	10.2	1.2	NA	NA	NA	0	0	0
NA	10.4	NA	NA	NA	NA	0	0	0
NA	10.1	NA	NA	NA	NA	0	0	0
0.4	10.1	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.7	NA	1.2	NA	102	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
10.1	8.3	NA	NA	102	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	104	NA	0	0	0
0.3	NA	NA	NA	NA	189	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	10.1	NA	NA	101	NA	0	0	0
0.5	NA	NA	NA	NA	176	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	201	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	222	0	0	0
0.5	NA	1.7	NA	NA	211	0	0	0
0.3	9.3	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	NA	NA	0	0	0
0.4	9.8	2.2	NA	NA	NA	0	0	0
0.5	NA	2.1	16	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.5	NA	2.3	19	NA	NA	0	0	0
0.4	NA	1.1	15	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.1	21	NA	NA	0	0	0
0.4	NA	1.3	16	NA	193	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1.7	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
18.1	9.2	3.4	NA	95	NA	0	0	0
8.6	NA	3.6	NA	101	NA	1	0	1
1	NA	NA	NA	NA	NA	0	1	1
2.7	NA	NA	NA	NA	NA	1	1	1
1.9	8.4	NA	NA	100	NA	1	0	0
0.9	NA	NA	NA	NA	NA	0	1	1
0.9	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
7.1	8.1	NA	79	107	NA	0	0	1
0.3	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	227	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	237	0	0	0
0.4	10.6	NA	NA	102	NA	0	0	1
0.3	9.9	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.9	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	10.1	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	8.3	NA	NA	100	NA	0	0	1
0.2	NA	NA	NA	101	NA	0	0	1
0.6	9.4	NA	NA	106	NA	0	0	1
0.6	8.6	NA	NA	108	NA	0	0	1
0.3	8.6	NA	NA	106	NA	0	0	1
0.5	9	NA	NA	104	NA	0	0	1
0.4	8.8	NA	NA	107	NA	0	0	1
1.6	8.9	NA	NA	102	NA	0	0	1
0.8	8.1	NA	NA	104	NA	0	0	1
2.1	8.5	NA	NA	91	NA	0	0	1
1.3	8.3	NA	NA	96	NA	0	0	1
1	8.6	NA	NA	103	NA	0	0	1
0.2	NA	NA	NA	100	NA	0	0	0
0.2	NA	3.8	NA	NA	NA	0	0	0
1.5	NA	1.1	NA	108	NA	1	0	0
0.3	NA	NA	12	105	215	0	0	0
0.3	7.9	NA	NA	110	NA	0	0	0
0.9	8.7	NA	NA	102	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	106	NA	0	0	1
0.4	8.5	4.8	NA	107	NA	0	0	1
0.2	NA	NA	NA	106	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	8.6	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.6	7.7	NA	NA	113	NA	0	0	1
0.7	NA	3.6	NA	96	NA	0	0	0
0.8	NA	2.5	NA	NA	NA	1	0	0
0.8	NA	NA	NA	NA	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.5	9	2.3	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	106	148	0	0	0
0.5	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
NA	NA	NA	17	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	10.1	NA	NA	97	NA	0	0	0
0.3	10.1	4.9	NA	98	NA	0	0	1
0.4	9.6	NA	NA	99	NA	0	0	1
1.3	8.5	4.6	NA	102	NA	0	0	1
0.7	NA	3.6	NA	109	152	0	0	1
0.3	NA	1.2	18	NA	NA	0	0	0
0.3	NA	1.2	26	NA	NA	0	0	0
0.2	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.1	17	NA	NA	0	0	0
1	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
1.6	9	7.4	NA	108	NA	0	0	0
0.4	NA	NA	NA	109	NA	0	0	0
2.4	8.9	NA	NA	105	NA	0	0	1
3.1	NA	NA	NA	104	NA	0	0	1
3	NA	NA	NA	108	NA	0	0	1
0.4	NA	1.7	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
2.7	9.1	26	NA	100	NA	0	0	1
2.3	9	8.3	NA	106	NA	0	0	1
1.6	8	18	NA	108	NA	0	0	1
NA	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	NA	14	NA	NA	0	0	0
0.3	NA	1	15	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.3	14	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.1	17	NA	NA	0	0	0
13.2	7.9	2.3	NA	113	NA	0	0	1
0.4	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	3.2	NA	NA	270	0	0	0
0.4	NA	5.5	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.7	9.4	7.4	NA	102	NA	0	0	0
0.5	10.2	1.1	NA	100	NA	0	0	0
0.7	8.8	NA	NA	104	NA	0	0	0
0.3	9.2	2.8	NA	95	199	1	0	0
2.7	8.2	7	NA	97	106	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	9.5	NA	NA	0	0	0
0.6	9.1	1.4	NA	102	NA	0	0	1
0.5	8.9	NA	NA	NA	NA	0	0	1
0.7	NA	2.6	NA	103	NA	0	0	1
0.5	9.5	NA	NA	NA	NA	0	0	1
0.5	9.6	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	NA	2.5	NA	100	NA	0	0	1
1.2	NA	2.4	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	1.5	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	1.3	NA	NA	NA	0	0	0
NA	NA	2.8	12	NA	NA	0	0	0
0.4	NA	2.6	13	NA	NA	0	0	0
0.4	NA	3.5	23	NA	NA	0	0	0
0.3	NA	3.1	NA	100	NA	0	0	0
0.5	NA	2.6	NA	NA	NA	0	0	0
0.3	9.1	2.6	24	NA	175	0	0	0
0.3	8.9	2.5	NA	100	NA	0	0	0
0.4	NA	2.7	23	NA	NA	0	0	0
0.3	9.3	2.5	NA	NA	NA	0	0	0
0.3	NA	3	NA	100	NA	0	0	0
0.7	9	3.1	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
0.3	NA	1.9	22	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	8.6	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.2	9.5	1.6	6.3	97	NA	0	0	0
0.5	NA	NA	NA	104	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.2	9.2	1.1	NA	NA	NA	0	0	0
0.2	9.4	1.3	NA	NA	NA	0	0	0
2.1	8.5	3.6	NA	101	NA	0	0	1
0.3	NA	2.3	NA	99	NA	0	0	0
0.6	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
NA	NA	8.2	NA	NA	NA	1	1	1
0.4	NA	NA	NA	112	NA	0	0	1
0.9	8.8	5.1	NA	104	NA	0	0	0
0.4	NA	NA	NA	103	NA	0	0	0
0.8	NA	4	NA	105	NA	0	0	1
NA	NA	2	14	NA	NA	0	0	0
0.6	NA	1.4	11	NA	NA	0	0	0
0.5	NA	2.9	NA	NA	NA	0	0	1
0.5	NA	5.7	NA	NA	NA	0	0	1
0.2	9.8	8	NA	NA	NA	0	0	0
0.3	9.7	9.9	NA	NA	NA	0	0	0
0.3	10.2	13	NA	100	NA	0	0	0
0.2	9.6	17	NA	NA	NA	0	0	1
0.2	9.7	19	NA	NA	NA	0	0	1
0.4	NA	30	NA	NA	NA	0	0	1
0.4	9.8	31	NA	NA	NA	0	0	1
0.4	NA	46	NA	NA	NA	0	0	1
0.2	NA	33	11	NA	NA	0	0	1
0.3	NA	30	NA	NA	NA	0	0	1
0.3	NA	32	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	10	53	NA	NA	NA	0	0	1
NA	9.5	76	NA	103	NA	0	0	1
0.4	8.9	135	NA	99	NA	0	0	1
6.1	NA	146	NA	NA	NA	0	0	1
0.7	9.2	NA	NA	101	92	0	0	0
1.2	NA	NA	NA	NA	NA	1	0	0
8	NA	NA	NA	105	NA	1	0	0
2.7	8.9	2.3	NA	105	NA	0	0	0
2.8	NA	NA	NA	104	NA	1	0	0
5.3	NA	NA	NA	103	NA	1	0	0
2.9	NA	NA	NA	106	NA	1	0	0
9.8	8.5	5.7	NA	95	NA	0	0	1
9.7	NA	NA	NA	93	NA	0	0	1
4.3	NA	7.5	NA	NA	NA	0	0	1
3	9.2	NA	NA	102	NA	0	0	1
4.3	9.4	NA	NA	105	NA	0	0	1
1.5	NA	3.7	NA	101	164	0	0	1
1.3	9.1	NA	NA	103	NA	0	0	1
1.2	NA	NA	NA	106	NA	0	0	1
1.3	9.2	4.5	NA	104	NA	0	0	1
1.1	NA	NA	NA	100	NA	0	0	1
0.7	NA	NA	NA	104	NA	0	0	1
1.8	NA	NA	NA	101	NA	0	0	1
1	9.4	NA	NA	105	NA	0	0	1
1.1	NA	NA	NA	100	NA	0	0	1
NA	NA	1.1	NA	101	NA	1	0	0
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	9.8	1.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.8	NA	106	NA	0	0	0
0.2	NA	2.1	NA	104	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
NA	NA	3.2	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	1
NA	NA	2.3	NA	NA	NA	0	0	0
NA	9.5	2.3	NA	NA	NA	0	0	1
NA	NA	2.3	NA	NA	NA	0	0	1
NA	NA	2.6	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	2.9	NA	NA	NA	0	0	1
0.9	NA	5.7	NA	NA	NA	0	0	1
0.7	NA	4.4	NA	NA	NA	0	0	1
NA	8.9	4.2	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.9	NA	6.5	NA	NA	NA	0	0	1
0.5	9.2	3	NA	NA	NA	0	0	0
0.5	9.2	3	NA	NA	NA	0	0	1
0.8	NA	4	NA	NA	NA	0	0	1
0.8	NA	4.2	NA	NA	NA	0	0	1
0.9	NA	5.2	NA	NA	NA	0	0	1
0.7	8.6	4.7	NA	NA	NA	0	0	1
0.7	NA	5.1	NA	NA	NA	0	0	1
NA	NA	5	NA	NA	NA	0	0	1
0.4	NA	3.6	NA	NA	NA	0	0	1
0.5	NA	3.6	NA	NA	NA	0	0	1
0.5	NA	2.7	NA	NA	NA	0	0	1
0.5	NA	3.6	NA	NA	NA	0	0	1
0.4	NA	3.8	NA	NA	NA	0	0	1
0.5	NA	4.1	NA	NA	NA	0	0	1
0.5	NA	3.9	NA	NA	NA	0	0	1
NA	NA	3.3	NA	NA	NA	0	0	1
0.5	NA	4.2	NA	NA	NA	0	0	1
0.6	NA	4.5	NA	NA	NA	0	0	1
0.1	NA	3.5	NA	NA	NA	0	0	1
0.5	9	4	NA	NA	NA	0	0	1
0.4	NA	3.8	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.6	3.9	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	9.9	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	9.5	9	NA	NA	NA	0	0	1
0.7	9.2	NA	NA	NA	NA	0	0	1
NA	9.2	6	NA	NA	NA	0	0	1
0.6	9.8	NA	NA	102	NA	0	0	1
0.5	NA	3.4	NA	NA	NA	0	0	1
0.6	NA	3.5	NA	NA	NA	0	0	1
0.7	NA	4.4	NA	NA	NA	0	0	1
0.8	8.4	NA	NA	106	NA	0	0	1
1.4	7.4	NA	NA	102	NA	0	0	1
1.7	NA	NA	NA	NA	NA	0	0	1
1.5	8.6	2.9	NA	97	NA	0	0	1
4.7	9.1	3.3	NA	103	125	0	0	0
0.5	8	32	NA	106	NA	0	0	0
NA	NA	NA	29	NA	NA	0	0	0
1.5	9.6	NA	NA	98	NA	0	1	1
1.7	9.9	NA	NA	101	NA	0	1	1
1.7	10.4	NA	NA	99	NA	0	1	1
2.1	10.4	NA	NA	100	NA	0	1	1
2.4	10.1	NA	NA	99	NA	0	1	1
2.3	9.9	NA	NA	98	NA	0	1	1
1.7	9.3	NA	NA	98	NA	0	0	1
1.7	9.2	NA	NA	99	NA	0	1	1
1.6	NA	NA	NA	NA	NA	0	1	1
6.4	8.7	NA	NA	103	NA	1	0	0
NA	8.3	NA	NA	103	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	1.9	12	NA	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
2.6	8.4	8.3	NA	104	NA	0	0	1
2.5	NA	NA	NA	NA	NA	0	0	1
2.3	NA	7.6	NA	NA	NA	0	0	1
0.3	9.4	8.6	NA	105	NA	0	0	1
0.4	9.7	NA	NA	100	NA	0	0	1
0.4	9.4	NA	NA	101	NA	0	0	1
0.3	8.8	NA	NA	104	NA	0	0	1
0.3	8.3	3.2	NA	106	NA	0	0	1
0.4	NA	NA	NA	103	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	8.9	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	9.4	NA	NA	NA	NA	0	0	1
NA	9.1	NA	NA	NA	NA	0	0	1
0.4	9.2	NA	NA	NA	NA	0	1	1
0.4	9.2	NA	NA	NA	NA	0	1	1
NA	8.8	NA	NA	NA	NA	0	0	1
NA	8.8	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	9.1	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	1	1
0.2	9.2	NA	NA	NA	NA	0	0	1
0.3	9.2	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	7.9	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	8.9	NA	NA	NA	NA	0	0	1
NA	9.1	NA	NA	102	NA	0	1	1
0.5	8.8	NA	NA	NA	NA	0	0	1
0.5	9.4	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.7	9	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.2	NA	NA	NA	NA	NA	0	1	0
NA	8.5	1.8	49	103	NA	0	0	0
2.6	9.1	3.2	NA	105	211	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.7	NA	3.4	5.5	NA	NA	0	0	0
0.8	NA	3.9	5.5	NA	NA	0	0	0
1.1	9.9	3.1	4.6	NA	NA	0	0	0
0.6	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	103	NA	0	0	0
0.2	9.1	4.8	NA	97	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.7	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	9.9	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
5.1	9.1	1.1	NA	99	NA	1	0	1
1.1	9.1	NA	NA	104	NA	0	0	1
1	NA	NA	NA	103	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	9.5	NA	NA	NA	NA	0	0	1
0.2	9	NA	NA	104	NA	0	0	1
0.2	9.6	NA	NA	102	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	9.4	NA	NA	100	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9	NA	NA	103	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	9	NA	NA	99	NA	0	0	1
0.3	9.2	NA	NA	102	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	1
0.2	NA	4.9	NA	NA	NA	0	0	1
0.1	NA	5.7	NA	NA	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	104	NA	0	0	1
0.4	NA	19	NA	100	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.5	9.8	32	NA	NA	NA	0	0	1
0.3	9.4	14	NA	NA	NA	0	0	1
0.3	9.4	13	NA	NA	NA	0	0	1
0.5	NA	16	NA	NA	NA	0	0	1
NA	NA	1.5	NA	NA	NA	0	0	0
3.2	NA	4.5	NA	98	NA	0	0	1
NA	9.5	1.4	NA	103	NA	0	0	0
0.6	9.1	2	NA	NA	NA	0	0	0
0.5	9.3	2	NA	NA	NA	0	0	0
0.5	9	2	NA	NA	NA	0	0	0
0.3	NA	NA	18	NA	NA	0	0	0
0.5	NA	1.3	13	NA	NA	0	0	0
0.6	NA	1.9	26	NA	NA	0	0	0
0.5	9.4	2.5	NA	NA	NA	0	0	1
0.4	NA	2.5	NA	NA	NA	0	0	0
0.6	9	NA	NA	NA	NA	0	0	1
0.6	NA	3.8	NA	NA	NA	0	0	0
0.3	9.1	1.9	NA	106	NA	0	0	1
NA	8.8	2	NA	103	NA	0	0	1
0.4	8.8	3.2	NA	NA	NA	0	0	1
NA	NA	3.7	37	NA	NA	0	0	1
0.4	9	3.6	NA	NA	NA	0	0	1
0.4	8.6	2.5	NA	NA	NA	0	0	1
0.3	8.2	1.8	NA	NA	NA	0	0	1
0.6	NA	1.7	24	NA	NA	0	0	1
0.6	NA	1.7	NA	NA	NA	0	0	1
0.3	NA	2.2	NA	NA	NA	0	0	1
0.6	NA	4.4	NA	NA	NA	0	0	1
NA	9.5	12	NA	NA	NA	0	0	1
NA	7.4	13	NA	96	NA	0	0	1
0.5	NA	23	NA	91	NA	0	0	1
NA	NA	1.9	24	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	NA	0	0	0
0.7	NA	3.4	NA	NA	NA	0	0	0
0.5	NA	7.4	NA	NA	NA	0	0	0
0.3	NA	5.8	NA	NA	NA	0	0	1
0.5	NA	6.5	NA	NA	NA	0	0	1
0.4	NA	6.3	NA	NA	NA	0	0	1
NA	NA	1.3	NA	NA	NA	0	0	0
2.1	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
1.5	8.6	5	NA	106	NA	0	0	0
5.1	NA	1.7	NA	99	NA	0	0	1
0.5	NA	NA	NA	104	NA	0	0	0
0.3	9.1	2.3	NA	103	NA	0	0	0
3.8	NA	1.5	NA	NA	NA	1	0	1
1.3	9.7	NA	NA	90	NA	0	0	1
NA	7.9	NA	NA	94	NA	0	0	1
NA	8.6	NA	NA	98	NA	0	0	1
0.3	8.7	NA	NA	101	NA	0	0	1
0.3	9.2	NA	NA	99	NA	0	0	1
0.3	8.8	NA	NA	103	NA	0	0	1
0.3	8.5	NA	NA	99	NA	0	0	1
0.4	8.6	NA	NA	96	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.1	8.9	NA	NA	103	NA	0	0	1
NA	NA	2	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	102	191	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	9.4	6.1	NA	107	NA	0	0	1
0.5	NA	11	NA	NA	NA	0	0	1
0.5	NA	10	NA	NA	NA	0	0	1
0.5	8.8	9	NA	NA	NA	0	0	1
0.2	9.4	7.7	NA	NA	NA	0	0	1
0.4	NA	NA	41	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	NA	3.1	NA	NA	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	0
NA	NA	NA	NA	106	NA	0	0	0
NA	NA	NA	9.1	NA	NA	0	0	0
NA	10	7.6	NA	NA	NA	0	0	0
NA	10.7	5.2	21	NA	NA	0	0	0
NA	NA	5	19	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	7.7	41	NA	108	NA	0	0	1
0.8	NA	2.3	9.3	NA	NA	0	0	0
0.9	NA	2.1	NA	NA	NA	0	0	0
0.8	NA	1.8	14	NA	NA	0	0	0
0.9	NA	1.7	12	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.4	9.3	NA	NA	100	NA	1	0	0
0.5	NA	1.8	NA	99	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	10	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	5.4	NA	NA	NA	0	0	1
0.2	NA	5.4	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
NA	9.5	4.5	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	4.7	NA	NA	NA	0	0	0
0.2	NA	6.8	NA	NA	NA	0	0	1
0.2	NA	7.3	NA	NA	NA	0	0	1
0.1	NA	9	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	9.4	1.2	NA	NA	NA	0	0	0
0.2	10	3	NA	106	NA	0	0	0
0.1	NA	3.8	NA	NA	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
0.1	NA	2.5	NA	NA	NA	0	0	0
0.2	NA	3.3	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
0.2	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	206	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	3.6	NA	97	NA	0	0	1
9	9.4	3.9	NA	103	NA	0	0	0
0.2	NA	8	NA	99	NA	0	0	0
0.8	9.2	2.8	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
6.8	NA	2.9	NA	101	NA	0	0	0
26.7	9	4.8	NA	98	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	0
0.6	NA	4.5	NA	NA	NA	1	0	0
0.6	NA	NA	NA	NA	NA	1	0	0
1	NA	NA	NA	NA	NA	0	0	0
0.9	9	NA	NA	NA	NA	1	0	0
0.6	NA	3	NA	NA	NA	0	0	0
0.9	8.5	1.8	NA	NA	NA	0	0	0
1.1	NA	NA	NA	105	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	103	NA	1	0	0
6.3	7.4	3.5	NA	95	65	0	0	0
0.4	NA	NA	NA	103	NA	1	0	0
0.4	NA	NA	NA	101	NA	1	0	0
0.6	NA	NA	NA	100	NA	1	0	0
1.2	NA	NA	NA	NA	NA	1	0	0
1	NA	NA	NA	99	NA	0	0	0
0.9	NA	NA	NA	98	NA	1	0	0
0.6	NA	1	NA	NA	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
NA	9.9	1	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
11.8	8.9	98	NA	89	NA	0	0	1
23.7	9.2	3.3	NA	106	235	0	0	1
18.6	NA	NA	NA	104	NA	0	0	1
0.6	10.1	4.3	NA	98	NA	0	0	1
0.6	NA	3	NA	NA	NA	0	0	0
0.6	NA	4.3	NA	NA	NA	0	0	0
0.4	NA	3.5	NA	NA	NA	0	0	0
0.5	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	4.7	NA	NA	NA	0	0	0
9.1	8.8	2	NA	102	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	109	NA	1	0	1
0.7	NA	NA	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	9.6	NA	NA	104	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	9.3	2	NA	106	NA	0	0	1
2.4	NA	NA	NA	99	NA	0	0	1
0.5	9.2	NA	NA	104	NA	1	0	1
0.8	NA	NA	NA	105	NA	0	0	1
0.5	NA	NA	NA	105	NA	0	0	1
0.8	NA	NA	NA	104	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
0.6	8.8	17	NA	101	NA	0	0	1
0.5	9.5	NA	NA	99	NA	0	0	0
0.8	9.8	3.8	NA	101	130	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	9.8	NA	NA	104	NA	0	0	0
0.5	NA	7.5	NA	NA	NA	0	0	1
0.4	NA	10	NA	NA	NA	0	0	1
0.5	NA	28	NA	NA	NA	0	0	1
0.5	NA	37	NA	NA	NA	0	0	1
0.5	NA	60	NA	NA	NA	0	0	1
0.6	NA	75	NA	104	NA	0	0	1
NA	NA	84	NA	NA	NA	0	0	1
NA	NA	108	NA	NA	NA	0	0	1
NA	NA	110	NA	NA	NA	0	0	1
0.5	NA	117	NA	NA	NA	0	0	1
0.8	NA	130	NA	NA	NA	0	0	1
0.6	NA	124	NA	NA	NA	0	0	1
0.5	9.9	129	NA	NA	NA	0	0	1
0.8	NA	183	NA	NA	NA	0	0	1
0.7	9.4	221	NA	NA	NA	0	0	1
0.6	9.2	207	NA	NA	NA	0	0	1
0.7	8.7	182	NA	NA	NA	0	0	1
0.6	8.8	104	NA	NA	NA	0	0	1
1.2	NA	80	NA	NA	NA	0	0	1
1	NA	70	NA	NA	NA	0	0	1
1	9.3	93	NA	NA	NA	0	0	1
1.3	9.2	79	NA	NA	NA	0	0	1
0.9	9.2	75	NA	NA	NA	0	0	1
NA	NA	96	NA	NA	NA	0	0	1
NA	9.7	505	NA	99	NA	0	0	1
0.7	9.4	697	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.7	NA	1.3	NA	NA	NA	0	0	0
0.6	9.5	1.4	NA	102	NA	0	0	0
0.5	NA	1.4	NA	NA	204	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
0.7	NA	1.1	NA	NA	NA	0	0	0
NA	NA	15	NA	NA	NA	0	0	0
0.6	7.6	NA	NA	108	NA	0	0	0
0.5	9.3	3.8	NA	99	NA	0	0	1
NA	10.3	3.1	NA	108	271	0	0	1
0.4	NA	1.3	NA	NA	NA	1	0	0
0.5	NA	1.4	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	135	1	0	1
0.3	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	130	1	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
NA	9.5	1.5	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.2	9.4	1.7	NA	106	NA	0	0	0
0.2	9.8	1.9	NA	NA	NA	0	0	0
0.2	9.9	1.9	NA	103	NA	0	0	0
0.3	9.3	1.6	NA	NA	NA	0	0	0
0.2	9.6	1.5	NA	NA	NA	0	0	0
0.2	9.9	1.9	NA	104	NA	0	0	0
0.3	9.7	2	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	1
0.2	9.3	2.7	NA	NA	NA	0	0	1
0.6	8	3.8	NA	114	NA	0	0	0
NA	NA	NA	8.5	NA	NA	0	0	0
0.7	NA	NA	NA	NA	202	0	0	0
1.6	10.1	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	4.5	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	101	NA	0	0	0
0.3	9.4	NA	NA	93	NA	0	0	0
0.3	9.1	2.8	NA	93	NA	0	0	0
NA	NA	NA	NA	95	NA	0	0	0
NA	NA	4.6	NA	NA	NA	0	0	0
0.4	9.9	3.1	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
0.4	10.6	14	NA	99	NA	0	0	1
NA	NA	19	NA	95	NA	0	0	1
0.7	NA	17	NA	95	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	47	NA	91	NA	0	0	1
0.4	NA	110	NA	NA	NA	0	0	1
NA	NA	340	NA	NA	NA	0	0	1
0.3	NA	605	NA	99	NA	0	0	1
0.3	9	385	NA	104	NA	0	0	1
0.5	NA	2146	NA	NA	NA	0	0	1
0.4	NA	2823	NA	104	NA	0	0	1
0.5	9.4	4981	NA	NA	NA	0	0	1
0.3	NA	5874	NA	102	NA	0	0	1
0.3	9.5	4854	NA	101	NA	0	0	1
0.6	9.4	1551	NA	NA	NA	0	0	1
0.5	NA	1939	NA	NA	NA	0	0	1
NA	NA	NA	411	NA	NA	0	0	1
0.6	NA	3698	NA	NA	NA	0	0	1
0.5	9.3	3496	1437	95	NA	0	0	1
0.2	9	3358	1350	98	NA	0	0	1
0.3	9.9	3.2	NA	NA	NA	0	0	0
1.7	10.3	27	NA	100	NA	0	0	0
0.4	NA	3.4	NA	NA	164	0	0	0
4.6	8.4	8.2	NA	104	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	12	NA	NA	NA	0	1	0
0.4	NA	17	1151	NA	NA	0	1	0
0.3	NA	15	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	104	NA	0	1	0
NA	NA	3.6	7.8	NA	NA	1	1	0
0.5	NA	4	18	NA	NA	0	0	0
0.4	NA	4.5	50	105	300	0	1	0
0.5	NA	4.5	86	104	NA	0	0	0
1.4	NA	4.5	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
1.3	9.1	5.7	NA	101	NA	0	0	1
5.6	8.6	4.7	NA	108	NA	0	0	1
0.9	9.4	16	NA	102	145	0	0	0
2.2	8.4	4.3	NA	111	151	0	0	1
0.3	9.5	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.3	8.2	1.1	547	105	NA	0	0	1
NA	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.8	NA	2.9	NA	NA	NA	0	0	0
0.9	NA	2.3	NA	NA	NA	0	0	0
0.8	NA	2.9	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
1.9	8.6	NA	NA	100	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	1	0
1.6	NA	1.8	NA	NA	NA	0	0	0
2.5	8.9	2.2	NA	99	NA	0	0	0
1.4	9	8	NA	99	NA	0	0	0
1.6	9.1	NA	NA	NA	NA	0	0	1
0.6	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	1
0.5	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
0.7	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	1.6	NA	NA	NA	0	0	0
NA	NA	NA	359	NA	NA	0	1	0
0.5	NA	1.8	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.9	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	234	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	9.1	1.8	NA	NA	NA	0	0	0
28.1	9.6	1.4	NA	99	NA	0	0	0
0.3	8.1	NA	518	102	NA	0	0	0
NA	NA	1.6	NA	100	235	0	0	0
1.2	10.1	NA	NA	98	NA	0	0	0
NA	9.9	1.2	228	100	NA	0	0	1
1.1	8.1	2	43	104	NA	0	0	0
0.4	7.9	1.2	NA	111	NA	0	0	0
1	NA	NA	NA	96	NA	0	0	0
1.1	NA	7	NA	105	NA	0	0	1
1.1	9.5	4.9	NA	104	NA	0	0	1
2	9.3	9.2	NA	101	183	0	0	0
1.2	9.5	NA	NA	105	NA	0	0	0
3.7	8.9	2.3	NA	115	NA	0	0	0
1.4	NA	NA	NA	101	NA	1	0	0
0.6	10.3	2.4	NA	102	NA	0	0	0
0.3	8.4	2.7	NA	104	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
0.3	10	2.3	NA	101	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1940	NA	103	NA	0	0	1
0.2	NA	1.4	11	NA	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
2.1	NA	NA	NA	NA	NA	0	0	1
NA	NA	2	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
NA	NA	NA	11	NA	NA	0	0	0
NA	9.3	NA	NA	NA	NA	0	0	1
0.6	9.1	22437	NA	NA	NA	0	0	1
NA	NA	2156	NA	NA	NA	0	0	1
0.9	10.1	602	NA	NA	NA	0	0	1
NA	NA	623	NA	NA	NA	0	0	1
NA	10.4	667	NA	NA	NA	0	0	1
NA	NA	1498	NA	NA	NA	0	0	1
NA	NA	2329	NA	NA	NA	0	0	1
NA	9.9	3932	NA	NA	NA	0	0	1
0.4	NA	2.3	NA	NA	NA	0	0	1
0.3	NA	2.9	NA	NA	NA	0	0	1
0.5	NA	3	NA	NA	NA	0	0	1
0.6	NA	3.2	NA	NA	279	0	0	1
0.6	NA	3.2	NA	NA	NA	0	0	1
0.6	NA	3.2	NA	NA	NA	0	0	1
0.7	NA	2.7	NA	NA	NA	0	0	1
0.4	NA	3	NA	NA	NA	0	0	1
0.4	NA	3.3	NA	NA	NA	0	0	1
0.4	NA	3.3	NA	NA	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	0
0.6	NA	1.9	NA	NA	NA	0	0	0
NA	7.6	3.7	37	104	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	22	101	264	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	9.4	NA	NA	101	274	0	0	1
2	7.8	5.4	NA	91	63	0	0	1
NA	NA	NA	145	NA	NA	0	0	0
0.3	9.5	NA	NA	101	NA	0	0	0
0.4	9.6	NA	NA	103	NA	0	0	0
0.3	9.8	NA	NA	103	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.9	7.4	NA	NA	98	NA	0	0	0
1.1	8.2	NA	NA	103	NA	0	0	1
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	1
0.4	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	172	0	0	0
0.5	NA	1.1	NA	NA	172	0	0	1
0.3	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	3.5	NA	NA	NA	0	0	0
0.2	NA	3.1	NA	NA	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
0.1	NA	2.4	NA	NA	NA	0	0	1
NA	NA	2.5	NA	NA	NA	0	0	1
NA	NA	2.6	NA	NA	NA	0	0	1
NA	NA	2.8	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	NA	7.7	NA	NA	NA	0	0	1
0.4	NA	17	NA	NA	NA	0	0	1
0.5	9.2	17	NA	102	NA	0	0	1
0.4	8.5	22	NA	109	NA	0	0	1
0.4	8.5	22	NA	109	NA	0	0	1
0.6	NA	32	NA	NA	NA	0	0	1
1.1	8.8	33	NA	NA	NA	0	0	1
26.5	6.9	2.2	NA	108	NA	0	0	0
0.2	NA	35	NA	102	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	1.7	22	NA	NA	0	0	0
1	NA	NA	NA	103	NA	0	0	1
0.7	NA	NA	NA	106	NA	0	0	1
0.6	NA	NA	NA	105	NA	0	0	1
1.1	NA	NA	NA	103	NA	0	0	1
0.9	8.1	NA	NA	107	NA	0	0	1
1	7.8	NA	NA	111	NA	0	0	1
NA	NA	1.1	132	94	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.3	10.2	3.1	NA	101	NA	0	0	0
0.4	10	1.9	NA	101	NA	0	0	0
1.3	NA	2.2	NA	NA	NA	0	0	0
1.2	NA	2	NA	NA	NA	0	0	0
1.3	NA	2.6	NA	NA	NA	0	0	0
1.3	NA	3	NA	NA	NA	0	0	0
1.4	NA	3.6	NA	NA	NA	0	0	0
1.1	NA	2.5	NA	NA	NA	0	0	0
0.9	NA	4.5	NA	NA	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
1	8.5	21	NA	91	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	3.6	NA	NA	NA	0	0	0
0.3	NA	6.2	NA	NA	NA	0	0	0
0.2	NA	5.2	NA	NA	NA	0	0	0
0.2	NA	5.1	NA	NA	NA	0	0	0
0.3	NA	5.8	NA	NA	NA	0	0	0
0.3	NA	6.3	NA	NA	NA	0	0	0
1	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	6	NA	NA	NA	0	0	0
0.5	NA	4.3	NA	NA	NA	0	0	0
1.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	106	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
20.1	8.4	2.4	NA	103	NA	1	1	1
NA	NA	NA	NA	NA	NA	0	1	0
1	9.6	NA	NA	103	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
2.7	NA	NA	NA	93	NA	0	1	1
NA	NA	NA	117	NA	NA	0	0	1
0.4	NA	1.5	NA	NA	NA	0	0	0
NA	9.9	1.6	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	1
0.6	9.2	NA	NA	NA	NA	1	0	1
1	9	NA	NA	NA	NA	1	0	1
0.7	8.4	NA	NA	NA	NA	1	0	1
0.8	8.1	NA	NA	NA	NA	0	0	1
1.3	NA	NA	NA	NA	NA	1	0	1
1.5	7.9	NA	NA	107	NA	0	1	1
0.4	NA	1.5	NA	NA	NA	0	0	0
0.1	9.4	2.6	29	104	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	NA	NA	101	NA	0	0	0
3.1	8.8	1.9	NA	111	131	0	0	0
NA	NA	NA	14	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
NA	NA	3.9	NA	95	NA	0	0	0
0.1	8.3	1.6	NA	106	NA	1	1	0
3.6	7.9	8.3	NA	97	NA	0	0	1
0.3	NA	4	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.6	NA	2.5	NA	NA	NA	0	0	0
0.4	9	2.8	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.3	9.8	2.1	NA	96	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.4	NA	1.2	NA	98	NA	1	0	0
0.4	10.1	NA	NA	102	NA	1	0	0
0.3	NA	NA	NA	99	NA	1	0	0
0.3	NA	NA	NA	97	NA	1	0	0
0.4	NA	NA	NA	98	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.5	10.4	NA	NA	99	NA	1	0	0
2	8.3	6.2	NA	108	NA	0	0	0
0.6	8.3	NA	NA	103	NA	0	0	1
NA	9.7	2.5	NA	NA	NA	0	0	1
NA	NA	2.9	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	3.7	NA	NA	NA	0	0	1
NA	NA	3.6	NA	NA	NA	0	0	1
0.4	NA	4.2	NA	NA	NA	0	0	1
0.9	8.5	5.7	NA	NA	NA	0	0	1
NA	8.9	5.7	NA	NA	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	1
NA	NA	2.2	NA	NA	NA	0	0	0
NA	NA	NA	8.6	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
3.8	8.2	NA	NA	104	NA	1	0	1
1.4	NA	NA	NA	NA	NA	1	0	1
1.9	8.9	NA	NA	104	NA	1	0	1
0.7	NA	NA	NA	110	NA	0	1	1
0.6	NA	NA	NA	108	NA	0	0	1
1.5	NA	NA	NA	104	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	0	0
2.5	8.6	NA	NA	101	142	0	0	1
12	10.9	NA	NA	98	NA	0	0	1
0.3	NA	3.6	NA	NA	NA	0	0	1
0.2	NA	3.1	NA	NA	NA	0	0	1
NA	NA	3	NA	NA	NA	0	0	1
0.2	NA	3.8	NA	NA	NA	0	0	1
0.2	NA	4.2	NA	NA	NA	0	0	1
0.3	NA	4.4	NA	102	NA	0	0	1
0.2	9.4	3.8	NA	105	NA	0	0	1
0.5	NA	2.4	NA	NA	NA	0	0	0
NA	10.1	1.5	NA	NA	NA	0	0	0
NA	10.1	1.8	NA	NA	NA	0	0	0
NA	9.8	NA	NA	NA	NA	0	0	0
NA	9.7	2.2	NA	NA	NA	0	0	1
NA	9.8	NA	NA	NA	239	0	0	0
NA	10	NA	NA	NA	NA	0	0	1
0.2	10.5	2.3	NA	105	NA	0	0	0
NA	9.7	2.5	NA	NA	251	0	0	0
NA	9.2	2.7	NA	NA	NA	0	0	0
NA	9.5	2.9	NA	NA	NA	0	0	0
NA	9.2	3.5	NA	103	NA	0	0	1
NA	NA	2.2	NA	NA	NA	0	0	1
NA	NA	2.4	NA	NA	NA	0	0	1
0.3	NA	1.9	NA	NA	NA	0	0	1
NA	NA	1.4	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	1.3	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
1.2	8.9	6.6	NA	106	NA	0	0	1
0.4	9.4	NA	NA	103	NA	0	0	1
0.3	9.4	NA	NA	104	NA	0	0	0
0.7	8.1	NA	NA	106	NA	0	0	0
21.8	8.2	NA	NA	104	NA	0	0	0
NA	9.4	1.3	5.6	NA	NA	0	0	0
0.1	9.5	1.2	NA	99	183	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9.8	1.4	NA	102	NA	0	0	0
0.4	10.2	1.5	NA	100	NA	0	0	0
0.4	8.5	3.9	NA	100	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	1
NA	NA	NA	NA	105	NA	0	0	1
NA	NA	2.6	NA	NA	NA	0	0	1
NA	10.1	7.3	NA	NA	NA	0	0	1
NA	NA	6	NA	NA	NA	0	0	1
NA	NA	6.4	NA	NA	NA	0	0	1
0.3	NA	7	NA	103	NA	0	0	1
NA	NA	6.6	NA	NA	NA	0	0	1
NA	NA	8.5	NA	NA	NA	0	0	1
0.3	NA	8.6	NA	NA	NA	0	0	1
0.3	NA	9.3	NA	NA	NA	0	0	1
0.3	NA	9.8	NA	NA	NA	0	0	1
0.3	NA	9	NA	NA	NA	0	0	1
NA	NA	9.6	NA	NA	NA	0	0	1
NA	NA	9.2	NA	NA	NA	0	0	1
NA	NA	9.6	NA	NA	NA	0	0	1
NA	NA	10	NA	NA	NA	0	0	1
0.4	NA	11	NA	NA	NA	0	0	1
NA	NA	14	NA	NA	NA	0	0	1
NA	9.8	13	NA	NA	NA	0	0	1
NA	NA	17	NA	NA	NA	0	0	1
NA	NA	17	NA	NA	NA	0	0	1
0.4	9.3	11	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	10	1.2	10	NA	NA	0	0	0
0.4	9.9	1	NA	NA	NA	0	0	0
0.3	NA	1.3	10	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	6.9	NA	NA	0	0	0
0.2	NA	1.1	8.7	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	3.3	NA	NA	NA	0	0	0
0.3	9.1	6.7	NA	109	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	10	93	246	103	NA	0	0	0
0.5	NA	3.5	NA	NA	NA	0	0	1
0.4	NA	3.6	NA	102	NA	0	0	1
0.3	NA	NA	NA	NA	NA	1	0	1
0.4	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
1.4	NA	NA	NA	105	NA	1	0	1
0.8	NA	NA	NA	NA	NA	1	0	1
0.9	NA	NA	NA	NA	NA	1	0	1
0.6	NA	NA	NA	NA	NA	1	0	1
0.6	NA	NA	NA	NA	NA	1	0	1
1.2	NA	NA	NA	NA	NA	0	1	1
5.3	8.1	NA	NA	103	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	0
2.5	9.6	NA	NA	102	NA	0	0	0
0.3	10.1	8.9	NA	97	NA	0	0	0
NA	NA	5.2	NA	NA	NA	0	0	1
0.4	NA	2.5	NA	NA	NA	0	0	0
0.6	NA	3.7	NA	108	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.7	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.4	9.9	1.8	NA	NA	NA	0	0	0
0.5	9.9	2.2	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	1	1
1	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
1	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.9	NA	NA	NA	NA	NA	0	1	1
3.6	NA	NA	NA	NA	NA	0	1	1
1.5	8.2	NA	NA	105	NA	1	1	1
1.1	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
2.7	NA	NA	NA	NA	NA	0	1	1
1.6	9.7	3	NA	NA	NA	0	1	1
1.6	9.7	3.5	NA	NA	NA	1	1	1
0.6	9.9	4.4	NA	NA	NA	0	1	1
0.4	NA	3.3	NA	102	NA	0	0	0
0.5	NA	6433	NA	105	NA	0	0	1
NA	NA	4133	NA	105	NA	0	0	1
0.9	NA	5690	NA	102	NA	0	0	1
0.5	8.8	1.7	NA	110	NA	0	0	0
NA	NA	5.7	NA	NA	NA	0	0	1
1.4	10.3	NA	NA	97	NA	0	0	1
0.3	NA	1.2	27	103	NA	0	0	0
0.4	9.9	NA	NA	104	NA	0	0	0
0.4	9.2	NA	NA	101	NA	0	0	0
0.4	8.7	NA	NA	102	NA	0	0	0
0.4	9	NA	NA	105	NA	0	0	0
0.4	9	NA	NA	107	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	8.8	NA	NA	102	NA	0	0	1
0.5	9.2	NA	NA	101	NA	0	0	1
0.3	9.4	NA	NA	100	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	106	NA	0	0	0
0.4	9	NA	NA	106	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.9	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
8.3	9.6	7.6	NA	97	NA	1	0	1
NA	NA	1.1	NA	NA	NA	0	0	0
0.3	9.5	NA	NA	NA	NA	0	0	0
0.6	8.4	3.4	NA	108	NA	0	0	0
0.3	9.4	3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	9	NA	NA	104	NA	0	0	1
0.2	9.1	2.4	NA	106	NA	0	0	0
0.2	9.1	4.2	NA	NA	NA	0	0	0
0.2	9.1	3.9	NA	109	NA	0	0	0
NA	NA	4.1	NA	NA	NA	0	0	0
NA	9.7	4.1	NA	NA	NA	0	0	0
NA	NA	4	NA	NA	NA	0	0	0
0.9	9.3	NA	NA	95	NA	0	0	1
1.1	NA	2.8	NA	NA	NA	0	0	0
0.5	NA	3.3	NA	NA	NA	0	0	0
0.5	NA	3.4	NA	NA	NA	0	0	0
0.7	NA	3.2	NA	NA	NA	0	0	0
NA	NA	16	NA	NA	NA	0	0	1
0.4	7.7	NA	83	106	NA	0	0	1
0.2	9.2	16	NA	105	NA	0	0	1
NA	NA	13	NA	99	NA	0	0	1
0.2	8.9	13	NA	NA	NA	0	0	1
0.2	NA	12	NA	105	NA	0	0	1
0.2	9.8	11	NA	108	NA	0	0	1
NA	9.2	13	NA	NA	NA	0	0	1
NA	9.7	14	NA	NA	NA	0	0	1
0.2	9.7	16	NA	NA	NA	0	0	1
NA	9.3	NA	NA	NA	NA	0	0	1
0.2	8.8	25	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	9	NA	NA	NA	NA	0	0	1
0.2	9.9	20	NA	NA	NA	0	0	1
0.3	8.8	21	NA	103	NA	0	0	1
1.1	NA	2.3	NA	NA	NA	0	0	1
0.4	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
0.6	9.7	1.1	NA	104	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	NA	8.4	NA	NA	0	0	0
0.4	9.5	NA	NA	106	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	44	NA	NA	0	0	0
0.3	NA	NA	9.8	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.2	NA	7.5	NA	NA	NA	0	0	0
NA	9.4	3.4	NA	100	NA	0	0	0
0.5	8.7	6	71	102	NA	0	0	1
NA	NA	1.2	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	317	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
NA	NA	3.6	NA	NA	NA	0	0	1
NA	8.6	4.9	NA	NA	NA	0	0	1
NA	NA	4.8	NA	NA	NA	0	0	1
NA	8.8	6	NA	NA	NA	0	0	1
0.4	NA	10	NA	NA	NA	0	0	1
NA	9.4	14	NA	NA	NA	0	0	1
NA	NA	15	NA	NA	NA	0	0	1
NA	NA	22	NA	NA	NA	0	0	1
0.3	9.1	NA	NA	106	94	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
1.7	NA	2	NA	100	NA	0	0	1
1.7	NA	NA	NA	104	NA	0	0	0
3	9.3	NA	NA	101	NA	0	0	1
0.3	8.8	1.9	NA	105	151	0	0	0
0.5	9.5	2.3	NA	101	NA	0	0	0
NA	NA	NA	NA	102	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.9	NA	NA	NA	100	NA	1	0	0
0.3	NA	NA	NA	101	NA	1	0	0
NA	NA	NA	NA	102	NA	0	0	0
5.7	8.6	1.8	NA	105	NA	0	0	0
0.8	NA	1.3	NA	97	203	0	0	0
NA	NA	3.4	NA	NA	NA	0	0	1
0.6	NA	3.6	NA	98	NA	0	0	1
0.6	9.8	2.5	NA	105	NA	0	0	0
0.6	6.5	NA	NA	108	NA	0	0	0
0.3	NA	2	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	9.7	2.1	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
1.2	NA	5.6	NA	99	NA	0	0	1
NA	NA	3.4	NA	NA	NA	0	0	1
NA	10.6	5.3	NA	90	NA	0	0	0
0.7	NA	1.6	NA	100	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
40.7	9.8	4.1	81	100	NA	0	0	0
1.5	NA	NA	NA	99	NA	0	0	1
0.5	NA	NA	NA	97	NA	0	1	1
0.3	NA	NA	NA	99	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	102	NA	0	1	1
0.7	NA	NA	NA	NA	NA	0	1	1
0.7	9.8	NA	NA	103	NA	0	0	1
0.5	NA	NA	NA	106	NA	0	0	1
0.5	9	6	NA	100	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
19.8	NA	NA	NA	NA	NA	1	0	1
10.3	8.2	2.5	NA	101	NA	0	0	1
2.2	8	3.2	NA	97	NA	0	0	1
0.3	NA	1.9	NA	102	NA	0	0	1
0.3	9.7	NA	NA	104	NA	0	0	1
NA	9.6	NA	NA	103	NA	0	0	1
NA	9.1	NA	NA	105	NA	0	0	1
NA	9.5	NA	NA	104	NA	0	0	1
0.4	9.2	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	9.3	NA	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.4	8.8	NA	NA	99	NA	0	0	1
1.7	NA	NA	NA	NA	NA	0	0	0
0.4	9.6	NA	NA	104	NA	0	0	0
0.4	10	NA	NA	101	NA	0	0	0
0.3	9	NA	NA	101	NA	0	0	0
0.7	8.9	NA	NA	100	NA	0	1	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	9.4	NA	NA	102	NA	0	0	0
NA	NA	1.4	NA	99	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
0.6	9.8	NA	NA	103	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.5	8.4	NA	NA	105	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	101	NA	NA	0	1	1
0.3	NA	NA	77	102	NA	0	1	1
0.2	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.4	8.7	NA	NA	105	NA	0	1	1
2.1	NA	2.7	NA	97	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	9.9	2.2	NA	NA	NA	0	0	0
0.2	NA	2	NA	NA	NA	0	0	1
0.1	NA	2.4	NA	NA	NA	0	0	0
1.1	NA	6.4	NA	108	NA	0	0	1
0.9	NA	5.4	NA	108	NA	0	0	1
1.2	9.3	NA	NA	109	NA	0	0	1
1.1	NA	NA	NA	104	NA	0	0	1
1	NA	6.3	NA	NA	NA	0	0	1
0.4	8.7	13	63	104	NA	0	0	1
2.3	NA	1.4	NA	109	NA	0	0	0
1.8	NA	NA	NA	101	NA	0	0	1
1.4	NA	NA	NA	99	232	0	0	1
1.3	NA	9.7	NA	NA	NA	0	0	1
1.3	8.7	NA	NA	102	NA	0	0	0
0.7	8.9	1.2	NA	102	126	0	0	0
0.4	8.8	NA	NA	103	145	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.7	7.6	NA	NA	110	NA	0	0	0
0.2	NA	8.1	NA	NA	NA	1	0	0
1.2	8.6	2.1	NA	95	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	1
0.4	NA	1.1	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	10	1.8	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.2	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.6	NA	NA	NA	0	0	1
NA	NA	1.4	NA	NA	NA	0	0	1
NA	9.9	2	NA	NA	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	1
3.9	8.5	14	28	114	NA	0	0	0
1.6	8.9	1.2	NA	107	127	0	0	0
1.3	8.1	5.2	NA	96	NA	0	0	0
18.2	NA	NA	NA	101	NA	1	1	0
0.4	9.1	2.9	18	106	NA	0	0	0
0.4	9	2.6	17	105	NA	0	0	0
0.7	9.5	3.6	19	107	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
1.1	8	NA	NA	100	NA	0	0	0
1.2	8.2	NA	NA	103	NA	0	0	0
0.3	9.1	NA	NA	108	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.9	NA	1.1	NA	110	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	1	0	0
1	NA	NA	NA	102	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
1	NA	8.3	NA	NA	NA	0	0	0
NA	NA	1.9	NA	106	NA	0	0	0
1.6	9.8	13	NA	99	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.6	8.3	2.6	NA	107	NA	0	0	0
3.3	NA	2.5	NA	104	NA	1	0	0
0.5	8.2	NA	33	104	NA	0	0	0
0.6	9.1	1.8	NA	105	NA	0	0	0
8.3	NA	2.4	NA	NA	NA	1	0	1
18.1	8.1	NA	NA	105	NA	0	0	1
0.6	9.4	5.9	NA	103	NA	0	0	1
NA	NA	NA	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	26	NA	NA	0	0	1
6.7	9.4	5.7	NA	101	NA	0	0	0
2.9	8.5	6.2	NA	109	NA	0	0	0
7.6	8.5	NA	NA	97	NA	0	0	0
2.7	7.8	2.9	NA	100	NA	0	0	0
2.7	7.6	2.9	NA	104	NA	0	0	0
2.7	9.2	7.1	NA	101	NA	0	0	0
7.9	NA	2.1	NA	105	NA	0	0	1
1.1	NA	NA	NA	105	NA	0	0	1
0.7	NA	3.1	NA	105	NA	0	0	1
0.7	10	NA	NA	105	NA	0	0	1
0.4	NA	2.1	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
8.1	NA	3.5	NA	99	NA	0	0	0
0.9	NA	3.3	NA	94	NA	0	0	0
NA	9.7	2639	1335	94	NA	0	0	1
2.2	8.7	143	NA	104	NA	0	0	0
0.2	NA	2.7	NA	NA	NA	0	0	0
0.3	9.7	1.9	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
NA	NA	1.5	NA	99	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	0
2.3	NA	NA	NA	104	NA	0	0	0
3.5	8.3	4.4	NA	99	NA	0	0	0
0.3	NA	NA	NA	106	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	1	0
0.4	9.8	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	106	142	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.6	9.3	2.4	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	2.5	NA	NA	NA	0	0	0
0.6	8.7	2.7	NA	106	95	0	0	0
0.8	NA	1.2	NA	105	NA	0	0	0
NA	8.6	NA	NA	102	NA	0	0	0
0.5	10.2	NA	NA	102	NA	0	0	0
4.2	8.7	11	NA	109	NA	0	0	1
0.3	NA	4.5	NA	NA	NA	1	0	1
1.3	8.2	1.7	NA	105	NA	0	0	1
13.4	8.8	2.8	NA	104	NA	1	0	1
0.4	8.8	NA	NA	NA	NA	0	0	1
0.2	9.3	1.2	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
NA	9.5	1.6	NA	104	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
0.4	9.8	4	NA	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.4	10	2.5	NA	104	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
NA	NA	3.4	NA	NA	NA	0	0	0
NA	NA	3.2	NA	NA	NA	0	0	0
0.7	9.4	2.3	NA	103	NA	0	0	0
1.1	8.5	NA	NA	110	NA	0	0	1
5.6	NA	8	NA	103	NA	0	0	1
0.4	NA	1.4	NA	NA	NA	0	0	1
0.7	NA	1.9	NA	NA	NA	0	0	1
0.6	NA	2	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	101	NA	0	0	0
21.9	8.4	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	97	NA	0	0	0
1.6	9.5	NA	NA	100	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	2	NA	NA	218	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	209	0	0	0
0.9	8.8	2.4	NA	107	172	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
7.2	8.5	5.2	NA	104	NA	0	0	0
3	8.2	3.2	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	9.1	2	NA	NA	NA	0	0	0
0.5	10.1	NA	NA	100	220	0	0	1
0.2	NA	NA	NA	101	176	0	0	1
0.7	10.5	5.2	NA	NA	NA	0	0	1
0.5	10.4	2.7	NA	NA	NA	0	0	1
NA	9.8	2.4	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
NA	10.5	NA	NA	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	10.1	2.6	NA	NA	NA	0	0	0
0.7	NA	2.4	NA	NA	NA	0	0	0
0.9	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	16	NA	NA	NA	0	0	0
0.5	NA	26	15	NA	NA	0	0	0
0.5	NA	41	15.9	NA	NA	0	0	0
0.4	NA	42	22	NA	NA	0	0	0
0.6	9.3	67	NA	NA	NA	0	0	0
0.3	NA	80	NA	NA	NA	0	0	0
0.5	9.5	151	21	NA	NA	0	0	0
0.5	9.4	149	NA	NA	NA	0	0	1
0.8	NA	141	NA	NA	NA	0	0	0
0.4	NA	161	NA	NA	NA	0	0	1
0.4	NA	137	NA	NA	NA	0	0	0
0.5	NA	99	NA	NA	NA	0	0	0
0.6	9.3	86	NA	NA	NA	0	0	0
0.5	8.8	67	NA	NA	NA	0	0	0
0.4	8.9	32	NA	NA	NA	0	0	0
0.4	9.9	NA	NA	96	NA	0	0	1
1.7	10	NA	NA	93	NA	0	0	1
1.1	10.4	85	NA	90	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.5	NA	33	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	12	NA	NA	NA	0	0	1
0.6	NA	11	NA	NA	NA	0	0	1
0.4	NA	11	NA	100	NA	0	0	1
0.4	NA	16	NA	NA	NA	0	0	1
0.5	NA	30	NA	NA	NA	0	0	1
0.9	NA	46	NA	NA	NA	0	0	1
0.3	NA	41	NA	NA	NA	0	0	1
0.7	8.6	67	NA	100	NA	0	0	1
0.5	NA	68	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	128	0	0	0
0.2	NA	4.3	NA	NA	NA	0	0	0
0.4	NA	3.7	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.3	NA	3.5	NA	NA	NA	0	0	0
0.4	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
0.4	9	2.5	NA	103	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.4	NA	NA	NA	98	NA	1	0	0
0.4	9.7	NA	NA	103	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
1.7	NA	NA	NA	98	NA	1	0	1
1.2	NA	NA	NA	97	NA	1	0	1
0.7	NA	NA	NA	NA	NA	1	0	0
0.6	NA	NA	NA	101	NA	1	0	0
0.6	NA	NA	NA	102	NA	1	0	1
NA	NA	NA	NA	NA	NA	1	0	1
0.6	NA	NA	NA	97	NA	1	0	1
0.7	9.6	NA	NA	98	NA	0	0	1
0.4	9.7	NA	NA	101	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	9.3	NA	NA	98	NA	1	0	1
0.4	NA	3.6	NA	99	NA	0	0	1
0.5	NA	NA	NA	NA	NA	1	0	1
1.1	NA	NA	NA	NA	NA	1	0	1
0.7	NA	2.6	NA	100	NA	1	0	1
7	8.6	NA	NA	98	NA	1	0	1
8.6	8.6	NA	NA	93	NA	1	0	1
10.6	NA	NA	NA	92	NA	1	0	1
0.4	NA	NA	NA	NA	NA	1	0	0
1	NA	NA	NA	103	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.2	8.8	NA	NA	NA	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	104	NA	1	0	0
1.2	NA	NA	NA	96	NA	0	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	98	NA	1	0	0
0.3	NA	NA	NA	102	NA	0	0	0
0.4	8.8	NA	NA	102	190	1	0	0
0.3	NA	NA	NA	102	NA	0	0	0
0.5	8.9	NA	NA	102	NA	0	0	0
0.4	NA	NA	NA	103	NA	0	0	0
0.8	NA	NA	NA	NA	NA	1	0	0
0.8	NA	NA	NA	103	NA	1	0	0
0.4	9.6	NA	NA	103	NA	1	0	0
0.6	8.2	NA	NA	105	NA	1	0	0
0.7	9.1	NA	NA	101	NA	1	0	0
0.5	8.8	NA	NA	102	NA	1	0	0
0.6	9.6	NA	NA	101	NA	0	0	0
0.4	9.2	NA	NA	NA	NA	1	0	0
0.6	NA	NA	NA	105	NA	1	0	0
0.5	9.2	1.1	NA	102	NA	0	0	0
0.2	9.6	2.1	NA	105	NA	0	0	0
0.3	10.1	2.6	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	2.8	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
2	9.2	11	NA	100	NA	0	0	0
NA	8.4	16	NA	99	NA	0	0	1
1.1	9.4	12	NA	107	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	0
0.7	9.4	NA	NA	NA	NA	0	0	0
0.5	NA	4	NA	NA	NA	0	0	0
0.8	NA	2.8	14	NA	NA	0	0	0
0.7	NA	3	14	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
1.6	9.8	2.4	NA	NA	NA	0	0	0
1.3	9.4	2.1	NA	NA	NA	0	0	0
2.5	NA	2.6	NA	NA	NA	0	0	0
1.5	9.2	2.6	23	NA	NA	0	0	0
0.6	9.8	1.6	11	NA	NA	0	0	0
0.3	NA	NA	NA	NA	214	0	0	0
0.3	NA	NA	NA	NA	NA	1	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	1	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	1	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	101	NA	0	0	1
0.3	NA	NA	NA	NA	NA	1	0	1
0.2	NA	NA	NA	96	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	102	NA	0	0	1
0.2	NA	3.6	NA	NA	NA	0	0	1
0.2	NA	NA	NA	96	NA	0	0	1
0.2	NA	NA	NA	NA	203	0	0	1
1.5	10.3	3.3	NA	NA	NA	0	0	0
NA	NA	5.7	NA	NA	NA	0	0	0
NA	NA	5.1	NA	NA	NA	0	0	0
0.9	NA	5.5	NA	NA	NA	0	0	0
0.9	NA	6.1	NA	NA	NA	0	0	0
NA	NA	5.2	NA	NA	NA	0	0	0
NA	NA	4.7	NA	NA	NA	0	0	0
1.2	NA	5.3	NA	NA	NA	0	0	0
1	9.7	1.2	NA	97	NA	0	0	0
0.8	9.1	2.4	NA	97	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	107	NA	0	0	0
0.3	NA	4.5	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	2.3	NA	NA	NA	0	0	0
0.1	NA	2.1	NA	NA	NA	0	0	0
0.1	9	1.7	NA	NA	NA	0	0	0
0.1	NA	2.2	NA	NA	NA	0	0	0
0.1	NA	2.4	NA	NA	NA	0	0	0
NA	7.9	1.6	33	100	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
10.3	9.5	239	NA	100	NA	0	1	1
4.2	9.4	239	NA	96	NA	0	1	1
1	NA	191	NA	NA	NA	0	0	1
0.5	9	111	NA	NA	NA	0	0	1
0.5	9.2	64	NA	105	NA	0	1	1
0.4	NA	35	NA	NA	NA	0	0	1
0.3	NA	19	NA	NA	NA	0	1	0
0.4	NA	12	NA	NA	NA	0	1	1
0.5	NA	5.8	NA	NA	NA	0	0	1
0.4	NA	4.7	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	8.9	NA	NA	NA	0	0	1
NA	NA	8.9	NA	NA	NA	0	0	1
0.5	8.9	NA	NA	102	NA	0	0	1
1	NA	17	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	49	NA	NA	NA	0	0	1
0.2	NA	50	NA	NA	NA	0	1	1
0.3	NA	34	NA	NA	NA	0	1	1
0.2	NA	16	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	7.4	NA	NA	NA	0	0	1
0.3	NA	5.3	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.3	8.9	NA	NA	105	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.2	NA	22	NA	NA	NA	0	0	1
0.3	NA	20	NA	104	NA	0	0	1
0.1	NA	15	NA	NA	NA	0	1	1
0.2	NA	16	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.3	NA	27	NA	NA	NA	0	1	1
0.3	NA	30	NA	NA	NA	0	1	1
0.8	6.9	35	NA	101	NA	0	0	1
0.5	7.7	NA	NA	99	NA	0	1	1
0.4	8.4	42	NA	97	NA	0	1	1
0.5	NA	44	NA	92	NA	0	1	1
0.6	NA	84	NA	93	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	8.6	1.2	290	106	NA	0	0	0
0.9	8.8	NA	NA	98	NA	0	0	0
0.4	8.8	NA	56	107	NA	0	0	0
1.4	8.5	NA	NA	92	NA	0	0	1
NA	10.9	1.1	NA	104	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
NA	NA	8.2	NA	NA	NA	0	0	0
0.4	NA	10	NA	NA	NA	0	0	0
0.2	NA	9.5	NA	NA	NA	0	0	0
NA	NA	13	NA	NA	NA	0	0	0
0.3	NA	15	NA	NA	NA	0	0	0
0.3	9	22	NA	106	NA	0	0	1
0.3	NA	28	NA	NA	NA	0	0	1
0.4	9.5	22	NA	NA	NA	0	0	1
0.5	NA	24	NA	NA	NA	0	0	1
0.7	NA	22	NA	NA	NA	0	0	1
0.5	9.1	26	NA	99	NA	0	0	1
0.5	8.7	21	NA	97	NA	0	0	1
0.4	9.3	11	NA	NA	NA	0	0	1
0.6	NA	4.3	NA	104	NA	0	0	1
0.4	NA	4.9	NA	NA	NA	0	0	1
0.7	7.9	4.7	NA	108	NA	0	0	1
0.9	9.6	NA	NA	96	NA	0	0	1
0.7	9.6	6.3	NA	96	NA	0	0	1
NA	8.3	1.3	18	104	NA	0	0	0
0.4	NA	1.3	NA	103	NA	0	0	0
1.3	NA	2.4	NA	NA	NA	0	0	0
1.1	NA	1.9	NA	NA	NA	0	0	0
1.6	NA	2	NA	NA	NA	0	0	0
0.9	NA	2.1	NA	NA	NA	0	0	0
1.1	NA	2	NA	NA	NA	0	0	0
0.9	NA	2.3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	10.2	5.2	NA	108	NA	0	0	0
0.2	NA	NA	NA	101	NA	0	1	0
0.3	NA	1.8	NA	NA	NA	0	0	0
NA	9.6	7.3	NA	NA	NA	0	0	0
0.8	7.8	NA	226	106	NA	0	0	0
NA	8.2	NA	524	95	NA	0	0	0
1.7	NA	NA	NA	NA	NA	1	0	1
0.7	9.7	NA	NA	104	NA	1	0	1
1.5	NA	3.6	NA	NA	NA	0	0	1
1.3	NA	3.9	NA	NA	NA	1	0	1
1.4	NA	4.9	NA	99	NA	1	0	1
1.5	NA	4.7	NA	101	NA	1	0	1
1.3	10.1	4.7	NA	100	NA	1	0	1
1	NA	NA	NA	NA	NA	1	0	1
1.6	9.6	NA	NA	100	NA	1	0	1
2	9.7	NA	NA	102	NA	1	0	1
2.6	9.4	4.3	NA	101	NA	0	0	1
2.4	NA	NA	NA	NA	NA	0	0	1
3.8	NA	5.1	NA	NA	NA	1	0	1
3.6	9.3	NA	NA	101	NA	1	0	1
5.7	NA	5.1	NA	NA	NA	1	0	1
5.9	NA	NA	NA	100	NA	0	0	1
5.5	9.3	NA	NA	103	NA	1	0	1
5.7	9.5	NA	NA	NA	NA	0	0	1
8.8	9.4	NA	NA	97	NA	1	0	1
9.2	9.3	NA	NA	100	NA	1	0	1
6	8.5	NA	NA	106	NA	1	0	0
NA	8.9	NA	NA	99	NA	1	0	0
7.5	8.8	NA	NA	102	NA	1	0	0
0.8	8.4	2.5	NA	114	NA	0	0	0
0.8	8.4	2.4	NA	114	NA	0	0	0
2.4	9.4	NA	NA	105	NA	0	0	0
0.6	8.5	3.6	NA	108	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1	4.5	NA	NA	0	0	0
0.3	NA	NA	6.2	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	5.6	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	1
0.6	8.7	2.6	NA	105	NA	0	0	0
0.6	NA	1.6	NA	NA	NA	0	0	0
0.8	NA	3.5	NA	NA	NA	0	0	0
0.6	NA	3.6	NA	NA	NA	0	0	0
0.7	NA	4	NA	NA	NA	0	0	0
0.7	9.5	4.7	NA	106	134	0	0	0
0.7	NA	3.9	NA	NA	NA	0	0	0
0.5	NA	4.9	NA	NA	NA	0	0	0
0.7	9.5	1.4	NA	102	NA	0	0	0
2.4	9.6	5.1	NA	98	NA	0	0	0
1	NA	NA	NA	106	NA	0	0	0
0.7	NA	NA	NA	106	NA	1	0	0
0.9	NA	NA	NA	108	NA	1	0	0
1.5	NA	1.1	NA	99	NA	1	0	0
0.3	NA	NA	NA	91	NA	0	0	1
0.4	NA	4.5	NA	NA	243	0	0	0
0.3	NA	3.9	NA	NA	NA	0	0	0
0.3	9.7	4	NA	NA	NA	0	0	1
0.4	NA	3.2	NA	NA	NA	0	0	1
0.3	NA	3.8	NA	NA	NA	0	0	1
0.5	NA	3.5	NA	NA	NA	0	0	1
0.6	NA	3.4	NA	NA	NA	0	0	1
NA	9.6	3.3	NA	NA	NA	0	0	1
NA	8.9	3.5	NA	NA	NA	0	0	1
0.4	NA	3.8	NA	NA	NA	0	0	1
NA	NA	3.6	NA	NA	NA	0	0	1
NA	NA	3.6	NA	NA	NA	0	0	1
0.3	9.1	5	NA	103	NA	0	0	0
0.3	NA	NA	14	NA	NA	0	0	0
NA	9.6	2.6	14	101	NA	0	0	0
1.3	8.7	4.6	NA	93	86	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
1.2	NA	NA	NA	102	NA	0	0	0
0.3	NA	NA	NA	95	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
17.5	8.2	2.2	NA	96	NA	0	0	0
NA	NA	10	NA	NA	NA	0	0	0
1.5	8.3	5.1	NA	105	NA	0	0	1
0.7	NA	NA	NA	101	NA	0	1	1
0.8	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	1	0	1
1.3	NA	NA	NA	106	NA	1	0	1
1.6	8.4	1.5	NA	102	NA	0	0	1
1.8	NA	NA	NA	NA	NA	1	0	1
0.5	9.6	2.1	NA	106	NA	0	0	1
0.7	NA	NA	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.9	NA	4.4	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	4	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	4	NA	NA	NA	0	0	0
0.3	NA	NA	NA	102	NA	0	0	0
0.4	9.6	NA	NA	103	NA	0	0	0
0.3	NA	NA	NA	103	NA	0	0	1
0.3	10	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	9.7	NA	NA	102	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	9.1	NA	NA	98	NA	1	0	1
0.5	NA	5.3	NA	88	NA	0	0	0
0.2	8.7	3.9	NA	93	NA	0	0	0
0.4	7.7	NA	NA	98	NA	0	0	0
0.7	NA	3.1	NA	108	NA	0	0	0
0.6	NA	NA	NA	105	NA	1	0	0
0.3	NA	NA	NA	101	NA	0	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
1.1	NA	1	NA	NA	NA	0	0	0
0.3	NA	4.6	NA	NA	NA	0	0	0
0.2	NA	4.6	8.7	NA	NA	0	0	0
0.3	NA	3.9	NA	NA	NA	0	0	0
0.4	NA	4.6	NA	NA	NA	0	0	0
0.2	NA	4.7	NA	NA	NA	0	0	0
0.3	NA	NA	NA	111	NA	0	0	1
0.3	NA	1.7	NA	NA	NA	0	0	0
0.2	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	1
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
1.8	9.1	5.5	NA	103	NA	0	0	1
10.5	NA	3	NA	107	NA	1	0	1
2.9	8.5	1.7	NA	100	NA	1	0	1
0.7	NA	NA	NA	NA	NA	1	0	1
0.3	NA	NA	NA	NA	NA	1	0	0
0.1	NA	3.6	NA	NA	NA	0	0	0
0.3	NA	7.7	NA	NA	NA	0	0	0
0.3	NA	9.2	NA	NA	NA	0	0	0
0.2	NA	7	NA	NA	276	0	0	0
0.4	9.7	9.2	NA	NA	NA	0	0	0
0.2	NA	7.3	NA	NA	NA	0	0	0
0.3	9.7	7.7	NA	NA	NA	0	0	0
0.9	9.5	39	NA	91	NA	0	0	1
0.6	NA	24	NA	94	NA	0	0	1
1.1	8.9	46	NA	NA	NA	0	0	1
1	8.1	32	NA	98	NA	0	0	1
0.1	8.9	3.6	NA	NA	NA	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
0.4	NA	3.1	NA	NA	NA	0	0	0
0.3	NA	3.7	NA	NA	NA	0	0	0
0.2	8.6	6.7	NA	NA	NA	0	0	0
0.3	9.3	3	NA	NA	NA	0	0	0
0.2	8.8	2.3	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.3	9	2.5	NA	105	NA	0	0	0
0.2	9.5	2.7	NA	105	NA	0	0	0
0.2	NA	2.4	NA	NA	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
0.3	10	1.9	NA	NA	NA	0	0	0
0.2	NA	1.8	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.2	NA	1.8	NA	NA	NA	0	0	0
0.8	NA	1	NA	102	NA	0	0	0
5.6	8.6	NA	NA	103	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	1	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	103	NA	0	0	0
0.5	NA	NA	NA	100	NA	0	0	0
0.3	9.1	NA	NA	103	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	9.1	NA	NA	103	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	102	NA	0	0	0
0.6	NA	NA	NA	102	NA	1	0	1
0.6	NA	NA	NA	104	NA	1	0	0
0.3	9.8	NA	NA	106	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	101	NA	1	0	0
0.2	NA	NA	NA	104	NA	1	0	0
0.3	NA	NA	NA	100	NA	1	0	0
0.5	NA	NA	NA	99	NA	1	0	0
0.4	NA	NA	NA	102	NA	1	0	0
0.2	NA	4.2	NA	NA	NA	0	0	0
0.5	9.7	NA	NA	98	NA	0	0	0
0.8	NA	NA	NA	97	NA	1	0	0
0.6	NA	NA	NA	99	NA	1	0	0
0.4	NA	NA	NA	101	NA	1	0	0
0.5	10.1	NA	NA	99	NA	1	0	0
0.5	NA	NA	NA	97	NA	1	0	0
NA	9.3	NA	NA	NA	NA	0	0	0
0.9	8.2	1.6	NA	105	NA	0	0	1
1.2	NA	NA	NA	NA	NA	0	0	1
4.6	8.9	7.2	NA	102	NA	0	0	1
2.4	8.1	NA	NA	113	NA	0	0	0
2	NA	NA	NA	99	NA	1	0	0
2.3	NA	NA	NA	99	NA	0	0	0
3.6	9.4	NA	NA	99	NA	1	0	0
2.8	NA	NA	NA	101	173	1	0	0
3.9	NA	NA	NA	101	NA	1	0	0
5.4	8.9	NA	NA	102	181	0	0	0
4.7	8.4	NA	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	104	NA	0	0	1
NA	NA	4.9	NA	NA	NA	0	0	0
NA	NA	6.1	NA	NA	NA	0	0	0
NA	NA	7.2	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	1
NA	NA	2.5	NA	NA	NA	0	0	1
NA	NA	2.2	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.6	NA	NA	NA	0	0	1
0.3	NA	2.2	NA	NA	NA	0	0	1
0.5	NA	1.5	NA	NA	NA	0	0	1
NA	NA	1.7	NA	NA	NA	0	0	1
0.2	NA	1.5	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.2	9.7	3.2	NA	99	NA	0	0	1
0.7	NA	NA	NA	107	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	9.4	NA	NA	NA	NA	0	0	0
0.3	NA	NA	23	NA	179	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	2.7	NA	NA	NA	0	0	0
0.4	NA	3.1	NA	NA	NA	0	0	0
0.4	8.4	NA	NA	106	NA	0	0	0
0.1	NA	1.8	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	1.4	17	NA	NA	0	0	0
0.3	NA	6.1	NA	NA	NA	0	0	1
0.2	NA	7.3	NA	NA	NA	0	0	1
0.3	NA	6.2	NA	NA	NA	0	0	1
0.2	NA	6.6	NA	NA	NA	0	0	1
0.4	NA	6.5	NA	NA	NA	0	0	1
0.1	NA	1.8	NA	NA	NA	0	0	1
0.2	NA	1.8	NA	NA	NA	0	0	1
0.3	NA	1.3	NA	NA	NA	0	0	1
0.2	NA	1.5	NA	NA	NA	0	0	1
0.2	NA	1.2	NA	NA	NA	0	0	1
0.2	NA	1.6	NA	NA	NA	0	0	1
0.2	NA	1.3	NA	NA	NA	0	0	1
0.2	8.6	NA	10	NA	NA	0	0	0
0.1	NA	1.3	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	3.2	NA	107	NA	1	0	0
0.6	NA	2.7	NA	NA	NA	1	0	0
1	NA	3.6	NA	NA	NA	0	0	0
1.1	NA	NA	NA	NA	NA	1	0	0
1.5	NA	NA	NA	104	NA	1	0	0
1.1	NA	NA	NA	103	NA	1	0	0
1.1	NA	NA	NA	100	NA	1	0	1
1.8	NA	NA	NA	100	NA	1	0	1
1.1	NA	NA	NA	NA	NA	1	1	1
0.7	NA	NA	NA	108	NA	1	0	1
1.5	NA	NA	NA	107	NA	1	0	0
1	NA	NA	NA	105	NA	1	0	0
0.9	NA	NA	NA	106	NA	1	0	0
1.1	9.2	6.3	NA	97	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	8.6	NA	NA	NA	NA	0	0	0
0.3	8.4	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	8.6	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	8.9	NA	NA	103	NA	0	0	1
0.3	8.7	NA	NA	103	NA	0	0	1
0.3	8.3	1.3	NA	102	NA	0	0	1
0.2	8.6	1.5	NA	103	NA	0	0	1
0.3	7.9	20	NA	95	NA	0	0	1
0.2	8.2	18	NA	98	NA	0	0	1
0.1	8.2	13	NA	97	NA	0	0	1
0.1	8.3	9	NA	103	NA	0	0	1
0.2	8.5	6.7	NA	102	NA	0	0	1
0.2	NA	2	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	193	0	0	0
0.4	NA	NA	NA	102	NA	1	0	0
1.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	2.6	NA	NA	NA	0	0	0
0.5	NA	2.8	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
5	NA	12	NA	103	NA	0	0	1
1.5	NA	1.3	NA	NA	NA	0	0	0
0.2	9.3	2.3	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	1	0
0.4	NA	3.5	NA	103	NA	0	0	1
0.4	NA	NA	NA	101	NA	0	1	1
0.2	NA	1	NA	NA	NA	0	0	1
0.2	NA	2.2	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.2	NA	5.8	NA	NA	148	0	0	0
1.2	8.8	4.1	3639	98	NA	0	0	1
NA	NA	2.3	287	NA	NA	0	0	1
0.5	NA	3.7	359	NA	NA	0	0	1
1.6	9	4.9	2261	98	NA	0	0	1
NA	10.3	2.1	NA	NA	NA	0	0	0
NA	10.1	1.9	NA	NA	NA	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
NA	NA	3.6	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	3.6	NA	NA	NA	0	0	1
0.4	9.4	NA	NA	NA	NA	0	0	1
0.6	NA	6.3	NA	NA	NA	0	0	1
0.6	7.5	4.9	NA	NA	NA	0	0	1
0.6	NA	3.6	NA	NA	NA	0	0	1
0.4	6.8	3.2	NA	104	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	0
NA	NA	8.6	NA	NA	NA	0	0	0
NA	NA	9.9	NA	NA	NA	0	0	0
6.3	8.6	5.1	NA	107	NA	0	0	1
2.3	NA	8.6	NA	NA	NA	1	0	1
0.5	9.2	NA	NA	101	NA	1	0	0
NA	NA	7.2	NA	103	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	1	0
0.9	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	100	NA	0	0	0
0.9	NA	NA	NA	102	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
1.2	8.8	7.7	NA	103	NA	0	0	1
1.5	8.9	NA	NA	100	NA	1	0	0
0.5	NA	NA	NA	100	NA	0	0	0
0.5	8.7	4	NA	103	NA	0	0	1
1.4	9.6	22	NA	104	NA	0	0	1
NA	8.6	17	NA	99	NA	0	0	1
1.3	8.7	32	NA	101	NA	0	0	1
1.4	NA	33	NA	100	NA	0	0	1
0.4	NA	1	NA	NA	NA	0	0	0
27.8	6.5	NA	NA	98	NA	1	0	1
2.3	NA	NA	NA	NA	NA	1	0	0
1.9	8	7	NA	103	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.1	3.8	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	9.3	1.6	NA	101	NA	0	0	0
0.4	NA	2.7	9.1	NA	NA	0	0	0
0.4	NA	37	NA	NA	NA	0	0	1
0.4	NA	4.1	NA	NA	NA	0	0	1
0.4	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	8.6	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	3.8	NA	102	NA	0	0	0
0.4	NA	NA	NA	100	NA	1	0	0
0.5	9.3	NA	NA	99	NA	0	0	0
0.3	NA	NA	NA	101	NA	1	0	1
0.4	NA	NA	NA	102	NA	1	0	0
0.6	NA	NA	NA	NA	NA	1	0	0
NA	NA	1.2	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	99	NA	1	0	0
0.4	8.3	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	103	NA	1	0	0
10.2	8.8	7.3	NA	102	NA	0	0	0
10.5	8.6	7.3	NA	104	NA	0	0	0
0.8	NA	NA	NA	98	NA	0	0	0
0.6	NA	NA	NA	101	NA	0	0	0
1.5	NA	5	NA	NA	NA	0	0	1
0.4	NA	NA	13	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.2	8.2	NA	NA	104	NA	0	0	0
NA	NA	113	NA	NA	NA	0	0	1
0.3	NA	67	NA	NA	NA	0	0	1
0.2	NA	27	NA	NA	NA	0	0	1
0.2	NA	18	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	18	NA	NA	NA	0	0	1
0.2	NA	19	NA	NA	NA	0	0	1
0.2	NA	26	NA	NA	NA	0	0	1
0.2	NA	41	NA	NA	NA	0	0	1
0.3	NA	53	NA	NA	NA	0	0	1
0.2	NA	28	NA	105	NA	0	0	1
0.2	NA	30	NA	104	NA	0	0	1
0.2	9.5	109	NA	NA	NA	0	0	1
NA	NA	121	NA	NA	NA	0	0	1
NA	NA	150	NA	NA	NA	0	0	1
0.2	NA	137	NA	NA	NA	0	0	1
0.3	NA	208	NA	NA	NA	0	0	1
NA	NA	210	NA	NA	NA	0	0	1
NA	NA	263	NA	NA	NA	0	0	1
NA	NA	191	NA	NA	NA	0	0	1
NA	NA	272	NA	NA	NA	0	0	1
NA	NA	284	NA	NA	NA	0	0	1
0.1	NA	268	NA	NA	NA	0	0	1
0.1	NA	192	NA	NA	NA	0	0	1
0.3	8.9	176	NA	NA	NA	0	0	1
NA	NA	164	NA	NA	NA	0	0	1
NA	NA	173	NA	NA	NA	0	0	1
0.3	9.3	201	NA	NA	NA	0	0	1
0.6	NA	1	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.5	9.6	NA	NA	NA	NA	0	0	1
0.5	NA	1.3	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	9.6	1.1	12	NA	NA	0	0	0
NA	NA	NA	12	NA	NA	0	0	0
0.3	7.9	12	NA	108	NA	0	0	0
21.2	8.5	3	NA	99	NA	0	0	1
NA	8.8	NA	NA	111	NA	0	0	0
4	NA	6	NA	108	NA	0	0	0
6.1	8.6	NA	NA	118	NA	0	0	1
0.6	9.6	3.3	NA	101	NA	0	0	1
0.2	NA	NA	NA	NA	NA	1	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
2.8	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.7	NA	3.1	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	2.2	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	2.4	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	0	0
0.4	9.1	NA	NA	107	NA	0	0	0
0.4	9.3	11	NA	NA	NA	0	0	1
0.3	NA	12	NA	NA	NA	0	0	1
0.5	9.4	12	NA	101	NA	0	0	1
0.6	9.3	11	NA	NA	NA	0	0	1
0.7	NA	11	NA	NA	NA	0	0	1
NA	NA	9.4	NA	NA	NA	0	0	1
0.6	NA	8.6	NA	NA	NA	0	0	1
0.5	NA	9.5	NA	NA	NA	0	0	1
0.5	8.9	9.1	NA	NA	NA	0	0	1
0.6	NA	8.5	NA	NA	NA	0	0	1
0.5	NA	8.6	NA	NA	NA	0	0	1
0.6	NA	8.6	NA	NA	NA	0	0	1
NA	NA	8.7	NA	NA	NA	0	0	1
0.6	NA	8.6	NA	NA	NA	0	0	1
0.6	NA	9.3	NA	NA	NA	0	0	1
0.6	NA	11	NA	NA	NA	0	0	1
0.6	NA	12	NA	NA	NA	0	0	1
0.7	8.5	13	NA	NA	NA	0	0	1
0.3	NA	12	NA	NA	NA	0	0	1
NA	NA	9.3	NA	NA	NA	0	0	1
NA	NA	7.5	NA	NA	NA	0	0	1
NA	NA	5.9	NA	NA	NA	0	0	1
0.3	8.3	5.8	NA	NA	NA	0	0	1
0.4	NA	6.1	NA	NA	NA	0	0	1
0.4	NA	6.1	NA	104	NA	0	0	1
0.4	9.2	6.1	NA	NA	NA	0	0	1
NA	NA	6.4	NA	NA	NA	0	0	1
0.3	NA	6.7	NA	NA	NA	0	0	1
0.3	NA	6.3	NA	NA	NA	0	0	1
0.3	NA	6.7	NA	100	NA	0	0	1
NA	NA	6.9	NA	NA	NA	0	0	1
NA	NA	6.6	NA	NA	NA	0	0	1
0.2	NA	7.5	NA	NA	NA	0	0	1
NA	NA	6.9	NA	NA	NA	0	0	1
NA	NA	6.8	NA	NA	NA	0	0	1
0.2	NA	7.5	NA	NA	NA	0	0	1
0.3	NA	9.2	NA	NA	NA	0	0	1
NA	NA	8.6	NA	NA	NA	0	0	1
0.3	NA	6.8	NA	NA	NA	0	0	1
1.1	NA	NA	NA	100	NA	0	0	1
NA	8.3	NA	NA	107	NA	1	0	0
0.4	9.4	1	NA	NA	NA	0	0	0
0.3	9.2	1.6	NA	103	181	0	0	0
NA	9.9	8.2	NA	NA	NA	0	0	1
NA	NA	5.6	NA	102	NA	0	0	1
0.3	9.7	7.1	NA	NA	NA	0	0	0
0.3	8.5	5.9	NA	102	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	98	NA	1	0	0
1	10.3	4.9	NA	98	165	0	0	1
NA	NA	NA	15	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.5	9.3	NA	NA	NA	NA	0	0	0
0.3	9.1	1.7	20	NA	NA	0	0	1
0.2	9.4	2	NA	106	NA	0	0	1
0.2	NA	1.9	NA	107	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	9	NA	NA	107	NA	0	0	1
0.3	9	NA	NA	107	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	105	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
3.1	9.7	4	NA	98	NA	0	0	1
0.4	9.2	1.5	NA	95	NA	0	0	1
0.4	9	2.4	NA	101	NA	0	0	0
15.7	NA	2.1	NA	NA	NA	0	0	1
0.5	8.6	1	NA	101	122	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	1
0.4	9.6	NA	NA	NA	NA	0	0	0
0.7	NA	6.9	NA	93	NA	0	0	1
0.4	8.3	NA	NA	108	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
25.5	8.4	1.4	20	103	NA	1	1	1
1.4	NA	NA	NA	NA	NA	1	0	1
3	9	2.4	NA	106	NA	0	0	1
9	8.5	NA	NA	92	NA	0	0	1
NA	NA	NA	18	102	NA	0	0	0
0.4	7.8	2.1	NA	102	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.3	NA	1.4	NA	NA	NA	1	0	0
7	8.4	NA	NA	105	NA	1	0	1
0.5	9.3	3.1	NA	101	NA	0	0	1
1.2	NA	NA	NA	NA	NA	1	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
1.5	NA	1.5	NA	98	NA	0	0	0
0.2	8.2	1.4	NA	111	NA	0	0	0
1.3	8.9	2.3	NA	106	NA	0	0	1
2	8.6	5.7	NA	96	NA	0	0	1
6.7	10.1	14	NA	94	NA	0	0	1
0.2	9.3	3.3	NA	102	NA	0	0	0
2.2	NA	1.2	NA	101	NA	0	0	0
NA	NA	4.7	NA	NA	NA	0	0	0
0.5	NA	4.3	NA	NA	NA	0	0	0
0.4	9.3	3.7	NA	108	NA	0	0	0
0.4	9.7	3.9	NA	NA	NA	0	0	0
0.2	NA	23	NA	NA	NA	1	0	0
24.3	8.4	4.8	NA	103	NA	1	0	1
NA	NA	2.1	NA	NA	NA	0	0	1
0.6	NA	2.6	NA	NA	NA	0	0	0
0.8	NA	14	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.1	8.6	11	NA	107	NA	0	0	0
0.2	8.5	NA	NA	101	NA	0	0	0
0.6	NA	1.5	NA	95	NA	0	0	1
0.8	10.9	NA	NA	96	NA	0	0	1
2	NA	NA	NA	NA	NA	0	0	1
2.1	NA	NA	NA	NA	NA	0	0	1
1.1	9.7	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.8	9.9	3.8	NA	NA	NA	0	0	1
0.8	9.4	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
1.4	NA	2.8	NA	NA	NA	0	0	1
3.4	9.2	NA	1075	NA	NA	0	0	1
NA	NA	NA	30	95	NA	0	0	0
10.3	8.8	4.3	NA	102	NA	1	0	1
0.5	NA	2.3	NA	NA	NA	0	0	0
4.7	9.9	9.1	NA	102	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	0
2.4	NA	2.1	NA	103	NA	0	0	0
0.5	NA	21	NA	NA	NA	0	0	0
0.3	NA	NA	NA	101	NA	0	0	0
1.1	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.2	17	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	1
1.8	8.6	16	NA	107	NA	0	0	1
0.4	NA	1.6	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
3.3	8.4	4.2	NA	102	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	9.4	1.7	NA	104	NA	0	0	0
NA	9.2	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	1
0.7	8.1	NA	NA	103	NA	0	0	1
2.2	8.1	NA	NA	105	NA	0	0	1
3.2	8.3	NA	NA	92	NA	1	0	0
0.4	NA	7.3	NA	97	NA	1	0	0
0.6	NA	6.5	NA	101	NA	0	0	0
0.2	NA	1.1	NA	103	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.6	NA	3	NA	103	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
5.9	9.5	NA	NA	NA	NA	0	0	1
2.4	8.4	NA	NA	96	NA	0	0	1
2.2	8.5	12	NA	100	NA	0	0	0
0.6	NA	7.1	NA	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
0.6	NA	2.4	NA	NA	NA	0	0	1
NA	NA	2.7	NA	NA	NA	0	0	0
0.3	NA	3.6	NA	NA	NA	0	0	0
0.4	7.9	2.7	NA	101	NA	0	0	0
6	8.4	7.4	NA	95	NA	0	0	1
NA	NA	3.4	18	98	NA	0	0	0
4.8	9.6	NA	NA	103	NA	1	0	1
2	NA	4.8	NA	104	NA	0	0	1
1.7	9.1	4.3	NA	99	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
2	NA	7.3	NA	101	NA	0	0	1
0.3	NA	3	8.7	NA	NA	0	0	0
1	8.6	3.3	NA	109	152	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.2	NA	2.6	NA	NA	NA	0	0	0
0.2	NA	2.6	NA	NA	NA	0	0	0
0.4	10	2.7	NA	NA	NA	0	0	0
0.3	9.6	2.8	10	NA	NA	0	0	0
0.2	NA	2.4	11	NA	NA	0	0	0
NA	9	5.5	NA	107	NA	0	0	1
0.2	NA	1.9	NA	NA	NA	0	0	0
NA	9.6	1.4	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.3	10.2	1.7	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1.5	NA	NA	NA	0	0	0
0.6	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
0.9	NA	1.4	NA	NA	NA	0	0	0
1	NA	1.3	NA	NA	NA	0	0	0
0.7	NA	1.3	NA	NA	NA	0	0	0
NA	9	2.7	NA	101	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.7	NA	1.5	NA	NA	NA	1	0	0
17.5	NA	4.1	NA	103	NA	1	0	1
0.8	NA	NA	NA	101	NA	0	0	0
0.4	NA	NA	NA	104	NA	0	0	0
0.5	NA	NA	NA	104	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	8.4	NA	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	8.5	NA	NA	108	NA	0	0	0
0.3	NA	NA	NA	108	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	8.2	NA	NA	107	NA	0	0	1
0.3	8.4	12	NA	108	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	10	NA	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
13.7	8.4	547	NA	100	NA	1	0	1
7	NA	NA	NA	100	NA	0	0	1
1.2	6.8	1.9	NA	103	NA	0	0	0
0.4	10.1	2	NA	NA	NA	0	0	0
2.5	NA	13	NA	101	NA	0	0	1
1.1	9.5	13	NA	101	NA	0	0	1
0.3	8.4	NA	NA	96	NA	0	0	1
3.3	NA	NA	NA	104	NA	0	0	0
0.2	9	3.5	NA	96	241	1	0	0
0.3	NA	4.5	NA	NA	NA	0	0	0
0.3	NA	4.3	NA	NA	NA	0	0	0
0.2	NA	9.4	NA	NA	NA	0	0	0
0.1	NA	4.3	NA	NA	NA	0	0	0
0.1	NA	4.5	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.1	NA	4.8	20	NA	NA	0	0	0
0.2	NA	5.1	NA	NA	NA	0	0	0
0.1	8.6	4.1	27	NA	NA	0	0	0
0	NA	4	NA	NA	NA	0	0	0
NA	NA	4.3	NA	NA	202	0	0	0
0.1	NA	3.6	NA	NA	NA	0	0	0
0.1	8.9	3	NA	105	NA	0	0	0
21.1	NA	7.4	NA	NA	NA	0	0	1
1	NA	20	NA	NA	NA	0	0	1
0.8	NA	25	NA	95	NA	0	0	1
0.4	NA	2	NA	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
0.5	10	2.9	NA	104	NA	0	0	0
0.4	NA	2.5	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	101	NA	0	0	0
0.8	9.1	1.7	NA	103	NA	0	0	0
0.9	8.6	3.1	NA	107	NA	0	0	0
0.6	NA	NA	NA	100	NA	0	0	1
2.6	8.6	3.1	NA	99	NA	0	0	1
4.5	NA	NA	NA	NA	NA	0	0	1
NA	8.1	53	NA	105	NA	0	0	1
17	NA	2.4	NA	95	NA	0	1	1
0.9	8	4	NA	106	NA	0	0	1
0.8	8.5	3.7	NA	97	NA	0	0	1
NA	9.1	2	NA	105	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
NA	8.9	15	NA	100	NA	0	0	1
2.8	8.5	NA	NA	110	NA	0	0	1
NA	NA	2.8	NA	NA	NA	0	0	0
NA	NA	4.1	NA	NA	NA	0	0	0
0.3	NA	3.6	NA	NA	NA	0	0	1
0.3	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	NA	NA	0	0	0
0.3	NA	4.4	NA	NA	NA	0	0	0
NA	NA	3.9	NA	NA	NA	0	0	0
0.2	9.8	4	NA	NA	NA	0	0	1
0.2	NA	3.4	NA	NA	NA	0	0	0
0.3	NA	3.2	NA	NA	NA	0	0	1
0.3	NA	1.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.7	10	1.9	NA	101	178	0	0	0
0.7	9.4	3.3	NA	105	NA	0	0	1
0.3	8.5	1.6	NA	103	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	1
0.2	NA	2.2	NA	NA	NA	0	0	0
NA	NA	3.9	NA	NA	NA	0	0	0
0.3	NA	3.3	NA	104	NA	1	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	102	NA	0	0	0
18.2	NA	5.6	NA	NA	NA	1	0	1
0.7	NA	NA	NA	NA	NA	1	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	2	36	100	NA	0	0	1
0.5	8.5	NA	NA	97	NA	0	0	1
NA	NA	4.2	NA	105	NA	0	0	0
0.6	12.2	4.9	NA	103	NA	0	0	0
0.3	9.5	7.7	NA	NA	NA	0	0	0
0.5	NA	6.9	NA	NA	NA	0	0	0
0.4	9.3	6.9	NA	NA	NA	0	0	0
NA	NA	6.5	NA	NA	NA	0	0	0
0.4	NA	6.9	NA	NA	NA	0	0	0
0.9	NA	5.6	NA	99	NA	0	0	0
0.2	8.4	300	NA	105	NA	0	0	1
0.2	NA	2	22	90	NA	0	0	0
10.3	9.4	NA	NA	119	NA	0	0	1
0.3	NA	5.6	NA	106	NA	0	0	0
1.2	NA	3.2	NA	NA	NA	1	0	1
2	NA	NA	NA	98	NA	1	0	1
5	NA	NA	NA	NA	NA	1	0	1
2.2	NA	NA	NA	96	NA	1	0	1
1.2	9.4	NA	NA	97	NA	1	0	1
1.2	10.5	2.3	NA	97	183	0	0	1
0.7	9.4	NA	NA	97	NA	1	0	1
0.8	10.1	NA	NA	NA	NA	1	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.6	9.7	2.7	NA	100	165	1	0	0
0.7	NA	NA	NA	101	NA	1	0	0
1	NA	NA	NA	103	NA	1	0	0
0.6	9.9	2.8	NA	97	NA	1	0	0
0.7	9.9	NA	NA	101	154	1	0	0
0.6	NA	2.4	NA	98	NA	1	0	0
1.1	7.4	1.7	NA	108	NA	1	0	0
0.9	NA	NA	NA	97	NA	1	0	0
0.6	9.6	NA	NA	99	131	1	0	0
0.9	NA	NA	NA	102	171	1	0	0
0.8	9.6	NA	NA	100	NA	1	0	0
0.9	9.5	NA	NA	100	NA	1	0	0
1.2	8.4	NA	NA	105	136	0	0	1
1.3	9.9	2.9	NA	98	NA	0	0	0
10.7	9	15	NA	99	NA	0	0	1
11.2	NA	17	NA	103	NA	0	0	1
3.3	8.8	4.3	NA	104	NA	0	0	0
6.8	9.2	NA	NA	106	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	99	NA	0	0	0
0.7	9.2	NA	NA	112	NA	0	0	0
0.3	8.8	2.8	68	104	NA	0	0	0
1.9	9.8	17	NA	99	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	5.2	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
0.3	9.7	2.2	NA	NA	NA	0	0	1
0.5	NA	3.2	NA	NA	NA	0	1	1
0.4	NA	4.1	NA	NA	NA	0	0	1
0.4	NA	4.1	NA	NA	NA	0	0	1
0.3	9.1	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	2.2	NA	NA	NA	0	1	1
0.9	9.5	2.9	NA	98	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.4	9.1	1.1	NA	NA	NA	0	0	0
0.5	9.2	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	11	NA	NA	0	0	0
0.3	9.9	1.4	NA	103	NA	0	0	0
0.3	10	1.7	NA	98	NA	0	0	0
0.4	9.8	NA	NA	96	NA	0	0	0
0.2	9.8	2.4	NA	96	NA	0	0	0
0.2	9.6	2.6	NA	96	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
2.7	8.4	10	NA	108	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	3.4	NA	96	NA	1	0	1
0.4	NA	116	NA	96	129	0	0	1
0.4	9.3	3.3	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	9.3	2.7	NA	NA	NA	0	0	0
0.4	NA	4.8	NA	94	NA	0	0	0
0.5	9.5	3.9	NA	102	NA	0	0	0
0.4	NA	3.6	NA	NA	NA	0	0	0
0.2	NA	3.6	NA	NA	NA	0	0	0
0.4	NA	3.1	NA	NA	NA	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
0.4	NA	3.3	NA	NA	NA	0	0	0
0.5	NA	3.4	NA	NA	NA	0	0	0
0.4	NA	1.4	NA	103	NA	1	0	0
NA	NA	6.4	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
4.7	NA	6.6	NA	105	138	0	0	1
NA	NA	2.8	NA	NA	NA	0	0	0
0.6	NA	2.8	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
0.6	NA	2.7	NA	NA	NA	0	0	0
0.6	10.1	2.8	NA	NA	NA	0	0	0
0.5	10.2	2.4	NA	NA	NA	0	0	0
0.5	10	2.6	NA	103	NA	0	0	0
0.5	10	2.5	NA	104	NA	0	0	0
0.5	9.6	1.3	NA	106	NA	0	0	0
0.3	9.3	2	NA	102	NA	0	0	0
0.3	8.7	1.9	NA	96	NA	0	0	0
0.3	9	1.6	NA	101	NA	0	0	0
0.3	10.1	2.9	NA	102	188	0	0	1
0.3	9	2	NA	105	NA	0	0	0
NA	NA	1	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	3	NA	NA	NA	0	0	0
2	8.7	6.9	NA	105	NA	0	0	1
10.2	8.8	NA	NA	98	NA	1	1	1
0.4	9.6	2.4	NA	105	NA	0	0	0
6.8	NA	NA	NA	106	NA	0	0	0
NA	10.3	1.6	NA	106	NA	0	0	0
0.7	8.8	1.6	NA	108	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	NA	NA	0	0	0
0.6	NA	1.9	NA	NA	NA	0	0	0
2.2	8.6	8.6	NA	102	122	0	0	1
0.4	NA	NA	NA	104	NA	0	0	0
2.7	NA	4.6	NA	88	NA	1	0	1
0.5	NA	1.2	20	104	195	0	0	0
NA	NA	1.2	NA	NA	NA	1	0	0
0.4	NA	1.4	NA	NA	NA	0	0	0
0.5	9.8	NA	NA	100	NA	0	0	0
NA	10.1	4.2	118	100	NA	0	0	0
0.6	NA	NA	10	NA	NA	0	0	0
NA	9.5	NA	13	NA	NA	0	0	0
0.4	8.9	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	9.4	NA	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
0.4	9	NA	NA	110	NA	0	0	0
0.5	NA	14	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	9.1	28	NA	NA	NA	0	0	1
NA	9.5	NA	13.5	101	NA	0	0	0
1	NA	1.9	NA	NA	NA	1	0	0
0.2	8.9	NA	NA	100	NA	0	0	0
6.3	8.9	2.4	NA	104	NA	1	0	1
33.8	NA	3.8	NA	93	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	0
18.8	NA	117	NA	102	NA	1	0	1
13.5	NA	NA	NA	NA	NA	1	0	1
12.4	8.7	188	NA	101	NA	1	0	1
26.7	10.4	NA	NA	96	NA	0	0	1
12.1	9.4	NA	NA	99	155	0	0	1
3.5	9.9	NA	NA	99	NA	0	0	1
1.8	NA	NA	NA	NA	NA	0	0	1
2.9	7.6	NA	NA	96	NA	0	0	1
0.6	7.8	1.8	NA	102	NA	1	0	0
0.4	NA	NA	NA	102	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	10	NA	100	NA	0	0	1
NA	NA	2.5	NA	NA	NA	0	0	0
0.4	9.4	NA	NA	99	NA	0	0	1
NA	10	NA	NA	102	NA	0	0	1
0.7	8.7	NA	NA	105	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	1	0
0.4	9.9	NA	NA	102	NA	0	1	1
NA	9.1	NA	NA	106	NA	0	1	1
9.7	10	NA	NA	102	NA	1	1	1
1.8	12.1	NA	NA	98	NA	0	1	1
0.4	9.7	4.2	NA	105	NA	0	0	0
0.4	NA	NA	NA	107	NA	0	0	0
NA	8	8.7	NA	102	NA	0	0	1
0.4	NA	NA	NA	102	NA	0	0	0
NA	NA	NA	NA	100	198	0	0	0
0.8	9.7	NA	NA	100	NA	0	0	0
0.4	9.3	NA	NA	101	NA	0	0	0
0.3	9.1	NA	NA	101	NA	0	0	0
0.1	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	8.9	2.7	NA	102	NA	0	0	0
0.3	NA	6.5	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	8.3	NA	NA	103	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
1.2	NA	1.4	NA	NA	NA	0	0	0
0.6	9.4	1.7	21	NA	NA	0	0	0
0.7	NA	2.1	NA	NA	NA	0	0	0
0.6	NA	2	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	1	0	1
0.4	8.8	1.1	NA	NA	NA	0	0	0
0.3	9.7	1.5	NA	NA	NA	0	0	0
NA	9.7	2.6	NA	104	NA	0	0	0
0.4	NA	2.1	NA	101	NA	0	0	0
8.5	9.6	4	NA	96	NA	1	0	1
0.4	8.5	39	NA	106	NA	0	0	1
0.4	8.5	39	NA	106	NA	0	0	1
0.3	NA	NA	NA	NA	NA	1	0	0
0.3	9.6	NA	NA	97	NA	0	0	0
0.4	8.5	14	NA	100	NA	0	0	1
0.5	9.7	NA	NA	106	NA	0	0	1
24.7	8.9	NA	NA	96	NA	0	0	1
27.7	9.3	NA	NA	95	NA	0	0	1
1.2	NA	5	NA	103	NA	0	0	0
11.7	7.9	NA	NA	101	NA	1	0	1
0.6	NA	1.7	NA	111	NA	0	0	0
0.4	9.2	1.7	NA	105	NA	0	0	0
0.5	8.8	1.9	NA	103	NA	0	0	0
0.2	9.2	1.8	NA	104	NA	0	0	0
0.3	8.9	2	NA	NA	NA	0	0	0
1.4	9.3	1.5	NA	95	NA	0	0	1
NA	NA	2	NA	NA	NA	0	0	0
0.6	9.7	2.1	NA	104	NA	0	0	0
0.3	9.1	1	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
0.3	9.2	NA	NA	NA	NA	0	0	0
0.3	9.3	NA	NA	NA	NA	0	0	0
0.4	9.9	1.2	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
NA	9.4	1	NA	NA	NA	0	0	0
0.3	NA	43	NA	NA	NA	0	0	1
0.2	9.6	8.1	NA	105	NA	0	0	1
0.2	NA	7.1	NA	NA	NA	0	0	0
0.3	NA	4.2	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
0.8	NA	2.3	NA	101	NA	0	0	0
0.5	9.7	2	NA	102	NA	0	0	0
0.6	NA	NA	NA	101	NA	0	0	0
0.3	10.1	1.4	NA	98	NA	0	1	0
0.2	9	NA	NA	99	NA	0	1	0
0.4	9	NA	NA	95	NA	0	1	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.2	NA	4.4	NA	NA	NA	0	0	0
1	8.9	4.2	NA	107	NA	0	0	0
0.6	NA	1.5	NA	102	NA	0	1	1
0.3	NA	13	NA	NA	NA	0	0	0
NA	8.7	13	NA	NA	NA	0	0	0
NA	9	11	NA	NA	NA	0	0	0
0.4	9.1	10	NA	NA	NA	0	0	0
NA	NA	11	NA	NA	NA	0	0	0
0.2	NA	12	NA	NA	NA	0	0	0
0.5	NA	16	NA	NA	NA	0	0	0
NA	NA	2.8	47	105	NA	0	0	0
0.9	10	4.7	NA	NA	NA	0	0	0
0.7	NA	4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	1	0	1
0.7	NA	NA	NA	105	NA	0	0	0
0.3	NA	1.4	NA	104	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.1	9.7	1.4	NA	NA	NA	0	0	1
0.2	NA	1.9	NA	NA	NA	0	0	1
0.3	10.4	2.1	NA	NA	NA	0	0	0
0.2	NA	6.8	NA	NA	NA	0	0	1
0.3	NA	15	NA	96	NA	0	0	1
NA	NA	31	NA	98	NA	0	0	1
0.5	9.1	31	NA	105	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	70	NA	97	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9.4	NA	NA	95	NA	0	0	1
NA	NA	30	NA	NA	NA	0	0	1
0.8	9.9	NA	NA	91	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	91	NA	0	0	1
0.8	NA	NA	NA	91	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	3.2	NA	103	NA	1	0	0
10.2	9.2	15	NA	99	NA	0	0	1
7.4	8.6	NA	NA	102	NA	0	0	1
1	8	NA	NA	100	NA	0	0	0
0.7	NA	NA	NA	100	NA	0	0	1
5	NA	NA	NA	98	NA	0	0	1
5.8	8.1	NA	NA	96	NA	0	0	1
1.9	NA	NA	NA	102	NA	0	0	1
2.3	8	NA	NA	100	NA	0	0	1
9	9.7	3.4	NA	85	NA	0	0	1
0.5	NA	NA	NA	105	NA	0	0	0
0.4	NA	2.1	NA	NA	NA	0	0	0
1.2	9.9	NA	NA	104	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.3	9.8	NA	NA	99	NA	0	0	0
0.3	8.8	NA	17	101	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	1
NA	NA	2.5	NA	105	197	0	0	0
0.1	NA	1.5	NA	NA	NA	0	0	0
0.2	9.3	1.7	NA	NA	NA	0	0	0
0.3	9.7	1.9	NA	102	241	0	0	0
1.8	NA	2.3	17	109	NA	0	0	0
NA	NA	5.9	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	102	NA	0	0	0
3.6	8.4	NA	NA	104	NA	0	0	0
0.5	8.6	2	NA	108	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	9.3	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	8.1	NA	NA	112	NA	0	0	1
0.4	9.6	NA	NA	102	NA	0	0	1
0.2	8.9	NA	NA	106	NA	0	0	1
0.3	8.7	NA	NA	103	NA	0	0	0
0.5	NA	2.7	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	101	NA	0	0	0
0.2	NA	NA	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	NA	1.5	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.3	9.1	1.7	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.6	12	NA	NA	0	0	0
1.5	8.8	2.6	NA	101	NA	0	0	1
4	NA	17	NA	NA	NA	0	0	1
0.3	9.3	80	NA	103	NA	0	0	0
0.2	NA	2.9	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	1
0.4	NA	1.8	NA	NA	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.7	NA	3.8	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
0.7	NA	3	NA	NA	NA	0	0	0
0.3	8.9	NA	NA	101	NA	0	0	1
0.1	NA	4.4	NA	NA	NA	0	0	1
NA	NA	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	7.7	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	7.7	NA	NA	NA	0	0	1
0.4	NA	6.5	NA	NA	NA	0	0	1
6.1	8.2	19	NA	102	NA	0	0	1
0.3	NA	2.6	NA	104	NA	0	0	0
0.6	9.3	67	NA	101	194	0	0	1
1	9.8	4.6	NA	100	NA	0	0	0
2.4	9.7	NA	NA	104	NA	1	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.6	NA	2.4	NA	NA	NA	0	0	0
0.7	NA	2.1	NA	96	NA	0	0	1
NA	NA	1.7	NA	NA	NA	0	0	0
NA	NA	5.8	NA	104	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.5	9.9	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	1	0	1
0.5	NA	4.7	NA	100	NA	1	0	1
0.5	9.8	5.5	NA	NA	NA	0	0	1
0.7	9.9	3.5	NA	NA	NA	1	0	1
0.6	NA	NA	NA	NA	NA	1	0	1
0.5	NA	NA	NA	NA	NA	1	0	1
0.6	NA	3.8	NA	NA	NA	1	0	1
0.6	NA	NA	NA	NA	NA	1	0	1
0.5	NA	4.1	NA	NA	NA	1	0	1
0.6	NA	3.9	NA	NA	NA	0	0	1
0.5	NA	3.2	NA	NA	NA	1	0	1
0.5	NA	3.1	NA	NA	NA	1	0	1
0.5	NA	NA	NA	NA	135	1	0	1
0.4	NA	NA	NA	NA	NA	1	0	1
0.5	NA	NA	NA	NA	NA	1	0	1
0.5	NA	NA	NA	NA	NA	1	0	1
0.4	NA	NA	NA	NA	NA	1	0	1
0.5	NA	NA	NA	NA	NA	1	0	1
0.4	9.5	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	1	0	1
0.4	NA	NA	NA	NA	NA	1	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	2.4	NA	100	NA	0	0	0
NA	NA	NA	25	NA	NA	0	0	0
0.5	10.6	6.9	NA	94	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
1.9	7.7	8	NA	111	NA	0	0	0
0.5	9.5	21665	3173	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.8	10.6	NA	NA	103	NA	0	0	1
1	10.7	4.5	NA	106	NA	0	0	1
1	9.5	NA	NA	104	93	0	0	0
0.9	NA	1.4	NA	NA	NA	1	0	0
1.8	8.6	NA	NA	97	NA	1	0	0
0.3	10.1	1.3	NA	100	NA	0	0	0
2.1	7.8	9.8	NA	105	NA	0	0	0
23.2	NA	7.2	NA	102	NA	0	1	1
3.4	NA	7.1	NA	106	NA	0	0	1
0.3	NA	9.1	NA	NA	NA	0	0	0
5.5	8.8	4.6	NA	114	NA	0	0	0
0.5	10	NA	NA	96	NA	0	0	1
NA	NA	5.3	NA	99	NA	0	0	0
0.8	NA	4	NA	NA	NA	0	0	0
0.9	NA	14	NA	NA	NA	0	0	0
0.3	NA	NA	NA	102	NA	0	0	0
0.3	NA	NA	5449	100	NA	0	0	0
14	8.8	2.1	NA	102	NA	0	0	1
5.6	NA	NA	NA	NA	NA	0	0	1
4.9	NA	NA	NA	NA	NA	0	0	1
0.4	10.1	2.9	NA	104	NA	0	0	1
0.4	10.2	2.9	NA	104	NA	0	0	1
NA	NA	2.6	NA	NA	NA	0	0	1
NA	NA	2.6	NA	NA	NA	0	0	1
0.5	NA	2.1	NA	NA	NA	0	0	1
0.4	9.8	1.5	NA	NA	NA	0	0	1
0.3	9.5	1.5	NA	105	NA	0	0	1
0.4	NA	1.9	NA	NA	NA	0	0	1
1	NA	3.4	NA	NA	NA	0	0	1
NA	NA	4.1	NA	NA	NA	0	0	1
1	9.5	4	25	103	NA	0	0	1
1.1	NA	4.7	NA	NA	NA	0	0	1
0.9	9.7	4.8	NA	NA	NA	0	0	1
1.2	NA	5.2	NA	NA	NA	0	0	1
0.8	9.3	6.4	NA	107	NA	0	0	1
0.8	9.5	6.2	NA	106	NA	0	0	1
1	9.8	6.2	NA	NA	NA	0	0	1
1.4	NA	6.5	NA	NA	NA	0	0	1
0.8	NA	4.7	NA	NA	NA	0	0	1
0.8	9.3	4.2	NA	NA	NA	0	0	1
1.2	9.4	3.8	NA	105	NA	0	0	1
0.8	NA	NA	42	NA	NA	0	0	1
4.7	8.2	6.5	NA	112	140	0	0	1
NA	8.6	NA	NA	106	NA	0	0	1
5.4	8.4	3.1	NA	107	NA	0	0	1
NA	NA	1.4	NA	NA	NA	0	0	0
0.2	NA	1.6	NA	NA	NA	0	0	0
0.4	8.7	NA	NA	93	NA	0	0	1
0.6	7.9	NA	NA	85	NA	0	0	1
2.7	9.2	1.9	NA	105	NA	0	0	0
2.2	NA	NA	NA	NA	NA	1	0	0
1.9	NA	NA	NA	NA	216	1	0	0
1.8	NA	NA	NA	NA	NA	0	0	0
2.1	NA	NA	NA	NA	NA	1	0	0
1.9	NA	NA	NA	NA	NA	1	0	0
7.5	8.3	NA	NA	105	NA	0	0	0
7.5	8.9	1.2	NA	105	NA	1	0	0
10.4	NA	NA	NA	103	NA	1	0	0
9.7	NA	1.3	NA	100	NA	1	0	0
9.1	NA	NA	NA	111	NA	1	0	0
6.6	9	NA	NA	109	NA	1	0	0
1.6	9	6.3	NA	NA	NA	0	0	1
6.2	NA	NA	NA	96	NA	0	0	1
0.4	8.9	1.7	11	103	191	0	0	0
8.8	9.1	5.2	NA	103	NA	0	0	0
3.2	11.4	6.9	NA	117	NA	0	1	1
1.1	8.7	2.5	NA	107	NA	0	0	0
0.2	9.2	4.9	NA	101	NA	0	0	0
0.1	8.6	5.8	NA	103	NA	0	0	0
0.4	8.8	2.9	NA	101	NA	0	0	0
0.6	NA	2.6	NA	NA	NA	0	1	0
NA	9.2	1.3	NA	102	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.7	NA	1.8	NA	NA	NA	0	0	1
13.5	NA	3.6	NA	97	NA	0	0	1
NA	8.6	2.1	NA	107	NA	0	0	0
0.4	9.4	3.7	45	101	NA	0	0	0
NA	NA	2.3	NA	103	NA	0	0	0
NA	9.3	3.2	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
1.7	7.7	2.8	NA	100	358	0	0	1
1.8	NA	NA	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
10.2	9.2	9.9	NA	105	NA	0	0	1
1.8	8.5	3.2	NA	106	NA	0	0	0
3	8.4	6.7	NA	89	NA	0	0	0
0.9	8.4	80	NA	97	NA	0	0	1
0.2	NA	2.5	NA	NA	206	0	0	0
0.3	NA	3	NA	NA	NA	0	0	0
0.2	NA	NA	23	NA	NA	0	0	0
0.4	NA	3.3	15	108	NA	0	0	0
0.5	9.5	5.5	NA	102	NA	0	0	0
0.6	9.5	NA	NA	101	NA	0	0	0
0.5	8.9	NA	NA	101	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.8	8.8	NA	NA	103	150	0	0	0
0.3	8.9	6.5	NA	97	NA	0	0	1
2.2	NA	NA	NA	99	NA	0	0	0
0.2	9.7	NA	NA	104	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
NA	NA	23	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	41	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	1
1.6	9	NA	NA	101	NA	0	0	1
1.9	8.3	20	NA	100	NA	0	1	1
1.2	NA	NA	NA	95	NA	0	0	1
1.1	NA	NA	NA	90	119	0	0	1
2.9	10.1	6.8	NA	85	140	0	0	0
17.8	8.1	14	NA	106	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	9.5	NA	NA	101	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
1.8	8.4	16	NA	106	NA	1	0	1
5.9	8.8	4	NA	97	211	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
13.6	7.8	5.7	NA	99	NA	0	0	0
8.5	8.8	NA	NA	112	NA	0	0	1
0.4	9.4	3.4	NA	100	NA	0	0	1
0.7	9.8	8.9	NA	103	NA	0	0	1
NA	NA	1.4	NA	NA	NA	0	0	0
NA	10.3	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	7.4	NA	NA	122	NA	0	0	1
2.5	8.4	5.2	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	1	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
10.2	8.5	6.9	NA	94	NA	0	0	1
0.3	NA	2	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
1.3	NA	8.9	NA	102	NA	0	0	1
9.6	8.7	4.6	NA	99	NA	0	0	1
2.7	8.7	4.3	NA	102	NA	0	0	0
0.7	8.7	3.3	NA	104	NA	0	0	0
1.2	9.4	NA	NA	101	NA	0	0	1
0.3	8.6	NA	NA	102	NA	0	0	1
0.4	NA	NA	NA	102	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
1.8	NA	4.4	NA	107	NA	0	0	0
1.2	9.1	7	NA	103	NA	0	0	1
7	9.6	5.6	NA	97	NA	0	0	1
2	9.2	3.9	NA	107	NA	0	0	0
0.2	NA	2.1	NA	NA	NA	0	0	0
0.6	NA	2.4	NA	NA	NA	0	0	0
2.5	9.7	1.7	NA	95	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
1	NA	1.9	NA	NA	NA	0	0	0
NA	NA	1.5	6.8	106	154	0	0	0
NA	NA	2.4	NA	NA	NA	0	0	0
6.8	7	18	NA	92	NA	0	0	1
0.7	NA	4	NA	NA	NA	0	0	1
0.8	NA	3.8	NA	NA	NA	1	0	1
4.4	8.9	NA	NA	101	NA	0	0	1
0.5	7.9	7.3	NA	104	NA	0	0	0
15.7	8.8	6.3	NA	102	NA	1	0	1
9.1	8.9	NA	NA	102	NA	1	0	1
7.7	NA	NA	NA	103	NA	1	0	1
2.9	NA	4.8	NA	105	NA	0	0	0
1.3	NA	NA	NA	109	NA	0	0	0
2.8	9	10	NA	108	NA	0	0	0
0.9	NA	NA	NA	NA	180	0	0	0
1.2	NA	3.1	NA	101	NA	0	0	1
2.6	8.7	6.4	NA	104	NA	0	0	1
1.8	NA	NA	NA	105	NA	0	0	1
0.8	NA	154	NA	NA	NA	0	0	1
NA	NA	205	NA	NA	NA	0	0	1
0.4	NA	303	NA	NA	NA	0	0	1
0.4	8.6	491	NA	104	NA	0	0	1
1.1	8.5	NA	NA	NA	NA	0	0	1
1.9	NA	NA	NA	NA	NA	0	0	1
1.9	NA	1406	NA	NA	NA	0	0	1
21.1	9.6	4.4	NA	94	NA	0	0	1
4.1	7.9	11	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.9	NA	2.2	NA	NA	NA	0	0	0
1.4	9	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	101	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	6.5	160	102	NA	0	0	1
0.4	8.2	4.3	NA	107	NA	0	0	1
5.3	9.1	NA	NA	102	NA	0	0	1
5.2	9	20	NA	96	NA	0	0	1
NA	9.7	4.2	NA	NA	NA	0	0	0
2.1	NA	7.4	NA	107	NA	0	0	0
0.5	7.2	1.4	NA	95	NA	0	0	0
0.5	9	NA	NA	101	NA	0	0	0
NA	NA	2.7	NA	NA	NA	0	0	0
0.5	NA	2.8	NA	NA	NA	0	0	0
0.6	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	2.8	NA	NA	NA	0	0	0
0.4	9.8	2.7	NA	NA	NA	0	0	0
0.5	10	2.8	NA	NA	NA	0	0	0
0.4	NA	3.4	NA	NA	NA	0	0	0
0.4	NA	3.9	NA	NA	NA	0	0	0
0.5	NA	4.6	NA	NA	NA	0	0	0
NA	NA	5.1	NA	NA	NA	0	0	1
NA	9.9	8.9	NA	98	NA	0	0	1
2.6	9.1	14	NA	99	NA	1	0	1
0.8	NA	NA	11	103	172	0	0	1
NA	NA	2.2	9.4	NA	NA	0	0	1
0.4	8.7	1.8	NA	102	NA	0	0	0
0.4	NA	1.9	NA	101	NA	0	0	0
0.1	NA	4.3	NA	NA	NA	0	0	0
0.2	9.5	3.7	NA	NA	NA	0	0	0
0.2	9.1	NA	NA	NA	NA	0	0	0
2	NA	3.9	NA	104	NA	0	0	0
1.5	9.2	4.1	NA	103	NA	0	0	0
0.2	9.2	NA	NA	103	213	0	0	0
0.2	9.6	NA	NA	102	228	0	0	0
0.2	9.5	NA	NA	105	NA	0	0	0
0.2	9.2	NA	NA	100	NA	0	0	0
0.1	8.8	NA	NA	104	NA	0	0	0
0.2	9.3	NA	NA	105	NA	0	0	0
0.3	9.4	NA	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.9	NA	1.9	NA	NA	NA	0	0	0
6.5	8.8	11	NA	108	NA	0	0	1
NA	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
1.1	NA	2	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
1.4	NA	2.1	NA	108	NA	0	0	0
NA	NA	6.4	NA	NA	169	0	0	0
0.6	8.4	1.1	NA	101	NA	0	0	0
NA	NA	3.1	NA	102	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	11	NA	NA	0	0	0
1.7	NA	2.1	22	NA	NA	0	0	0
0.2	10.1	2	NA	NA	NA	0	0	0
0.3	9.5	2.7	NA	114	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
NA	NA	1.9	NA	109	NA	0	0	0
NA	NA	14	NA	92	NA	0	0	1
43.1	9.5	3.5	NA	105	NA	0	0	0
0.3	9.8	2	NA	NA	NA	0	0	0
0.3	9.1	1.6	NA	NA	NA	0	0	0
0.4	NA	3	NA	NA	NA	0	0	0
NA	NA	3	NA	NA	NA	0	0	0
0.4	NA	3.7	NA	NA	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
1.5	NA	2.4	NA	103	NA	0	0	0
2.8	8.2	14	NA	100	NA	0	0	1
0.3	NA	NA	NA	106	NA	0	0	0
0.4	NA	NA	163	NA	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.3	NA	1	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	10	1.1	17	99	NA	0	0	0
6.7	NA	39	NA	NA	NA	1	0	1
0.8	9.6	2.2	NA	105	NA	1	0	1
0.3	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	2	NA	101	NA	0	0	0
0.6	NA	1.9	NA	101	NA	0	0	0
NA	NA	70	50	NA	NA	0	0	0
0.7	NA	1.9	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
12.2	8.4	2.9	NA	104	NA	0	0	0
21	NA	3.6	NA	NA	NA	1	1	1
0.6	9.1	9	NA	105	NA	0	0	0
NA	NA	1.7	NA	NA	NA	1	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	0
0.9	NA	13	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	1	0	0
0.5	9	NA	NA	102	NA	0	0	0
0.2	8.5	NA	NA	102	173	0	0	1
0.2	8.5	NA	NA	102	173	0	0	1
NA	NA	3.4	NA	90	NA	0	0	0
5.1	8	12	NA	98	NA	0	0	0
0.3	9.3	2.6	35	106	NA	0	0	0
0.7	NA	NA	NA	104	NA	0	0	1
0.6	8.9	NA	NA	104	NA	0	0	1
0.9	NA	150	NA	101	NA	0	0	1
NA	NA	140	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	235	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	124	NA	102	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	1	0
3	8.4	78	NA	105	NA	1	0	1
NA	9.9	7.3	NA	95	NA	0	0	0
0.2	9.4	NA	NA	NA	NA	0	0	0
2	8.8	1.7	NA	103	191	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
NA	9.3	1.4	NA	NA	NA	0	0	0
4.6	8.3	11	NA	106	NA	0	0	0
NA	NA	3.8	NA	102	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	1
27.3	NA	NA	NA	92	NA	0	0	1
NA	NA	2.2	NA	NA	NA	1	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	2.2	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
4.4	8.4	10	NA	114	NA	0	0	1
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
0.5	NA	1.4	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	9.4	1.1	NA	104	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	NA	NA	105	NA	0	0	1
0.4	9.2	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	8.5	NA	NA	99	NA	0	0	1
0.6	8.6	NA	NA	102	NA	0	0	1
0.6	9.1	NA	NA	100	NA	0	0	1
0.8	8.4	NA	NA	100	NA	0	0	1
0.6	8.4	NA	NA	104	NA	0	0	1
NA	8.4	NA	NA	103	NA	0	0	1
1	8.8	NA	NA	93	NA	1	0	1
0.9	8.4	NA	NA	97	NA	1	0	1
0.9	7.8	NA	NA	102	NA	0	0	1
1.1	8.4	NA	NA	103	NA	0	0	1
0.6	NA	NA	NA	102	NA	0	0	0
2.3	9.8	25	NA	101	NA	0	1	1
0.5	NA	136	NA	100	NA	0	0	1
4.4	8.7	5.6	NA	102	NA	0	0	1
0.5	NA	2.1	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.9	9.1	NA	NA	103	NA	0	0	1
0.2	9.3	143	NA	NA	NA	0	0	0
0.8	NA	13	NA	NA	NA	0	0	0
0.4	7.7	2.7	NA	109	NA	0	0	0
12.5	8.7	5.8	NA	102	NA	0	0	1
5.1	NA	NA	38	104	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	0
0.4	8.7	NA	NA	108	NA	0	0	0
12.5	9.6	2.2	NA	103	NA	0	0	0
2.8	8.8	1.3	NA	96	NA	0	0	0
0.8	8.9	7	NA	101	NA	0	0	1
0.3	9.7	NA	NA	104	178	0	0	0
0.6	8.7	NA	NA	NA	NA	0	0	0
0.7	8.7	2.5	NA	108	NA	0	0	0
19.8	9.4	6	NA	94	NA	0	0	1
1.4	NA	8.1	NA	112	NA	0	0	0
1.2	7.4	NA	NA	114	NA	0	0	0
0.3	10.8	447	NA	NA	NA	0	0	1
0.5	NA	6.9	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
4.2	8.6	2.3	NA	104	NA	0	0	1
0.5	8.2	NA	NA	100	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	106	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	0
1.1	9.5	1.5	NA	108	NA	0	0	0
1.1	NA	NA	NA	NA	NA	0	1	0
1.1	NA	1.8	NA	NA	NA	0	1	1
1.2	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.7	NA	NA	NA	1	0	1
0.6	NA	NA	17	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
0.4	NA	NA	9.5	NA	NA	0	0	0
0.3	9.6	0.8	10.3	NA	NA	0	0	0
0.4	NA	5.5	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	8.9	1.7	NA	NA	NA	0	0	0
8.2	NA	2.7	NA	NA	NA	1	0	1
0.6	9.6	NA	NA	104	NA	0	0	1
3.2	NA	NA	NA	106	NA	0	0	1
0.3	NA	2	NA	106	NA	0	0	0
0.3	9.2	1.7	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
7.4	NA	9.1	NA	NA	NA	1	0	1
0.8	NA	1.1	NA	NA	NA	0	0	0
1.6	NA	3.3	NA	104	NA	0	0	0
NA	NA	74	NA	NA	NA	0	0	1
NA	NA	49	NA	NA	NA	0	0	0
0.3	9.6	1.3	NA	NA	NA	0	0	0
NA	9.9	NA	NA	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
NA	NA	3.5	NA	NA	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
NA	NA	3.1	NA	NA	NA	0	0	0
0.2	8.9	2.8	NA	NA	NA	0	0	0
NA	9.2	3.1	NA	NA	NA	0	0	0
0.2	NA	3.4	NA	NA	NA	0	0	0
1.5	9.1	NA	NA	100	NA	1	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	9	NA	NA	102	NA	0	0	1
0.3	9.5	16	NA	100	NA	0	1	1
1.8	8.7	NA	NA	105	NA	0	0	0
1.9	9.6	NA	NA	92	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
NA	NA	2	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.2	NA	1.7	NA	NA	NA	0	0	0
NA	NA	1.7	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	9.6	NA	NA	103	NA	0	0	0
0.6	NA	1.4	NA	103	NA	0	0	0
8.8	8.6	7.2	NA	103	NA	0	0	1
12.2	8.8	9.5	NA	100	NA	0	0	1
0.3	9.4	NA	10	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	3	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.8	9	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	9.3	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
1.4	NA	2.1	NA	NA	NA	0	0	0
2.9	7.9	5.7	NA	106	NA	0	0	0
3	9.4	2.6	NA	104	NA	0	0	0
3	NA	2.4	NA	103	147	0	0	0
0.4	9.9	1	NA	NA	NA	0	0	0
NA	NA	1	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
3.2	NA	5.5	NA	99	NA	0	0	1
0.6	10.1	5.6	38	92	NA	0	0	0
1	9	2	NA	107	145	0	0	0
0.4	9.3	2.8	NA	104	NA	0	0	0
0.2	8.7	3.3	28	104	NA	0	0	0
9.6	NA	3.2	28	95	NA	0	0	1
0.5	8.2	2	NA	108	NA	0	0	0
1	8.9	2.3	NA	102	NA	0	0	0
0.2	8.9	NA	8	106	154	0	0	0
2.4	8.3	1.2	NA	99	NA	0	0	0
1.1	8	3.3	NA	106	NA	0	0	0
0.8	8.3	NA	NA	104	NA	1	0	0
1.7	9.2	NA	NA	106	NA	0	0	1
1.1	8	NA	NA	94	NA	1	0	0
6.5	NA	5.7	NA	105	NA	0	0	1
1.7	10.1	3.7	NA	96	NA	0	0	0
14.9	8.4	2.8	NA	95	NA	1	0	1
1.5	10.4	1.4	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	1	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
1	9.6	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.7	8.7	NA	NA	NA	NA	0	0	1
0.8	9.5	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	9.3	NA	NA	NA	NA	0	1	1
0.7	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.4	9.7	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.6	NA	NA	NA	NA	NA	0	0	1
1.6	11.1	NA	NA	NA	NA	0	1	1
0.4	9	NA	NA	101	NA	0	0	0
0.5	9.3	1.3	NA	105	NA	0	0	0
8.8	8.3	33	NA	108	NA	0	0	1
4.3	NA	56	NA	NA	NA	0	0	1
1.3	8.5	68	NA	103	NA	0	0	1
NA	NA	58	NA	NA	NA	0	0	1
0.3	NA	1.6	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	0
0.3	NA	2.2	NA	NA	NA	0	0	0
NA	9.7	1.8	NA	96	199	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.8	14	NA	NA	0	0	1
1.4	11	4.8	19	98	NA	0	0	0
0.6	14.1	86	NA	100	NA	0	0	0
0.3	NA	2.4	NA	103	NA	0	0	0
11.1	8.4	13	NA	98	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
2.1	8.8	2.4	NA	NA	NA	0	1	1
0.6	9.2	4.2	NA	97	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.9	9	NA	NA	100	NA	0	0	1
7.3	NA	NA	NA	94	NA	0	0	1
15.5	8.7	NA	NA	94	NA	0	0	1
12.4	NA	1.8	NA	101	NA	0	0	0
3.5	9.5	NA	NA	103	NA	1	0	0
1.4	8.5	1.3	NA	106	160	1	1	0
0.9	NA	NA	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	1	1	1
1.3	NA	NA	NA	104	NA	0	0	0
3.7	NA	NA	NA	NA	NA	1	0	0
2.7	NA	NA	NA	91	NA	0	0	0
NA	NA	NA	NA	NA	NA	1	0	1
4.4	NA	NA	NA	NA	NA	0	0	0
1	NA	41	NA	104	NA	0	0	0
0.6	NA	5.4	NA	98	NA	0	0	1
NA	NA	5	NA	NA	NA	0	0	1
3.1	9.7	14	NA	100	233	0	0	1
2.4	9.2	8.2	NA	102	NA	0	0	1
4.5	8.5	5.9	NA	98	NA	0	0	0
2.6	7.7	8.8	NA	104	NA	0	0	0
0.3	NA	1.7	NA	NA	NA	0	0	0
0.6	NA	1.8	NA	101	NA	0	0	0
0.3	9.6	NA	NA	99	NA	1	0	0
0.2	9.3	NA	NA	100	NA	1	0	0
NA	8.3	1.3	56	104	NA	0	0	0
0.4	NA	1.9	NA	108	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
0.8	NA	3.2	NA	103	NA	0	0	0
1.6	NA	1.7	NA	101	NA	0	0	1
1.6	NA	NA	NA	NA	NA	0	0	1
20.3	NA	4.9	NA	NA	NA	1	0	1
0.9	9.3	4.1	NA	102	NA	0	0	1
0.5	9	5.1	NA	NA	NA	0	0	0
NA	NA	NA	NA	104	NA	0	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
22.9	8.9	8	NA	102	NA	0	0	1
1.5	NA	NA	NA	96	NA	0	0	0
3.1	NA	2.9	NA	107	NA	0	0	1
1.1	9.5	NA	NA	NA	NA	0	0	1
3.3	NA	4.5	NA	NA	NA	1	0	1
0.4	9.3	1083	NA	100	NA	0	0	1
2.1	9	NA	NA	101	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.7	8.4	42	NA	103	NA	0	0	1
0.5	NA	147	NA	NA	NA	0	0	1
4.1	NA	NA	NA	NA	NA	0	0	0
2.5	8.7	12	NA	105	NA	0	0	1
3.2	9.9	9.4	104	106	NA	0	0	0
6.3	9.4	4.2	NA	105	NA	0	0	1
2	9.3	NA	NA	NA	NA	0	0	1
2.1	NA	4.2	NA	100	NA	0	0	1
0.5	NA	1.2	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.5	NA	1.5	14	NA	NA	0	0	0
33.5	9	4.6	NA	94	NA	0	0	1
NA	9.6	1.2	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	1
0.3	NA	1.5	NA	NA	NA	0	0	0
0.2	9.7	1.6	NA	NA	NA	0	0	0
NA	NA	6.1	NA	NA	NA	1	1	0
0.8	9.7	NA	7.1	101	NA	0	0	1
0.4	9.6	1.1	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.6	NA	5.7	NA	89	130	0	0	0
NA	9	4.2	12	102	NA	0	0	0
6.3	NA	17	NA	100	NA	0	0	1
8.4	NA	NA	NA	99	NA	0	0	1
0.5	10	NA	NA	102	NA	0	0	0
NA	9	1.1	NA	NA	NA	0	0	0
NA	10.3	NA	NA	103	NA	0	0	0
NA	8.3	NA	NA	103	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.6	9	119	NA	107	NA	0	0	1
13.2	NA	2.9	NA	NA	NA	1	0	0
3.4	8.7	3.9	NA	93	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.6	NA	NA	NA	90	NA	0	0	0
0.3	9.4	NA	NA	96	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	94	NA	0	0	0
0.4	8.7	NA	NA	98	NA	0	0	0
0.3	8.9	NA	NA	97	NA	0	0	0
0.4	NA	NA	NA	95	NA	0	0	0
0.5	9	NA	NA	96	NA	0	0	0
2.4	8	6.2	NA	102	NA	0	0	0
0.4	NA	NA	NA	102	NA	1	0	0
1.3	7.9	5.5	NA	102	NA	0	0	0
0.3	NA	NA	NA	103	NA	0	0	0
0.4	9.1	NA	NA	99	NA	1	0	0
0.3	NA	NA	NA	101	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	9	NA	NA	99	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.6	8.3	NA	NA	108	NA	1	0	0
0.6	8.4	NA	NA	105	NA	0	0	0
10.1	NA	3.2	NA	104	NA	0	0	1
1.3	8.7	4.3	NA	102	NA	0	0	1
0.3	NA	1.5	NA	NA	NA	0	0	1
0.3	NA	2.1	NA	NA	NA	0	0	0
0.1	NA	1.3	NA	NA	NA	0	0	0
1.6	9.2	3.7	NA	101	NA	0	0	0
4.9	9	9.2	NA	109	184	0	0	0
4.2	NA	NA	NA	NA	NA	0	0	0
6.4	9.4	85	NA	107	NA	1	1	1
7.9	9.6	126	NA	104	NA	0	1	1
4.7	9.4	NA	NA	103	NA	0	0	1
1.8	8.7	NA	NA	NA	NA	0	1	1
1	NA	NA	NA	NA	NA	0	1	1
0.7	8.4	NA	NA	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
1.5	8.6	NA	NA	100	NA	0	0	1
0.8	8.4	NA	NA	106	NA	0	1	1
1.3	8.5	NA	NA	103	NA	0	1	1
0.4	9.1	5.6	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	100	NA	0	0	0
0.5	NA	NA	NA	101	NA	0	0	0
1.7	NA	NA	NA	105	NA	0	0	0
2	8.6	3.5	NA	104	NA	0	0	0
0.7	8.1	4.8	NA	105	NA	0	0	0
0.7	8.8	6	NA	107	NA	0	0	0
2.7	8.2	4.6	NA	110	NA	0	0	1
0.7	NA	31	NA	99	NA	0	0	1
0.5	8.5	4	NA	108	NA	0	0	1
0.8	8.8	8.9	NA	106	132	0	0	1
1.7	NA	4	NA	101	NA	0	0	0
0.6	8.3	4.7	NA	116	138	0	0	0
0.5	NA	1.6	NA	99	NA	0	0	0
0.9	NA	4.4	NA	103	NA	0	0	0
NA	NA	7.3	NA	NA	NA	0	0	1
0.5	NA	8.2	NA	NA	132	0	0	0
5.5	NA	NA	NA	102	NA	0	0	0
0.4	8.3	NA	NA	107	NA	0	0	1
1.3	10	5.2	NA	93	192	0	0	0
1.1	9.5	5.8	NA	100	NA	0	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.9	NA	NA	NA	NA	NA	1	0	0
0.2	NA	NA	NA	NA	NA	1	0	1
0.2	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	99	188	1	0	0
0.2	NA	NA	NA	100	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	103	246	0	0	0
10.7	9	NA	NA	101	NA	0	0	1
1.8	8.7	3.6	NA	105	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9.9	NA	NA	100	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	8.8	NA	NA	NA	NA	0	0	1
0.5	6.7	27	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	92	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.7	NA	4.4	NA	NA	NA	0	0	1
0.7	8.9	1.7	NA	NA	180	1	0	0
0.3	NA	2.1	8.8	NA	NA	0	0	0
NA	9.4	2.3	NA	104	NA	0	0	0
0.3	9.6	234	NA	101	NA	0	0	0
0.9	NA	6.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
3.4	NA	1.2	NA	101	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.7	NA	2.9	NA	98	NA	0	0	0
0.6	8.7	12	NA	101	NA	1	0	0
0.8	NA	NA	NA	107	NA	0	0	1
0.9	8.9	NA	NA	98	NA	0	0	1
3.1	8.9	NA	224	98	NA	0	1	1
3.7	NA	NA	NA	NA	NA	0	0	1
1.8	8.5	4.9	NA	106	NA	0	0	1
1.6	9.2	NA	NA	101	NA	0	0	0
0.3	8.9	1.2	NA	96	NA	0	0	0
0.3	NA	3.4	NA	NA	NA	0	0	0
0.6	8.9	10	NA	96	NA	0	0	1
NA	NA	4.8	NA	NA	NA	1	0	1
41.6	10.7	NA	NA	101	NA	0	0	1
8.7	NA	NA	NA	90	NA	0	0	1
NA	NA	2.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	9.3	16	NA	100	NA	0	0	0
0.2	9.4	16	NA	101	NA	0	0	0
0.9	8.9	1.8	NA	104	NA	0	0	0
0.9	8.7	1.8	NA	103	NA	0	0	0
1.1	8.8	2.6	NA	96	NA	0	0	0
1.1	9.4	NA	NA	102	NA	1	0	0
1.2	10.1	NA	NA	103	NA	1	0	0
0.8	10	NA	NA	105	NA	0	0	0
1.2	10.5	2.7	NA	104	NA	0	0	0
0.6	9.9	NA	NA	102	NA	0	0	0
0.3	9.8	1.8	NA	105	NA	0	0	0
0.4	8.8	NA	NA	109	NA	1	0	0
0.7	9.7	NA	NA	104	NA	1	0	0
0.5	NA	NA	NA	103	NA	0	0	0
0.5	9.5	NA	NA	103	NA	0	0	0
0.5	NA	NA	NA	104	NA	0	0	0
0.7	9.6	NA	NA	99	NA	1	0	1
1	NA	NA	NA	100	NA	0	0	0
0.9	10	NA	NA	104	NA	0	0	0
0.6	NA	1.8	NA	107	NA	0	0	0
0.7	NA	NA	NA	102	NA	0	0	0
NA	NA	NA	NA	103	NA	0	0	0
NA	NA	1.1	NA	101	NA	0	0	1
NA	9.1	NA	NA	103	NA	0	0	1
NA	9.5	1.7	NA	106	NA	0	0	1
0.2	9.2	NA	NA	104	NA	0	0	0
0.8	NA	NA	NA	105	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	NA	9.4	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
3.8	NA	6.6	NA	105	NA	0	0	1
0.5	9.4	NA	NA	103	NA	0	0	1
0.4	9.5	NA	NA	103	NA	0	0	1
0.4	NA	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	103	NA	0	0	1
0.5	7.7	NA	NA	103	NA	0	0	1
0.5	NA	NA	NA	100	NA	0	0	1
0.3	NA	NA	NA	105	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	107	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.5	8.6	1.6	NA	101	NA	0	0	0
NA	NA	5.4	NA	101	NA	0	0	0
0.4	6.9	5	NA	108	NA	0	0	0
0.2	NA	5.7	NA	100	NA	0	0	0
0.3	8.8	6.8	NA	NA	NA	0	0	1
0.3	NA	6	NA	NA	NA	0	0	1
NA	8.7	2.9	NA	109	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	0	1
0.4	NA	1.5	NA	NA	NA	0	0	1
0.4	NA	1.9	NA	NA	NA	0	0	1
0.3	NA	1.8	NA	NA	NA	0	0	1
0.2	NA	NA	21	NA	NA	0	0	1
0.2	NA	1.9	NA	NA	NA	0	0	0
0.6	9.1	NA	NA	NA	NA	0	0	0
1.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
1.9	8	NA	NA	104	NA	0	0	0
NA	NA	NA	30	NA	192	0	0	0
5	NA	2.7	NA	101	NA	1	0	1
0.7	9.1	1.5	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	8.8	NA	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	1.1	NA	NA	NA	0	1	0
0.4	8.9	NA	NA	105	NA	0	0	0
1.1	8.7	1.4	NA	99	NA	0	0	0
2.1	8.9	20	NA	99	NA	0	0	1
1.5	NA	NA	NA	101	NA	0	0	1
14.1	8.6	NA	NA	91	NA	0	0	1
10.1	8.8	12	NA	89	NA	0	0	1
0.6	7.4	NA	NA	104	NA	0	0	0
6.9	NA	7.6	NA	104	NA	0	0	1
1.5	10.5	4.1	NA	100	NA	0	0	1
1	10.7	NA	NA	95	NA	0	0	1
0.5	9.1	5.4	NA	NA	NA	0	0	1
0.6	9.8	6.6	NA	NA	NA	0	0	1
NA	10.4	NA	NA	NA	NA	0	0	1
0.5	9.6	7	NA	NA	NA	0	0	1
0.4	10	7.4	NA	107	NA	0	0	1
0.3	NA	5.8	NA	NA	NA	0	0	1
0.4	9.7	7.1	NA	105	NA	0	0	1
0.4	NA	7.5	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	7.9	NA	NA	NA	0	0	1
NA	NA	7.2	NA	NA	NA	0	0	1
0.3	NA	8	NA	103	NA	0	0	1
0.4	NA	NA	NA	103	NA	1	0	1
0.4	NA	7.6	NA	103	NA	1	0	1
0.4	NA	NA	NA	NA	NA	1	0	1
0.5	NA	9.5	NA	NA	NA	1	0	1
0.4	NA	8	NA	NA	NA	1	0	1
0.5	9.3	10	NA	99	NA	0	0	1
1.2	9.6	1.4	NA	107	NA	0	0	0
NA	NA	1.6	NA	NA	NA	0	0	0
0.4	NA	2.6	NA	NA	NA	1	0	1
0.7	9.1	1.2	NA	NA	NA	0	0	0
0.5	NA	1.6	NA	NA	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
1	9	3.4	NA	NA	NA	0	0	0
1.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	4.3	NA	NA	NA	0	0	0
0.4	8.6	3.6	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	4.3	NA	NA	NA	0	0	0
0.2	8.6	5	NA	NA	NA	0	0	0
0.3	NA	6.1	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	4.8	NA	NA	NA	0	0	0
0.3	NA	4.8	NA	NA	NA	0	0	0
0.8	NA	1.4	NA	102	NA	0	0	0
NA	8.5	19	NA	103	NA	0	0	1
0.8	8.2	NA	NA	108	338	0	0	1
13.3	8	11	NA	104	NA	0	0	1
7.3	8.9	NA	NA	96	NA	0	0	0
0.6	NA	NA	NA	102	NA	0	0	0
0.4	10.1	NA	NA	100	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
3.2	NA	9	NA	104	NA	0	0	1
1.6	NA	1.5	NA	109	NA	0	0	0
0.4	9.4	67	NA	106	NA	0	0	0
25	9.5	NA	NA	103	NA	1	0	0
0.3	NA	NA	NA	95	NA	0	0	1
0.4	NA	6.2	NA	104	NA	1	0	0
NA	9.1	NA	NA	108	NA	0	0	1
0.6	12	3.4	NA	107	NA	0	0	1
0.8	8.2	1.2	NA	99	NA	0	0	0
2.2	NA	3.5	NA	106	NA	0	0	0
0.7	9.4	4	18	100	NA	0	0	0
0.6	9.3	NA	NA	99	NA	0	0	0
2.4	8.5	6.9	NA	109	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.4	9.6	NA	11	NA	NA	0	0	0
NA	8.7	4	NA	105	NA	0	0	0
0.8	NA	4.5	NA	102	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	9.1	385	NA	106	NA	0	0	1
0.5	NA	NA	NA	104	NA	0	1	1
0.5	NA	1396	NA	109	NA	0	1	1
0.6	NA	1977	NA	101	NA	0	1	1
0.8	7.5	3.1	NA	113	NA	0	0	0
NA	NA	2275	NA	98	314	0	0	0
0.7	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	6.3	NA	NA	NA	0	0	0
2.8	9.4	3.1	NA	97	NA	0	0	0
2.8	8.9	NA	NA	97	NA	0	0	0
NA	9.4	NA	NA	NA	206	0	0	0
0.2	9.1	NA	NA	NA	NA	0	0	0
42.5	9.8	6.3	NA	106	NA	0	0	1
2.3	8.6	2	NA	98	165	0	0	0
1.4	9.5	17	NA	100	NA	0	0	1
0.2	NA	1.2	NA	NA	NA	0	0	0
0.3	8.4	NA	NA	111	NA	0	0	0
0.9	NA	1.7	NA	104	NA	0	0	0
0.2	NA	2.7	NA	108	NA	0	0	0
1.9	NA	NA	NA	103	NA	0	0	1
0.5	10.1	NA	NA	97	NA	0	0	1
2.4	NA	6.9	NA	103	NA	1	0	1
3.2	9	7.5	NA	103	NA	0	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	9.8	NA	NA	102	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	101	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	102	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.6	9.6	1.9	NA	100	NA	0	0	0
1.6	NA	2.4	NA	106	NA	0	0	1
1.6	8	2.5	NA	109	NA	0	0	1
0.8	9	4	NA	97	203	0	0	1
0.4	8.3	NA	NA	107	NA	0	0	0
NA	NA	NA	37	NA	NA	0	0	0
1.2	8.2	NA	NA	103	NA	0	0	0
2	9.2	6.4	NA	101	NA	0	0	1
3.1	8.8	4.3	NA	100	157	0	0	0
0.9	9.2	3.6	46	105	NA	0	0	0
0.2	NA	1.5	NA	106	NA	0	0	1
NA	8.8	2.6	NA	100	NA	0	0	1
NA	NA	4.3	NA	NA	NA	0	0	0
0.2	NA	4.3	NA	NA	NA	0	0	0
0.5	9.9	NA	NA	101	NA	0	0	0
0.5	9.9	4.3	17	104	NA	0	0	0
7.4	NA	147	NA	102	NA	0	0	1
1.5	NA	NA	NA	NA	NA	0	0	1
0.9	8.4	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	8.3	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	8.4	465	NA	NA	NA	0	0	1
NA	8.9	628	NA	103	NA	0	0	1
0.2	10	792	NA	100	NA	0	0	1
NA	NA	4401	NA	NA	NA	0	0	1
0.6	NA	5.2	NA	103	NA	1	0	0
0.6	NA	4.8	NA	99	NA	1	0	0
0.7	NA	5.5	NA	NA	NA	1	0	0
0.6	NA	NA	NA	101	NA	0	0	0
0.5	NA	1.5	NA	102	NA	1	0	0
2	9.7	24	NA	95	NA	0	0	0
1.3	9.1	NA	NA	99	NA	0	0	0
0.5	8.6	NA	NA	99	NA	0	0	0
0.6	9.8	402	402	NA	NA	0	0	1
0.3	9.2	444	469	NA	NA	0	0	1
0.4	NA	461	NA	NA	NA	0	0	1
0.5	NA	859	NA	NA	NA	0	0	1
0.7	8.3	509	1195	98	NA	0	0	0
NA	8.7	NA	NA	NA	NA	0	0	1
NA	5.3	27	NA	97	NA	0	0	1
0.5	9.1	13	NA	NA	NA	0	0	1
NA	8.9	8.9	NA	95	NA	0	0	0
NA	8.8	10	NA	100	NA	0	0	1
NA	9.5	10	NA	NA	NA	0	0	1
NA	8.3	NA	NA	NA	NA	0	0	1
0.6	8.6	8.5	NA	NA	NA	0	0	1
0.6	9	13	NA	NA	NA	0	0	1
0.5	8.3	14	NA	NA	NA	0	0	1
NA	NA	13	NA	NA	NA	0	0	1
0.4	8.6	15	NA	NA	NA	0	0	1
NA	8.5	17	NA	NA	NA	0	0	1
NA	NA	NA	NA	105	NA	0	0	1
0.5	8.7	17	NA	NA	NA	0	0	1
0.4	8.5	20	NA	NA	NA	0	0	1
0.7	7.7	1.6	NA	105	NA	0	0	0
0.8	8.8	5.5	NA	107	NA	0	0	1
0.4	NA	6.1	NA	NA	NA	0	0	0
0.3	9.8	5.7	NA	NA	NA	0	0	0
NA	9.9	2.5	NA	101	NA	0	0	1
0.4	9.6	3.2	NA	NA	NA	0	0	1
0.4	NA	2.2	NA	NA	NA	0	0	1
0.3	9.2	NA	NA	103	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
1.3	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
1.2	NA	NA	NA	NA	NA	0	0	1
1.3	NA	NA	NA	NA	NA	0	0	1
1.8	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.7	NA	33	NA	NA	NA	0	0	1
1.8	7.6	58	NA	102	NA	0	0	1
0.7	NA	48	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
11.7	8.9	8.3	NA	103	NA	0	0	0
0.2	NA	7.2	NA	NA	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
3	NA	NA	NA	NA	NA	1	0	0
0.7	NA	3.2	NA	104	NA	0	0	0
1	NA	3.4	NA	104	NA	0	0	0
24	8.9	5.4	NA	105	NA	0	0	0
1.5	8.7	NA	NA	100	NA	0	0	1
1.8	8.4	5.7	NA	107	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	1.5	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	99	NA	0	0	0
0.2	9.6	NA	NA	108	NA	0	0	0
0.3	NA	NA	NA	106	NA	0	0	0
11.2	8.7	2.1	NA	102	NA	1	0	1
1	NA	1.1	NA	106	NA	0	0	0
NA	NA	NA	NA	NA	248	0	0	0
0.2	9.1	2	NA	NA	NA	0	0	0
0.4	9.6	2.2	NA	102	NA	0	0	1
0.4	9.4	3.5	NA	NA	NA	0	0	1
0.6	8.3	1198	NA	97	NA	0	0	1
2.6	8.2	NA	NA	107	NA	0	0	0
0.6	NA	3.3	NA	93	NA	0	0	0
0.3	NA	NA	NA	102	NA	0	0	0
0.6	10.1	2.7	NA	103	NA	0	0	0
1.8	8.6	5.9	NA	103	NA	0	0	1
59.4	9.4	3	NA	99	51	0	0	1
2.7	NA	5.7	NA	NA	NA	1	0	0
NA	NA	NA	6.1	NA	NA	1	0	0
3.3	8.5	4.9	NA	105	NA	0	0	1
2.3	8.8	NA	NA	108	NA	0	0	1
2.6	8.4	NA	NA	108	NA	1	0	0
1.9	NA	3	NA	106	NA	0	0	0
2.5	8.4	2.8	NA	108	112	0	0	0
9.6	NA	8.7	NA	NA	NA	1	0	1
0.5	9.9	3.5	NA	102	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	8.6	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.1	NA	NA	NA	NA	NA	0	0	0
0.2	8.9	5.5	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9.7	4.7	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	1	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9	NA	NA	103	NA	0	0	1
0.7	9.8	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.3	8.8	NA	NA	104	NA	0	0	1
0.4	9.3	NA	NA	101	NA	0	0	1
0.5	9.5	NA	NA	100	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
8.7	NA	3.8	NA	104	NA	0	0	0
3	NA	3.1	NA	102	NA	0	0	1
6.3	9.3	NA	NA	102	NA	0	0	1
5.1	NA	NA	NA	99	NA	0	0	1
0.4	9.9	2.6	56	NA	NA	0	0	1
0.8	9	NA	NA	NA	NA	0	0	1
0.9	8.6	NA	NA	95	NA	0	0	1
0.6	8	NA	NA	102	NA	0	0	1
0.6	7.4	4.1	NA	98	NA	0	0	1
0.5	7.4	NA	NA	104	159	0	0	1
0.6	7.9	NA	NA	101	NA	0	0	1
0.5	7.9	5.4	NA	100	NA	0	0	1
0.4	9	2.2	NA	100	NA	0	0	0
7.1	9.7	5.8	145	94	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
NA	9.1	1.5	NA	104	NA	0	0	0
0.7	NA	7.5	NA	105	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	1	1
0.3	8.8	4.9	NA	NA	NA	0	1	1
0.4	8.4	NA	NA	NA	NA	0	1	1
0.3	9.2	NA	NA	NA	NA	0	0	1
0.5	9.9	3.5	NA	95	NA	0	0	0
2.7	10	3.8	NA	97	NA	0	0	0
NA	NA	1.3	NA	NA	NA	0	0	0
1.1	NA	4	NA	NA	NA	0	0	0
2	9.2	1.5	NA	107	139	0	0	0
2.2	9.4	NA	NA	100	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.2	NA	3.4	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	3.9	12	NA	NA	0	0	0
5.4	9.5	2.6	NA	107	NA	0	0	0
3.2	NA	3.9	NA	102	NA	0	0	0
0.6	9.6	NA	NA	NA	NA	0	0	0
2.3	8.8	2.8	NA	102	NA	0	0	1
0.6	9.3	NA	24	102	NA	1	0	1
1.8	NA	NA	NA	102	NA	1	0	0
1	9.7	6.1	NA	106	NA	0	0	0
1.4	NA	2.2	NA	100	NA	0	0	0
2.9	NA	2.3	NA	103	NA	0	0	0
2.6	9.4	1.9	NA	103	216	0	0	0
1.2	9.1	4	NA	97	NA	0	0	0
0.3	8.7	155	NA	102	NA	0	0	0
NA	NA	NA	NA	103	159	0	0	0
13.3	NA	3.4	NA	NA	NA	0	0	0
0.6	9.4	NA	NA	102	NA	0	0	0
0.5	8.5	NA	NA	NA	NA	0	0	0
0.3	NA	2.7	NA	101	NA	0	0	0
NA	8.8	122	NA	98	NA	0	0	1
2.4	7.7	10	NA	107	98	0	0	1
0.5	8.1	36	630	99	NA	0	0	1
0.3	8.6	6.4	NA	NA	NA	0	0	0
0.4	NA	8.7	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	14	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	11.1	2.8	NA	NA	NA	0	0	0
1.1	8.9	1.1	NA	NA	NA	0	0	0
1.3	NA	NA	NA	109	NA	1	0	0
2	NA	NA	NA	NA	NA	1	0	0
2.6	NA	NA	NA	107	NA	1	0	0
2.6	NA	NA	NA	110	NA	1	0	0
2	8.8	1.1	NA	107	NA	0	0	0
1.6	NA	NA	NA	108	NA	0	0	0
2.4	8.8	1.2	NA	102	NA	0	0	0
3.9	8	NA	NA	111	NA	0	0	0
8.1	8.5	NA	NA	106	NA	1	0	0
0.8	9.3	NA	NA	101	NA	0	0	1
NA	NA	NA	8.3	NA	151	0	0	0
NA	9.1	NA	6.8	NA	164	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.8	8.8	2.9	NA	100	NA	0	0	0
0.3	8.6	17	NA	103	NA	0	0	1
17.1	NA	1.5	NA	100	NA	0	0	1
1.9	8.7	9.1	NA	107	NA	0	0	0
NA	10	1.4	70	101	NA	0	0	0
0.4	7.5	3.6	NA	106	NA	1	0	0
0.2	7.9	1.1	NA	108	159	0	0	0
0.2	9.8	2	NA	NA	NA	0	0	0
NA	NA	2.1	NA	NA	NA	0	0	1
NA	NA	2.4	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	0
0.8	NA	3.3	NA	101	NA	0	0	0
NA	NA	2.3	NA	NA	NA	1	0	0
0.8	10	NA	NA	100	NA	0	0	0
1.1	9.3	4	NA	92	NA	0	0	1
1.5	8.8	5.7	NA	105	NA	0	0	0
15.8	8.7	3.5	NA	106	NA	1	0	1
1.3	9.7	1.7	NA	NA	NA	0	1	0
2.8	5.2	7.9	NA	118	NA	0	0	1
0.6	9	373	NA	106	NA	0	0	1
1.9	8	3.4	NA	105	NA	0	0	1
0.7	9.1	3.3	NA	98	NA	0	0	0
1.5	NA	1.3	NA	NA	165	0	0	0
2.4	8.9	NA	NA	101	NA	0	0	0
0.5	9.6	3.5	NA	99	NA	0	0	1
0.2	NA	1.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	9.2	NA	NA	102	NA	0	0	0
NA	NA	1.6	NA	108	NA	0	0	0
0.2	NA	NA	NA	104	NA	0	0	0
0.3	NA	NA	NA	103	NA	0	1	0
0.4	NA	NA	NA	103	NA	0	0	0
0.3	NA	NA	NA	105	NA	0	0	0
0.3	9.6	NA	NA	105	NA	0	0	0
0.3	9.9	NA	NA	102	NA	0	0	0
0.3	9.6	NA	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	3.6	NA	NA	NA	0	0	1
NA	9.5	3.7	NA	106	NA	0	0	0
0.6	9.4	8.1	NA	98	NA	1	0	0
1.1	NA	NA	NA	NA	NA	0	0	0
1.3	9.6	1.6	NA	102	NA	0	0	0
1.2	NA	1.9	NA	NA	NA	1	0	0
1.1	NA	NA	NA	NA	NA	0	0	0
1.9	NA	NA	NA	NA	NA	0	0	0
1.5	NA	NA	NA	103	NA	1	0	0
NA	9.4	NA	NA	105	NA	0	0	0
0.9	NA	1.7	NA	NA	NA	0	0	0
5.2	8.9	1.2	NA	109	125	0	0	0
1.2	NA	4.5	NA	104	NA	0	0	1
0.5	7.7	2508	NA	91	NA	0	0	1
0.4	NA	11	2464	NA	NA	0	0	1
0.4	NA	12	1938	NA	NA	0	0	1
0.3	NA	11	2051	NA	NA	0	0	1
NA	NA	13	2372	NA	NA	0	0	1
NA	NA	9.4	2139	NA	NA	0	0	1
0.5	10.2	12	2304	102	NA	0	0	1
0.4	9.3	12	2316	102	NA	0	0	1
0.6	9.2	12	3496	104	NA	0	0	1
0.4	9.4	11	5881	100	NA	0	0	1
NA	NA	10	4333	NA	NA	0	0	1
0.4	9.7	11	1856	100	NA	0	0	1
0.4	9.7	11	983	101	NA	0	0	1
0.4	9.4	12	704	100	NA	0	0	1
0.9	9.4	4.5	NA	100	NA	0	0	1
0.3	NA	4.5	NA	NA	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
2.4	NA	3.7	NA	NA	NA	1	0	1
0.4	9	2.2	NA	102	NA	0	0	1
9	8.5	NA	NA	101	NA	0	0	1
5.6	8.6	8.5	NA	103	NA	0	0	1
NA	NA	2.1	NA	105	NA	0	0	0
NA	NA	NA	NA	105	NA	0	0	0
0.8	8.7	3.3	NA	107	NA	0	0	1
2.9	7.8	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	97	NA	0	0	0
10.9	8.2	2.4	NA	99	NA	0	0	1
1.8	9	NA	NA	100	NA	0	0	1
0.8	NA	NA	51	NA	NA	0	0	1
0.5	NA	NA	96	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	1	0	1
0.4	NA	NA	191	NA	NA	0	1	1
0.4	NA	NA	188	102	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	101	NA	1	1	1
NA	NA	NA	NA	NA	NA	0	1	1
4.8	8.9	3.6	NA	110	NA	0	0	1
5.4	8.1	NA	NA	106	NA	0	0	1
0.4	9.2	1.4	14	104	NA	0	0	0
0.2	NA	3.1	NA	112	NA	0	0	0
3.5	NA	16	NA	86	NA	0	0	1
3	NA	NA	NA	103	NA	1	0	1
2	8.8	3.5	NA	106	NA	0	0	1
1.5	NA	NA	NA	97	NA	0	0	0
1.7	NA	NA	NA	93	NA	0	0	1
1.3	NA	NA	NA	97	NA	0	0	0
0.3	9.3	3.2	48	103	NA	0	0	0
0.6	NA	3.7	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
2.7	8.1	1.9	NA	104	NA	1	0	0
0.6	NA	3.5	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
16.2	NA	1.7	NA	NA	NA	1	0	0
2.1	NA	11	NA	99	NA	0	0	1
1.3	8.7	8	NA	104	NA	0	0	0
0.8	9.8	4.8	NA	102	144	0	0	1
0.7	8.8	NA	NA	99	NA	0	0	1
0.6	8.8	NA	NA	100	126	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.1	NA	102	NA	0	0	0
15.1	9	6.3	NA	100	NA	1	0	1
0.5	NA	2.7	NA	NA	NA	0	0	0
2.3	9.3	3.8	NA	93	NA	0	0	1
0.3	9.1	63	NA	102	NA	0	0	1
NA	NA	2	NA	NA	NA	1	0	1
0.3	8.1	4.6	NA	103	NA	0	0	1
0.6	NA	4	NA	107	NA	0	0	0
2.7	8.8	2.3	NA	104	NA	0	0	0
0.5	8.8	13	NA	105	NA	0	0	0
2.3	9.3	4.3	NA	104	NA	0	0	0
0.8	8.9	2	NA	95	NA	0	0	0
0.8	10	2.4	NA	104	NA	0	0	0
0.9	9.5	2.2	NA	103	NA	0	0	0
0.7	9.2	4.5	NA	103	NA	0	0	0
0.6	9.6	NA	NA	104	206	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	9.7	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9.2	NA	NA	108	NA	0	0	0
0.4	8.8	NA	NA	105	NA	0	0	0
0.6	9.6	2.1	20	103	NA	0	0	1
0.5	NA	2.3	23	NA	NA	0	0	1
0.5	NA	4.2	26	NA	NA	0	0	1
0.8	8.5	7.5	NA	101	NA	0	0	0
1.1	8.6	NA	NA	95	NA	0	1	1
3	NA	12	NA	100	NA	0	0	1
2.7	8.8	8.9	NA	107	NA	0	0	1
NA	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	1
2.3	8.3	8.8	NA	103	NA	0	0	1
0.2	8.3	NA	NA	98	NA	0	0	1
2.2	NA	1.5	NA	98	NA	0	0	1
NA	NA	1.2	NA	NA	NA	0	1	1
0.6	NA	1.2	NA	NA	NA	0	0	1
0.4	8.6	1.5	NA	102	NA	0	1	1
0.2	NA	1.9	NA	101	NA	0	1	1
0.5	NA	1.6	NA	100	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	108	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	103	NA	0	1	1
0.6	9.3	NA	NA	101	NA	0	1	1
NA	NA	1.8	NA	NA	NA	0	1	1
1.8	NA	1.8	NA	NA	NA	0	1	1
0.6	NA	2.1	NA	102	NA	0	1	1
NA	NA	2.3	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.3	NA	4.1	NA	NA	NA	0	1	1
0.3	8.6	7.4	NA	103	NA	0	1	1
0.5	8.5	NA	NA	99	NA	0	0	1
0.9	10.1	NA	NA	85	NA	0	1	1
0.4	9.9	3.8	NA	103	NA	0	0	0
4.3	8.8	7	NA	101	NA	0	0	1
5.5	NA	2.8	NA	NA	NA	0	0	1
NA	9.2	1.8	NA	103	NA	0	0	1
0.4	NA	2.8	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.9	9.2	4.1	NA	NA	NA	0	0	1
0.4	NA	NA	19	NA	NA	0	0	1
0.4	9.1	6.2	NA	100	NA	0	0	0
1	NA	35	NA	107	NA	0	0	1
0.9	NA	1.7	NA	98	NA	0	0	0
0.4	NA	5.6	NA	NA	NA	0	0	1
NA	NA	5	NA	NA	NA	0	0	1
0.2	NA	6.2	NA	NA	NA	0	0	1
0.2	NA	5.8	10	NA	NA	0	0	1
3.9	8.8	4.6	NA	95	NA	0	0	1
9	8.1	NA	NA	91	NA	0	0	1
4.9	NA	NA	643	NA	NA	0	0	1
0.3	NA	3.1	NA	NA	NA	1	0	0
0.5	NA	2	NA	NA	NA	0	0	0
0.4	9.3	1872	NA	102	NA	0	0	1
15.9	8.3	28	NA	100	NA	0	0	1
5.7	9.9	NA	NA	99	NA	1	0	1
NA	NA	7.8	NA	NA	NA	0	0	1
0.6	NA	1.3	NA	NA	NA	0	0	0
0.5	NA	2.5	NA	NA	NA	0	0	1
3.9	NA	1.7	NA	NA	NA	1	0	0
3.2	NA	NA	NA	98	NA	1	0	0
9.4	NA	NA	NA	NA	NA	1	0	0
7.1	7.8	NA	NA	102	NA	0	0	0
10.2	NA	NA	NA	98	NA	1	0	0
8.3	8.4	NA	NA	94	NA	0	0	0
12	NA	NA	NA	93	NA	0	0	0
0.3	8.7	1568	486	105	173	0	0	0
NA	NA	11	NA	NA	NA	0	0	0
NA	NA	1.5	NA	NA	NA	0	0	0
0.4	9.2	NA	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	101	NA	NA	NA	0	0	0
NA	NA	146	NA	NA	NA	0	0	0
NA	NA	110	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	48	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	307	NA	NA	NA	0	0	0
10.8	NA	11	NA	98	NA	1	0	1
0.3	8.9	NA	NA	104	NA	0	0	0
0.8	8.9	1.8	NA	103	NA	0	0	0
3.4	NA	2.1	NA	NA	NA	0	0	0
1.7	NA	2.3	NA	NA	NA	0	0	0
6.2	8.4	NA	NA	95	NA	0	0	0
NA	NA	2.8	NA	102	NA	0	0	0
0.8	NA	31	NA	94	NA	0	0	0
2.4	8.5	2.5	NA	102	NA	0	0	0
0.9	NA	NA	NA	107	NA	0	0	0
3	9.2	1.9	NA	103	NA	0	0	0
0.7	9.4	NA	NA	103	NA	0	0	0
10	9.4	9.8	NA	94	NA	0	0	1
0.3	9.2	NA	NA	106	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
NA	NA	5.8	5.5	104	NA	0	0	0
27.6	8.3	NA	NA	100	NA	1	0	1
3.3	8.8	NA	NA	106	NA	0	0	1
0.8	9.1	NA	NA	103	NA	0	0	1
0.6	9	NA	NA	103	NA	0	0	1
25.5	8.5	2.1	NA	110	NA	0	0	1
0.2	NA	4.4	NA	NA	NA	1	0	0
0.8	8.1	NA	8.9	97	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	1	NA	NA	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	1
NA	NA	1	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
NA	NA	4.8	7.6	NA	NA	0	0	0
0.3	9.2	7.6	NA	98	211	0	0	1
NA	NA	5.2	NA	NA	NA	0	0	1
NA	NA	6.6	25	NA	NA	0	0	0
1	NA	NA	NA	104	NA	0	0	0
0.6	9.5	4	NA	105	NA	0	0	1
0.7	9.3	4	NA	102	192	0	0	0
20.2	7.5	86	NA	112	NA	1	0	1
7.7	8.4	1.3	NA	106	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.9	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	NA	21	NA	NA	0	0	0
0.5	NA	NA	NA	107	NA	0	0	0
1.6	8.7	NA	NA	108	NA	0	0	1
4.3	NA	NA	NA	101	NA	1	0	1
0.4	9.3	NA	NA	104	NA	0	0	1
2.7	9.1	NA	NA	108	NA	0	0	0
2.3	NA	4.5	NA	100	NA	0	0	1
4.3	NA	5.6	NA	NA	NA	0	1	1
7.8	NA	5.3	NA	100	NA	0	1	1
4.8	NA	NA	NA	NA	NA	0	0	1
2.6	9.1	NA	NA	102	NA	0	0	1
2	NA	5	NA	NA	NA	0	0	1
6.9	NA	4.9	NA	NA	NA	0	0	1
1.9	9.2	NA	NA	NA	NA	0	0	1
2	NA	5.7	NA	NA	NA	0	0	1
1	NA	5.6	NA	103	NA	0	0	1
2	8	NA	NA	101	NA	0	0	1
0.4	9.7	NA	NA	NA	NA	0	0	0
NA	8.6	NA	NA	104	NA	0	0	0
0.4	9.8	1.1	NA	102	NA	0	0	0
0.2	NA	NA	NA	105	NA	0	0	0
2.7	NA	NA	NA	NA	NA	0	0	1
0.8	9.6	4.9	NA	99	NA	0	0	1
3.7	8.7	12	NA	103	NA	0	0	1
NA	NA	1.1	NA	NA	NA	0	0	0
NA	NA	NA	6.7	NA	NA	0	0	0
NA	8.7	1	6.1	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9.8	NA	7	NA	NA	0	0	0
0.2	NA	NA	5.7	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.7	NA	6.3	NA	107	NA	0	0	0
1.4	NA	17	NA	107	NA	0	0	0
0.9	7.8	25	NA	108	NA	0	0	0
0.5	9.6	7.7	NA	93	NA	0	0	1
0.4	9.6	3.5	NA	103	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.6	NA	NA	NA	0	0	0
NA	9.4	NA	NA	102	171	0	0	0
0.8	8.2	2.7	NA	114	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	267	NA	102	NA	0	0	0
NA	11	35	NA	104	NA	0	0	1
8.8	9.7	NA	NA	95	NA	0	0	1
1.2	8.7	2.1	NA	107	NA	0	0	1
NA	NA	1.4	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
1	9.2	1.7	NA	NA	NA	0	0	0
NA	8.6	NA	NA	106	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	0	0
NA	8.9	NA	NA	106	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.6	NA	2.3	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	0
0.6	9.8	NA	NA	105	NA	0	0	0
1.4	9	6	NA	100	NA	0	0	0
1.1	NA	7.6	NA	NA	NA	0	0	0
2.7	8.9	8.5	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	8.6	NA	NA	NA	0	0	1
NA	NA	12	NA	NA	NA	0	0	0
2.5	9.5	6.5	NA	NA	NA	0	0	1
36.3	8.5	NA	NA	101	NA	0	0	1
2.1	10.2	4	NA	101	NA	0	0	0
13.2	NA	4.1	NA	97	NA	1	1	1
0.3	9.6	1.5	NA	103	NA	0	1	0
0.3	NA	1.3	NA	103	NA	0	0	0
1.6	8.7	3.8	NA	105	NA	0	0	1
0.2	8.9	1.4	22	NA	NA	0	0	0
0.7	NA	NA	NA	104	NA	0	0	1
0.7	NA	2.4	NA	100	NA	0	0	0
2.9	NA	11	NA	108	NA	0	0	1
5.3	NA	76	NA	99	NA	0	0	1
2.1	9.4	156	NA	100	NA	0	0	1
8.5	7.1	116	NA	93	NA	0	0	1
0.7	NA	4.1	NA	101	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
NA	9.3	NA	NA	103	170	0	0	0
0.5	8.1	115	326	101	NA	0	0	1
1.2	10.5	1.8	NA	NA	NA	0	0	0
0.3	NA	2.4	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	132	328	NA	NA	0	0	1
1.2	9.7	NA	NA	106	NA	0	0	0
0.8	NA	7	NA	NA	NA	0	0	0
0.5	9.6	1.8	NA	102	NA	0	0	0
0.4	9.1	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	8.7	2.1	NA	103	NA	0	0	0
0.2	NA	2.5	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	9.4	2.7	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	4.5	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9.1	NA	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	8.4	NA	NA	100	NA	0	0	1
0.3	NA	5.6	NA	NA	NA	0	0	1
0.4	7.9	6.9	NA	102	NA	0	0	1
0.4	8.7	6	NA	NA	NA	0	0	1
0.3	9	3.4	NA	NA	NA	0	0	1
0.4	9.2	NA	NA	101	NA	0	0	1
NA	NA	4.4	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	9	5.4	NA	99	NA	0	0	1
0.3	8.9	4.8	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.5	NA	NA	NA	NA	NA	0	0	1
6.5	8.4	6.4	NA	91	234	0	0	1
0.8	NA	4.1	NA	NA	NA	0	0	0
5.3	8.3	10	NA	97	NA	0	0	1
1.1	9.2	3.4	NA	98	NA	0	0	0
6.4	8.8	3	NA	101	NA	0	0	1
0.5	9.8	1.4	NA	102	NA	1	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
2	8.7	3.1	NA	109	NA	0	0	1
0.3	8.9	304	NA	104	NA	0	0	1
0.2	NA	463	NA	103	NA	0	0	1
0.4	8.5	432	NA	107	NA	0	0	1
0.9	8.2	339	NA	107	NA	0	0	1
1.3	9.3	2	NA	101	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	0
4.9	9.1	NA	NA	102	NA	1	0	1
NA	9.2	NA	NA	97	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	9.4	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	1.5	NA	NA	NA	0	0	0
NA	9.5	NA	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
14.6	9.7	32	NA	100	NA	1	0	1
NA	NA	9	NA	NA	NA	0	0	1
0.3	9.9	NA	NA	99	196	0	0	0
0.4	NA	1.9	NA	NA	NA	0	0	0
NA	NA	8.5	20	NA	NA	0	0	0
1.1	NA	NA	NA	102	NA	0	1	0
17.3	8.1	5.2	NA	103	NA	0	0	1
5.5	8.4	14	NA	100	NA	0	0	1
5.6	NA	NA	NA	100	NA	0	0	1
1.4	9.7	1.5	NA	96	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
0.3	NA	3.7	NA	NA	NA	0	0	0
0.6	NA	3.6	NA	NA	NA	0	0	0
0.4	8.2	5.8	NA	106	NA	0	0	1
0.7	8.9	NA	NA	106	NA	0	0	0
1.8	8.4	NA	NA	106	NA	0	0	1
1.5	NA	27	NA	105	NA	0	0	1
1.7	NA	1.7	NA	NA	NA	0	0	0
0.5	NA	2	NA	NA	NA	0	0	0
7.1	9.1	NA	NA	98	NA	0	0	0
0.6	NA	3	NA	102	185	0	0	0
0.6	NA	NA	NA	104	NA	0	0	1
0.4	9.5	1.6	NA	104	NA	0	0	1
0.5	9.2	1.6	NA	101	NA	0	0	1
0.5	9.2	1.5	NA	103	NA	0	0	1
0.5	9.4	NA	NA	99	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	9.1	NA	NA	94	NA	0	0	0
0.3	9.4	NA	NA	100	NA	0	0	0
0.3	9.1	NA	NA	102	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	10.4	1.3	NA	104	NA	0	0	0
4	7.9	6.7	NA	104	NA	0	0	1
2.6	NA	8.7	NA	103	NA	0	0	1
1.1	9	3.6	NA	103	NA	0	0	0
0.5	NA	1.7	NA	102	NA	0	0	0
1.1	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
10.4	8.4	1.8	NA	102	NA	1	0	1
0.5	NA	6.6	NA	102	NA	0	0	1
0.4	NA	NA	NA	103	NA	0	0	1
2.7	8.2	13	NA	98	NA	0	0	0
0.5	9.8	2.8	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.6	8.8	5.1	NA	106	122	0	0	1
0.2	NA	4.3	NA	NA	NA	0	0	0
0.2	NA	6.7	NA	NA	NA	0	0	0
0.4	NA	4	NA	NA	NA	0	0	0
1.1	9.6	NA	NA	99	NA	0	0	0
NA	NA	3.9	17	NA	NA	0	0	0
5.8	8.3	5.4	NA	NA	NA	0	1	1
2.6	8.3	4	NA	107	NA	0	1	1
3.3	8.6	NA	NA	100	NA	0	0	1
9.9	8.8	30	NA	96	NA	0	0	0
0.4	8.8	NA	NA	109	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	9.8	5.9	NA	106	NA	0	0	0
NA	NA	NA	NA	104	NA	0	0	1
0.3	7.7	NA	NA	111	NA	0	0	1
2.9	NA	9.8	NA	100	NA	0	0	1
2.5	9.7	8	NA	99	NA	0	0	1
2.3	8.7	NA	NA	105	NA	0	0	1
2	NA	NA	NA	101	NA	0	0	1
1.9	8.8	NA	NA	102	NA	0	0	1
1.4	8.6	8.8	NA	98	NA	0	0	1
1.5	9.7	6.5	NA	106	NA	0	0	1
1.7	NA	NA	NA	104	NA	0	0	1
0.8	8.8	7.3	NA	100	NA	0	0	0
8	8.8	2.9	178	100	NA	1	0	1
NA	NA	2	160	NA	NA	0	0	0
0.6	NA	NA	NA	103	NA	0	0	0
0.6	NA	1	NA	NA	NA	0	0	1
0.6	NA	1.1	36	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	7.5	NA	NA	NA	0	0	0
1.7	9.1	3.9	NA	104	NA	0	0	1
0.7	10	4.6	NA	98	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	5.2	NA	NA	NA	0	0	0
0.5	NA	4.3	NA	NA	NA	0	0	0
0.1	NA	NA	NA	105	NA	1	0	0
0.2	10	NA	NA	106	NA	0	0	0
0.5	NA	NA	175	103	NA	0	0	0
NA	NA	1.4	NA	NA	NA	1	0	0
2.3	9.2	6.4	NA	89	139	0	0	0
0.3	NA	NA	NA	110	NA	0	0	1
0.5	6.7	NA	NA	110	NA	0	0	0
0.6	9	1.5	NA	102	184	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
1.8	NA	11	NA	105	NA	0	0	1
3.2	9	6.3	NA	99	NA	0	0	1
NA	9.1	NA	NA	NA	NA	0	0	0
1.3	8.2	2.3	NA	109	NA	0	0	0
NA	9.3	4.1	NA	100	NA	0	0	1
0.3	NA	3.6	NA	NA	NA	0	0	1
0.5	NA	5.9	NA	NA	NA	0	0	1
1.3	8	NA	NA	108	NA	0	0	0
0.3	NA	1.3	NA	109	NA	1	0	0
2.4	NA	3.2	NA	99	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	1	1
1	NA	2.9	NA	101	NA	0	0	1
0.6	NA	2.8	NA	99	202	0	0	0
0.4	NA	1.3	NA	99	NA	0	0	0
0.4	9.7	160	NA	103	NA	0	0	1
0.2	NA	1.9	NA	104	NA	0	0	0
1	9.1	67	NA	99	227	0	0	1
21.5	NA	NA	NA	NA	NA	1	1	1
8.8	NA	5.6	NA	101	NA	0	0	1
1	NA	NA	NA	104	NA	0	0	0
0.7	8.2	NA	NA	104	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
1	10.2	NA	NA	105	NA	0	0	1
0.7	NA	3.8	79	104	NA	0	1	0
0.8	10.1	NA	38	102	NA	0	1	0
1	8.8	NA	NA	102	NA	0	1	0
1.4	8.6	NA	NA	102	NA	0	1	0
1.1	8.6	NA	NA	104	NA	0	1	0
1.3	NA	NA	NA	102	NA	0	0	0
2	9.2	NA	NA	94	NA	0	1	1
1.6	8.7	2.5	NA	101	NA	0	0	0
1.4	9.1	NA	NA	99	NA	0	0	1
2.3	8.8	NA	NA	95	NA	0	1	1
0.3	9.9	6.4	NA	97	NA	0	0	0
0.5	9.8	NA	NA	98	NA	0	0	0
0.7	8.4	5.7	NA	104	NA	0	0	0
1.5	8.4	6.3	NA	106	NA	0	0	0
3.4	8.6	15	NA	104	NA	0	0	0
0.6	9.1	2.2	NA	102	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	4.1	NA	108	NA	0	0	1
0.5	8.8	2.5	NA	NA	NA	0	0	1
1.2	9.2	1.4	NA	100	NA	0	0	1
3	9.6	10	NA	106	NA	0	0	0
0.6	NA	4.7	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.9	NA	NA	NA	99	NA	0	0	1
1.9	9.1	10	NA	94	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.5	8.7	1.6	NA	109	NA	0	0	0
0.6	10.1	NA	NA	106	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.7	8.2	2	NA	106	NA	0	0	0
1	10.5	5.2	NA	105	NA	0	0	1
0.5	8.7	1.2	NA	104	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	8.3	NA	101	NA	0	0	0
NA	NA	6.6	NA	NA	NA	0	0	0
0.2	9.4	6.1	NA	105	NA	0	0	0
0.8	NA	4	NA	101	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
1.8	9.4	4.2	NA	102	NA	1	0	1
1.3	NA	3.6	NA	105	NA	1	0	1
1.5	9.3	3.6	NA	100	NA	1	0	1
1.5	NA	3.3	NA	NA	NA	0	0	1
1.5	NA	NA	NA	102	NA	0	0	1
1.3	NA	3.7	NA	99	NA	0	0	1
1	NA	NA	NA	104	NA	1	0	1
1.2	NA	3.6	NA	102	NA	0	0	1
1.1	NA	3.3	NA	NA	NA	0	0	1
1.1	NA	NA	NA	100	NA	1	0	1
1.2	NA	3.3	NA	NA	NA	1	0	1
0.7	9.4	NA	NA	103	NA	1	0	1
1.2	9.3	NA	NA	101	NA	0	0	1
0.7	NA	NA	NA	104	NA	0	0	1
0.6	NA	NA	NA	102	NA	1	0	1
1.2	10.2	NA	NA	101	NA	0	0	1
0.8	NA	NA	NA	105	NA	1	0	1
1.4	9.7	NA	NA	101	NA	0	0	1
2	NA	NA	NA	103	NA	0	0	1
2.6	NA	3.3	NA	NA	NA	1	0	1
2.4	9.6	3.4	NA	102	NA	0	0	1
0.3	9.4	NA	45	NA	NA	0	0	0
1.3	8.2	1.1	NA	101	NA	0	0	0
4	9	3.3	NA	98	NA	0	0	1
NA	NA	2.2	NA	NA	NA	1	0	1
0.4	NA	2.2	NA	NA	NA	0	0	1
0.4	NA	NA	NA	99	NA	0	0	1
0.6	NA	NA	NA	107	NA	0	0	1
0.4	NA	NA	NA	108	NA	0	0	1
0.5	NA	NA	NA	102	NA	0	0	1
0.8	8.6	NA	NA	102	NA	0	0	0
2.2	9.5	NA	NA	102	NA	0	0	0
0.9	NA	3.3	40	102	NA	0	0	1
NA	NA	1.6	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.1	NA	NA	NA	0	0	0
0.3	9.6	NA	NA	NA	NA	0	0	0
0.3	9.3	1.3	NA	NA	NA	0	0	0
0.9	8.5	4	NA	99	NA	0	0	1
1.3	NA	NA	NA	100	NA	0	0	1
1	NA	NA	NA	104	NA	0	0	1
1.9	8.8	NA	NA	103	NA	0	0	1
9.1	8.3	NA	NA	103	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.6	9	1.3	NA	98	NA	0	0	1
NA	NA	1.5	NA	NA	NA	0	0	1
NA	NA	2.5	NA	NA	NA	0	0	1
5.3	8.7	4.3	NA	103	NA	0	0	1
NA	NA	2.7	NA	NA	NA	0	0	0
1.2	9.5	4	NA	103	NA	0	0	1
NA	NA	NA	NA	103	131	0	0	1
0.6	NA	2.8	NA	NA	NA	0	0	0
0.5	7.8	1.9	NA	110	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
1.2	9.2	NA	NA	106	NA	1	0	0
2.5	NA	NA	NA	NA	NA	1	0	0
14.2	NA	NA	NA	NA	NA	1	0	0
9.1	8.9	1.3	NA	104	NA	1	0	0
2.6	8.9	NA	NA	103	NA	1	0	0
2.3	NA	NA	NA	105	NA	1	0	0
2.6	NA	NA	NA	103	NA	1	0	0
2.9	8.7	NA	NA	104	NA	1	0	0
7	NA	NA	NA	106	NA	1	0	0
6.4	8.3	NA	NA	101	NA	1	0	0
9.6	8.5	NA	NA	104	NA	1	0	0
6.4	8	NA	NA	106	NA	1	0	0
37.1	8.6	NA	NA	103	NA	1	0	0
48	7.8	NA	NA	98	NA	0	0	1
21.2	8.2	3.4	NA	103	NA	0	0	1
0.4	NA	1.5	NA	NA	NA	0	0	0
NA	NA	3.3	NA	NA	NA	0	0	1
NA	NA	2.2	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
2.3	9.3	2.1	NA	101	NA	0	0	0
0.3	NA	3.9	NA	NA	NA	0	0	1
1.2	NA	3.3	NA	104	121	0	0	0
2.5	8.2	4.3	NA	102	NA	0	0	1
1.3	8.1	1.9	NA	107	NA	1	0	1
NA	8.1	NA	NA	103	NA	0	0	1
0.5	NA	NA	NA	100	NA	0	0	1
0.4	NA	NA	NA	104	NA	0	0	0
0.6	NA	NA	NA	102	NA	0	0	0
0.4	NA	NA	NA	104	NA	0	0	0
0.4	8.9	NA	NA	104	NA	0	0	0
0.5	8.6	NA	NA	100	NA	0	0	1
0.9	8.3	NA	NA	98	NA	0	0	1
0.5	8.6	NA	NA	98	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	8.2	NA	NA	100	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	7.8	NA	NA	95	NA	0	0	0
0.5	7.3	NA	NA	93	NA	0	0	1
0.6	7.6	NA	NA	97	NA	0	0	1
0.4	NA	930	NA	102	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	1	0
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	1787	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	1
3.1	8.5	4.4	43	NA	NA	1	0	1
34.6	8.1	6.6	NA	106	NA	1	0	1
5.6	NA	NA	NA	NA	NA	0	0	1
1.2	NA	NA	NA	NA	NA	0	0	1
3	NA	NA	NA	NA	NA	0	0	1
1.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
1.4	7.1	NA	NA	110	NA	0	0	1
0.5	NA	NA	NA	97	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.6	7.6	NA	NA	110	NA	0	0	1
0.5	6.9	NA	NA	104	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.3	NA	4.8	NA	NA	NA	1	0	0
0.5	NA	11	NA	103	NA	0	0	1
0.2	9.4	1.3	534	100	NA	0	0	0
0.2	NA	2.6	NA	108	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	97	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1	9.1	3.7	NA	95	NA	0	0	0
2.1	NA	4.1	NA	98	NA	0	0	0
1.4	8.6	4.9	NA	100	NA	0	0	1
0.6	NA	1.9	NA	101	NA	0	0	1
0.5	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	102	NA	1	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.7	NA	2.2	NA	NA	NA	1	0	0
0.7	NA	2.3	16	101	NA	0	0	0
0.8	NA	1.6	NA	99	NA	0	0	0
0.3	NA	1.4	NA	NA	NA	0	0	0
1.1	9.9	5.3	NA	99	NA	0	0	0
0.2	8.3	NA	202	108	NA	0	0	1
4.8	7.3	11	NA	111	NA	0	0	0
2.1	NA	3.7	NA	102	145	0	0	0
4.6	NA	3.4	NA	102	110	0	0	1
3	8.9	1.7	NA	100	134	0	0	0
25.5	9	5.1	NA	101	NA	0	0	0
NA	NA	2.3	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	98	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	1.5	NA	105	NA	0	0	0
0.5	8.9	3.7	25	100	NA	0	0	1
0.6	10	183	NA	100	NA	0	0	1
0.4	9.8	NA	NA	104	NA	0	0	0
13	NA	6.9	NA	101	NA	0	0	1
12.9	NA	NA	NA	97	NA	0	1	1
6.1	8.9	2.9	NA	103	283	0	0	0
3.1	8.6	3.3	NA	102	215	0	0	0
2.2	9.1	13	NA	118	NA	0	0	0
1.6	8.8	NA	NA	101	NA	1	1	1
1.5	9.1	2	NA	97	NA	0	0	1
1.3	9.1	1.9	NA	92	NA	0	1	1
0.9	NA	1.2	NA	101	NA	0	0	0
0.5	7.8	1.6	NA	109	113	0	0	0
0.5	8.7	NA	NA	100	NA	0	0	0
2.7	8.5	3.3	NA	102	150	0	0	1
2.5	NA	NA	NA	101	NA	0	0	1
0.8	8.3	3.8	NA	100	NA	0	0	1
1.5	8.6	2.2	NA	108	146	0	0	1
1.4	NA	NA	NA	105	NA	0	0	1
2.1	8.3	NA	NA	109	172	0	0	1
2.3	8.3	NA	NA	106	NA	0	0	1
2	NA	NA	NA	103	NA	0	0	1
6.3	8	NA	NA	108	NA	0	0	0
0.8	NA	1.4	NA	NA	NA	0	0	0
0.6	NA	1.9	NA	NA	NA	0	0	0
0.4	NA	2.3	NA	102	163	0	0	0
0.6	8.5	3.2	NA	106	NA	0	0	0
0.5	NA	NA	NA	104	NA	0	0	0
0.8	9.5	1.1	NA	107	NA	0	0	0
1.9	9.6	4.9	NA	91	NA	0	0	1
0.9	8.4	1.5	NA	106	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	0	0
12.8	8.3	4.8	NA	109	NA	0	0	1
0.2	8.9	2.6	NA	98	NA	0	0	0
0.4	8.4	NA	NA	104	181	0	0	0
22.6	9.6	3.1	96	97	NA	0	0	1
3.2	7.4	2.8	NA	99	NA	0	0	1
NA	NA	11	NA	NA	NA	0	0	0
10.8	NA	NA	NA	NA	NA	0	0	1
0.3	NA	1.7	NA	NA	NA	0	0	0
19.5	8.3	2.8	NA	117	NA	0	0	0
0.6	9.8	NA	NA	104	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.6	7.2	NA	NA	109	NA	0	1	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.5	9	4.7	NA	99	NA	0	0	0
11.8	7.7	4.4	NA	99	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	0
1.2	NA	2.2	9.2	101	192	0	0	0
15.1	8.1	5.9	NA	93	NA	0	0	1
1.8	8.9	NA	NA	99	NA	0	0	0
2.7	NA	9.2	NA	99	NA	0	0	0
0.7	9	NA	NA	100	NA	0	0	1
1.4	9	4.3	NA	93	NA	0	0	0
NA	9.2	4.3	NA	102	NA	0	0	1
NA	NA	2.1	NA	NA	NA	1	0	0
NA	NA	2.3	8.7	NA	NA	0	0	0
10.2	10.3	NA	NA	102	NA	0	0	0
5.5	9.7	3.8	NA	101	106	0	0	0
5.2	9.4	3.3	NA	104	NA	1	0	0
11.2	8.8	NA	NA	107	NA	0	0	1
0.6	NA	112	NA	99	NA	0	0	0
0.9	9.1	34	NA	100	NA	1	0	1
0.6	NA	NA	NA	100	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
1.1	9	1.5	NA	104	NA	0	0	0
2.5	7.7	2.1	NA	106	NA	0	0	0
0.5	8.8	3.3	167	107	NA	0	0	1
0.4	NA	5	NA	NA	NA	0	0	1
0.3	NA	2.9	44	NA	NA	0	0	0
NA	NA	2.7	30	NA	NA	0	0	0
0.5	9.6	1.6	19	109	NA	0	0	0
0.5	NA	2	22	106	NA	0	0	0
0.5	10.1	1.2	23	104	NA	1	0	0
0.4	NA	2.1	20	NA	NA	0	0	0
0.5	NA	2.7	22	NA	NA	0	1	0
2.4	8.9	4.6	NA	105	NA	0	0	0
4.2	8.4	NA	NA	107	NA	1	0	1
1.1	NA	9.8	NA	NA	NA	0	0	0
0.2	8.7	1.5	NA	101	NA	0	0	1
4.8	7.9	NA	NA	106	NA	1	0	1
2.3	8	NA	NA	103	NA	0	0	1
8.5	7.8	6.7	100	102	NA	1	0	1
1.2	8.4	NA	NA	98	NA	0	0	1
2.5	NA	4.2	NA	NA	NA	1	0	0
0.6	NA	NA	NA	NA	NA	1	0	0
0.9	9	4.8	NA	102	NA	0	0	1
2.2	9.5	NA	NA	95	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
3	8.2	NA	NA	104	NA	0	0	0
0.4	8.9	1.7	NA	102	NA	0	0	1
0.3	9.4	NA	NA	NA	NA	0	0	0
0.4	NA	2.5	23	96	NA	0	0	0
1.2	8.4	3.4	NA	103	NA	0	0	0
1.2	10.5	287	NA	106	NA	0	0	1
27	9.6	5.6	NA	98	NA	0	0	0
1.4	10.9	2.2	NA	106	117	0	0	0
1	9	4.1	NA	108	NA	0	0	0
0.3	9.2	2.4	NA	106	NA	0	0	0
1.1	9.7	2.2	NA	103	NA	0	0	0
5.3	8.8	5.7	NA	108	NA	0	0	0
1.1	8.8	1.8	NA	105	NA	0	0	0
0.5	NA	2.3	NA	NA	NA	0	0	0
15.5	9.7	99	NA	101	NA	0	0	0
NA	10	2.2	32	95	NA	0	0	0
0.4	NA	5.7	NA	NA	NA	0	0	1
0.2	NA	5.5	NA	101	NA	0	0	1
0.6	NA	4.3	NA	100	NA	0	0	1
0.6	NA	4.3	NA	100	NA	0	0	1
0.5	NA	NA	NA	101	NA	0	0	1
0.4	NA	NA	NA	104	NA	0	0	1
0.4	NA	NA	NA	98	NA	0	0	1
0.4	NA	NA	NA	99	NA	0	0	1
0.3	8.9	NA	NA	104	NA	0	0	1
0.2	8.8	NA	NA	108	NA	0	0	1
0.2	8.5	NA	NA	104	NA	0	0	1
0.4	8.5	NA	NA	100	NA	0	0	1
0.5	10.4	7.2	NA	106	NA	0	0	0
1.2	9.1	2.1	NA	101	NA	0	0	0
0.6	NA	2.6	NA	100	NA	0	0	0
0.3	NA	9.6	NA	NA	NA	0	0	0
0.2	NA	55	NA	NA	NA	0	0	0
0.3	NA	54	NA	NA	NA	0	0	0
1.4	NA	NA	NA	105	NA	0	0	0
0.9	NA	2.8	NA	105	NA	1	0	0
1.4	9.3	2.9	NA	104	185	0	0	0
1.1	NA	NA	NA	107	NA	1	0	0
0.5	NA	NA	NA	103	NA	0	0	0
5.7	8.6	6.5	NA	104	NA	1	0	1
0.2	NA	1.1	NA	NA	NA	0	0	1
0.2	9.3	NA	NA	100	NA	0	0	1
0.5	NA	NA	NA	99	NA	1	0	1
0.5	NA	NA	NA	98	NA	0	0	1
0.9	NA	10	NA	104	NA	1	0	1
1	NA	13	NA	NA	NA	0	0	1
13.2	NA	13	NA	100	NA	1	0	1
0.5	NA	19	NA	NA	NA	1	1	1
0.9	NA	37	NA	NA	NA	0	1	1
1.8	9.3	6.5	NA	99	NA	0	0	1
9.5	9.3	14	NA	100	NA	0	0	0
0.4	8.2	2.8	NA	93	91	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
1.5	8.1	3.2	NA	101	NA	0	0	1
0.4	9.5	NA	NA	105	NA	0	0	1
NA	NA	2.2	23	NA	NA	0	0	0
5.5	8.7	NA	NA	100	NA	0	0	0
NA	NA	2	83	NA	NA	0	0	0
13.2	NA	NA	NA	98	NA	0	0	1
1.5	NA	NA	NA	100	NA	0	0	1
1.2	8.2	2.1	NA	100	NA	0	0	1
0.4	NA	1.3	NA	99	NA	0	0	0
0.5	10.2	1.8	16	107	NA	0	0	0
0.2	9.2	NA	NA	100	NA	0	1	1
0.2	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	1	1
2.6	NA	NA	NA	NA	NA	0	1	1
1.3	9.3	NA	NA	95	NA	0	0	1
0.2	NA	3.4	NA	NA	NA	0	0	0
13.2	8.8	9.8	NA	102	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	9.1	NA	NA	NA	NA	0	1	0
0.9	NA	NA	NA	100	NA	0	1	0
0.9	NA	NA	NA	103	NA	0	0	0
NA	9.6	NA	NA	99	NA	0	1	0
0.8	9.5	1.3	NA	102	NA	0	1	0
0.6	NA	1.2	NA	104	NA	0	1	0
0.8	9.3	NA	NA	103	NA	0	0	0
0.8	9.5	NA	NA	100	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.6	NA	1.2	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	1	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
NA	NA	2.1	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	105	NA	0	0	0
NA	NA	NA	NA	104	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	105	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	105	NA	0	0	0
0.5	NA	NA	NA	104	NA	0	0	0
0.8	NA	NA	NA	105	NA	0	0	0
1	9.4	NA	NA	105	NA	0	0	0
0.5	9.7	NA	NA	103	NA	0	0	0
0.6	9.6	NA	NA	101	NA	0	0	0
0.4	9.8	NA	NA	102	NA	0	0	0
0.7	9.3	NA	NA	NA	NA	0	0	0
0.5	9.7	NA	NA	94	NA	0	0	0
0.4	9.5	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	9.8	NA	NA	95	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
9.9	9.1	NA	NA	109	NA	1	1	0
15.3	8.6	5.8	NA	107	NA	1	0	0
2.7	8.1	4.1	NA	106	NA	0	0	0
0.9	NA	NA	NA	NA	NA	1	0	0
1	NA	NA	NA	NA	NA	1	0	0
1.3	8.8	3.2	NA	109	NA	1	0	0
1	NA	NA	NA	98	NA	0	0	0
3.3	NA	NA	NA	100	NA	1	0	0
1.5	9.4	NA	NA	106	NA	1	0	0
3.1	NA	NA	NA	NA	NA	1	0	0
2.4	NA	NA	NA	102	NA	0	0	0
2.5	NA	NA	NA	NA	NA	1	0	0
2.2	NA	NA	NA	94	NA	1	0	0
1.7	8.9	5.2	477	99	NA	0	0	0
0.9	9.2	NA	NA	102	NA	0	0	0
5.2	7.6	54	NA	101	NA	0	0	1
2	8.8	8.2	NA	107	139	0	0	1
0.7	8.7	1.6	NA	103	120	0	0	0
0.7	8.8	4.2	NA	105	NA	0	0	0
3	9.1	11	NA	102	129	0	0	0
1.7	9.3	21	NA	101	NA	0	0	1
2.4	8.2	3.6	NA	104	NA	0	0	0
0.9	8.8	3.2	NA	95	NA	0	0	0
NA	8.7	5.3	NA	92	NA	0	0	1
0.3	8.4	NA	28	103	NA	0	0	0
4.2	7.9	4.3	NA	95	NA	0	0	1
0.5	NA	759	NA	NA	NA	0	0	1
0.5	8.2	7.3	NA	109	NA	0	0	0
0.9	8	6.6	NA	106	132	0	0	0
2.1	NA	4.8	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.2	9	NA	NA	105	NA	0	0	1
0.4	NA	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.7	NA	NA	NA	NA	NA	1	0	1
1.5	9.1	NA	NA	98	NA	0	0	1
0.7	8.7	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	1.2	NA	101	NA	0	0	1
0.5	7.7	25	1093	101	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	8.5	20	NA	105	NA	0	0	1
1.6	8.8	1.6	NA	106	NA	1	0	0
0.7	8.5	3.1	NA	101	NA	0	0	0
0.7	10	4.4	NA	NA	216	0	0	1
0.5	NA	3	NA	NA	NA	1	0	1
0.5	NA	2.9	NA	NA	NA	1	0	1
0.7	NA	NA	NA	105	NA	0	0	0
0.3	9.3	11	NA	100	NA	0	0	1
0.7	9.4	10	NA	97	NA	0	0	1
2	9.1	38	NA	99	NA	0	0	1
1.7	8.6	NA	NA	99	NA	0	0	1
NA	NA	NA	NA	101	226	0	0	0
17.2	9.5	37	NA	95	NA	1	0	1
15.1	7.9	12	NA	100	NA	1	0	0
0.3	9.4	NA	NA	NA	NA	0	0	1
0.3	9.2	NA	NA	105	NA	0	0	1
0.3	9.6	NA	NA	106	NA	0	0	1
0.4	9.6	1.6	NA	NA	NA	0	0	1
NA	NA	NA	27	104	NA	0	0	0
1.4	NA	6.2	NA	NA	NA	0	0	1
1.8	9.1	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	104	151	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
20.3	9.6	5.7	NA	101	NA	0	0	1
1.8	9.4	NA	NA	102	NA	0	0	1
NA	9.7	NA	NA	97	NA	0	0	1
0.7	9.9	30	NA	NA	NA	0	0	1
1.8	9.6	16	NA	99	NA	0	0	1
0.7	NA	16	NA	NA	NA	0	0	1
0.6	9.2	35	NA	NA	NA	0	0	1
0.3	9.3	2.5	NA	97	NA	0	0	0
15.5	9.6	NA	NA	105	NA	1	0	1
0.9	7.9	5.2	NA	110	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.3	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
14.7	NA	2.5	NA	107	NA	1	0	1
1.7	7.5	NA	NA	103	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2	NA	NA	NA	0	0	0
NA	NA	1.9	NA	NA	NA	0	0	0
0.7	NA	1.9	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.5	NA	2.1	NA	NA	NA	0	1	0
0.4	NA	2.1	NA	102	NA	0	1	0
0.5	NA	NA	NA	NA	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	1.3	NA	NA	NA	0	0	0
NA	NA	2.6	NA	101	NA	0	1	1
NA	NA	2	NA	NA	NA	0	0	0
NA	NA	2.2	NA	NA	NA	0	0	0
0.5	NA	2.1	NA	NA	NA	0	1	0
0.6	NA	2.1	NA	NA	NA	0	0	0
6.2	8.2	7.2	NA	95	NA	0	0	1
0.2	7.7	NA	266	105	NA	0	0	0
0.7	9.2	1.6	NA	105	NA	0	0	1
1.7	8.6	11	NA	104	141	0	0	1
2	9	NA	NA	103	NA	0	0	1
0.4	NA	14	NA	98	NA	0	0	0
3.2	8.7	10	NA	104	NA	0	0	1
1.2	NA	3.3	NA	104	NA	0	0	1
0.6	NA	NA	NA	102	NA	0	0	1
0.3	NA	NA	NA	103	NA	1	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
0.2	NA	NA	NA	102	NA	0	0	1
0.3	NA	2.7	NA	100	NA	0	0	1
0.3	NA	3.1	NA	NA	NA	0	0	1
0.3	9.1	2.6	NA	NA	NA	0	0	1
0.3	9	3.9	NA	NA	NA	0	0	1
0.2	NA	3.6	NA	NA	NA	0	0	1
7.7	8.5	NA	NA	108	NA	1	0	1
0.3	8.3	1.3	NA	110	NA	0	0	1
0.2	9.9	NA	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9.7	NA	NA	107	NA	0	0	0
0.3	9.7	NA	NA	107	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.6	NA	NA	NA	0	0	0
0.2	NA	1.5	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	18	NA	NA	0	0	0
3.9	NA	NA	NA	98	NA	0	0	1
4.9	NA	NA	NA	NA	NA	0	0	1
1.3	NA	NA	NA	NA	NA	0	0	1
0.6	NA	2.8	NA	NA	NA	0	0	1
2	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
1.6	8.3	NA	NA	103	NA	0	0	1
1.5	8.1	NA	NA	100	NA	0	0	1
0.5	NA	NA	NA	105	NA	0	0	1
1.8	NA	NA	NA	106	NA	0	0	1
0.5	NA	NA	NA	105	NA	0	0	1
0.3	NA	NA	NA	110	NA	0	0	1
0.3	NA	NA	NA	106	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	105	NA	0	0	1
0.4	NA	NA	NA	107	NA	0	0	1
0.6	NA	NA	NA	100	NA	0	0	1
0.5	7.6	NA	NA	103	NA	0	0	1
0.7	NA	NA	NA	110	NA	0	0	1
0.9	NA	NA	NA	100	NA	0	0	1
1.1	7.3	NA	NA	101	NA	0	0	1
0.5	9.3	2.9	NA	102	NA	0	0	0
1.3	NA	3.1	26	103	NA	0	0	0
17	9	7.4	NA	101	NA	1	0	0
0.8	NA	6.3	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	9.2	NA	NA	NA	0	0	0
NA	NA	7.4	NA	NA	NA	0	0	0
0.5	NA	7.6	NA	NA	NA	0	0	0
0.4	NA	8	NA	NA	NA	0	0	0
0.5	NA	9.2	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.8	NA	10	NA	NA	NA	0	0	0
0.6	8.5	5.7	NA	103	NA	0	0	0
0.6	8.7	9	NA	102	NA	0	0	0
0.7	9.3	NA	NA	101	NA	0	0	0
6.4	7.6	14	NA	107	NA	1	0	0
14.6	8.6	NA	NA	101	NA	0	0	0
28.5	7.9	9.2	NA	99	NA	1	0	0
4	9.1	9.1	NA	95	NA	0	0	0
1.7	8.5	9.5	NA	105	NA	0	0	1
0.2	8.6	NA	NA	98	NA	0	0	0
2.6	8.7	NA	NA	105	NA	0	0	0
0.6	8.9	1.3	NA	105	NA	0	0	0
20.8	9.2	15	NA	106	NA	1	0	1
7.4	9.1	9	NA	104	NA	0	0	1
0.8	8.9	2.1	NA	100	NA	0	0	0
0.2	7.9	2.8	NA	110	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.9	9.4	5.3	787	102	144	0	0	0
0.3	8.8	NA	NA	96	NA	0	0	0
0.5	9.3	NA	NA	99	NA	0	0	0
0.8	9.3	2.6	NA	100	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	1
0.7	9.4	NA	NA	103	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.8	9.7	NA	NA	106	NA	0	0	1
0.5	9.2	NA	NA	107	NA	0	0	1
0.8	9.3	NA	NA	107	NA	0	0	1
0.7	9.5	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	9.2	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	103	NA	0	0	1
0.7	8.9	NA	NA	105	NA	0	0	1
0.8	9.3	NA	NA	104	NA	0	0	1
NA	9.4	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	101	NA	0	0	1
0.8	8.8	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	103	NA	0	0	1
0.9	9.2	NA	NA	102	NA	0	0	1
2.6	9.8	3	NA	99	NA	0	0	0
0.6	9.7	4.9	NA	105	NA	0	0	0
0.4	NA	3.2	NA	NA	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
0.3	8.3	4.5	NA	106	NA	0	0	0
0.5	9	7.6	NA	103	NA	0	0	0
0.5	NA	4.9	NA	NA	NA	0	0	0
0.3	8.5	4.6	NA	107	NA	0	0	0
0.7	9.5	4.4	NA	107	NA	0	0	0
0.6	8.9	4	NA	NA	NA	0	0	0
0.7	8.9	4.3	NA	NA	NA	0	0	0
0.7	9.1	4.1	NA	104	NA	0	0	0
0.6	NA	4.3	NA	NA	NA	0	0	0
0.7	8.8	5.6	NA	101	NA	0	0	0
0.6	9.2	4.8	NA	105	NA	0	0	0
NA	NA	5	NA	NA	NA	0	0	0
0.6	NA	4.7	NA	NA	NA	0	0	0
17.5	NA	NA	NA	103	NA	1	0	1
NA	8.3	NA	NA	105	NA	0	0	1
0.5	8.7	NA	NA	NA	NA	0	0	1
NA	8	NA	NA	99	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	25	NA	NA	NA	0	0	1
0.7	7.8	NA	NA	97	149	0	0	1
0.9	9.8	NA	NA	NA	NA	0	0	1
NA	8.9	NA	NA	99	NA	0	0	1
0.4	8.7	NA	NA	100	NA	0	0	0
5.1	NA	4	NA	100	NA	1	0	1
0.5	8.4	3.2	NA	105	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.6	9.1	3.6	NA	105	NA	0	0	1
4.6	8.9	17	NA	100	NA	0	0	0
0.8	NA	1.5	NA	NA	NA	1	0	1
0.9	NA	47	NA	106	NA	0	0	1
0.9	8.4	NA	NA	94	NA	0	0	1
NA	NA	476	NA	NA	NA	0	0	0
NA	NA	NA	NA	105	NA	0	0	0
0.6	8.3	3.6	927	106	149	0	0	0
0.8	10.2	2.3	NA	95	NA	0	0	0
NA	NA	3.8	NA	NA	NA	0	0	1
2.2	7.6	NA	NA	101	NA	0	0	0
NA	NA	2.2	NA	107	NA	0	0	1
9.1	9.1	3	NA	97	NA	0	0	0
NA	NA	1.8	NA	NA	NA	0	1	0
NA	NA	2.1	NA	NA	NA	0	1	0
0.4	10	1.9	NA	NA	NA	0	1	0
0.3	10	1.8	NA	100	NA	0	1	0
0.4	9.3	2.6	NA	NA	NA	0	0	0
0.9	8.9	3.1	NA	98	NA	0	0	0
0.4	8.9	3	NA	NA	NA	0	1	0
0.5	9.5	NA	NA	NA	NA	0	1	0
0.8	8.9	4.7	NA	NA	NA	0	0	0
1.1	8.7	6.3	NA	NA	NA	1	1	0
0.7	8.7	5.3	NA	106	NA	0	0	0
NA	9.1	2.8	NA	103	NA	0	1	0
0.4	NA	2.4	NA	101	NA	0	0	0
0.5	NA	2.7	NA	NA	NA	0	1	0
0.3	9	2.4	NA	101	NA	0	0	0
0.3	8.7	1.6	NA	NA	NA	0	0	0
0.4	8.5	1.8	NA	NA	NA	0	1	0
0.3	8.8	2.2	NA	NA	NA	0	0	0
0.3	8.6	1.6	NA	NA	NA	0	1	0
0.3	NA	1.8	NA	103	NA	0	1	0
0.4	9.7	1.9	NA	NA	NA	0	1	0
0.3	NA	1.6	NA	NA	NA	0	1	0
2.1	7.7	2.7	NA	105	NA	0	0	1
3.2	8.5	6	NA	92	NA	0	0	1
3.3	9.2	5.7	NA	101	NA	0	0	1
0.7	NA	1291	NA	NA	NA	0	0	1
0.6	7.8	1140	NA	NA	NA	0	0	1
0.4	7.7	365	NA	NA	NA	0	0	0
0.6	NA	NA	NA	102	183	0	0	0
NA	NA	4.2	31	106	NA	0	0	0
0.9	NA	NA	NA	102	268	0	0	0
0.6	9	1.8	NA	104	NA	0	0	0
0.3	8.1	NA	NA	109	NA	0	0	0
0.3	NA	5.3	NA	NA	NA	0	0	0
34.8	9.1	3.8	NA	102	NA	0	0	1
0.5	7.9	7.2	NA	110	NA	0	0	1
0.4	10	NA	NA	100	231	0	0	0
0.7	8.9	1.6	31	101	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
1.9	NA	2.1	NA	106	NA	0	0	1
1.2	NA	NA	NA	108	NA	0	0	0
0.3	9.2	4.5	NA	100	NA	0	0	0
0.6	NA	1	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.7	8.5	2.2	NA	106	115	0	0	0
0.5	9	1.5	NA	102	NA	0	0	0
0.2	9.3	NA	NA	102	NA	0	0	1
0.3	NA	NA	NA	110	NA	0	0	0
1.8	9	5	NA	101	NA	0	0	1
0.3	NA	1.3	NA	103	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
1.5	9.4	2.3	NA	93	NA	1	0	1
2.4	8.9	14	NA	101	NA	0	0	1
0.4	9.8	1.9	NA	97	222	0	0	0
0.5	NA	1	NA	103	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
0.6	NA	1.4	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	9.8	NA	NA	101	NA	0	0	0
0.6	NA	3.5	NA	92	NA	0	0	0
0.3	NA	6.3	NA	NA	NA	0	0	0
0.6	NA	NA	NA	101	NA	0	0	0
NA	10.5	5.2	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
2.8	8.9	11	NA	91	NA	0	0	0
2	9.4	NA	NA	104	NA	0	0	0
1.3	10.9	2.6	NA	NA	NA	0	0	0
4.6	8.2	24	NA	90	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
0.3	8.3	NA	NA	97	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
2.5	NA	3.5	NA	NA	NA	0	0	1
0.6	NA	NA	NA	100	NA	1	1	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	105	NA	1	0	0
0.7	NA	NA	NA	104	NA	0	0	0
10	8	NA	NA	110	NA	1	0	0
0.2	NA	17	NA	NA	NA	0	0	1
NA	NA	7.2	NA	NA	NA	0	0	1
0.5	NA	1.5	NA	NA	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.3	9.4	1	NA	104	NA	0	0	0
3.5	8.1	13	NA	105	NA	0	0	1
0.6	NA	NA	NA	104	NA	0	0	0
1.5	9.4	1.6	NA	102	NA	0	0	0
1	9.3	1.9	NA	103	NA	0	0	0
3.2	8.4	NA	NA	107	NA	1	0	1
2	NA	1.8	NA	97	NA	0	0	0
0.3	9.6	1.8	NA	106	NA	0	0	0
41.5	9.5	9.3	NA	91	50	0	0	1
1.1	9.5	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	9.4	NA	NA	103	NA	0	0	1
1.3	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	0
1.2	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
10.1	9.4	NA	NA	102	NA	0	0	1
1.8	9.3	NA	NA	103	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	104	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
1.4	NA	NA	NA	NA	NA	0	0	1
2.1	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	106	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	8.7	NA	NA	106	117	0	0	0
0.3	8.4	NA	NA	104	NA	0	0	0
NA	9	NA	NA	104	NA	0	0	0
NA	NA	3.2	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	2.1	NA	NA	NA	0	0	1
NA	8.4	NA	NA	104	NA	0	0	1
0.4	NA	3	NA	NA	NA	0	0	1
0.4	8.6	NA	NA	105	NA	0	0	1
0.4	8.5	NA	NA	109	NA	0	0	1
0.3	8.2	NA	NA	107	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	8.7	NA	NA	102	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	8.4	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	8.7	NA	NA	109	NA	0	0	1
0.2	8.1	NA	NA	106	NA	0	0	0
2	8.8	1.6	NA	100	NA	0	0	1
1.8	8.6	2.2	NA	98	NA	0	0	1
2.5	8.2	6.4	NA	101	NA	0	0	1
1.2	8.6	4.3	NA	109	NA	0	0	0
0.4	8.7	3.2	NA	105	NA	0	0	0
4.8	8.3	3.6	NA	105	NA	0	0	1
2.5	NA	3.8	NA	NA	NA	0	0	0
0.4	NA	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.7	8.9	NA	NA	98	NA	0	0	1
0.9	NA	NA	NA	99	NA	0	0	1
NA	NA	3.3	NA	NA	NA	0	0	0
1.5	NA	3	NA	91	NA	0	0	1
2.9	NA	2.8	NA	NA	NA	0	0	1
0.4	NA	4.3	NA	102	NA	0	0	0
1.1	8.9	2.7	NA	NA	NA	0	0	1
0.4	9.7	NA	NA	100	NA	0	0	1
6.7	11	2	NA	111	NA	0	0	0
0.7	NA	NA	NA	102	NA	0	0	0
0.7	9	1.4	NA	101	NA	0	0	0
26.2	9.7	6.9	NA	89	NA	0	0	1
18.3	NA	7	NA	85	NA	0	0	1
1	10	NA	NA	104	168	0	0	0
0.9	9.8	NA	NA	105	NA	0	0	0
0.2	8.7	10	NA	111	NA	0	0	0
3.3	8.7	3.4	NA	110	NA	0	0	0
0.4	9.6	NA	NA	102	161	0	0	0
0.3	7.8	10	96	108	NA	0	0	1
34.2	9.8	16	NA	105	NA	0	0	1
1.9	8.9	4.3	NA	106	NA	0	0	0
2.8	9.8	3.6	NA	103	NA	0	0	1
2.6	9.7	NA	NA	103	NA	0	0	1
0.3	9.9	NA	NA	93	NA	0	0	0
0.3	10.2	1.7	22	107	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
1.2	7.4	3.3	74	112	NA	0	0	0
3.2	NA	3.5	NA	101	NA	0	0	0
11.6	8.8	3	NA	102	NA	1	0	1
4	8.1	9.7	NA	97	NA	0	0	1
NA	9.4	2	NA	97	NA	0	0	0
NA	9.3	2	NA	96	NA	0	0	0
3.3	NA	2.9	NA	99	NA	0	0	1
1.9	NA	NA	NA	101	NA	0	0	1
0.2	NA	1.3	53	103	NA	0	0	0
0.2	NA	1.1	36	105	NA	0	0	0
NA	NA	1.2	NA	100	NA	0	0	0
0.6	8.5	2.3	NA	100	NA	0	0	1
0.3	NA	NA	NA	102	NA	0	0	1
1	9.1	1.5	NA	104	NA	0	0	0
0.5	NA	8.3	NA	102	NA	0	0	0
0.4	NA	NA	NA	101	NA	0	0	0
0.5	NA	6.8	NA	103	NA	0	0	0
1.2	9.4	1.3	NA	95	NA	0	0	0
19	8.6	NA	NA	107	NA	1	0	1
1.8	9.1	1.6	NA	99	165	0	0	0
1.5	NA	3.9	NA	101	NA	1	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	1.3	NA	NA	NA	0	0	0
0.7	9	1.4	NA	107	NA	0	0	0
0.8	9	1.5	NA	108	NA	0	0	0
0.6	NA	NA	NA	97	NA	0	0	0
0.7	9.5	1.3	NA	94	NA	0	0	0
4.4	8.7	15	NA	115	144	0	0	1
0.5	NA	1.9	NA	NA	NA	0	0	0
0.6	NA	NA	NA	106	NA	0	0	0
NA	7.9	NA	NA	107	NA	0	0	0
0.3	8.6	427	NA	104	NA	0	0	0
0.7	8.9	NA	NA	102	NA	0	0	0
0.2	7	NA	NA	103	NA	0	0	0
13.8	9.2	NA	NA	100	NA	1	0	1
1.8	NA	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	6.4	417	NA	NA	0	0	1
0.3	NA	8.3	529	NA	NA	0	0	1
0.3	NA	9.2	433	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.5	9.6	NA	NA	108	NA	0	0	0
0.2	NA	2.2	NA	NA	NA	0	0	0
0.8	12	NA	NA	NA	NA	0	0	0
0.5	NA	3.4	NA	NA	NA	1	0	0
0.3	NA	NA	NA	102	NA	1	0	0
0.4	7.7	1.5	NA	105	NA	0	0	0
4.7	8.2	1.8	NA	106	NA	0	0	1
0.8	8.5	NA	NA	103	151	0	0	0
0.3	NA	3.1	418	103	NA	0	0	1
0.7	8	NA	492	100	NA	0	0	1
0.4	9.1	NA	NA	103	NA	0	0	0
0.4	9.8	NA	NA	104	NA	0	0	0
10.7	9.5	23	NA	111	NA	0	0	0
0.7	9.3	NA	NA	101	NA	0	0	0
NA	NA	NA	24	NA	NA	0	0	0
1.8	7.8	NA	NA	102	190	0	0	1
0.5	9.9	1.7	NA	108	223	0	0	0
0.3	9.6	2	NA	105	NA	0	0	0
0.3	9.6	2	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	2.1	NA	100	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	105	NA	0	0	0
0.3	NA	NA	NA	108	NA	0	0	0
0.3	NA	NA	NA	107	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.7	NA	100	168	0	0	0
10.2	9.2	3.9	NA	106	NA	0	0	0
0.3	8.5	3.9	NA	104	NA	0	0	0
0.8	8.4	NA	NA	100	NA	0	0	0
0.4	NA	NA	NA	NA	NA	1	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	8.1	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	8	NA	NA	102	NA	0	0	1
0.3	NA	1.2	NA	NA	NA	0	0	0
15.5	9.9	NA	NA	NA	NA	0	0	0
0.3	9.2	2.6	NA	105	NA	0	0	1
0.7	NA	NA	NA	92	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	NA	1.7	NA	NA	NA	0	0	0
0.6	10.3	2.9	NA	96	NA	0	0	1
NA	10.2	43	NA	98	NA	0	1	1
0.5	NA	NA	NA	99	NA	0	0	1
8.1	9.6	NA	NA	91	NA	0	0	1
1.1	9.6	NA	NA	104	NA	0	1	1
0.8	9.7	NA	NA	NA	NA	0	1	0
0.5	9	NA	NA	100	NA	0	0	1
0.5	9.1	NA	NA	96	NA	0	1	1
NA	9.5	NA	NA	98	NA	0	1	1
9.1	9.2	NA	NA	95	NA	0	1	1
5.5	8.8	NA	NA	94	NA	0	0	1
NA	9.9	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9.9	NA	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	103	NA	0	0	1
0.4	NA	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	101	NA	0	0	1
0.3	NA	NA	NA	96	NA	0	0	1
NA	NA	NA	NA	94	NA	0	0	1
NA	NA	140	NA	NA	NA	0	0	1
0.9	9.1	NA	NA	104	NA	0	0	1
0.4	9	NA	NA	108	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.3	8.7	34	NA	109	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	107	NA	0	0	1
0.5	NA	NA	NA	109	NA	0	0	1
0.4	NA	NA	NA	107	NA	0	0	1
0.4	8.7	73	NA	109	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	104	190	0	0	0
0.9	8.9	7.7	NA	103	NA	0	0	0
0.4	NA	1.4	NA	96	NA	0	0	1
2.7	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	1.8	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	8.6	NA	NA	98	NA	0	0	1
0.3	8.6	NA	NA	106	NA	0	0	1
0.4	9.7	NA	NA	105	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	9.3	4.9	NA	109	NA	0	0	1
0.3	9	4.8	NA	NA	NA	0	0	1
0.4	9.1	8.6	NA	NA	NA	0	0	1
0.3	9.1	11	NA	106	NA	0	0	1
0.3	8.6	8.6	NA	106	NA	0	0	1
NA	9.2	9.2	NA	107	NA	0	0	1
0.3	8.4	8.7	NA	108	NA	0	0	1
0.4	8.9	8.6	NA	107	NA	0	0	1
0.4	9	6.6	NA	107	NA	0	0	1
0.4	8.8	6.7	NA	108	NA	0	0	1
0.4	8.5	5.7	NA	108	NA	0	0	1
0.6	8.9	5.2	NA	105	NA	0	0	1
0.3	9.1	3.7	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	8.6	4.2	NA	108	NA	0	0	1
0.3	8.7	5	NA	107	NA	0	0	1
0.2	8.6	18	NA	107	NA	0	0	1
0.3	9	NA	NA	104	NA	0	0	1
0.3	NA	90	NA	103	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	0
1.3	NA	NA	NA	NA	NA	0	0	0
2.4	NA	NA	NA	NA	NA	1	0	0
1.4	NA	NA	NA	NA	NA	1	0	0
0.9	NA	NA	NA	NA	NA	1	0	0
1.1	NA	NA	NA	NA	NA	0	0	0
2.2	9.1	NA	NA	108	NA	1	0	0
2	NA	NA	NA	NA	NA	1	0	0
1.9	NA	NA	NA	NA	NA	1	0	0
20.7	8.6	2.1	NA	105	NA	1	0	0
0.7	8.8	1.6	NA	106	NA	0	0	0
3.8	8.2	3.8	NA	104	NA	0	0	1
4.8	NA	NA	NA	105	NA	1	0	1
4.9	NA	NA	NA	105	NA	1	0	1
5.6	NA	NA	NA	101	NA	0	0	1
9	7.7	NA	NA	96	NA	0	0	1
NA	9.2	1.4	NA	100	NA	0	0	0
2.4	8.9	12	NA	101	193	0	0	0
0.3	NA	4.4	NA	97	NA	0	0	1
2.9	9.1	1.9	NA	100	NA	0	0	0
0.8	8.6	2.7	NA	104	NA	0	0	0
0.8	8.9	NA	NA	102	NA	0	0	0
2.1	9.1	4.5	NA	91	NA	0	0	1
0.3	NA	2	152	NA	NA	0	0	1
0.8	9.7	NA	NA	94	NA	0	0	1
0.7	8.5	NA	NA	95	NA	0	0	1
7.5	9.6	3.1	NA	91	NA	0	0	1
2.4	NA	2.6	NA	103	NA	0	0	0
0.7	NA	2.9	NA	97	NA	1	0	1
0.3	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	97	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.3	8.4	NA	NA	98	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	92	NA	0	1	1
0.3	8.2	NA	NA	90	NA	0	1	1
0.6	7.5	NA	NA	96	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
NA	8.4	3.6	67	102	NA	0	0	0
5.2	8.3	19	NA	103	NA	0	0	1
0.3	7.9	4.6	48	104	NA	1	0	0
5.8	8.6	6.6	NA	96	NA	1	0	0
0.5	NA	NA	NA	101	NA	0	0	1
0.6	9.2	2.1	NA	101	NA	0	0	1
0.3	8.9	2.7	NA	99	NA	0	0	1
0.4	8	2	NA	101	113	0	0	0
1.4	9.5	5.3	NA	104	NA	0	0	1
3.9	8	4.5	NA	105	NA	0	0	1
1.2	8.8	NA	NA	99	NA	0	0	0
0.4	NA	NA	NA	99	NA	0	0	0
2.3	NA	3.2	NA	102	NA	0	0	1
3.4	NA	NA	NA	NA	NA	0	0	1
4.9	NA	NA	NA	102	NA	0	1	1
NA	NA	3.9	9.5	NA	NA	0	0	0
16.8	NA	2.8	NA	102	NA	0	0	1
4.7	9	NA	NA	98	NA	0	0	1
1.5	8.3	NA	NA	105	NA	1	0	0
NA	NA	1	NA	NA	NA	0	0	0
0.5	8.7	2.4	NA	98	NA	1	0	0
28.2	9	13	NA	89	NA	0	0	0
NA	NA	2.9	NA	NA	NA	0	0	0
0.6	NA	19	NA	108	NA	0	0	0
5.1	NA	31	NA	NA	NA	1	0	0
1	9.2	5	NA	102	166	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	0
4.5	8.1	13	NA	109	NA	0	0	0
NA	NA	3.4	NA	NA	NA	0	0	0
2.1	8	NA	NA	97	NA	0	0	1
14.1	6.6	1.3	NA	108	NA	1	0	1
0.2	8.3	1.4	NA	110	159	0	0	0
1.6	9	2.2	NA	106	NA	0	0	0
NA	NA	NA	NA	NA	NA	1	0	1
NA	NA	1.5	27	NA	NA	0	0	0
NA	NA	1.9	38	NA	NA	0	0	0
0.3	9.4	NA	77	111	NA	0	0	0
6.6	8.7	11	NA	96	NA	0	0	1
1.3	8.7	NA	NA	104	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	9	1.2	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1	NA	NA	NA	0	0	1
0.3	NA	1.4	NA	NA	NA	0	0	0
1.3	NA	2.9	NA	109	NA	0	0	0
12.7	8.3	5.6	NA	100	NA	1	1	1
0.4	9.9	2.2	NA	102	NA	0	1	0
8	NA	NA	NA	NA	NA	0	0	1
1.5	7.5	NA	NA	110	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.6	9	2.2	NA	107	NA	0	0	0
0.4	NA	2.7	NA	NA	NA	0	0	0
4.1	8.1	1.5	NA	105	NA	0	0	0
0.3	9.2	1.3	4722	107	NA	0	0	1
2.3	9.7	3.5	NA	NA	NA	0	0	1
0.8	9.7	2.5	NA	NA	NA	0	0	1
0.5	NA	1.4	NA	NA	NA	0	0	0
0.4	NA	1.2	NA	NA	NA	0	0	0
0.9	9.1	2	NA	103	NA	0	0	1
0.9	10	1.3	NA	98	NA	0	0	1
0.5	9.7	1.3	NA	99	NA	0	0	0
2.3	8.9	4	NA	97	NA	0	0	0
0.6	8.7	7.5	NA	104	NA	0	0	0
0.4	NA	1.2	NA	103	NA	0	0	1
12	9.2	5.5	NA	93	NA	0	0	1
1	9.3	3.5	NA	104	NA	0	0	1
0.8	NA	NA	NA	NA	NA	1	0	0
1.1	NA	NA	NA	NA	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
0.5	NA	2	NA	NA	NA	1	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	1	0	0
0.6	NA	NA	NA	NA	NA	1	0	0
0.8	NA	NA	NA	NA	NA	1	0	0
NA	NA	1.1	26	NA	NA	0	0	0
NA	NA	1.5	32	NA	NA	0	0	0
NA	NA	NA	26	NA	NA	0	0	0
NA	NA	1.1	22	NA	NA	0	0	0
0.4	NA	2974	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	9	34834	NA	NA	NA	0	0	1
0.8	NA	14955	NA	93	NA	0	0	1
NA	NA	16075	NA	NA	NA	0	0	1
0.5	NA	21044	NA	NA	NA	0	0	1
NA	NA	16742	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.9	8.2	37745	NA	95	NA	0	0	1
0.4	NA	NA	NA	NA	NA	1	0	0
0.2	NA	NA	NA	102	NA	1	0	0
0.2	NA	NA	NA	103	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.2	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.2	NA	NA	NA	104	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
4.4	9.5	2	NA	98	NA	0	0	0
0.6	9.8	NA	NA	104	NA	0	0	0
0.5	9.7	2.3	NA	102	NA	0	0	0
0.7	NA	NA	NA	102	181	0	0	0
0.9	9	1.2	7	102	177	0	0	0
0.3	8	3.3	NA	102	NA	0	0	0
0.2	8.5	2	NA	98	NA	0	0	0
0.3	10.7	NA	NA	98	NA	0	0	1
0.3	NA	NA	NA	94	NA	0	0	1
NA	NA	NA	NA	98	NA	0	0	1
0.6	9.8	1.2	NA	103	NA	0	0	0
0.6	9.1	NA	NA	104	98	1	0	1
0.6	NA	NA	NA	103	NA	0	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.8	NA	NA	NA	103	NA	1	0	0
0.5	NA	NA	NA	109	NA	1	0	0
1.3	NA	NA	NA	101	NA	1	1	0
0.6	NA	NA	NA	104	NA	0	0	0
0.6	9.1	NA	NA	108	101	0	0	0
0.6	NA	NA	NA	107	NA	0	0	1
0.5	NA	NA	NA	NA	NA	1	0	0
0.6	NA	NA	NA	104	NA	0	0	1
0.5	NA	NA	NA	104	NA	0	0	0
0.5	8.9	NA	NA	103	NA	1	1	0
0.3	9.8	NA	NA	103	NA	0	0	0
NA	9.7	NA	NA	105	NA	0	0	0
0.2	9.8	2.5	NA	NA	NA	0	0	0
0.2	NA	1.2	NA	NA	NA	0	0	0
0.9	NA	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	8.5	1.5	NA	107	NA	0	0	0
39.6	8.8	NA	NA	104	NA	0	0	0
NA	NA	2.7	NA	NA	NA	1	0	1
0.7	NA	NA	NA	102	NA	0	0	0
0.6	NA	2.2	NA	105	NA	0	0	0
1	8.9	NA	NA	97	NA	0	0	0
NA	NA	2.9	NA	NA	NA	0	0	0
0.8	8.7	2.6	NA	105	NA	0	0	0
0.8	8.8	1.8	NA	107	NA	0	0	0
NA	NA	NA	NA	108	NA	0	0	0
1	9.1	NA	NA	NA	NA	0	0	0
0.9	9	NA	NA	105	NA	0	0	0
0.7	8.9	NA	NA	107	NA	0	0	0
0.9	8.9	NA	NA	103	NA	0	0	0
1.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.8	8.9	NA	NA	105	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
5	8.8	10	NA	96	NA	0	0	1
2.5	NA	1.1	NA	NA	NA	0	0	0
1.8	9.3	308	411	100	NA	1	0	1
1.2	8.8	1.7	NA	104	NA	0	0	0
5.9	8.5	NA	NA	100	NA	0	0	0
3.4	7.2	1	NA	101	NA	1	0	0
1.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	9.8	NA	NA	106	NA	0	0	0
0.4	8.6	NA	NA	106	NA	0	0	0
0.4	NA	7.5	NA	NA	NA	0	0	1
7.3	8.4	572	NA	106	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	104	NA	1	0	1
0.5	NA	1.4	NA	108	NA	1	0	0
0.6	NA	1.3	NA	NA	NA	1	0	0
0.5	NA	1.6	NA	NA	NA	1	0	0
0.7	NA	1.3	NA	NA	NA	1	0	0
1	NA	2.3	NA	102	NA	1	0	1
0.8	NA	NA	NA	101	NA	1	0	0
0.9	8.9	NA	NA	101	NA	0	0	0
3.1	NA	NA	NA	105	NA	0	0	1
0.3	NA	1.6	NA	103	NA	0	0	1
0.3	NA	NA	NA	102	NA	0	0	1
0.2	9.1	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	108	NA	0	0	1
0.3	9.1	NA	NA	104	NA	0	0	1
0.3	NA	NA	NA	107	NA	0	0	1
0.3	8.9	NA	NA	99	NA	0	0	1
0.4	8.6	NA	NA	104	NA	0	0	1
0.4	7.9	NA	NA	104	NA	0	0	1
0.4	8.2	NA	NA	105	NA	0	0	1
0.3	8.5	NA	NA	106	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	8.5	NA	NA	105	NA	0	0	1
0.5	8.6	NA	NA	107	89	0	0	1
0.3	8.5	NA	NA	108	NA	0	0	1
0.4	8.5	NA	NA	103	NA	0	0	1
0.4	8.4	NA	NA	108	NA	0	0	1
0.5	8.8	NA	NA	107	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	8.4	NA	NA	102	NA	0	0	1
0.4	8.9	NA	NA	101	NA	0	0	1
0.3	8.8	NA	NA	NA	NA	0	0	1
0.5	8.5	NA	NA	106	NA	0	0	1
0.6	9	NA	NA	105	NA	0	0	1
0.4	9.5	NA	NA	103	NA	0	0	1
0.7	7.5	NA	10	110	86	0	0	1
0.4	8.2	NA	NA	104	NA	0	0	1
0.4	8.9	NA	NA	103	NA	0	0	1
0.2	9.2	NA	NA	106	NA	0	0	1
0.7	NA	NA	NA	103	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.6	8.3	NA	NA	108	69	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.4	9.1	2.7	NA	104	NA	0	0	0
0.9	8.5	4	NA	99	NA	0	0	1
1.6	8.8	NA	NA	99	NA	0	0	1
1.1	8.4	NA	NA	102	NA	0	0	1
1.6	8.1	4.1	NA	107	NA	0	0	0
1	8.4	1.8	NA	109	NA	0	0	0
5.5	8.6	7.3	NA	105	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.8	9	5.3	NA	106	NA	0	0	0
3.5	9.4	3.9	NA	101	NA	0	0	0
1	9.2	4.5	NA	109	NA	0	0	1
0.6	NA	NA	NA	100	NA	1	0	1
4.7	7.7	6.8	NA	99	NA	0	0	1
1.1	NA	NA	NA	94	NA	0	0	1
1.2	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	102	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
0.7	NA	1.6	NA	98	NA	0	0	0
2.2	8.3	3.4	NA	109	NA	0	0	0
0.4	9.1	NA	183	91	NA	0	0	0
4.8	NA	NA	NA	102	NA	1	1	1
1.6	10	NA	NA	102	NA	0	0	1
NA	9.2	2.3	62	98	NA	0	0	1
0.4	NA	1.9	NA	102	NA	0	0	0
0.7	8.2	1.3	NA	107	146	0	0	0
3.1	8.8	3.8	NA	97	NA	0	0	0
1	NA	1.4	NA	NA	NA	0	0	0
1.5	9.7	NA	NA	99	NA	0	0	1
1.3	NA	NA	NA	96	NA	0	0	0
1.1	9.8	NA	NA	97	NA	0	0	0
1.3	9.6	2	NA	99	NA	0	0	0
0.5	9.8	1.9	NA	101	NA	0	0	0
1.5	9.7	2.5	NA	104	NA	0	0	0
0.3	8.8	58	101	94	NA	0	0	1
0.2	9.2	NA	NA	104	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	9.5	NA	NA	106	NA	0	0	0
0.3	NA	2.1	NA	102	NA	1	0	0
0.2	NA	NA	NA	99	NA	0	0	0
0.3	8.4	1.1	NA	103	129	0	0	0
0.7	7.9	NA	NA	100	NA	0	0	0
NA	NA	2.3	NA	104	NA	0	0	0
1.3	8.6	NA	NA	99	NA	0	0	1
3.6	9	4	NA	91	NA	0	0	0
15.3	8.5	3.7	NA	94	NA	0	0	1
2.7	8	4.4	NA	102	NA	1	0	0
4.2	8.7	15	NA	90	NA	0	0	1
0.7	7.8	4.3	NA	111	NA	0	0	0
0.6	8	3.5	NA	112	NA	0	0	0
1.6	10	NA	NA	100	NA	0	1	0
NA	8.8	NA	NA	101	NA	0	0	1
0.4	8.9	NA	NA	101	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	1
0.3	9.7	NA	NA	104	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.1	7.9	4.9	71	108	NA	0	0	1
3	8.3	NA	NA	96	NA	1	1	1
NA	9.1	NA	NA	99	193	0	0	0
0.7	NA	1.4	NA	104	NA	0	0	0
1.6	9.4	NA	NA	107	NA	1	0	1
0.3	8.5	2.2	NA	NA	NA	0	0	1
0.3	9.1	1.7	NA	NA	NA	0	0	1
0.2	9.2	1.8	NA	106	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	104	NA	0	0	1
0.5	NA	NA	NA	101	NA	1	0	0
0.6	7.5	NA	NA	109	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.2	8.3	NA	388	103	NA	0	0	0
0.4	NA	1.5	NA	101	NA	0	0	0
0.5	9	NA	NA	100	NA	0	0	0
NA	9	NA	NA	104	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
2.2	NA	2.3	NA	106	NA	0	0	0
0.3	8.8	1.1	NA	NA	NA	0	0	1
0.6	8.2	NA	NA	102	NA	1	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
1.2	7.5	4.6	NA	90	NA	0	0	0
1.4	7.8	4.7	NA	94	NA	0	0	0
NA	8.8	NA	NA	108	NA	0	0	0
1.6	9.5	6.9	NA	98	NA	0	0	1
0.4	NA	1.7	NA	NA	NA	1	0	0
0.7	NA	1.8	NA	NA	NA	1	0	0
0.5	NA	2.5	NA	NA	NA	0	0	0
11.9	8.8	NA	NA	105	NA	1	0	0
2.5	9	7.7	NA	105	NA	0	0	0
0.2	9.4	2.7	NA	98	271	0	0	0
0.3	NA	2.9	NA	NA	NA	1	0	0
11.8	NA	13	NA	NA	NA	1	0	1
0.6	8.2	12	NA	106	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
3.2	8.3	4.4	NA	101	207	0	0	1
2.4	8.8	3.4	NA	106	162	0	0	1
2.1	NA	NA	NA	103	NA	1	0	0
1.6	8.7	8.8	NA	102	NA	0	0	1
0.4	9	4	NA	103	NA	0	0	0
1.6	NA	NA	NA	101	247	0	0	0
0.8	8.6	4.8	NA	103	NA	0	0	0
0.4	10	1.2	NA	89	NA	0	0	0
0.3	NA	5.3	NA	NA	NA	0	0	0
0.9	8.5	8.9	NA	102	152	0	0	0
0.6	NA	NA	NA	99	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
1.5	NA	6.7	NA	NA	150	0	0	1
1.6	8.9	9.1	NA	101	NA	0	0	1
1.7	NA	NA	NA	101	NA	0	0	1
1.6	9.2	NA	NA	101	NA	0	0	0
0.4	9.8	196	NA	103	NA	0	0	0
0.7	9.2	6	NA	96	NA	0	0	1
0.7	NA	1.3	NA	100	NA	1	0	1
NA	NA	NA	NA	100	NA	0	0	0
0.6	9.3	8.3	26	95	NA	0	0	0
0.7	NA	5.4	NA	100	NA	0	0	0
1.1	9.2	NA	NA	103	NA	0	0	0
3.6	8.4	11	NA	102	NA	0	0	1
0.3	NA	5.1	NA	103	NA	0	0	1
0.4	NA	2.6	NA	99	NA	0	0	0
0.4	NA	3.9	NA	NA	NA	0	0	0
0.2	NA	3.2	NA	NA	NA	0	0	0
0.2	NA	3.8	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	106	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	4.4	NA	NA	NA	0	0	0
0.4	9.6	3.5	NA	104	NA	0	0	0
0.3	8.8	3.4	NA	100	NA	0	0	0
0.3	9.4	4.9	NA	101	NA	0	0	0
0.3	9.6	5.4	NA	99	NA	0	0	0
0.3	NA	5.9	NA	99	NA	0	0	0
0.3	9.8	5.9	NA	100	NA	0	0	1
0.3	10.3	6.8	NA	98	NA	0	0	1
0.7	9.7	7.1	NA	93	NA	0	0	1
0.4	10.1	6.9	NA	97	NA	0	0	1
0.4	9.8	6.6	NA	100	NA	0	0	1
0.2	9.8	4.7	NA	98	NA	0	0	1
0.3	9.6	5.5	NA	101	NA	0	0	1
0.3	9.7	6.4	NA	100	NA	0	0	1
0.3	9.6	6	NA	99	NA	0	0	1
0.4	9.5	6.5	NA	100	NA	0	0	1
0.3	9.7	6.6	NA	102	NA	0	0	1
0.4	9.8	6.5	NA	101	NA	0	0	1
0.4	9.8	7	NA	103	NA	0	0	1
0.4	9.3	5.6	NA	105	NA	0	0	1
0.5	8.9	5.3	NA	105	NA	0	0	1
0.4	9.4	6	NA	106	NA	0	0	1
0.3	9.6	6.6	NA	104	NA	0	0	1
0.4	9.3	6.1	NA	106	NA	0	0	1
0.5	9.2	8.5	NA	106	NA	0	0	1
0.3	9.5	17	NA	105	NA	0	0	1
0.2	9.3	NA	NA	106	NA	0	0	1
2.3	8.4	6	NA	99	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	1
0.2	9.4	3.1	NA	102	NA	0	0	0
1.2	8.5	3.8	NA	104	NA	0	0	0
0.6	NA	3.5	NA	102	NA	0	0	1
0.6	NA	2.1	NA	99	NA	0	0	0
0.6	9.3	87	NA	96	180	0	0	1
4.9	7	NA	NA	102	NA	0	0	1
5.5	9.1	NA	NA	105	NA	0	0	0
0.5	8.3	NA	NA	101	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
12.1	9.5	NA	NA	104	NA	1	0	0
1.2	9.1	NA	NA	99	NA	0	0	0
1.2	9.4	1.1	NA	91	NA	0	0	0
0.4	9.9	NA	9	102	NA	0	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
NA	NA	2.1	9.3	NA	NA	0	0	0
0.5	9.6	1.6	14	106	NA	0	0	0
NA	9.3	2.8	7	108	NA	0	0	0
0.3	9.4	NA	NA	109	NA	0	0	0
1.4	NA	9.1	NA	98	NA	1	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
2.1	8.6	NA	NA	103	NA	0	0	1
0.9	8.2	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
1.1	8.5	NA	NA	103	NA	0	0	0
1.3	8.9	NA	NA	94	NA	0	0	0
1	8.3	NA	NA	104	NA	0	0	0
1.2	8.2	NA	NA	101	NA	0	0	0
0.7	NA	NA	NA	106	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	8.5	NA	NA	106	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	0
0.6	8.9	NA	NA	104	NA	0	0	1
0.5	8.5	NA	NA	108	NA	0	0	0
0.5	8.7	NA	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	8.4	NA	NA	106	NA	0	0	1
0.4	8.5	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9.4	5.1	NA	99	NA	0	0	1
0.3	9.4	5.6	102	100	NA	0	0	1
0.7	9.7	6.3	131	96	NA	0	0	1
0.6	8.7	11	206	100	NA	0	0	1
0.7	8.1	11	314	94	NA	0	0	1
0.5	9.6	NA	NA	103	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	1	0
0.2	NA	NA	NA	100	NA	0	1	0
0.3	NA	NA	NA	102	NA	0	1	0
0.3	NA	NA	NA	98	NA	0	1	0
0.3	NA	NA	NA	99	NA	0	1	0
0.2	9	NA	NA	101	NA	0	1	0
0.2	NA	NA	NA	99	NA	0	1	0
0.2	9.1	NA	NA	98	NA	0	1	0
0.2	9	1.2	NA	102	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	1
0.2	9.1	NA	NA	99	NA	0	1	0
0.3	9.3	NA	NA	97	NA	0	0	1
0.4	9.3	NA	NA	97	NA	0	1	1
0.5	9.4	NA	NA	100	NA	0	1	1
0.4	NA	142	NA	100	NA	0	0	1
6.3	NA	NA	NA	NA	NA	1	0	0
3.4	NA	NA	NA	NA	NA	1	0	0
4.5	9.8	NA	NA	NA	NA	1	0	0
5.6	NA	NA	NA	NA	NA	0	0	0
2.7	NA	NA	NA	NA	NA	1	0	0
3.2	NA	NA	NA	NA	NA	1	0	0
4.1	NA	18	NA	106	NA	0	0	0
0.8	NA	NA	NA	105	NA	0	1	0
0.4	8.7	NA	NA	104	NA	0	1	0
0.2	NA	2.7	NA	105	NA	0	0	0
22.5	9.1	735	NA	97	115	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	101	NA	1	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.7	NA	2.6	NA	NA	NA	0	0	0
0.6	NA	NA	NA	105	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.6	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	9.4	1.5	NA	98	NA	0	0	0
5.7	8.6	9.3	NA	95	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	101	NA	0	0	0
0.6	9.6	NA	NA	97	226	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
1.2	8.4	NA	NA	99	NA	0	0	1
0.6	8.5	3.1	NA	107	NA	1	0	1
0.2	NA	1.6	NA	NA	NA	0	0	0
0.5	NA	NA	NA	102	NA	0	0	0
16.1	NA	2.1	NA	NA	NA	0	1	1
7.4	8.9	5.5	NA	96	NA	0	1	1
1.6	9.2	4.8	NA	102	NA	0	0	1
0.9	NA	8	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	99	NA	0	0	0
1.2	NA	2.1	NA	NA	NA	0	0	0
0.8	NA	NA	NA	101	NA	0	0	1
0.3	9.3	NA	NA	102	NA	0	0	1
0.3	9.7	3.7	NA	103	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	1	0
0.9	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
1.1	NA	NA	NA	NA	NA	0	1	0
0.9	NA	NA	NA	NA	NA	0	1	0
1	NA	NA	NA	NA	177	0	1	0
1	NA	245	NA	NA	NA	0	1	0
1.4	9	248	NA	103	NA	0	0	0
0.7	NA	52	NA	101	NA	0	0	1
0.4	9.4	NA	NA	102	143	0	0	0
21.2	9	9.3	NA	101	NA	1	0	1
0.6	9.4	5.7	NA	103	NA	0	0	1
0.6	NA	2.4	NA	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
2.4	NA	NA	NA	NA	NA	0	0	1
0.9	NA	2.2	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.7	7.5	NA	NA	114	NA	0	0	1
0.6	8.6	NA	NA	107	NA	0	0	1
1.1	9.7	NA	NA	101	NA	0	0	1
0.5	NA	NA	NA	101	NA	0	0	1
0.5	NA	NA	NA	97	NA	0	0	1
0.7	9	NA	NA	91	NA	0	0	1
0.6	NA	NA	NA	NA	123	0	0	0
0.6	NA	2	NA	NA	NA	0	0	0
0.5	8.6	142	285	102	NA	0	0	1
NA	8.1	NA	NA	97	NA	0	0	1
0.4	NA	2.7	NA	106	NA	0	0	0
NA	NA	4.2	NA	NA	NA	0	0	0
NA	NA	3.3	NA	NA	NA	0	0	0
0.3	8.6	3.9	NA	NA	NA	0	0	0
0.6	NA	3.7	NA	NA	NA	0	0	0
0.4	NA	3.5	NA	106	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	3.3	NA	103	NA	0	0	1
0.5	NA	NA	NA	104	NA	0	0	1
15.9	8.9	2.5	NA	104	NA	1	0	0
0.7	NA	1.4	NA	106	NA	0	0	0
1.5	8.5	7.9	NA	97	NA	0	0	0
0.2	9.7	5.6	21	93	NA	0	0	1
0.4	9.8	1.9	NA	102	NA	0	0	1
0.6	11.8	2.9	37	112	NA	0	0	0
0.7	9.2	1.2	NA	102	NA	0	0	1
0.4	NA	3.1	NA	105	NA	0	0	0
0.4	NA	NA	NA	107	NA	0	0	0
1.7	11.8	1.3	NA	104	NA	0	0	1
2.9	9.7	3.4	NA	101	NA	0	0	0
1.4	8.8	NA	NA	99	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.1	NA	3.4	NA	96	NA	0	0	1
1.9	NA	7.9	NA	103	NA	0	0	1
1.7	8.6	NA	NA	102	NA	0	0	1
1.8	8.7	6.2	NA	103	197	0	0	1
2.3	NA	NA	NA	106	NA	0	0	1
2.1	8	NA	NA	105	NA	0	0	1
0.6	9.9	NA	NA	98	NA	0	0	0
1.7	11.1	4	NA	104	NA	0	0	0
NA	8.7	1.6	NA	97	NA	0	0	0
0.6	9.7	273	NA	99	NA	0	0	1
3.2	NA	NA	NA	99	NA	0	0	0
NA	8.1	NA	NA	109	NA	1	0	1
0.4	8.8	4.8	NA	107	NA	0	0	0
10.1	NA	NA	NA	NA	NA	1	0	1
0.5	8.9	NA	NA	103	NA	0	0	1
NA	8.9	2.5	NA	102	NA	0	0	1
NA	9.2	2.8	NA	99	NA	0	0	1
0.3	8.5	2.4	NA	104	NA	0	0	1
0.3	8.9	NA	NA	106	NA	0	0	1
0.4	8.9	NA	NA	105	NA	0	0	1
0.3	8.9	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9	5.5	NA	104	NA	0	0	1
NA	NA	5.2	NA	NA	NA	0	0	1
NA	NA	4.7	NA	NA	NA	0	0	1
NA	NA	4.3	NA	NA	NA	0	0	1
NA	NA	4.1	NA	NA	NA	0	0	1
NA	8.8	NA	NA	103	132	0	0	1
0.4	8	3.7	NA	105	NA	0	0	1
NA	8.6	4.4	NA	104	NA	0	0	1
0.6	9	NA	NA	100	NA	0	0	1
0.5	8.6	NA	NA	103	NA	0	0	1
6.5	8.4	NA	NA	100	NA	1	0	0
0.7	NA	NA	NA	NA	NA	1	0	0
NA	8.6	NA	63	116	NA	0	0	0
2.4	7.4	7.8	NA	95	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	3.8	NA	NA	NA	0	0	0
0.6	9.7	5.6	NA	103	NA	0	0	1
0.5	9.3	NA	NA	NA	NA	0	0	1
0.5	9.4	6.9	NA	101	100	0	0	1
8.6	NA	7.2	154	NA	NA	0	0	1
4.2	9	12	NA	102	NA	0	0	1
2.1	9	NA	NA	99	NA	0	0	1
NA	8.8	NA	NA	96	NA	0	0	1
0.8	8.7	NA	NA	96	NA	0	0	1
0.5	8.2	NA	NA	98	NA	0	0	1
0.6	NA	1.7	NA	97	NA	1	0	0
1.1	9.7	NA	NA	99	NA	0	0	1
0.9	NA	NA	NA	102	NA	0	0	1
5.8	NA	2.6	NA	NA	NA	1	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	8.8	NA	NA	110	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	8.4	NA	NA	110	NA	0	0	1
0.3	8.4	NA	NA	111	NA	0	0	1
NA	8.2	NA	NA	112	149	0	0	1
0.3	8.5	NA	NA	105	NA	0	0	1
NA	8.9	NA	NA	104	NA	0	0	1
0.2	NA	NA	NA	NA	NA	1	0	0
5.7	9.7	1.3	365	106	NA	0	0	1
0.4	8.8	NA	NA	102	NA	0	0	0
2	8.5	3.7	NA	98	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
1.3	NA	1.4	NA	103	NA	0	0	0
0.5	NA	NA	NA	102	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
1.9	8.1	10	NA	91	NA	0	0	0
0.2	NA	3136	NA	105	NA	0	0	0
1.2	8.7	1.8	NA	108	NA	0	0	1
1	8.7	NA	NA	107	NA	0	0	0
0.6	9.3	NA	NA	105	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	8	6.5	16	94	NA	0	0	1
16.7	9.3	6.2	NA	95	98	0	0	1
9.8	9.3	NA	NA	95	NA	0	0	0
5.7	7.9	2.8	NA	99	NA	1	0	1
4.2	8.1	4.6	NA	106	NA	0	0	0
6	9	NA	NA	103	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.6	8.9	NA	NA	105	NA	0	0	1
1.5	8.3	NA	NA	101	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.6	9.1	NA	NA	98	NA	0	0	1
0.9	8.5	4.2	NA	107	NA	0	0	0
10.6	9.5	NA	NA	99	NA	1	0	0
11.8	9.4	2.8	NA	93	NA	0	0	0
9.7	NA	6.7	NA	101	NA	1	0	0
3.3	8.9	20	NA	95	NA	0	0	0
0.2	NA	4	NA	NA	NA	0	0	1
0.3	9.7	1.6	6.6	105	NA	0	1	0
13.3	8.7	NA	NA	105	NA	1	1	1
2.3	NA	NA	NA	104	NA	0	0	1
1.2	NA	NA	NA	NA	NA	0	0	1
0.6	8.4	NA	NA	101	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	100	NA	0	0	1
0.7	NA	8.7	NA	97	NA	0	0	0
5.2	9.4	4.9	NA	97	NA	0	0	0
0.2	8.2	2.8	NA	111	NA	0	0	1
2.3	NA	7.3	NA	97	NA	0	0	1
1.7	NA	6	NA	NA	NA	0	0	1
30.7	8.1	8.7	NA	95	NA	0	0	1
5.2	9.5	4.7	NA	100	107	0	0	0
1.2	NA	NA	NA	109	NA	0	0	1
3.1	8.9	7.2	NA	97	NA	0	0	1
1.6	8.9	NA	NA	109	NA	0	0	0
1.1	8	NA	NA	106	NA	0	0	1
NA	8.9	NA	NA	107	NA	0	0	1
0.4	8.8	NA	9.1	102	NA	0	0	1
0.5	8.5	NA	NA	103	NA	0	0	1
0.3	8.2	NA	NA	107	NA	0	0	1
0.3	8.3	NA	NA	105	NA	0	0	1
0.3	8.6	NA	NA	102	NA	0	0	1
25.2	9.5	103	NA	100	NA	1	0	1
0.8	NA	2.7	NA	103	NA	0	1	1
0.5	9	NA	NA	101	NA	0	1	1
0.7	8.8	NA	NA	102	NA	0	1	1
0.6	8.7	NA	NA	102	NA	0	1	1
0.8	8.9	NA	NA	102	NA	0	0	1
0.4	8.7	NA	NA	104	NA	0	0	1
0.5	8.6	NA	NA	103	NA	0	0	1
0.3	8.6	NA	NA	103	NA	0	0	1
0.4	8.5	10	NA	100	NA	0	0	1
0.4	8.7	15	NA	104	NA	0	1	1
0.5	8.3	18	NA	104	NA	0	0	1
0.4	8.2	22	NA	NA	NA	0	1	1
0.6	7.9	38	NA	105	NA	0	1	1
0.5	8.1	34	NA	105	NA	0	1	1
5.8	NA	NA	NA	105	NA	1	0	1
0.2	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	1.8	NA	NA	NA	0	0	0
0.4	NA	1.8	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.1	8.8	NA	NA	108	NA	0	0	0
0.4	8.8	NA	NA	107	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.1	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	9.4	1.7	NA	104	NA	1	0	0
5.9	8.7	NA	NA	98	NA	1	0	1
NA	NA	4.9	NA	NA	NA	0	0	1
NA	NA	NA	NA	104	NA	0	0	0
0.8	9.5	1	NA	107	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	8.4	2.8	NA	103	NA	0	0	1
2.2	8.6	2.8	NA	98	169	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
4	NA	3	NA	104	NA	0	0	0
3.7	9.4	2.7	NA	104	222	0	0	0
0.6	9.9	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	10	1.8	551	99	NA	0	0	1
9.9	9.5	NA	NA	99	NA	0	0	1
2.8	9.1	5.7	NA	104	NA	0	0	1
2.4	9.2	4.1	NA	104	NA	0	0	0
9.1	8.8	4.8	NA	96	52	0	0	0
9.2	10.3	NA	NA	101	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	3	NA	NA	NA	1	0	0
1	8.9	4	NA	100	NA	0	0	1
0.5	9.3	NA	NA	104	NA	0	0	1
4.4	9.4	6.4	NA	101	196	0	0	0
2.1	NA	2.6	NA	97	NA	0	0	0
0.6	NA	NA	NA	99	NA	0	0	0
3	NA	6.6	NA	102	NA	0	0	1
0.6	10.1	2.7	NA	103	169	0	0	0
20.9	8.1	2.3	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
3.8	9.4	7.8	NA	98	196	0	0	0
11.8	8.7	4.1	NA	103	NA	1	1	1
10.1	8.3	3.5	NA	106	NA	1	1	1
1.1	9.5	NA	NA	98	NA	0	1	1
0.6	9.2	NA	NA	103	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.3	9.4	NA	NA	103	NA	0	1	1
0.2	NA	NA	NA	104	NA	0	1	1
0.3	9	NA	NA	104	NA	0	1	1
0.3	9.8	NA	NA	102	NA	0	1	1
0.3	9.3	NA	NA	105	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.3	8.7	NA	NA	99	NA	0	1	1
0.3	9.1	NA	NA	102	290	0	1	1
0.5	NA	NA	NA	105	NA	0	1	1
0.5	8.9	NA	NA	101	NA	0	1	1
0.8	8.5	NA	NA	103	NA	0	1	1
0.5	9.1	NA	NA	102	NA	0	0	1
0.5	9.3	NA	NA	106	NA	0	1	1
0.8	9.1	NA	NA	100	NA	0	1	1
1.1	9.6	NA	NA	102	NA	0	1	1
1.2	9.4	NA	NA	107	NA	0	1	1
1.4	8.9	NA	NA	104	NA	0	1	1
0.9	NA	NA	NA	107	NA	0	1	1
0.7	9.1	NA	NA	108	NA	0	1	1
0.5	9.8	NA	NA	103	NA	0	1	1
0.6	9.6	NA	NA	102	NA	0	1	1
0.5	9.6	NA	NA	105	NA	0	1	1
0.6	9.5	NA	NA	104	NA	0	1	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	1	1
1	NA	NA	NA	102	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.4	9.5	NA	NA	105	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.9	NA	NA	NA	NA	NA	0	1	1
0.7	NA	NA	NA	106	NA	1	0	1
0.7	NA	NA	NA	NA	NA	0	1	1
1	9.4	NA	NA	102	NA	0	1	1
5.1	9.6	3.1	NA	102	NA	1	0	0
0.4	9.4	NA	NA	100	NA	0	0	1
0.2	9.6	NA	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
13.7	NA	NA	NA	NA	NA	1	1	1
NA	NA	2.2	NA	NA	NA	0	1	0
1.7	7.9	NA	NA	99	NA	0	0	1
0.4	7.5	NA	NA	99	NA	0	0	1
0.5	8.4	NA	NA	103	NA	0	0	1
NA	8.6	NA	NA	99	NA	0	0	1
0.4	8.5	NA	NA	102	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
1.7	NA	NA	NA	NA	NA	0	0	1
2.1	NA	NA	NA	NA	NA	0	0	1
1.3	NA	NA	NA	NA	NA	0	0	1
1.5	NA	NA	NA	NA	NA	0	0	1
1.7	NA	NA	NA	NA	NA	0	0	1
1.5	NA	NA	NA	NA	NA	0	0	1
2.4	9.8	3.2	NA	101	NA	0	0	0
0.3	NA	6.2	NA	103	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	106	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
1.4	8.1	1.5	NA	101	NA	0	0	0
1.4	8.3	NA	NA	108	NA	1	0	1
14.4	NA	3.6	NA	NA	NA	1	0	1
1.4	9.4	4.8	NA	108	NA	0	0	0
1.4	NA	4.6	NA	NA	NA	0	0	0
1.6	NA	4.7	NA	108	NA	1	0	0
1.8	NA	NA	NA	NA	NA	1	0	0
1.6	9	NA	NA	105	NA	0	0	0
2	NA	NA	NA	NA	NA	1	0	0
1.7	NA	NA	NA	104	NA	1	0	0
4.5	8.4	1	NA	102	NA	1	0	1
0.7	9	1.1	NA	105	NA	0	1	0
0.5	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.7	8.4	NA	NA	106	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	1	0
0.7	NA	NA	NA	100	NA	0	0	0
0.7	NA	NA	NA	94	NA	0	1	0
0.8	NA	NA	NA	96	NA	0	1	0
0.7	9.1	13	NA	103	142	0	0	1
0.5	NA	NA	NA	107	NA	1	0	0
0.6	8.6	2.5	NA	95	NA	0	0	0
26.9	NA	5.8	NA	105	NA	1	0	1
6.6	NA	NA	NA	NA	NA	1	0	1
2.4	9.5	NA	NA	103	NA	0	0	1
1.3	9.7	NA	NA	105	NA	0	0	1
0.8	9.5	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.5	9.6	NA	NA	104	144	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.5	9.5	NA	NA	105	NA	0	0	1
1.3	9.2	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.8	9.3	NA	NA	106	NA	0	0	1
1.4	NA	NA	NA	105	NA	0	0	1
1.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1.3	9.3	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.8	7.9	2.5	NA	107	54	0	0	0
0.3	8.8	3.1	NA	103	135	0	0	0
0.8	NA	10	NA	106	NA	0	1	1
0.8	8.7	3.2	NA	105	NA	0	0	0
0.5	8.8	4.4	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	9.2	5.2	NA	105	NA	0	0	0
0.5	8.1	11	NA	104	NA	0	0	0
0.6	8.4	12	NA	107	NA	0	0	0
1	8.5	11	NA	102	NA	0	0	0
0.7	8.7	11	NA	102	NA	0	0	0
0.5	8.6	12	NA	102	NA	0	0	0
0.4	8.7	12	NA	106	NA	0	0	0
0.4	NA	13	NA	106	NA	0	0	0
0.5	8.3	14	NA	104	NA	0	0	0
0.5	7.6	11	NA	102	NA	0	0	0
0.7	7.9	10	NA	104	NA	0	0	0
3.2	7.9	11	NA	108	NA	0	0	0
3.1	7.5	15	NA	107	NA	0	0	0
5.1	8.3	NA	NA	101	NA	0	0	0
1.2	9	55	NA	NA	NA	0	0	1
0.6	8.4	91	NA	NA	NA	0	0	1
0.3	NA	5.5	NA	103	NA	0	0	0
10.9	9.1	NA	NA	106	NA	1	0	1
NA	8.4	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.8	9.3	3.6	NA	104	NA	0	0	0
2.1	8.7	3.4	NA	104	NA	1	0	0
1.3	8.8	2.7	NA	100	NA	1	0	0
2.2	NA	NA	NA	102	NA	1	0	0
1.9	9.3	NA	NA	102	NA	1	0	0
2.6	9.8	NA	NA	99	NA	1	0	0
1.9	8.8	NA	NA	102	NA	0	0	0
0.5	NA	1.6	NA	103	NA	0	0	1
0.3	9.6	NA	NA	105	NA	0	0	0
NA	9.3	NA	NA	105	NA	0	1	1
NA	9.3	NA	NA	102	NA	0	1	1
0.8	NA	NA	NA	NA	NA	0	0	1
6.2	7.8	8.5	NA	103	55	0	0	1
2.4	8.6	NA	NA	103	NA	0	0	1
6.9	8.7	NA	NA	102	NA	0	0	1
4.3	8.7	NA	NA	102	NA	0	0	1
1.2	NA	NA	NA	93	NA	0	1	1
1.1	NA	NA	NA	NA	NA	0	0	1
0.9	NA	3	NA	NA	NA	0	0	0
0.5	NA	4.2	NA	NA	NA	0	0	0
2.7	9	3.5	NA	107	NA	0	0	0
0.2	7.9	NA	203	97	NA	0	0	0
0.2	7.7	NA	203	106	NA	0	0	0
6.2	8.8	13	NA	95	49	0	0	0
NA	9.1	NA	NA	103	NA	0	0	1
0.5	8.9	NA	NA	104	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
3.3	8.5	NA	NA	NA	NA	1	0	1
2.9	NA	3.8	NA	102	NA	0	0	1
0.8	9.2	NA	NA	103	NA	1	1	1
0.6	9.5	NA	NA	102	NA	0	1	1
0.3	9.7	NA	NA	106	NA	0	1	1
0.6	10.1	NA	NA	104	NA	0	1	1
0.6	9.5	NA	NA	100	NA	0	1	1
0.3	NA	2.3	NA	101	NA	0	0	0
0.4	NA	NA	NA	99	NA	0	0	0
0.4	NA	2.8	NA	100	NA	0	0	0
0.5	9.5	1.9	NA	99	218	0	0	0
2.4	7.9	6.5	NA	106	NA	0	0	0
4.7	8.6	8.1	NA	107	NA	1	1	1
1.4	NA	3.7	NA	97	NA	0	0	1
1.3	8.5	2.8	NA	99	NA	0	0	0
NA	NA	1.1	30	NA	NA	0	0	0
1.3	9.2	1.6	NA	103	NA	0	0	0
0.3	NA	2	NA	104	NA	0	0	0
9.1	7.9	NA	NA	110	NA	1	0	1
2	NA	NA	NA	105	NA	0	0	1
0.9	8.5	NA	NA	110	NA	0	1	1
2.7	NA	NA	NA	NA	NA	0	1	1
6.5	9	NA	NA	98	NA	0	0	1
2.2	NA	NA	NA	NA	NA	0	1	1
2.6	8.5	NA	NA	102	NA	0	0	1
7.5	NA	NA	NA	101	NA	0	1	1
3.6	8.5	NA	NA	102	NA	0	1	1
7.2	7.8	NA	NA	105	NA	0	0	1
0.3	NA	1.1	NA	NA	NA	0	0	0
0.7	NA	1.1	NA	NA	NA	0	0	0
0.4	NA	1.1	NA	NA	NA	0	0	0
0.7	NA	1.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
2.3	NA	NA	NA	97	NA	0	0	0
4.2	9.1	NA	NA	94	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.4	9.3	4.6	NA	109	NA	0	0	0
0.4	8.8	2.2	NA	101	NA	1	0	1
0.7	NA	3.6	NA	105	NA	0	0	0
0.5	NA	1.5	NA	104	NA	0	0	0
3.2	8.7	4.8	NA	97	NA	0	0	0
11.8	8.9	NA	NA	100	NA	0	0	1
1.2	NA	17	NA	NA	NA	0	1	1
0.3	9.3	NA	NA	NA	173	0	0	0
1	9.8	1	NA	97	NA	0	1	1
0.4	8.8	NA	NA	101	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9.7	NA	NA	96	NA	0	0	0
0.1	NA	NA	NA	102	NA	0	0	0
0.3	8.9	NA	NA	96	NA	0	0	0
2.5	8.2	2.9	NA	105	NA	0	0	1
0.6	9.5	2.2	NA	104	NA	0	0	0
0.4	8	1.5	NA	109	NA	0	0	0
2.4	9.3	3.4	NA	95	162	0	0	0
2.7	9.5	3.8	NA	103	NA	0	0	0
4.5	9.1	7.1	NA	105	NA	0	0	0
0.3	NA	2	NA	103	NA	1	0	0
0.5	9.1	NA	NA	104	NA	1	0	0
1.2	NA	NA	NA	103	NA	1	0	0
1.4	NA	3.7	NA	NA	NA	0	1	0
0.8	9.1	3.6	NA	104	NA	0	1	0
NA	9.4	NA	NA	NA	NA	0	1	0
0.8	NA	NA	NA	NA	NA	0	1	0
1.1	9.1	NA	NA	107	NA	0	1	0
1	NA	NA	NA	NA	NA	0	1	0
1.1	9.8	20	NA	97	NA	0	1	1
0.8	9.2	19	NA	NA	NA	0	1	1
1.4	8.9	NA	NA	102	NA	0	0	1
0.3	8.6	NA	NA	104	NA	0	0	0
3.7	9.7	2.6	NA	96	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
1.2	9.1	NA	NA	101	NA	0	0	1
1.1	9.2	NA	NA	99	NA	0	0	1
1.5	8.6	NA	NA	94	NA	0	0	1
1.2	8.5	NA	NA	101	NA	0	0	1
16.3	8.5	6.3	NA	103	NA	1	0	1
5.4	8.3	NA	NA	106	NA	0	0	1
11.3	9	5.7	NA	93	68	0	0	1
14.9	9.2	9.1	NA	89	70	0	0	1
NA	NA	NA	NA	102	NA	0	0	0
2.3	9.6	NA	NA	100	NA	0	0	1
1.2	NA	NA	NA	105	NA	0	0	1
0.5	9.4	NA	NA	105	NA	0	0	0
3.4	8.6	NA	NA	103	NA	1	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9.1	NA	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9.1	1	NA	105	NA	0	0	0
6.9	7.8	NA	NA	104	NA	0	0	0
0.5	7.8	2.3	NA	109	NA	0	0	0
NA	NA	NA	NA	NA	NA	1	0	0
3.5	9.4	1.1	NA	NA	NA	0	0	0
0.5	NA	1.5	NA	NA	NA	0	0	0
0.4	9.4	1.8	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	9.5	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	NA	1.4	NA	NA	NA	0	0	0
0.2	8.9	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
15.4	5.4	NA	NA	86	NA	0	0	1
2.8	8.3	2.5	NA	103	NA	0	0	0
2	8.7	2.4	NA	98	NA	0	0	1
1.9	9.3	4.4	NA	102	NA	0	0	0
2	8.7	4.6	NA	99	NA	0	0	1
4.9	8.8	NA	NA	105	NA	0	0	1
1.7	8.9	6.8	NA	99	NA	0	0	0
0.8	7.9	25	NA	102	NA	0	0	0
1	7.9	26	NA	97	NA	0	0	0
0.8	9.1	3	NA	107	NA	0	0	1
0.4	10.1	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	100	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	10	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	100	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	10.2	NA	NA	105	NA	0	0	0
0.4	NA	NA	NA	104	NA	0	0	0
0.5	NA	NA	NA	100	NA	0	0	0
0.6	NA	NA	NA	101	NA	0	0	0
0.5	NA	NA	NA	98	NA	0	0	0
1.5	9.1	1.8	NA	105	NA	0	0	0
31.9	8.2	3.1	NA	110	NA	1	0	1
13.8	9	NA	NA	108	NA	0	0	1
14.1	9.4	NA	NA	93	NA	1	0	1
1.4	9.3	4.1	NA	99	NA	0	0	1
1.6	NA	NA	NA	103	NA	0	0	1
1.3	9.5	NA	NA	100	NA	0	0	1
2.3	NA	NA	NA	103	NA	0	0	1
2.3	NA	2.6	NA	102	NA	0	0	1
4	8.6	40	NA	99	NA	0	0	1
63.5	9.2	17	NA	101	NA	0	0	1
0.2	9.6	NA	NA	101	NA	0	0	0
26.4	NA	NA	NA	106	NA	1	0	0
1.3	8.7	2.7	NA	105	NA	0	0	1
0.4	8.9	1.1	NA	104	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
4.8	8.7	4.7	NA	95	NA	0	0	0
6.9	8.7	NA	NA	101	244	1	0	1
1.1	8.3	NA	NA	105	83	0	1	1
8.7	9.5	NA	NA	112	NA	1	1	1
2.3	10.3	1.7	NA	107	NA	0	0	1
1.3	9.5	NA	NA	110	NA	0	0	1
0.8	9.6	1.9	NA	111	NA	0	0	1
0.8	9.8	2.4	NA	110	NA	0	0	1
0.6	9.8	1.9	NA	110	NA	0	0	1
0.4	9.5	1.8	NA	109	NA	0	0	1
0.4	9.6	2.4	NA	109	NA	0	0	1
0.5	9.6	2.7	NA	109	NA	0	0	1
NA	9.6	NA	NA	109	NA	0	0	1
NA	9	5.3	NA	111	NA	0	1	1
0.5	NA	4.9	NA	111	NA	0	0	1
0.7	NA	3.1	NA	105	NA	0	0	1
1.4	8.9	4.6	NA	102	NA	0	0	1
3.3	8.7	4.6	NA	97	117	0	0	0
3.5	8.8	9.1	NA	106	NA	0	1	1
1.7	7.9	NA	NA	104	NA	0	0	1
0.8	8.9	NA	NA	NA	NA	0	0	1
0.6	NA	26	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	18	NA	NA	NA	0	0	1
0.6	9.2	10	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	107	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.3	9.5	NA	NA	110	NA	0	0	0
0.9	NA	NA	NA	108	NA	0	0	1
1.4	NA	310	NA	108	NA	0	0	1
7.9	NA	2264	NA	102	NA	0	0	1
5.9	7.6	8	NA	105	NA	0	0	1
15.6	8.3	7	NA	109	NA	0	0	1
18	9.3	NA	NA	106	NA	0	0	1
2.1	9.3	NA	NA	97	NA	0	0	1
0.5	NA	NA	NA	105	NA	0	0	0
7.7	8.5	419	NA	112	NA	1	0	1
1.3	NA	NA	NA	103	NA	0	0	1
0.6	10	NA	NA	97	NA	0	0	0
NA	NA	1.2	NA	NA	NA	0	0	0
0.8	NA	NA	NA	94	NA	0	0	0
2.1	8.9	2.6	NA	109	117	0	0	0
9.1	9	1.6	NA	106	NA	1	0	1
9.3	9	1.6	NA	106	NA	1	0	1
1.5	8	NA	NA	99	NA	0	0	0
6.7	9.6	1.1	NA	81	NA	0	1	1
14.9	8.5	2.2	NA	107	NA	0	0	1
1.4	11.9	NA	NA	99	NA	0	0	0
23.2	8.9	6.3	NA	101	NA	0	0	1
2.2	NA	2	NA	99	NA	1	0	0
0.7	9.2	NA	NA	100	NA	0	0	1
NA	8.4	NA	393	103	NA	0	0	0
10.9	8.5	13	NA	93	NA	1	1	1
2.7	7.4	NA	NA	101	NA	0	0	1
5.3	NA	1.1	NA	103	107	0	0	1
1.4	8.2	1.1	NA	106	128	0	0	0
0.9	NA	NA	NA	NA	NA	1	0	0
11.8	8.5	1.8	NA	94	NA	0	0	1
7	NA	NA	NA	100	NA	1	1	1
2.2	8.1	3.9	NA	105	NA	0	0	0
NA	9.5	2.2	NA	107	NA	0	0	0
5.7	NA	NA	NA	100	NA	1	0	0
3.4	7.7	2.8	46	102	NA	1	0	1
0.4	NA	2.6	NA	NA	NA	0	1	0
0.8	9.1	NA	NA	103	NA	0	1	0
1.4	9.3	NA	NA	101	NA	0	1	0
2.1	9.1	NA	NA	101	NA	0	1	0
1.3	NA	3.5	NA	98	NA	1	1	0
0.8	NA	9.9	NA	NA	NA	0	1	1
1.3	NA	NA	NA	NA	NA	0	1	1
1	8	NA	426	97	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
1.3	9.4	9.3	NA	103	NA	0	0	0
7	8.3	8.5	NA	104	125	0	0	1
0.6	10.5	3.3	NA	99	NA	0	0	0
NA	9.3	3	NA	109	NA	0	0	1
1.2	8.5	3.7	NA	100	40	0	0	0
1.8	NA	2.1	NA	102	NA	1	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	9.6	NA	NA	NA	NA	0	0	1
0.4	9.9	14	NA	100	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9.5	NA	NA	NA	NA	0	0	0
0.3	9.4	11	NA	103	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	9.2	9.6	NA	103	NA	0	0	0
0.4	8.9	8.7	NA	99	NA	0	0	0
0.4	9.3	8.6	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	6.9	NA	NA	NA	0	0	0
0.5	8.9	7.3	NA	NA	NA	0	0	0
0.4	8.9	7.3	NA	NA	NA	0	0	0
0.4	NA	7.8	NA	NA	NA	0	0	0
0.4	NA	7.8	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.6	8.6	4.9	NA	101	NA	0	0	0
3.4	9.6	8.3	NA	96	NA	0	0	1
4.9	8.3	5.4	NA	96	NA	1	1	1
0.8	8.7	3553	NA	98	NA	0	0	1
1.3	8.4	4998	NA	96	NA	0	0	1
1.3	8.7	2696	NA	92	NA	0	0	1
1.1	9.2	3459	NA	94	NA	0	0	1
0.5	8.9	1884	NA	101	NA	0	0	1
0.6	NA	1144	NA	100	NA	0	0	1
0.9	9.2	2817	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
40.6	7.4	5.8	NA	105	56	0	0	1
3.3	6.7	3.1	NA	106	NA	0	0	1
0.6	9.4	2.9	NA	102	149	0	0	0
NA	NA	3.6	9	NA	NA	0	0	0
1.1	NA	2	NA	107	NA	0	0	1
0.6	9.8	NA	NA	110	NA	0	0	0
0.9	9.4	NA	NA	103	NA	0	0	0
0.7	9.2	NA	NA	102	NA	0	0	0
0.4	8.7	NA	NA	108	NA	0	0	0
0.7	8.9	NA	NA	104	137	0	0	0
0.7	9.3	NA	NA	104	NA	0	0	0
0.7	8.8	NA	NA	104	NA	0	0	0
0.5	8.9	NA	NA	105	145	0	0	1
0.6	8.9	NA	NA	105	NA	0	0	0
0.4	NA	NA	NA	104	NA	0	0	0
0.3	9	NA	NA	106	NA	0	0	0
0.4	8.8	1.4	NA	108	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9.1	NA	NA	108	NA	0	0	0
0.3	9.2	NA	NA	108	NA	0	0	0
0.5	9.2	2.4	NA	105	NA	0	0	0
15.6	NA	1.4	NA	NA	NA	1	0	1
1.6	8.3	1.2	NA	107	114	0	0	0
6.9	8.3	4.7	NA	104	NA	1	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.3	7.8	31	NA	107	NA	1	0	1
1.4	8.8	2.9	NA	99	NA	0	0	0
0.3	9.8	1.6	837	101	NA	0	0	0
0.3	9.8	NA	33	102	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
8.6	9.2	NA	NA	108	NA	1	0	1
8.7	NA	NA	NA	101	NA	1	0	1
33	7.8	174	NA	92	NA	0	0	0
2	NA	2	NA	97	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	104	NA	0	1	0
0.5	9.5	NA	NA	102	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.4	NA	6.5	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.8	9.6	1.1	NA	99	NA	0	0	0
24.7	8.8	9.1	NA	97	92	0	0	0
1.3	8.6	8.5	NA	101	NA	0	0	0
0.3	NA	336	NA	106	NA	0	0	1
1	8.4	2888	78	106	NA	0	0	1
1	8.7	3	NA	102	NA	0	0	1
5.1	7.7	1.6	NA	107	NA	0	0	0
0.3	NA	NA	NA	105	NA	0	0	0
0.4	9.6	NA	NA	104	NA	0	0	0
0.4	9.2	NA	NA	107	NA	0	0	1
0.6	NA	2.2	NA	102	NA	0	0	0
1.4	9.3	3.6	NA	110	NA	0	0	0
4.4	8.5	5	NA	106	NA	0	0	0
6.1	9.7	6.4	NA	100	NA	0	0	1
1.6	8.2	18	NA	101	NA	0	0	1
0.2	9.1	NA	NA	101	NA	0	0	1
0.5	8.8	1.6	NA	107	NA	0	0	0
0.4	9.5	9.6	NA	100	NA	0	0	1
0.2	9.7	NA	NA	101	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.7	8.5	3.5	NA	103	NA	0	0	0
0.3	NA	11	NA	101	NA	0	0	1
3.5	NA	NA	NA	103	NA	0	0	0
8.3	NA	2.2	NA	NA	NA	1	0	1
0.5	8.8	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	1.1	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	8.4	1.1	NA	106	NA	0	0	0
0.3	8.7	1.2	NA	105	NA	0	0	0
0.4	8.7	1.9	NA	103	NA	0	0	0
0.3	8.4	1.8	NA	105	NA	0	0	0
0.3	8.3	2	NA	106	NA	0	1	0
0.4	8.7	2.8	NA	105	NA	0	0	0
0.4	8.7	2.7	NA	105	NA	0	1	0
0.4	9	3.1	NA	103	133	0	0	0
0.3	8.9	2.6	NA	103	NA	0	0	0
0.3	NA	3.8	NA	104	NA	0	0	0
0.3	NA	5.3	NA	NA	NA	0	0	0
0.3	NA	4.2	NA	NA	NA	0	1	0
0.4	8.8	5.5	NA	102	NA	0	0	0
0.3	8.8	4.9	NA	106	NA	0	0	0
0.3	8.5	4	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	2	NA	NA	NA	0	0	0
0.2	NA	4.2	NA	NA	NA	0	0	0
0.3	9.5	2.8	24	99	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	1
0.3	9.6	NA	NA	101	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	104	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	8.9	NA	NA	NA	NA	0	0	1
0.4	9.5	NA	NA	103	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	9	NA	NA	94	NA	0	0	1
0.2	9.2	NA	NA	97	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	7.7	NA	NA	97	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.3	NA	NA	93	NA	0	0	1
0.4	9.4	NA	NA	97	NA	0	0	1
0.5	9.5	NA	NA	95	NA	0	0	1
0.4	9.9	NA	NA	96	NA	0	0	1
0.5	9.8	NA	NA	96	NA	0	0	1
0.5	9.6	NA	NA	98	NA	0	0	1
0.6	9.6	NA	NA	98	NA	0	0	1
0.6	9.4	NA	NA	99	NA	0	0	1
0.6	9.5	NA	NA	99	NA	0	0	1
0.7	8.9	NA	NA	95	NA	0	0	1
0.7	8.8	NA	NA	95	NA	0	0	1
NA	NA	NA	NA	96	NA	0	0	1
11.2	9.5	NA	NA	93	NA	0	0	1
3.4	8.8	NA	NA	99	NA	1	0	1
1.2	8.5	NA	NA	105	NA	1	0	1
0.7	7.5	4.1	276	104	NA	0	0	1
0.7	9.7	7.4	NA	103	NA	0	0	1
1.1	NA	NA	NA	105	NA	0	0	1
0.3	9	1.7	NA	103	120	0	0	0
4.5	9.7	4.3	NA	102	302	0	0	0
1.1	9.2	1.5	NA	96	NA	0	0	0
1.1	8.7	1.6	NA	105	NA	0	0	0
1	NA	2	NA	104	NA	0	0	0
14.7	NA	4.1	NA	102	NA	1	0	1
16.9	NA	3.7	NA	96	NA	1	0	1
0.6	9.5	2.4	NA	100	NA	1	1	0
NA	NA	NA	NA	99	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
NA	9	NA	NA	101	NA	0	1	1
0.3	8.1	NA	NA	102	NA	0	1	1
NA	8.8	NA	NA	104	NA	0	0	1
0.3	NA	NA	NA	102	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	1	0
0.7	8.6	NA	NA	103	NA	0	0	1
0.6	NA	NA	NA	103	NA	1	0	0
0.7	9.4	2.9	NA	101	143	0	0	0
0.4	9.5	3.9	NA	101	NA	0	0	0
1	8.2	5.7	NA	101	105	0	0	1
3.5	NA	6.9	NA	103	NA	0	0	0
0.4	6.3	2.9	NA	101	NA	0	0	1
0.6	5.2	NA	NA	97	NA	0	0	1
0.3	7.6	NA	NA	100	NA	0	0	1
0.2	8.8	4.1	NA	102	NA	0	0	1
0.2	9	NA	NA	103	NA	0	0	1
0.2	9.2	4.3	NA	102	NA	0	0	1
NA	9	5.6	NA	103	NA	0	0	1
0.2	NA	17	NA	100	NA	0	0	0
1.8	8.6	8.7	NA	105	163	0	0	1
1.8	NA	NA	NA	105	NA	0	0	1
2.1	NA	NA	NA	103	NA	0	0	1
5.6	9.8	NA	NA	99	NA	0	0	1
26	9	2.6	NA	107	NA	0	0	0
1.1	8.7	4.8	NA	105	NA	0	0	0
4	9.3	16	NA	104	NA	1	1	1
0.3	NA	NA	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
26	8.5	6.7	NA	101	NA	0	0	1
0.6	NA	NA	12	102	NA	0	0	0
0.3	NA	2.7	NA	NA	NA	0	0	0
0.7	NA	1.7	NA	NA	NA	1	0	1
2.4	7.9	1.2	NA	110	NA	0	0	1
0.5	10	NA	NA	104	NA	0	0	0
0.5	NA	1.2	NA	NA	NA	0	0	0
0.3	NA	1.5	NA	NA	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	1	0
0.6	NA	1.2	NA	NA	NA	0	0	0
0.4	NA	1.3	NA	NA	NA	0	1	0
0.5	NA	1.3	NA	NA	NA	0	0	0
0.5	10.1	NA	NA	100	NA	0	0	0
0.5	9.9	1.3	NA	101	NA	0	0	0
0.4	9.7	NA	NA	101	NA	0	1	0
0.8	8.4	3.5	NA	106	NA	0	0	1
0.8	9.1	6.7	NA	NA	NA	0	0	1
0.3	8.9	NA	NA	NA	NA	0	1	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	7.9	NA	NA	NA	NA	0	0	1
NA	NA	6.9	NA	NA	NA	0	0	1
0.4	NA	7.3	NA	NA	NA	0	0	1
0.3	NA	9.1	NA	NA	NA	0	0	1
2.5	NA	8.9	NA	NA	NA	0	0	1
1.6	NA	11	NA	NA	NA	0	0	1
0.9	NA	9.9	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	8.3	NA	NA	104	NA	0	0	1
0.4	NA	52	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
1	9.6	1.1	NA	101	NA	0	0	0
0.9	NA	6.3	NA	99	NA	0	0	0
5.5	8.9	8.9	NA	97	NA	0	0	1
4.5	NA	NA	NA	96	NA	0	0	1
NA	NA	28	NA	NA	NA	0	0	0
1.7	9.5	5	NA	105	181	0	0	1
2.2	NA	NA	NA	107	NA	0	0	0
1.1	8.7	2.5	NA	104	NA	0	0	0
23.6	7.3	NA	NA	108	NA	0	0	1
1.1	NA	2.7	NA	99	293	0	0	0
0.4	8.8	2.5	NA	107	NA	0	0	1
0.2	9.5	NA	NA	97	NA	0	1	1
0.3	9.8	NA	NA	99	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.1	8.9	NA	NA	103	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.2	8.9	NA	NA	98	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.3	7.6	NA	NA	96	NA	0	0	1
7.7	9.5	3	NA	108	NA	1	0	1
2.2	9.6	NA	NA	97	NA	0	1	1
0.6	9.7	NA	NA	93	NA	0	1	1
0.4	NA	2.9	NA	NA	NA	0	1	1
0.5	9.3	NA	NA	98	NA	0	1	1
0.3	9.6	NA	NA	93	NA	0	1	1
0.3	9	NA	NA	97	NA	0	1	1
NA	9.4	NA	NA	98	NA	0	1	1
0.3	8.9	NA	NA	93	NA	0	1	1
0.3	9.4	NA	NA	97	NA	0	1	1
0.3	9.2	NA	NA	98	NA	0	1	1
0.3	9.3	NA	NA	95	NA	0	1	1
0.4	9	NA	NA	96	NA	0	1	1
0.4	9.7	NA	NA	96	NA	0	1	1
0.6	9.3	NA	NA	94	NA	0	1	1
0.3	9.1	NA	NA	100	NA	0	1	1
0.3	9.6	NA	NA	96	NA	0	1	1
0.4	9.7	NA	NA	96	NA	0	1	1
0.4	8.7	NA	NA	100	NA	0	0	1
0.4	9.2	NA	NA	96	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	9.4	NA	NA	96	NA	0	0	0
0.6	10.2	1.8	NA	102	207	0	0	1
2.9	8.9	4.7	NA	97	NA	0	0	1
5.9	9.7	14	NA	97	NA	0	0	0
1.1	8.5	1.8	NA	107	NA	0	0	0
0.7	8.3	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
5.6	NA	2.5	NA	96	NA	0	0	1
0.3	NA	1	NA	NA	NA	0	0	0
0.6	NA	1.3	NA	NA	NA	0	0	0
2.4	8.5	2.4	NA	100	116	0	0	0
39	8.1	NA	NA	121	NA	1	0	0
0.4	9	14	NA	100	NA	0	0	0
0.3	NA	1	NA	103	NA	0	0	1
7.1	8	3.9	NA	101	NA	0	0	0
NA	9.6	NA	NA	101	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
5.7	8.7	9	NA	108	NA	0	0	1
0.5	9.2	7.6	NA	NA	NA	0	0	1
0.4	NA	NA	NA	101	NA	1	0	1
0.3	NA	NA	NA	106	NA	0	0	1
0.3	9.2	8.9	NA	105	NA	0	0	1
0.3	NA	NA	NA	98	NA	0	0	1
0.3	8	5.9	NA	99	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	8.5	NA	NA	101	NA	0	0	1
0.9	6.1	1.9	NA	110	NA	0	0	1
0.5	NA	2.6	NA	NA	NA	0	0	0
0.3	NA	2	NA	102	NA	0	0	1
0.3	8.4	NA	NA	NA	NA	0	0	1
0.7	7.9	15	NA	97	NA	0	0	1
0.9	7.8	16	NA	93	NA	0	0	1
0.6	8.5	NA	NA	105	195	1	1	0
0.3	NA	1.5	NA	99	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
6.7	10.1	10	NA	98	NA	0	0	1
4.2	10.3	NA	NA	107	NA	0	0	1
2	9.2	2.2	NA	103	108	0	0	0
0.4	NA	1.9	NA	NA	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1	NA	1.3	NA	99	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.8	9	1.7	NA	102	NA	0	0	0
1	8.8	NA	NA	106	NA	0	1	1
0.7	NA	1.3	NA	NA	NA	0	0	0
0.9	NA	2	NA	NA	NA	0	0	0
0.6	NA	1.7	NA	NA	NA	0	1	0
1.2	NA	2.2	NA	NA	NA	0	0	0
1.1	NA	2.1	NA	NA	NA	0	0	0
1.4	NA	2.2	NA	NA	NA	0	0	0
0.3	9.1	NA	NA	NA	NA	0	0	0
1.7	9.5	1.5	NA	104	NA	0	0	0
4.3	NA	2.1	NA	99	NA	0	0	0
0.3	7.5	3	NA	114	NA	0	0	0
0.3	NA	10	NA	101	NA	0	0	0
0.3	9.4	10	NA	101	224	0	0	0
0.4	NA	NA	NA	103	NA	0	0	0
3.6	9	2.7	NA	102	NA	1	0	1
2.8	9.4	NA	NA	99	NA	1	0	1
6.3	8.4	NA	NA	98	NA	1	0	1
7.8	NA	NA	NA	99	NA	1	0	1
6	NA	NA	NA	104	NA	0	0	1
4.6	8.7	4.1	NA	98	NA	0	0	1
0.8	NA	NA	NA	NA	NA	1	0	0
0.3	10.2	1.1	NA	98	NA	0	0	0
0.3	NA	NA	NA	103	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.5	NA	NA	NA	104	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	1	0
1.6	9.1	2.3	NA	103	185	0	0	0
1.7	9.2	NA	NA	105	NA	0	0	0
0.6	9.6	NA	NA	104	NA	0	0	0
0.4	9.7	NA	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	9.2	NA	NA	100	NA	0	0	0
0.4	8.9	NA	NA	102	NA	0	0	0
0.4	8.5	NA	NA	105	NA	0	0	0
0.4	8.8	NA	NA	107	NA	0	0	0
0.3	8.9	NA	NA	105	NA	0	0	0
0.3	8.6	NA	NA	105	NA	0	0	0
0.3	9.3	NA	NA	107	NA	0	0	0
0.3	9.5	5.9	NA	104	NA	0	0	0
0.3	9.8	5.1	NA	105	NA	0	0	0
0.3	9.6	NA	NA	103	NA	0	0	0
0.3	9.5	6.4	NA	107	NA	0	0	0
2.2	9.3	4.7	NA	103	52	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	1.1	NA	NA	NA	0	1	0
1.9	8.8	7.5	NA	102	NA	0	0	0
11.3	7.3	1.6	NA	100	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.8	7.9	4.3	NA	104	NA	0	0	0
0.3	NA	NA	28	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	108	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	109	NA	0	0	1
0.3	8	NA	NA	109	NA	0	0	1
1.6	8.6	5.8	NA	106	NA	0	0	0
0.6	9.9	1503	NA	97	NA	0	0	1
2.5	9	8.6	NA	105	NA	1	0	1
2.6	NA	NA	NA	104	NA	0	0	1
3.5	NA	NA	NA	106	NA	0	0	1
0.5	NA	1.3	NA	NA	NA	1	0	1
0.3	NA	NA	NA	101	NA	0	0	1
0.3	8.8	1.4	NA	100	NA	0	1	0
0.2	NA	NA	NA	NA	NA	0	1	0
0.8	NA	NA	NA	106	NA	1	0	0
0.3	NA	NA	NA	102	NA	0	0	0
0.3	9.2	NA	NA	102	NA	0	0	0
0.3	NA	4.1	NA	103	NA	1	0	1
0.6	NA	NA	NA	NA	NA	0	0	0
4	10	3.2	NA	93	112	0	0	0
0.6	9.5	2.6	NA	100	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.5	9.6	2	NA	103	NA	0	0	0
0.5	9.2	1.4	NA	106	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.7	8.9	NA	NA	103	NA	0	0	0
0.6	NA	NA	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	104	NA	0	0	0
0.7	NA	NA	NA	103	NA	0	0	0
0.7	NA	1.7	NA	NA	NA	0	0	0
1	NA	1.2	NA	102	NA	0	0	0
1	NA	1.3	NA	NA	NA	0	0	0
0.9	9.5	1	NA	101	NA	0	0	0
1	NA	1	NA	NA	NA	0	0	0
1.5	NA	1.2	NA	99	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
1.3	9.4	1.5	NA	106	NA	0	0	0
0.7	NA	1.9	NA	NA	NA	0	0	0
1.2	NA	3.1	NA	105	NA	0	1	0
6.9	9	1.2	NA	101	NA	0	0	0
3.9	8.2	NA	NA	100	NA	0	0	0
1.5	NA	NA	NA	101	NA	0	1	0
0.1	9.4	143	NA	109	NA	0	0	1
12	8.4	1.7	NA	100	NA	0	0	1
3.6	8.5	29	NA	99	175	0	0	1
NA	NA	NA	17	106	NA	0	0	0
0.4	NA	7.3	NA	102	NA	0	0	1
NA	NA	NA	NA	105	NA	0	0	1
0.5	NA	16	NA	106	NA	0	0	1
2.4	NA	NA	NA	106	NA	1	0	0
0.6	8.4	NA	NA	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	98	NA	1	0	1
0.4	8.5	NA	NA	91	NA	0	0	1
2.8	NA	1.8	NA	93	NA	0	0	1
2.1	NA	NA	NA	97	NA	0	0	1
4.3	NA	NA	NA	104	NA	1	0	1
1.7	NA	NA	NA	NA	NA	0	0	1
0.2	10.3	NA	NA	103	NA	0	0	0
0.3	10	NA	NA	104	NA	0	0	1
0.7	8.1	NA	NA	110	NA	0	0	0
0.3	9.3	NA	NA	103	NA	0	0	1
0.2	9.8	NA	NA	106	NA	0	0	1
0.2	9.6	NA	NA	106	NA	0	0	1
0.3	9.4	NA	NA	101	NA	0	0	1
0.3	9.7	NA	NA	101	NA	0	0	1
0.4	9.3	7.6	NA	101	55	0	0	0
0.3	NA	2.5	NA	NA	NA	0	0	0
0.5	9.6	2.6	NA	102	NA	0	1	0
0.3	9.7	2.1	NA	100	NA	0	1	0
0.3	NA	2.6	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
2.2	9.1	7.2	NA	NA	NA	0	0	1
NA	8.4	3.4	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	1.9	NA	107	NA	0	0	0
0.3	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
NA	10.3	3.1	NA	103	NA	0	0	0
0.6	NA	1.3	NA	103	NA	0	0	0
1.3	9	16	NA	100	177	0	0	1
1.5	NA	7.6	NA	102	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
3.5	9.2	4	NA	104	122	0	0	0
0.5	9.4	1.6	NA	105	NA	0	0	1
4.3	8.8	NA	NA	100	NA	0	0	1
1.6	9.8	1.6	NA	98	148	0	0	0
0.6	9	NA	NA	105	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	99	NA	1	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	112	NA	0	0	1
0.2	6.7	1.5	NA	99	NA	1	0	1
NA	9.2	2.4	NA	108	NA	0	0	1
1.1	9.9	3.3	NA	104	NA	0	0	1
1.3	9.2	3	NA	92	NA	0	0	1
0.9	NA	NA	NA	100	NA	0	0	1
0.4	NA	2	NA	103	226	0	0	0
11.1	9.1	1.9	NA	108	NA	0	0	1
NA	9.8	2.3	NA	105	180	0	0	0
0.7	8.1	2.6	NA	102	NA	0	0	1
20.9	9	4.7	NA	103	78	0	0	1
0.4	9.8	NA	NA	102	NA	0	0	0
0.4	NA	NA	NA	104	NA	0	0	0
15.5	NA	8.8	NA	100	NA	0	0	0
0.4	NA	4.4	NA	103	NA	1	0	0
3.3	9	2	NA	105	NA	0	0	0
2.5	9	3.3	NA	95	NA	0	0	0
2.8	9.6	2.8	NA	85	191	0	0	0
NA	NA	1.7	NA	99	NA	0	0	0
2.5	9	2	NA	103	NA	0	0	0
1.1	7.5	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.7	10.7	7.5	NA	96	154	0	0	0
3.6	NA	NA	NA	105	NA	1	0	1
0.8	7.9	NA	NA	101	NA	0	0	0
3.5	8.6	9.2	NA	103	80	0	0	1
0.6	9.4	NA	NA	103	NA	0	0	1
1.3	8.7	NA	NA	97	NA	0	0	0
0.8	NA	2.9	NA	NA	NA	0	1	1
NA	NA	NA	NA	98	NA	0	0	1
0.3	9.2	3.3	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	3.8	NA	101	NA	0	0	1
0.3	9.3	3.2	NA	100	NA	0	0	1
0.2	9	3.6	NA	100	NA	0	0	1
1.8	8.6	6.4	NA	104	NA	0	0	0
1.8	8.9	2.4	NA	105	NA	0	0	1
2.1	8.6	3.4	NA	105	NA	0	0	1
3.7	9	4	NA	103	200	0	0	1
8.6	10	18	NA	96	NA	1	0	1
0.5	10.1	3.2	NA	103	NA	0	0	0
0.7	NA	1.8	NA	107	NA	1	0	0
0.4	8.4	NA	NA	103	NA	1	0	0
0.4	NA	6.4	NA	106	NA	0	0	0
0.5	9.7	4.1	NA	105	NA	0	0	0
0.2	NA	NA	NA	107	NA	0	0	1
0.2	9.1	NA	NA	107	NA	0	0	1
6.2	NA	20	NA	NA	NA	0	1	0
0.5	9.5	NA	NA	103	NA	0	1	1
1.9	9.6	NA	NA	99	NA	0	1	1
2.1	8.6	53	NA	100	NA	0	0	1
0.9	9.5	2	NA	104	157	0	0	0
0.9	9.9	5.9	NA	98	172	0	0	1
1.7	9.1	2.9	NA	99	155	0	0	1
NA	9.2	NA	NA	99	NA	0	0	1
19.7	8.8	1.9	NA	89	NA	0	0	1
9.8	9.1	1.9	NA	105	26	0	0	1
0.9	9.1	1.4	NA	106	NA	0	0	1
2.3	8.2	4.2	NA	109	NA	1	0	1
0.4	9.5	3.9	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
1.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	103	NA	0	0	1
0.7	9.5	NA	NA	105	NA	0	0	0
NA	NA	42	NA	NA	NA	0	0	1
2	8.9	NA	NA	94	NA	0	0	0
2	8.1	3.3	NA	104	NA	1	0	1
2.2	9.1	6.1	NA	106	72	0	0	1
0.6	9.4	NA	NA	105	NA	0	0	0
0.3	8.5	NA	NA	106	NA	0	0	0
0.4	NA	NA	NA	106	NA	0	0	1
0.4	8.5	NA	NA	108	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	1
0.8	8.8	4	NA	102	153	0	0	0
0.2	8.5	2.5	NA	106	NA	0	0	1
0.2	NA	NA	NA	96	NA	0	0	1
0.3	NA	3.3	NA	100	NA	0	0	1
0.5	9.1	4.4	NA	103	182	0	0	0
9.7	8.1	5	NA	106	91	0	0	1
NA	10.2	2.6	NA	104	NA	0	0	0
1	9.1	NA	NA	106	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	110	NA	0	0	1
0.8	NA	NA	NA	110	NA	0	0	1
0.8	8.2	NA	NA	111	NA	0	0	1
0.8	NA	NA	NA	114	NA	0	0	1
0.4	8.4	NA	NA	110	NA	0	0	1
0.5	NA	NA	NA	106	NA	0	0	1
0.5	NA	NA	NA	103	NA	0	0	1
NA	8.3	NA	NA	99	NA	0	0	1
1.3	8.4	NA	NA	103	NA	0	0	1
5.2	8.1	7.7	NA	107	NA	0	0	0
0.5	NA	2.4	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	102	NA	0	1	0
0.7	NA	NA	NA	NA	NA	0	1	0
0.6	NA	NA	NA	NA	NA	0	1	0
5.8	8.5	NA	NA	98	NA	0	0	1
NA	NA	1.3	NA	NA	281	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	227	0	0	1
0.4	7.7	NA	NA	109	NA	0	0	1
0.8	NA	9.8	NA	NA	NA	0	0	1
NA	NA	1.4	NA	NA	NA	0	0	0
0.5	NA	NA	NA	106	NA	0	1	0
39.1	8.5	4.8	NA	108	NA	0	0	1
0.5	8.4	NA	NA	103	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.5	9.2	101	NA	100	NA	0	0	1
0.5	9.7	133	NA	99	NA	0	0	1
2.9	NA	197	NA	98	NA	1	0	1
4.8	NA	NA	NA	95	NA	0	1	1
4.3	NA	NA	NA	94	NA	0	1	1
13.9	NA	NA	NA	90	NA	0	1	1
1.8	9	4.1	NA	101	107	0	0	0
5.1	8.5	3.4	NA	101	97	0	0	0
6.1	8.9	5.7	NA	99	NA	0	0	0
0.6	8.2	NA	48	105	NA	0	0	0
0.3	8.4	1.2	NA	101	NA	0	0	0
2.9	8.3	6.2	NA	105	NA	0	0	0
0.6	NA	NA	NA	100	NA	0	0	0
0.4	8.8	NA	NA	96	NA	0	0	0
0.3	9	NA	NA	99	NA	0	0	0
0.3	8.8	NA	NA	100	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	9.5	NA	NA	98	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	9.3	NA	NA	91	NA	0	0	0
3	9.1	7.9	NA	95	NA	0	0	1
0.5	8.9	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	8.4	NA	NA	104	NA	0	0	0
0.4	8.5	1.5	NA	100	NA	0	0	0
0.4	NA	1.5	NA	NA	NA	0	0	0
0.4	9.2	1.2	NA	104	NA	0	0	0
0.3	9	NA	NA	105	NA	0	0	0
0.5	9.7	NA	NA	95	NA	0	0	1
0.2	9.1	NA	NA	101	NA	0	0	0
0.3	9.2	NA	NA	104	NA	0	0	0
0.3	8.4	NA	NA	100	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	101	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	104	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	8.8	NA	NA	97	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	100	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
4.5	NA	NA	NA	NA	NA	0	0	1
0.5	9.2	32	NA	NA	NA	0	0	1
0.4	NA	28	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	25	NA	107	NA	0	0	1
0.5	NA	NA	NA	105	NA	0	0	1
NA	NA	NA	NA	102	NA	0	0	1
0.4	9	NA	NA	103	NA	0	0	1
0.5	NA	NA	NA	101	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	9.2	NA	NA	104	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
26.2	8.5	NA	NA	93	NA	0	0	1
0.4	NA	2.3	NA	NA	NA	0	0	0
8.1	NA	NA	NA	101	NA	0	0	0
1	NA	NA	NA	104	NA	0	0	1
0.9	NA	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	106	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	106	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
1.8	8	NA	NA	107	NA	0	0	1
1.7	8.9	NA	NA	105	NA	0	0	1
1.1	NA	NA	NA	103	NA	0	0	1
16.9	8.2	4.7	NA	94	NA	0	0	1
0.2	NA	1.1	NA	102	NA	0	0	0
3.3	7.4	2.7	NA	103	NA	0	0	1
0.6	NA	NA	NA	104	NA	1	0	1
0.4	9.8	NA	NA	NA	NA	0	1	1
0.5	9.3	NA	NA	104	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
0.5	9.5	NA	NA	104	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.3	8.9	NA	NA	106	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
5.5	9.3	NA	NA	107	NA	0	1	1
0.7	9.2	NA	NA	102	NA	0	0	1
0.6	9.3	NA	NA	103	NA	0	0	1
0.8	8.1	2.6	NA	98	NA	0	0	1
0.6	8.1	NA	NA	98	NA	0	1	1
0.6	NA	NA	NA	108	NA	1	0	0
0.4	8.9	2.4	NA	106	NA	0	0	0
0.8	9.9	2.2	NA	95	187	0	0	1
34.8	9	11	NA	88	NA	0	0	1
27.6	NA	NA	NA	94	NA	0	0	1
1.3	8.7	4.1	NA	105	124	0	0	1
0.8	8.9	1.6	NA	111	199	0	0	0
0.5	9.4	1.1	NA	104	284	0	0	0
0.4	NA	NA	NA	102	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	103	NA	0	0	1
0.9	9.1	NA	NA	99	NA	0	0	0
3.2	9.6	3.5	NA	101	112	0	0	0
0.7	NA	NA	NA	100	NA	0	0	1
4.5	9.6	5.3	NA	98	249	0	0	1
2.3	9.4	NA	NA	102	NA	0	0	1
1.1	8.8	NA	NA	102	NA	0	0	0
1.5	8.5	NA	NA	100	NA	0	0	0
0.8	8.4	NA	NA	100	NA	0	0	0
1	8.4	NA	NA	103	NA	0	0	0
4	8	NA	NA	96	NA	0	0	1
1.8	NA	NA	NA	NA	NA	0	0	1
3.5	8.7	2.8	NA	99	137	0	0	1
0.7	8.4	5.1	NA	97	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	106	NA	0	0	1
1.1	NA	5.2	NA	94	NA	0	0	1
0.7	NA	5.3	NA	95	NA	0	1	1
0.6	NA	NA	NA	97	NA	0	1	1
0.8	9.6	NA	NA	92	NA	0	0	1
0.5	9.7	5.3	NA	96	NA	0	1	1
0.5	9.7	5.5	NA	99	NA	0	0	1
0.5	9.5	6.1	NA	98	NA	0	1	1
1.5	10.3	5.2	NA	91	176	0	0	1
0.3	NA	4.2	NA	104	NA	0	0	1
0.3	NA	4	NA	NA	NA	0	0	1
0.3	NA	12	NA	101	NA	0	0	1
0.2	NA	7.3	NA	NA	NA	0	0	1
0.6	NA	3.7	NA	NA	NA	0	0	0
NA	NA	2.5	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
6.1	8.6	2.4	NA	108	NA	1	0	1
7.8	7.9	2.4	NA	105	NA	1	0	1
0.8	NA	NA	NA	103	NA	1	0	0
11.7	8.5	12	NA	95	199	0	0	1
0.7	8.9	4.4	NA	104	138	0	0	0
0.5	8.9	NA	NA	106	NA	1	1	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	106	NA	0	0	0
1.3	9.4	NA	NA	101	NA	0	1	1
1	9.4	NA	NA	101	NA	0	1	1
0.6	8.8	NA	NA	103	NA	0	1	1
0.7	9.1	NA	NA	101	NA	0	1	1
0.5	7.8	NA	NA	103	NA	0	1	1
0.6	8.4	NA	NA	104	NA	0	1	1
0.7	8.9	NA	NA	105	NA	0	1	1
0.4	8.9	NA	NA	105	NA	0	1	1
0.6	9.4	NA	NA	102	NA	0	1	1
0.6	8.5	NA	NA	106	NA	0	0	1
0.8	9	NA	NA	100	NA	0	1	1
0.7	NA	NA	NA	101	NA	0	1	1
0.5	9	NA	NA	102	NA	0	1	1
2	9.1	NA	NA	99	NA	0	1	1
1.1	9.4	NA	NA	95	NA	0	1	1
0.7	NA	3.2	NA	104	NA	0	0	0
18.6	9.1	1.7	NA	97	NA	0	0	1
11.3	NA	495	NA	106	NA	1	1	1
11.4	9	495	561	102	NA	1	1	1
1.2	NA	NA	NA	104	NA	1	1	1
0.6	9.3	7.9	NA	105	228	0	0	1
0.6	8.7	2.1	NA	107	131	0	0	1
0.5	9.2	NA	NA	98	NA	0	0	1
0.9	NA	NA	NA	97	NA	0	0	1
1.7	NA	NA	NA	93	NA	0	0	1
1.5	NA	2.3	NA	104	141	0	0	0
18.2	8.6	1.3	NA	97	NA	1	0	1
19.9	8.3	NA	NA	99	NA	1	1	1
2.6	8	2.9	NA	101	NA	0	0	0
1	8.8	NA	NA	101	NA	0	0	0
1	NA	6.6	NA	101	NA	1	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	8.7	1.2	NA	102	NA	0	0	0
16.5	8.9	1.3	NA	92	NA	0	0	1
0.3	9.4	NA	254	103	NA	0	0	1
17.8	9.5	13	NA	99	45	0	0	0
0.4	7.9	2.9	NA	110	NA	0	0	1
0.2	NA	NA	NA	100	NA	0	0	1
0.4	8.8	NA	NA	102	NA	0	0	1
0.3	NA	NA	NA	102	NA	0	0	1
0.3	9.3	NA	NA	106	NA	0	0	1
0.3	9.5	NA	NA	102	NA	0	0	1
0.3	9.5	NA	NA	104	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	9.2	NA	NA	102	NA	0	0	1
0.3	9	NA	NA	105	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.7	8.2	NA	NA	97	NA	0	0	1
11.5	NA	NA	NA	NA	NA	0	0	1
18.6	8.7	NA	NA	94	NA	0	0	1
13.1	NA	NA	NA	97	NA	0	0	1
1.4	9.6	1.6	NA	108	NA	0	0	0
0.9	NA	NA	NA	101	NA	0	0	1
0.5	NA	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	104	NA	0	0	1
NA	8.5	NA	NA	93	NA	0	0	0
5.4	9.7	18	NA	91	286	0	0	0
5.2	NA	12	NA	106	NA	1	1	1
10.6	9.6	4.3	NA	92	NA	1	0	1
26.8	8.2	1.5	NA	106	NA	0	0	0
2.1	NA	NA	NA	97	NA	0	0	1
0.6	9.5	NA	NA	100	NA	0	1	1
0.9	NA	NA	NA	98	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	9.8	NA	NA	100	NA	0	0	1
0.9	NA	NA	NA	100	NA	0	1	1
0.5	NA	NA	NA	100	NA	0	0	1
0.5	NA	NA	NA	100	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.8	NA	NA	NA	92	NA	0	0	1
1.6	8.7	NA	NA	98	NA	1	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	97	NA	0	0	1
1.8	8.5	NA	NA	96	NA	0	0	1
2	8.9	1.4	NA	102	NA	0	0	1
3.6	8.7	12	NA	102	NA	0	0	0
12.8	9.8	2.5	NA	105	NA	1	0	0
0.6	9.2	NA	NA	104	NA	0	0	0
0.4	9.4	NA	NA	104	NA	0	0	0
0.5	9.6	NA	NA	103	NA	0	0	0
0.4	9.4	NA	NA	107	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.6	9.4	NA	NA	98	NA	0	0	0
0.3	9.4	NA	NA	100	NA	0	0	0
0.4	9.9	NA	NA	105	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	9.1	NA	NA	104	NA	0	1	1
0.4	9.2	NA	NA	104	NA	0	0	1
0.5	NA	NA	NA	96	NA	0	0	1
0.4	8.7	NA	NA	102	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	9.8	NA	NA	96	NA	0	0	1
9.6	8.3	25	NA	95	NA	0	0	1
0.9	9.6	3	NA	98	167	0	0	0
1.3	NA	NA	NA	103	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	102	NA	0	0	1
0.2	NA	NA	NA	101	NA	0	0	1
3.8	NA	NA	NA	103	NA	0	0	0
2.5	9.5	6.9	NA	102	181	0	0	0
23.5	NA	6.7	NA	100	NA	0	0	0
7.4	8.7	9.2	NA	105	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	0	1
1	NA	9.6	NA	99	NA	0	1	1
5.5	NA	17	NA	104	NA	1	1	1
0.7	9.7	14	NA	99	NA	0	1	1
0.8	9.4	NA	NA	97	NA	0	1	1
0.7	NA	NA	NA	100	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	102	NA	0	1	1
0.3	NA	NA	NA	104	NA	0	0	1
0.4	9.1	NA	NA	103	NA	0	1	0
0.4	NA	NA	NA	105	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	1	0
0.4	NA	NA	NA	105	NA	0	1	0
NA	NA	NA	NA	100	NA	0	1	0
0.3	NA	NA	NA	99	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.3	9.2	NA	NA	102	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.3	9.3	NA	NA	104	NA	0	1	0
0.3	10.1	NA	NA	96	NA	0	1	0
NA	NA	NA	NA	97	NA	0	1	0
NA	NA	NA	NA	94	NA	0	1	0
0.4	NA	NA	NA	85	NA	0	1	1
0.3	NA	NA	NA	96	NA	0	1	0
0.4	NA	NA	NA	95	NA	0	1	0
0.4	NA	NA	NA	93	NA	0	1	0
0.5	8.7	NA	NA	96	NA	0	0	0
0.6	8.6	NA	NA	98	NA	0	1	0
0.5	7.9	NA	NA	97	NA	0	1	0
0.4	8.3	NA	NA	92	NA	0	0	1
0.3	9.2	NA	NA	91	NA	0	1	1
0.5	9.2	NA	NA	96	NA	0	1	0
0.3	8.7	NA	NA	94	NA	0	0	1
0.6	NA	NA	NA	93	NA	0	1	0
0.4	NA	NA	NA	99	NA	0	1	1
0.4	8.2	NA	NA	97	NA	0	1	1
0.6	8.4	NA	NA	95	NA	0	0	1
0.4	8.5	NA	NA	96	NA	0	1	1
0.4	8.3	NA	NA	97	NA	0	1	1
0.4	8.9	NA	NA	102	NA	0	1	1
0.4	9	NA	NA	98	NA	0	1	0
0.3	NA	NA	NA	94	NA	0	1	0
0.4	9.5	NA	NA	99	NA	0	1	0
0.3	9.4	NA	NA	93	NA	0	1	0
0.5	8.2	2.5	NA	99	NA	0	0	1
2	10.1	3.1	NA	100	NA	0	0	0
1	NA	NA	NA	104	NA	1	0	0
2	NA	NA	NA	102	NA	1	0	0
0.6	10.3	NA	NA	98	NA	0	0	1
0.5	10.6	NA	NA	97	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
6	NA	NA	NA	105	NA	1	0	0
5.3	9.4	1.9	NA	104	161	0	0	0
1.8	8.7	3.8	NA	103	109	0	0	0
0.9	NA	NA	NA	106	NA	1	0	1
0.2	9	NA	NA	101	NA	0	0	1
0.2	8.5	NA	NA	104	NA	0	0	1
0.4	8.4	NA	NA	105	NA	0	0	1
0.3	9.1	NA	NA	107	NA	0	0	1
0.2	NA	NA	NA	108	NA	0	0	1
0.2	NA	NA	NA	112	NA	0	0	1
NA	NA	NA	NA	108	NA	0	0	1
0.3	8.5	NA	NA	109	NA	0	0	1
0.2	8.3	NA	NA	111	NA	0	0	1
0.3	NA	NA	NA	109	NA	0	0	1
0.3	8.6	NA	NA	112	NA	0	0	1
0.4	8.8	NA	NA	112	NA	0	0	1
0.4	7.9	NA	NA	107	NA	0	0	1
0.4	7.3	NA	NA	105	NA	0	0	1
0.5	7.9	NA	NA	105	NA	0	0	1
0.5	7.8	NA	NA	104	NA	0	0	1
0.2	7.1	NA	NA	103	NA	0	0	1
6.8	NA	1.9	NA	106	NA	0	0	1
6.9	7.5	1.8	NA	110	NA	0	0	1
0.3	9	4.1	19	109	NA	0	0	0
6.5	9	NA	NA	97	NA	0	0	1
4.9	NA	NA	NA	95	NA	0	1	1
8	9.2	NA	NA	94	NA	0	1	0
1.8	NA	NA	NA	98	NA	0	1	0
3.2	10.4	2.5	NA	100	199	0	0	0
0.5	8.3	3	NA	108	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.7	10	1.7	NA	100	NA	0	0	1
21.3	9.8	NA	NA	104	NA	1	0	0
1.1	9.2	NA	NA	97	NA	0	0	0
1	9.3	NA	NA	99	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
1.1	9.1	NA	NA	101	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
1.1	NA	NA	NA	NA	NA	0	0	0
1.2	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
2.8	9	3.4	NA	100	129	0	0	0
0.2	9.3	NA	NA	101	194	0	0	0
0.3	9.1	1.5	45	101	NA	0	0	0
1.3	9	NA	NA	102	NA	0	0	0
1.6	8.2	41	NA	100	NA	0	0	0
1.9	NA	1.4	NA	103	NA	0	0	0
1.6	8.7	1.5	NA	105	NA	0	0	0
1.7	8.7	NA	NA	104	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.7	8.7	NA	NA	NA	NA	0	0	0
1.6	NA	1.5	NA	100	NA	0	0	0
1.3	NA	1.3	NA	NA	NA	0	0	0
1.5	NA	1.4	NA	NA	NA	0	0	0
2.3	NA	1.4	NA	NA	NA	0	0	0
5	9.6	1.6	NA	94	NA	0	0	1
NA	9.3	NA	NA	97	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	0
4.3	9	NA	NA	98	NA	0	0	1
1.9	NA	NA	NA	NA	NA	0	0	1
10.9	8.7	NA	NA	97	NA	0	0	1
4.9	NA	NA	NA	NA	NA	0	0	1
10.8	NA	NA	NA	NA	NA	1	0	1
7.5	NA	NA	NA	NA	NA	0	0	1
12	NA	NA	NA	NA	NA	0	0	0
15.1	NA	NA	NA	102	NA	0	0	0
12.6	8.5	NA	NA	99	NA	0	0	1
6.9	NA	NA	NA	NA	NA	0	0	1
5.1	8.8	NA	NA	89	NA	0	0	1
3.2	9	3	NA	102	160	0	0	0
NA	9.2	1.1	NA	101	NA	0	0	0
3.9	9	7.9	NA	96	170	0	0	0
5.4	9	7.2	NA	100	150	0	0	1
1.7	NA	2.7	NA	100	NA	0	0	1
1.2	8.9	NA	NA	99	NA	0	1	1
1.1	NA	NA	NA	101	NA	0	1	1
0.7	NA	NA	NA	101	NA	0	1	0
0.6	NA	NA	NA	103	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	103	NA	0	1	1
0.6	NA	NA	NA	104	NA	0	1	1
0.6	NA	NA	NA	102	NA	0	1	1
0.5	NA	NA	NA	101	NA	0	1	1
1	NA	NA	NA	101	NA	0	1	0
0.5	NA	NA	NA	101	NA	0	1	0
0.8	NA	NA	NA	100	NA	0	1	0
0.7	NA	NA	NA	101	NA	0	1	0
0.7	NA	NA	NA	101	NA	0	1	1
0.8	NA	NA	NA	96	NA	0	1	0
1.1	NA	NA	NA	98	NA	0	1	0
0.7	7.4	NA	NA	103	127	0	0	1
4	NA	9.7	NA	NA	NA	0	0	1
0.7	8.9	3.5	44	100	NA	0	0	0
1.7	8.8	NA	NA	100	NA	0	0	0
0.6	7.6	2.6	NA	100	NA	0	0	1
18.9	9.7	NA	NA	96	NA	0	0	1
1.3	NA	NA	NA	NA	NA	0	0	1
0.4	10	NA	NA	99	NA	0	0	0
0.6	9	NA	NA	103	NA	0	1	1
0.7	9.2	NA	NA	104	NA	0	1	1
0.6	8.9	NA	NA	105	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.6	9.2	NA	NA	103	NA	0	1	1
0.8	NA	NA	NA	NA	NA	0	1	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.4	9.1	NA	NA	102	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.7	9.3	NA	NA	88	NA	0	1	1
0.6	9.4	2.5	NA	101	121	0	0	0
0.3	8.9	3.1	NA	105	NA	0	0	0
0.7	9.8	4.6	NA	104	NA	0	0	0
0.6	9.4	NA	NA	101	192	0	0	0
0.6	NA	NA	NA	101	NA	0	0	0
0.4	NA	NA	NA	106	NA	0	0	0
4.6	8.1	7.8	NA	100	74	0	0	1
0.8	10.2	1	18	103	NA	0	0	0
0.2	8.8	NA	NA	105	NA	0	0	0
0.5	9	NA	NA	105	NA	0	0	0
0.6	NA	NA	NA	103	NA	0	0	0
0.6	9.1	NA	NA	105	NA	0	0	0
0.8	8.5	NA	NA	102	NA	0	0	0
0.6	8.5	NA	NA	106	NA	0	0	0
0.6	NA	NA	NA	104	NA	0	0	0
0.6	NA	NA	NA	106	NA	0	0	0
1	NA	NA	NA	105	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	0
1	NA	8.3	NA	NA	NA	0	0	0
1	9.1	NA	NA	101	NA	0	0	0
1.2	9.7	NA	NA	99	NA	0	0	0
5.2	NA	10	NA	99	NA	1	0	0
1.3	9.5	4.2	NA	104	103	0	0	0
0.4	7.9	4.6	332	104	NA	0	0	0
0.7	8.3	1.4	NA	106	NA	0	0	0
13	8.3	20	NA	103	NA	1	0	0
1.1	NA	4.4	NA	101	NA	0	0	0
0.6	7.3	1.1	3.3	119	NA	0	0	0
1	NA	NA	NA	NA	NA	0	0	1
2	9.2	9	NA	110	125	0	0	1
0.6	NA	11	NA	102	NA	0	0	1
27.3	8.8	5.5	NA	102	134	0	0	1
8.2	8.6	1	NA	104	NA	1	0	1
0.6	9.3	NA	NA	101	NA	0	0	0
0.3	9.1	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	8.9	NA	NA	104	NA	0	0	1
0.4	8.2	NA	NA	98	NA	0	0	1
NA	NA	NA	NA	104	NA	0	0	1
0.3	8.3	NA	NA	106	NA	0	0	1
0.6	NA	5.4	29	104	NA	0	0	0
2.4	NA	1	33	105	NA	1	0	1
0.4	NA	NA	NA	98	NA	0	0	0
0.3	8.7	NA	NA	102	NA	0	1	1
0.7	8.3	1.1	NA	103	NA	0	0	1
0.3	9	NA	NA	98	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	105	NA	0	0	0
1.2	8.6	2.9	NA	108	NA	1	0	0
3.4	9.4	12	NA	101	144	0	0	1
3.7	8.5	2.6	NA	100	NA	0	0	1
0.3	NA	NA	NA	99	NA	1	0	0
9.8	NA	2.5	NA	101	NA	0	0	1
3.1	NA	NA	NA	98	NA	0	1	1
0.8	8.9	NA	NA	98	NA	0	0	1
0.5	NA	NA	NA	101	NA	0	1	1
0.3	NA	NA	NA	103	NA	0	1	1
0.3	NA	NA	NA	103	NA	0	1	1
0.3	NA	NA	NA	103	NA	0	1	1
0.2	NA	NA	NA	103	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.7	9.1	NA	NA	100	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.7	NA	NA	NA	NA	NA	0	1	1
0.2	NA	NA	NA	101	NA	0	0	0
NA	NA	NA	NA	84	299	0	0	0
0.9	9.5	NA	NA	108	NA	0	0	0
0.5	9.5	NA	NA	107	NA	0	0	0
0.4	9	NA	NA	104	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.5	8.5	NA	NA	113	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
1.2	NA	NA	NA	110	NA	0	0	1
1.4	NA	NA	NA	NA	NA	0	0	1
1.7	NA	NA	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
1.2	7.6	NA	NA	108	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	0
13.1	9.1	1.3	NA	98	NA	1	0	0
1	9.1	NA	NA	100	NA	0	1	1
0.7	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	101	NA	0	0	0
2.1	7.6	NA	NA	96	NA	1	0	0
1.2	9.6	1.9	NA	100	139	0	0	0
0.9	8	9.8	NA	103	142	0	0	1
1.4	9.5	4.8	NA	100	220	0	0	1
0.3	9.4	4.2	NA	102	NA	0	0	1
1.2	9.5	NA	NA	101	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	8.5	NA	NA	98	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	1
4	9	NA	NA	99	NA	0	0	1
0.9	8	NA	NA	108	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
2.9	NA	2.1	NA	100	NA	0	0	0
1.4	8	NA	NA	99	125	0	0	1
NA	NA	1	76	103	NA	0	0	0
0.5	NA	1.1	14	102	NA	0	1	0
0.6	9	NA	NA	90	NA	0	0	1
NA	8.5	2.4	NA	111	NA	0	0	0
0.3	9.9	NA	NA	104	NA	0	0	0
0.1	9.4	NA	NA	105	NA	0	0	0
0.1	9.5	NA	NA	102	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.1	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	106	NA	0	0	0
0.1	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.2	9.2	NA	NA	99	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	1	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.7	NA	NA	NA	102	NA	0	0	1
0.5	8.8	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	101	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.6	8.4	NA	NA	101	NA	0	0	1
1.7	8.1	NA	NA	98	NA	0	0	1
0.4	9.2	2.4	NA	100	218	0	0	0
1.4	8	2.3	NA	103	NA	0	0	0
1.1	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	106	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	104	NA	0	0	0
0.5	NA	NA	NA	104	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
1	NA	NA	NA	NA	NA	0	0	1
1.8	8.1	NA	NA	104	NA	1	0	1
1.2	9.1	NA	NA	104	NA	0	0	1
1	8.7	NA	NA	101	NA	0	0	1
0.6	8.9	NA	NA	104	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.7	9	NA	NA	103	NA	0	0	1
0.5	8.1	NA	NA	104	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.8	8.3	NA	NA	102	NA	0	0	1
0.5	8.3	NA	NA	105	NA	0	0	1
0.7	8.3	NA	NA	101	NA	0	0	1
0.5	8.2	NA	NA	99	NA	0	0	1
1.3	NA	NA	NA	103	NA	0	0	0
1.1	NA	NA	NA	103	NA	0	0	0
1.1	9.6	NA	NA	98	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.6	9.4	NA	NA	99	NA	0	0	1
0.6	9.2	NA	NA	100	NA	0	0	1
2.2	NA	5.8	NA	102	NA	0	0	0
4.3	NA	7.3	NA	109	NA	0	0	0
1.1	7.2	2.5	NA	108	NA	0	0	0
1.7	9.2	3.1	NA	102	NA	1	0	1
1.6	NA	NA	NA	103	NA	0	0	1
0.3	NA	1.9	NA	102	NA	0	0	0
3	8.2	4.2	NA	102	NA	0	0	1
2.1	8.1	6.1	NA	96	36	0	0	1
1	NA	3.3	NA	NA	NA	0	0	0
1.1	9.7	NA	NA	101	NA	0	0	0
5.6	9	6.5	NA	100	NA	1	0	1
0.3	9	6.6	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	0
NA	NA	2.3	NA	NA	NA	0	1	0
0.8	9.3	1	NA	96	NA	0	0	0
0.3	NA	2.9	NA	96	NA	0	1	0
0.3	9	2.4	NA	98	NA	0	0	0
0.5	NA	127	NA	98	NA	0	0	1
0.4	8.4	15	NA	101	NA	0	0	0
1.1	8.2	NA	NA	101	103	0	0	0
0.5	9.1	2	NA	100	NA	0	0	1
13.1	9.4	4.4	NA	98	NA	0	0	1
1.2	8.7	NA	NA	102	157	0	0	0
4.1	8.9	4.7	NA	94	121	0	0	0
0.5	9.3	1.9	NA	102	150	0	0	0
0.3	9.6	85	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	1
1.1	NA	3.9	NA	105	NA	0	0	0
0.9	8.7	4.9	NA	103	NA	0	0	0
0.7	8.7	6.8	38	109	NA	0	0	0
0.3	NA	NA	232	103	NA	0	0	1
1.9	10	2.4	NA	104	159	0	0	0
1.3	NA	2.7	NA	103	NA	0	0	0
21.7	8.4	5.6	NA	100	44	0	0	1
0.3	9.3	NA	NA	101	NA	0	0	1
8.2	NA	NA	NA	99	NA	0	0	1
0.9	9.8	NA	NA	97	NA	0	1	1
0.2	NA	NA	NA	102	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
11.4	9.1	NA	NA	93	NA	0	0	0
0.9	NA	NA	NA	99	NA	0	0	1
1.8	NA	NA	NA	100	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
1.1	NA	NA	NA	NA	NA	0	0	1
2.6	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.3	8.6	79	NA	94	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.8	7.5	NA	NA	109	117	0	0	1
1.5	8.8	3	NA	105	132	0	0	0
NA	8.8	20	21	110	NA	0	0	1
0.9	NA	2.6	NA	107	NA	0	0	0
1.1	6.9	1.2	NA	106	NA	1	0	1
1.3	NA	NA	NA	105	NA	1	0	0
1.3	NA	1.5	NA	NA	NA	1	0	0
1.8	NA	NA	NA	NA	NA	0	1	0
1.1	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.5	NA	NA	NA	NA	NA	0	0	0
1.8	NA	NA	NA	NA	NA	0	0	0
2.1	NA	NA	NA	112	NA	0	0	0
0.6	8.8	405	NA	92	NA	0	0	1
0.4	5.2	91	NA	98	NA	0	0	1
0.5	6	NA	NA	99	NA	0	0	1
NA	8.4	10	256	97	NA	0	0	1
2.8	NA	8.9	NA	100	NA	0	0	0
1.6	8.3	3	NA	99	88	0	0	1
7.1	7.4	10	NA	104	78	0	0	0
40.5	9	5.4	NA	110	51	0	0	0
0.7	NA	NA	NA	94	NA	1	0	0
0.8	8.7	NA	NA	101	NA	1	0	0
0.6	8.8	2.7	NA	107	119	0	0	0
24.5	9.3	6.3	NA	99	NA	0	0	1
0.6	NA	NA	NA	NA	NA	1	0	0
0.9	NA	3.4	NA	97	NA	0	0	1
3.4	7.9	1.5	NA	103	NA	0	0	0
2.7	8.4	NA	196	95	NA	0	0	1
0.8	7.7	11	NA	102	NA	0	0	1
24	8.6	3.9	NA	94	NA	0	0	1
1.6	9	3.5	NA	103	168	0	0	0
1.2	10	288	NA	99	NA	0	0	1
3.9	11	NA	NA	92	NA	0	0	1
2.2	8.7	3.6	NA	100	142	0	0	1
2.3	8.9	3.4	NA	99	145	0	0	1
3.1	8.2	4.9	NA	92	NA	0	0	1
14.3	NA	NA	NA	104	NA	0	1	0
1.4	NA	4.7	NA	102	NA	1	0	1
0.2	8.5	NA	NA	110	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
43.7	9.7	2.1	NA	96	NA	0	0	1
1	9.8	2.5	NA	97	234	0	0	0
NA	9.7	1.1	1351	99	NA	0	0	0
1.1	9.2	6.8	NA	98	212	0	0	0
2.8	8.6	5.1	NA	107	134	0	0	0
0.2	NA	5.1	NA	103	NA	0	0	0
0.3	10.2	2.2	NA	101	NA	0	0	0
3	8.3	2.9	NA	100	72	0	0	1
1.1	8.9	NA	NA	99	203	0	0	0
2.5	9.3	7.6	NA	87	92	0	0	0
1.2	9.1	7.6	NA	108	136	0	0	1
0.5	NA	4.9	NA	NA	NA	0	0	1
0.6	NA	NA	NA	101	NA	1	0	1
0.5	NA	NA	NA	104	NA	1	0	1
0.3	7.9	NA	NA	107	NA	1	0	1
0.3	NA	NA	NA	108	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.4	10.3	NA	NA	103	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.8	NA	NA	NA	103	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.7	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.7	NA	NA	NA	NA	NA	0	1	1
1.6	NA	NA	NA	NA	NA	0	1	1
1.5	NA	NA	NA	NA	NA	0	1	1
1	9.4	4	NA	100	176	0	0	1
0.5	8.7	5.4	NA	110	169	0	0	0
1.1	9.9	9	NA	101	NA	0	0	1
1.7	8.5	11	NA	97	137	0	0	1
0.2	9.4	5	NA	98	177	0	0	1
2.7	NA	2.7	NA	NA	NA	1	0	1
0.4	9.6	NA	NA	101	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
11.1	9.2	1.4	NA	102	NA	1	0	1
0.7	NA	1.1	NA	NA	NA	0	0	0
13.2	9	NA	NA	102	NA	0	0	1
0.9	8.9	NA	NA	103	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	8.6	NA	NA	108	NA	0	0	1
1.1	10.6	3.8	NA	109	NA	0	0	0
1.3	NA	NA	NA	NA	NA	0	0	1
4.4	8.7	4.4	NA	100	NA	0	0	0
3.8	NA	19	NA	94	NA	0	0	1
0.5	NA	2.4	NA	102	NA	1	0	0
0.5	NA	2.3	NA	103	NA	1	0	0
1.4	8.9	124	NA	99	NA	0	0	1
4.5	7.2	1.7	NA	110	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	2.9	NA	NA	NA	1	0	0
14.5	8.9	2.2	NA	105	NA	1	0	1
0.4	9.2	NA	NA	101	NA	0	0	1
0.4	8.8	1.2	NA	105	NA	0	0	1
2.4	7.9	5.2	NA	109	167	0	0	1
1.6	9.3	4.6	NA	104	NA	0	0	0
0.3	NA	3.7	NA	104	NA	0	0	1
13.7	9.3	4.6	NA	99	NA	0	0	0
0.2	9.5	3.6	NA	107	NA	0	1	0
0.2	NA	4.3	NA	NA	NA	0	1	0
0.3	NA	5.5	NA	NA	NA	0	0	0
0.2	NA	6.2	NA	NA	NA	0	0	0
0.3	NA	6.2	NA	NA	NA	0	0	0
0.8	9.1	1.9	NA	98	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
10.1	9.5	4.6	NA	100	NA	0	0	1
1.5	NA	NA	NA	NA	NA	0	1	0
1.1	NA	5.6	NA	92	NA	0	0	1
0.8	NA	NA	NA	95	NA	0	0	1
0.4	NA	NA	NA	90	NA	0	0	1
0.5	NA	NA	NA	92	NA	0	0	1
0.4	NA	NA	NA	94	NA	0	0	1
NA	NA	NA	NA	93	NA	0	0	1
0.6	NA	NA	NA	93	NA	0	0	1
0.5	NA	NA	NA	94	NA	0	0	1
0.7	NA	NA	NA	95	NA	0	0	1
0.7	9	NA	NA	90	NA	0	0	1
0.8	NA	NA	NA	87	NA	0	0	1
0.5	NA	NA	NA	85	NA	0	0	1
0.6	NA	NA	NA	94	NA	0	0	1
0.4	NA	NA	NA	100	NA	0	0	1
NA	9	NA	NA	97	NA	0	0	1
0.6	NA	NA	NA	96	NA	0	0	1
0.5	NA	NA	NA	98	NA	0	0	1
0.3	NA	NA	NA	97	NA	0	0	1
0.4	NA	NA	NA	95	NA	0	0	1
1.4	NA	NA	NA	91	NA	0	0	1
0.3	NA	2.3	NA	NA	NA	0	0	0
0.4	NA	3.6	NA	NA	NA	0	0	0
3.2	9.6	2.7	NA	102	271	0	0	0
1.4	8.8	2.2	NA	105	186	0	0	0
23.8	9.4	8.4	NA	96	NA	1	0	1
3.7	9.6	NA	NA	94	NA	0	0	1
0.5	9.8	NA	NA	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	9.4	NA	NA	104	NA	0	0	1
0.1	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.2	9.6	NA	NA	103	NA	0	0	0
0.3	9.5	NA	NA	100	NA	0	0	1
0.3	10.4	NA	NA	99	NA	0	0	1
0.3	9.8	NA	NA	98	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	9.5	NA	NA	99	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.1	9.2	NA	NA	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.1	8.6	NA	NA	99	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	9	NA	NA	102	NA	0	0	1
0.1	8.9	NA	NA	98	NA	0	0	1
0.5	9.5	29	NA	99	NA	0	0	0
1.2	NA	4	NA	108	NA	0	0	0
9.3	8.7	3.4	NA	96	NA	0	0	1
0.4	8.6	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	8.8	NA	NA	104	NA	0	0	1
3.2	8.6	NA	NA	104	NA	0	0	0
0.4	8.2	2.8	NA	94	NA	0	0	1
0.6	NA	4.2	NA	100	NA	0	0	1
0.2	9.5	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	107	NA	0	0	1
0.4	10.4	NA	NA	97	NA	0	0	1
0.3	9.5	NA	NA	99	NA	0	0	1
0.4	9.5	NA	NA	99	NA	0	0	1
0.5	9.8	NA	NA	99	NA	0	0	1
0.3	9.4	NA	NA	94	NA	0	0	1
0.3	9.5	NA	NA	97	NA	0	0	1
0.4	9.6	NA	NA	99	NA	0	0	1
0.5	NA	3.9	NA	91	NA	0	0	1
22.7	10.1	6.9	NA	95	NA	0	0	1
0.2	NA	1.8	NA	102	NA	0	0	0
13.9	9.7	NA	NA	101	NA	0	0	0
3.4	8	17	NA	99	111	0	0	0
0.9	9.3	5.7	NA	107	87	0	0	1
1.5	9.2	NA	NA	107	NA	1	0	0
0.5	8.8	3.5	NA	106	NA	0	0	0
2.7	9.3	16	NA	99	142	0	0	1
0.2	NA	1.2	NA	101	NA	0	0	0
NA	9	2.2	NA	105	NA	0	0	0
9.4	8.4	5.6	NA	96	198	0	0	1
26.8	9.3	3.8	NA	105	NA	1	0	1
0.5	9.6	4.2	NA	101	159	0	0	0
6.6	9.2	30	NA	93	127	0	0	1
16	9	NA	NA	99	NA	1	0	1
7.9	9.3	NA	NA	98	NA	0	1	1
2.8	9.4	NA	NA	96	NA	0	0	1
4.8	9.1	6.3	NA	104	NA	0	0	0
0.5	8.8	1.3	32	98	NA	0	0	0
0.4	NA	1.1	NA	98	NA	0	0	0
5.1	10.5	3.7	NA	100	502	0	0	0
1.4	NA	3.1	NA	106	NA	0	0	0
NA	8	NA	NA	101	NA	1	0	1
NA	NA	NA	7.7	106	NA	0	0	0
2.6	8.7	1.5	NA	95	119	0	0	1
NA	NA	1.1	35	105	NA	0	0	0
1.7	8	31	NA	104	NA	0	0	1
1.2	NA	NA	NA	NA	NA	0	0	1
0.3	9	6.2	NA	104	NA	0	0	1
1.8	8.5	5.4	NA	106	123	0	0	1
0.3	7.7	NA	NA	100	NA	0	0	1
0.7	NA	10	NA	104	NA	0	0	0
1.4	NA	NA	NA	100	NA	0	0	1
0.6	9.4	NA	NA	96	NA	0	1	1
0.6	10.3	NA	NA	97	NA	0	1	1
10	10.3	NA	NA	92	NA	0	0	1
4.5	10.2	NA	NA	94	NA	0	0	1
0.7	9.7	NA	NA	93	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
0.3	9.5	1.2	NA	NA	216	0	0	0
1	NA	NA	NA	101	NA	0	0	0
0.8	10.2	NA	NA	102	NA	0	1	0
0.5	9.8	NA	NA	103	NA	0	1	0
0.9	10	NA	NA	99	NA	0	1	0
0.7	9.2	NA	NA	105	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.4	9.1	NA	NA	105	NA	0	1	0
0.4	8.9	NA	NA	106	NA	0	1	0
0.9	8.9	NA	NA	101	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	6.9	NA	105	NA	0	0	0
1	8.2	41	89	110	NA	0	0	0
1.7	8.6	4.2	NA	100	75	0	0	0
0.4	NA	NA	NA	103	NA	0	0	1
0.5	NA	1.6	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
1.2	7.8	1.7	NA	103	NA	0	0	0
0.3	8.3	NA	12	103	NA	0	0	0
0.2	NA	11	40	105	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	NA	2.8	NA	96	NA	1	0	1
0.2	8.9	NA	NA	108	NA	0	0	1
4.1	7.5	1.5	NA	108	NA	0	0	0
0.3	NA	3	NA	99	NA	0	0	0
1	9.4	NA	NA	NA	NA	0	0	0
0.5	NA	1.5	3300	101	NA	0	0	1
8.4	8.4	22	NA	93	86	0	0	0
16.3	8.2	5.4	NA	104	87	0	0	1
0.3	9.6	1.7	NA	101	207	0	0	0
1.8	8	NA	NA	101	NA	0	0	1
4.8	9.7	4.6	NA	104	194	0	0	0
0.2	9.4	NA	NA	105	NA	0	0	0
0.4	9.1	NA	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9.5	NA	NA	99	NA	0	0	0
0.3	9.1	NA	NA	104	NA	0	0	0
NA	9.4	NA	NA	100	NA	0	0	0
0.3	NA	NA	NA	102	NA	0	0	0
0.4	9	NA	NA	102	NA	0	0	0
0.4	9.1	NA	NA	100	NA	0	0	0
0.3	NA	4.2	NA	NA	NA	0	0	1
14.6	9.3	NA	NA	99	NA	0	0	1
5.8	9.1	NA	NA	94	NA	0	0	1
1.5	9.2	NA	NA	97	NA	0	0	1
0.8	NA	NA	NA	98	NA	0	0	1
0.9	8.9	NA	NA	96	NA	0	0	1
0.3	9.5	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	8.2	NA	NA	106	136	0	0	1
NA	NA	NA	NA	NA	NA	0	1	1
0.4	9.3	NA	NA	100	NA	0	0	1
0.7	8.7	NA	NA	101	NA	0	0	1
0.8	8.7	NA	NA	100	NA	0	0	1
12.2	NA	NA	NA	99	NA	0	0	1
0.6	8.8	6	NA	102	NA	0	0	0
0.4	NA	NA	NA	101	NA	1	0	0
0.7	NA	NA	10	102	NA	0	0	0
20.9	8.6	31	NA	102	42	0	0	1
0.8	8	1.7	NA	106	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	1
1.9	8.3	9.6	NA	99	93	0	0	1
0.3	8.9	NA	NA	97	204	0	0	0
18.5	8.2	352	NA	103	NA	0	0	1
0.2	7.9	1.1	NA	102	NA	0	0	1
0.8	7	1.8	NA	113	NA	1	0	0
0.6	9.7	22	NA	105	NA	0	0	1
0.6	8.8	18	NA	99	180	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	15	NA	NA	NA	0	0	1
0.4	9.8	NA	NA	100	NA	0	0	1
0.4	NA	9.7	NA	NA	NA	0	0	1
0.5	NA	8.4	NA	NA	NA	0	0	1
0.4	NA	8.4	NA	102	NA	0	0	1
0.4	NA	9.4	NA	NA	NA	0	0	1
0.3	NA	10	NA	NA	NA	0	0	1
0.3	NA	8.9	NA	NA	NA	0	0	1
0.5	NA	11	NA	NA	NA	0	0	1
0.5	NA	NA	NA	104	NA	0	0	0
3.9	7.3	13	NA	106	84	0	0	1
2.4	8.2	3.4	NA	105	NA	0	0	1
2.6	NA	3.7	NA	100	NA	1	0	1
0.3	8.6	1.1	NA	92	NA	0	0	0
8.2	8.3	NA	NA	113	NA	0	0	0
NA	7.5	1.3	NA	98	NA	0	0	0
0.4	NA	2.4	NA	101	NA	0	0	0
0.4	NA	NA	NA	94	NA	0	0	1
0.6	NA	NA	NA	93	NA	0	0	1
0.4	NA	NA	NA	107	NA	0	0	1
0.5	NA	NA	NA	102	NA	0	0	1
0.4	8.7	NA	NA	102	NA	0	0	1
0.4	8.5	NA	NA	99	NA	0	0	1
0.4	8.5	NA	NA	103	NA	0	0	1
0.4	NA	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	102	NA	0	0	1
0.3	NA	NA	NA	105	NA	0	0	1
0.4	NA	NA	NA	103	NA	0	0	1
0.5	NA	NA	NA	101	NA	0	0	1
0.4	NA	NA	NA	105	NA	0	0	1
0.3	NA	NA	NA	107	NA	0	0	1
0.3	NA	NA	NA	110	NA	0	0	1
0.2	NA	NA	NA	106	NA	0	0	1
0.3	NA	NA	NA	108	NA	0	0	1
0.2	NA	NA	NA	111	NA	0	0	1
0.2	NA	NA	NA	110	NA	0	0	1
0.2	NA	NA	NA	110	NA	0	0	1
0.3	NA	NA	NA	108	NA	0	0	1
0.2	NA	NA	NA	108	NA	0	0	1
0.3	NA	NA	NA	108	NA	0	0	1
0.2	NA	NA	NA	109	NA	0	0	1
0.3	NA	NA	NA	105	NA	0	0	1
0.3	NA	NA	NA	106	NA	0	0	1
0.8	9.5	2.6	NA	103	225	0	0	1
7.2	9.5	NA	NA	97	NA	0	0	1
8.7	NA	1.5	NA	101	NA	1	0	0
0.8	NA	NA	NA	106	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	107	NA	0	0	0
0.5	9	NA	NA	99	NA	0	0	1
0.3	8.9	NA	NA	108	NA	0	0	1
0.7	8.4	NA	NA	103	NA	0	0	0
0.6	8.6	NA	NA	97	NA	0	0	0
0.6	7.9	NA	NA	102	NA	0	0	0
0.5	8	NA	NA	100	NA	0	0	0
0.3	8.9	2.2	743	104	NA	0	0	1
0.4	NA	NA	NA	99	NA	1	0	0
0.4	NA	NA	NA	104	NA	0	1	0
6.9	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	0	0
3.6	9	4.6	NA	100	128	0	0	0
0.3	NA	4.3	NA	100	NA	0	0	0
6	9.8	10	NA	92	293	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.2	NA	3.3	NA	84	NA	0	0	0
0.4	NA	112	115	106	NA	0	0	1
0.1	9.3	1.8	53	105	NA	0	0	1
0.2	9.6	1.7	28	106	NA	0	0	1
0.1	9.6	NA	23	107	NA	0	0	1
NA	9.5	NA	21	105	NA	0	0	1
NA	9.1	NA	24	108	NA	0	0	0
NA	9.3	2	25	104	NA	0	0	0
NA	9.2	1.7	21	107	NA	0	0	0
0.2	NA	1.9	24	NA	NA	0	0	0
0.2	NA	1.9	23	NA	NA	0	0	0
0.3	NA	2.3	22	103	NA	0	0	0
0.3	NA	1.9	19	NA	NA	0	0	0
NA	NA	NA	21	NA	NA	0	0	0
NA	9.6	NA	21	NA	NA	0	0	1
0.3	9.8	2.3	20	105	NA	0	0	0
30.5	9.2	3.3	NA	92	147	0	0	1
NA	NA	9.1	NA	NA	NA	0	1	1
0.4	NA	5.5	NA	105	NA	0	0	1
0.4	NA	5.8	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	3.5	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	104	NA	0	0	1
NA	8.3	NA	NA	106	NA	0	0	1
NA	NA	1.4	NA	NA	NA	0	0	1
7.8	8.8	4.3	NA	102	NA	0	1	1
5.2	NA	NA	NA	NA	NA	0	1	1
1.2	8.8	4.1	NA	100	NA	0	1	1
3.1	9	2.4	NA	106	162	0	0	0
NA	8.7	NA	NA	106	NA	1	0	1
1.3	8.3	NA	NA	97	NA	0	0	1
13	8.3	3.6	NA	107	NA	0	0	1
7.2	9.8	2	NA	105	NA	0	0	1
1.4	10.1	NA	NA	99	NA	0	0	0
1.1	10.4	NA	NA	99	NA	0	0	0
NA	10	1.1	NA	101	NA	0	0	1
0.6	9.6	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.5	9.7	NA	NA	100	NA	0	0	1
0.6	10.3	52	NA	102	NA	0	0	1
0.4	NA	17	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.5	NA	9.2	NA	NA	NA	0	1	1
1	NA	8.5	NA	NA	NA	0	1	1
11.1	8.6	NA	NA	100	NA	1	0	1
2.4	7.3	NA	NA	100	NA	0	1	1
1.2	9.3	9	NA	98	NA	0	1	1
0.6	NA	6.2	NA	NA	NA	0	1	1
1.4	7.9	10	NA	101	NA	0	0	1
0.8	9.4	1.8	NA	104	NA	1	0	0
3.5	8.5	3.1	NA	102	NA	0	0	1
0.7	8.1	1.9	NA	103	120	0	0	0
0.6	NA	NA	NA	100	NA	0	0	0
0.3	8.1	NA	NA	103	NA	0	0	1
0.7	8.1	NA	NA	104	NA	0	0	1
0.5	NA	4.3	NA	99	NA	0	0	0
NA	NA	NA	8.5	105	NA	0	0	0
7.6	8.6	4.1	NA	96	NA	0	0	1
0.7	NA	NA	NA	102	NA	0	0	0
0.9	NA	3.8	NA	99	NA	0	0	0
0.3	8.9	2	NA	101	NA	0	0	0
1.3	NA	3.4	NA	108	NA	1	0	1
1.6	7.4	4.9	NA	102	NA	1	0	0
0.3	NA	NA	NA	99	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	97	NA	0	0	1
0.9	NA	NA	NA	98	NA	0	0	1
1.6	NA	NA	NA	98	NA	0	0	1
10.1	9.2	17	78	98	NA	1	1	1
4	9.3	2.8	NA	105	157	1	0	0
4.2	8.9	NA	NA	107	NA	1	0	0
1.4	9.1	1.6	NA	98	151	0	0	0
0.4	9.5	1.4	NA	107	181	0	0	0
6.2	8.3	12	NA	105	NA	0	0	1
0.5	8.8	2.9	NA	104	NA	0	0	0
4.7	7.8	NA	NA	108	NA	1	0	1
4.7	7.7	NA	NA	108	NA	1	0	1
1.3	7.3	NA	NA	115	NA	0	0	1
2.4	9.2	3	NA	105	NA	0	0	0
4.1	9.7	1.4	20	101	NA	0	0	0
17.1	NA	NA	NA	104	NA	0	0	1
0.4	8.6	2.5	1249	101	NA	0	0	0
1.2	9.4	2	NA	101	201	0	0	0
0.2	8.3	15	197	112	NA	0	0	0
2.3	8.5	6.1	NA	104	NA	0	0	1
NA	NA	12	NA	NA	NA	0	0	1
0.2	9	NA	NA	101	NA	0	0	1
0.2	NA	NA	NA	103	NA	0	0	1
0.2	NA	NA	NA	105	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	103	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	8.8	NA	NA	108	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	9.1	NA	NA	106	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
2.1	NA	NA	NA	NA	NA	0	0	1
1.1	8.7	NA	NA	98	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	8.6	NA	NA	105	NA	0	0	1
0.2	NA	NA	NA	107	NA	0	0	0
0.2	NA	NA	NA	104	NA	0	0	0
0.5	8.9	2	NA	102	NA	0	0	0
0.2	9.2	NA	13	93	NA	0	0	0
4.2	NA	NA	NA	110	NA	0	0	1
10	9.3	5.9	NA	102	NA	0	0	1
NA	9	NA	54	102	NA	0	0	0
0.5	8.3	NA	15	108	NA	1	0	1
0.5	8.9	NA	NA	100	NA	1	0	0
0.3	NA	NA	NA	101	NA	1	0	0
9.8	8.5	6.4	NA	105	NA	1	0	1
0.4	8.6	71	NA	104	NA	0	0	1
0.5	NA	71	NA	NA	NA	0	0	0
0.4	NA	NA	NA	98	NA	0	0	0
0.7	8.5	NA	NA	101	NA	0	0	1
5.1	8.1	2.7	NA	105	100	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.4	8.6	2.6	NA	104	NA	0	0	1
9.6	9.4	6.5	NA	100	NA	0	0	0
2	8.6	3.5	NA	104	NA	1	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.4	9	NA	NA	95	NA	0	0	1
0.6	NA	NA	NA	102	NA	0	0	0
NA	NA	NA	NA	98	NA	0	0	1
4.9	7.7	8.1	NA	108	NA	0	0	1
0.4	8	3.8	138	103	NA	0	0	0
5.1	8.2	4.5	NA	93	134	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	108	NA	0	0	0
20.4	NA	25	NA	94	NA	0	0	1
2.6	NA	17	NA	101	NA	0	0	0
1.5	9	6.5	NA	98	261	0	0	1
NA	NA	NA	NA	101	NA	0	0	0
1.8	9.1	1.1	NA	103	114	0	0	0
1.1	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	1	0	0
1.8	NA	NA	NA	106	NA	0	0	0
1.9	NA	2.6	NA	102	NA	0	0	0
0.7	8.6	1.9	NA	107	NA	0	0	0
3.7	8.8	1.9	NA	102	NA	1	1	1
0.4	NA	NA	NA	103	NA	1	0	0
0.3	NA	NA	NA	NA	NA	0	1	0
0.3	NA	NA	NA	NA	NA	0	0	1
0.6	NA	1.7	NA	NA	NA	0	1	0
0.6	NA	1.9	NA	NA	NA	1	0	1
3.4	8.3	7	NA	107	139	0	0	0
1.3	8.9	2.1	NA	102	112	0	0	0
0.8	9.1	2.4	NA	101	205	0	0	0
11.4	NA	4.6	NA	104	NA	0	0	0
3	8.4	119	NA	114	NA	0	0	1
1.1	9.9	2	NA	103	NA	0	0	0
2.5	8.5	11	NA	103	106	0	0	1
18.7	8.5	26	NA	97	NA	1	1	1
16.4	NA	NA	NA	107	NA	0	0	1
0.2	NA	NA	NA	102	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.6	9.5	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	1	0	0
0.3	NA	NA	NA	NA	NA	1	0	0
0.4	NA	1	NA	NA	NA	1	0	0
0.3	11.4	3.6	57	96	NA	0	0	0
NA	8.9	33	2664	102	NA	0	0	1
NA	NA	508	NA	107	NA	0	0	0
1	8.1	1.3	NA	106	NA	1	0	1
0.3	9.2	NA	NA	96	NA	0	0	1
0.4	NA	5.3	NA	108	93	0	0	1
NA	8.5	4.4	15	111	156	0	0	1
0.4	9.7	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	NA	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.9	9.1	NA	NA	99	NA	0	0	1
0.5	8.8	NA	NA	103	NA	0	0	1
0.7	8.7	NA	NA	106	NA	0	0	1
0.6	8.7	NA	NA	101	NA	0	0	1
0.6	8.1	NA	NA	100	NA	0	0	1
1	8.8	NA	NA	88	NA	0	0	1
0.5	NA	2	NA	NA	NA	0	0	0
0.6	10.2	NA	NA	106	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.4	10.4	NA	NA	103	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	107	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
1.7	9	1960	NA	107	NA	0	0	1
1.2	8.8	3.9	NA	97	136	0	0	0
9.7	8.7	NA	NA	107	NA	0	0	1
3.2	8.9	18	NA	108	NA	0	0	1
18.5	9.3	352	NA	99	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
5.8	9.3	3.1	NA	100	257	0	0	0
0.3	8.6	2.4	512	101	NA	0	0	1
14	9.1	12	NA	104	206	0	0	1
0.6	NA	5.1	NA	104	NA	0	0	0
22	8.3	7.3	NA	99	NA	0	0	0
0.4	9.1	1.7	NA	112	NA	0	0	0
2.9	7.9	9.4	NA	102	138	0	0	1
1.6	9.4	4.1	NA	105	104	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
11.9	NA	NA	NA	96	NA	1	0	0
0.2	NA	1.7	11	NA	NA	0	0	0
0.3	9.6	3.6	NA	106	NA	0	0	0
0.4	9.8	2.5	NA	100	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	9.4	3.2	NA	103	123	0	0	0
0.3	NA	4.7	NA	102	NA	0	0	0
NA	NA	2.9	NA	103	NA	0	0	1
1.8	8.9	NA	NA	104	NA	0	0	0
1.4	NA	NA	NA	106	NA	0	0	0
25.7	8.4	NA	NA	105	NA	0	0	0
0.6	9	2.6	NA	101	199	0	0	0
1.2	7.4	7.8	NA	105	NA	0	0	1
0.7	8	NA	NA	103	NA	1	0	0
NA	7.8	1.4	NA	107	NA	0	0	0
1.3	9.3	3.8	NA	104	129	0	0	1
1.9	8.8	6.4	NA	103	169	0	0	0
NA	NA	NA	67	NA	NA	0	0	0
27.2	10	5.1	NA	84	306	0	0	1
9.9	9.4	12	NA	99	NA	0	0	1
2.1	9	6.3	NA	101	183	0	0	1
1.7	9	1.6	798	102	NA	0	0	1
2.8	9.2	NA	NA	102	NA	0	1	1
2.6	9.1	NA	NA	102	NA	0	1	1
4.8	8.3	2.2	NA	103	428	1	0	1
5	8.4	2.1	NA	100	NA	1	0	0
0.7	NA	1.4	NA	NA	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
0.3	NA	6.5	NA	105	NA	0	1	1
1.4	9.2	8.5	NA	102	131	0	0	0
0.3	7.8	NA	NA	103	NA	1	0	1
0.3	7.7	1.2	113	102	NA	0	0	1
2.7	8.6	4.7	NA	99	207	0	0	0
NA	NA	1.3	NA	99	NA	0	0	0
0.3	8.2	2.5	NA	98	NA	0	0	0
0.4	NA	NA	NA	100	NA	0	0	0
0.3	NA	1.1	NA	100	NA	0	0	0
0.3	NA	NA	722	101	NA	0	0	0
1.9	9.5	NA	NA	108	NA	1	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
NA	NA	2.3	NA	100	NA	0	0	0
1.5	9.2	1.4	NA	100	138	1	0	0
1.7	8.7	NA	NA	98	NA	0	0	0
0.6	9.7	2.8	12	105	215	0	0	0
3.3	9.2	2.3	NA	95	NA	0	0	1
0.5	NA	2.1	NA	103	NA	0	0	1
0.6	6.6	1.8	NA	110	NA	0	0	0
4.2	8.7	3	NA	100	NA	1	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.5	NA	5.6	NA	102	NA	0	0	1
19.7	NA	NA	NA	102	NA	0	1	0
5.9	8.6	7.3	NA	87	NA	0	0	1
0.7	8	2.3	NA	99	NA	0	0	0
1.5	8.6	7.5	NA	96	165	0	0	1
1.4	NA	NA	NA	97	NA	0	0	1
2.6	8.1	6.8	NA	97	102	0	0	0
18.4	9.3	134	NA	99	NA	1	1	1
6.3	8.9	10	NA	96	NA	0	0	1
4.2	8.2	5	NA	98	NA	0	0	0
0.4	9.2	1.4	NA	99	NA	0	0	1
0.4	10.6	NA	NA	98	NA	0	0	1
0.3	NA	NA	NA	99	NA	1	0	1
0.4	NA	NA	NA	NA	NA	1	0	0
24	9.2	5.6	NA	99	NA	0	0	0
19.4	8	5.6	NA	102	NA	0	0	0
3.3	NA	4.8	NA	99	NA	0	0	0
0.6	NA	2.1	NA	97	NA	0	0	0
0.5	NA	3.6	NA	NA	NA	0	0	0
0.5	9.1	NA	NA	94	NA	0	0	0
0.4	8.9	NA	NA	104	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.8	NA	NA	NA	NA	NA	0	0	0
9.7	8.6	2.3	NA	104	NA	1	0	1
0.5	8.1	NA	NA	101	NA	0	0	1
0.2	8.9	NA	NA	100	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	9.2	NA	NA	99	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.2	8.1	NA	NA	97	NA	0	0	1
0.2	7.6	NA	NA	98	NA	0	0	1
0.3	NA	NA	NA	99	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	0
2.8	9.1	2	NA	105	125	0	0	1
NA	8.9	4.3	18	111	NA	0	0	1
6.2	9.3	3.8	NA	96	NA	1	0	1
0.3	9	NA	NA	101	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	0
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	102	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	NA	NA	0	0	1
0.8	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
1.6	8.5	12	NA	108	91	0	0	0
0.6	9.6	NA	NA	99	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	1
21.3	9.6	48	NA	102	NA	0	0	1
21.8	10	NA	NA	102	NA	0	1	1
1	9.7	NA	NA	103	NA	0	0	0
0.2	9.2	NA	NA	106	NA	0	0	0
0.3	9.6	NA	NA	106	191	0	0	0
0.2	8.9	NA	NA	108	NA	0	0	0
0.2	9.3	NA	NA	105	NA	0	0	0
0.2	8.8	NA	NA	107	NA	0	0	0
2.3	7.5	1.3	NA	105	NA	0	0	0
0.3	8.4	1.5	NA	108	101	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
1.1	NA	1.7	NA	NA	NA	1	0	0
1.1	8	9.5	NA	105	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	102	NA	1	0	1
0.2	9.2	NA	NA	105	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	103	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
0.9	NA	NA	NA	NA	NA	0	0	1
13.6	8.6	NA	NA	100	NA	0	0	1
3.3	9.3	7.8	NA	103	148	0	0	0
1.6	9.3	5.1	NA	99	199	0	0	0
10.8	7.8	2.1	NA	109	NA	1	0	1
0.1	7.7	3	NA	99	109	0	0	0
0.2	8.3	3.8	NA	95	NA	1	0	1
0.9	9.1	1.3	NA	96	NA	0	0	1
0.6	8.9	NA	NA	92	NA	1	1	1
13.2	7.1	10	NA	111	NA	1	0	1
0.9	8.6	1435	NA	102	NA	0	0	1
2.4	7.9	4.1	NA	106	NA	0	0	0
5.1	7.6	2.7	183	112	NA	0	0	1
3	7.6	NA	NA	106	NA	0	0	1
0.3	NA	NA	NA	102	NA	0	0	0
0.7	NA	1	NA	103	NA	0	0	1
1.5	8.5	4.7	NA	103	137	0	0	1
0.4	9.5	1.4	NA	98	202	0	0	0
0.6	NA	1.7	NA	100	NA	0	0	0
0.6	NA	1.7	NA	100	NA	0	0	0
0.2	8.9	NA	NA	114	NA	0	0	0
0.6	9.2	5	NA	103	NA	0	0	1
26.4	NA	NA	NA	93	NA	1	0	0
1.5	8.9	5.6	NA	102	144	0	0	0
0.9	NA	1.9	NA	NA	NA	0	0	0
2	9	3.1	NA	107	170	0	0	0
0.5	9.5	23	NA	104	NA	0	0	1
0.8	9	13	NA	102	NA	0	0	1
0.4	10.2	NA	NA	97	NA	0	0	1
0.5	10.8	NA	NA	94	NA	0	0	1
5.6	9.9	NA	NA	92	NA	0	0	1
1.3	8.6	1.9	NA	105	158	0	0	0
0.7	8.9	2.2	NA	101	NA	0	0	0
22.6	NA	2.7	NA	99	NA	1	0	1
4.9	NA	8.1	NA	97	NA	1	0	1
0.6	8.7	51	NA	103	NA	0	0	1
0.3	NA	NA	NA	104	NA	1	0	1
3.4	8.4	5.2	40	101	NA	0	0	1
2.1	10.2	NA	NA	98	NA	0	1	1
1.4	10.2	NA	NA	99	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.3	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
7.6	NA	NA	NA	100	NA	0	1	1
6.7	7.4	NA	NA	97	NA	0	1	1
12.2	9.6	7.4	NA	119	149	0	0	0
1	8.7	1.3	NA	106	NA	0	0	0
2.8	NA	NA	NA	106	NA	0	0	1
0.5	NA	NA	NA	104	NA	1	1	0
0.4	NA	NA	NA	107	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	1	0
0.5	NA	NA	NA	105	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.5	NA	1	NA	NA	NA	0	0	0
9.8	8	NA	NA	108	NA	0	0	1
0.6	9.6	2.1	NA	104	NA	0	0	0
1.9	8.9	1.1	NA	105	NA	0	0	0
NA	NA	3.7	NA	NA	NA	0	0	0
NA	NA	1.4	NA	NA	NA	0	0	0
1	9.9	4.1	NA	102	108	0	0	0
2	8	4.6	NA	107	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
1	NA	NA	NA	105	NA	0	0	1
0.4	8.5	5.7	NA	102	NA	0	0	0
14.7	8.6	3.6	NA	102	109	0	0	1
9.8	9.2	2.3	NA	96	NA	0	0	1
0.6	9.4	NA	NA	99	NA	0	0	1
0.4	7.5	NA	NA	97	NA	0	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.3	10	1.3	7.7	96	NA	0	0	0
0.3	NA	1.1	NA	93	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
NA	9.4	NA	NA	93	NA	0	1	0
0.2	9.3	NA	NA	94	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.2	10.1	NA	NA	93	NA	0	1	0
0.4	9	NA	NA	90	NA	0	1	1
0.3	NA	NA	NA	92	NA	0	0	1
0.2	9.8	NA	NA	93	NA	0	1	1
0.3	NA	NA	NA	95	NA	0	1	1
0.4	9.5	NA	NA	93	NA	0	1	1
0.4	9.4	NA	NA	89	NA	0	1	1
0.7	NA	2.8	NA	NA	NA	0	0	0
3.8	9	3.3	NA	99	NA	0	0	0
22.5	8.6	2.6	NA	105	NA	1	0	1
1.9	10.1	NA	NA	101	NA	0	1	1
0.5	10.9	NA	NA	103	NA	0	1	0
0.4	9.9	NA	NA	104	NA	0	1	1
NA	10.1	NA	NA	104	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
NA	NA	NA	NA	NA	NA	0	1	1
0.3	9.6	NA	NA	106	NA	0	1	1
0.5	10.2	NA	NA	104	NA	0	1	0
NA	9.2	NA	NA	106	NA	0	1	0
0.4	9.4	NA	NA	105	NA	0	1	0
0.5	9.1	NA	NA	104	NA	0	0	0
0.8	9.1	NA	NA	101	NA	0	1	0
0.5	9.4	NA	NA	104	NA	0	1	0
1.1	7.9	2.8	NA	96	NA	0	0	0
1.8	NA	NA	NA	91	NA	0	0	1
13.4	8.7	5.6	NA	90	27	0	0	1
3.2	8	3.5	NA	101	NA	0	0	0
1.3	9.6	5.1	NA	103	123	0	0	0
1.1	NA	6.6	NA	99	222	0	0	1
1	NA	6.4	NA	92	222	0	0	1
NA	13.5	NA	NA	101	NA	0	0	0
NA	NA	NA	15	NA	NA	0	0	1
0.8	10.1	NA	NA	104	NA	0	0	0
NA	NA	5.4	NA	NA	NA	0	0	1
0.3	9.1	12	NA	107	NA	0	0	0
0.4	8	5	NA	108	NA	0	0	0
0.3	9.6	NA	NA	92	119	0	0	1
0.5	NA	1.3	NA	NA	NA	0	0	0
8.4	8.4	NA	NA	102	NA	1	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
17.9	7.9	3.7	NA	103	NA	1	0	1
1.1	9.8	NA	NA	100	104	0	0	0
0.8	10.1	NA	NA	103	NA	0	0	0
NA	NA	2.8	NA	NA	NA	0	0	0
1.1	NA	1.2	NA	98	NA	0	0	0
0.6	NA	NA	NA	NA	NA	0	0	0
0.6	10.8	NA	NA	102	NA	0	0	0
0.5	NA	NA	NA	106	NA	0	0	0
0.6	9.8	NA	NA	106	NA	0	0	0
0.4	9.7	NA	NA	101	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	1
0.4	9.2	4.4	NA	99	200	0	0	1
0.5	8	2.4	NA	106	NA	0	0	1
0.4	9.4	30	NA	105	162	0	0	0
0.4	9.1	NA	NA	104	NA	0	0	0
7.3	8.1	4.5	NA	104	NA	0	0	1
2.6	8.4	5.1	NA	105	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	1	0
NA	NA	2.5	11	106	NA	0	0	0
33.1	8.3	5.4	NA	96	81	0	0	1
1.5	NA	2.6	NA	101	NA	1	0	0
0.6	NA	NA	NA	103	NA	0	1	0
0.7	9.6	NA	NA	96	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
0.6	9	NA	NA	103	NA	0	1	0
0.4	9	NA	NA	103	NA	0	1	0
0.5	8.8	NA	NA	105	NA	0	1	0
0.3	8.5	NA	NA	105	136	0	1	0
1.9	NA	1.6	NA	99	NA	0	0	0
2.3	9.3	1.9	NA	99	103	0	0	0
2.4	8.2	207	NA	86	NA	0	0	1
24	NA	NA	NA	NA	NA	1	0	0
2.2	NA	NA	NA	NA	NA	0	0	0
NA	8.3	3.2	NA	107	NA	0	0	0
10.6	8.9	NA	NA	101	NA	1	0	0
13.4	9.5	1.9	NA	97	NA	1	0	1
0.8	10.2	NA	NA	92	NA	0	0	0
0.5	10	NA	NA	101	NA	0	0	0
0.5	9.7	NA	NA	104	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.2	NA	NA	NA	103	NA	0	0	0
0.2	9.2	NA	NA	102	NA	0	0	0
0.4	9.1	NA	NA	103	170	0	0	0
0.2	8.1	1.7	NA	110	NA	0	0	1
0.3	8.9	1.9	NA	107	NA	1	0	1
0.5	NA	NA	NA	108	NA	1	0	0
0.5	9.9	NA	NA	102	NA	0	0	0
0.5	NA	1.9	NA	103	NA	0	0	0
0.6	9	2.7	NA	108	157	0	0	1
NA	8.3	6.6	NA	106	NA	1	0	1
0.6	NA	18	NA	110	NA	0	0	0
0.7	NA	NA	6266	97	NA	0	0	0
0.6	10.6	3.8	NA	102	212	0	0	0
2.8	8.4	3.5	NA	107	31	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.8	NA	NA	NA	NA	NA	0	0	0
0.2	8.6	5.3	NA	108	NA	0	0	0
0.8	8	1.1	NA	107	NA	0	0	0
0.3	9.3	5.8	111	112	NA	0	0	0
1.8	9	NA	NA	101	NA	0	0	1
0.8	8.9	NA	NA	102	NA	0	0	1
0.2	8.6	NA	NA	106	NA	0	0	0
0.4	8.7	11	60	93	NA	0	0	1
0.2	NA	2	138	103	NA	0	0	0
31.9	10	NA	NA	97	NA	0	0	0
NA	NA	4.8	NA	98	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	1	0
2.5	7.9	3.4	NA	97	NA	0	0	1
4.5	NA	3.3	NA	100	NA	1	0	1
0.4	9.8	NA	NA	99	NA	0	0	0
0.9	NA	38	NA	104	NA	0	1	0
0.4	NA	NA	NA	NA	NA	0	1	0
0.6	NA	NA	NA	NA	NA	0	1	0
0.6	NA	NA	NA	NA	NA	0	1	0
0.8	NA	NA	NA	NA	NA	0	0	0
0.9	NA	NA	NA	NA	NA	0	1	0
0.6	NA	NA	NA	NA	NA	0	1	0
1	NA	NA	NA	NA	NA	0	0	0
0.6	8.6	9.5	NA	109	172	0	0	1
2	8.9	7.7	NA	97	NA	0	0	1
NA	NA	4.5	NA	NA	NA	1	0	0
25.1	8.7	1.1	NA	103	76	0	0	0
0.3	NA	1.4	NA	105	NA	0	0	0
18.8	8.1	3.2	NA	100	80	1	0	1
7.5	8.7	5.5	NA	95	NA	0	0	0
1.2	9.2	1.9	NA	98	NA	1	0	1
0.6	8.7	NA	NA	97	NA	0	0	1
0.5	8.8	NA	NA	92	NA	0	0	1
0.3	10	NA	NA	103	NA	0	0	1
0.2	9.6	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.6	9.1	NA	NA	101	NA	0	0	1
1.3	9.2	NA	NA	103	NA	0	0	1
1	9.2	NA	NA	101	NA	1	0	1
1.1	9.2	NA	NA	101	NA	0	0	1
2.3	8.6	NA	NA	99	NA	0	0	1
7.9	NA	4.5	NA	103	138	0	0	0
0.3	NA	NA	NA	102	NA	0	0	0
0.4	NA	3.6	NA	105	NA	0	0	0
5.3	8.1	6.2	NA	106	NA	0	0	0
10.2	8.8	18	NA	109	NA	0	0	1
2.9	8.5	18	NA	110	NA	0	0	1
2.3	9	1.6	NA	104	153	0	0	0
0.4	NA	NA	NA	101	NA	0	0	0
6.1	7.7	NA	NA	111	NA	0	0	0
10.5	8.6	2.9	NA	97	185	0	0	0
7.1	8.4	NA	NA	102	NA	0	0	0
2.3	10.2	3.5	275	92	NA	0	0	0
1.4	7.6	3.3	NA	111	NA	0	0	0
1.3	7.8	9.6	NA	91	31	0	0	0
14.8	NA	10	NA	99	65	0	0	0
0.2	10	NA	NA	95	NA	0	0	0
1.4	9.4	3037	NA	114	NA	0	0	1
1.6	9.2	3037	NA	105	NA	0	0	1
60.5	9	NA	NA	101	NA	0	0	1
5.1	8.3	5.3	NA	105	148	0	0	0
6.4	9.4	NA	NA	103	297	1	0	1
0.7	NA	NA	NA	95	NA	0	0	0
0.6	NA	3.4	NA	NA	NA	0	0	0
0.3	9.4	NA	NA	102	75	0	0	0
3.1	8.9	2.1	NA	103	NA	1	1	1
0.3	8.7	NA	NA	106	NA	0	0	1
0.3	9.3	NA	NA	102	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
0.3	NA	NA	NA	NA	NA	0	0	1
0.3	NA	3.6	NA	103	NA	0	0	1
0.3	NA	NA	NA	105	NA	0	0	0
0.3	NA	NA	NA	107	NA	0	0	0
0.2	NA	NA	NA	NA	NA	0	0	0
0.7	8.9	6.3	NA	99	NA	0	0	1
5.2	8.1	NA	NA	108	NA	1	1	1
0.8	NA	NA	NA	100	NA	0	0	1
0.4	NA	NA	NA	102	NA	0	0	0
0.7	NA	NA	NA	98	NA	0	0	1
NA	NA	1.1	19	106	NA	0	0	0
17.5	7.3	3.4	NA	98	71	0	0	0
0.4	NA	NA	NA	103	NA	0	0	0
1.4	NA	1.8	NA	105	NA	0	1	1
13.6	9.7	2.7	NA	107	NA	1	0	1
2.3	NA	NA	NA	108	NA	0	1	1
0.3	NA	1.5	NA	101	NA	0	0	0
18.1	8.7	144	NA	105	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
NA	9.1	NA	NA	103	NA	0	0	1
NA	9.9	NA	NA	106	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	9	NA	NA	106	NA	0	0	0
10.2	8.3	NA	NA	101	NA	0	0	0
8.2	8.2	NA	NA	106	NA	0	0	1
0.9	8.2	NA	NA	99	NA	0	0	1
4.5	9.4	2.4	NA	100	NA	1	0	1
1	7.8	2.2	NA	108	NA	0	0	0
5.8	8.5	3.6	NA	105	NA	0	0	0
0.4	9.6	4.9	NA	100	NA	0	0	0
0.3	10	5.4	NA	103	NA	0	0	0
0.2	NA	6.1	NA	105	NA	0	0	0
0.1	9.1	8.1	NA	103	NA	0	0	0
0.3	10.2	7.8	NA	102	NA	0	0	0
0.4	10.1	7	NA	103	NA	0	0	0
0.6	7.6	2.4	NA	113	NA	0	0	1
0.9	NA	2.1	NA	NA	NA	0	0	1
0.9	NA	NA	NA	103	NA	0	0	0
0.5	NA	NA	NA	102	NA	0	0	1
1.2	NA	NA	NA	NA	NA	0	1	0
0.5	7.9	3	NA	107	NA	0	1	0
11.3	9.5	3.5	NA	95	NA	0	0	0
0.3	NA	3.7	NA	102	NA	0	0	1
NA	8.4	NA	NA	98	NA	0	0	1
0.3	NA	NA	NA	103	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	1
0.2	9.4	NA	NA	103	NA	0	0	1
0.2	9.5	NA	NA	104	NA	0	0	1
0.2	NA	NA	NA	NA	NA	0	0	1
1.6	9.3	6	NA	101	73	0	0	1
0.4	8.7	2.9	NA	106	NA	1	0	0
0.6	9.5	NA	NA	103	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.5	NA	3.1	NA	NA	NA	0	0	1
0.5	NA	2.9	NA	NA	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.3	9	3.3	501	96	NA	0	0	0
0.5	9.9	4.8	NA	99	194	0	0	0
0.4	NA	1.4	NA	103	NA	0	0	1
2	8.9	NA	15	104	NA	0	0	0
2.4	8.8	1.5	NA	108	129	0	0	0
NA	NA	1.8	101	107	NA	0	0	0
21	8.2	NA	NA	105	NA	1	0	1
0.4	8.1	NA	NA	100	NA	0	0	0
2.7	8.5	NA	NA	98	NA	1	0	1
6.1	8.7	3.6	NA	103	NA	0	0	0
0.7	NA	NA	NA	NA	NA	0	0	1
1.9	NA	NA	NA	92	NA	0	0	1
1.8	NA	2.7	NA	102	NA	0	0	0
0.4	NA	3.8	NA	103	NA	0	0	1
2.6	8.7	3.6	NA	97	NA	0	0	0
0.3	8.5	NA	NA	105	NA	0	0	0
NA	9.5	1.1	NA	NA	NA	0	0	0
9.6	NA	2.1	NA	107	NA	1	0	1
0.5	9.2	NA	NA	102	NA	0	0	1
0.3	9.1	NA	NA	103	NA	0	0	1
0.3	9.1	NA	NA	103	NA	0	0	1
0.5	8.6	NA	NA	106	NA	0	0	1
0.3	8.7	NA	NA	106	NA	0	0	1
0.8	NA	2.8	NA	NA	NA	0	0	1
2.5	8.6	5.5	NA	95	189	0	0	0
0.4	NA	3.1	NA	102	NA	0	0	0
0.8	NA	4.9	NA	98	NA	0	0	1
0.5	9.7	NA	NA	100	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.6	NA	NA	NA	NA	NA	0	1	1
0.5	NA	NA	NA	NA	NA	0	1	1
0.9	NA	NA	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
0.8	NA	NA	NA	NA	NA	0	0	1
2.4	NA	NA	NA	NA	NA	0	1	1
0.6	8.1	3.5	NA	105	109	0	0	0
2.1	7.5	7.3	NA	111	NA	0	0	0
9	8.1	3.7	NA	96	NA	0	0	1
3.1	NA	NA	NA	NA	NA	0	0	1
0.8	9.2	3.4	NA	102	173	0	0	1
0.7	8.6	4	NA	91	120	0	0	0
8.8	9	7.6	NA	101	NA	0	0	1
0.2	NA	1	NA	100	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
22	7.4	4	NA	101	NA	0	0	0
29.1	8.5	4	NA	101	88	0	0	0
21	8.8	12	NA	97	NA	0	0	1
4.9	8.6	2.7	NA	105	NA	1	0	1
0.5	8.8	NA	NA	101	NA	0	0	1
0.4	8.2	3.5	NA	96	NA	0	0	1
0.4	NA	NA	NA	103	NA	0	0	1
0.2	8.8	NA	NA	102	NA	0	0	1
NA	NA	NA	NA	98	NA	0	0	1
0.2	8.5	NA	NA	100	NA	0	1	1
0.3	NA	NA	NA	96	NA	0	1	1
0.4	NA	NA	NA	98	NA	0	0	1
0.5	NA	7.5	NA	98	NA	0	0	1
0.4	NA	NA	NA	95	NA	0	0	1
NA	9.7	NA	56	104	NA	0	0	1
4.1	9.3	36	NA	99	NA	0	0	1
1.5	9.2	6.2	NA	103	152	0	0	0
10.1	8.3	20	NA	95	154	0	0	0
10	9	NA	NA	93	NA	0	0	1
16.2	9.2	NA	NA	104	NA	0	0	0
18	8.6	1.5	NA	103	NA	0	0	1
18.2	8.9	1.5	NA	90	NA	0	1	1
4.6	9.1	5.9	NA	108	NA	0	0	0
0.5	NA	5.1	NA	NA	NA	0	0	0
0.1	9.8	NA	NA	104	NA	0	0	0
5.9	9.1	9	NA	88	68	0	0	0
3.3	9.1	NA	NA	109	NA	0	0	0
2.7	9.2	1.8	NA	107	NA	1	1	0
0.3	8.9	NA	NA	104	NA	0	1	0
NA	NA	NA	NA	NA	NA	0	1	0
20.9	NA	7	NA	97	NA	0	0	1
0.6	NA	5.1	NA	NA	NA	1	0	1
0.5	NA	NA	NA	NA	NA	0	0	1
0.4	9.3	NA	NA	102	NA	0	0	1
0.4	9.6	NA	NA	105	NA	0	0	1
0.5	9.6	5.5	NA	109	186	0	0	0
0.3	9.2	NA	NA	NA	NA	0	0	1
0.9	9.4	5	NA	101	NA	0	0	0
0.4	8.7	2	NA	102	NA	0	0	0
0.8	8.8	2.2	NA	102	104	0	0	0
0.4	9.9	3.5	NA	102	NA	1	0	0
0.5	9.5	1.8	NA	105	154	0	0	0
0.3	NA	NA	NA	NA	NA	0	0	0
1.1	8.5	1.5	NA	94	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
2.7	8	1.9	NA	107	145	0	0	0
2	9.8	3.4	NA	102	162	0	0	0
0.9	8.6	3.9	NA	106	NA	1	0	1
3.7	NA	5.4	NA	NA	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.7	NA	NA	NA	101	NA	0	0	1
0.4	NA	NA	NA	NA	NA	0	0	1
0.4	8.9	NA	NA	105	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
12.2	8.2	NA	NA	94	NA	0	0	0
0.3	8.4	4.5	NA	97	NA	0	0	1
0.5	10	NA	39	100	334	0	0	0
1.2	8.6	4.6	NA	102	136	0	0	0
2.4	NA	3.1	NA	104	NA	0	0	1
2	8.5	9.2	425	98	NA	0	0	1
4.1	NA	7.9	707	94	NA	0	0	1
11.5	9.2	NA	NA	99	NA	0	0	1
14.9	NA	20	NA	104	NA	1	0	1
0.7	9.4	NA	NA	102	NA	0	1	1
0.3	9.6	NA	NA	103	NA	0	1	1
NA	9.5	NA	NA	100	NA	0	1	1
0.3	9.3	NA	NA	103	NA	0	0	1
1.3	NA	3.8	NA	100	NA	0	0	0
3.6	8.7	8.4	NA	94	101	0	0	0
22.9	9.7	5.3	NA	93	NA	1	0	1
1.5	NA	2.8	NA	95	NA	0	0	1
0.6	NA	NA	NA	104	NA	0	0	1
0.5	NA	NA	NA	100	NA	0	0	1
0.4	NA	4.1	NA	97	NA	0	0	1
0.4	NA	NA	NA	98	NA	0	0	1
0.7	8.5	2.5	NA	102	NA	0	0	1
7.6	8.2	1.1	NA	104	NA	1	0	1
19.9	NA	2.3	NA	102	NA	1	1	1
0.9	NA	NA	NA	105	NA	0	0	1
0.6	NA	NA	NA	NA	NA	0	0	1
0.4	9.4	NA	NA	101	NA	0	1	1
0.4	9.5	NA	NA	103	NA	0	0	0
0.5	8.7	NA	NA	105	NA	0	0	0
0.4	9	NA	NA	102	NA	0	0	1
0.3	8.1	NA	NA	104	NA	0	0	1
9.7	NA	4.7	NA	101	NA	1	0	1
0.5	NA	7	NA	101	NA	0	0	0
4	NA	5.8	NA	NA	273	0	1	1
1.2	NA	3.2	NA	NA	NA	0	1	1
0.4	NA	NA	NA	NA	NA	0	1	1
NA	9	NA	6.5	106	NA	0	0	0
6.1	7.5	2.1	NA	102	NA	1	0	1
25	9	NA	NA	99	NA	1	0	1
0.4	8.5	1.9	NA	106	NA	0	0	1
5.4	8.7	1.6	NA	103	NA	1	0	0
1.1	NA	NA	NA	95	NA	0	0	0
0.7	8.5	NA	NA	102	NA	0	0	0
0.4	9.9	2.6	NA	95	NA	0	0	0
0.4	NA	NA	NA	NA	NA	0	0	0
0.3	NA	NA	NA	95	NA	0	0	1
0.4	NA	NA	NA	101	NA	0	0	0
7.5	7.9	1.7	NA	105	NA	0	0	0
NA	9.6	NA	9.8	105	NA	0	0	0
1	8.6	NA	NA	102	NA	0	0	0
NA	8.7	NA	NA	95	NA	0	0	1
NA	NA	NA	NA	NA	NA	0	0	0
0.3	10.1	NA	NA	107	NA	0	0	0
NA	NA	NA	NA	NA	NA	0	0	0
1.2	8.2	11	NA	95	88	0	0	0
0.7	NA	1.8	NA	105	NA	0	0	0
0.5	8.7	NA	NA	103	NA	0	0	0
2.6	6.6	2.2	NA	106	NA	0	0	0
1.8	9.2	6.7	NA	105	152	0	0	0
13.9	NA	NA	NA	103	NA	1	0	1
2.8	NA	NA	NA	103	NA	0	0	1
29.5	7.7	7.5	NA	96	NA	1	0	1
0.3	NA	3.8	NA	99	NA	0	0	0
6	8.4	2	NA	106	NA	0	0	1
5.1	8.5	NA	NA	105	NA	0	0	1
NA	8.5	1	2349	109	NA	0	0	0
0.3	9.4	1.6	NA	100	NA	0	0	0
NA	NA	4.2	NA	NA	NA	0	1	0
18.8	8.6	7.2	NA	99	35	0	0	1
0.5	NA	1.6	NA	103	NA	0	0	0
14.3	8.5	NA	NA	99	NA	1	0	1
0.2	8.3	6.4	NA	104	NA	0	0	1
0.2	NA	NA	NA	101	NA	0	0	1
21.1	10.1	16	NA	90	109	0	0	0
0.6	NA	2.2	NA	107	NA	1	0	1
0.6	9.4	NA	NA	97	NA	0	0	1
13.1	8.8	NA	NA	91	NA	0	0	0
0.7	9.6	NA	NA	103	NA	0	0	0
0.5	8	8.1	NA	89	NA	0	0	1
5.9	8.4	NA	NA	112	NA	0	0	1
1.4	7.7	1.3	NA	110	NA	0	0	1
0.2	9.3	NA	NA	97	NA	0	0	0
0.4	NA	1.1	NA	99	NA	0	1	0
NA	NA	2.4	29	102	NA	0	0	0
3.7	8.2	2.1	19	105	NA	1	0	0
2.2	7.7	5.2	NA	102	64	0	0	1
6.6	9.9	63	NA	114	NA	0	0	1
0.2	9.5	8.7	NA	100	NA	0	0	1
17.2	8.9	1.3	NA	98	NA	0	0	1
0.3	9	NA	NA	100	NA	0	0	0
13	9.3	NA	NA	101	NA	0	0	1
14.4	9.3	45	NA	101	NA	0	0	1
19.6	NA	3.2	NA	99	NA	0	0	0
26.8	NA	3	NA	104	NA	0	0	1
12.6	7.3	3	NA	91	79	0	0	1

From mbressan at arpa.veneto.it  Fri Oct  4 08:32:50 2013
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Fri, 04 Oct 2013 08:32:50 +0200
Subject: [R] storing element number of a list in a column data frame
In-Reply-To: <009701cec04b$0a2b67a0$1e8236e0$@tamu.edu>
References: <524D8224.5080604@arpa.veneto.it>
	<009701cec04b$0a2b67a0$1e8236e0$@tamu.edu>
Message-ID: <524E6112.3020705@arpa.veneto.it>

yes, I like this: a very elegant and neat solution (in my very umble 
opinion)
sometime is so difficult to me to think of a solution in such a simple 
and effective terms: less is more!
thank you
max


Il 03/10/2013 17:12, David Carlson ha scritto:
> Try this
>
>> i=which(!sapply(mytest, is.null))
>> n=do.call(rbind, mytest[i])
>> mydf <- data.frame(i, n)
>> mydf
>    i  n
> 1 1 45
> 2 3 18
> 3 5 99
>
> -------------------------------------
> David L Carlson
> Associate Professor of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Massimo
> Bressan
> Sent: Thursday, October 3, 2013 9:42 AM
> To: r-help at r-project.org
> Subject: [R] storing element number of a list in a column data
> frame
>
> #let's suppose I have a list like this
>
> mytest<-list(45, NULL, 18, NULL, 99)
>
> #to note that this is just an amended example because in fact
>
> #I'm dealing with a long list (more than 400 elements)
>
> #with no evident pattern of the NULL values
>
> #I want to end up with a data frame like the following
>
> data.frame(i=c(1,3,5), n=c(45,18,99))
>
> #i.e. a data frame storing in
>
> #column i the number of corresponding element list
>
> #column n the unique component of that element
>
> #I've been trying with
>
> do.call(rbind, mytest)
>
> #or
>
> do.call(rbind.data.frame, mytest)
>
> #but this approach is not properly achieving the desired result
>
> #now I'm in trouble on how to store each element number of the
> list in
> the first column data frame
>
> #any help for this?
>
> #thanks
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
> code.
>
>


From b.rowlingson at lancaster.ac.uk  Fri Oct  4 10:08:50 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 4 Oct 2013 09:08:50 +0100
Subject: [R] Importing odf file into R
In-Reply-To: <ec3a5a26526d4fc7bca0568ba57e9b5d@EX-1-HT0.lancs.local>
References: <ec3a5a26526d4fc7bca0568ba57e9b5d@EX-1-HT0.lancs.local>
Message-ID: <CANVKczMtrLD2rw_UWhRoJo5CUP-7taUcmiZO+swRRRvKONMUVw@mail.gmail.com>

On Fri, Oct 4, 2013 at 5:57 AM, Peter Maclean <pmaclean2011 at yahoo.com> wrote:
> Anyone aware of a package or technique to import odf data file into R, I will appreciate his/her help.

A quick scan of R-help points me here:

http://www.omegahat.org/ROpenOffice/

Reports of that working (or not) would be appreciated - I've not tried it.

Alternatively, there's python code for reading ODF so you could
interface to that in a number of ways.

Barry


From efisio.solazzo at jrc.ec.europa.eu  Fri Oct  4 10:37:33 2013
From: efisio.solazzo at jrc.ec.europa.eu (efx)
Date: Fri, 4 Oct 2013 01:37:33 -0700 (PDT)
Subject: [R] lattice multi-panel layout
In-Reply-To: <000c01cec091$4b05b820$e1112860$@bigpond.com>
References: <1380806708263-4677500.post@n4.nabble.com>
	<000c01cec091$4b05b820$e1112860$@bigpond.com>
Message-ID: <1380875853458-4677566.post@n4.nabble.com>

Hi, thanks. 
the printing one by one seems the only working solution. I also tried the
grid.arrange function but couldnt output what I am after.

Now the plots are placed in one page but I got the message "error using
packet 1: promise already under evalution: recursive default arguments
reference or earlier problems? "

this error seems to be associated with the panel option I pass to the xyplot
function:
plott[[i]] <- xyplot( 
  bin_avg ~ dist , type=("p")
  ,panel = automap:::autokrige.vgm.panel 
  ,labels = as.character(pop), shift = 0.03 
  ,model = auto_Sph_h[[i]]$var_model
)

if the panel option is commented out the error disappears.

Any further suggestion?

Thanks



--
View this message in context: http://r.789695.n4.nabble.com/lattice-multi-panel-layout-tp4677500p4677566.html
Sent from the R help mailing list archive at Nabble.com.


From stefanML at collocations.de  Fri Oct  4 13:18:21 2013
From: stefanML at collocations.de (Stefan Evert)
Date: Fri, 4 Oct 2013 13:18:21 +0200
Subject: [R] Random Projection
In-Reply-To: <76C496901E46C14899C1D32504ED54778B55E9D446@MAILBOX.gc.cuny.edu>
References: <76C496901E46C14899C1D32504ED54778B55E9D446@MAILBOX.gc.cuny.edu>
Message-ID: <7750F473-5566-4CCD-82B6-B13800035AA7@collocations.de>


On 3 Oct 2013, at 22:39, "Monaghan, David" <DMonaghan at gc.cuny.edu> wrote:

> I was wondering, has anyone has encountered an R package that performs random projection/random mapping?  RP is a procedure that is akin to Principal Components Analysis in that it accomplishes dimensionality reduction, but is far more computationally efficient.  I have been searching for some time, but haven't seen anything on CRAN-r yet.  

The experimental "wordspace" package available from R-Forge has an implementation of RI in the dsm.projection() function.  See

	https://r-forge.r-project.org/R/?group_id=783

for download / installation.

Best,
Stefan


	

From jrkrideau at inbox.com  Fri Oct  4 13:51:30 2013
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 4 Oct 2013 03:51:30 -0800
Subject: [R] Importing odf file into R
In-Reply-To: <1380862652.22798.YahooMailNeo@web121703.mail.ne1.yahoo.com>
Message-ID: <ECC25442F5F.000005ACjrkrideau@inbox.com>

Assuming you want to read in data from an AOO or LO spreadsheet, have a look at the gnumeric package.  I have only used it once or twice but it seems to work well and is quite flexible.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: pmaclean2011 at yahoo.com
> Sent: Thu, 3 Oct 2013 21:57:32 -0700 (PDT)
> To: r-help at r-project.org
> Subject: Re: [R] Importing odf file into R
> 
> Anyone aware of a package or technique to import odf data file into R, I
> will appreciate his/her help.
> 
> Peter Maclean
> Department of Economics
> UDSM
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From pdalgd at gmail.com  Fri Oct  4 14:10:03 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 4 Oct 2013 14:10:03 +0200
Subject: [R] prcomp - surprising structure
In-Reply-To: <CAKyZeBvt46RLRGGZija+4sEcvdE56z9x+sm+7yeNpC8sCD6TnQ@mail.gmail.com>
References: <CAKyZeBtUUbYLYdEEaPD0aaCc8zng=BjBg9TWf3kXS-eWsrGWpw@mail.gmail.com>
	<0008DD19-B983-43A2-92CC-C4B0D8D4801B@gmail.com>
	<CAKyZeBvt46RLRGGZija+4sEcvdE56z9x+sm+7yeNpC8sCD6TnQ@mail.gmail.com>
Message-ID: <0D0B2121-12B9-4314-9593-FF06A75604E1@gmail.com>


On Oct 3, 2013, at 16:30 , Hermann Norpois wrote:

> Thanks for answering.
> 
> I already started hunting. But my first doubt was if I used prcomp correctly (and this is in the moment my most important point). So far as I understood your answer is yes. Is that correct? 

Yes. There are a couple of slightly dubious aspects: The missing value imputation, the scaling could be wrong, and the data are highly discrete, but I don't see how either of those would explain the effect. 

On the off chance that it could be a bug triggered by the large number of columns, you could consider disregarding SNP columns (say) 1:50000 and 250000:300000, rerun the prcomp(), and see if you still get the "columns" in the same positions. 

> 
> I am puzzled by the fact that these "columns" are more or less in the middle of my snp-data.

...or to be precise, there are narrow _ranges_ of SNPs in which the eigenvectors have many extreme coordinate values (positive or negative). I suspect that you need to consider what these ranges represent, both in biological terms and in technological terms. Are they parts of chromosomes, or maybe something to do with the SNP-chip layout?

(Unless you come up with an actual bug, we probably should not continue the discussion on this list.)

-pd

> 
> > However, it could also be a biological effect. Are your ids by any chance from the same pedigree? If so, you might be seeing something like  the effect of a crossover event in a distant ancestor. 
> 
> No there is no such pedigree scheme. Things like this are ruled out by IBD-measurement. (Further, the data is checked by an EIGENSTRAT analysis.)
> 
> > (b) the scaling by sqrt(pi*(1-pi)) implicitly requiring Hardy-Weinberg  equilibrium, so if your data are all 0 or 2 (aa or AA) there will be overdispersion.
> 
> This is a good point. But why do find such effects in the "middle" of my data?
> 
> Thanks
> Hermann
> 
> 
> 
> 
> 2013/10/3 peter dalgaard <pdalgd at gmail.com>
> It's not so obvious to me that this is an artifact. What prcomp() says is that some of the eigenvectors have a lot of "activity" in some relatively narrow ranges of SNPs (on the same chromosome, perhaps?). If something artificial is going on, I could imagine effects not so much of centering columns but maybe one of
> (a) imputing zero for missing values
> (b) the scaling by sqrt(pi*(1-pi)) implicitly requiring Hardy-Weinberg equilibrium, so if your data are all 0 or 2 (aa or AA) there will be overdispersion.
> 
> However, it could also be a biological effect. Are your ids by any chance from the same pedigree? If so, you might be seeing something like the effect of a crossover event in a distant ancestor. (Talk to a geneticist, I just "play one on TV".)
> 
> To investigate further, you could go looking at the individual scores and see who is having extreme values on component 2-4 and then go back and see if there is something peculiar about their SNPs in the "strange" region.
> 
> Of course, you might have stumbled upon a bug in R, but I doubt so.
> 
> Happy hunting!
> 
> -pd
> 
> 
> On Oct 3, 2013, at 11:41 , Hermann Norpois wrote:
> 
> > Hello,
> >
> > I did a pca with over 200000 snps for 340 observations (ids). If I plot the
> > eigenvectors (called rotation in prcomp) 2,3 and 4 (e.g. plot
> > (rotation[,2]) I see a strange "column" in my data (see attachment). I
> > suggest it is an artefact (but of what?).
> >
> > Suggestion:
> > I used prcomp this way: prcomp (mat), where mat is a matrix with the column
> > means already substracted followed by a normalisation procedure (see below
> > for details). Is that okay? Or does prcomp repeat substraction steps?
> >
> > Originally my approach was driven by the idea to compute a covariation
> > matrix followed by the use of eigen, but the covariation matrix was to huge
> > to handle. So I switched to prcomp.
> >
> > As I guess that the "columns" in my plots reflect some artefact production
> > I hope to get some help. For the case that my use of prcomp was not okay,
> > could you please give me instructions how to use it - including with the
> > normalisation procedure that I need to include before doing a pca.
> >
> > Thanks
> > Hermann
> >
> > #
> > # mat: matrix with genotypes coded as 0,1 and 2 (columns); IDs
> > (observations) as rows.
> > #
> > prcomp.snp <- function (mat)
> >  {
> >    m <- ncol (mat)
> >    n <- nrow (mat)
> >    snp.namen <- colnames (mat)
> >    for (i in 1:m)
> >                   {
> >                     # snps in columns
> >                     ui <- mat[,i]
> >                     n <- length (which (!is.na(ui)))
> >                     # see methods Price et al. as correction
> >                     pi <- (1+ sum(ui, na.rm=TRUE))/(2+2*n)
> >
> >                     # substract mean
> >                     ui <- ui - mean (ui, na.rm=TRUE)
> >                     # NAs set to zero
> >                     ui[is.na(ui)] <- 0
> >                     # normalisation of the genotype for each ID
> > important normalisation step
> >                     ui <- ui/ (sqrt (pi*(1-pi)))
> >                     # fill matrix with ui
> >                     mat[,i] <- ui
> >                   }
> >    mat <- prcomp (mat)
> >    return (mat)
> >   }
> > <rotplot.png>______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dulcalma at bigpond.com  Fri Oct  4 14:32:41 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 4 Oct 2013 22:32:41 +1000
Subject: [R] lattice multi-panel layout
In-Reply-To: <1380875853458-4677566.post@n4.nabble.com>
References: <1380806708263-4677500.post@n4.nabble.com>	<000c01cec091$4b05b820$e1112860$@bigpond.com>
	<1380875853458-4677566.post@n4.nabble.com>
Message-ID: <000601cec0fd$d1ff4730$75fdd590$@bigpond.com>

Hi 

I have never used the automap package and your syntax for xyplot does not
seem to be in the correct format for lattice. 

A quick search showed that vgm.panel.xyplot from  gstat package may give you
some ideas. 
It appears that there are some particular adaptations for lattice for
spatial plots and I am not up on them. 

Regards

Duncan

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of efx
Sent: Friday, 4 October 2013 18:38
To: r-help at r-project.org
Subject: Re: [R] lattice multi-panel layout

Hi, thanks. 
the printing one by one seems the only working solution. I also tried the
grid.arrange function but couldnt output what I am after.

Now the plots are placed in one page but I got the message "error using
packet 1: promise already under evalution: recursive default arguments
reference or earlier problems? "

this error seems to be associated with the panel option I pass to the xyplot
function:
plott[[i]] <- xyplot(
  bin_avg ~ dist , type=("p")
  ,panel = automap:::autokrige.vgm.panel
  ,labels = as.character(pop), shift = 0.03
  ,model = auto_Sph_h[[i]]$var_model
)

if the panel option is commented out the error disappears.

Any further suggestion?

Thanks



--
View this message in context:
http://r.789695.n4.nabble.com/lattice-multi-panel-layout-tp4677500p4677566.h
tml
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at lgcgroup.com  Fri Oct  4 15:03:35 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Fri, 4 Oct 2013 14:03:35 +0100
Subject: [R] Counting numbers in R
In-Reply-To: <CA+jRDxAQ=StpYU3V47gUQVo8KjYi0B7dSGOAqieynh456GkVoA@mail.gmail.com>
References: <CA+jRDxAQ=StpYU3V47gUQVo8KjYi0B7dSGOAqieynh456GkVoA@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487CC37AD@GOLD.corp.lgc-group.com>

> I have a set of data and I need to find out how many points are below a
> certain value but R will not calculate this properly for me. 
R will. But you aren't.

> Negative numbers seem to be causing the issue.
You haven't got any negative numbers in your data set. In fact, you haven't got any numbers. It's all character strings. Is there a reason for that?

Assuming there is, if you have your data in a data frame 'A' and just want the count:

table(as.numeric(A$Tm_ugL) <= 0.0002)

If you just want a complete vector of TRUE or FALSE
as.numeric(d$Tm_ugL) <= 0.0002)

does that. If you want to add that to your data frame (is it called A?) that looks like
A$Censored <- as.numeric(d$Tm_ugL) <= 0.0002)

But you really shouldn't have numbers in character format; read it as numeric. Then it's just
table(d$Tm_ugL <= 0.0002) and so on. If it's refusing to read as numeric, find out why and fix the data.


And some comments on code, while I'm here: 

> for (i in one:nrow(A))
...
>   if (A[i,two]<=A_LLD)
Variables called 'one' and 'two' look like a really bad idea. If they are equal to 1 and 2, use 1 and 2 (or 1L and 2L if you want to be _sure_ they are integer). If not, the names are going to be pretty confusing, no? 

>     (A_Censored[i,two]<-"TRUE")
Why use a character string like "TRUE" that R can't interpret as logical instead of the logical values TRUE and FALSE?

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From nashjc at uottawa.ca  Fri Oct  4 15:28:57 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Fri, 04 Oct 2013 09:28:57 -0400
Subject: [R] SSweibull() : problems with step factor and singular gradient
In-Reply-To: <mailman.2417.1380867556.4612.r-help@r-project.org>
References: <mailman.2417.1380867556.4612.r-help@r-project.org>
Message-ID: <524EC299.5060900@uottawa.ca>

I think you have chosen a model that is ill-suited to the data.

My initial thoughts were simply that the issue was the usual nls() 
"singular gradient" (actually jacobian if you want to be understood in 
the optimization community) woes, but in this case the jacobian really 
is bad.

My quick and dirty tries give some insight, but do not provide a 
satisfactory answer. Note that the last two columns of the nlxb summary 
are the gradient and the Jacobian singular values, so one can see how 
bad things are.

days <- c(163,168,170,175,177,182,185,189,196,203,211,217,224)
height <- c(153,161,171,173,176,173,185,192,195,187,195,203,201)
dat <- as.data.frame(cbind(days,height))
fit <- try(nls(y ~ SSweibull(x, Asym, Drop, lrc, pwr), data = dat, 
trace=T, control=nls.control(minFactor=1/100000)))
## failed

fdata<-data.frame(x=days, y=height)

require(nlmrt)
strt2<-c(Asym=250, Drop=1, lrc=1, pwr=1)
fit2<-nlxb(y ~ Asym - (Drop * ( exp(-(exp(lrc)*(x^pwr))))), data=fdata, 
start=strt2, trace=TRUE)

strt3<-c(Asym=250, Drop=.5, lrc=.1, pwr=2)
fit3<-nlxb(y ~ Asym - (Drop * ( exp(-(exp(lrc)*(x^pwr))))), data=fdata, 
start=strt3, trace=TRUE)

strt4<-c(Asym=200, Drop=.5, lrc=.1, pwr=2)
fit4<-nlxb(y ~ Asym - (Drop * ( exp(-(exp(lrc)*(x^pwr))))), data=fdata, 
start=strt4, trace=TRUE, masked=c("Asym"))

d50<-days-160
fd2<-data.frame(x=d50, y=height)
fit5<-nlxb(y ~ Asym - (Drop * ( exp(-(exp(lrc)*(x^pwr))))), data=fd2, 
start=strt3, trace=TRUE)
fit5

John Nash


On 13-10-04 02:19 AM, r-help-request at r-project.org wrote:
> Message: 40
> Date: Thu, 3 Oct 2013 20:49:36 +0200
> From:aline.frank at wsl.ch
> To:r-help at r-project.org
> Subject: [R] SSweibull() : problems with step factor and singular
> 	gradient
> Message-ID:
> 	<OF669FA420.9EF643ED-ONC1257BF9.00676B04-C1257BF9.00676B07 at wsl.ch>
> Content-Type: text/plain
>
>   SSweibull() : ? problems with step factor and singular gradient
>
> Hello
>
> I  am working with growth data of ~4000 tree seedlings and trying to fit  non-linear Weibull growth curves through the data of each plant. Since  they differ a lot in their shape, initial parameters cannot be set for  all plants. That???s why I use the self-starting function SSweibull().
> However, I often got two error messages:
>
> 1)
> # Example
> days <- c(163,168,170,175,177,182,185,189,196,203,211,217,224)
> height <- c(153,161,171,173,176,173,185,192,195,187,195,203,201)
> dat <- as.data.frame(cbind(days,height))
> fit <- nls(y ~ SSweibull(x, Asym, Drop, lrc, pwr), data = dat, trace=T, control=nls.control(minFactor=1/100000))
>
> Error in nls(y ~cbind(1, -exp(-exp(lrc)* x^pwr)), data = xy, algorithm = ???plinear???, : ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?
> step factor 0.000488281 reduced below `minFactor` of 0.000976562
>
> I  tried to avoid this error by reducing the step factor below the  standard minFactor of 1/1024 using the nls.control function (shown in  the example above). However, this didn???t work, as shown in the example  (minFactor still the standard).
> Thus, does nls.control() not work for self-starting functions like SSweibull()? Or is there another explanation?
>
> 2)
> In other cases, a second error message showed up:
>
> Error in nls(y ~cbind(1, -exp(-exp(lrc)* x^pwr)), data = xy, algorithm = ???plinear???, : ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?  ?
> singular gradient
>
> Is there a way to avoid the problem of a singular gradient?
>
> I???d be very glad about helpful comments. Thanks a lot.
> Aline
> 	[[alternative HTML version deleted]]


From eliza_botto at hotmail.com  Fri Oct  4 15:37:14 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Fri, 4 Oct 2013 13:37:14 +0000
Subject: [R] vif
In-Reply-To: <1380820958.97817.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <BLU170-W802FE25B05F0A1E7CED77B89170@phx.gbl>, ,
	<1380816113.92158.YahooMailNeo@web142601.mail.bf1.yahoo.com>,
	<BLU170-W530A0B4F57F313FAC511B789170@phx.gbl>,
	<1380820958.97817.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <BLU170-W452D478AAF7594F1265FB189100@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/0f47ebe3/attachment.pl>

From S.Ellison at LGCGroup.com  Fri Oct  4 15:34:03 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 4 Oct 2013 14:34:03 +0100
Subject: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U) test
In-Reply-To: <CAKxRbrf-ZqkizD00H=rKMTbg85zMdUgu3jSd_gLSint9jGxseA@mail.gmail.com>
References: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5487C275ED@GOLD.corp.lgc-group.com>
	<CAKxRbrf-ZqkizD00H=rKMTbg85zMdUgu3jSd_gLSint9jGxseA@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487CC37EE@GOLD.corp.lgc-group.com>



> -----Original Message-----
> Got it! I agree it should had been more obvious to me... :)
I wouldn't feel too bad about that. I've spent most of the last 25 years discovering the hard way that statistics is very much a field where things are 'obvious' only _after_ you know the answer... 

S



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From dimitri.liakhovitski at gmail.com  Fri Oct  4 15:49:58 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 4 Oct 2013 09:49:58 -0400
Subject: [R] Trying it 'isolate' correctly in Shiny
Message-ID: <CAN2xGJaxN678u2wYRhj1jDsKGy9NN=b7k6pzJU+t+XqAAQcQfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/45bf4fa6/attachment.pl>

From pmassicotte at hotmail.com  Fri Oct  4 15:49:56 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Fri, 4 Oct 2013 13:49:56 +0000
Subject: [R] Trying to avoid nested loop
Message-ID: <COL127-W42FEB48DA7EBDB7F7E0408B3100@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/81eb293d/attachment.pl>

From careyshan at gmail.com  Fri Oct  4 15:50:39 2013
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 4 Oct 2013 14:50:39 +0100
Subject: [R] Counting numbers in R
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5487CC37AD@GOLD.corp.lgc-group.com>
References: <CA+jRDxAQ=StpYU3V47gUQVo8KjYi0B7dSGOAqieynh456GkVoA@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5487CC37AD@GOLD.corp.lgc-group.com>
Message-ID: <CA+jRDxDVLm6KnxEx0tDV-_cHdMr2qeyTkXZ+q9ijKVdmkV78DQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/fd450243/attachment.pl>

From S.Ellison at LGCGroup.com  Fri Oct  4 16:13:49 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 4 Oct 2013 15:13:49 +0100
Subject: [R] Trying to avoid nested loop
In-Reply-To: <COL127-W42FEB48DA7EBDB7F7E0408B3100@phx.gbl>
References: <COL127-W42FEB48DA7EBDB7F7E0408B3100@phx.gbl>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487CC3851@GOLD.corp.lgc-group.com>


> I'm trying to avoid using nested loops in the following code but I'm
> not sure how to proceed. Any help would be greatly appreciated.
> With regards,Phil
> X = matrix(rnorm(100), 10, 10)
> result = 0
> for(m in 1:nrow(X)){  
>	for(n in 1:ncol(X)){        
>		if(X[m,n] != 0){      
>			result = result + (X[m,n] / (1 + abs(m - n)))    
>		}      
>	}
> }
First, you don't need  the 'if', do you? If X[m,n]==0 (rare for a floating point number) (X[m,n] / (1 + abs(m - n)) will be zero anyway.

Then, depending on the matrix size, you can probably do the whole thing using an index array.

Something like:

idx <- as.matrix( expand.grid(1:nrow(X), 1:ncol(X)) )
result <- sum(  X[idx] / apply(idx,1, function(x) 1+abs(diff(x))) )

#... which seemed to do the identically the same thing as your loop when I tried it.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jenny.williams at kew.org  Fri Oct  4 16:17:15 2013
From: jenny.williams at kew.org (Jenny Williams)
Date: Fri, 4 Oct 2013 15:17:15 +0100
Subject: [R] climstats 'spatial_sync_raster' function
In-Reply-To: <F790EF15-F8E0-406A-A121-76514C7C6785@comcast.net>
References: <DEF541F3CB545B4A8BC9A811132359C003697191EFE2@KEXCH00.ad.kew.org>
	<1FB1E28E-2A6E-4474-950A-95C378442109@comcast.net>
	<5249B73C.20901@stats.ox.ac.uk>
	<FE8088E7-5EB5-488B-A8CE-57A05268C4D1@comcast.net>
	<DEF541F3CB545B4A8BC9A811132359C003697191F01B@KEXCH00.ad.kew.org>
	<F790EF15-F8E0-406A-A121-76514C7C6785@comcast.net>
Message-ID: <DEF541F3CB545B4A8BC9A811132359C003697191F032@KEXCH00.ad.kew.org>

The function I have been trying to use is: spatial_sync_raster

The maintainer has let me know that this is available in his spatial.tools package, which you can get from CRAN:
install.packages("spatial.tools")

problem solved.

Thanks

jenny


-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: 03 October 2013 20:45
To: Jenny Williams
Cc: Prof Brian Ripley; r-help at r-project.org
Subject: Re: [R] climstats


On Oct 3, 2013, at 10:00 AM, Jenny Williams wrote:

> It seems to load now on 3.0.2 32bit and 64bit but NOT 3.0.1. 
> install.packages("climstats", repos="http://R-Forge.R-project.org", 
> type="source")
> 
> I did have to manually install some of the dependencies.
> There were 2 of us that tried loading climstats on different machines so there must have been a blip with our firewall or something.
> 
> Now that I have climstats loaded the function I am trying to use doesn't work. 
> I can bring up the help file:
> ?spatial_sync_raster
> 
> but I get this error when I try to use the function:
> Error: could not find function "spatial_sync_raster"

I was going to say a case offailing to load the package but you say that you got information from 

?spatial_sync_raster   # be sure to check exact spelling

.. so that seems unlikely. (You are asked to show sessionInfor and the exact code which you have failed to provide.) Maybe you should ask the package maintainer. Type:

maintainer("climstats")

--
David
> 
> On Sep 30, 2013, at 10:39 AM, Prof Brian Ripley wrote:
> 
>> On 30/09/2013 18:19, David Winsemius wrote:
>>> 
>>> On Sep 30, 2013, at 3:25 AM, Jenny Williams wrote:
>>> 
>>>> I have been trying to download the climstats package:
>>>> https://r-forge.r-project.org/R/?group_id=861
>>>> 
>>>> but it doesn't seem to run on R 3.0.2 or 3.0.1
>>> 
>>> What makes you say this? What errors are reprorted? ("Doesn't seems 
>>> to run" is a bit vague.)
>>> 
>>>> and the zipfile is empty.
>>> 
>>> I was able to install version 1.0 from sources with:
>>> 
>>> install.packages("climstats", repos="http://R-Forge.R-project.org", 
>>> type="source")
>>> 
>>> (I agree that the zipfile for Windows was not found.)
>>> 
>>> R version 3.0.1 Patched (2013-07-23 r63392) Running Mac OS 10.7.5. It appears to require a fair number of external package, so you would need to check the Depends in the description file.
>>> 
>>> Depends: R (>= 2.13), raster, rgdal, chron, zoo, sp, ncdf, R.utils
>>> 
>>> It did not appear to do any C or Fortran compiling, so I think that means you do not need to have RTools installed on Windows.
>>> 
>>> But since it requires rgdal, you would need to have GDAL installed if you were to get it to load.
>> 
>> Why do you say that?  On both Windows and OS X, GDAL is part of the rgdal binary.
> 
> My error apparently. I have in the past had incorrect installations of GDAL that prevented rgdal from loading properly and my sometimes fuzzy memory was that I fixed this by reinstalling GDAL. So I thought they were independent installations. Apologies for the noise.
> 
> --
> David.
> 
> 
>> 
>>> 
>>>> 
>>>> Does anyone know the status of this package or where I can download it.
>>>> 
>>>> Thanks
>>>> 
>>>> ******************
>>>> Jenny Williams
>>>> Spatial Information Scientist, GIS Unit Herbarium, Library, Art & 
>>>> Archives Directorate Royal Botanic Gardens, Kew Richmond, TW9 3AB, 
>>>> UK
>>>> 
>>>> Tel: +44 (0)208 332 5277
>>>> email: jenny.williams at kew.org<mailto:jenny.williams at kew.org>
>>>> ******************
>>>> 
>>>> Film: The Forgotten Home of Coffee - Beyond the 
>>>> Gardens<http://www.youtube.com/watch?v=-uDtytKMKpA&sns=tw>
>>>> Stories: Coffee Expedition - Ethiopia<http://storify.com/KewGIS/coffee-expedition-ethiopia>
>>>>            Blog: Discovering Coffee in Ethiopia    <http://www.kew.org/news/kew-blogs/incrEdibles-food-blog/discovering-coffee.htm>
>>>>            Kew in Harapan Rainforest 
>>>> Sumatra<http://storify.com/KewGIS/kew-in-harapan-rainforest>
>>>> Articles: Seeing the wood for the 
>>>> trees<http://www.kew.org/ucm/groups/public/documents/document/kppco
>>>> nt_060602.pdf> How Kew's GIS team and South East Asia botanists are 
>>>> working to help conserve and restore a rainforest in Sumatra. 
>>>> Download a pdf of this article 
>>>> here.<http://www.kew.org/ucm/groups/public/documents/document/kppco
>>>> nt_060602.pdf>
>>>> 
>>>> 
> 

David Winsemius
Alameda, CA, USA


From pmassicotte at hotmail.com  Fri Oct  4 16:33:41 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Fri, 4 Oct 2013 14:33:41 +0000
Subject: [R] Trying to avoid nested loop
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5487CC3851@GOLD.corp.lgc-group.com>
References: <COL127-W42FEB48DA7EBDB7F7E0408B3100@phx.gbl>,
	<A4E5A0B016B8CB41A485FC629B633CED5487CC3851@GOLD.corp.lgc-group.com>
Message-ID: <COL127-W2DEA27151DF30A19860C4B3100@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/8bcefb94/attachment.pl>

From daniel.hickman at live.com  Fri Oct  4 16:48:36 2013
From: daniel.hickman at live.com (Daniel Hickman)
Date: Fri, 4 Oct 2013 14:48:36 +0000
Subject: [R] =?utf-8?q?time_series_has_no_or_less_than_2_periods?=
Message-ID: <BAY404-EAS14051E2C6FC7D353105FE60ED100@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/810e4705/attachment.pl>

From smartpink111 at yahoo.com  Fri Oct  4 17:01:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 4 Oct 2013 08:01:09 -0700 (PDT)
Subject: [R] Trying to avoid nested loop
In-Reply-To: <1380897058.38544.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <COL127-W42FEB48DA7EBDB7F7E0408B3100@phx.gbl>
	<1380897058.38544.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1380898869.87860.YahooMailNeo@web142602.mail.bf1.yahoo.com>



Hi,
set.seed(49)
?X = matrix(rnorm(100), 10, 10)
X1<- X

result<-0
for(m in 1:nrow(X)){? for(n in 1:ncol(X)){??????? if(X[m,n] != 0){????? result = result + (X[m,n] / (1 + abs(m - n)))??? }????? }}


indx<-which(X!=0,arr.ind=TRUE)
?indx1<-1+abs(indx[,1]-indx[,2])

X1[indx]<- X1[indx]/indx1
#or

res1<- sapply(seq_len(nrow(X)),function(m) do.call(rbind,lapply(seq_len(ncol(X)),function(n) {if(X[m,n]!=0) X[m,n]/(1+abs(m-n))})))
?res2<-t(X1)
?identical(res1,res2)
#[1] TRUE


res3<- sum(res2)
all.equal(res3,result)
#[1] TRUE
A.K.




----- Original Message -----
From: philippe massicotte <pmassicotte at hotmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Friday, October 4, 2013 9:49 AM
Subject: [R] Trying to avoid nested loop

Dear R users.
I'm trying to avoid using nested loops in the following code but I'm not sure how to proceed. Any help would be greatly appreciated.
With regards,Phil
X = matrix(rnorm(100), 10, 10)
## Version with nested loopsresult = 0
for(m in 1:nrow(X)){? for(n in 1:ncol(X)){? ? ? ? if(X[m,n] != 0){? ? ? result = result + (X[m,n] / (1 + abs(m - n)))? ? }? ? ? }}
## No loop-sum(ifelse(M > 0, M/??? , 0))

??? ???? ??? ?? ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From TAPO at novozymes.com  Fri Oct  4 13:01:15 2013
From: TAPO at novozymes.com (TAPO (Thomas Agersten Poulsen))
Date: Fri, 4 Oct 2013 13:01:15 +0200
Subject: [R] R-help Digest, Vol 128, Issue 5
In-Reply-To: <mailman.29.1380880808.17398.r-help@r-project.org>
References: <mailman.29.1380880808.17398.r-help@r-project.org>
Message-ID: <06B94BF8548CBD40A94D09667C236AB762AB368D5C@NZT0013E.dknz.nzcorp.net>

Hi Peter,

The ssconvert tool (part of gnumeric) is very good at converting spreadsheets to csv-files.
There is a wrapper in the "gnumeric" package on cran.

Cheers,
Thomas

> Date: Fri, 4 Oct 2013 09:08:50 +0100
> From: Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
> To: Peter Maclean <pmaclean2011 at yahoo.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Subject: Re: [R] Importing odf file into R
> Message-ID:
> 	<CANVKczMtrLD2rw_UWhRoJo5CUP-
> 7taUcmiZO+swRRRvKONMUVw at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> On Fri, Oct 4, 2013 at 5:57 AM, Peter Maclean <pmaclean2011 at yahoo.com>
> wrote:
> > Anyone aware of a package or technique to import odf data file into R, I
> will appreciate his/her help.
> 
> A quick scan of R-help points me here:
> 
> http://www.omegahat.org/ROpenOffice/
> 
> Reports of that working (or not) would be appreciated - I've not tried it.
> 
> Alternatively, there's python code for reading ODF so you could
> interface to that in a number of ways.
> 
> Barry


From khatriumesh88 at gmail.com  Fri Oct  4 13:53:31 2013
From: khatriumesh88 at gmail.com (umesh khatri)
Date: Fri, 4 Oct 2013 17:23:31 +0530
Subject: [R] Tex-mining in R
In-Reply-To: <CA+vqiLFx9Dxbq8UqgNREehbFJ7sL+CO46PHP7NNE-EHqKNp3Tg@mail.gmail.com>
References: <CAJQybkmEqxvJ85TUa0_1r=7TG1=k=zq311m3-eEkHvRgyCv5JQ@mail.gmail.com>
	<CA+vqiLFx9Dxbq8UqgNREehbFJ7sL+CO46PHP7NNE-EHqKNp3Tg@mail.gmail.com>
Message-ID: <CAJQybkmmDKoTOjB2PjhW9gFRp891VbTEb3_RsATXL4CfuVw3pw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/5103cf19/attachment.pl>

From dstr7320 at uni.sydney.edu.au  Fri Oct  4 14:00:31 2013
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Fri, 4 Oct 2013 12:00:31 +0000
Subject: [R] Tab Separated File Reading Error
Message-ID: <A4D0AD48C137224D9E532742F418928A1CFE1DCE@BL2PRD0111MB520.prod.exchangelabs.com>

Hello,

I have a seemingly simple problem that a tab-delimited file can't be read in.

> annoTranscripts <- read.table("matched.txt", sep = '\t', stringsAsFactors = FALSE)
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  : 
  line 5933 did not have 12 elements

However, all lines do have 12 columns.

> lines <- readLines("matched.txt")
> tabsPosns <- gregexpr("\t", lines)
> table(sapply(tabsPosns, length))

    11 
367274 

> system("wc -l matched.txt")
367274 matched.txt

You can obtain the file from https://dl.dropboxusercontent.com/u/37992150/matched.txt

The line does not contain comment or quote characters. What can you suggest ?

> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8    
 [5] LC_MONETARY=en_AU.UTF-8    LC_MESSAGES=en_AU.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     

loaded via a namespace (and not attached):
[1] tools_3.0.1

--------------------------------------
Dario Strbenac
PhD Student
University of Sydney
Camperdown NSW 2050
Australia

From hans_hans74 at gmx.de  Fri Oct  4 16:16:49 2013
From: hans_hans74 at gmx.de (hans74)
Date: Fri, 4 Oct 2013 07:16:49 -0700 (PDT)
Subject: [R] abline is not plotting
Message-ID: <1380896209391-4677583.post@n4.nabble.com>

Hello there,

I have some data I want to plot together with a best-fit line. (see MWE
below)
The points from the first plot does appear as expected, but the abline does
not appear, no matter what I change. I removed the log parameter before, but
the abline is a very steep line around the origin. I really want to keep the
logarithmic scale, plus a working abline.

Can someone help me with that? What am I doing wrong?

Thanks in advance,
Hans

#############
d = data.frame( x = c(154471 , 517423 , 704286 , 236117 , 10664898 , 21887 ,
104994 , 794101 , 289567 , 74818 , 63920 , 251053 , 263583 , 84882 , 55075 ,
741076 , 92000 , 137799 , 59856 , 184992 , 8292355),
                   y = c(624 , 1681 , 590 , 2073 , 12189 , 42 , 343 , 365 ,
969 , 108 , 366 , 1664 , 738 , 420 , 318 , 1278 , 887 , 395 , 462 , 1376 ,
17907)
                 )
plot(d, log = "xy")
abline(lm(x ~ y, data = d))



--
View this message in context: http://r.789695.n4.nabble.com/abline-is-not-plotting-tp4677583.html
Sent from the R help mailing list archive at Nabble.com.


From aj409 at bath.ac.uk  Fri Oct  4 17:03:35 2013
From: aj409 at bath.ac.uk (aj409 at bath.ac.uk)
Date: Fri, 04 Oct 2013 16:03:35 +0100
Subject: [R] Subsetting Timestamped data
Message-ID: <20131004160335.Horde.M-GXYM1vlIJSTtjHyfFVKUA@webmail.bath.ac.uk>


Hi,

I have a data frame, data, containing two columns: one- the TimeStamp  
(formatted using data$TimeStamp <-  
as.POSTIXct(as.character(data$TimeStamp), format = "%d/%m/%Y %H:%M") )  
and two- the data value.

The data frame has been read from a .csv file and should contain 48  
values for each day of the year (values sampled at 30 minute  
intervals). However, there are only 15,948 observations i.e. only  
approx 332 days worth of data. I therefore would like to remove any  
days that do not contain the 48 values.

My question, how would I go about doing this?

Many thanks,

-A.


From smartpink111 at yahoo.com  Fri Oct  4 16:30:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 4 Oct 2013 07:30:58 -0700 (PDT)
Subject: [R] Trying to avoid nested loop
In-Reply-To: <COL127-W42FEB48DA7EBDB7F7E0408B3100@phx.gbl>
References: <COL127-W42FEB48DA7EBDB7F7E0408B3100@phx.gbl>
Message-ID: <1380897058.38544.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
set.seed(49)
?X = matrix(rnorm(100), 10, 10)
X1<- X

result<-0
for(m in 1:nrow(X)){? for(n in 1:ncol(X)){??????? if(X[m,n] != 0){????? result = result + (X[m,n] / (1 + abs(m - n)))??? }????? }}


indx<-which(X!=0,arr.ind=TRUE)
?indx1<-1+abs(indx[,1]-indx[,2])

X1[indx]<- X1[indx]/indx1
#or

res1<- sapply(seq_len(nrow(X)),function(m) do.call(rbind,lapply(seq_len(ncol(X)),function(n) {if(X[m,n]!=0) X[m,n]/(1+abs(m-n))})))
?res2<-t(X1)
?identical(res1,res2)
#[1] TRUE


res3<- sum(res2)
all.equal(res3,result)
#[1] TRUE
A.K.



----- Original Message -----
From: philippe massicotte <pmassicotte at hotmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Friday, October 4, 2013 9:49 AM
Subject: [R] Trying to avoid nested loop

Dear R users.
I'm trying to avoid using nested loops in the following code but I'm not sure how to proceed. Any help would be greatly appreciated.
With regards,Phil
X = matrix(rnorm(100), 10, 10)
## Version with nested loopsresult = 0
for(m in 1:nrow(X)){? for(n in 1:ncol(X)){? ? ? ? if(X[m,n] != 0){? ? ? result = result + (X[m,n] / (1 + abs(m - n)))? ? }? ? ? }}
## No loop-sum(ifelse(M > 0, M/??? , 0))

??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jrkrideau at inbox.com  Fri Oct  4 17:35:59 2013
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 4 Oct 2013 07:35:59 -0800
Subject: [R] abline is not plotting
In-Reply-To: <1380896209391-4677583.post@n4.nabble.com>
Message-ID: <EEB80FC5BAA.00000864jrkrideau@inbox.com>

Well you logged the x and y values before plotting but did not log the lm(). I think this means you have plotted abline() off the scale.  

I'm not sure how to fix it though.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: hans_hans74 at gmx.de
> Sent: Fri, 4 Oct 2013 07:16:49 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] abline is not plotting
> 
> Hello there,
> 
> I have some data I want to plot together with a best-fit line. (see MWE
> below)
> The points from the first plot does appear as expected, but the abline
> does
> not appear, no matter what I change. I removed the log parameter before,
> but
> the abline is a very steep line around the origin. I really want to keep
> the
> logarithmic scale, plus a working abline.
> 
> Can someone help me with that? What am I doing wrong?
> 
> Thanks in advance,
> Hans
> 
> #############
> d = data.frame( x = c(154471 , 517423 , 704286 , 236117 , 10664898 ,
> 21887 ,
> 104994 , 794101 , 289567 , 74818 , 63920 , 251053 , 263583 , 84882 ,
> 55075 ,
> 741076 , 92000 , 137799 , 59856 , 184992 , 8292355),
>                    y = c(624 , 1681 , 590 , 2073 , 12189 , 42 , 343 , 365
> ,
> 969 , 108 , 366 , 1664 , 738 , 420 , 318 , 1278 , 887 , 395 , 462 , 1376
> ,
> 17907)
>                  )
> plot(d, log = "xy")
> abline(lm(x ~ y, data = d))
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/abline-is-not-plotting-tp4677583.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From clint at ecy.wa.gov  Fri Oct  4 17:52:07 2013
From: clint at ecy.wa.gov (Clint Bowman)
Date: Fri, 4 Oct 2013 08:52:07 -0700 (PDT)
Subject: [R] time series has no or less than 2 periods
In-Reply-To: <BAY404-EAS14051E2C6FC7D353105FE60ED100@phx.gbl>
References: <BAY404-EAS14051E2C6FC7D353105FE60ED100@phx.gbl>
Message-ID: <alpine.LRH.2.03.1310040829270.12815@ecy.wa.gov>

Perhaps looking at your data will suggest an appropriate number, viz.

plot(data,type="b",xlim=c(0,20),ylim=c(0,50))
par(new=T)
ind<-1:19  # in this case where the data length is 19
data.ind<-data.frame(ind,data)
data.lo<-loess(data~ind,data.ind)
data.pre<-predict(data.lo,data.frame(ind = seq(1,19,1))) 
plot(data.pre,pch=3,col=2,xlim=c(0,20),ylim=c(0,50))

If you now plot the difference between the data and the loess prediction,

data.ind<-cbind(data.ind,data.pre)
data.diff<-with(data.ind,data-data.pre)
data.ind<-cbind(data.ind,data.diff)
with(data.ind,plot(ind,data.diff,type="b"))
abline(h=0)

there is also a pretty strong two week signal--is that of any interest?

Now you should be able to decide how to proceed.

Clint

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Fri, 4 Oct 2013, Daniel Hickman wrote:

> Bill,
>
> Thanks for replying.
>
>
> The data is weekly time series data.  Assume there is 52 weeks in the year.  Of the 52 weeks, I typically only have data for weeks 8 through 40.
>
>
> 4-Apr-10, 8, 27.2
> 11-Apr-10, 9, 32.3
> 18-Apr-10, 10, 31.7
>
> DataXYZ, 40, 13.4
>
>
> data <- c(0,24.57,29.93,24.19,12.25,48.07,36.68,24.78,48.69,30.39,48.17,36.51,36.43,36.52,48.75,24.17,37.07,0,18.89)
> ts <- ts(data= data, start = 8, end = 40, frequency = ????)
>
>
> There is a weekly seasonality effect.  What should I set my frequency value to?
>
>
> Thanks,
>
> Dan Hickman
>
>
>
>
>
>
> From: William Dunlap
> Sent: ???Thursday???, ???October??? ???3???, ???2013 ???3???:???57??? ???PM
> To: David Winsemius, Daniel Hickman
> Cc: r-help at r-project.org
>
>
>>> ts <- ts(data$QtyPerWeek, frequency=52)
>>> HoltWinters(ts,0.46924,0.05,0.2)
>>>
>>> This results in the following error. "Error in decompose(ts(x[1L:wind], start = start(x),
>> frequency = f), seasonal) : time series has no or less than 2 periods"
>
> Since you have set the frequency of the time series to 52, you need
> to have 104 observations to get the initial estimate of the seasonal
> pattern.  How many observations are in 'ts'?  If you don't have enough
> you can omit the seaonal component (HoltWinters(gamma=FALSE,...)),
> change start.periods from the default 2 to 1, or supply a 52-long vector
> of the initial seasonal pattern as the s.start argument.
>
> If you do have more than 104 observations then you will have to tell
> us more about the data.
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of David Winsemius
>> Sent: Thursday, October 03, 2013 12:39 PM
>> To: Daniel Hickman
>> Cc: r-help at r-project.org
>> Subject: Re: [R] time series has no or less than 2 periods
>>
>>
>> On Oct 3, 2013, at 8:32 AM, Daniel Hickman wrote:
>>
>>> Hello,
>>>
>>>
>>>
>>> I have been tasked with taking an excel file that my colleague had implemented Triple
>> Exponential Smoothing and recreate using R.
>>>
>>> The following image shows the before and after of smoothing out a fixed interval time
>> series data using Triple Exponential Smoothing inside of Excel.
>>>
>>> enter image description here
>>
>> The image file formats that I know are acceptable are .ps, .pdf or .png. Not sure about
>> jpeg.
>>
>>>
>>> I am trying to perform the same triple exponential smoothing in R.  I created a csv file
>> with the before smoothing data.  The csv file is attached and can also be found here.
>>
>> Need to send with .txt extension.
>>
>>>
>>> I found the HoltWinters method but I keep getting an error when I try to apply
>> HoltWinters against the csv.
>>> setwd("C:/temp")
>>> data <- read.table("TripleExpSmoothingXLS.csv", header=TRUE, sep=",")
>>> ts <- ts(data$QtyPerWeek, frequency=52)
>>> HoltWinters(ts,0.46924,0.05,0.2)
>>>
>>> This results in the following error. "Error in decompose(ts(x[1L:wind], start = start(x),
>> frequency = f), seasonal) : time series has no or less than 2 periods"
>>
>> Perhaps a data entry problem. We would need to see either the file or output of
>> str(data).
>>>
>>> In case it helps,  excel file with the triple exponential smoothing formulas and original
>> data can be found here.
>>
>> Again.... there is no here here.
>>
>>>
>>> Any advice?
>>>
>>> Thanks, Dan______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 	[[alternative HTML version deleted]]


From S.Ellison at lgcgroup.com  Fri Oct  4 17:49:23 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Fri, 4 Oct 2013 16:49:23 +0100
Subject: [R] abline is not plotting
In-Reply-To: <1380896209391-4677583.post@n4.nabble.com>
References: <1380896209391-4677583.post@n4.nabble.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487CC3904@GOLD.corp.lgc-group.com>

 
> I have some data I want to plot together with a best-fit line. (see MWE
> below)
...
> Can someone help me with that? What am I doing wrong?

Not logging the lm. Also, you've calculated lm() the wrong way round; you've regressed x on y.

Try

plot(log(d), xlab="log(x)", ylab="log(y)")
abline(lm(y ~ x, data = log(d)))

S Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jimmycloud at gmail.com  Fri Oct  4 18:06:50 2013
From: jimmycloud at gmail.com (Jie)
Date: Fri, 4 Oct 2013 12:06:50 -0400
Subject: [R]  quote a column of a dataframe by its name
Message-ID: <CACXG3Gh5BJOvneHHAg49ieS8jrPN3D4efHxsvWbRBzjdB7vPxA@mail.gmail.com>

Dear All,

I have a question, suppose X is a dataframe, with column names as
"x1", "x2", "x3", ..... And I would like to use the i-th column by X[,'xi'].
But it seems the single quote and double quote are different.
So if I run X[, names(X)[i]], it has some error.
Please use the below example code

X = matrix(rnorm(50),ncol = 5)
X = data.frame(X)
names(X)=c("x1","x2","x3","x4","x5")

#pick the 4-th column
X[,'x4']  #working
X[,names(X)[4]]  # not working , so how to modify this line?

names(X)[4] #  returns "x4"
sQuote(names(X)[4])  # returns "'x4'"


Best,


From jimmycloud at gmail.com  Fri Oct  4 18:10:21 2013
From: jimmycloud at gmail.com (Jie)
Date: Fri, 4 Oct 2013 12:10:21 -0400
Subject: [R] quote a column of a dataframe by its name
In-Reply-To: <CACXG3Gh5BJOvneHHAg49ieS8jrPN3D4efHxsvWbRBzjdB7vPxA@mail.gmail.com>
References: <CACXG3Gh5BJOvneHHAg49ieS8jrPN3D4efHxsvWbRBzjdB7vPxA@mail.gmail.com>
Message-ID: <CACXG3Gii2_+r=+06c5=95yHK1ugqaLpokz4x5ACMk3iZ=9puAQ@mail.gmail.com>

Sorry, this sample code seems to be OK.
I will look into my original problem and update it soon.

Best wishes,


On Fri, Oct 4, 2013 at 12:06 PM, Jie <jimmycloud at gmail.com> wrote:
> Dear All,
>
> I have a question, suppose X is a dataframe, with column names as
> "x1", "x2", "x3", ..... And I would like to use the i-th column by X[,'xi'].
> But it seems the single quote and double quote are different.
> So if I run X[, names(X)[i]], it has some error.
> Please use the below example code
>
> X = matrix(rnorm(50),ncol = 5)
> X = data.frame(X)
> names(X)=c("x1","x2","x3","x4","x5")
>
> #pick the 4-th column
> X[,'x4']  #working
> X[,names(X)[4]]  # not working , so how to modify this line?
>
> names(X)[4] #  returns "x4"
> sQuote(names(X)[4])  # returns "'x4'"
>
>
> Best,


From ruipbarradas at sapo.pt  Fri Oct  4 18:14:02 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 04 Oct 2013 17:14:02 +0100
Subject: [R] quote a column of a dataframe by its name
In-Reply-To: <CACXG3Gh5BJOvneHHAg49ieS8jrPN3D4efHxsvWbRBzjdB7vPxA@mail.gmail.com>
References: <CACXG3Gh5BJOvneHHAg49ieS8jrPN3D4efHxsvWbRBzjdB7vPxA@mail.gmail.com>
Message-ID: <524EE94A.2030003@sapo.pt>

Hello,

I had no problems, and it shouldn't. What exactly do you mean by "not 
working"?

Hope this helps,

Rui Barradas

Em 04-10-2013 17:06, Jie escreveu:
> Dear All,
>
> I have a question, suppose X is a dataframe, with column names as
> "x1", "x2", "x3", ..... And I would like to use the i-th column by X[,'xi'].
> But it seems the single quote and double quote are different.
> So if I run X[, names(X)[i]], it has some error.
> Please use the below example code
>
> X = matrix(rnorm(50),ncol = 5)
> X = data.frame(X)
> names(X)=c("x1","x2","x3","x4","x5")
>
> #pick the 4-th column
> X[,'x4']  #working
> X[,names(X)[4]]  # not working , so how to modify this line?
>
> names(X)[4] #  returns "x4"
> sQuote(names(X)[4])  # returns "'x4'"
>
>
> Best,
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at inbox.com  Fri Oct  4 18:15:02 2013
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 4 Oct 2013 08:15:02 -0800
Subject: [R] quote a column of a dataframe by its name
In-Reply-To: <CACXG3Gh5BJOvneHHAg49ieS8jrPN3D4efHxsvWbRBzjdB7vPxA@mail.gmail.com>
Message-ID: <EF0F57ED352.0000093Djrkrideau@inbox.com>

X[,names(X)[4]]  works fine  for me.  I had never thought of doing this. Neat idea.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jimmycloud at gmail.com
> Sent: Fri, 4 Oct 2013 12:06:50 -0400
> To: r-help at r-project.org
> Subject: [R] quote a column of a dataframe by its name
> 
> Dear All,
> 
> I have a question, suppose X is a dataframe, with column names as
> "x1", "x2", "x3", ..... And I would like to use the i-th column by
> X[,'xi'].
> But it seems the single quote and double quote are different.
> So if I run X[, names(X)[i]], it has some error.
> Please use the below example code
> 
> X = matrix(rnorm(50),ncol = 5)
> X = data.frame(X)
> names(X)=c("x1","x2","x3","x4","x5")
> 
> #pick the 4-th column
> X[,'x4']  #working
> X[,names(X)[4]]  # not working , so how to modify this line?
> 
> names(X)[4] #  returns "x4"
> sQuote(names(X)[4])  # returns "'x4'"
> 
> 
> Best,
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From wdunlap at tibco.com  Fri Oct  4 18:22:47 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 4 Oct 2013 16:22:47 +0000
Subject: [R] Tab Separated File Reading Error
In-Reply-To: <A4D0AD48C137224D9E532742F418928A1CFE1DCE@BL2PRD0111MB520.prod.exchangelabs.com>
References: <A4D0AD48C137224D9E532742F418928A1CFE1DCE@BL2PRD0111MB520.prod.exchangelabs.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C348A5A@PA-MBX01.na.tibco.com>

> > annoTranscripts <- read.table("matched.txt", sep = '\t', stringsAsFactors = FALSE)
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>   line 5933 did not have 12 elements
> 
> However, all lines do have 12 columns.
> 
> > lines <- readLines("matched.txt")
> ...[many omitted lines]...
> The line does not contain comment or quote characters. What can you suggest ?

I suggest looking at the lines preceding the one where the error was found, with both
print and cat:
    print(lines[5933 - (10:0)])
    cat(lines[5933 - (10:0)], sep="\n")

If things are not obvious after looking at them, see if read.table can read just those lines
    read.table(text=lines[5933 - (10:0)], sep="\t", stringsAsFactors=FALSE)
If it can, try backing up more than 10 lines.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Dario Strbenac
> Sent: Friday, October 04, 2013 5:01 AM
> To: r-help at r-project.org
> Subject: [R] Tab Separated File Reading Error
> 
> Hello,
> 
> I have a seemingly simple problem that a tab-delimited file can't be read in.
> 
> > annoTranscripts <- read.table("matched.txt", sep = '\t', stringsAsFactors = FALSE)
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>   line 5933 did not have 12 elements
> 
> However, all lines do have 12 columns.
> 
> > lines <- readLines("matched.txt")
> > tabsPosns <- gregexpr("\t", lines)
> > table(sapply(tabsPosns, length))
> 
>     11
> 367274
> 
> > system("wc -l matched.txt")
> 367274 matched.txt
> 
> You can obtain the file from
> https://dl.dropboxusercontent.com/u/37992150/matched.txt
> 
> The line does not contain comment or quote characters. What can you suggest ?
> 
> > sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> locale:
>  [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8
>  [5] LC_MONETARY=en_AU.UTF-8    LC_MESSAGES=en_AU.UTF-8
>  [7] LC_PAPER=C                 LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
> 
> loaded via a namespace (and not attached):
> [1] tools_3.0.1
> 
> --------------------------------------
> Dario Strbenac
> PhD Student
> University of Sydney
> Camperdown NSW 2050
> Australia
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Fri Oct  4 18:52:16 2013
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 4 Oct 2013 10:52:16 -0600
Subject: [R] quote a column of a dataframe by its name
In-Reply-To: <EF0F57ED352.0000093Djrkrideau@inbox.com>
References: <CACXG3Gh5BJOvneHHAg49ieS8jrPN3D4efHxsvWbRBzjdB7vPxA@mail.gmail.com>
	<EF0F57ED352.0000093Djrkrideau@inbox.com>
Message-ID: <CAFEqCdxdBh4QG4e5nj9KouACe3RVbSya-cSuDdYjBCTuBKAUFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/9907dd69/attachment.pl>

From smartpink111 at yahoo.com  Fri Oct  4 18:38:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 4 Oct 2013 09:38:16 -0700 (PDT)
Subject: [R] Tab Separated File Reading Error
In-Reply-To: <A4D0AD48C137224D9E532742F418928A1CFE1DCE@BL2PRD0111MB520.prod.exchangelabs.com>
References: <A4D0AD48C137224D9E532742F418928A1CFE1DCE@BL2PRD0111MB520.prod.exchangelabs.com>
Message-ID: <1380904696.15826.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
annoTranscripts<- read.csv("matched.txt", sep = '\t', stringsAsFactors = FALSE,quote="",header=FALSE)
?str(annoTranscripts)
'data.frame':??? 367274 obs. of? 12 variables:
?$ V1 : chr? "comp103529_c0_seq1" "comp129123_c0_seq1" "comp129123_c0_seq1" "comp129124_c0_seq1" ...
?$ V2 : chr? "XM_003723822" "XM_778057" "EU116908" "XM_786928" ...
?$ V3 : chr? "PREDICTED: Strongylocentrotus purpuratus neuromedin-U receptor 2-like (LOC100888633), mRNA" "PREDICTED: Strongylocentrotus purpuratus 60S ribosomal protein L30-like (LOC577852), mRNA" "Barentsia elongata putative ribosomal protein L30 mRNA, complete cds" "PREDICTED: Strongylocentrotus purpuratus 60S ribosomal protein L29-1-like (LOC587182), mRNA" ...
?$ V4 : int? 91 392 69 149 149 451 399 203 193 185 ...
?$ V5 : int? 136 479 203 209 209 541 463 451 456 472 ...
?$ V6 : int? 15 16 40 20 20 24 20 71 83 85 ...
?$ V7 : int? 0 11 4 0 0 5 1 10 4 9 ...
?$ V8 : num? 2e-38 0e+00 6e-26 2e-70 2e-70 ...
?$ V9 : int? 1 22 210 135 135 131 189 205 196 185 ...
?$ V10: int? 136 499 410 343 343 669 650 650 649 653 ...
?$ V11: int? 576 159 27 1 1 1 21 23 140 22 ...
?$ V12: int? 441 627 227 209 209 538 483 468 593 487 ...
?dim(annoTranscripts)
[1] 367274???? 12
A.K.




----- Original Message -----
From: Dario Strbenac <dstr7320 at uni.sydney.edu.au>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Friday, October 4, 2013 8:00 AM
Subject: [R] Tab Separated File Reading Error

Hello,

I have a seemingly simple problem that a tab-delimited file can't be read in.

> annoTranscripts <- read.table("matched.txt", sep = '\t', stringsAsFactors = FALSE)
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,? : 
? line 5933 did not have 12 elements

However, all lines do have 12 columns.

> lines <- readLines("matched.txt")
> tabsPosns <- gregexpr("\t", lines)
> table(sapply(tabsPosns, length))

? ? 11 
367274 

> system("wc -l matched.txt")
367274 matched.txt

You can obtain the file from https://dl.dropboxusercontent.com/u/37992150/matched.txt

The line does not contain comment or quote characters. What can you suggest ?

> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
[1] LC_CTYPE=en_AU.UTF-8? ? ?  LC_NUMERIC=C? ? ? ? ? ? ? 
[3] LC_TIME=en_AU.UTF-8? ? ? ? LC_COLLATE=en_AU.UTF-8? ? 
[5] LC_MONETARY=en_AU.UTF-8? ? LC_MESSAGES=en_AU.UTF-8? 
[7] LC_PAPER=C? ? ? ? ? ? ? ?  LC_NAME=C? ? ? ? ? ? ? ? 
[9] LC_ADDRESS=C? ? ? ? ? ? ?  LC_TELEPHONE=C? ? ? ? ? ? 
[11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C? ? ? 

attached base packages:
[1] stats? ?  graphics? grDevices utils? ?  datasets? methods? 
[7] base? ? 

loaded via a namespace (and not attached):
[1] tools_3.0.1

--------------------------------------
Dario Strbenac
PhD Student
University of Sydney
Camperdown NSW 2050
Australia
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jrkrideau at inbox.com  Fri Oct  4 20:20:44 2013
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 4 Oct 2013 10:20:44 -0800
Subject: [R] Drawing garbled
In-Reply-To: <2311f4b1.7d65.14179de5d3b.Coremail.celsnrt@163.com>
Message-ID: <F02850E957F.00000A81jrkrideau@inbox.com>

Do you have the correct fonts installed on Windows?

John Kane
Kingston ON Canada


> -----Original Message-----
> From: celsnrt at 163.com
> Sent: Wed, 2 Oct 2013 23:51:58 +0800 (CST)
> To: r-help at r-project.org
> Subject: [R] Drawing garbled
> 
> Hi:
>        I am Chinese, I am developing a java application, and  deploy it
> to tomcat 7.0.42, I use rJava to use the R, when I use the command line
> to start tomcat, the R drawing well done, see attachment histview.png,but
> when i use windows service to start tomcat, the R drawing bad, see
> attachment histview2.png, I don't why, can you give me a suggestion? My
> window OS is window 7 home, thanks your help!
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From kw1958 at gmail.com  Fri Oct  4 20:38:21 2013
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Fri, 4 Oct 2013 14:38:21 -0400
Subject: [R] Applying and labeling scenarios
Message-ID: <3772A9FA-E252-415F-BC7E-FCBF81EACEC5@gmail.com>

Folks,

I have a working version of the code below for my "real world" problem. I was wondering if there was a better way to do this.

I have 3 sets of parameters and I want to iterate over all combinations and label the results.

Would some of the plyr tools make this easier?

# Input Scenarios
scens<-list(A=c(.2,.3), B= c(.2,.4), C=2:3)

# All combinations
allPerms<-expand.grid(scens)

# Create labels
labels<-sapply(1:nrow(allPerms), 
              function(x, y) paste0("[", paste0(y[x,], collapse = "|"), "]"), 
              allPerms)

# Simple example computation
vals<-sapply(1:nrow(allPerms), function(x, y) cumsum(t(y[x,])), allPerms)

# Apply labels to columns
colnames(vals)<-labels

# "Beautiful" output!
dput(vals)
structure(c(0.2, 0.4, 2.4, 0.3, 0.5, 2.5, 0.2, 0.6, 2.6, 0.3, 
0.7, 2.7, 0.2, 0.4, 3.4, 0.3, 0.5, 3.5, 0.2, 0.6, 3.6, 0.3, 0.7, 
3.7), .Dim = c(3L, 8L), .Dimnames = list(NULL, c("[0.2|0.2|2]", 
"[0.3|0.2|2]", "[0.2|0.4|2]", "[0.3|0.4|2]", "[0.2|0.2|3]", "[0.3|0.2|3]", 
"[0.2|0.4|3]", "[0.3|0.4|3]")))


Thanks for your time,
KW

--


From smartpink111 at yahoo.com  Fri Oct  4 20:57:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 4 Oct 2013 11:57:52 -0700 (PDT)
Subject: [R] Applying and labeling scenarios
In-Reply-To: <3772A9FA-E252-415F-BC7E-FCBF81EACEC5@gmail.com>
References: <3772A9FA-E252-415F-BC7E-FCBF81EACEC5@gmail.com>
Message-ID: <1380913072.50717.YahooMailNeo@web142605.mail.bf1.yahoo.com>



?labels1<- paste0("[",with(allPerms,paste(A,B,C,sep="|")),"]")
vals2<-as.matrix(cumsum(as.data.frame(t(allPerms))))
?dimnames(vals2)<- list(NULL,labels1)
?all.equal(vals,vals2)
#[1] TRUE
A.K.



----- Original Message -----
From: Keith S Weintraub <kw1958 at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Friday, October 4, 2013 2:38 PM
Subject: [R] Applying and labeling scenarios

Folks,

I have a working version of the code below for my "real world" problem. I was wondering if there was a better way to do this.

I have 3 sets of parameters and I want to iterate over all combinations and label the results.

Would some of the plyr tools make this easier?

# Input Scenarios
scens<-list(A=c(.2,.3), B= c(.2,.4), C=2:3)

# All combinations
allPerms<-expand.grid(scens)

# Create labels
labels<-sapply(1:nrow(allPerms), 
? ? ? ? ? ? ? function(x, y) paste0("[", paste0(y[x,], collapse = "|"), "]"), 
? ? ? ? ? ? ? allPerms)

# Simple example computation
vals<-sapply(1:nrow(allPerms), function(x, y) cumsum(t(y[x,])), allPerms)

# Apply labels to columns
colnames(vals)<-labels

# "Beautiful" output!
dput(vals)
structure(c(0.2, 0.4, 2.4, 0.3, 0.5, 2.5, 0.2, 0.6, 2.6, 0.3, 
0.7, 2.7, 0.2, 0.4, 3.4, 0.3, 0.5, 3.5, 0.2, 0.6, 3.6, 0.3, 0.7, 
3.7), .Dim = c(3L, 8L), .Dimnames = list(NULL, c("[0.2|0.2|2]", 
"[0.3|0.2|2]", "[0.2|0.4|2]", "[0.3|0.4|2]", "[0.2|0.2|3]", "[0.3|0.2|3]", 
"[0.2|0.4|3]", "[0.3|0.4|3]")))


Thanks for your time,
KW

--

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From mary.kindall at gmail.com  Fri Oct  4 21:16:41 2013
From: mary.kindall at gmail.com (Mary Kindall)
Date: Fri, 4 Oct 2013 15:16:41 -0400
Subject: [R] Why 'gbm' is not giving me error when I change the response
 from numeric to categorical?
Message-ID: <CANStr566N26+hG+nUjL=ew0FNNqghbu7no=-3Uy4r7=0eBuc_Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/b1db0674/attachment.pl>

From gunter.berton at gene.com  Fri Oct  4 21:26:31 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 4 Oct 2013 12:26:31 -0700
Subject: [R] Why 'gbm' is not giving me error when I change the response
 from numeric to categorical?
In-Reply-To: <CANStr566N26+hG+nUjL=ew0FNNqghbu7no=-3Uy4r7=0eBuc_Q@mail.gmail.com>
References: <CANStr566N26+hG+nUjL=ew0FNNqghbu7no=-3Uy4r7=0eBuc_Q@mail.gmail.com>
Message-ID: <CACk-te2LuXfmsem=D7E9kXYV=ENLQUV=LCjoiEKaxfxDLNV_TQ@mail.gmail.com>

"My question is, Is binarizing the response will have so much effect that it
does not find anythin useful in the predictors?"

Yes. Dichotomizing throws away most of the information in the data.
Which is why you shouldn't do it.

This is a statistics, not an R question, so any follow-up should be
posted on a statistical list like stats.stackexchange.com, not here.

-- Bert

On Fri, Oct 4, 2013 at 12:16 PM, Mary Kindall <mary.kindall at gmail.com> wrote:
> This reproducible example is from the help of 'gbm' in R.
>
> I ran the following code in R, and works fine as long as the response is
> numeric.  The problem starts when I convert the response from numeric to
> binary (0/1). It gives me an error.
>
> My question is, is converting the response from numeric to binary will have
> this much effect.
>
> Help page code:
>
> N <- 1000
> X1 <- runif(N)
> X2 <- 2*runif(N)
> X3 <- ordered(sample(letters[1:4],N,replace=TRUE),levels=letters[4:1])
> X4 <- factor(sample(letters[1:6],N,replace=TRUE))
> X5 <- factor(sample(letters[1:3],N,replace=TRUE))
> X6 <- 3*runif(N)
> mu <- c(-1,0,1,2)[as.numeric(X3)]
>
> SNR <- 10 # signal-to-noise ratio
> Y <- X1**1.5 + 2 * (X2**.5) + mu
> sigma <- sqrt(var(Y)/SNR)
> Y <- Y + rnorm(N,0,sigma)
>
> # introduce some missing values
> X1[sample(1:N,size=500)] <- NA
> X4[sample(1:N,size=300)] <- NA
>
> data <- data.frame(Y=Y,X1=X1,X2=X2,X3=X3,X4=X4,X5=X5,X6=X6)
>
> # fit initial model
> gbm1 <-
>   gbm(Y~X1+X2+X3+X4+X5+X6,         # formula
>       data=data,                   # dataset
>       var.monotone=c(0,0,0,0,0,0), # -1: monotone decrease,
>       # +1: monotone increase,
>       #  0: no monotone restrictions
>       distribution="gaussian",     # see the help for other choices
>       n.trees=1000,                # number of trees
>       shrinkage=0.05,              # shrinkage or learning rate,
>       # 0.001 to 0.1 usually work
>       interaction.depth=3,         # 1: additive model, 2: two-way
> interactions, etc.
>       bag.fraction = 0.5,          # subsampling fraction, 0.5 is probably
> best
>       train.fraction = 0.5,        # fraction of data for training,
>       # first train.fraction*N used for training
>       n.minobsinnode = 10,         # minimum total weight needed in each
> node
>       cv.folds = 3,                # do 3-fold cross-validation
>       keep.data=TRUE,              # keep a copy of the dataset with the
> object
>       verbose=FALSE)               # don't print out progress
>
> gbm1
> summary(gbm1)
>
>
> Now I slightly change the response variable to make it binary.
>
> Y[Y < mean(Y)] = 0   #My edit
> Y[Y >= mean(Y)] = 1  #My edit
> data <- data.frame(Y=Y,X1=X1,X2=X2,X3=X3,X4=X4,X5=X5,X6=X6)
> fmla = as.formula(factor(Y)~X1+X2+X3+X4+X5+X6) #My edit
>
> gbm2 <-
>   gbm(fmla,                        # formula
>       data=data,                   # dataset
>       distribution="bernoulli",     # My edit
>       n.trees=1000,                # number of trees
>       shrinkage=0.05,              # shrinkage or learning rate,
>       # 0.001 to 0.1 usually work
>       interaction.depth=3,         # 1: additive model, 2: two-way
> interactions, etc.
>       bag.fraction = 0.5,          # subsampling fraction, 0.5 is probably
> best
>       train.fraction = 0.5,        # fraction of data for training,
>       # first train.fraction*N used for training
>       n.minobsinnode = 10,         # minimum total weight needed in each
> node
>       cv.folds = 3,                # do 3-fold cross-validation
>       keep.data=TRUE,              # keep a copy of the dataset with the
> object
>       verbose=FALSE)               # don't print out progress
>
> gbm2
>
>
>> gbm2
> gbm(formula = fmla, distribution = "bernoulli", data = data,
>     n.trees = 1000, interaction.depth = 3, n.minobsinnode = 10,
>     shrinkage = 0.05, bag.fraction = 0.5, train.fraction = 0.5,
>     cv.folds = 3, keep.data = TRUE, verbose = FALSE)
> A gradient boosted model with bernoulli loss function.
> 1000 iterations were performed.
> The best cross-validation iteration was .
> The best test-set iteration was .
> Error in 1:n.trees : argument of length 0
>
>
> My question is, Is binarizing the response will have so much effect that it
> does not find anythin useful in the predictors?
>
> Thanks
>
> --
> -------------
> Mary Kindall
> Yorktown Heights, NY
> USA
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From marc_schwartz at me.com  Fri Oct  4 21:34:11 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 04 Oct 2013 14:34:11 -0500
Subject: [R] Why 'gbm' is not giving me error when I change the response
 from numeric to categorical?
In-Reply-To: <CANStr566N26+hG+nUjL=ew0FNNqghbu7no=-3Uy4r7=0eBuc_Q@mail.gmail.com>
References: <CANStr566N26+hG+nUjL=ew0FNNqghbu7no=-3Uy4r7=0eBuc_Q@mail.gmail.com>
Message-ID: <633DC75C-4DE7-455F-8C6E-09B3B3B391DA@me.com>


On Oct 4, 2013, at 2:16 PM, Mary Kindall <mary.kindall at gmail.com> wrote:

> This reproducible example is from the help of 'gbm' in R.
> 
> I ran the following code in R, and works fine as long as the response is
> numeric.  The problem starts when I convert the response from numeric to
> binary (0/1). It gives me an error.
> 
> My question is, is converting the response from numeric to binary will have
> this much effect.
> 
> Help page code:
> 
> N <- 1000
> X1 <- runif(N)
> X2 <- 2*runif(N)
> X3 <- ordered(sample(letters[1:4],N,replace=TRUE),levels=letters[4:1])
> X4 <- factor(sample(letters[1:6],N,replace=TRUE))
> X5 <- factor(sample(letters[1:3],N,replace=TRUE))
> X6 <- 3*runif(N)
> mu <- c(-1,0,1,2)[as.numeric(X3)]
> 
> SNR <- 10 # signal-to-noise ratio
> Y <- X1**1.5 + 2 * (X2**.5) + mu
> sigma <- sqrt(var(Y)/SNR)
> Y <- Y + rnorm(N,0,sigma)
> 
> # introduce some missing values
> X1[sample(1:N,size=500)] <- NA
> X4[sample(1:N,size=300)] <- NA
> 
> data <- data.frame(Y=Y,X1=X1,X2=X2,X3=X3,X4=X4,X5=X5,X6=X6)
> 
> # fit initial model
> gbm1 <-
>  gbm(Y~X1+X2+X3+X4+X5+X6,         # formula
>      data=data,                   # dataset
>      var.monotone=c(0,0,0,0,0,0), # -1: monotone decrease,
>      # +1: monotone increase,
>      #  0: no monotone restrictions
>      distribution="gaussian",     # see the help for other choices
>      n.trees=1000,                # number of trees
>      shrinkage=0.05,              # shrinkage or learning rate,
>      # 0.001 to 0.1 usually work
>      interaction.depth=3,         # 1: additive model, 2: two-way
> interactions, etc.
>      bag.fraction = 0.5,          # subsampling fraction, 0.5 is probably
> best
>      train.fraction = 0.5,        # fraction of data for training,
>      # first train.fraction*N used for training
>      n.minobsinnode = 10,         # minimum total weight needed in each
> node
>      cv.folds = 3,                # do 3-fold cross-validation
>      keep.data=TRUE,              # keep a copy of the dataset with the
> object
>      verbose=FALSE)               # don't print out progress
> 
> gbm1
> summary(gbm1)
> 
> 
> Now I slightly change the response variable to make it binary.
> 
> Y[Y < mean(Y)] = 0   #My edit
> Y[Y >= mean(Y)] = 1  #My edit
> data <- data.frame(Y=Y,X1=X1,X2=X2,X3=X3,X4=X4,X5=X5,X6=X6)
> fmla = as.formula(factor(Y)~X1+X2+X3+X4+X5+X6) #My edit
> 
> gbm2 <-
>  gbm(fmla,                        # formula
>      data=data,                   # dataset
>      distribution="bernoulli",     # My edit
>      n.trees=1000,                # number of trees
>      shrinkage=0.05,              # shrinkage or learning rate,
>      # 0.001 to 0.1 usually work
>      interaction.depth=3,         # 1: additive model, 2: two-way
> interactions, etc.
>      bag.fraction = 0.5,          # subsampling fraction, 0.5 is probably
> best
>      train.fraction = 0.5,        # fraction of data for training,
>      # first train.fraction*N used for training
>      n.minobsinnode = 10,         # minimum total weight needed in each
> node
>      cv.folds = 3,                # do 3-fold cross-validation
>      keep.data=TRUE,              # keep a copy of the dataset with the
> object
>      verbose=FALSE)               # don't print out progress
> 
> gbm2
> 
> 
>> gbm2
> gbm(formula = fmla, distribution = "bernoulli", data = data,
>    n.trees = 1000, interaction.depth = 3, n.minobsinnode = 10,
>    shrinkage = 0.05, bag.fraction = 0.5, train.fraction = 0.5,
>    cv.folds = 3, keep.data = TRUE, verbose = FALSE)
> A gradient boosted model with bernoulli loss function.
> 1000 iterations were performed.
> The best cross-validation iteration was .
> The best test-set iteration was .
> Error in 1:n.trees : argument of length 0
> 
> 
> My question is, Is binarizing the response will have so much effect that it
> does not find anythin useful in the predictors?
> 
> Thanks



Sure, it's possible. See this page for a good overview of why you should not dichotomize continuous data:

  http://biostat.mc.vanderbilt.edu/wiki/Main/CatContinuous

Regards,

Marc Schwartz


From pdalgd at gmail.com  Fri Oct  4 21:35:03 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 4 Oct 2013 21:35:03 +0200
Subject: [R] Why 'gbm' is not giving me error when I change the response
	from numeric to categorical?
In-Reply-To: <CANStr566N26+hG+nUjL=ew0FNNqghbu7no=-3Uy4r7=0eBuc_Q@mail.gmail.com>
References: <CANStr566N26+hG+nUjL=ew0FNNqghbu7no=-3Uy4r7=0eBuc_Q@mail.gmail.com>
Message-ID: <7A7662A6-5A5F-4D19-8080-193D857023A3@gmail.com>


On Oct 4, 2013, at 21:16 , Mary Kindall wrote:

> Y[Y < mean(Y)] = 0   #My edit
> Y[Y >= mean(Y)] = 1  #My edit

I have no clue about gbm, but I don't think the above does what I think you think it does. 

Y <- as.integer(Y >= mean(Y)) 

might be closer to the mark.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From marc_schwartz at me.com  Fri Oct  4 21:50:26 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 04 Oct 2013 14:50:26 -0500
Subject: [R] Why 'gbm' is not giving me error when I change the response
 from numeric to categorical?
In-Reply-To: <7A7662A6-5A5F-4D19-8080-193D857023A3@gmail.com>
References: <CANStr566N26+hG+nUjL=ew0FNNqghbu7no=-3Uy4r7=0eBuc_Q@mail.gmail.com>
	<7A7662A6-5A5F-4D19-8080-193D857023A3@gmail.com>
Message-ID: <76DA8733-4DFF-4328-964F-A94959D6E43C@me.com>


On Oct 4, 2013, at 2:35 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> 
> On Oct 4, 2013, at 21:16 , Mary Kindall wrote:
> 
>> Y[Y < mean(Y)] = 0   #My edit
>> Y[Y >= mean(Y)] = 1  #My edit
> 
> I have no clue about gbm, but I don't think the above does what I think you think it does. 
> 
> Y <- as.integer(Y >= mean(Y)) 
> 
> might be closer to the mark.


Good catch Peter! I didn't pay attention to that initially.

Here is an example:

set.seed(1)
Y <- rnorm(10)

> Y
 [1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078 -0.8204684
 [7]  0.4874291  0.7383247  0.5757814 -0.3053884

> mean(Y)
[1] 0.1322028

Before changing Y:

> Y[Y < mean(Y)]
[1] -0.6264538 -0.8356286 -0.8204684 -0.3053884

> Y[Y >= mean(Y)]
[1] 0.1836433 1.5952808 0.3295078 0.4874291 0.7383247 0.5757814


However, the incantation that Mary is using, which calculates mean(Y) separately in each call, results in:

Y[Y < mean(Y)]  = 0

> Y
 [1] 0.0000000 0.1836433 0.0000000 1.5952808 0.3295078 0.0000000
 [7] 0.4874291 0.7383247 0.5757814 0.0000000


# mean(Y) is no longer the original value from above
> mean(Y)
[1] 0.3909967


Thus:

Y[Y >= mean(Y)]  = 1

> Y
 [1] 0.0000000 0.1836433 0.0000000 1.0000000 0.3295078 0.0000000
 [7] 1.0000000 1.0000000 1.0000000 0.0000000


Some of the values in Y do not change because the threshold for modifying the values changed as a result of the recalculation of the mean after the first set of values in Y have changed. As Peter noted, you don't end up with a dichotomous vector.

Using Peter's method:

Y <- as.integer(Y >= mean(Y)) 
> Y
 [1] 0 1 0 1 1 0 1 1 1 0


That being said, the original viewpoint stands, which is to not do this due to loss of information.

Regards,

Marc Schwartz


From aline.frank at wsl.ch  Fri Oct  4 22:23:48 2013
From: aline.frank at wsl.ch (aline.frank at wsl.ch)
Date: Fri, 4 Oct 2013 22:23:48 +0200
Subject: [R] SSweibull() : problems with step factor and singular gradient
Message-ID: <OF007A9AF8.4E1C652D-ONC1257BFA.00700ACD-C1257BFA.00700AD2@wsl.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/71fd9eb8/attachment.pl>

From melsayed at students.kennesaw.edu  Fri Oct  4 18:51:09 2013
From: melsayed at students.kennesaw.edu (Mohamed Anany)
Date: Fri, 4 Oct 2013 12:51:09 -0400
Subject: [R] Web Scraping
Message-ID: <CAFA+-=bY50P=sqqV=jp4+9siYQsp9KPAPmRfmbUJPETTozXgRg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/fb24282d/attachment.pl>

From ireneruberto at yahoo.it  Fri Oct  4 18:14:29 2013
From: ireneruberto at yahoo.it (irene)
Date: Fri, 4 Oct 2013 09:14:29 -0700 (PDT)
Subject: [R] String substitution
In-Reply-To: <1380833396.66540.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1380831333950-4677541.post@n4.nabble.com>
	<1380833396.66540.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1380903231.48923.YahooMailNeo@web171402.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/44dca2d7/attachment.pl>

From smartpink111 at yahoo.com  Fri Oct  4 21:14:53 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 4 Oct 2013 12:14:53 -0700 (PDT)
Subject: [R] Subsetting Timestamped data
In-Reply-To: <1380905373.93702.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <20131004160335.Horde.M-GXYM1vlIJSTtjHyfFVKUA@webmail.bath.ac.uk>
	<1380905373.93702.YahooMailNeo@web142602.mail.bf1.yahoo.com> 
Message-ID: <1380914093.21119.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

May be this helps:

set.seed(45)
df1<- data.frame(datetime=as.POSIXct("2011-05-25",tz="GMT")+0:200*30*60,value=sample(1:40,201,replace=TRUE),value2= sample(45:90,201,replace=TRUE))
?df2<- df1[ave(1:nrow(df1),as.Date(df1[,1]),FUN=length)==48,]
?dim(df2)
#[1] 192?? 3

#or
library(plyr)
df3<-df1[ddply(df1,.(as.Date(datetime)),mutate,Ldt=length(datetime)==48)$Ldt,] 
?identical(df3,df2)
#[1] TRUE


A.K.



----- Original Message -----
From: "aj409 at bath.ac.uk" <aj409 at bath.ac.uk>
To: r-help at r-project.org
Cc: 
Sent: Friday, October 4, 2013 11:03 AM
Subject: [R] Subsetting Timestamped data


Hi,

I have a data frame, data, containing two columns: one- the TimeStamp? 
(formatted using data$TimeStamp <-? 
as.POSTIXct(as.character(data$TimeStamp), format = "%d/%m/%Y %H:%M") )? 
and two- the data value.

The data frame has been read from a .csv file and should contain 48? 
values for each day of the year (values sampled at 30 minute? 
intervals). However, there are only 15,948 observations i.e. only? 
approx 332 days worth of data. I therefore would like to remove any? 
days that do not contain the 48 values.

My question, how would I go about doing this?

Many thanks,

-A.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From kbannarm at hotmail.com  Fri Oct  4 23:23:54 2013
From: kbannarm at hotmail.com (Katherine Bannar-Martin)
Date: Fri, 4 Oct 2013 15:23:54 -0600
Subject: [R] function with loop that goes through columns of dataframes with
 different dimensions
Message-ID: <CAK69EQrT6wd2Pk9RW9Fom4heOhTPHgvBcFBqVrJGgDMzOc58zQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/29726df9/attachment.pl>

From rolf.turner at xtra.co.nz  Sat Oct  5 00:47:51 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sat, 05 Oct 2013 11:47:51 +1300
Subject: [R] quote a column of a dataframe by its name
In-Reply-To: <EF0F57ED352.0000093Djrkrideau@inbox.com>
References: <EF0F57ED352.0000093Djrkrideau@inbox.com>
Message-ID: <524F4597.5050405@xtra.co.nz>

On 10/05/13 05:15, John Kane wrote:
> X[,names(X)[4]]  works fine  for me.  I had never thought of doing this. Neat idea.

Perhaps I am being obtuse, but how would X[,names(X)[4]] differ from X[,4]?

     cheers,

     Rolf Turner


From fisher at plessthan.com  Sat Oct  5 00:50:47 2013
From: fisher at plessthan.com (Dennis Fisher)
Date: Fri, 4 Oct 2013 15:50:47 -0700
Subject: [R] Cannot read XPT file using foreign package
Message-ID: <8620B49D-740E-4990-ABE6-B385525B55AB@plessthan.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/83e8bd19/attachment.pl>

From fisher at plessthan.com  Sat Oct  5 02:01:03 2013
From: fisher at plessthan.com (Dennis Fisher)
Date: Fri, 4 Oct 2013 17:01:03 -0700
Subject: [R] Cannot read XPT file using foreign package
In-Reply-To: <524F539D.4040601@gmail.com>
References: <8620B49D-740E-4990-ABE6-B385525B55AB@plessthan.com>
	<524F539D.4040601@gmail.com>
Message-ID: <8FF6AE19-951A-4255-B7A2-1CAD6324F37A@plessthan.com>

Duncan

I looked at 
	support.sas.com/techsup/technote/ts140.pdf
and it is a bit difficult to decipher.  I then replaced the string "^@" in the file contents with "!".  There is some concordance with he sample text shown in support.sas.com/techsup/technote/ts140.pdf but I don't know exactly how much concordance is expected.  The time stamp in the file is today so I assume that the file was created today.  

You asked "why [I] think this is a file that follows the format" -- I did not make that assumption; I merely attempted to read an XPT file with read.xport and it failed.

Could there be an issue with the version of SAS (which appears to be 6.06) -- they are now up to version 9 (for Windows - I don't know the version # for UNIX).

Dennis


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com



On Oct 4, 2013, at 4:47 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 13-10-04 6:50 PM, Dennis Fisher wrote:
>> OS X 10.8
>> R 3.0.1
>> foreign 0.8-55 (2013-09-02)
>> 
>> Colleagues,
>> 
>> I received a SAS XPT file that I cannot read using the foreign package.
>> The command:
>> 	read.xport(FILENAME)
>> results in the following message:
>> 	Error in lookup.xport(file) : file not in SAS transfer format
>> I am able to read the file successfully using StatTransport so it appears that the file is OK.
>> 
>> When I examine the file using "more", the first few lines look like this:
>> !04Oct13:11:15:5904Oct13:11:15:59                                                                

>> HEADER RECORD*******MEMBER  HEADER RECORD!!!!!!!000000000000000001600000000140  

>> HEADER RECORD*******DSCRPTR HEADER RECORD!!!!!!!000000000000000000000000000000  

>> SAS     SAS     SASDATA 6.06    bsd4.2  !04Oct13:11:15:5904Oct13:11:15:59                                                                

>> HEADER RECORD*******NAMESTR HEADER RECORD!!!!!!!000000000500000000000000000000  

>> !^A!^H!^ASubject Subject                                 BEST    !^L!        !
>> !^A!^H!^BPeriod  Period                                  BEST    !^L!        !^H!
>> 
>> Of course, I can use StatTransport to write the file to another format.  However, I would like to understand why the foreign package is unable to process the file.
> 
> That file doesn't follow the documented format linked to from ?read.xport.  You'll have to ask SAS why their documentation is incorrect, or ask yourself why you think this file is a file that follows that format when it doesn't.
> 
> Duncan Murdoch
> 
> 


From klebyn at yahoo.com.br  Sat Oct  5 02:03:43 2013
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Fri, 04 Oct 2013 21:03:43 -0300
Subject: [R] trying to compile R in win 7 (with Rtools)
Message-ID: <524F575F.8060009@yahoo.com.br>

hello all,
I am trying to compile the R in Win7
and compiles one small part

but the script don't move from the 'base' directory to 'stats'

I installed the Rtools likee administrator
and call the terminal (MS-DOS) like administrator too.

if somebody can tell me any tips, I thank in advanced
cleber
#############################################


File LOG

http://klebyn.ploud.com/arquivo_log/log


C:\Rsrc>
C:\Rsrc>
C:\Rsrc>tar -xf R-3.0.2.tar.gz

C:\Rsrc>where basename cat cmp comm cp cut date diff du echo expr gzip 
ls makeinfo
C:\Rtools\bin\basename.exe
C:\Rtools\bin\cat.exe
C:\Rtools\bin\cmp.exe
C:\Rtools\bin\comm.exe
C:\Rtools\bin\cp.exe
C:\Rtools\bin\cut.exe
C:\Rtools\bin\date.exe
C:\Rtools\bin\diff.exe
C:\Rtools\bin\du.exe
C:\Rtools\bin\echo.exe
C:\Rtools\bin\expr.exe
C:\Rtools\bin\gzip.exe
C:\Rtools\bin\ls.exe
C:\Rtools\bin\makeinfo.exe
C:\Program Files (x86)\MiKTeX 2.9\miktex\bin\makeinfo.exe

C:\Rsrc>where mkdir mv rm rsync sed sort texindex touch uniq
C:\Rtools\bin\mkdir.exe
C:\Rtools\bin\mv.exe
C:\Rtools\bin\rm.exe
C:\Rtools\bin\rsync.exe
C:\Rtools\bin\sed.exe
C:\Rtools\bin\sort.exe
C:\Windows\System32\sort.exe
C:\Rtools\bin\texindex.exe
C:\Program Files (x86)\MiKTeX 2.9\miktex\bin\texindex.exe
C:\Rtools\bin\touch.exe
C:\Rtools\bin\uniq.exe

C:\Rsrc>sort --version
sort (GNU coreutils) 8.15
Packaged by Cygwin (8.15-1)
Copyright (C) 2012 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later 
<http://gnu.org/licenses/gpl.html>.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Written by Mike Haertel and Paul Eggert.

C:\Rsrc>cd R-3.0.2\src\gnuwin32
C:\Rsrc\R-3.0.2\src\gnuwin32>make all recommended > compilaR.log
#########################################################################
#########################################################################

http://klebyn.ploud.com/arquivo_log/log

#########################################################################
#########################################################################

connections.c: In function 'do_readbin':
connections.c:3759:8: warning: dereferencing type-punned pointer will 
break strict-aliasing rules [-Wstrict-aliasing]
connections.c:3761:8: warning: dereferencing type-punned pointer will 
break strict-aliasing rules [-Wstrict-aliasing]
connections.c:3769:4: warning: dereferencing type-punned pointer will 
break strict-aliasing rules [-Wstrict-aliasing]
connections.c:3784:4: warning: dereferencing type-punned pointer will 
break strict-aliasing rules [-Wstrict-aliasing]
connections.c:3788:4: warning: dereferencing type-punned pointer will 
break strict-aliasing rules [-Wstrict-aliasing]
pcre_exec.c: In function 'pcre_exec':
pcre_exec.c:7190:20: warning: 'match_partial' may be used uninitialized 
in this function [-Wuninitialized]
localtime.c: In function 'timesub.isra.2':
localtime.c:1407:5: warning: assuming signed overflow does not occur 
when assuming that (X + c) < X is always false [-Wstrict-overflow]
localtime.c:1411:8: warning: assuming signed overflow does not occur 
when assuming that (X - c) > X is always false [-Wstrict-overflow]
localtime.c: In function 'time2sub.constprop.10':
localtime.c:1566:8: warning: assuming signed overflow does not occur 
when assuming that (X + c) < X is always false [-Wstrict-overflow]
localtime.c:1581:5: warning: assuming signed overflow does not occur 
when assuming that (X + c) < X is always false [-Wstrict-overflow]
localtime.c:1593:9: warning: assuming signed overflow does not occur 
when assuming that (X + c) < X is always false [-Wstrict-overflow]
localtime.c:1599:8: warning: assuming signed overflow does not occur 
when assuming that (X - c) > X is always false [-Wstrict-overflow]
localtime.c:1619:5: warning: assuming signed overflow does not occur 
when assuming that (X - c) > X is always false [-Wstrict-overflow]
cannot create /tmp/R4428: directory nonexistent
mv: cannot stat `/tmp/R4428': No such file or directory
make[3]: *** [mkR1] Error 1
make[2]: *** [all] Error 2
make[1]: *** [R] Error 1
make: *** [all] Error 2

C:\Rsrc\R-3.0.2\src\gnuwin32>


From djnordlund at frontier.com  Sat Oct  5 02:45:39 2013
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Fri, 4 Oct 2013 17:45:39 -0700
Subject: [R] Cannot read XPT file using foreign package
In-Reply-To: <8FF6AE19-951A-4255-B7A2-1CAD6324F37A@plessthan.com>
References: <8620B49D-740E-4990-ABE6-B385525B55AB@plessthan.com><524F539D.4040601@gmail.com>
	<8FF6AE19-951A-4255-B7A2-1CAD6324F37A@plessthan.com>
Message-ID: <150B7EF5EB6C4D00A851179C449787DC@Aragorn>

There two different "transport" or "portable" file types that SAS creates: 1. using Proc CPORT
2. using the XPORT engine in a LIBNAME statement.

That may not mean much to a non-SAS user, but people often use 'xpt' as a file extension for both approaches.  If Proc CPORT was used to write the file, read.xport will not be able to read it.  read.xport only reads files written using the XPORT engine.

If you don't have access to SAS you will need to get whomever created the file to re-create it.  

Dan

Daniel Nordlund
Bothell, WA USA
 

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Dennis Fisher
> Sent: Friday, October 04, 2013 5:01 PM
> To: Duncan Murdoch; r-help at stat.math.ethz.ch
> Subject: Re: [R] Cannot read XPT file using foreign package
> 
> Duncan
> 
> I looked at
> 	support.sas.com/techsup/technote/ts140.pdf
> and it is a bit difficult to decipher.  I then replaced the string "^@" in
> the file contents with "!".  There is some concordance with he sample text
> shown in support.sas.com/techsup/technote/ts140.pdf but I don't know
> exactly how much concordance is expected.  The time stamp in the file is
> today so I assume that the file was created today.
> 
> You asked "why [I] think this is a file that follows the format" -- I did
> not make that assumption; I merely attempted to read an XPT file with
> read.xport and it failed.
> 
> Could there be an issue with the version of SAS (which appears to be 6.06)
> -- they are now up to version 9 (for Windows - I don't know the version #
> for UNIX).
> 
> Dennis
> 
> 
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
> 
> 
> 
> On Oct 4, 2013, at 4:47 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> 
> > On 13-10-04 6:50 PM, Dennis Fisher wrote:
> >> OS X 10.8
> >> R 3.0.1
> >> foreign 0.8-55 (2013-09-02)
> >>
> >> Colleagues,
> >>
> >> I received a SAS XPT file that I cannot read using the foreign package.
> >> The command:
> >> 	read.xport(FILENAME)
> >> results in the following message:
> >> 	Error in lookup.xport(file) : file not in SAS transfer format
> >> I am able to read the file successfully using StatTransport so it
> appears that the file is OK.
> >>
> >> When I examine the file using "more", the first few lines look like
> this:
> >> !04Oct13:11:15:5904Oct13:11:15:59
> 
> >> HEADER RECORD*******MEMBER  HEADER
> RECORD!!!!!!!000000000000000001600000000140
> 
> >> HEADER RECORD*******DSCRPTR HEADER
> RECORD!!!!!!!000000000000000000000000000000
> 
> >> SAS     SAS     SASDATA 6.06    bsd4.2
> !04Oct13:11:15:5904Oct13:11:15:59
> 
> >> HEADER RECORD*******NAMESTR HEADER
> RECORD!!!!!!!000000000500000000000000000000
> 
> >> !^A!^H!^ASubject Subject                                 BEST    !^L!
> !
> >> !^A!^H!^BPeriod  Period                                  BEST    !^L!
> !^H!
> >>
> >> Of course, I can use StatTransport to write the file to another format.
> However, I would like to understand why the foreign package is unable to
> process the file.
> >
> > That file doesn't follow the documented format linked to from
> ?read.xport.  You'll have to ask SAS why their documentation is incorrect,
> or ask yourself why you think this file is a file that follows that format
> when it doesn't.
> >
> > Duncan Murdoch
> >
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jwiley.psych at gmail.com  Sat Oct  5 03:02:09 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 4 Oct 2013 18:02:09 -0700
Subject: [R] trying to compile R in win 7 (with Rtools)
In-Reply-To: <524F575F.8060009@yahoo.com.br>
References: <524F575F.8060009@yahoo.com.br>
Message-ID: <CANz9Z_+r3tsB5agmq+uLSecpK5A6P0AqnvqhtvD5iBtTC69mjQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/0c096d5e/attachment.pl>

From klebyn at yahoo.com.br  Sat Oct  5 03:30:34 2013
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Fri, 04 Oct 2013 22:30:34 -0300
Subject: [R] trying to compile R in win 7 (with Rtools)
In-Reply-To: <524F6434.6000502@galaxysemi.com>
References: <524F575F.8060009@yahoo.com.br> <524F6434.6000502@galaxysemi.com>
Message-ID: <524F6BBA.40003@yahoo.com.br>

thanks.

I am logged in the MS-DOS.

I thought that cygwin is not necessary...
in cygwin terminal, when I type: "where sh"

CLEBER at pinkfloyd /cygdrive/c
$ where sh
C:\cygwin\bin\sh.exe
C:\Rtools\bin\sh.exe

so, I have two version of "sh"
and the cygwin will be priority...

I will make more test and to consider your sugestion of cygwin...

thanks

cleber



Em 04/10/2013 21:58, Tambellini William escreveu:
> Hi Cleber
>  It cant find /tmp which does not exist on standard win32 mount system.
>  Are you sure you dont have to call the "make all..." from the cygwin 
> bash ("cygwin terminal") and not the "msdos" pseudo terminal ?
> W.
>


From klebyn at yahoo.com.br  Sat Oct  5 03:46:19 2013
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Fri, 04 Oct 2013 22:46:19 -0300
Subject: [R] trying to compile R in win 7 (with Rtools)
In-Reply-To: <CANz9Z_+r3tsB5agmq+uLSecpK5A6P0AqnvqhtvD5iBtTC69mjQ@mail.gmail.com>
References: <524F575F.8060009@yahoo.com.br>
	<CANz9Z_+r3tsB5agmq+uLSecpK5A6P0AqnvqhtvD5iBtTC69mjQ@mail.gmail.com>
Message-ID: <524F6F6B.3030302@yahoo.com.br>


bingo!  :-)
I got one pass to advanced!

my TMP environment variable is:
%SystemRoot%\TEMP


thanks
cleber


Em 04/10/2013 22:02, Joshua Wiley escreveu:
> Hi Cleber,
>
> You need to set TMPDIR to a valid directory, the default /tmp/ does 
> not work on Windows.
>
> From the cmd shell:
>
> set TMPDIR=C:/TMP
>
> for example
>
> and then run make all recommended
>
> Cheers,
>
> Josh
>
>


From istazahn at gmail.com  Sat Oct  5 03:58:33 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 4 Oct 2013 21:58:33 -0400
Subject: [R] Web Scraping
In-Reply-To: <CAFA+-=bY50P=sqqV=jp4+9siYQsp9KPAPmRfmbUJPETTozXgRg@mail.gmail.com>
References: <CAFA+-=bY50P=sqqV=jp4+9siYQsp9KPAPmRfmbUJPETTozXgRg@mail.gmail.com>
Message-ID: <CA+vqiLHPsgZ1+fz7RkF_i1nTB=2TjnA0JcvqbuNjC67hoSXdTA@mail.gmail.com>

Hi,

I have a short demo at https://gist.github.com/izahn/5785265 that
might get you started.

Best,
Ista

On Fri, Oct 4, 2013 at 12:51 PM, Mohamed Anany
<melsayed at students.kennesaw.edu> wrote:
> Hello everybody,
> I just started using R and I'm presenting a poster for R day at Kennesaw
> State University and I really need some help in terms of web scraping.
> I'm trying to extract used cars data from www.cars.com to include the
> mileage, year, model, make, price, CARFAX availability and Technology
> package availability. I've done some research, and everything points to the
> XML package and RCurl package. I also got my hands on a function that would
> capture all the text in the web page and store as a huge character vector.
> I've never done data mining before so when i read the help documents on the
> packages i mentioned earlier is like reading Chinese. I would appreciate it
> if you guide me through this process of data extraction.
> Here's an example of what the data would look like:
>
> Cost    Year    Mileage    Tech    CARFAX    Make      Model
> $32000 1999   57,987      1         FREE        Audi       A4
>
> Here's the link to the search:-
> http://www.cars.com/for-sale/searchresults.action?stkTyp=U&tracktype=usedcc&mkId=20049&AmbMkId=20049&AmbMkNm=Audi&make=Audi&AmbMdNm=A4&model=A4&mdId=20596&AmbMdId=20596&rd=100&zc=30062&searchSource=QUICK_FORM&enableSeo=1
>
> I'm not expecting you to write the whole code for me, but just some
> guidance and where to start and what functions would be useful in my
> situation.
> Thanks a lot anyway.
>
> Regards,
> M. Samir Anany
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Oct  5 01:51:12 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 4 Oct 2013 16:51:12 -0700 (PDT)
Subject: [R] function with loop that goes through columns of dataframes
	with different dimensions
In-Reply-To: <CAK69EQrT6wd2Pk9RW9Fom4heOhTPHgvBcFBqVrJGgDMzOc58zQ@mail.gmail.com>
References: <CAK69EQrT6wd2Pk9RW9Fom4heOhTPHgvBcFBqVrJGgDMzOc58zQ@mail.gmail.com>
Message-ID: <1380930672.39703.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

May be this helps:
set.seed(24)
dat1<- as.data.frame(matrix(sample(1:50,100,replace=TRUE),10,10))
colnames(dat1)<- paste0("Col",1:ncol(dat1))

rnd.data1 <- function(x,n,ColSub,ColIndex=FALSE){
?library(matrixStats)
?if(ColIndex){
??? index <- seq_len(ncol(x))%in% ColSub
? Mins1 <- colMins(x[index])
? Maxs1 <- colMaxs(x[index])
?library(data.table)
?res <- sapply(seq_along(Mins1),function(i) runif(n, Mins1[i],Maxs1[i]))
? colnames(res)<- colnames(x)[index]
res <- data.table(res) 
? }
?else{
?Mins1 <- colMins(x)
?Maxs1 <- colMaxs(x)
?res <- sapply(seq_along(Mins1),function(i) runif(n, Mins1[i],Maxs1[i]))
?colnames(res) <- colnames(x)
?res <- data.table(res)
?}
res
?}
?rnd.data1(dat1,3)
#?????? Col1????? Col2????? Col3???? Col4????? Col5???? Col6???? Col7????? Col8
#1: 21.93711 17.314480? 7.351077 28.05296? 3.485837 27.97173 29.70568 19.273547
#2: 14.58832? 5.026405 36.467826 43.04324 19.002031 29.12006 14.61867? 4.809799
#3: 35.23000 17.353508 24.795010 18.65929 19.331303 16.85060 24.13479 49.966598
#?????? Col9??? Col10
#1: 14.90463 40.22131
#2: 16.03714 22.42686
#3: 32.74977 35.68602
?rnd.data1(dat1,3,c(2,5),TRUE)
#?????? Col2????? Col5
#1: 26.87589 22.872162
#2: 19.78380? 5.002566
#3: 37.43138 13.187147
?rnd.data1(dat1,3,c(2,5,8),TRUE)
#?????? Col2???? Col5???? Col8
#1: 39.63718 19.27199 49.86884
#2: 23.84264 14.19576 42.45117
#3: 41.13644 13.45054 36.48446


A.K.




----- Original Message -----
From: Katherine Bannar-Martin <kbannarm at hotmail.com>
To: r-help at r-project.org
Cc: 
Sent: Friday, October 4, 2013 5:23 PM
Subject: [R] function with loop that goes through columns of dataframes with different dimensions

Writing loops are the bane of my existence. I have this function, which
works:

rnd.data<-function(x){ min.x<-min(x[,2]) max.x<-max(x[,2])
min.y<-min(x[,3]) max.y<-max(x[,3]) data.table(x = runif(34, min.x,
max.x))[, y := runif(34, min.y, max.y)] }

it's purpose is to simulate data within parameters that are dependent on
the column of the dataframe in question for the first data set I wrote it
for had only 2 columns I wanted to simulate samples for however i have
additional dataframes with different numbers of columns ideally i would
write one function with a for loop that could compute samples for all
dataframes I want to input as I need to simulate more than 1000 samples per
dataframe

I tired manipulating the beginning to read as: rnd2.data<-function(x){
n<-dim(x)[2] for(i in 1:n){ if(n > 3){ but then got stuck as to what to do
next

Any help would be greatly appreciated Thanks!

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From william.tambellini at galaxysemi.com  Sat Oct  5 02:58:28 2013
From: william.tambellini at galaxysemi.com (Tambellini William)
Date: Fri, 04 Oct 2013 17:58:28 -0700
Subject: [R] trying to compile R in win 7 (with Rtools)
In-Reply-To: <524F575F.8060009@yahoo.com.br>
References: <524F575F.8060009@yahoo.com.br>
Message-ID: <524F6434.6000502@galaxysemi.com>

Hi Cleber
  It cant find /tmp which does not exist on standard win32 mount system.
  Are you sure you dont have to call the "make all..." from the cygwin 
bash ("cygwin terminal") and not the "msdos" pseudo terminal ?
W.


Le 04/10/2013 17:03, Cleber N.Borges a ?crit :
> hello all,
> I am trying to compile the R in Win7
> and compiles one small part
>
> but the script don't move from the 'base' directory to 'stats'
>
> I installed the Rtools likee administrator
> and call the terminal (MS-DOS) like administrator too.
>
> if somebody can tell me any tips, I thank in advanced
> cleber
> #############################################
>
>
> File LOG
>
> http://klebyn.ploud.com/arquivo_log/log
>
>
> C:\Rsrc>
> C:\Rsrc>
> C:\Rsrc>tar -xf R-3.0.2.tar.gz
>
> C:\Rsrc>where basename cat cmp comm cp cut date diff du echo expr gzip 
> ls makeinfo
> C:\Rtools\bin\basename.exe
> C:\Rtools\bin\cat.exe
> C:\Rtools\bin\cmp.exe
> C:\Rtools\bin\comm.exe
> C:\Rtools\bin\cp.exe
> C:\Rtools\bin\cut.exe
> C:\Rtools\bin\date.exe
> C:\Rtools\bin\diff.exe
> C:\Rtools\bin\du.exe
> C:\Rtools\bin\echo.exe
> C:\Rtools\bin\expr.exe
> C:\Rtools\bin\gzip.exe
> C:\Rtools\bin\ls.exe
> C:\Rtools\bin\makeinfo.exe
> C:\Program Files (x86)\MiKTeX 2.9\miktex\bin\makeinfo.exe
>
> C:\Rsrc>where mkdir mv rm rsync sed sort texindex touch uniq
> C:\Rtools\bin\mkdir.exe
> C:\Rtools\bin\mv.exe
> C:\Rtools\bin\rm.exe
> C:\Rtools\bin\rsync.exe
> C:\Rtools\bin\sed.exe
> C:\Rtools\bin\sort.exe
> C:\Windows\System32\sort.exe
> C:\Rtools\bin\texindex.exe
> C:\Program Files (x86)\MiKTeX 2.9\miktex\bin\texindex.exe
> C:\Rtools\bin\touch.exe
> C:\Rtools\bin\uniq.exe
>
> C:\Rsrc>sort --version
> sort (GNU coreutils) 8.15
> Packaged by Cygwin (8.15-1)
> Copyright (C) 2012 Free Software Foundation, Inc.
> License GPLv3+: GNU GPL version 3 or later 
> <http://gnu.org/licenses/gpl.html>.
> This is free software: you are free to change and redistribute it.
> There is NO WARRANTY, to the extent permitted by law.
>
> Written by Mike Haertel and Paul Eggert.
>
> C:\Rsrc>cd R-3.0.2\src\gnuwin32
> C:\Rsrc\R-3.0.2\src\gnuwin32>make all recommended > compilaR.log
> #########################################################################
> #########################################################################
>
> http://klebyn.ploud.com/arquivo_log/log
>
> #########################################################################
> #########################################################################
>
> connections.c: In function 'do_readbin':
> connections.c:3759:8: warning: dereferencing type-punned pointer will 
> break strict-aliasing rules [-Wstrict-aliasing]
> connections.c:3761:8: warning: dereferencing type-punned pointer will 
> break strict-aliasing rules [-Wstrict-aliasing]
> connections.c:3769:4: warning: dereferencing type-punned pointer will 
> break strict-aliasing rules [-Wstrict-aliasing]
> connections.c:3784:4: warning: dereferencing type-punned pointer will 
> break strict-aliasing rules [-Wstrict-aliasing]
> connections.c:3788:4: warning: dereferencing type-punned pointer will 
> break strict-aliasing rules [-Wstrict-aliasing]
> pcre_exec.c: In function 'pcre_exec':
> pcre_exec.c:7190:20: warning: 'match_partial' may be used 
> uninitialized in this function [-Wuninitialized]
> localtime.c: In function 'timesub.isra.2':
> localtime.c:1407:5: warning: assuming signed overflow does not occur 
> when assuming that (X + c) < X is always false [-Wstrict-overflow]
> localtime.c:1411:8: warning: assuming signed overflow does not occur 
> when assuming that (X - c) > X is always false [-Wstrict-overflow]
> localtime.c: In function 'time2sub.constprop.10':
> localtime.c:1566:8: warning: assuming signed overflow does not occur 
> when assuming that (X + c) < X is always false [-Wstrict-overflow]
> localtime.c:1581:5: warning: assuming signed overflow does not occur 
> when assuming that (X + c) < X is always false [-Wstrict-overflow]
> localtime.c:1593:9: warning: assuming signed overflow does not occur 
> when assuming that (X + c) < X is always false [-Wstrict-overflow]
> localtime.c:1599:8: warning: assuming signed overflow does not occur 
> when assuming that (X - c) > X is always false [-Wstrict-overflow]
> localtime.c:1619:5: warning: assuming signed overflow does not occur 
> when assuming that (X - c) > X is always false [-Wstrict-overflow]
> cannot create /tmp/R4428: directory nonexistent
> mv: cannot stat `/tmp/R4428': No such file or directory
> make[3]: *** [mkR1] Error 1
> make[2]: *** [all] Error 2
> make[1]: *** [R] Error 1
> make: *** [all] Error 2
>
> C:\Rsrc\R-3.0.2\src\gnuwin32>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From theobroma22 at gmail.com  Sat Oct  5 03:21:19 2013
From: theobroma22 at gmail.com (franklin johnson)
Date: Fri, 4 Oct 2013 18:21:19 -0700
Subject: [R] make a file from four individual files. but keys can be missing
	among files.
Message-ID: <CAGRQPxGXhqXhb+q2LxKb+GmPQNRxZaP5+LcXGhi-hHZU9rjAQA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/b4c0d550/attachment.pl>

From klebyn at yahoo.com.br  Sat Oct  5 04:29:47 2013
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Fri, 04 Oct 2013 23:29:47 -0300
Subject: [R] trying to compile R in win 7 (with Rtools) ... tcl.h
In-Reply-To: <524F6F6B.3030302@yahoo.com.br>
References: <524F575F.8060009@yahoo.com.br>
	<CANz9Z_+r3tsB5agmq+uLSecpK5A6P0AqnvqhtvD5iBtTC69mjQ@mail.gmail.com>
	<524F6F6B.3030302@yahoo.com.br>
Message-ID: <524F799B.4000603@yahoo.com.br>

stop because
*had a stone in the middle of the way*
*in the middle of the way had a stone*
(by vinicius de moraes)
#########################

so, one more help? somebody? :-)

thanks...
cleber

building package 'tcltk'
making init.d from init.c
making tcltk.d from tcltk.c
making tcltk_win.d from tcltk_win.c
gcc  -I"../../../../include" -DNDEBUG -I "../../../../Tcl"/include 
-DWin32         -O3 -Wall  -std=gnu99 -mtune=core2 -c init.c -o init.o
In file included from init.c:22:0:
tcltk.h:23:17: fatal error: tcl.h: No such file or directory
compilation terminated.
make[4]: *** [init.o] Error 1
make[3]: *** [mksrc-win2] Error 1
make[2]: *** [all] Error 2
make[1]: *** [R] Error 1
make: *** [all] Error 2




Em 04/10/2013 22:46, Cleber N.Borges escreveu:
>
> bingo!  :-)
> I got one pass to advanced!
>
> my TMP environment variable is:
> %SystemRoot%\TEMP
>
>
> thanks
> cleber
>
>
> Em 04/10/2013 22:02, Joshua Wiley escreveu:
>> Hi Cleber,
>>
>> You need to set TMPDIR to a valid directory, the default /tmp/ does 
>> not work on Windows.
>>
>> From the cmd shell:
>>
>> set TMPDIR=C:/TMP
>>
>> for example
>>
>> and then run make all recommended
>>
>> Cheers,
>>
>> Josh
>>
>>


From jwiley.psych at gmail.com  Sat Oct  5 04:45:16 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 4 Oct 2013 19:45:16 -0700
Subject: [R] trying to compile R in win 7 (with Rtools) ... tcl.h
In-Reply-To: <524F799B.4000603@yahoo.com.br>
References: <524F575F.8060009@yahoo.com.br>
	<CANz9Z_+r3tsB5agmq+uLSecpK5A6P0AqnvqhtvD5iBtTC69mjQ@mail.gmail.com>
	<524F6F6B.3030302@yahoo.com.br> <524F799B.4000603@yahoo.com.br>
Message-ID: <CANz9Z_Kvq6c=24DgQSZn-Acbs8eZhjR8gwxegx+hG-2jzQvdpQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131004/ac3205eb/attachment.pl>

From smartpink111 at yahoo.com  Sat Oct  5 05:21:13 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 4 Oct 2013 20:21:13 -0700 (PDT)
Subject: [R] try to subset zoo dataset
Message-ID: <1380943273.17322.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:


library(zoo)
z2<- read.zoo(text="Date WBK_Last WBK_1d_Close
2003-01-03 13.88506???? 14.08276
2003-01-06 14.11254???? 13.88506
2003-01-07 14.07033???? 14.11254
2003-01-14 14.24165???? 14.30967
2003-01-22 14.28913???? 14.30563
2003-01-29 13.95664???? 14.16483
2007-01-01 14.87033???? 15.11254
2007-01-07 14.34165???? 14.50967
2007-01-22 12.24913???? 14.80563
2008-01-29 12.95664???? 14.26483",sep="",header=TRUE,FUN=as.Date,format="%Y-%m-%d")
library(xts)
?x1<- as.xts(z2)

x1["2007-01-01/2007-12-31"]
#?????????? WBK_Last WBK_1d_Close
#2007-01-01 14.87033???? 15.11254
#2007-01-07 14.34165???? 14.50967
#2007-01-22 12.24913???? 14.80563
?x1["2007-01-01/"]
#?????????? WBK_Last WBK_1d_Close
#2007-01-01 14.87033???? 15.11254
#2007-01-07 14.34165???? 14.50967
#2007-01-22 12.24913???? 14.80563
#2008-01-29 12.95664???? 14.26483


A.K.



Hi There, 

I have a zoo dataset with more 10-year daily price data. However, I only want data from a specific date onward. 

This is how my data looks like: 

? ? ? ? ? ? ? ? ?WBK_Last WBK_1d_Close 
2003-01-03 13.88506 ? ? 14.08276 
2003-01-06 14.11254 ? ? 13.88506 
2003-01-07 14.07033 ? ? 14.11254 
2003-01-14 14.24165 ? ? 14.30967 
2003-01-22 14.28913 ? ? 14.30563 
2003-01-29 13.95664 ? ? 14.16483 

However, I only want data from 2007-01-01 onward. 
I know I can use " prices[as.Date"2007-01-01"] " to find out the 
data of the starting date but I can't subset the dataset from that date. 

Thank you in advance. 
Any help will be appreciated.


From dwinsemius at comcast.net  Sat Oct  5 08:02:53 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 4 Oct 2013 23:02:53 -0700
Subject: [R] Not getting any result from 'gbm'?
In-Reply-To: <CANStr54zF4cYiw+M+QB1iPtOi_Akx2izAdaTB-H6Lb9fOYLQxA@mail.gmail.com>
References: <CANStr54zF4cYiw+M+QB1iPtOi_Akx2izAdaTB-H6Lb9fOYLQxA@mail.gmail.com>
Message-ID: <837563C0-9C28-4D22-A868-860262A0400B@comcast.net>


On Oct 3, 2013, at 3:07 PM, Mary Kindall wrote:

> In the reproducible example given below, why I am not getting any result
> with generalized boosted model (gbm).  Other methods does show me the
> desired result.
> In the example data file (attached) example.txt, the predictors x3 and x4
> are correlated with response Y.
> 
> 
> 
> tmpData = read.table("Desktop/example.txt", sep="\t",header=TRUE)
> head(tmpData)
> fmla = getTheFormulaFromDataFrame(tmpData)

> fmla = getTheFormulaFromDataFrame(tmpData)
Error: could not find function "getTheFormulaFromDataFrame"


> fmla
> gbm(fmla, distribution = "bernoulli", data = tmpData) #doesn't work
> 
> #All the following works
> bagging(fmla,  data=tmpData, control=control, coob=TRUE)
> rpart(fmla,  dat=tmpData, method = "class", control=control )
> glm(fmla, family="binomial", data = tmpData)
> 
> 
> Thanks
> 
> 
> 
> -- 
> -------------
> Mary Kindall
> Yorktown Heights, NY
> USA
> <example.txt>______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Sat Oct  5 09:18:27 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 5 Oct 2013 09:18:27 +0200
Subject: [R] quote a column of a dataframe by its name
In-Reply-To: <524F4597.5050405@xtra.co.nz>
References: <EF0F57ED352.0000093Djrkrideau@inbox.com>
	<524F4597.5050405@xtra.co.nz>
Message-ID: <F989E9F5-3198-4443-B5ED-C5E36064B5AB@gmail.com>


On Oct 5, 2013, at 00:47 , Rolf Turner wrote:

> On 10/05/13 05:15, John Kane wrote:
>> X[,names(X)[4]]  works fine  for me.  I had never thought of doing this. Neat idea.
> 
> Perhaps I am being obtuse, but how would X[,names(X)[4]] differ from X[,4]?

By answering the question in the Subject field?

(No-one intended to use it in production code. The mystery is that it - reportedly - threw an error for the original poster, but not for anyone else.)

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jim at bitwrit.com.au  Sat Oct  5 09:16:35 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 05 Oct 2013 17:16:35 +1000
Subject: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U) test
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5487CC37EE@GOLD.corp.lgc-group.com>
References: <CAKxRbrd0wXSjyrkfpRkZcr9=D6BnCurW_qwMEWa3b=h6SOJ7xw@mail.gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED5487C275ED@GOLD.corp.lgc-group.com>	<CAKxRbrf-ZqkizD00H=rKMTbg85zMdUgu3jSd_gLSint9jGxseA@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5487CC37EE@GOLD.corp.lgc-group.com>
Message-ID: <524FBCD3.2030304@bitwrit.com.au>

On 10/04/2013 11:34 PM, S Ellison wrote:
> ...
 >> Got it! I agree it should had been more obvious to me... :)
> I wouldn't feel too bad about that. I've spent most of the last 25 years discovering the hard way that statistics is very much a field where things are 'obvious' only _after_ you know the answer...
>
A fortune ("hindsight") if I ever saw one.

Jim


From ripley at stats.ox.ac.uk  Sat Oct  5 09:57:38 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 05 Oct 2013 08:57:38 +0100
Subject: [R] trying to compile R in win 7 (with Rtools)
In-Reply-To: <CANz9Z_+r3tsB5agmq+uLSecpK5A6P0AqnvqhtvD5iBtTC69mjQ@mail.gmail.com>
References: <524F575F.8060009@yahoo.com.br>
	<CANz9Z_+r3tsB5agmq+uLSecpK5A6P0AqnvqhtvD5iBtTC69mjQ@mail.gmail.com>
Message-ID: <524FC672.3040301@stats.ox.ac.uk>

On 05/10/2013 02:02, Joshua Wiley wrote:
> Hi Cleber,
>
> You need to set TMPDIR to a valid directory, the default /tmp/ does not
> work on Windows.

May not work, more precisely.  Because package writers too often assume 
it does, I created c:/tmp (my Windows box has only one drive).

And of course, this is in the 'if all else fails read the manual, but at 
least do so before posting' category.  See the posting guide (footer of 
this and every R-help message).

This is documented at the top of 
http://cran.r-project.org/doc/manuals/r-release/R-admin.html#Building-the-core-files 
.

>
>>From the cmd shell:
>
> set TMPDIR=C:/TMP
>
> for example
>
> and then run make all recommended
>
> Cheers,
>
> Josh
>
[...]

>> PLEASE do read the posting guide http://www.R-project.org/**
>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.




-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tcmuigai at gmail.com  Sat Oct  5 10:52:02 2013
From: tcmuigai at gmail.com (Charles Thuo)
Date: Sat, 5 Oct 2013 11:52:02 +0300
Subject: [R] How to establish the order of a time series so as to fit ARIMA
Message-ID: <CAAJc=rMFEo6MuutfUiOfcXFC_Lk=O+88nyE+C6vYHeKvAp3umA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131005/e7910f26/attachment.pl>

From jrkrideau at inbox.com  Sat Oct  5 13:19:17 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 5 Oct 2013 03:19:17 -0800
Subject: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U) test
In-Reply-To: <524FBCD3.2030304@bitwrit.com.au>
References: <cakxrbrf-zqkizd00h=rkmtbg85zmdugu3jsd_glsint9jgxsea@mail.gmail.com>
	<a4e5a0b016b8cb41a485fc629b633ced5487cc37ee@gold.corp.lgc-group.com>
	<a4e5a0b016b8cb41a485fc629b633ced5487c275ed@gold.corp.lgc-group.com>
	<cakxrbrd0wxsjyrkfprkzcr9=d6bncurw_qwmewa3b=h6soj7xw@mail.gmail.com>
Message-ID: <F90CF5C6238.00000194jrkrideau@inbox.com>

+1

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jim at bitwrit.com.au
> Sent: Sat, 05 Oct 2013 17:16:35 +1000
> To: r-help at r-project.org
> Subject: Re: [R] Interpreting the result of a Wilcoxon (Mann-Whitney U)
> test
> 
> On 10/04/2013 11:34 PM, S Ellison wrote:
>> ...
>  >> Got it! I agree it should had been more obvious to me... :)
>> I wouldn't feel too bad about that. I've spent most of the last 25 years
>> discovering the hard way that statistics is very much a field where
>> things are 'obvious' only _after_ you know the answer...
>> 
> A fortune ("hindsight") if I ever saw one.
> 
> Jim
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From andreas at maunz.de  Sat Oct  5 14:12:43 2013
From: andreas at maunz.de (Andreas Maunz)
Date: Sat, 5 Oct 2013 14:12:43 +0200
Subject: [R] Heatmap with mouseover
Message-ID: <CAJHOUEN9yaLwi1m0Y4HJ4goVOn2gDD7cWhNkF9iaDmT0_d5JXA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131005/c3819395/attachment.pl>

From sarah.goslee at gmail.com  Sat Oct  5 17:20:37 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 5 Oct 2013 11:20:37 -0400
Subject: [R] make a file from four individual files. but keys can be
 missing among files.
In-Reply-To: <CAGRQPxGXhqXhb+q2LxKb+GmPQNRxZaP5+LcXGhi-hHZU9rjAQA@mail.gmail.com>
References: <CAGRQPxGXhqXhb+q2LxKb+GmPQNRxZaP5+LcXGhi-hHZU9rjAQA@mail.gmail.com>
Message-ID: <CAM_vjuk9A73pey7EWYpLo4Bbrz_5+PXQCuNpAxEE4_E2V0-jaw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131005/789638fb/attachment.pl>

From mary.kindall at gmail.com  Sat Oct  5 17:37:31 2013
From: mary.kindall at gmail.com (Mary Kindall)
Date: Sat, 5 Oct 2013 11:37:31 -0400
Subject: [R] Not getting any result from 'gbm'?
In-Reply-To: <837563C0-9C28-4D22-A868-860262A0400B@comcast.net>
References: <CANStr54zF4cYiw+M+QB1iPtOi_Akx2izAdaTB-H6Lb9fOYLQxA@mail.gmail.com>
	<837563C0-9C28-4D22-A868-860262A0400B@comcast.net>
Message-ID: <CANStr57+VoKqushcsovSE_szSKWoK-fwT8z3aJOHpi3pUqi09Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131005/4d14e18d/attachment.pl>

From mary.kindall at gmail.com  Sat Oct  5 18:14:54 2013
From: mary.kindall at gmail.com (Mary Kindall)
Date: Sat, 5 Oct 2013 12:14:54 -0400
Subject: [R] Why 'gbm' is not giving me error when I change the response
 from numeric to categorical?
In-Reply-To: <76DA8733-4DFF-4328-964F-A94959D6E43C@me.com>
References: <CANStr566N26+hG+nUjL=ew0FNNqghbu7no=-3Uy4r7=0eBuc_Q@mail.gmail.com>
	<7A7662A6-5A5F-4D19-8080-193D857023A3@gmail.com>
	<76DA8733-4DFF-4328-964F-A94959D6E43C@me.com>
Message-ID: <CANStr54As736FDywDQCKG7RZ5AddhUy7ydCVAfoHk=iLRjgAiA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131005/af5de31e/attachment.pl>

From dwarnold45 at suddenlink.net  Sat Oct  5 18:22:20 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Sat, 5 Oct 2013 09:22:20 -0700 (PDT)
Subject: [R] Verzani cover figure
Message-ID: <1380990139978-4677680.post@n4.nabble.com>

Hi,

Has anyone ever coded the figure on the cover of UsingR for Introductory
Statistics by John Verzani?

D.



--
View this message in context: http://r.789695.n4.nabble.com/Verzani-cover-figure-tp4677680.html
Sent from the R help mailing list archive at Nabble.com.


From lars52r at gmail.com  Sat Oct  5 22:17:27 2013
From: lars52r at gmail.com (Lars Bishop)
Date: Sat, 5 Oct 2013 16:17:27 -0400
Subject: [R] Permutation tests in {coin}
Message-ID: <CAO7OmOh_iobkDuP1OasQt3LJvR9U-70f2Oxb4fY40w0KQcW0vA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131005/518438d3/attachment.pl>

From dwinsemius at comcast.net  Sun Oct  6 00:02:16 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 5 Oct 2013 15:02:16 -0700
Subject: [R] Not getting any result from 'gbm'?
In-Reply-To: <CANStr57+VoKqushcsovSE_szSKWoK-fwT8z3aJOHpi3pUqi09Q@mail.gmail.com>
References: <CANStr54zF4cYiw+M+QB1iPtOi_Akx2izAdaTB-H6Lb9fOYLQxA@mail.gmail.com>
	<837563C0-9C28-4D22-A868-860262A0400B@comcast.net>
	<CANStr57+VoKqushcsovSE_szSKWoK-fwT8z3aJOHpi3pUqi09Q@mail.gmail.com>
Message-ID: <9FD27307-A2F0-4449-9E11-768174EF7096@comcast.net>


On Oct 5, 2013, at 8:37 AM, Mary Kindall wrote:

> Sorry David, 
> The formula that I use here is 
> 
> fmla = as.formula(Y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8)
> 
> Thanks 
> 
> 
> 
> 
> 
> On Sat, Oct 5, 2013 at 2:02 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> On Oct 3, 2013, at 3:07 PM, Mary Kindall wrote:
> 
> > In the reproducible example given below, why I am not getting any result
> > with generalized boosted model (gbm).  Other methods does show me the
> > desired result.
> > In the example data file (attached) example.txt, the predictors x3 and x4
> > are correlated with response Y.
> >
> >
> >
> > tmpData = read.table("Desktop/example.txt", sep="\t",header=TRUE)
> > head(tmpData)
> > fmla = getTheFormulaFromDataFrame(tmpData)
> 
> > fmla = getTheFormulaFromDataFrame(tmpData)
> Error: could not find function "getTheFormulaFromDataFrame"
> 
> 
> > fmla
> > gbm(fmla, distribution = "bernoulli", data = tmpData) #doesn't work

With the modifications proposed above I now get:

gbm(formula = fmla, distribution = "bernoulli", data = tmpData)
A gradient boosted model with bernoulli loss function.
100 iterations were performed.
There were 8 predictors of which 1 had non-zero influence.

So you need to do as suggested by the Posting Guide and report what sessionInfo() returns.

-- 
David.
> >
> > #All the following works
> > bagging(fmla,  data=tmpData, control=control, coob=TRUE)
> > rpart(fmla,  dat=tmpData, method = "class", control=control )
> > glm(fmla, family="binomial", data = tmpData)
> >
> >
> > Thanks
> >
> >
> >
> > --
> > -------------
> > Mary Kindall
> > Yorktown Heights, NY
> > USA
> > <example.txt>______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 
> 
> -- 
> -------------
> Mary Kindall 
> Yorktown Heights, NY
> USA

David Winsemius
Alameda, CA, USA


From robert.b.lynch at gmail.com  Sun Oct  6 03:11:37 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Sat, 5 Oct 2013 18:11:37 -0700
Subject: [R] trouble with nlme: Error in MEEM() : Singularity in backsolve
 at level 0, block 1
Message-ID: <CACYeG1jc-YD3fbtpe0A1YmkzAX_QbSojf8hiy6kqhWJDH8-8NA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131005/ecdcb2fe/attachment.pl>

From surabhiraj8prn at gmail.com  Sat Oct  5 18:07:20 2013
From: surabhiraj8prn at gmail.com (surabhi suhani)
Date: Sat, 5 Oct 2013 21:37:20 +0530
Subject: [R]  CRAN mirror for R in India: new one at WBUT,
 how do we get listed in the CRAN website?
Message-ID: <CAF+H4p+rmKcu5n1dGh+Z=PO3E6525FhFbWwf=Jo_acZMhQtvWw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131005/c051a8fb/attachment.pl>

From surabhiraj8prn at gmail.com  Sat Oct  5 18:15:18 2013
From: surabhiraj8prn at gmail.com (surabhi suhani)
Date: Sat, 5 Oct 2013 21:45:18 +0530
Subject: [R]  CRAN mirror for R in India: new one at WBUT,
 how do we get listed in the CRAN website?
Message-ID: <CAF+H4p+3mmMrEEGUTt43ieWt1jCmW0zj03vY2hDVQ5yy2TyWzQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131005/64a32587/attachment.pl>

From taavi at 7blaze.com  Sat Oct  5 18:27:00 2013
From: taavi at 7blaze.com (Taavi Ilves)
Date: Sat, 5 Oct 2013 19:27:00 +0300
Subject: [R] Help with effective diameter calculation
Message-ID: <CAPfG3h2zvVrEvtOZx_tt9C5-Vh_NwCgDtGSmvjHpH32_kt+Zqw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131005/2c36e05a/attachment.pl>

From ekyoungs at ncsu.edu  Sat Oct  5 23:41:26 2013
From: ekyoungs at ncsu.edu (Elsa Youngsteadt)
Date: Sat, 5 Oct 2013 17:41:26 -0400
Subject: [R] goodness of fit for nonlinear quantile regression
Message-ID: <CALD4PxjacG3JdjZ=pJABk890xTbwrijAfuLvO0OEsJuC11Vm_w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131005/d27eb947/attachment.pl>

From klebyn at yahoo.com.br  Sun Oct  6 01:42:10 2013
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Sat, 05 Oct 2013 20:42:10 -0300
Subject: [R] trying to compile R in win 7 (with Rtools) ... (bitmapdll -
 png.h )
In-Reply-To: <CANz9Z_Kvq6c=24DgQSZn-Acbs8eZhjR8gwxegx+hG-2jzQvdpQ@mail.gmail.com>
References: <524F575F.8060009@yahoo.com.br>	<CANz9Z_+r3tsB5agmq+uLSecpK5A6P0AqnvqhtvD5iBtTC69mjQ@mail.gmail.com>	<524F6F6B.3030302@yahoo.com.br>	<524F799B.4000603@yahoo.com.br>
	<CANz9Z_Kvq6c=24DgQSZn-Acbs8eZhjR8gwxegx+hG-2jzQvdpQ@mail.gmail.com>
Message-ID: <5250A3D2.8030904@yahoo.com.br>

I tried to follow the intrusions in
http://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Building-the-bitmap-files
when I type

make bitmapdll (in gnuwin directory)
or make (in gnuwin/bitmap dir)

the libpng and libjpeg seems to compile
but libtiff reclaims by png.h file.

I set in the MkRules.local:
-----------------------------------------
# optional overrides for making bitmapdll: names of source directories
JPEGDIR = C:/Rsrc/R-patched/src/gnuwin32/bitmap/jpeg-9
PNGDIR  = C:/Rsrc/R-patched/src/gnuwin32/bitmap/libpng
TIFFDIR =  C:/Rsrc/R-patched/src/gnuwin32/bitmap/libtiff

The error snippet:
-----------------------
make CC='gcc -std=gnu99 -m32' AR='ar' RANLIB=ranlib -C 
C:/Rsrc/R-patched/src/gnuwin32/bitmap/libtiff -f ../Makefile.tiff 
JPEGDIR=C:/Rsrc/R-patched/src/gnuwin32/bitmap/jpeg-9
gcc -std=gnu99 -m32  -DHAVE_PNG -DHAVE_JPEG -DHAVE_TIFF -I. 
-I../../extra/zlib -I./C:/Rsrc/R-patched/src/gnuwin32/bitmap/libpng 
-IC:/Rsrc/R-patched/src/gnuwin32/bitmap/jpeg-9 
-I./C:/Rsrc/R-patched/src/gnuwin32/bitmap/libtiff -I../../include -O3 
-Wall -pedantic    -c rbitmap.c -o rbitmap.o
rbitmap.c:53:17: fatal error: png.h: No such file or directory
compilation terminated.
make[1]: *** [rbitmap.o] Error 1
make: *** [all] Error 2


so, I don't understand the error because
*The png.h is in C:/Rsrc/R-patched/src/gnuwin32/bitmap/libpng*

I thank for some help

cleber


From dwinsemius at comcast.net  Sun Oct  6 09:21:24 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 6 Oct 2013 00:21:24 -0700
Subject: [R] CRAN mirror for R in India: new one at WBUT,
	how do we get listed in the CRAN website?
In-Reply-To: <CAF+H4p+3mmMrEEGUTt43ieWt1jCmW0zj03vY2hDVQ5yy2TyWzQ@mail.gmail.com>
References: <CAF+H4p+3mmMrEEGUTt43ieWt1jCmW0zj03vY2hDVQ5yy2TyWzQ@mail.gmail.com>
Message-ID: <724C1AD3-6102-4E62-8CB8-4D1B8706C059@comcast.net>


Well, first off, you ought to learn to post in plain text as requested in the Posting Guide. After you have mastered that rather simple task, you might consider searching  with Google for "setting up a cran mirror" which for me anyway produces this as the first hit:

http://cran.r-project.org/mirror-howto.html

One does wonders about the standard admonition:  learn to crawl before attempting to walk.


On Oct 5, 2013, at 9:15 AM, surabhi suhani wrote:

> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From soumitrodey1 at gmail.com  Sun Oct  6 09:58:27 2013
From: soumitrodey1 at gmail.com (Soumitro Dey)
Date: Sun, 6 Oct 2013 02:58:27 -0500
Subject: [R] power law plot
Message-ID: <CAJ+M79kaOe4PuN8NiXiRdhYHNUDD_NdZT2uBOUq29-9OE=LvWQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131006/f6075e43/attachment.pl>

From smartpink111 at yahoo.com  Sun Oct  6 15:29:06 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 6 Oct 2013 06:29:06 -0700 (PDT)
Subject: [R] Create a categorical variable from numeric column
In-Reply-To: <1381019939.82460.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1381019417.37789.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1381019939.82460.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1381066146.63858.YahooMailNeo@web142602.mail.bf1.yahoo.com>




Hi,

I created 3 categories. If 1-7 and 18-24 should come under the same category, then:
?Categ<- findInterval(dat1$Col1,c(8,18))+1
Categ[Categ>2]<- 1
dat1$Categ<- Categ
?tail(dat1)
#?? Col1?????? Col2 Categ
#45??? 2 -0.5419758???? 1
#46?? 21? 1.1042719???? 1
#47?? 24 -1.0787079???? 1
#48?? 18? 0.6253085???? 1
#49?? 15 -1.6822411???? 2
#50?? 16 -0.5966446???? 2

A.K.





----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Saturday, October 5, 2013 8:30 PM
Subject: Re: Create a categorical variable from numeric column

Hi,
Try:
set.seed(29)
dat1<- data.frame(Col1=sample(1:24,50,replace=TRUE),Col2=rnorm(50))
?dat1$Categ <- findInterval(dat1$Col1,c(8,18))+1
? head(dat1)
#? Col1??????? Col2 Categ
#1??? 3 -0.09381378???? 1
#2??? 6 -0.83640257???? 1
#3??? 3? 0.00307641???? 1
#4??? 8? 0.04197496???? 2
#5?? 15? 0.15433872???? 2
#6??? 3 -0.21301893???? 1

split(dat1,dat1$Categ)


A.K.


I ?have a data frame that contains a numerical variable ranging from 1 to 24. I would like to create a new category with two ranges: 1 to 7 
and 18 to 24 will form one category and 8 to 17 will form another. How 
can I create this category? 

Thanks


From smartpink111 at yahoo.com  Sun Oct  6 15:35:29 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 6 Oct 2013 06:35:29 -0700 (PDT)
Subject: [R] Creating a vector in R
Message-ID: <1381066529.95225.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI,
Try:
x1 <- (1:100)^2
A.K.

Hi 

I am newbie of using R. Please help me create vector x(1^2, 2^2, 3^2,....,100^2) in R. Thanks you 

I am looking forward to see your reply soon, 

Best wish 

Andrew,


From gunter.berton at gene.com  Sun Oct  6 16:18:26 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 6 Oct 2013 07:18:26 -0700
Subject: [R] Create a categorical variable from numeric column
In-Reply-To: <1381066146.63858.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1381019417.37789.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1381019939.82460.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1381066146.63858.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <CACk-te1aBVBrnWinFHSN3EBcn_-XdjG_TPQYp7jgisS=JxrBWw@mail.gmail.com>

No.

Use ?cut instead.

-- Bert

On Sun, Oct 6, 2013 at 6:29 AM, arun <smartpink111 at yahoo.com> wrote:
>
>
>
> Hi,
>
> I created 3 categories. If 1-7 and 18-24 should come under the same category, then:
>  Categ<- findInterval(dat1$Col1,c(8,18))+1
> Categ[Categ>2]<- 1
> dat1$Categ<- Categ
>  tail(dat1)
> #   Col1       Col2 Categ
> #45    2 -0.5419758     1
> #46   21  1.1042719     1
> #47   24 -1.0787079     1
> #48   18  0.6253085     1
> #49   15 -1.6822411     2
> #50   16 -0.5966446     2
>
> A.K.
>
>
>
>
>
> ----- Original Message -----
> From: arun <smartpink111 at yahoo.com>
> To: R help <r-help at r-project.org>
> Cc:
> Sent: Saturday, October 5, 2013 8:30 PM
> Subject: Re: Create a categorical variable from numeric column
>
> Hi,
> Try:
> set.seed(29)
> dat1<- data.frame(Col1=sample(1:24,50,replace=TRUE),Col2=rnorm(50))
>  dat1$Categ <- findInterval(dat1$Col1,c(8,18))+1
>   head(dat1)
> #  Col1        Col2 Categ
> #1    3 -0.09381378     1
> #2    6 -0.83640257     1
> #3    3  0.00307641     1
> #4    8  0.04197496     2
> #5   15  0.15433872     2
> #6    3 -0.21301893     1
>
> split(dat1,dat1$Categ)
>
>
> A.K.
>
>
> I  have a data frame that contains a numerical variable ranging from 1 to 24. I would like to create a new category with two ranges: 1 to 7
> and 18 to 24 will form one category and 8 to 17 will form another. How
> can I create this category?
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From ligges at statistik.tu-dortmund.de  Sun Oct  6 16:44:03 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 06 Oct 2013 16:44:03 +0200
Subject: [R] trouble with nlme: Error in MEEM() : Singularity in
 backsolve at level 0, block 1
In-Reply-To: <CACYeG1jc-YD3fbtpe0A1YmkzAX_QbSojf8hiy6kqhWJDH8-8NA@mail.gmail.com>
References: <CACYeG1jc-YD3fbtpe0A1YmkzAX_QbSojf8hiy6kqhWJDH8-8NA@mail.gmail.com>
Message-ID: <52517733.60002@statistik.tu-dortmund.de>



On 06.10.2013 03:11, Robert Lynch wrote:
> I am trying to fit my data, attached,  with the following model
>
> CutOff <- 0
>
> fit.full <- lme(fixed= zGrade ~ Rep + ISE +Yfrm7A +Ufrm7A +Female +White
> +HSGPA +MATH +AP_TOTAL +Years +Course +
>                   Course*Rep + Course*ISE +Course*Yfrm7A+Course*Ufrm7A
> +Course*Female +Course*White +Course*HSGPA +Course*MATH +Course*AP_TOTA
> L+Course*Years,
>                  random= ~1|SID,
>                  data = Master.complete[Master.complete$GRADE >= CutOff,])
>   I get the following error
> Error in MEEM(object, conLin, control$niterEM) :
>    Singularity in backsolve at level 0, block 1
>
>
> when I take out
> +Course*Yfrm7A+Course*Ufrm7A
> and just use
> fit.full <- lme(fixed= zGrade ~ Rep + ISE +Yfrm7A +Ufrm7A +Female +White
> +HSGPA +MATH +AP_TOTAL +Years +Course +
>                   Course*Rep + Course*ISE
> +Course*Female+Course*White+Course*HSGPA+Course*MATH+Course*AP_TOTAL+Course*Years,
>                  random= ~1|SID,
>                  data = Master.complete[Master.complete$GRADE >= CutOff,])
>    I don't get an error
>
> I think this is because when Course == P7A  Yfrm7A==Ufrm7A==0.

Hmmmm, actually it does not make sense to include constant variables in 
your model. Please talk to your supervisor, this i not a problem with R 
but about understanding the model.

Best,
Uwe Ligges


 > I am not
> sure how to work around this.  any suggestions would be welcome.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sun Oct  6 16:45:44 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 06 Oct 2013 16:45:44 +0200
Subject: [R] trying to compile R in win 7 (with Rtools) ... (bitmapdll -
 png.h )
In-Reply-To: <5250A3D2.8030904@yahoo.com.br>
References: <524F575F.8060009@yahoo.com.br>	<CANz9Z_+r3tsB5agmq+uLSecpK5A6P0AqnvqhtvD5iBtTC69mjQ@mail.gmail.com>	<524F6F6B.3030302@yahoo.com.br>	<524F799B.4000603@yahoo.com.br>
	<CANz9Z_Kvq6c=24DgQSZn-Acbs8eZhjR8gwxegx+hG-2jzQvdpQ@mail.gmail.com>
	<5250A3D2.8030904@yahoo.com.br>
Message-ID: <52517798.7010506@statistik.tu-dortmund.de>



On 06.10.2013 01:42, Cleber N.Borges wrote:
> I tried to follow the intrusions in
> http://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Building-the-bitmap-files
>
> when I type
>
> make bitmapdll (in gnuwin directory)
> or make (in gnuwin/bitmap dir)
>
> the libpng and libjpeg seems to compile
> but libtiff reclaims by png.h file.
>
> I set in the MkRules.local:
> -----------------------------------------
> # optional overrides for making bitmapdll: names of source directories
> JPEGDIR = C:/Rsrc/R-patched/src/gnuwin32/bitmap/jpeg-9
> PNGDIR  = C:/Rsrc/R-patched/src/gnuwin32/bitmap/libpng
> TIFFDIR =  C:/Rsrc/R-patched/src/gnuwin32/bitmap/libtiff
>
> The error snippet:
> -----------------------
> make CC='gcc -std=gnu99 -m32' AR='ar' RANLIB=ranlib -C
> C:/Rsrc/R-patched/src/gnuwin32/bitmap/libtiff -f ../Makefile.tiff
> JPEGDIR=C:/Rsrc/R-patched/src/gnuwin32/bitmap/jpeg-9
> gcc -std=gnu99 -m32  -DHAVE_PNG -DHAVE_JPEG -DHAVE_TIFF -I.
> -I../../extra/zlib -I./C:/Rsrc/R-patched/src/gnuwin32/bitmap/libpng

Not sure what you actually configured elsewhere, but
-I./C:/R..... is incorrect, it should be
-I C:/R......

Best,
Uwe Ligges


> -IC:/Rsrc/R-patched/src/gnuwin32/bitmap/jpeg-9
> -I./C:/Rsrc/R-patched/src/gnuwin32/bitmap/libtiff -I../../include -O3
> -Wall -pedantic    -c rbitmap.c -o rbitmap.o
> rbitmap.c:53:17: fatal error: png.h: No such file or directory
> compilation terminated.
> make[1]: *** [rbitmap.o] Error 1
> make: *** [all] Error 2
>
>
> so, I don't understand the error because
> *The png.h is in C:/Rsrc/R-patched/src/gnuwin32/bitmap/libpng*
>
> I thank for some help
>
> cleber
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sun Oct  6 17:54:19 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 6 Oct 2013 08:54:19 -0700
Subject: [R] Create a categorical variable from numeric column
In-Reply-To: <1381070868.50613.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1381019417.37789.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1381019939.82460.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1381066146.63858.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CACk-te1aBVBrnWinFHSN3EBcn_-XdjG_TPQYp7jgisS=JxrBWw@mail.gmail.com>
	<1381070868.50613.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CACk-te2mXVuVMMZBA=k6s7dPF=J_o4yagpXb9dNfB5ZoVyC1Eg@mail.gmail.com>

I think this is unwise. It depends on there being exactly 2 categories
in the desired result and silent coercion from logical to numeric, and
so does not generalize.  Sometimes brevity is **not** the soul of wit
(google if necessary).

I would suggest instead that cut specify three intervals and the final
condensation to 2 catgories be explicit. This can be done in many
ways, but, ifelse() is convenient here; e.g.

> x <- sample(1:24,10)
> x
 [1] 10  2 13  1 23 22  3 18 20  4

> y <- cut(x,bre=c(0,7,18,24),lab=FALSE)
## Note that the "include.lowest" and "right" arguments of cut() can
be invoked to handle endpoints as desired

> y
 [1] 2 1 2 1 3 3 1 2 3 1

> factor(ifelse(y ==2,2,1))
 [1] 2 1 2 1 1 1 1 2 1 1
Levels: 1 2

## This could all be condensed into a one-liner of course, but at the
cost of clarity.

Cheers,
Bert







On Sun, Oct 6, 2013 at 7:47 AM, arun <smartpink111 at yahoo.com> wrote:
>
> Thanks, ?cut() could be used in one line.
> Categ2<-(!is.na(cut(dat1[,1],breaks=c(7,17))))+1
>
>  identical(Categ,Categ2)
> #[1] TRUE
> A.K.
>
>
>
> ----- Original Message -----
> From: Bert Gunter <gunter.berton at gene.com>
> To: arun <smartpink111 at yahoo.com>
> Cc: R help <r-help at r-project.org>
> Sent: Sunday, October 6, 2013 10:18 AM
> Subject: Re: [R] Create a categorical variable from numeric column
>
> No.
>
> Use ?cut instead.
>
> -- Bert
>
>
> On Sun, Oct 6, 2013 at 6:29 AM, arun <smartpink111 at yahoo.com> wrote:
>>
>>
>>
>> Hi,
>>
>> I created 3 categories. If 1-7 and 18-24 should come under the same category, then:
>>  Categ<- findInterval(dat1$Col1,c(8,18))+1
>> Categ[Categ>2]<- 1
>> dat1$Categ<- Categ
>>  tail(dat1)
>> #   Col1       Col2 Categ
>> #45    2 -0.5419758     1
>> #46   21  1.1042719     1
>> #47   24 -1.0787079     1
>> #48   18  0.6253085     1
>> #49   15 -1.6822411     2
>> #50   16 -0.5966446     2
>>
>> A.K.
>>
>>
>>
>>
>>
>> ----- Original Message -----
>> From: arun <smartpink111 at yahoo.com>
>> To: R help <r-help at r-project.org>
>> Cc:
>> Sent: Saturday, October 5, 2013 8:30 PM
>> Subject: Re: Create a categorical variable from numeric column
>>
>> Hi,
>> Try:
>> set.seed(29)
>> dat1<- data.frame(Col1=sample(1:24,50,replace=TRUE),Col2=rnorm(50))
>>  dat1$Categ <- findInterval(dat1$Col1,c(8,18))+1
>>   head(dat1)
>> #  Col1        Col2 Categ
>> #1    3 -0.09381378     1
>> #2    6 -0.83640257     1
>> #3    3  0.00307641     1
>> #4    8  0.04197496     2
>> #5   15  0.15433872     2
>> #6    3 -0.21301893     1
>>
>> split(dat1,dat1$Categ)
>>
>>
>> A.K.
>>
>>
>> I  have a data frame that contains a numerical variable ranging from 1 to 24. I would like to create a new category with two ranges: 1 to 7
>> and 18 to 24 will form one category and 8 to 17 will form another. How
>> can I create this category?
>>
>> Thanks
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From fisher at plessthan.com  Sun Oct  6 19:30:38 2013
From: fisher at plessthan.com (Dennis Fisher)
Date: Sun, 6 Oct 2013 10:30:38 -0700
Subject: [R] Transposing the output of 'table'
Message-ID: <0F962A7E-8825-4EBF-A108-D815432C3FA8@plessthan.com>

R 3.0.1
OS X

Colleagues,

If I execute the command:
	table(OBJECT)
the output might look like:
  1   2 
 25 336 

I would like it to appear as:
	1	25
	2	336

I can accomplish this with:
	TABLE	<- table(OBJECT)
	data.frame(names(TABLE), as.numeric(TABLE))

However, I bet that a more clever approach exists?  Any takers?

Dennis


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From bhh at xs4all.nl  Sun Oct  6 19:44:30 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 6 Oct 2013 19:44:30 +0200
Subject: [R] Transposing the output of 'table'
In-Reply-To: <0F962A7E-8825-4EBF-A108-D815432C3FA8@plessthan.com>
References: <0F962A7E-8825-4EBF-A108-D815432C3FA8@plessthan.com>
Message-ID: <2D8BB763-E443-42DB-A61B-F2744CF05E09@xs4all.nl>


On 06-10-2013, at 19:30, Dennis Fisher <fisher at plessthan.com> wrote:

> R 3.0.1
> OS X
> 
> Colleagues,
> 
> If I execute the command:
> 	table(OBJECT)
> the output might look like:
>  1   2 
> 25 336 
> 
> I would like it to appear as:
> 	1	25
> 	2	336
> 
> I can accomplish this with:
> 	TABLE	<- table(OBJECT)
> 	data.frame(names(TABLE), as.numeric(TABLE))
> 
> However, I bet that a more clever approach exists?  Any takers?


Have you tried t(table(OBJECT)) ?

Berend


From gunter.berton at gene.com  Sun Oct  6 20:22:24 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 6 Oct 2013 11:22:24 -0700
Subject: [R] Transposing the output of 'table'
In-Reply-To: <2D8BB763-E443-42DB-A61B-F2744CF05E09@xs4all.nl>
References: <0F962A7E-8825-4EBF-A108-D815432C3FA8@plessthan.com>
	<2D8BB763-E443-42DB-A61B-F2744CF05E09@xs4all.nl>
Message-ID: <CACk-te1jEr+LG_DYWfc+EjK0LTT_uaHWOCfzzcDw8hQ_80JCiA@mail.gmail.com>

Berend et.al:

Yes.

But note that this only works for a 2-d table-- which the OP indicated
was what he had; in general, one would have to explicitly permute the
array(table) dimensions, e.g. via aperm()  .

Cheers,
Bert

On Sun, Oct 6, 2013 at 10:44 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>
> On 06-10-2013, at 19:30, Dennis Fisher <fisher at plessthan.com> wrote:
>
>> R 3.0.1
>> OS X
>>
>> Colleagues,
>>
>> If I execute the command:
>>       table(OBJECT)
>> the output might look like:
>>  1   2
>> 25 336
>>
>> I would like it to appear as:
>>       1       25
>>       2       336
>>
>> I can accomplish this with:
>>       TABLE   <- table(OBJECT)
>>       data.frame(names(TABLE), as.numeric(TABLE))
>>
>> However, I bet that a more clever approach exists?  Any takers?
>
>
> Have you tried t(table(OBJECT)) ?
>
> Berend
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From ruipbarradas at sapo.pt  Sun Oct  6 21:15:57 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 6 Oct 2013 20:15:57 +0100
Subject: [R] Transposing the output of 'table'
In-Reply-To: <CACk-te1jEr+LG_DYWfc+EjK0LTT_uaHWOCfzzcDw8hQ_80JCiA@mail.gmail.com>
References: <0F962A7E-8825-4EBF-A108-D815432C3FA8@plessthan.com>
	<2D8BB763-E443-42DB-A61B-F2744CF05E09@xs4all.nl>
	<CACk-te1jEr+LG_DYWfc+EjK0LTT_uaHWOCfzzcDw8hQ_80JCiA@mail.gmail.com>
Message-ID: <5251B6ED.6090102@sapo.pt>

Hello,

How about

OBJECT <- sample(4, 20, TRUE)
t(t(table(OBJECT)))

Hope this helps,

Rui Barradas

Em 06-10-2013 19:22, Bert Gunter escreveu:
> Berend et.al:
>
> Yes.
>
> But note that this only works for a 2-d table-- which the OP indicated
> was what he had; in general, one would have to explicitly permute the
> array(table) dimensions, e.g. via aperm()  .
>
> Cheers,
> Bert
>
> On Sun, Oct 6, 2013 at 10:44 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>>
>> On 06-10-2013, at 19:30, Dennis Fisher <fisher at plessthan.com> wrote:
>>
>>> R 3.0.1
>>> OS X
>>>
>>> Colleagues,
>>>
>>> If I execute the command:
>>>        table(OBJECT)
>>> the output might look like:
>>>   1   2
>>> 25 336
>>>
>>> I would like it to appear as:
>>>        1       25
>>>        2       336
>>>
>>> I can accomplish this with:
>>>        TABLE   <- table(OBJECT)
>>>        data.frame(names(TABLE), as.numeric(TABLE))
>>>
>>> However, I bet that a more clever approach exists?  Any takers?
>>
>>
>> Have you tried t(table(OBJECT)) ?
>>
>> Berend
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From bhh at xs4all.nl  Sun Oct  6 21:26:40 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 6 Oct 2013 21:26:40 +0200
Subject: [R] Transposing the output of 'table'
In-Reply-To: <A801ADFD-9079-4473-BF94-8609EFA08D32@plessthan.com>
References: <0F962A7E-8825-4EBF-A108-D815432C3FA8@plessthan.com>
	<2D8BB763-E443-42DB-A61B-F2744CF05E09@xs4all.nl>
	<A801ADFD-9079-4473-BF94-8609EFA08D32@plessthan.com>
Message-ID: <9740C819-BF1E-43DE-A103-86371AC4B2DB@xs4all.nl>


On 06-10-2013, at 20:32, Dennis Fisher <fisher at plessthan.com> wrote:

> unsuccessful
> 


Please reply to the list and not to me only.
That way others can contribute to solving the problem.


Berend

> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
> 
> 
> 
> On Oct 6, 2013, at 10:44 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
>> 
>> On 06-10-2013, at 19:30, Dennis Fisher <fisher at plessthan.com> wrote:
>> 
>>> R 3.0.1
>>> OS X
>>> 
>>> Colleagues,
>>> 
>>> If I execute the command:
>>> 	table(OBJECT)
>>> the output might look like:
>>> 1   2 
>>> 25 336 
>>> 
>>> I would like it to appear as:
>>> 	1	25
>>> 	2	336
>>> 
>>> I can accomplish this with:
>>> 	TABLE	<- table(OBJECT)
>>> 	data.frame(names(TABLE), as.numeric(TABLE))
>>> 
>>> However, I bet that a more clever approach exists?  Any takers?
>> 
>> 
>> Have you tried t(table(OBJECT)) ?
>> 
>> Berend
>> 
>


From murdoch.duncan at gmail.com  Sun Oct  6 21:51:01 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 6 Oct 2013 15:51:01 -0400
Subject: [R] Transposing the output of 'table'
In-Reply-To: <5251B6ED.6090102@sapo.pt>
References: <0F962A7E-8825-4EBF-A108-D815432C3FA8@plessthan.com>
	<2D8BB763-E443-42DB-A61B-F2744CF05E09@xs4all.nl>
	<CACk-te1jEr+LG_DYWfc+EjK0LTT_uaHWOCfzzcDw8hQ_80JCiA@mail.gmail.com>
	<5251B6ED.6090102@sapo.pt>
Message-ID: <5251BF25.4050901@gmail.com>

On 13-10-06 3:15 PM, Rui Barradas wrote:
> Hello,
>
> How about
>
> OBJECT <- sample(4, 20, TRUE)
> t(t(table(OBJECT)))

Or simply

as.matrix(table(OBJECT))

>
> Hope this helps,
>
> Rui Barradas
>
> Em 06-10-2013 19:22, Bert Gunter escreveu:
>> Berend et.al:
>>
>> Yes.
>>
>> But note that this only works for a 2-d table-- which the OP indicated
>> was what he had; in general, one would have to explicitly permute the
>> array(table) dimensions, e.g. via aperm()  .
>>
>> Cheers,
>> Bert
>>
>> On Sun, Oct 6, 2013 at 10:44 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>>>
>>> On 06-10-2013, at 19:30, Dennis Fisher <fisher at plessthan.com> wrote:
>>>
>>>> R 3.0.1
>>>> OS X
>>>>
>>>> Colleagues,
>>>>
>>>> If I execute the command:
>>>>         table(OBJECT)
>>>> the output might look like:
>>>>    1   2
>>>> 25 336
>>>>
>>>> I would like it to appear as:
>>>>         1       25
>>>>         2       336
>>>>
>>>> I can accomplish this with:
>>>>         TABLE   <- table(OBJECT)
>>>>         data.frame(names(TABLE), as.numeric(TABLE))
>>>>
>>>> However, I bet that a more clever approach exists?  Any takers?
>>>
>>>
>>> Have you tried t(table(OBJECT)) ?
>>>
>>> Berend
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Sun Oct  6 16:47:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 6 Oct 2013 07:47:48 -0700 (PDT)
Subject: [R] Create a categorical variable from numeric column
In-Reply-To: <CACk-te1aBVBrnWinFHSN3EBcn_-XdjG_TPQYp7jgisS=JxrBWw@mail.gmail.com>
References: <1381019417.37789.YahooMailNeo@web142602.mail.bf1.yahoo.com>	<1381019939.82460.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<1381066146.63858.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CACk-te1aBVBrnWinFHSN3EBcn_-XdjG_TPQYp7jgisS=JxrBWw@mail.gmail.com>
Message-ID: <1381070868.50613.YahooMailNeo@web142601.mail.bf1.yahoo.com>


Thanks, ?cut() could be used in one line. 
Categ2<-(!is.na(cut(dat1[,1],breaks=c(7,17))))+1

?identical(Categ,Categ2)
#[1] TRUE
A.K.



----- Original Message -----
From: Bert Gunter <gunter.berton at gene.com>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Sunday, October 6, 2013 10:18 AM
Subject: Re: [R] Create a categorical variable from numeric column

No.

Use ?cut instead.

-- Bert


On Sun, Oct 6, 2013 at 6:29 AM, arun <smartpink111 at yahoo.com> wrote:
>
>
>
> Hi,
>
> I created 3 categories. If 1-7 and 18-24 should come under the same category, then:
>? Categ<- findInterval(dat1$Col1,c(8,18))+1
> Categ[Categ>2]<- 1
> dat1$Categ<- Categ
>? tail(dat1)
> #?  Col1? ? ?  Col2 Categ
> #45? ? 2 -0.5419758? ?  1
> #46?  21? 1.1042719? ?  1
> #47?  24 -1.0787079? ?  1
> #48?  18? 0.6253085? ?  1
> #49?  15 -1.6822411? ?  2
> #50?  16 -0.5966446? ?  2
>
> A.K.
>
>
>
>
>
> ----- Original Message -----
> From: arun <smartpink111 at yahoo.com>
> To: R help <r-help at r-project.org>
> Cc:
> Sent: Saturday, October 5, 2013 8:30 PM
> Subject: Re: Create a categorical variable from numeric column
>
> Hi,
> Try:
> set.seed(29)
> dat1<- data.frame(Col1=sample(1:24,50,replace=TRUE),Col2=rnorm(50))
>? dat1$Categ <- findInterval(dat1$Col1,c(8,18))+1
>?  head(dat1)
> #? Col1? ? ? ? Col2 Categ
> #1? ? 3 -0.09381378? ?  1
> #2? ? 6 -0.83640257? ?  1
> #3? ? 3? 0.00307641? ?  1
> #4? ? 8? 0.04197496? ?  2
> #5?  15? 0.15433872? ?  2
> #6? ? 3 -0.21301893? ?  1
>
> split(dat1,dat1$Categ)
>
>
> A.K.
>
>
> I? have a data frame that contains a numerical variable ranging from 1 to 24. I would like to create a new category with two ranges: 1 to 7
> and 18 to 24 will form one category and 8 to 17 will form another. How
> can I create this category?
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374



From smartpink111 at yahoo.com  Sun Oct  6 18:21:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 6 Oct 2013 09:21:02 -0700 (PDT)
Subject: [R] work with observations in column
Message-ID: <1381076462.21800.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
May be this helps:
?vec1<- 1:10
library(zoo)
rollmean(vec1,2)
#[1] 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5
vec2<- c(5,8,9,13,20)
?diff(vec2)
#[1] 3 1 4 7

A.K.





Hello, 

How can I calculate half sum of 2 observ (l(i) + l(i+1))/2 ? 
How compute f(i) - f(i+1) ? 

please help me.


From alamont082 at gmail.com  Sun Oct  6 20:25:42 2013
From: alamont082 at gmail.com (Andrea Lamont)
Date: Sun, 6 Oct 2013 14:25:42 -0400
Subject: [R] FW:  Transposing the output of 'table'
In-Reply-To: <a00999f0b3654b3f87084f257105cab2@CAE145HUBP03.ds.sc.edu>
References: <0F962A7E-8825-4EBF-A108-D815432C3FA8@plessthan.com>
	<2D8BB763-E443-42DB-A61B-F2744CF05E09@xs4all.nl>
	<a00999f0b3654b3f87084f257105cab2@CAE145HUBP03.ds.sc.edu>
Message-ID: <CALxSy07ABgvZFjx1fhUOpTc5F9s-G6WXUnenTBJOS-OMv3HHgQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131006/4358408c/attachment.pl>

From matthias.weber at fnt.de  Mon Oct  7 09:57:59 2013
From: matthias.weber at fnt.de (Mat)
Date: Mon, 7 Oct 2013 00:57:59 -0700 (PDT)
Subject: [R] kill colnames Matrix
Message-ID: <1381132679107-4677726.post@n4.nabble.com>

Hello together, 

i have a little problem, maybe you can help me.
I have a matrix like this one:

                   [,1]          [,2]              [,3]           [,4]            
[,5]        
MONTH         "2012-10"    "2012-11"    "2012-12"    "2013-01"    "2013-02"   
PT_SATZ "     0.00000" " 500.53621" "  65.71684" "1080.58285" "1013.72028"

For a bar plot i need this matrix in the following formatting:

"2012-10"    "2012-11"    "2012-12"    "2013-01"    "2013-02"   
0.00000"    " 500.53621"  "  65.71684" "1080.58285" "1013.72028"

the data comes from a data.frame like this one:

     MONTH    PT_SATZ
1  2012-10    0.00000
2  2012-11  500.53621
3  2012-12   65.71684
4  2013-01 1080.58285
5  2013-02 1013.72028
6  2013-03  939.63030
7  2013-04  977.17073
8  2013-05    0.00000
9  2013-06    0.00000
10 2013-07 1047.56938
11 2013-08  225.44031
12 2013-09  667.91489
13 2013-10    0.00000

i converted this data.frame with plotbase<-t(plotbase).

Maybe you can help me.

Thanks Mat



--
View this message in context: http://r.789695.n4.nabble.com/kill-colnames-Matrix-tp4677726.html
Sent from the R help mailing list archive at Nabble.com.


From stefano.sofia at regione.marche.it  Mon Oct  7 10:05:57 2013
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Mon, 7 Oct 2013 08:05:57 +0000
Subject: [R] R:  Group all the consecutive days
In-Reply-To: <CAAxdm-7pXV2zJn=YY-yMbic1wcMfOF4QGQB7cjAg6f7akcdTWw@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F0DA25202@CHIENTI.regionemarche.intra>
	<8B435C9568170B469AE31E8891E8CC4F0DA25218@CHIENTI.regionemarche.intra>,
	<CAAxdm-7pXV2zJn=YY-yMbic1wcMfOF4QGQB7cjAg6f7akcdTWw@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F0DA25814@CHIENTI.regionemarche.intra>

Jim,
sorry for the delay of my answer.
The code works very well, thank you for your support.
I am a meteorologist and I am helping a geologist in some studies step by step.
As the time being this is exactly what I wanted to do.

Thank you
Stefano
________________________________________
Da: jim holtman [jholtman at gmail.com]
Inviato: mercoled? 2 ottobre 2013 17.29
A: Stefano Sofia
Cc: r-help at r-project.org
Oggetto: Re: [R] Group all the consecutive days

try this:

> rain <- read.table(text = '"year" "month" "day" "rainfall" "landslide"
+ "3" 2007 6 6 1.6 0
+ "4" 2007 6 7 1.8 0
+ "6" 2007 6 12 4.6 0
+ "8" 2007 7 5 6.6 0
+ "9" 2007 7 10 3 0
+ "10" 2007 7 11 1.2 0
+ "11" 2007 8 3 6.4 0
+ "12" 2007 8 10 2.8 0
+ "14" 2007 9 4 5.4 0
+ "15" 2007 9 5 1 0
+ "16" 2007 9 10 2.8 0
+ "17" 2007 9 11 6.8 0
+ "18" 2007 9 18 1.4 0
+ "19" 2007 9 19 1 0
+ "20" 2007 9 27 3 0
+ "21" 2007 10 6 41.4 0
+ "22" 2007 10 7 146 1
+ "23" 2007 10 10 2 0
+ "24" 2007 10 11 3.4 0
+ "26" 2007 10 18 17.4 0
+ "28" 2007 10 20 12.8 0
+ "29" 2007 10 21 1.8 0
+ "30" 2007 10 22 15.6 0
+ "33" 2007 10 25 8.6 0
+ "35" 2007 10 30 5.2 0
+ "36" 2007 10 31 34 1
+ "37" 2007 11 1 7.6 0
+ "39" 2007 11 9 6.8 1
+ "40" 2007 11 14 6.2 0
+ "41" 2007 11 15 3.8 0
+ "42" 2007 11 16 9.2 0', header = TRUE)
>
> # convert to Date
> rain$Date <- as.Date(paste0(rain$year, '-', rain$month, '-', rain$day))
>
> # determine consecutive if difference is one
> rain$consec <- cumsum(!c(TRUE, diff(rain$Date) == 1))
>
> # now split by consecutive days and create one row
> x <- split(rain, rain$consec)
>
> result <- do.call(rbind
+     , lapply(x, function(days){
+         data.frame(date = paste(days$Date, collapse = ',')
+                 , total = sum(days$rainfall)
+                 , stringsAsFactors = FALSE
+                 )
+         })
+     )
>
>
>
> result
                               date total
0             2007-06-06,2007-06-07   3.4
1                        2007-06-12   4.6
2                        2007-07-05   6.6
3             2007-07-10,2007-07-11   4.2
4                        2007-08-03   6.4
5                        2007-08-10   2.8
6             2007-09-04,2007-09-05   6.4
7             2007-09-10,2007-09-11   9.6
8             2007-09-18,2007-09-19   2.4
9                        2007-09-27   3.0
10            2007-10-06,2007-10-07 187.4
11            2007-10-10,2007-10-11   5.4
12                       2007-10-18  17.4
13 2007-10-20,2007-10-21,2007-10-22  30.2
14                       2007-10-25   8.6
15 2007-10-30,2007-10-31,2007-11-01  46.8
16                       2007-11-09   6.8
17 2007-11-14,2007-11-15,2007-11-16  19.2
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Oct 2, 2013 at 10:09 AM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R-users,
> I have a data frame where in each row there is the daily rainfall cumulative;
> missing days mean that in that days rainfall has been zero.
> I need to group all the consecutive days in a single row and store in the field "rainfall" the sum of these consecutive days.
> Is there a reasonable way to do that?
>
> Thank you for your help
> Stefano
>
> "year" "month" "day" "rainfall" "landslide"
> "3" 2007 6 6 1.6 0
> "4" 2007 6 7 1.8 0
> "6" 2007 6 12 4.6 0
> "8" 2007 7 5 6.6 0
> "9" 2007 7 10 3 0
> "10" 2007 7 11 1.2 0
> "11" 2007 8 3 6.4 0
> "12" 2007 8 10 2.8 0
> "14" 2007 9 4 5.4 0
> "15" 2007 9 5 1 0
> "16" 2007 9 10 2.8 0
> "17" 2007 9 11 6.8 0
> "18" 2007 9 18 1.4 0
> "19" 2007 9 19 1 0
> "20" 2007 9 27 3 0
> "21" 2007 10 6 41.4 0
> "22" 2007 10 7 146 1
> "23" 2007 10 10 2 0
> "24" 2007 10 11 3.4 0
> "26" 2007 10 18 17.4 0
> "28" 2007 10 20 12.8 0
> "29" 2007 10 21 1.8 0
> "30" 2007 10 22 15.6 0
> "33" 2007 10 25 8.6 0
> "35" 2007 10 30 5.2 0
> "36" 2007 10 31 34 1
> "37" 2007 11 1 7.6 0
> "39" 2007 11 9 6.8 1
> "40" 2007 11 14 6.2 0
> "41" 2007 11 15 3.8 0
> "42" 2007 11 16 9.2 0
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

From petr.pikal at precheza.cz  Mon Oct  7 10:44:59 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 7 Oct 2013 08:44:59 +0000
Subject: [R] kill colnames Matrix
In-Reply-To: <1381132679107-4677726.post@n4.nabble.com>
References: <1381132679107-4677726.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B958BE@SRVEXCHMBX.precheza.cz>

Hi

First of all do not mix data frame and matrix, they have quite different properties.

By transposing data frame you got character matrix and you cannot do barplot with characters.
So you shall transpose only column PT_SATZ and add names from MONTHS but why not to use your data frame directly?

dat<-data.frame(x=letters[1:5], y=1:5)
barplot(dat[,2], names.arg=dat[,1])

You could arrive to this answer quicker if you bother to look into documentation to barplot so as did I.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Mat
> Sent: Monday, October 07, 2013 9:58 AM
> To: r-help at r-project.org
> Subject: [R] kill colnames Matrix
> 
> Hello together,
> 
> i have a little problem, maybe you can help me.
> I have a matrix like this one:
> 
>                    [,1]          [,2]              [,3]           [,4]
> [,5]
> MONTH         "2012-10"    "2012-11"    "2012-12"    "2013-01"
> "2013-02"
> PT_SATZ "     0.00000" " 500.53621" "  65.71684" "1080.58285"
> "1013.72028"
> 
> For a bar plot i need this matrix in the following formatting:
> 
> "2012-10"    "2012-11"    "2012-12"    "2013-01"    "2013-02"
> 0.00000"    " 500.53621"  "  65.71684" "1080.58285" "1013.72028"
> 
> the data comes from a data.frame like this one:
> 
>      MONTH    PT_SATZ
> 1  2012-10    0.00000
> 2  2012-11  500.53621
> 3  2012-12   65.71684
> 4  2013-01 1080.58285
> 5  2013-02 1013.72028
> 6  2013-03  939.63030
> 7  2013-04  977.17073
> 8  2013-05    0.00000
> 9  2013-06    0.00000
> 10 2013-07 1047.56938
> 11 2013-08  225.44031
> 12 2013-09  667.91489
> 13 2013-10    0.00000
> 
> i converted this data.frame with plotbase<-t(plotbase).
> 
> Maybe you can help me.
> 
> Thanks Mat
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/kill-
> colnames-Matrix-tp4677726.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mohan.radhakrishnan at polarisft.com  Mon Oct  7 11:09:07 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Mon, 7 Oct 2013 14:39:07 +0530
Subject: [R] Growth calculation
Message-ID: <OF2DCEE010.673C576C-ON65257BFD.0031CDD2-65257BFD.00323A69@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131007/7e2ad543/attachment.pl>

From hans_hans74 at gmx.de  Mon Oct  7 11:26:50 2013
From: hans_hans74 at gmx.de (hans74)
Date: Mon, 7 Oct 2013 02:26:50 -0700 (PDT)
Subject: [R] abline is not plotting
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5487CC3904@GOLD.corp.lgc-group.com>
References: <1380896209391-4677583.post@n4.nabble.com>
	<A4E5A0B016B8CB41A485FC629B633CED5487CC3904@GOLD.corp.lgc-group.com>
Message-ID: <1381138010669-4677731.post@n4.nabble.com>

Hi,

it works now! Thanks to you both. 

I thought abline with the lm inside uses the already plotted x- and y-axes
automatically, as it does for a abline( h = ... ), for example. Applying the
logarithm on the lm-data fixes the graph.

Thank you,
Hans



--
View this message in context: http://r.789695.n4.nabble.com/abline-is-not-plotting-tp4677583p4677731.html
Sent from the R help mailing list archive at Nabble.com.


From charles.annis at statisticalengineering.com  Mon Oct  7 13:56:14 2013
From: charles.annis at statisticalengineering.com (Charles Annis)
Date: Mon, 7 Oct 2013 07:56:14 -0400
Subject: [R] convert data.frame to parameters
Message-ID: <000b01cec354$3935f630$aba1e290$@statisticalengineering.com>

Greetings:

I have a 24 row,  2-column csv file.  The first column is character, with
the names of parameters.  The second column is numeric, containing the
parameter values.

I can produce a 2-column data.frame with  case.study.parameters <-
read.csv(...)

I want to convert the data.frame to 24 parameters having those names and
their associated numeric values.

I've tried using package "ParamHelpers" with no success.  Likely because it
really isn't intended for that purpose.

Can anyone help?

Thanks.

Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
http://StatisticalEngineering.com
561-352-9699


From murdoch.duncan at gmail.com  Mon Oct  7 14:04:25 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 07 Oct 2013 08:04:25 -0400
Subject: [R] convert data.frame to parameters
In-Reply-To: <000b01cec354$3935f630$aba1e290$@statisticalengineering.com>
References: <000b01cec354$3935f630$aba1e290$@statisticalengineering.com>
Message-ID: <5252A349.9090102@gmail.com>

On 07/10/2013 7:56 AM, Charles Annis wrote:
> Greetings:
>
> I have a 24 row,  2-column csv file.  The first column is character, with
> the names of parameters.  The second column is numeric, containing the
> parameter values.
>
> I can produce a 2-column data.frame with  case.study.parameters <-
> read.csv(...)
>
> I want to convert the data.frame to 24 parameters having those names and
> their associated numeric values.
>
> I've tried using package "ParamHelpers" with no success.  Likely because it
> really isn't intended for that purpose.
>
> Can anyone help?

You say you want "parameters", but that's not an R type.  So here's one 
way, but it might not be what you're looking for.

df <- data.frame(names=letters, values=1:26)
parameters <- df$values
names(parameters) <- df$names

Duncan Murdoch


From charles.annis at statisticalengineering.com  Mon Oct  7 15:07:52 2013
From: charles.annis at statisticalengineering.com (Charles Annis)
Date: Mon, 7 Oct 2013 09:07:52 -0400
Subject: [R] convert data.frame to parameters
In-Reply-To: <5252A349.9090102@gmail.com>
References: <000b01cec354$3935f630$aba1e290$@statisticalengineering.com>
	<5252A349.9090102@gmail.com>
Message-ID: <002601cec35e$3b04de40$b10e9ac0$@statisticalengineering.com>

Sorry for using "parameters" when I meant "objects."  I also wasn't
sufficiently clear about what I'm trying to do.

Your suggestion produces a single object, "parameters."  What I want are 26
objects, a , b, c, ... whose values are df$values, which in my case are
numeric.

Thanks.

Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
http://StatisticalEngineering.com
561-352-9699

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Monday, October 7, 2013 8:04 AM
To: Charles Annis
Cc: r-help at r-project.org
Subject: Re: [R] convert data.frame to parameters

On 07/10/2013 7:56 AM, Charles Annis wrote:
> Greetings:
>
> I have a 24 row,  2-column csv file.  The first column is character, 
> with the names of parameters.  The second column is numeric, 
> containing the parameter values.
>
> I can produce a 2-column data.frame with  case.study.parameters <-
> read.csv(...)
>
> I want to convert the data.frame to 24 parameters having those names 
> and their associated numeric values.
>
> I've tried using package "ParamHelpers" with no success.  Likely 
> because it really isn't intended for that purpose.
>
> Can anyone help?

You say you want "parameters", but that's not an R type.  So here's one way,
but it might not be what you're looking for.

df <- data.frame(names=letters, values=1:26) parameters <- df$values
names(parameters) <- df$names

Duncan Murdoch


From smartpink111 at yahoo.com  Mon Oct  7 15:30:37 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 7 Oct 2013 06:30:37 -0700 (PDT)
Subject: [R] Why read.table replacing space with "." in the header
In-Reply-To: <1381149359.25833.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1381149359.25833.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1381152637.81530.YahooMailNeo@web142601.mail.bf1.yahoo.com>




Hi,
Use `check.names=FALSE`
head(dd,2)
#? Phylo.Tree Genesis.Tree
#1????????? 1??????????? 2
#2????????? 2??????????? 3

?dd <- data.frame("Phylo Tree"= c(1:10), "Genesis Tree"= c(2:11),check.names=FALSE) 
head(dd,2)
#? Phylo Tree Genesis Tree
#1????????? 1??????????? 2
#2????????? 2??????????? 3
write.csv(dd,"Crish.csv",row.names=FALSE)
?yy<- read.csv("Crish.csv",header=TRUE,check.names=FALSE)
?head(yy,2)
#? Phylo Tree Genesis Tree
#1????????? 1??????????? 2
#2????????? 2??????????? 3

A.K.



Hello Guys 

Please look at the following code. I dont have "." in the input 
data frame. But why i am getting when i read the data.frame again. 

dd <- data.frame("Phylo Tree"= c(1:10), "Genesis Tree"= c(2:11)) 
?write.table(dd, "D:\\Write_XML\\testdf.csv", sep=",") 
?yy <- read.table("D:\\Write_XML\\testdf.csv", sep=",") 
?names(yy) 
[1] "Phylo.Tree" ? "Genesis.Tree" 


Thanks 
Krishna


From gunter.berton at gene.com  Mon Oct  7 15:36:52 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 7 Oct 2013 06:36:52 -0700
Subject: [R] convert data.frame to parameters
In-Reply-To: <002601cec35e$3b04de40$b10e9ac0$@statisticalengineering.com>
References: <000b01cec354$3935f630$aba1e290$@statisticalengineering.com>
	<5252A349.9090102@gmail.com>
	<002601cec35e$3b04de40$b10e9ac0$@statisticalengineering.com>
Message-ID: <CACk-te3rTda3D=_O7Wk9W9Mt2wqvUpc31tLvWb-879WVAfzuOw@mail.gmail.com>

1. ?assign is what you're looking for, I think.

2. But I would guess that you do not need to do this. As a further
guess, see ?do.call for creating a function call that you can give a
list of arguments/parameters.

Cheers,
Bert

On Mon, Oct 7, 2013 at 6:07 AM, Charles Annis
<charles.annis at statisticalengineering.com> wrote:
> Sorry for using "parameters" when I meant "objects."  I also wasn't
> sufficiently clear about what I'm trying to do.
>
> Your suggestion produces a single object, "parameters."  What I want are 26
> objects, a , b, c, ... whose values are df$values, which in my case are
> numeric.
>
> Thanks.
>
> Charles Annis, P.E.
>
> Charles.Annis at StatisticalEngineering.com
> http://StatisticalEngineering.com
> 561-352-9699
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Monday, October 7, 2013 8:04 AM
> To: Charles Annis
> Cc: r-help at r-project.org
> Subject: Re: [R] convert data.frame to parameters
>
> On 07/10/2013 7:56 AM, Charles Annis wrote:
>> Greetings:
>>
>> I have a 24 row,  2-column csv file.  The first column is character,
>> with the names of parameters.  The second column is numeric,
>> containing the parameter values.
>>
>> I can produce a 2-column data.frame with  case.study.parameters <-
>> read.csv(...)
>>
>> I want to convert the data.frame to 24 parameters having those names
>> and their associated numeric values.
>>
>> I've tried using package "ParamHelpers" with no success.  Likely
>> because it really isn't intended for that purpose.
>>
>> Can anyone help?
>
> You say you want "parameters", but that's not an R type.  So here's one way,
> but it might not be what you're looking for.
>
> df <- data.frame(names=letters, values=1:26) parameters <- df$values
> names(parameters) <- df$names
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From charles.annis at statisticalengineering.com  Mon Oct  7 15:58:03 2013
From: charles.annis at statisticalengineering.com (Charles Annis)
Date: Mon, 7 Oct 2013 09:58:03 -0400
Subject: [R] convert data.frame to parameters
In-Reply-To: <CACk-te3rTda3D=_O7Wk9W9Mt2wqvUpc31tLvWb-879WVAfzuOw@mail.gmail.com>
References: <000b01cec354$3935f630$aba1e290$@statisticalengineering.com>	<5252A349.9090102@gmail.com>	<002601cec35e$3b04de40$b10e9ac0$@statisticalengineering.com>
	<CACk-te3rTda3D=_O7Wk9W9Mt2wqvUpc31tLvWb-879WVAfzuOw@mail.gmail.com>
Message-ID: <003d01cec365$3e17bf60$ba473e20$@statisticalengineering.com>

Yup.  You saved the day with "assign."  Works like a champ.  Thanks too for the "do.call" suggestion.  It turns out, however, that I'm using all these objects (parameters) in a more complex code, and not a single function call.

Thanks again! 

Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
http://StatisticalEngineering.com
561-352-9699

-----Original Message-----
From: Bert Gunter [mailto:gunter.berton at gene.com] 
Sent: Monday, October 7, 2013 9:37 AM
To: Charles Annis
Cc: Duncan Murdoch; r-help at r-project.org
Subject: Re: [R] convert data.frame to parameters

1. ?assign is what you're looking for, I think.

2. But I would guess that you do not need to do this. As a further guess, see ?do.call for creating a function call that you can give a list of arguments/parameters.

Cheers,
Bert

On Mon, Oct 7, 2013 at 6:07 AM, Charles Annis <charles.annis at statisticalengineering.com> wrote:
> Sorry for using "parameters" when I meant "objects."  I also wasn't 
> sufficiently clear about what I'm trying to do.
>
> Your suggestion produces a single object, "parameters."  What I want 
> are 26 objects, a , b, c, ... whose values are df$values, which in my 
> case are numeric.
>
> Thanks.
>
> Charles Annis, P.E.
>
> Charles.Annis at StatisticalEngineering.com
> http://StatisticalEngineering.com
> 561-352-9699
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Monday, October 7, 2013 8:04 AM
> To: Charles Annis
> Cc: r-help at r-project.org
> Subject: Re: [R] convert data.frame to parameters
>
> On 07/10/2013 7:56 AM, Charles Annis wrote:
>> Greetings:
>>
>> I have a 24 row,  2-column csv file.  The first column is character, 
>> with the names of parameters.  The second column is numeric, 
>> containing the parameter values.
>>
>> I can produce a 2-column data.frame with  case.study.parameters <-
>> read.csv(...)
>>
>> I want to convert the data.frame to 24 parameters having those names 
>> and their associated numeric values.
>>
>> I've tried using package "ParamHelpers" with no success.  Likely 
>> because it really isn't intended for that purpose.
>>
>> Can anyone help?
>
> You say you want "parameters", but that's not an R type.  So here's 
> one way, but it might not be what you're looking for.
>
> df <- data.frame(names=letters, values=1:26) parameters <- df$values
> names(parameters) <- df$names
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From smartpink111 at yahoo.com  Mon Oct  7 15:16:20 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 7 Oct 2013 06:16:20 -0700 (PDT)
Subject: [R] Data Frame Operation: Replace values based on contraints
Message-ID: <1381151780.51762.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
datNew <- read.table(text=as.character(mydata$NATIONALITY),sep="_")
?mydata2 <- within(mydata,{NATIONALITY <- as.character(datNew[,1]);YEAR <- datNew[,2]})
?head(mydata2)
#???? PROVINCE? AGE5 ZONA91OK NATIONALITY FREQUENCY YEAR
#1?????????? 1 10-14????? 101?????? SPAIN?????? 600 1998
#501???????? 4 30-34???? 4079?????? SPAIN????? 1000 1998
#1001??????? 7 50-54????? 712?????? SPAIN?????? 500 1998
#1501??????? 8 40-44???? 8205?????? SPAIN????? 2000 1998
#2001?????? 11 35-39??? 11022?????? SPAIN????? 1000 1998
#2501?????? 14 40-44??? 14021?????? SPAIN???? 10000 1998


A.K.




I have a dataset in which I want to split a variable in two variables, one telling me the nationality and the other the year. 

YEAR: four digit number with the year 
NATIONALITY: code for the nationality (e.g. SPAIN, EU15DC, etc.) 


? row PROVINCE	AGE5	ZONA91OK	NATIONALITY	FREQUENCY ?	YEAR 
? 1	1	10-14	101	SPAIN_1998	614.000000	Nationality 
? 501	4	30-34	4079	SPAIN_1998	1943.000000	Nationality 
? 1001	7	50-54	712	SPAIN_1998	596.053095	Nationality 
? 1501	8	40-44	8205	SPAIN_1998	2012.674138	Nationality 

so I would like to replace for instance: 
NATIONALITY: SPAIN_1998 

with 

NATIONALITY: SPAIN 

and for the corresponding rows 

YEAR: 1998 

Any help on the issue is very appreciated! 

Here is a reproducible sample: 
mydata<- ?structure(list(PROVINCE = c(1L, 4L, 7L, 8L, 11L, 14L, 17L, 20L, 
24L, 28L, 30L, 33L, 36L, 41L, 44L, 46L, 48L, 3L, 6L, 8L, 10L, 
13L, 15L, 18L, 23L, 26L, 29L, 31L, 35L, 38L, 41L, 46L, 47L, 2L, 
4L, 8L, 8L, 11L, 15L, 17L, 21L, 24L, 28L, 30L, 33L, 37L, 41L, 
45L, 46L, 49L, 3L, 6L, 8L, 10L, 13L, 15L, 19L, 23L, 27L, 29L, 
32L, 36L, 39L, 43L, 46L, 48L, 2L, 5L, 8L, 8L, 12L, 15L, 18L, 
21L, 24L, 28L, 30L, 33L, 37L, 41L, 45L, 46L, 50L, 3L, 7L, 8L, 
10L, 14L, 16L, 20L, 23L, 27L, 29L, 32L, 36L, 39L, 43L, 46L, 48L, 
3L, 6L, 8L, 8L, 12L, 15L, 18L, 21L, 25L, 28L, 31L, 34L, 38L, 
41L, 45L, 46L, 50L, 3L, 7L, 8L, 11L, 14L, 17L, 20L, 23L, 27L, 
29L, 33L, 36L, 40L, 43L, 46L, 48L, 3L, 6L, 8L, 9L, 12L, 15L, 
18L, 22L, 25L, 28L, 31L, 35L, 38L, 41L, 45L, 46L, 50L, 4L, 7L, 
8L, 11L, 14L, 17L, 20L, 24L, 28L, 30L, 33L, 36L, 41L, 43L, 46L, 
48L, 3L, 6L, 8L, 10L, 13L, 15L, 18L, 22L, 26L, 28L, 31L, 35L, 
38L, 41L, 46L, 47L, 1L, 4L, 8L, 8L, 11L, 14L, 17L, 20L, 24L, 
28L, 30L, 33L, 36L, 41L, 44L, 46L, 49L, 3L, 6L), AGE5 = structure(c(1L, 
5L, 9L, 7L, 6L, 7L, 5L, 8L, 3L, 3L, 3L, 5L, 8L, 2L, 3L, 6L, 9L, 
5L, 7L, 4L, 3L, 5L, 8L, 8L, 2L, 8L, 2L, 9L, 7L, 9L, 9L, 2L, 7L, 
2L, 9L, 1L, 8L, 8L, 1L, 8L, 1L, 6L, 4L, 6L, 7L, 2L, 3L, 1L, 7L, 
5L, 6L, 9L, 5L, 6L, 8L, 9L, 3L, 4L, 3L, 4L, 4L, 1L, 3L, 1L, 2L, 
2L, 6L, 6L, 2L, 9L, 2L, 2L, 1L, 5L, 9L, 5L, 8L, 9L, 7L, 4L, 3L, 
7L, 2L, 8L, 2L, 6L, 9L, 1L, 5L, 1L, 6L, 6L, 6L, 7L, 3L, 6L, 3L, 
3L, 4L, 1L, 1L, 2L, 9L, 6L, 4L, 3L, 8L, 3L, 7L, 1L, 5L, 2L, 6L, 
6L, 8L, 5L, 9L, 5L, 6L, 2L, 3L, 1L, 4L, 8L, 9L, 8L, 1L, 5L, 1L, 
6L, 4L, 6L, 2L, 3L, 3L, 5L, 9L, 5L, 5L, 4L, 7L, 8L, 4L, 2L, 5L, 
7L, 8L, 9L, 8L, 3L, 7L, 7L, 5L, 6L, 3L, 6L, 1L, 2L, 2L, 3L, 7L, 
1L, 9L, 5L, 8L, 4L, 5L, 4L, 1L, 3L, 7L, 7L, 9L, 3L, 9L, 7L, 5L, 
7L, 8L, 1L, 4L, 4L, 6L, 1L, 8L, 7L, 8L, 6L, 8L, 4L, 3L, 4L, 5L, 
9L, 2L, 6L, 6L, 1L, 5L, 7L), .Label = c("10-14", "15-19", "20-24", 
"25-29", "30-34", "35-39", "40-44", "45-49", "50-54"), class = "factor"), 
? ? ZONA91OK = c(101L, 4079L, 712L, 8205L, 11022L, 14021L, 1714L, 
? ? 20067L, 2414L, 2810L, 300799L, 3305L, 36026L, 41024L, 4405L, 
? ? 4607L, 48015L, 308L, 610L, 8121L, 1006L, 1307L, 1511L, 1813L, 
? ? 2308L, 2605L, 2910L, 310799L, 35026L, 3811L, 411199L, 4601L, 
? ? 4708L, 202L, 405L, 8015L, 837L, 11033L, 1502L, 1702L, 2112L, 
? ? 2408L, 28047L, 30015L, 3305L, 3709L, 410199L, 4511L, 1202L, 
? ? 490699L, 3063L, 610L, 827L, 1006L, 1301L, 15036L, 1901L, 
? ? 2310L, 2709L, 29025L, 3201L, 36008L, 390899L, 4301L, 46184L, 
? ? 4805L, 206L, 504L, 817L, 813L, 12135L, 1519L, 1810L, 2104L, 
? ? 2402L, 28130L, 30030L, 3305L, 3707L, 411399L, 45165L, 46181L, 
? ? 5008L, 305L, 7026L, 803L, 1006L, 1413L, 16078L, 200999L, 
? ? 2312L, 2712L, 29069L, 3210L, 3616L, 391199L, 4313L, 46105L, 
? ? 4805L, 310L, 6153L, 8252L, 8205L, 1205L, 1505L, 1808L, 2110L, 
? ? 2508L, 2810L, 311399L, 3405L, 3807L, 41024L, 4507L, 46102L, 
? ? 500599L, 3014L, 706L, 8121L, 11028L, 14042L, 1712L, 20045L, 
? ? 2314L, 27031L, 29901L, 33024L, 3614L, 400199L, 4307L, 46021L, 
? ? 4805L, 3066L, 6153L, 8015L, 901L, 12040L, 1522L, 1806L, 2203L, 
? ? 2508L, 28047L, 311099L, 35004L, 3801L, 410199L, 4515L, 46017L, 
? ? 501199L, 407L, 7027L, 827L, 1102L, 1404L, 17155L, 200599L, 
? ? 24089L, 2812L, 30019L, 33024L, 3612L, 41038L, 4301L, 4628L, 
? ? 4805L, 307L, 6153L, 817L, 1004L, 1309L, 1508L, 1804L, 2206L, 
? ? 2606L, 28130L, 310799L, 35011L, 38022L, 411399L, 4622L, 4701L, 
? ? 1036L, 4079L, 807L, 803L, 1108L, 1410L, 1708L, 201399L, 2410L, 
? ? 28058L, 30043L, 33024L, 3610L, 410399L, 4401L, 4621L, 490499L, 
? ? 3059L, 6153L), NATIONALITY = structure(c(1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 
? ? 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 
? ? 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
? ? 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
? ? 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
? ? 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
? ? 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
? ? 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
? ? 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
? ? 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 
? ? 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
? ? 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
? ? 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
? ? 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 13L, 13L), .Label = c("SPAIN_1998", 
? ? "EU15DC_1998", "ROE_1998", "MAGREB_1998", "SSA_1998", "LA_1998", 
? ? "ASIA_1998", "ROW_1998", "Total_1998", "SPAIN_1999", "EU15DC_1999", 
? ? "ROE_1999", "MAGREB_1999", "SSA_1999", "LA_1999", "ASIA_1999", 
? ? "ROW_1999", "Total_1999", "SPAIN_2000", "EU15DC_2000", "ROE_2000", 
? ? "MAGREB_2000", "SSA_2000", "LA_2000", "ASIA_2000", "ROW_2000", 
? ? "Total_2000", "SPAIN_2001", "EU15DC_2001", "ROE_2001", "MAGREB_2001", 
? ? "SSA_2001", "LA_2001", "ASIA_2001", "ROW_2001", "Total_2001", 
? ? "SPAIN_2002", "EU15DC_2002", "ROE_2002", "MAGREB_2002", "SSA_2002", 
? ? "LA_2002", "ASIA_2002", "ROW_2002", "Total_2002", "SPAIN_2003", 
? ? "EU15DC_2003", "ROE_2003", "MAGREB_2003", "SSA_2003", "LA_2003", 
? ? "ASIA_2003", "ROW_2003", "Total_2003", "SPAIN_2004", "EU15DC_2004", 
? ? "ROE_2004", "MAGREB_2004", "SSA_2004", "LA_2004", "ASIA_2004", 
? ? "ROW_2004", "Total_2004", "SPAIN_2005", "EU15DC_2005", "ROE_2005", 
? ? "MAGREB_2005", "SSA_2005", "LA_2005", "ASIA_2005", "ROW_2005", 
? ? "Total_2005", "SPAIN_2006", "EU15DC_2006", "ROE_2006", "MAGREB_2006", 
? ? "SSA_2006", "LA_2006", "ASIA_2006", "ROW_2006", "Total_2006", 
? ? "SPAIN_2007", "EU15DC_2007", "ROE_2007", "MAGREB_2007", "SSA_2007", 
? ? "LA_2007", "ASIA_2007", "ROW_2007", "Total_2007", "SPAIN_2008", 
? ? "EU15DC_2008", "ROE_2008", "MAGREB_2008", "SSA_2008", "LA_2008", 
? ? "ASIA_2008", "ROW_2008", "Total_2008", "SPAIN_2009", "EU15DC_2009", 
? ? "ROE_2009", "MAGREB_2009", "SSA_2009", "LA_2009", "ASIA_2009", 
? ? "ROW_2009", "Total_2009", "SPAIN_2010", "EU15DC_2010", "ROE_2010", 
? ? "MAGREB_2010", "SSA_2010", "LA_2010", "ASIA_2010", "ROW_2010", 
? ? "Total_2010", "SPAIN_2011", "EU15DC_2011", "ROE_2011", "MAGREB_2011", 
? ? "SSA_2011", "LA_2011", "ASIA_2011", "ROW_2011", "Total_2011", 
? ? "SPAIN_2012", "EU15DC_2012", "ROE_2012", "MAGREB_2012", "SSA_2012", 
? ? "LA_2012", "ASIA_2012", "ROW_2012", "Total_2012", "NOTSPAIN_1998", 
? ? "NOTSPAIN_1999", "NOTSPAIN_2000", "NOTSPAIN_2001", "NOTSPAIN_2002", 
? ? "NOTSPAIN_2003", "NOTSPAIN_2004", "NOTSPAIN_2005", "NOTSPAIN_2006", 
? ? "NOTSPAIN_2007", "NOTSPAIN_2008", "NOTSPAIN_2009", "NOTSPAIN_2010", 
? ? "NOTSPAIN_2011", "NOTSPAIN_2012", "AFRICA_1998", "AFRICA_1999", 
? ? "AFRICA_2000", "AFRICA_2001", "AFRICA_2002", "AFRICA_2003", 
? ? "AFRICA_2004", "AFRICA_2005", "AFRICA_2006", "AFRICA_2007", 
? ? "AFRICA_2008", "AFRICA_2009", "AFRICA_2010", "AFRICA_2011", 
? ? "AFRICA_2012", "DWC_1998", "DWC_1999", "DWC_2000", "DWC_2001", 
? ? "DWC_2002", "DWC_2003", "DWC_2004", "DWC_2005", "DWC_2006", 
? ? "DWC_2007", "DWC_2008", "DWC_2009", "DWC_2010", "DWC_2011", 
? ? "DWC_2012"), class = "factor"), FREQUENCY = c(600, 1000, 
? ? 500, 2000, 1000, 10000, 900, 
? ? 1000, 600, 1000, 1000, 600, 600, 900, 500, 
? ? 1000, 1000, 10, 0, 10,0, 0, 
? ? 0, 0, 0, 0, 20, 0, 10, 0, 1, 0, 10, 0, 0, 0, 10, 0, 
? ? 0, 0, 0, 0, 7, 1, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 
? ? 0, 0, 0, 0, 0, 10, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
? ? 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 11, 0, 0, 0, 3, 2, 1, 5, 
? ? 60, 1, 50, 1, 0, 0, 10, 0, 1, 1, 1, 0, 0, 0, 
? ? 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
? ? 0, 0, 0, 0, 0, 0, 0, 213, 97, 989, 88, 
? ? 42, 10, 17, 0, 60, 100, 60, 
? ? 1761, 700, 600, 400, 1000, 400, 900, 700, 
? ? 1000, 1000, 700, 900, 700, 3000, 1000, 1000, 10000, 500, 
? ? 344, 67, 82, 87, 1, 0, 10, 0, 1, 3, 3, 0, 0, 1, 8, 3, 
? ? 12, 0, 2, 1, 0, 4, 0, 0, 0, 0, 0, 0, 1, 100, 0, 7, 0, 0, 0, 
? ? 0, 0, 5, 2), YEAR = c("Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality")), .Names = c("PROVINCE", "AGE5", "ZONA91OK", 
"NATIONALITY", "FREQUENCY", "YEAR"), row.names = c(1L, 501L, 
1001L, 1501L, 2001L, 2501L, 3001L, 3501L, 4001L, 4501L, 5001L, 
5501L, 6001L, 6501L, 7001L, 7501L, 8001L, 8501L, 9001L, 9501L, 
10001L, 10501L, 11001L, 11501L, 12001L, 12501L, 13001L, 13501L, 
14001L, 14501L, 15001L, 15501L, 16001L, 16501L, 17001L, 17501L, 
18001L, 18501L, 19001L, 19501L, 20001L, 20501L, 21001L, 21501L, 
22001L, 22501L, 23001L, 23501L, 24001L, 24501L, 25001L, 25501L, 
26001L, 26501L, 27001L, 27501L, 28001L, 28501L, 29001L, 29501L, 
30001L, 30501L, 31001L, 31501L, 32001L, 32501L, 33001L, 33501L, 
34001L, 34501L, 35001L, 35501L, 36001L, 36501L, 37001L, 37501L, 
38001L, 38501L, 39001L, 39501L, 40001L, 40501L, 41001L, 41501L, 
42001L, 42501L, 43001L, 43501L, 44001L, 44501L, 45001L, 45501L, 
46001L, 46501L, 47001L, 47501L, 48001L, 48501L, 49001L, 49501L, 
50001L, 50501L, 51001L, 51501L, 52001L, 52501L, 53001L, 53501L, 
54001L, 54501L, 55001L, 55501L, 56001L, 56501L, 57001L, 57501L, 
58001L, 58501L, 59001L, 59501L, 60001L, 60501L, 61001L, 61501L, 
62001L, 62501L, 63001L, 63501L, 64001L, 64501L, 65001L, 65501L, 
66001L, 66501L, 67001L, 67501L, 68001L, 68501L, 69001L, 69501L, 
70001L, 70501L, 71001L, 71501L, 72001L, 72501L, 73001L, 73501L, 
74001L, 74501L, 75001L, 75501L, 76001L, 76501L, 77001L, 77501L, 
78001L, 78501L, 79001L, 79501L, 80001L, 80501L, 81001L, 81501L, 
82001L, 82501L, 83001L, 83501L, 84001L, 84501L, 85001L, 85501L, 
86001L, 86501L, 87001L, 87501L, 88001L, 88501L, 89001L, 89501L, 
90001L, 90501L, 91001L, 91501L, 92001L, 92501L, 93001L, 93501L, 
94001L, 94501L, 95001L, 95501L, 96001L, 96501L, 97001L, 97501L, 
98001L, 98501L, 99001L, 99501L), class = "data.frame")


From smartpink111 at yahoo.com  Mon Oct  7 16:09:39 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 7 Oct 2013 07:09:39 -0700 (PDT)
Subject: [R] Data Frame Operation: Replace values based on contraints
In-Reply-To: <1381151780.51762.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1381151780.51762.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1381154979.26172.YahooMailNeo@web142601.mail.bf1.yahoo.com>




Hi,
Try:
datNew <- read.table(text=as.character(mydata$NATIONALITY),sep="_")
?mydata2 <- within(mydata,{NATIONALITY <- as.character(datNew[,1]);YEAR <- datNew[,2]})
?head(mydata2)
#???? PROVINCE? AGE5 ZONA91OK NATIONALITY FREQUENCY YEAR
#1?????????? 1 10-14????? 101?????? SPAIN?????? 600 1998
#501???????? 4 30-34???? 4079?????? SPAIN????? 1000 1998
#1001??????? 7 50-54????? 712?????? SPAIN?????? 500 1998
#1501??????? 8 40-44???? 8205?????? SPAIN????? 2000 1998
#2001?????? 11 35-39??? 11022?????? SPAIN????? 1000 1998
#2501?????? 14 40-44??? 14021?????? SPAIN???? 10000 1998


A.K.




I have a dataset in which I want to split a variable in two variables, one telling me the nationality and the other the year. 

YEAR: four digit number with the year 
NATIONALITY: code for the nationality (e.g. SPAIN, EU15DC, etc.) 


? row PROVINCE??? AGE5??? ZONA91OK??? NATIONALITY??? FREQUENCY ???? YEAR 
? 1??? 1??? 10-14??? 101??? SPAIN_1998??? 614.000000??? Nationality 
? 501??? 4??? 30-34??? 4079??? SPAIN_1998??? 1943.000000??? Nationality 
? 1001??? 7??? 50-54??? 712??? SPAIN_1998??? 596.053095??? Nationality 
? 1501??? 8??? 40-44??? 8205??? SPAIN_1998??? 2012.674138??? Nationality 

so I would like to replace for instance: 
NATIONALITY: SPAIN_1998 

with 

NATIONALITY: SPAIN 

and for the corresponding rows 

YEAR: 1998 

Any help on the issue is very appreciated! 

Here is a reproducible sample: 
mydata<- ?structure(list(PROVINCE = c(1L, 4L, 7L, 8L, 11L, 14L, 17L, 20L, 
24L, 28L, 30L, 33L, 36L, 41L, 44L, 46L, 48L, 3L, 6L, 8L, 10L, 
13L, 15L, 18L, 23L, 26L, 29L, 31L, 35L, 38L, 41L, 46L, 47L, 2L, 
4L, 8L, 8L, 11L, 15L, 17L, 21L, 24L, 28L, 30L, 33L, 37L, 41L, 
45L, 46L, 49L, 3L, 6L, 8L, 10L, 13L, 15L, 19L, 23L, 27L, 29L, 
32L, 36L, 39L, 43L, 46L, 48L, 2L, 5L, 8L, 8L, 12L, 15L, 18L, 
21L, 24L, 28L, 30L, 33L, 37L, 41L, 45L, 46L, 50L, 3L, 7L, 8L, 
10L, 14L, 16L, 20L, 23L, 27L, 29L, 32L, 36L, 39L, 43L, 46L, 48L, 
3L, 6L, 8L, 8L, 12L, 15L, 18L, 21L, 25L, 28L, 31L, 34L, 38L, 
41L, 45L, 46L, 50L, 3L, 7L, 8L, 11L, 14L, 17L, 20L, 23L, 27L, 
29L, 33L, 36L, 40L, 43L, 46L, 48L, 3L, 6L, 8L, 9L, 12L, 15L, 
18L, 22L, 25L, 28L, 31L, 35L, 38L, 41L, 45L, 46L, 50L, 4L, 7L, 
8L, 11L, 14L, 17L, 20L, 24L, 28L, 30L, 33L, 36L, 41L, 43L, 46L, 
48L, 3L, 6L, 8L, 10L, 13L, 15L, 18L, 22L, 26L, 28L, 31L, 35L, 
38L, 41L, 46L, 47L, 1L, 4L, 8L, 8L, 11L, 14L, 17L, 20L, 24L, 
28L, 30L, 33L, 36L, 41L, 44L, 46L, 49L, 3L, 6L), AGE5 = structure(c(1L, 
5L, 9L, 7L, 6L, 7L, 5L, 8L, 3L, 3L, 3L, 5L, 8L, 2L, 3L, 6L, 9L, 
5L, 7L, 4L, 3L, 5L, 8L, 8L, 2L, 8L, 2L, 9L, 7L, 9L, 9L, 2L, 7L, 
2L, 9L, 1L, 8L, 8L, 1L, 8L, 1L, 6L, 4L, 6L, 7L, 2L, 3L, 1L, 7L, 
5L, 6L, 9L, 5L, 6L, 8L, 9L, 3L, 4L, 3L, 4L, 4L, 1L, 3L, 1L, 2L, 
2L, 6L, 6L, 2L, 9L, 2L, 2L, 1L, 5L, 9L, 5L, 8L, 9L, 7L, 4L, 3L, 
7L, 2L, 8L, 2L, 6L, 9L, 1L, 5L, 1L, 6L, 6L, 6L, 7L, 3L, 6L, 3L, 
3L, 4L, 1L, 1L, 2L, 9L, 6L, 4L, 3L, 8L, 3L, 7L, 1L, 5L, 2L, 6L, 
6L, 8L, 5L, 9L, 5L, 6L, 2L, 3L, 1L, 4L, 8L, 9L, 8L, 1L, 5L, 1L, 
6L, 4L, 6L, 2L, 3L, 3L, 5L, 9L, 5L, 5L, 4L, 7L, 8L, 4L, 2L, 5L, 
7L, 8L, 9L, 8L, 3L, 7L, 7L, 5L, 6L, 3L, 6L, 1L, 2L, 2L, 3L, 7L, 
1L, 9L, 5L, 8L, 4L, 5L, 4L, 1L, 3L, 7L, 7L, 9L, 3L, 9L, 7L, 5L, 
7L, 8L, 1L, 4L, 4L, 6L, 1L, 8L, 7L, 8L, 6L, 8L, 4L, 3L, 4L, 5L, 
9L, 2L, 6L, 6L, 1L, 5L, 7L), .Label = c("10-14", "15-19", "20-24", 
"25-29", "30-34", "35-39", "40-44", "45-49", "50-54"), class = "factor"), 
? ? ZONA91OK = c(101L, 4079L, 712L, 8205L, 11022L, 14021L, 1714L, 
? ? 20067L, 2414L, 2810L, 300799L, 3305L, 36026L, 41024L, 4405L, 
? ? 4607L, 48015L, 308L, 610L, 8121L, 1006L, 1307L, 1511L, 1813L, 
? ? 2308L, 2605L, 2910L, 310799L, 35026L, 3811L, 411199L, 4601L, 
? ? 4708L, 202L, 405L, 8015L, 837L, 11033L, 1502L, 1702L, 2112L, 
? ? 2408L, 28047L, 30015L, 3305L, 3709L, 410199L, 4511L, 1202L, 
? ? 490699L, 3063L, 610L, 827L, 1006L, 1301L, 15036L, 1901L, 
? ? 2310L, 2709L, 29025L, 3201L, 36008L, 390899L, 4301L, 46184L, 
? ? 4805L, 206L, 504L, 817L, 813L, 12135L, 1519L, 1810L, 2104L, 
? ? 2402L, 28130L, 30030L, 3305L, 3707L, 411399L, 45165L, 46181L, 
? ? 5008L, 305L, 7026L, 803L, 1006L, 1413L, 16078L, 200999L, 
? ? 2312L, 2712L, 29069L, 3210L, 3616L, 391199L, 4313L, 46105L, 
? ? 4805L, 310L, 6153L, 8252L, 8205L, 1205L, 1505L, 1808L, 2110L, 
? ? 2508L, 2810L, 311399L, 3405L, 3807L, 41024L, 4507L, 46102L, 
? ? 500599L, 3014L, 706L, 8121L, 11028L, 14042L, 1712L, 20045L, 
? ? 2314L, 27031L, 29901L, 33024L, 3614L, 400199L, 4307L, 46021L, 
? ? 4805L, 3066L, 6153L, 8015L, 901L, 12040L, 1522L, 1806L, 2203L, 
? ? 2508L, 28047L, 311099L, 35004L, 3801L, 410199L, 4515L, 46017L, 
? ? 501199L, 407L, 7027L, 827L, 1102L, 1404L, 17155L, 200599L, 
? ? 24089L, 2812L, 30019L, 33024L, 3612L, 41038L, 4301L, 4628L, 
? ? 4805L, 307L, 6153L, 817L, 1004L, 1309L, 1508L, 1804L, 2206L, 
? ? 2606L, 28130L, 310799L, 35011L, 38022L, 411399L, 4622L, 4701L, 
? ? 1036L, 4079L, 807L, 803L, 1108L, 1410L, 1708L, 201399L, 2410L, 
? ? 28058L, 30043L, 33024L, 3610L, 410399L, 4401L, 4621L, 490499L, 
? ? 3059L, 6153L), NATIONALITY = structure(c(1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 
? ? 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 
? ? 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
? ? 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
? ? 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
? ? 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
? ? 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
? ? 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
? ? 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
? ? 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 
? ? 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
? ? 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
? ? 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
? ? 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 13L, 13L), .Label = c("SPAIN_1998", 
? ? "EU15DC_1998", "ROE_1998", "MAGREB_1998", "SSA_1998", "LA_1998", 
? ? "ASIA_1998", "ROW_1998", "Total_1998", "SPAIN_1999", "EU15DC_1999", 
? ? "ROE_1999", "MAGREB_1999", "SSA_1999", "LA_1999", "ASIA_1999", 
? ? "ROW_1999", "Total_1999", "SPAIN_2000", "EU15DC_2000", "ROE_2000", 
? ? "MAGREB_2000", "SSA_2000", "LA_2000", "ASIA_2000", "ROW_2000", 
? ? "Total_2000", "SPAIN_2001", "EU15DC_2001", "ROE_2001", "MAGREB_2001", 
? ? "SSA_2001", "LA_2001", "ASIA_2001", "ROW_2001", "Total_2001", 
? ? "SPAIN_2002", "EU15DC_2002", "ROE_2002", "MAGREB_2002", "SSA_2002", 
? ? "LA_2002", "ASIA_2002", "ROW_2002", "Total_2002", "SPAIN_2003", 
? ? "EU15DC_2003", "ROE_2003", "MAGREB_2003", "SSA_2003", "LA_2003", 
? ? "ASIA_2003", "ROW_2003", "Total_2003", "SPAIN_2004", "EU15DC_2004", 
? ? "ROE_2004", "MAGREB_2004", "SSA_2004", "LA_2004", "ASIA_2004", 
? ? "ROW_2004", "Total_2004", "SPAIN_2005", "EU15DC_2005", "ROE_2005", 
? ? "MAGREB_2005", "SSA_2005", "LA_2005", "ASIA_2005", "ROW_2005", 
? ? "Total_2005", "SPAIN_2006", "EU15DC_2006", "ROE_2006", "MAGREB_2006", 
? ? "SSA_2006", "LA_2006", "ASIA_2006", "ROW_2006", "Total_2006", 
? ? "SPAIN_2007", "EU15DC_2007", "ROE_2007", "MAGREB_2007", "SSA_2007", 
? ? "LA_2007", "ASIA_2007", "ROW_2007", "Total_2007", "SPAIN_2008", 
? ? "EU15DC_2008", "ROE_2008", "MAGREB_2008", "SSA_2008", "LA_2008", 
? ? "ASIA_2008", "ROW_2008", "Total_2008", "SPAIN_2009", "EU15DC_2009", 
? ? "ROE_2009", "MAGREB_2009", "SSA_2009", "LA_2009", "ASIA_2009", 
? ? "ROW_2009", "Total_2009", "SPAIN_2010", "EU15DC_2010", "ROE_2010", 
? ? "MAGREB_2010", "SSA_2010", "LA_2010", "ASIA_2010", "ROW_2010", 
? ? "Total_2010", "SPAIN_2011", "EU15DC_2011", "ROE_2011", "MAGREB_2011", 
? ? "SSA_2011", "LA_2011", "ASIA_2011", "ROW_2011", "Total_2011", 
? ? "SPAIN_2012", "EU15DC_2012", "ROE_2012", "MAGREB_2012", "SSA_2012", 
? ? "LA_2012", "ASIA_2012", "ROW_2012", "Total_2012", "NOTSPAIN_1998", 
? ? "NOTSPAIN_1999", "NOTSPAIN_2000", "NOTSPAIN_2001", "NOTSPAIN_2002", 
? ? "NOTSPAIN_2003", "NOTSPAIN_2004", "NOTSPAIN_2005", "NOTSPAIN_2006", 
? ? "NOTSPAIN_2007", "NOTSPAIN_2008", "NOTSPAIN_2009", "NOTSPAIN_2010", 
? ? "NOTSPAIN_2011", "NOTSPAIN_2012", "AFRICA_1998", "AFRICA_1999", 
? ? "AFRICA_2000", "AFRICA_2001", "AFRICA_2002", "AFRICA_2003", 
? ? "AFRICA_2004", "AFRICA_2005", "AFRICA_2006", "AFRICA_2007", 
? ? "AFRICA_2008", "AFRICA_2009", "AFRICA_2010", "AFRICA_2011", 
? ? "AFRICA_2012", "DWC_1998", "DWC_1999", "DWC_2000", "DWC_2001", 
? ? "DWC_2002", "DWC_2003", "DWC_2004", "DWC_2005", "DWC_2006", 
? ? "DWC_2007", "DWC_2008", "DWC_2009", "DWC_2010", "DWC_2011", 
? ? "DWC_2012"), class = "factor"), FREQUENCY = c(600, 1000, 
? ? 500, 2000, 1000, 10000, 900, 
? ? 1000, 600, 1000, 1000, 600, 600, 900, 500, 
? ? 1000, 1000, 10, 0, 10,0, 0, 
? ? 0, 0, 0, 0, 20, 0, 10, 0, 1, 0, 10, 0, 0, 0, 10, 0, 
? ? 0, 0, 0, 0, 7, 1, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 
? ? 0, 0, 0, 0, 0, 10, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
? ? 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 11, 0, 0, 0, 3, 2, 1, 5, 
? ? 60, 1, 50, 1, 0, 0, 10, 0, 1, 1, 1, 0, 0, 0, 
? ? 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
? ? 0, 0, 0, 0, 0, 0, 0, 213, 97, 989, 88, 
? ? 42, 10, 17, 0, 60, 100, 60, 
? ? 1761, 700, 600, 400, 1000, 400, 900, 700, 
? ? 1000, 1000, 700, 900, 700, 3000, 1000, 1000, 10000, 500, 
? ? 344, 67, 82, 87, 1, 0, 10, 0, 1, 3, 3, 0, 0, 1, 8, 3, 
? ? 12, 0, 2, 1, 0, 4, 0, 0, 0, 0, 0, 0, 1, 100, 0, 7, 0, 0, 0, 
? ? 0, 0, 5, 2), YEAR = c("Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality", "Nationality", "Nationality", "Nationality", 
? ? "Nationality")), .Names = c("PROVINCE", "AGE5", "ZONA91OK", 
"NATIONALITY", "FREQUENCY", "YEAR"), row.names = c(1L, 501L, 
1001L, 1501L, 2001L, 2501L, 3001L, 3501L, 4001L, 4501L, 5001L, 
5501L, 6001L, 6501L, 7001L, 7501L, 8001L, 8501L, 9001L, 9501L, 
10001L, 10501L, 11001L, 11501L, 12001L, 12501L, 13001L, 13501L, 
14001L, 14501L, 15001L, 15501L, 16001L, 16501L, 17001L, 17501L, 
18001L, 18501L, 19001L, 19501L, 20001L, 20501L, 21001L, 21501L, 
22001L, 22501L, 23001L, 23501L, 24001L, 24501L, 25001L, 25501L, 
26001L, 26501L, 27001L, 27501L, 28001L, 28501L, 29001L, 29501L, 
30001L, 30501L, 31001L, 31501L, 32001L, 32501L, 33001L, 33501L, 
34001L, 34501L, 35001L, 35501L, 36001L, 36501L, 37001L, 37501L, 
38001L, 38501L, 39001L, 39501L, 40001L, 40501L, 41001L, 41501L, 
42001L, 42501L, 43001L, 43501L, 44001L, 44501L, 45001L, 45501L, 
46001L, 46501L, 47001L, 47501L, 48001L, 48501L, 49001L, 49501L, 
50001L, 50501L, 51001L, 51501L, 52001L, 52501L, 53001L, 53501L, 
54001L, 54501L, 55001L, 55501L, 56001L, 56501L, 57001L, 57501L, 
58001L, 58501L, 59001L, 59501L, 60001L, 60501L, 61001L, 61501L, 
62001L, 62501L, 63001L, 63501L, 64001L, 64501L, 65001L, 65501L, 
66001L, 66501L, 67001L, 67501L, 68001L, 68501L, 69001L, 69501L, 
70001L, 70501L, 71001L, 71501L, 72001L, 72501L, 73001L, 73501L, 
74001L, 74501L, 75001L, 75501L, 76001L, 76501L, 77001L, 77501L, 
78001L, 78501L, 79001L, 79501L, 80001L, 80501L, 81001L, 81501L, 
82001L, 82501L, 83001L, 83501L, 84001L, 84501L, 85001L, 85501L, 
86001L, 86501L, 87001L, 87501L, 88001L, 88501L, 89001L, 89501L, 
90001L, 90501L, 91001L, 91501L, 92001L, 92501L, 93001L, 93501L, 
94001L, 94501L, 95001L, 95501L, 96001L, 96501L, 97001L, 97501L, 
98001L, 98501L, 99001L, 99501L), class = "data.frame")


From smartpink111 at yahoo.com  Mon Oct  7 14:35:59 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 7 Oct 2013 05:35:59 -0700 (PDT)
Subject: [R] Why read.table replacing space with "." in the header
Message-ID: <1381149359.25833.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Use `check.names=FALSE`
head(dd,2)
#? Phylo.Tree Genesis.Tree
#1????????? 1??????????? 2
#2????????? 2??????????? 3

?dd <- data.frame("Phylo Tree"= c(1:10), "Genesis Tree"= c(2:11),check.names=FALSE) 
head(dd,2)
#? Phylo Tree Genesis Tree
#1????????? 1??????????? 2
#2????????? 2??????????? 3
write.csv(dd,"Crish.csv",row.names=FALSE)
?yy<- read.csv("Crish.csv",header=TRUE,check.names=FALSE)
?head(yy,2)
#? Phylo Tree Genesis Tree
#1????????? 1??????????? 2
#2????????? 2??????????? 3

A.K.



Hello Guys 

Please look at the following code. I dont have "." in the input 
data frame. But why i am getting when i read the data.frame again. 

dd <- data.frame("Phylo Tree"= c(1:10), "Genesis Tree"= c(2:11)) 
?write.table(dd, "D:\\Write_XML\\testdf.csv", sep=",") 
?yy <- read.table("D:\\Write_XML\\testdf.csv", sep=",") 
?names(yy) 
[1] "Phylo.Tree" ? "Genesis.Tree" 


Thanks 
Krishna


From sarah.goslee at gmail.com  Mon Oct  7 18:03:02 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 7 Oct 2013 12:03:02 -0400
Subject: [R] Growth calculation
In-Reply-To: <OF2DCEE010.673C576C-ON65257BFD.0031CDD2-65257BFD.00323A69@polarisft.com>
References: <OF2DCEE010.673C576C-ON65257BFD.0031CDD2-65257BFD.00323A69@polarisft.com>
Message-ID: <CAM_vjukLtWXU=T7AEq7GAQ+urvmYitVWetgPC9rN9-W=G0TK=A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131007/0e5b77d6/attachment.pl>

From dimitri.liakhovitski at gmail.com  Mon Oct  7 18:04:10 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Mon, 7 Oct 2013 12:04:10 -0400
Subject: [R] Color font in verbatim text output in Shiny
Message-ID: <CAN2xGJYX49hQQocnCDsgTBd1nbvtgsJCT4bNt0yOdCW8o5ziMw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131007/6f39331e/attachment.pl>

From jarod_v6 at libero.it  Mon Oct  7 18:09:49 2013
From: jarod_v6 at libero.it (jarod_v6 at libero.it)
Date: Mon, 7 Oct 2013 18:09:49 +0200 (CEST)
Subject: [R] Information Frequency problem calculation
Message-ID: <5878049.2034711381162189183.JavaMail.defaultUser@defaultHost>

Dear All,

I Have a dataframe like that:

Name1 Name2 category

mauro francesco E234
luca   giuseppe  E5578
luca   franco  E5569
maria luca E4556
...
I would like to calculate the frequency of many time in my data I found  in 
the list name:

a<-read.table("pippo.csv",header=T,sep="\t")
name1<-as.character(a[,1])
name2<-as.character(a[,2])
category<-as.character(a[,3])

for(i in 1:lenght(name1)){
 re <-which(name1 == name2)

}

So how can create a table of frequncy of many times I found a name in column 
one respect to the second ?
Thanks in advance for your help!
M.


From flaviomargarito at gmail.com  Mon Oct  7 18:18:53 2013
From: flaviomargarito at gmail.com (Flavio Barros)
Date: Mon, 7 Oct 2013 13:18:53 -0300
Subject: [R] Indirect Association Rules
Message-ID: <CAOKagtPgp6+biGzOhfXv5=rS6V=YkGTfqxGBY_KL=Tsrmf7hag@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20131007/1331a03b/attachment.pl>

From jholtman at gmail.com  Mon Oct  7 18:38:34 2013
From: jholtman at gmail.com (jim holtman)
Date: Mon, 7 Oct 2013 12:38:34 -0400
Subject: [R] Information Frequency problem calculation
In-Reply-To: <5878049.2034711381162189183.JavaMail.defaultUser@defaultHost>
References: <5878049.2034711381162189183.JavaMail.defaultUser@defaultHost>
Message-ID: <CAAxdm-5VDhLKvWaYSB5TzKFsv_6hoFHPfn1EPQrmQ1Qse9qSHw@mail.gmail.com>

does 'table' do the job for you?

> input <- read.table(text = "Name1 Name2 category
+
+ mauro francesco E234
+ luca   giuseppe  E5578
+ luca   franco  E5569
+ maria luca E4556", header = TRUE, as.is = TRUE)
> input
  Name1     Name2 category
1 mauro francesco     E234
2  luca  giuseppe    E5578
3  luca    franco    E5569
4 maria      luca    E4556
> table(input$Name1, input$Name2)

        francesco franco giuseppe luca
  luca          0      1        1    0
  maria         0      0        0    1
  mauro         1      0        0    0
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Mon, Oct 7, 2013 at 12:09 PM, jarod_v6 at libero.it <jarod_v6 at libero.it> wrote:
> Dear All,
>
> I Have a dataframe like that:
>
> Name1 Name2 category
>
> mauro francesco E234
> luca   giuseppe  E5578
> luca   franco  E5569
> maria luca E4556
> ...
> I would like to calculate the frequency of many time in my data I found  in
> the list name:
>
> a<-read.table("pippo.csv",header=T,sep="\t")
> name1<-as.character(a[,1])
> name2<-as.character(a[,2])
> category<-as.character(a[,3])
>
> for(i in 1:lenght(name1)){
>  re <-which(name1 == name2)
>
> }
>
> So how can create a table of frequncy of many times I found a name in column
> one respect to the second ?
> Thanks in advance for your help!
> M.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Mon Oct  7 18:45:12 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 7 Oct 2013 09:45:12 -0700 (PDT)
Subject: [R] Information Frequency problem calculation
In-Reply-To: <5878049.2034711381162189183.JavaMail.defaultUser@defaultHost>
References: <5878049.2034711381162189183.JavaMail.defaultUser@defaultHost>
Message-ID: <1381164312.39371.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Not sure what your expected output would be:
a<- read.table(text="Name1 Name2 category
mauro francesco E234
luca? giuseppe? E5578
luca? franco? E5569
maria luca E4556",sep="",header=TRUE,stringsAsFactors=FALSE)
sapply(seq_len(nrow(a)),function(i) sum(a[,2] %in% a[i,1]))
#[1] 0 1 1 0


A.K.





----- Original Message -----
From: "jarod_v6 at libero.it" <jarod_v6 at libero.it>
To: r-help at r-project.org
Cc: 
Sent: Monday, October 7, 2013 12:09 PM
Subject: [R] Information Frequency problem calculation

Dear All,

I Have a dataframe like that:

Name1 Name2 category

mauro francesco E234
luca?  giuseppe? E5578
luca?  franco? E5569
maria luca E4556
...
I would like to calculate the frequency of many time in my data I found? in 
the list name:

a<-read.table("pippo.csv",header=T,sep="\t")
name1<-as.character(a[,1])
name2<-as.character(a[,2])
category<-as.character(a[,3])

for(i in 1:lenght(name1)){
re <-which(name1 == name2)

}

So how can create a table of frequncy of many times I found a name in column 
one respect to the second ?
Thanks in advance for your help!
M.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From pdxgary163 at gmail.com  Mon Oct  7 19:56:28 2013
From: pdxgary163 at gmail.com (Gary Dong)
Date: Mon, 7 Oct 2013 10:56:28 -0700
Subject: [R] Interpretation of coefficients in spatial lag models
Message-ID: <CAEVDvzWuhp34MTYkU_CdZ5ZDKLPpe4wnEhvUvWX+zBB88hx+YA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131007/5e128b5d/attachment.pl>

From prasadjoshi124 at gmail.com  Mon Oct  7 12:02:45 2013
From: prasadjoshi124 at gmail.com (Prasad Joshi)
Date: Mon, 7 Oct 2013 15:32:45 +0530
Subject: [R] Need help with plotting the graph
Message-ID: <CAFEQX0fhcbLh=AVR0guY7TG8q1skYGqaBXDXoK_tMoVv+itPJQ@mail.gmail.com>

Hello All,

The version of R I am using is as follows
> version
               _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          2
minor          14.1
year           2011
month          12
day            22
svn rev        57956
language       R
version.string R version 2.14.1 (2011-12-22)


I just few days back started using R for basic statistical analysis. I
want to plot the graph of following information


> df
                  disk vmfs  vmdk     IOPS       BW
1 naa.5000a7203007ed8f    3 eager 16886.77 65.96393
2 naa.5000a7203007ed8f    3  lazy 44623.15 174.3092
3 naa.5000a7203007ed8f    5 eager 16767.53 65.49815
4 naa.5000a7203007ed8f    5  lazy 45891.55 179.2639

> str(df)
'data.frame':    4 obs. of  5 variables:
 $ disk:List of 4
  ..$ : chr "naa.5000a7203007ed8f"
  ..$ : chr "naa.5000a7203007ed8f"
  ..$ : chr "naa.5000a7203007ed8f"
  ..$ : chr "naa.5000a7203007ed8f"
 $ vmfs:List of 4
  ..$ : num 3
  ..$ : num 3
  ..$ : num 5
  ..$ : num 5
 $ vmdk:List of 4
  ..$ : chr "eager"
  ..$ : chr "lazy"
  ..$ : chr "eager"
  ..$ : chr "lazy"
 $ IOPS:List of 4
  ..$ : num 16887
  ..$ : num 44623
  ..$ : num 16768
  ..$ : num 45892
 $ BW  :List of 4
  ..$ : num 66
  ..$ : num 174
  ..$ : num 65.5
  ..$ : num 179

I would like Y axis to represent BW and X axis to represent disk, vmfs and vmdk.

All the examples in books or online have single X axis. I could not
find an example which does something similar to what I am trying. Can
anyone please give me some pointers?

Thanks and Regards,
Prasad


From dcarlson at tamu.edu  Mon Oct  7 20:12:14 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 7 Oct 2013 13:12:14 -0500
Subject: [R] Information Frequency problem calculation
In-Reply-To: <1381164312.39371.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <5878049.2034711381162189183.JavaMail.defaultUser@defaultHost>
	<1381164312.39371.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <033301cec388$c000a780$4001f680$@tamu.edu>

If you want a symmetric table, try this:

> a<- read.table(text="Name1 Name2 category
+ mauro francesco E234
+ luca  giuseppe  E5578
+ luca  franco  E5569
+ maria luca E4556",sep="",header=TRUE,stringsAsFactors=FALSE)
> names <- sort(unique(c(a$Name1, a$Name2)))
> a$Name1 <- factor(a$Name1, names)
> a$Name2 <- factor(a$Name2, names)
> xtabs(~Name1+Name2, a)
           Name2
Name1       francesco franco giuseppe luca maria mauro
  francesco         0      0        0    0     0     0
  franco            0      0        0    0     0     0
  giuseppe          0      0        0    0     0     0
  luca              0      1        1    0     0     0
  maria             0      0        0    1     0     0
  mauro             1      0        0    0     0     0


-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352





-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of arun
Sent: Monday, October 7, 2013 11:45 AM
To: jarod_v6 at libero.it
Cc: R help
Subject: Re: [R] Information Frequency problem calculation

Hi,
Not sure what your expected output would be:
a<- read.table(text="Name1 Name2 category
mauro francesco E234
luca? giuseppe? E5578
luca? franco? E5569
maria luca E4556",sep="",header=TRUE,stringsAsFactors=FALSE)
sapply(seq_len(nrow(a)),function(i) sum(a[,2] %in% a[i,1]))
#[1] 0 1 1 0


A.K.





----- Original Message -----
From: "jarod_v6 at libero.it" <jarod_v6 at libero.it>
To: r-help at r-project.org
Cc: 
Sent: Monday, October 7, 2013 12:09 PM
Subject: [R] Information Frequency problem calculation

Dear All,

I Have a dataframe like that:

Name1 Name2 category

mauro francesco E234
luca?  giuseppe? E5578
luca?  franco? E5569
maria luca E4556
...
I would like to calculate the frequency of many time in my data
I found? in 
the list name:

a<-read.table("pippo.csv",header=T,sep="\t")
name1<-as.character(a[,1])
name2<-as.character(a[,2])
category<-as.character(a[,3])

for(i in 1:lenght(name1)){
re <-which(name1 == name2)

}

So how can create a table of frequncy of many times I found a
name in column 
one respect to the second ?
Thanks in advance for your help!
M.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From mkultrateam at yahoo.it  Mon Oct  7 17:23:17 2013
From: mkultrateam at yahoo.it (Jacopo)
Date: Mon, 7 Oct 2013 17:23:17 +0200
Subject: [R] interacting with the user: programming r in order to ask
	questions to the user
Message-ID: <5B694902-AAAF-4462-859A-B953A2A7CA10@yahoo.it>

hello everyone.
I am trying to create a model in which R asks some questions to the user,
and the user answer to them. I have already create two vector; In one there
are number ex 1,2,3,4,5,6,7,8,9,10 and in the other there are "word" ex one,
two, three, four. I would like to create a script that automatically ask
this questions, for instance "1 ? " and the user answer "one" and so on. If
the user make a mistake R remembers the mistake and ask the question again
after n questions. I think I should use while command, if , and readline but
I am not sure about that. Help is very appreciated !! Thank you in advance


From laomeng_3 at 163.com  Mon Oct  7 12:22:53 2013
From: laomeng_3 at 163.com (meng)
Date: Mon, 7 Oct 2013 18:22:53 +0800 (CST)
Subject: [R] plotting the predict values of time series
Message-ID: <77eb926f.5c04.1419270e184.Coremail.laomeng_3@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131007/679adf1e/attachment.pl>

From ch.haeni at gmail.com  Mon Oct  7 15:26:40 2013
From: ch.haeni at gmail.com (=?ISO-8859-1?Q?Christoph_H=E4ni?=)
Date: Mon, 7 Oct 2013 15:26:40 +0200
Subject: [R] GLM: Defining non-constant variance for (gaussian) family
Message-ID: <CAOKy5g94mGho+OoSc4GKGzYuc5xmW_n-6wyOatkx5TFPuu01pg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131007/1089742c/attachment.pl>

From dcarlson at tamu.edu  Mon Oct  7 22:18:52 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 7 Oct 2013 15:18:52 -0500
Subject: [R] Need help with plotting the graph
In-Reply-To: <CAFEQX0fhcbLh=AVR0guY7TG8q1skYGqaBXDXoK_tMoVv+itPJQ@mail.gmail.com>
References: <CAFEQX0fhcbLh=AVR0guY7TG8q1skYGqaBXDXoK_tMoVv+itPJQ@mail.gmail.com>
Message-ID: <035001cec39a$70eccc70$52c66550$@tamu.edu>

First. You should update R to the latest version, 3.0.2.

Second. What commands have you tried and what error messages did
you receive?

Third. Use dput(df) and send the output to the mailing list. A
data frame usually consists of several vectors, not several
lists. It might be necessary to explain how you created or
obtained df. 

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Prasad Joshi
Sent: Monday, October 7, 2013 5:03 AM
To: r-help at r-project.org
Subject: [R] Need help with plotting the graph

Hello All,

The version of R I am using is as follows
> version
               _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          2
minor          14.1
year           2011
month          12
day            22
svn rev        57956
language       R
version.string R version 2.14.1 (2011-12-22)


I just few days back started using R for basic statistical
analysis. I
want to plot the graph of following information


> df
                  disk vmfs  vmdk     IOPS       BW
1 naa.5000a7203007ed8f    3 eager 16886.77 65.96393
2 naa.5000a7203007ed8f    3  lazy 44623.15 174.3092
3 naa.5000a7203007ed8f    5 eager 16767.53 65.49815
4 naa.5000a7203007ed8f    5  lazy 45891.55 179.2639

> str(df)
'data.frame':    4 obs. of  5 variables:
 $ disk:List of 4
  ..$ : chr "naa.5000a7203007ed8f"
  ..$ : chr "naa.5000a7203007ed8f"
  ..$ : chr "naa.5000a7203007ed8f"
  ..$ : chr "naa.5000a7203007ed8f"
 $ vmfs:List of 4
  ..$ : num 3
  ..$ : num 3
  ..$ : num 5
  ..$ : num 5
 $ vmdk:List of 4
  ..$ : chr "eager"
  ..$ : chr "lazy"
  ..$ : chr "eager"
  ..$ : chr "lazy"
 $ IOPS:List of 4
  ..$ : num 16887
  ..$ : num 44623
  ..$ : num 16768
  ..$ : num 45892
 $ BW  :List of 4
  ..$ : num 66
  ..$ : num 174
  ..$ : num 65.5
  ..$ : num 179

I would like Y axis to represent BW and X axis to represent
disk, vmfs and vmdk.

All the examples in books or online have single X axis. I could
not
find an example which does something similar to what I am
trying. Can
anyone please give me some pointers?

Thanks and Regards,
Prasad

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From jim at bitwrit.com.au  Mon Oct  7 22:31:44 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 08 Oct 2013 07:31:44 +1100
Subject: [R] Need help with plotting the graph
In-Reply-To: <CAFEQX0fhcbLh=AVR0guY7TG8q1skYGqaBXDXoK_tMoVv+itPJQ@mail.gmail.com>
References: <CAFEQX0fhcbLh=AVR0guY7TG8q1skYGqaBXDXoK_tMoVv+itPJQ@mail.gmail.com>
Message-ID: <52531A30.9010007@bitwrit.com.au>

On 10/07/2013 09:02 PM, Prasad Joshi wrote:
> Hello All,
> ....
> I would like Y axis to represent BW and X axis to represent disk, vmfs and vmdk.
>
> All the examples in books or online have single X axis. I could not
> find an example which does something similar to what I am trying. Can
> anyone please give me some pointers?
>
Hi Prasad,
You may want something like the following:

df<-read.table(
  text="disk vmfs  vmdk     IOPS       BW
  naa.5000a7203007ed8f    3 eager 16886.77 65.96393 

  naa.5000a7203007ed8f    3  lazy 44623.15 174.3092
  naa.5000a7203007ed8f    5 eager 16767.53 65.49815
  naa.5000a7203007ed8f    5  lazy 45891.55 179.2639",
  header=TRUE)
x11(width=10,height=5)
par(mfrow=c(1,3))
brkdn_disk<-by(df$BW,df$disk,FUN=mean)
plot(brkdn_disk,xaxt="n")
axis(1,at=1:length(brkdn_disk),labels=names(brkdn_disk))
brkdn_vmfs<-by(df$BW,df$vmfs,FUN=mean)
plot(brkdn_vmfs,xaxt="n")
axis(1,at=1:length(brkdn_vmfs),labels=names(brkdn_vmfs))
brkdn_vmdk<-by(df$BW,df$vmdk,FUN=mean)
plot(brkdn_vmdk,xaxt="n")
axis(1,at=1:length(brkdn_vmdk),labels=names(brkdn_vmdk))

You can also have the plots in a vertical format by using:

par(mfrow=c(3,1))

Jim


From macqueen1 at llnl.gov  Mon Oct  7 22:52:18 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 7 Oct 2013 20:52:18 +0000
Subject: [R] Subsetting Timestamped data
In-Reply-To: <20131004160335.Horde.M-GXYM1vlIJSTtjHyfFVKUA@webmail.bath.ac.uk>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D47BDE0@PRDEXMBX-08.the-lab.llnl.gov>

Here is an approach using base R tools (not tested, so I hope I don't
embarrass myself!)

dayid <- format(data$TimeStamp, '%Y-%m-%d')
day.counts <- table(dayid)
good.days <- names(day.counts)[day.counts == 48]
subset(data, dayid %in% good.days)

This could be written in a one-liner, but it's much easier to understand
and to check if done step by step.

(And I'll indulge in a side comment ... as a matter of personal opinion, I
think it's beneficial to learn how to do basic data manipulation using
base R tools before delving into the use of more sophisticated functions
from various packages. This helps build R skills.)

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/4/13 8:03 AM, "aj409 at bath.ac.uk" <aj409 at bath.ac.uk> wrote:

>
>Hi,
>
>I have a data frame, data, containing two columns: one- the TimeStamp
>(formatted using data$TimeStamp <-
>as.POSTIXct(as.character(data$TimeStamp), format = "%d/%m/%Y %H:%M") )
>and two- the data value.
>
>The data frame has been read from a .csv file and should contain 48
>values for each day of the year (values sampled at 30 minute
>intervals). However, there are only 15,948 observations i.e. only
>approx 332 days worth of data. I therefore would like to remove any
>days that do not contain the 48 values.
>
>My question, how would I go about doing this?
>
>Many thanks,
>
>-A.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From David.Reiner at xrtrading.com  Mon Oct  7 23:29:02 2013
From: David.Reiner at xrtrading.com (David Reiner)
Date: Mon, 7 Oct 2013 16:29:02 -0500
Subject: [R] Color font in verbatim text output in Shiny
In-Reply-To: <CAN2xGJYX49hQQocnCDsgTBd1nbvtgsJCT4bNt0yOdCW8o5ziMw@mail.gmail.com>
References: <CAN2xGJYX49hQQocnCDsgTBd1nbvtgsJCT4bNt0yOdCW8o5ziMw@mail.gmail.com>
Message-ID: <9DE405308A6AA24AA794B76282C6C00F4A58DF5D6B@HQ-POST1>

inline below.
HTH,
-- David

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Dimitri Liakhovitski
Sent: Monday, October 07, 2013 11:04 AM
To: r-help
Subject: [R] Color font in verbatim text output in Shiny

Hello!

Is there any way to change the colors (and other characteristics) of the
font that is being used by Shiny when the ui.r code hase some
verbatimTextOutput?

For example, I am producing 2 outputs in two tabs.

  mainPanel(
    tabsetPanel(
# You can set many attributes, not just colors
    tags$style(type='text/css', '#myoutput1 {background-color: rgba(255,255,0,0.40); color: green;}'),
    tags$style(type='text/css', '#myoutput2 {background-color: rgba(0,0,255,0.10); color: blue;}'),

    tabPanel("Output 1", verbatimTextOutput("myoutput1")),
    tabPanel("Output 2", verbatimTextOutput("myoutput2"))
    )
  )


Thank you!
Dimitri Liakhovitski

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


This e-mail and any materials attached hereto, including, without limitation, all content hereof and thereof (collectively, "XR Content") are confidential and proprietary to XR Trading, LLC ("XR") and/or its affiliates, and are protected by intellectual property laws.  Without the prior written consent of XR, the XR Content may not (i) be disclosed to any third party or (ii) be reproduced or otherwise used by anyone other than current employees of XR or its affiliates, on behalf of XR or its affiliates.

THE XR CONTENT IS PROVIDED AS IS, WITHOUT REPRESENTATIONS OR WARRANTIES OF ANY KIND.  TO THE MAXIMUM EXTENT PERMISSIBLE UNDER APPLICABLE LAW, XR HEREBY DISCLAIMS ANY AND ALL WARRANTIES, EXPRESS AND IMPLIED, RELATING TO THE XR CONTENT, AND NEITHER XR NOR ANY OF ITS AFFILIATES SHALL IN ANY EVENT BE LIABLE FOR ANY DAMAGES OF ANY NATURE WHATSOEVER, INCLUDING, BUT NOT LIMITED TO, DIRECT, INDIRECT, CONSEQUENTIAL, SPECIAL AND PUNITIVE DAMAGES, LOSS OF PROFITS AND TRADING LOSSES, RESULTING FROM ANY PERSON'S USE OR RELIANCE UPON, OR INABILITY TO USE, ANY XR CONTENT, EVEN IF XR IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR IF SUCH DAMAGES WERE FORESEEABLE.


From Jason.Law at portlandoregon.gov  Mon Oct  7 23:41:10 2013
From: Jason.Law at portlandoregon.gov (Law, Jason)
Date: Mon, 7 Oct 2013 14:41:10 -0700
Subject: [R] Transposing the output of 'table'
In-Reply-To: <0F962A7E-8825-4EBF-A108-D815432C3FA8@plessthan.com>
References: <0F962A7E-8825-4EBF-A108-D815432C3FA8@plessthan.com>
Message-ID: <0EFBC7C31DB4F24F8CAC48136A1762D70184EDC02B14@MAIL2.rose.portland.local>

If you want a dataframe rather than a matrix, I often use the as.data.frame method for table objects.  See ?table for the documentation.  You can even nicely name the dimensions and frequency.

OBJECT <- sample(4, 20, TRUE)

as.data.frame(table(var1 = OBJECT), responseName = 'frequency')

Jason

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Dennis Fisher
Sent: Sunday, October 06, 2013 10:31 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Transposing the output of 'table'

R 3.0.1
OS X

Colleagues,

If I execute the command:
	table(OBJECT)
the output might look like:
  1   2 
 25 336 

I would like it to appear as:
	1	25
	2	336

I can accomplish this with:
	TABLE	<- table(OBJECT)
	data.frame(names(TABLE), as.numeric(TABLE))

However, I bet that a more clever approach exists?  Any takers?

Dennis


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Tue Oct  8 00:11:46 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 8 Oct 2013 00:11:46 +0200
Subject: [R] FW:  Transposing the output of 'table'
In-Reply-To: <CALxSy07ABgvZFjx1fhUOpTc5F9s-G6WXUnenTBJOS-OMv3HHgQ@mail.gmail.com>
References: <0F962A7E-8825-4EBF-A108-D815432C3FA8@plessthan.com>
	<2D8BB763-E443-42DB-A61B-F2744CF05E09@xs4all.nl>
	<a00999f0b3654b3f87084f257105cab2@CAE145HUBP03.ds.sc.edu>
	<CALxSy07ABgvZFjx1fhUOpTc5F9s-G6WXUnenTBJOS-OMv3HHgQ@mail.gmail.com>
Message-ID: <44D0AC9D-ACF2-431D-8FAC-F3E3B79053C1@gmail.com>


On Oct 6, 2013, at 20:25 , Andrea Lamont wrote:

> If t(table(OBJECT)) does not work, does:
> u<-as.matrix(table(OBJ))
> t(u)
> 
> -i.e. use matrix operations?


Please try before posting...

table() results in a 1d table, i.e. a vector; t() of a vector is a row matrix, so it still displays horisontally. To get a column matrix, it works to transpose twice, but as.matrix works too, as others have already pointed out. I think my favorite is to use cbind(), which conveniently also allows you to set a heading:

> cbind(Freq=table(airquality$Month))
  Freq
5   31
6   30
7   31
8   31
9   30

- Peter D.

> 
> 
> 
> 
> On Sun, Oct 6, 2013 at 1:47 PM, LAMONT, ANDREA <LAMONTA at mailbox.sc.edu>wrote:
> 
>> 
>> 
>> 
>> ________________________________________
>> From: r-help-bounces at r-project.orgOn Behalf OfBerend Hasselman
>> Sent: Sunday, October 06, 2013 1:44:30 PM (UTC-05:00) Eastern Time (US &
>> Canada)
>> To: Dennis Fisher
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] Transposing the output of 'table'
>> 
>> On 06-10-2013, at 19:30, Dennis Fisher <fisher at plessthan.com> wrote:
>> 
>>> R 3.0.1
>>> OS X
>>> 
>>> Colleagues,
>>> 
>>> If I execute the command:
>>>      table(OBJECT)
>>> the output might look like:
>>> 1   2
>>> 25 336
>>> 
>>> I would like it to appear as:
>>>      1       25
>>>      2       336
>>> 
>>> I can accomplish this with:
>>>      TABLE   <- table(OBJECT)
>>>      data.frame(names(TABLE), as.numeric(TABLE))
>>> 
>>> However, I bet that a more clever approach exists?  Any takers?
>> 
>> 
>> Have you tried t(table(OBJECT)) ?
>> 
>> Berend
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> -- 
> Andrea Lamont, MA
> Clinical-Community Psychology
> University of South Carolina
> Barnwell College
> Columbia, SC 29208
> 
> Please consider the environment before printing this email.
> 
> CONFIDENTIAL: This transmission is intended for the use of the
> individual(s) or entity to which it is addressed, and may contain
> information that is privileged, confidential, and exempt from disclosure
> under applicable law. Should the reader of this message not be the intended
> recipient(s), you are hereby notified that any dissemination, distribution,
> or copying of this communication is strictly prohibited.  If you are not
> the intended recipient, please contact the sender by reply email and
> destroy/delete all copies of the original message.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From robert.b.lynch at gmail.com  Tue Oct  8 01:52:36 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Mon, 7 Oct 2013 16:52:36 -0700
Subject: [R] Centering multi-level unordered factors
Message-ID: <CACYeG1hG4=KJDgn9tM2ptX=mRO4=62SUkfrX_PwuM9nHrysXJg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131007/e75df433/attachment.pl>

From dwinsemius at comcast.net  Tue Oct  8 03:53:40 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 7 Oct 2013 18:53:40 -0700
Subject: [R] Centering multi-level unordered factors
In-Reply-To: <CACYeG1hG4=KJDgn9tM2ptX=mRO4=62SUkfrX_PwuM9nHrysXJg@mail.gmail.com>
References: <CACYeG1hG4=KJDgn9tM2ptX=mRO4=62SUkfrX_PwuM9nHrysXJg@mail.gmail.com>
Message-ID: <C00C83AF-B34E-45FC-A62A-DD193DAE12E4@comcast.net>


On Oct 7, 2013, at 4:52 PM, Robert Lynch wrote:

> I have a question I am not even sure quite how to ask.
> 
> When r fits models with  un-ordered categorical variables as predictors
> (RHS of model) it automatically converts them into 1 less dichotomous
> variables than there are levels.
> 
> For example  if I had levels(trait) = ("A","B","C") it would automatically
> recode to
>          NewVar1 NewVar2
> A         0               0
> B         1               0
> C          0               1
> 
> What I would like to know is, is there a way that I can "center" these
> categorical variables, and if so how
> 
> for continuous variables it is simple
> x <- x-mean(x)

You can choose different contrasts. Take a look at contr.sum()

> trait <- factor(1:3, labels = c("A","B","C"))

> contrasts(trait) <- contr.sum(3)
> model.matrix( ~trait )
  (Intercept) trait1 trait2
1           1      1      0
2           1      0      1
3           1     -1     -1
attr(,"assign")
[1] 0 1 1
attr(,"contrasts")
attr(,"contrasts")$trait
  [,1] [,2]
A    1    0
B    0    1
C   -1   -1

-- 
David.

> 
> for a single dichotomous variable it is not so hard
> gender <- gender - sum(gender)/length(gender)
> where the gender are (0,1) or (-.5,.5) for  example
> which would give  gender coefficients in a model  that would still reflect
> the difference between the two genders but the intercept and the other
> coefficients would be for some one of "average gender"
> 
> and it is that last part that I am unclear on for a multi (3 or more) level
> factor.  How do you set up variables so that the *other* coefficients
> reflect the average across the factor levels. Do I need two or three
> centered variables? and is there a quick way to get at all those variables
> if my factor has many levels, e.g. 14?
> 
> 
> Robert
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From prasadjoshi124 at gmail.com  Tue Oct  8 02:24:23 2013
From: prasadjoshi124 at gmail.com (Prasad Joshi)
Date: Tue, 8 Oct 2013 05:54:23 +0530
Subject: [R] Need help with plotting the graph
In-Reply-To: <035001cec39a$70eccc70$52c66550$@tamu.edu>
References: <CAFEQX0fhcbLh=AVR0guY7TG8q1skYGqaBXDXoK_tMoVv+itPJQ@mail.gmail.com>
	<035001cec39a$70eccc70$52c66550$@tamu.edu>
Message-ID: <CAFEQX0f-URO=hANxFz6nktXPscrTf2wHjYZyar+CQoj8nbPTeA@mail.gmail.com>

On Tue, Oct 8, 2013 at 1:48 AM, David Carlson <dcarlson at tamu.edu> wrote:
> First. You should update R to the latest version, 3.0.2.
>
Hello David,

Thanks a lot for your reply. I will update R.

>
> Third. Use dput(df) and send the output to the mailing list. A
> data frame usually consists of several vectors, not several
> lists. It might be necessary to explain how you created or
> obtained df.
>

The data is generated by reading the CSV files. The source code is as below
==============================================================
get_iops <- function(x) {
  good <- complete.cases(x$Read.IOps)
  mean(x$Read.IOps[good])
}

get_mbs <- function(x) {
  good <- complete.cases(x$Read.MBps)
  mean(x$Read.MBps[good])
}

lappend <- function(lst, obj) {
  lst[[length(lst)+1]] <- obj
  return(lst)
}

result <- list()

disk <- "naa.5000a7203007ed8f"
vmfs3_eager = read.csv("VMFS3-Thick-Eager.csv")
iops <- get_iops(vmfs3_eager)
bw <- get_mbs(vmfs3_eager)
x <- list(disk = disk, vmfs = 3, vmdk = "eager", IOPS = iops, BW = bw)
result <- lappend(result, x)

# I read 6 such CSV files
...
...

df <- as.data.frame(do.call(rbind, result))
==============================================================

> dput(df)
structure(list(disk = list("naa.5000a7203007ed8f", "naa.5000a7203007ed8f",
    "naa.5000a7203007ed8f", "naa.5000a7203007ed8f", "naa.5000a720300895c4",
    "naa.5000a720300895c4", "naa.5000a720300895c4", "naa.5000a720300895c4"),
    vmfs = list(3, 3, 5, 5, 3, 3, 5, 5), vmdk = list("eager",
        "lazy", "eager", "lazy", "eager", "lazy", "eager", "lazy"),
    IOPS = list(16886.766301, 44623.145983, 16767.526886, 45891.547436,
        16794.495655, 45289.670722, 16603.198764, 46092.4011),
    BW = list(65.963931, 174.309164, 65.498152, 179.263857, 65.603499,
        176.912776, 64.856245, 180.048442)), .Names = c("disk",
"vmfs", "vmdk", "IOPS", "BW"), row.names = c(NA, -8L), class = "data.frame")

> df
                  disk vmfs  vmdk     IOPS       BW
1 naa.5000a7203007ed8f    3 eager 16886.77 65.96393
2 naa.5000a7203007ed8f    3  lazy 44623.15 174.3092
3 naa.5000a7203007ed8f    5 eager 16767.53 65.49815
4 naa.5000a7203007ed8f    5  lazy 45891.55 179.2639
5 naa.5000a720300895c4    3 eager  16794.5  65.6035
6 naa.5000a720300895c4    3  lazy 45289.67 176.9128
7 naa.5000a720300895c4    5 eager  16603.2 64.85625
8 naa.5000a720300895c4    5  lazy  46092.4 180.0484


I used lists since, I wanted to avoid the compulsory coercion that
happens in vectors. I though using numbers for IOPS and BW would be
better for plotting the graphs.

> Second. What commands have you tried and what error messages did
> you receive?

I wanted to plot the graph of BW or IOPS against combination of
disk+vmfs+vmdk. For example: if I take the first row from above df
dataframe, I would like graph to contain BW 65 on Y axis and X axis
caption would be "naa.5000a7203007ed8f-3-eager".

I tried to plot graph using hist, plot, boxplot -- however I could not
find a way to specify multiple values for X axis.

I will look forward for your reply.

Thanks and Regards,
Prasad


> -------------------------------------
> David L Carlson
> Associate Professor of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Prasad Joshi
> Sent: Monday, October 7, 2013 5:03 AM
> To: r-help at r-project.org
> Subject: [R] Need help with plotting the graph
>
> Hello All,
>
> The version of R I am using is as follows
>> version
>                _
> platform       x86_64-pc-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          2
> minor          14.1
> year           2011
> month          12
> day            22
> svn rev        57956
> language       R
> version.string R version 2.14.1 (2011-12-22)
>
>
> I just few days back started using R for basic statistical
> analysis. I
> want to plot the graph of following information
>
>
>> df
>                   disk vmfs  vmdk     IOPS       BW
> 1 naa.5000a7203007ed8f    3 eager 16886.77 65.96393
> 2 naa.5000a7203007ed8f    3  lazy 44623.15 174.3092
> 3 naa.5000a7203007ed8f    5 eager 16767.53 65.49815
> 4 naa.5000a7203007ed8f    5  lazy 45891.55 179.2639
>
>> str(df)
> 'data.frame':    4 obs. of  5 variables:
>  $ disk:List of 4
>   ..$ : chr "naa.5000a7203007ed8f"
>   ..$ : chr "naa.5000a7203007ed8f"
>   ..$ : chr "naa.5000a7203007ed8f"
>   ..$ : chr "naa.5000a7203007ed8f"
>  $ vmfs:List of 4
>   ..$ : num 3
>   ..$ : num 3
>   ..$ : num 5
>   ..$ : num 5
>  $ vmdk:List of 4
>   ..$ : chr "eager"
>   ..$ : chr "lazy"
>   ..$ : chr "eager"
>   ..$ : chr "lazy"
>  $ IOPS:List of 4
>   ..$ : num 16887
>   ..$ : num 44623
>   ..$ : num 16768
>   ..$ : num 45892
>  $ BW  :List of 4
>   ..$ : num 66
>   ..$ : num 174
>   ..$ : num 65.5
>   ..$ : num 179
>
> I would like Y axis to represent BW and X axis to represent
> disk, vmfs and vmdk.
>
> All the examples in books or online have single X axis. I could
> not
> find an example which does something similar to what I am
> trying. Can
> anyone please give me some pointers?
>
> Thanks and Regards,
> Prasad
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
> code.
>


From prasadjoshi124 at gmail.com  Tue Oct  8 02:36:09 2013
From: prasadjoshi124 at gmail.com (Prasad Joshi)
Date: Tue, 8 Oct 2013 06:06:09 +0530
Subject: [R] Need help with plotting the graph
In-Reply-To: <52531A30.9010007@bitwrit.com.au>
References: <CAFEQX0fhcbLh=AVR0guY7TG8q1skYGqaBXDXoK_tMoVv+itPJQ@mail.gmail.com>
	<52531A30.9010007@bitwrit.com.au>
Message-ID: <CAFEQX0eoXZi83a8UqZt9_vWmpofRWyHTDxELT3h6WA+RXXv4hw@mail.gmail.com>

On Tue, Oct 8, 2013 at 2:01 AM, Jim Lemon <jim at bitwrit.com.au> wrote:
> On 10/07/2013 09:02 PM, Prasad Joshi wrote:
>>
>> Hello All,
>> ....
>>
>> I would like Y axis to represent BW and X axis to represent disk, vmfs and
>> vmdk.
>>
>> All the examples in books or online have single X axis. I could not
>> find an example which does something similar to what I am trying. Can
>> anyone please give me some pointers?
>>
> Hi Prasad,
> You may want something like the following:
>
> df<-read.table(
>  text="disk vmfs  vmdk     IOPS       BW
>
>  naa.5000a7203007ed8f    3 eager 16886.77 65.96393
>  naa.5000a7203007ed8f    3  lazy 44623.15 174.3092
>  naa.5000a7203007ed8f    5 eager 16767.53 65.49815
>  naa.5000a7203007ed8f    5  lazy 45891.55 179.2639",
>  header=TRUE)
> x11(width=10,height=5)
> par(mfrow=c(1,3))
> brkdn_disk<-by(df$BW,df$disk,FUN=mean)
> plot(brkdn_disk,xaxt="n")
> axis(1,at=1:length(brkdn_disk),labels=names(brkdn_disk))
> brkdn_vmfs<-by(df$BW,df$vmfs,FUN=mean)
> plot(brkdn_vmfs,xaxt="n")
> axis(1,at=1:length(brkdn_vmfs),labels=names(brkdn_vmfs))
> brkdn_vmdk<-by(df$BW,df$vmdk,FUN=mean)
> plot(brkdn_vmdk,xaxt="n")
> axis(1,at=1:length(brkdn_vmdk),labels=names(brkdn_vmdk))
>
> You can also have the plots in a vertical format by using:

Thanks Jim for your efforts. The code you gave works for me if I
include df <- read.table() line.

Since I am kind of new to R, I think I am not being efficient with the
data.frame df.

> dput(df)
structure(list(disk = list("naa.5000a7203007ed8f", "naa.5000a7203007ed8f",
    "naa.5000a7203007ed8f", "naa.5000a7203007ed8f", "naa.5000a720300895c4",
    "naa.5000a720300895c4", "naa.5000a720300895c4", "naa.5000a720300895c4"),
    vmfs = list(3, 3, 5, 5, 3, 3, 5, 5), vmdk = list("eager",
        "lazy", "eager", "lazy", "eager", "lazy", "eager", "lazy"),
    IOPS = list(16886.766301, 44623.145983, 16767.526886, 45891.547436,
        16794.495655, 45289.670722, 16603.198764, 46092.4011),
    BW = list(65.963931, 174.309164, 65.498152, 179.263857, 65.603499,
        176.912776, 64.856245, 180.048442)), .Names = c("disk",
"vmfs", "vmdk", "IOPS", "BW"), row.names = c(NA, -8L), class = "data.frame")

I will find the way to correctly represent the result dataframe.

Any ways thanks Jim for your reply.

Thanks and Regards,
Prasad

>
> par(mfrow=c(3,1))
>
> Jim


From petr.pikal at precheza.cz  Tue Oct  8 08:32:02 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 8 Oct 2013 06:32:02 +0000
Subject: [R] Need help with plotting the graph
In-Reply-To: <CAFEQX0f-URO=hANxFz6nktXPscrTf2wHjYZyar+CQoj8nbPTeA@mail.gmail.com>
References: <CAFEQX0fhcbLh=AVR0guY7TG8q1skYGqaBXDXoK_tMoVv+itPJQ@mail.gmail.com>
	<035001cec39a$70eccc70$52c66550$@tamu.edu>
	<CAFEQX0f-URO=hANxFz6nktXPscrTf2wHjYZyar+CQoj8nbPTeA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B95C96@SRVEXCHMBX.precheza.cz>

Hi

Your data frame is a bit weird. I changed it to more standard structure

df<-as.data.frame(lapply(df, unlist))

You can concatenate labels to one character vector
x<-with(df, paste(disk, vmfs, vmdk, sep="-"))
Then you can use barplot, however labels are quite long to fit.

barplot(df$BW, names=x)

Package plotrix can deal with alternating labels for x axis, or you can use perpendicular labeling. See las from ?par

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Prasad Joshi
> Sent: Tuesday, October 08, 2013 2:24 AM
> To: dcarlson at tamu.edu
> Cc: r-help at r-project.org
> Subject: Re: [R] Need help with plotting the graph
> 
> On Tue, Oct 8, 2013 at 1:48 AM, David Carlson <dcarlson at tamu.edu>
> wrote:
> > First. You should update R to the latest version, 3.0.2.
> >
> Hello David,
> 
> Thanks a lot for your reply. I will update R.
> 
> >
> > Third. Use dput(df) and send the output to the mailing list. A data
> > frame usually consists of several vectors, not several lists. It
> might
> > be necessary to explain how you created or obtained df.
> >
> 
> The data is generated by reading the CSV files. The source code is as
> below ==============================================================
> get_iops <- function(x) {
>   good <- complete.cases(x$Read.IOps)
>   mean(x$Read.IOps[good])
> }
> 
> get_mbs <- function(x) {
>   good <- complete.cases(x$Read.MBps)
>   mean(x$Read.MBps[good])
> }
> 
> lappend <- function(lst, obj) {
>   lst[[length(lst)+1]] <- obj
>   return(lst)
> }
> 
> result <- list()
> 
> disk <- "naa.5000a7203007ed8f"
> vmfs3_eager = read.csv("VMFS3-Thick-Eager.csv") iops <-
> get_iops(vmfs3_eager) bw <- get_mbs(vmfs3_eager) x <- list(disk = disk,
> vmfs = 3, vmdk = "eager", IOPS = iops, BW = bw) result <-
> lappend(result, x)
> 
> # I read 6 such CSV files
> ...
> ...
> 
> df <- as.data.frame(do.call(rbind, result))
> ==============================================================
> 
> > dput(df)
> structure(list(disk = list("naa.5000a7203007ed8f",
> "naa.5000a7203007ed8f",
>     "naa.5000a7203007ed8f", "naa.5000a7203007ed8f",
> "naa.5000a720300895c4",
>     "naa.5000a720300895c4", "naa.5000a720300895c4",
> "naa.5000a720300895c4"),
>     vmfs = list(3, 3, 5, 5, 3, 3, 5, 5), vmdk = list("eager",
>         "lazy", "eager", "lazy", "eager", "lazy", "eager", "lazy"),
>     IOPS = list(16886.766301, 44623.145983, 16767.526886, 45891.547436,
>         16794.495655, 45289.670722, 16603.198764, 46092.4011),
>     BW = list(65.963931, 174.309164, 65.498152, 179.263857, 65.603499,
>         176.912776, 64.856245, 180.048442)), .Names = c("disk", "vmfs",
> "vmdk", "IOPS", "BW"), row.names = c(NA, -8L), class = "data.frame")
> 
> > df
>                   disk vmfs  vmdk     IOPS       BW
> 1 naa.5000a7203007ed8f    3 eager 16886.77 65.96393
> 2 naa.5000a7203007ed8f    3  lazy 44623.15 174.3092
> 3 naa.5000a7203007ed8f    5 eager 16767.53 65.49815
> 4 naa.5000a7203007ed8f    5  lazy 45891.55 179.2639
> 5 naa.5000a720300895c4    3 eager  16794.5  65.6035
> 6 naa.5000a720300895c4    3  lazy 45289.67 176.9128
> 7 naa.5000a720300895c4    5 eager  16603.2 64.85625
> 8 naa.5000a720300895c4    5  lazy  46092.4 180.0484
> 
> 
> I used lists since, I wanted to avoid the compulsory coercion that
> happens in vectors. I though using numbers for IOPS and BW would be
> better for plotting the graphs.
> 
> > Second. What commands have you tried and what error messages did you
> > receive?
> 
> I wanted to plot the graph of BW or IOPS against combination of
> disk+vmfs+vmdk. For example: if I take the first row from above df
> dataframe, I would like graph to contain BW 65 on Y axis and X axis
> caption would be "naa.5000a7203007ed8f-3-eager".
> 
> I tried to plot graph using hist, plot, boxplot -- however I could not
> find a way to specify multiple values for X axis.
> 
> I will look forward for your reply.
> 
> Thanks and Regards,
> Prasad
> 
> 
> > -------------------------------------
> > David L Carlson
> > Associate Professor of Anthropology
> > Texas A&M University
> > College Station, TX 77840-4352
> >
> > -----Original Message-----
> > From: r-help-bounces at r-project.org
> > [mailto:r-help-bounces at r-project.org] On Behalf Of Prasad Joshi
> > Sent: Monday, October 7, 2013 5:03 AM
> > To: r-help at r-project.org
> > Subject: [R] Need help with plotting the graph
> >
> > Hello All,
> >
> > The version of R I am using is as follows
> >> version
> >                _
> > platform       x86_64-pc-linux-gnu
> > arch           x86_64
> > os             linux-gnu
> > system         x86_64, linux-gnu
> > status
> > major          2
> > minor          14.1
> > year           2011
> > month          12
> > day            22
> > svn rev        57956
> > language       R
> > version.string R version 2.14.1 (2011-12-22)
> >
> >
> > I just few days back started using R for basic statistical analysis.
> I
> > want to plot the graph of following information
> >
> >
> >> df
> >                   disk vmfs  vmdk     IOPS       BW
> > 1 naa.5000a7203007ed8f    3 eager 16886.77 65.96393
> > 2 naa.5000a7203007ed8f    3  lazy 44623.15 174.3092
> > 3 naa.5000a7203007ed8f    5 eager 16767.53 65.49815
> > 4 naa.5000a7203007ed8f    5  lazy 45891.55 179.2639
> >
> >> str(df)
> > 'data.frame':    4 obs. of  5 variables:
> >  $ disk:List of 4
> >   ..$ : chr "naa.5000a7203007ed8f"
> >   ..$ : chr "naa.5000a7203007ed8f"
> >   ..$ : chr "naa.5000a7203007ed8f"
> >   ..$ : chr "naa.5000a7203007ed8f"
> >  $ vmfs:List of 4
> >   ..$ : num 3
> >   ..$ : num 3
> >   ..$ : num 5
> >   ..$ : num 5
> >  $ vmdk:List of 4
> >   ..$ : chr "eager"
> >   ..$ : chr "lazy"
> >   ..$ : chr "eager"
> >   ..$ : chr "lazy"
> >  $ IOPS:List of 4
> >   ..$ : num 16887
> >   ..$ : num 44623
> >   ..$ : num 16768
> >   ..$ : num 45892
> >  $ BW  :List of 4
> >   ..$ : num 66
> >   ..$ : num 174
> >   ..$ : num 65.5
> >   ..$ : num 179
> >
> > I would like Y axis to represent BW and X axis to represent disk,
> vmfs
> > and vmdk.
> >
> > All the examples in books or online have single X axis. I could not
> > find an example which does something similar to what I am trying. Can
> > anyone please give me some pointers?
> >
> > Thanks and Regards,
> > Prasad
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From vksingh.iiitb at gmail.com  Tue Oct  8 08:36:56 2013
From: vksingh.iiitb at gmail.com (Vivek Singh)
Date: Tue, 8 Oct 2013 14:36:56 +0800
Subject: [R] R function for Bisecting K-means algorithm
Message-ID: <CAFgDSD6CXm2fpE55PyW0RmKyACZY6UPAZsFg1UFQistOmELW7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/925d0af4/attachment.pl>

From mohan.radhakrishnan at polarisft.com  Tue Oct  8 10:29:05 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Tue, 8 Oct 2013 13:59:05 +0530
Subject: [R] Growth calculation
In-Reply-To: <CAM_vjukLtWXU=T7AEq7GAQ+urvmYitVWetgPC9rN9-W=G0TK=A@mail.gmail.com>
References: <OF2DCEE010.673C576C-ON65257BFD.0031CDD2-65257BFD.00323A69@polarisft.com>
	<CAM_vjukLtWXU=T7AEq7GAQ+urvmYitVWetgPC9rN9-W=G0TK=A@mail.gmail.com>
Message-ID: <OF82928CF9.73075171-ON65257BFE.002E4177-65257BFE.002E92A9@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/9e133a6e/attachment.pl>

From asis.hallab at gmail.com  Tue Oct  8 11:22:53 2013
From: asis.hallab at gmail.com (Asis Hallab)
Date: Tue, 8 Oct 2013 11:22:53 +0200
Subject: [R] =?utf-8?q?What_is_the_difference_between_Reduce=28=E2=80=A6?=
	=?utf-8?b?KSBhbmQgZG8uY2FsbCjigKYpID8=?=
Message-ID: <CAPccJQEEqbT9kSimUN1BVrv49m_ho_i8e-=95c1Qx7DWk7KNrQ@mail.gmail.com>

Dear R-Experts,

using both do.call(?) and Reduce(?), I wonder about the differences of both.
Please consider the following example:

m <- matrix( 1:9, ncol=3 )
lst <- list( m, 2*m, 3*m )

rbind( lst )
# Returns
        [,1]      [,2]      [,3]
tmp.lst Integer,9 Numeric,9 Numeric,9

do.call( 'rbind', tmp.lst )
# Returns
      [,1] [,2] [,3]
 [1,]    1    4    7
 [2,]    2    5    8
 [3,]    3    6    9
 [4,]    2    8   14
 [5,]    4   10   16
 [6,]    6   12   18
 [7,]    3   12   21
 [8,]    6   15   24
 [9,]    9   18   27

Reduce( rbind, tmp.lst )
# Returns the same
      [,1] [,2] [,3]
 [1,]    1    4    7
 [2,]    2    5    8
 [3,]    3    6    9
 [4,]    2    8   14
 [5,]    4   10   16
 [6,]    6   12   18
 [7,]    3   12   21
 [8,]    6   15   24
 [9,]    9   18   27

So, what is the difference between Reduce and do.call and when best to
use which?

Your help will be much appreciated.

Kind regards!


From b.rowlingson at lancaster.ac.uk  Tue Oct  8 11:46:14 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 8 Oct 2013 10:46:14 +0100
Subject: [R]
	=?windows-1252?q?What_is_the_difference_between_Reduce=28=85?=
	=?windows-1252?q?=29_and_do=2Ecall=28=85=29_=3F?=
In-Reply-To: <a0153a73a33347a1834922b8da703d04@EX-0-HT0.lancs.local>
References: <a0153a73a33347a1834922b8da703d04@EX-0-HT0.lancs.local>
Message-ID: <CANVKczMNJfY+xXqvqd20cc1PWMNBjM9ibMRP4MXVF=mM_h8q5A@mail.gmail.com>

On Tue, Oct 8, 2013 at 10:22 AM, Asis Hallab <asis.hallab at gmail.com> wrote:
> Dear R-Experts,

> So, what is the difference between Reduce and do.call and when best to
> use which?

>From the help:

?Reduce? uses a binary function to successively combine the
     elements of a given vector and a possibly given initial value.

  ?do.call? constructs and executes a function call from a name or a
     function and a list of arguments to be passed to it.


 In your example, rbind gets called N-1 times when using Reduce (where
N is the length of the list) because it is doing something like:

 rbind(x[[1]],rbind(x[[2]],x[[3]]))

For longer lists, its doing something like (where a b c d e are list
elements x[[1]] to x[[5]])

rbind( a, rbind( b, rbind( c, rbind( d, e ) ) ) )

whereas do.call calls it once, as rbind(a,b,c,d,e)

Use Reduce when you are doing a Reduce operation (read up on
Functional Programming). Use do.call when you want to call a function
with parameters in a list.

Barry


From elaine.kuo.tw at gmail.com  Tue Oct  8 13:21:21 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Tue, 8 Oct 2013 19:21:21 +0800
Subject: [R] row sum with all absence in a presence-absence matrix
Message-ID: <CAGJhoDyDgi7wwU3o-CFBr8OuX7RgKCGuqeGmFPGra9044AcjRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/ddcbe597/attachment.pl>

From jim at bitwrit.com.au  Tue Oct  8 13:37:23 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 08 Oct 2013 22:37:23 +1100
Subject: [R] row sum with all absence in a presence-absence matrix
In-Reply-To: <CAGJhoDyDgi7wwU3o-CFBr8OuX7RgKCGuqeGmFPGra9044AcjRA@mail.gmail.com>
References: <CAGJhoDyDgi7wwU3o-CFBr8OuX7RgKCGuqeGmFPGra9044AcjRA@mail.gmail.com>
Message-ID: <5253EE73.8060109@bitwrit.com.au>

On 10/08/2013 10:21 PM, Elaine Kuo wrote:
> Dear list
>
>
>
> I have a matrix composed of islandID as rows and speciesID as columns.
>
> IslandID: Island A, B, C?.O (15 islands in total)
>
> SpeciesID: D0001, D0002, D0003?.D0100 (100 species in total)
>
>
>
> The cell of the matrix describes presence (1) or absence (0) of the species
> in an island.
>
>
>
> Now I would like to search how many species are found in (1, presence) for
> Island A, Island D, and Island L respectively.
>
>
>
> Please kindly advise the R code for the search purpose.
>
Hi Elaine,
Sounds like "rowSums" to me.

Jim


From lomasvega at hotmail.com  Tue Oct  8 14:25:45 2013
From: lomasvega at hotmail.com (Marta Lomas)
Date: Tue, 8 Oct 2013 14:25:45 +0200
Subject: [R] na.action within glmmADMB package?
Message-ID: <DUB116-W97E3BEF4AA91789529AB71A61C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/82e435d2/attachment.pl>

From cef24 at pitt.edu  Tue Oct  8 08:34:44 2013
From: cef24 at pitt.edu (cf2059)
Date: Mon, 7 Oct 2013 23:34:44 -0700 (PDT)
Subject: [R] frailtypack
In-Reply-To: <1282061687542-2328606.post@n4.nabble.com>
References: <1282061687542-2328606.post@n4.nabble.com>
Message-ID: <1381214084278-4677787.post@n4.nabble.com>

Hello,

I am encountering very similar problems with frailtypack (only, it seems, 3
years later).  I would be incredibly grateful if you would be willing to
share any solutions you happened upon for the problem you mention. I have a
datafile that is even longer than yours (over 15000 events). Events follow a
two-level nesting structure. When I attempt to run the nested survival model
in frailtypack the program either stops running entirely or produces an
error message. I have contacted the frailtypack maintainer but have not yet
received a response.  It seems that frailtypack is perhaps the only
widely-available platform for the analysis of nested survival data, so the
seeming bugginess of this program is troubling.  Please let me know if you
ended up coming up with a solution to your problem or, alternatively,
another program able to run the nested analysis. Thank you so much!



--
View this message in context: http://r.789695.n4.nabble.com/frailtypack-tp2328606p4677787.html
Sent from the R help mailing list archive at Nabble.com.


From gxg627 at bham.ac.uk  Tue Oct  8 10:55:58 2013
From: gxg627 at bham.ac.uk (Grace Garner)
Date: Tue, 08 Oct 2013 09:55:58 +0100
Subject: [R] Lattice z colours when using formula class
Message-ID: <5253C89E.4050407@bham.ac.uk>

Dear all,

I'm using Windows 7, R version 2.15.0 and lattice_0.20-6.

I'm plotting observed data in lattice using wireframe(). I have 3 
matrices of observed values (Temp,Dist,Time) and I'm using the formula 
method (Temp~Dist*Time).

How do I instruct wireframe to colour the plot surface based on the 
heights of my z data (Temp) only?

At present I do not understand how the colours in the colourkey relate 
to either my z, x or y data.

I include below my code:

mycols<-colorRampPalette(c("dodgerblue", "firebrick"), space="rgb")

wireframe(Temp~Dist*Time,
            shade=F, drape=T, colorkey = T, col.regions=mycols(200), 
col="transparent")

Thank you,
Grace


From bbolker at gmail.com  Tue Oct  8 15:17:55 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 8 Oct 2013 13:17:55 +0000
Subject: [R] na.action within glmmADMB package?
References: <DUB116-W97E3BEF4AA91789529AB71A61C0@phx.gbl>
Message-ID: <loom.20131008T150556-522@post.gmane.org>

Marta Lomas <lomasvega <at> hotmail.com> writes:

> 
> Hello everybody, 
> 
> I would like to know if within the  glmmADMB package into R interface 
> there is a way to deal with the NAs
> different than applying "dataformodeling= na.omit(dataframe)". 
> This way as you may know removes all
> the rows of the data set with at leas 1 NA.
 
> I would rather prefer to run my models with more observations. Thus,
> I am trying to find the way that the model takes into account the
> rest of information in the affected rows with at least 1 NA that,
> otherwise. with "na.omit", is eliminated.

   I don't think the NA-handling machinery in R really does what you
think it does.  In general, other than na.omit and na.fail (the latter
obviously won't do you wany good), the typical choices are na.pass
(which just passes NA values through as is, which will lead to all of
the answers being NA) and na.exclude.  The last is useful, but it is
just a convenient function; it still strips the NA values out before
fitting the model but re-introduces them when predicting or returning
residuals.

  The basic problem is that you generally *can't* fit statistical
models with NA values in the predictor variables; the mathematics
just wouldn't make sense in general. You either have to do
imputation of some kind to fill in the missing values, or 
possibly use some kind of 'random forest' technique to average
over the predictions of different models with different sets
of predictors.

  Imputation is non-trivial; Frank Harrell's _Regression Modeling
Strategies_ book and library("sos"); findFn("imputation") will
get you started if you want to go that direction.


From johannesradinger at gmail.com  Tue Oct  8 15:37:40 2013
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Tue, 8 Oct 2013 15:37:40 +0200
Subject: [R] Latin Hypercube Sample and transformation to uniformly
 distributed integers or classes
Message-ID: <CABsGe_xZmJS4YSpzB9VX3hjSKdsxC7A37ZzL_V1Z+X8rOrYFJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/a87e60cf/attachment.pl>

From petr.pikal at precheza.cz  Tue Oct  8 16:02:04 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 8 Oct 2013 14:02:04 +0000
Subject: [R] Latin Hypercube Sample and transformation to uniformly
 distributed integers or classes
In-Reply-To: <CABsGe_xZmJS4YSpzB9VX3hjSKdsxC7A37ZzL_V1Z+X8rOrYFJA@mail.gmail.com>
References: <CABsGe_xZmJS4YSpzB9VX3hjSKdsxC7A37ZzL_V1Z+X8rOrYFJA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B95F0C@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Johannes Radinger
> Sent: Tuesday, October 08, 2013 3:38 PM
> To: R help
> Subject: [R] Latin Hypercube Sample and transformation to uniformly
> distributed integers or classes
> 
> Hi,
> 
> I'd like to use Latin Hypercube Sampling (LHC) in the the context of
> uncertainty / sensitivity analysis of a complex model with
> approximately 10 input variables. With the LHC approach I'd like to
> generate parameter combinations for my model input variables.
> Therefore I came across an simple example here on the mailing list (
> https://stat.ethz.ch/pipermail/r-help/2011-June/279931.html):
> 
> Easy Example
> Parameter 1: normal(1, 2)
> Parameter 2: normal(3, 4)
> Parameter 3: uniform(5, 10)
> 
> require(lhs)
> N <- 1000
> x <- randomLHS(N, 3)

This put 3 columns of uniformly distributed random numbers in x

> y <- x
> y[,1] <- qnorm(x[,1], 1, 2)
> y[,2] <- qnorm(x[,2], 3, 4)
> y[,3] <- qunif(x[,3], 5, 10)
> 
> par(mfrow=c(2,2))
> apply(x, 2, hist)
> 
> par(mfrow=c(2,2))
> apply(y, 2, hist)
> 
> 
> However, some of my parameters are uniformly distributed integer values
> and/or uniformly distributed classes. So, for example one input
> parameter can be "yellow", "green", "red" with equal probability. Of

Maybe

set.seed(333)
x<-sample(c("yellow", "green", "red"), 1000, replace=TRUE)
table(x)
x
 green    red yellow 
   334    327    339 

> course these attributes can be transformed into integers (1,2,3) with a
> uniform distribution.

I would use 

xf <- factor(x)

to transform it to numbers and still retaining labels.

> 
> So far I've tried to use the round function:
> 
> y[,3] <- round(qunif(x[,3], 5, 10))
> 
> which does not sample the 1 and 10 eqally to 2:8 (this is discussed
> already somewhere else here on the list in another context, and the
> function
> sample() is suggested). How can this be applied here and how can a
> column of the lhs-output be transformed in e.g integers 1:10 or the
> three colors as mentioned above?

Maybe cut.
as.numeric(as.factor(cut(x[,1], 10)))
factor(cut(x[,1], 3), labels=c("yellow", "green", "red"))

Regards
Petr


> 
> thanks,
> 
> Johannes
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From shuklvineet at gmail.com  Tue Oct  8 16:02:36 2013
From: shuklvineet at gmail.com (Vineet Shukla)
Date: Tue, 8 Oct 2013 19:32:36 +0530
Subject: [R] how to check the accuracy for maxent ?
Message-ID: <CA+hec4RHzbxU65rZ5-A_Z1-GbPYOWF6iQ+W9jsR-uJd5PsWE+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/df4f99c7/attachment.pl>

From murdoch.duncan at gmail.com  Tue Oct  8 16:10:31 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 08 Oct 2013 10:10:31 -0400
Subject: [R] Latin Hypercube Sample and transformation to uniformly
 distributed integers or classes
In-Reply-To: <CABsGe_xZmJS4YSpzB9VX3hjSKdsxC7A37ZzL_V1Z+X8rOrYFJA@mail.gmail.com>
References: <CABsGe_xZmJS4YSpzB9VX3hjSKdsxC7A37ZzL_V1Z+X8rOrYFJA@mail.gmail.com>
Message-ID: <52541257.6080101@gmail.com>

On 08/10/2013 9:37 AM, Johannes Radinger wrote:
> Hi,
>
> I'd like to use Latin Hypercube Sampling (LHC) in the the context of
> uncertainty / sensitivity analysis of a complex model with approximately 10
> input variables. With the LHC approach I'd like to generate parameter
> combinations for my model input variables.
> Therefore I came across an simple example here on the mailing list (
> https://stat.ethz.ch/pipermail/r-help/2011-June/279931.html):
>
> Easy Example
> Parameter 1: normal(1, 2)
> Parameter 2: normal(3, 4)
> Parameter 3: uniform(5, 10)
>
> require(lhs)
> N <- 1000
> x <- randomLHS(N, 3)
> y <- x
> y[,1] <- qnorm(x[,1], 1, 2)
> y[,2] <- qnorm(x[,2], 3, 4)
> y[,3] <- qunif(x[,3], 5, 10)
>
> par(mfrow=c(2,2))
> apply(x, 2, hist)
>
> par(mfrow=c(2,2))
> apply(y, 2, hist)
>
>
> However, some of my parameters are uniformly distributed integer values
> and/or uniformly distributed classes. So, for example one input parameter
> can be "yellow", "green", "red" with equal probability. Of course these
> attributes can be transformed into integers (1,2,3) with a uniform
> distribution.
>
> So far I've tried to use the round function:
>
> y[,3] <- round(qunif(x[,3], 5, 10))

Why round()?  floor() would make more sense.  And why have a lower limit 
of 5?  I would use 0.

When I do that I get reasonable results:

table(floor(qunif(runif(100000), 0, 10)) + 1)

(You should put in your lhs values instead of runif.  You will run into 
problems if they are ever exactly equal to 1; runif() would never do that.)

Duncan Murdoch

>
> which does not sample the 1 and 10 eqally to 2:8 (this is discussed already
> somewhere else here on the list in another context, and the function
> sample() is suggested). How can this be applied here and how can a column
> of the lhs-output be transformed in e.g integers 1:10 or the three colors
> as mentioned above?
>
> thanks,
>
> Johannes
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Tue Oct  8 14:38:15 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 8 Oct 2013 05:38:15 -0700 (PDT)
Subject: [R] row sum with all absence in a presence-absence matrix
In-Reply-To: <CAGJhoDyDgi7wwU3o-CFBr8OuX7RgKCGuqeGmFPGra9044AcjRA@mail.gmail.com>
References: <CAGJhoDyDgi7wwU3o-CFBr8OuX7RgKCGuqeGmFPGra9044AcjRA@mail.gmail.com>
Message-ID: <1381235895.27134.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,
Try:

set.seed(49)
mat1<- matrix(sample(0:1,15*100,replace=TRUE),nrow=15,ncol=100,dimnames=list(LETTERS[1:15],paste0("D",sprintf("%04d",1:100))))
?rowSums(mat1[rownames(mat1)%in% c("A","D","L"),])
# A? D? L 
#44 55 50 
A.K.



----- Original Message -----
From: Elaine Kuo <elaine.kuo.tw at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Tuesday, October 8, 2013 7:21 AM
Subject: [R] row sum with all absence in a presence-absence matrix

Dear list



I have a matrix composed of islandID as rows and speciesID as columns.

IslandID: Island A, B, C?.O (15 islands in total)

SpeciesID: D0001, D0002, D0003?.D0100 (100 species in total)



The cell of the matrix describes presence (1) or absence (0) of the species
in an island.



Now I would like to search how many species are found in (1, presence) for
Island A, Island D, and Island L respectively.



Please kindly advise the R code for the search purpose.

Thank you.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From nashjc at uottawa.ca  Tue Oct  8 16:44:19 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Tue, 08 Oct 2013 10:44:19 -0400
Subject: [R] rbenchmark: why is function benchmark back-quoted?
Message-ID: <52541A43.5040006@uottawa.ca>

I'm wondering what the purpose of the back-quoting of the name is, since 
benchmark seems a valid name. The language reference does mention 
back-quoting names to make them syntactic names, but I found no 
explanation of the "why".

Can someone give a concise reason?

JN


From nicomet80 at gmail.com  Tue Oct  8 16:47:44 2013
From: nicomet80 at gmail.com (Nico Met)
Date: Tue, 8 Oct 2013 16:47:44 +0200
Subject: [R] matrix of mean values
Message-ID: <CAMMD=S5_druNFxzGtK5bnqKB15HD04CskeCEpYKqQmRhE3u0Lw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/13afb93e/attachment.pl>

From smartpink111 at yahoo.com  Tue Oct  8 16:56:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 8 Oct 2013 07:56:03 -0700 (PDT)
Subject: [R] matrix of mean values
In-Reply-To: <1381244075.53183.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAMMD=S5_druNFxzGtK5bnqKB15HD04CskeCEpYKqQmRhE3u0Lw@mail.gmail.com>
	<1381244075.53183.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1381244163.66311.YahooMailNeo@web142601.mail.bf1.yahoo.com>

To make it matrix:


row.names(res)<- res[,1]
?res1<- as.matrix(res[,-1])
A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Nico Met <nicomet80 at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, October 8, 2013 10:54 AM
Subject: Re: [R] matrix of mean values

Try:

d1$value<-as.numeric(gsub(",","",as.character(d1$value)))
library(reshape2)
res <- dcast(d1,loc~variables,value.var="value",mean)
A.K.



----- Original Message -----
From: Nico Met <nicomet80 at gmail.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Tuesday, October 8, 2013 10:47 AM
Subject: [R] matrix of mean values

Dear all, I have a data set where I want to make a matrix of the mean
values using 3rd column (value). Where rows are unique ?loc? and columns
would be ?variables?. If there is one observation or no observation just
use ?NA?.



> dput(d1)

structure(list(loc = structure(c(6L, 9L, 9L, 9L, 9L, 4L, 4L,

4L, 4L, 4L, 4L, 13L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L,

7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 10L,

10L, 10L, 10L, 10L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 1L,

3L, 3L, 3L, 2L), .Label = c("AX09_126", "AX09_628", "AX09_924",

"IALA08_3299", "JA08_246", "JA08_3299", "JA08_408", "JE08_246",

"JE08_3299", "JE08_408", "NO08_246", "NO08_408", "PP08_3299"), class =
"factor"),

? ? variables = structure(c(5L, 6L, 6L, 6L, 6L, 6L, 5L, 5L, 5L,

? ? 7L, 7L, 7L, 7L, 4L, 4L, 4L, 4L, 4L, 2L, 2L, 2L, 2L, 3L, 3L,

? ? 3L, 3L, 3L, 3L, 1L, 1L, 1L, 2L, 1L, 5L, 5L, 5L, 6L, 6L, 7L,

? ? 7L, 7L, 7L, 7L, 7L, 7L, 3L, 7L, 4L, 4L, 4L, 7L, 7L, 7L, 7L

? ? ), .Label = c("i", "r", "s", "t", "x", "y", "z"), class = "factor"),

? ? value = structure(c(1L, 21L, 2L, 1L, 30L, 32L, 4L, 32L, 5L,

? ? 20L, 5L, 1L, 24L, 12L, 26L, 24L, 12L, 15L, 26L, 14L, 15L,

? ? 23L, 13L, 11L, 23L, 25L, 23L, 6L, 7L, 3L, 8L, 19L, 3L, 19L,

? ? 28L, 16L, 18L, 18L, 17L, 31L, 29L, 10L, 27L, 22L, 9L, 22L,

? ? 22L, 9L, 9L, 35L, 33L, 33L, 33L, 34L), .Label = c("0", "0,3333",

? ? "142,1", "1506,00006", "1520,66664", "170,36", "18,6185",

? ? "19,2933", "20,2125", "20,7423", "225,94", "23,2245", "24,3526",

? ? "24,3685", "24,4593", "242,84", "25,7422", "26,34", "26,5989",

? ? "30,33336284", "36,33336608", "39,913", "41,4933", "43,9104",

? ? "47,1241", "49,3467", "49,5715", "50,0037", "50,7974", "53,6667",

? ? "56,2778", "76", "76,5", "77,6667", "82"), class = "factor")), .Names =
c("loc",

"variables", "value"), class = "data.frame", row.names = c(NA,

-54L))



Thanks



Nico

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ekyoungs at ncsu.edu  Tue Oct  8 15:36:34 2013
From: ekyoungs at ncsu.edu (Elsa Youngsteadt)
Date: Tue, 8 Oct 2013 09:36:34 -0400
Subject: [R] goodness of fit for nonlinear quantile regression
Message-ID: <CALD4PxjYny-HjLxiD7gThkKCEhWVgbzs6KMHEjvf0kUm_7-mKw@mail.gmail.com>

Hello,

I am having trouble obtaining AIC or pseudo R^2 for nonlinear quantile
regression fits. I would like to use one of these measures to compare
non-nested models (each with a single, unique predictor variable).

I am trying to fit the following gaussian peak model using the quantreg package:

fit1.nlrq <- nlrq(y ~ a*exp(-((x-b)/c)**2), data=data, start =
list(a=.2,b=25.5,c=1), tau=0.5, trace=T);

(and so on, for multiple tau; I would like a local goodness of fit
measure at each tau, to help compare this model to a similar one that
uses, say, x1 as a predictor instead of x.)

Parameter estimates and predictions for the model looks as expected,
but when I try to use AIC(fit1.nlrq) or AIC.nlrq(fit1.nlrq) I get the
following output

numeric(0)
attr(,"edf")
[1] 0

Similarly, logLik(fit1.nlrq)

yields

'log Lik.'  (df=0)

Can someone advise? (The output for deviance does exist and is a number...)

As an alternative, I could perhaps calculate pseudo R2. I think this
would be [1 - (deviance of fitted model/ deviance of null model)] but
don't know how to obtain the deviance for the relevant null models.
Can someone offer code or advice on this front?

Perhaps someone has a more desirable alternative altogether for
comparing among non-nested, nonlinear, quantile regression models.

I am new to R and to R-help, please advise of posting mistakes or
missing information!

sessionInfo is as follows:

R version 3.0.0 (2013-04-03)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] quantreg_4.98 SparseM_1.02

loaded via a namespace (and not attached):
[1] tools_3.0.0



-- 
Elsa Youngsteadt
Research Associate
Department of Entomology
North Carolina State University
Campus Box 7613
Raleigh, NC 27695
919-515-1661


From valentina.lauria at nuigalway.ie  Tue Oct  8 16:03:58 2013
From: valentina.lauria at nuigalway.ie (Lauria, Valentina)
Date: Tue, 8 Oct 2013 14:03:58 +0000
Subject: [R] problems with package COZIGAM
Message-ID: <B11DE93D7F439D4BA1E942572BA750308BC5C79E@UDSMBX02.uds.nuigalway.ie>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/a571b0ab/attachment.pl>

From dwinsemius at comcast.net  Tue Oct  8 17:05:53 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 8 Oct 2013 08:05:53 -0700
Subject: [R] problems with package COZIGAM
In-Reply-To: <B11DE93D7F439D4BA1E942572BA750308BC5C79E@UDSMBX02.uds.nuigalway.ie>
References: <B11DE93D7F439D4BA1E942572BA750308BC5C79E@UDSMBX02.uds.nuigalway.ie>
Message-ID: <13D21E69-FFEE-46F0-8D9A-71DE1C8711B0@comcast.net>


On Oct 8, 2013, at 7:03 AM, Lauria, Valentina wrote:

> Dear All I am having problems to install the package COZIGAM.
> 
> Despite I have the update version of R (3.0.2) when I try to load the package I cannot find it in the list of available packages.
> 
> If I try to install it from a local zip file I do get this error message:
> 
> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>  cannot open the connection
> In addition: Warning messages:
> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>  cannot open compressed file 'COZIGAM_2.0-3.tar.gz/DESCRIPTION', probable reason 'No such file or directory'
>> 
> 
> Could anyone help me?

The obvious google search produces this:

http://cran.r-project.org/web/packages/COZIGAM/index.html
> 

-- 

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Tue Oct  8 17:12:18 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 08 Oct 2013 11:12:18 -0400
Subject: [R] rbenchmark: why is function benchmark back-quoted?
In-Reply-To: <52541A43.5040006@uottawa.ca>
References: <52541A43.5040006@uottawa.ca>
Message-ID: <525420D2.5070807@gmail.com>

On 08/10/2013 10:44 AM, Prof J C Nash (U30A) wrote:
> I'm wondering what the purpose of the back-quoting of the name is, since
> benchmark seems a valid name. The language reference does mention
> back-quoting names to make them syntactic names, but I found no
> explanation of the "why".
>
> Can someone give a concise reason?

It has no effect, so it is just a matter of style.  You'd have to ask 
the maintainer why he likes that style, or what tool he used to produce 
the source code.

Duncan Murdoch


From jdnewmil at dcn.davis.CA.us  Tue Oct  8 17:15:56 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 08 Oct 2013 08:15:56 -0700
Subject: [R] rbenchmark: why is function benchmark back-quoted?
In-Reply-To: <52541A43.5040006@uottawa.ca>
References: <52541A43.5040006@uottawa.ca>
Message-ID: <d62f5820-714b-48f0-a5b0-a547fcbfff7a@email.android.com>

Your use of the English language is failing to communicate. You mention  "the name" when "name" is not a proper noun. Are you referring to some specific example?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"Prof J C Nash (U30A)" <nashjc at uottawa.ca> wrote:
>I'm wondering what the purpose of the back-quoting of the name is,
>since 
>benchmark seems a valid name. The language reference does mention 
>back-quoting names to make them syntactic names, but I found no 
>explanation of the "why".
>
>Can someone give a concise reason?
>
>JN
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From nicomet80 at gmail.com  Tue Oct  8 17:33:21 2013
From: nicomet80 at gmail.com (Nico Met)
Date: Tue, 8 Oct 2013 17:33:21 +0200
Subject: [R] matrix of mean values
In-Reply-To: <1381244163.66311.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CAMMD=S5_druNFxzGtK5bnqKB15HD04CskeCEpYKqQmRhE3u0Lw@mail.gmail.com>
	<1381244075.53183.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1381244163.66311.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CAMMD=S6eHJQoVSZ5ZRJvp5LEE2=6TY4JVH8RxHUbbjCMURnOZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/31eeb14e/attachment.pl>

From nashjc at uottawa.ca  Tue Oct  8 17:36:38 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Tue, 08 Oct 2013 11:36:38 -0400
Subject: [R] rbenchmark: why is function benchmark back-quoted?
In-Reply-To: <d62f5820-714b-48f0-a5b0-a547fcbfff7a@email.android.com>
References: <52541A43.5040006@uottawa.ca>
	<d62f5820-714b-48f0-a5b0-a547fcbfff7a@email.android.com>
Message-ID: <52542686.3030103@uottawa.ca>

The function 'benchmark' which is the only one in package 'rbenchmark' 
has a back-quoted name in its first line

`benchmark` <- function( ....

I wondered whether this had specific importance. It appears not.

JN


On 13-10-08 11:15 AM, Jeff Newmiller wrote:
> Your use of the English language is failing to communicate. You mention  "the name" when "name" is not a proper noun. Are you referring to some specific example?
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> "Prof J C Nash (U30A)" <nashjc at uottawa.ca> wrote:
>> I'm wondering what the purpose of the back-quoting of the name is,
>> since
>> benchmark seems a valid name. The language reference does mention
>> back-quoting names to make them syntactic names, but I found no
>> explanation of the "why".
>>
>> Can someone give a concise reason?
>>
>> JN
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From dan.abner99 at gmail.com  Tue Oct  8 17:46:16 2013
From: dan.abner99 at gmail.com (Dan Abner)
Date: Tue, 8 Oct 2013 11:46:16 -0400
Subject: [R] Summary functions in sqldf() XXXX
Message-ID: <CAPRGo-k32Gwv6P1Fdd33LK0Uux69Jro032xoiGMDRO7HMLdqhw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/d50473c1/attachment.pl>

From rkoenker at illinois.edu  Tue Oct  8 17:31:43 2013
From: rkoenker at illinois.edu (Roger Koenker)
Date: Tue, 8 Oct 2013 10:31:43 -0500
Subject: [R] goodness of fit for nonlinear quantile regression
In-Reply-To: <46c286a901d142ac93a274531b21cc8a@CITESHT1.ad.uillinois.edu>
References: <46c286a901d142ac93a274531b21cc8a@CITESHT1.ad.uillinois.edu>
Message-ID: <CAA0A6C2-32CE-4B41-B64F-0ED2B21BD97F@illinois.edu>

Elsa,

It is usual to write to package authors/maintainers about packages before
trying R-help.  Inference for nonlinear quantile regression is still a bit
underdeveloped.  To get logLik you can use:

logLik.nlrq <- function (object, ...)
{
    n <- length(object$m$resid())
    p <- length(object$m$getPars())
    tau <- object$m$tau()
    fid <- object$m$rho
    val <- n * (log(tau * (1 - tau)) - 1 - log(fid/n))
    attr(val, "n") <- n
    attr(val, "df") <- p
    class(val) <- "logLik"
    val
}

and from there AIC should work as usual for nls models.

RK

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801

On Oct 8, 2013, at 8:36 AM, Elsa Youngsteadt wrote:

> Hello,
> 
> I am having trouble obtaining AIC or pseudo R^2 for nonlinear quantile
> regression fits. I would like to use one of these measures to compare
> non-nested models (each with a single, unique predictor variable).
> 
> I am trying to fit the following gaussian peak model using the quantreg package:
> 
> fit1.nlrq <- nlrq(y ~ a*exp(-((x-b)/c)**2), data=data, start =
> list(a=.2,b=25.5,c=1), tau=0.5, trace=T);
> 
> (and so on, for multiple tau; I would like a local goodness of fit
> measure at each tau, to help compare this model to a similar one that
> uses, say, x1 as a predictor instead of x.)
> 
> Parameter estimates and predictions for the model looks as expected,
> but when I try to use AIC(fit1.nlrq) or AIC.nlrq(fit1.nlrq) I get the
> following output
> 
> numeric(0)
> attr(,"edf")
> [1] 0
> 
> Similarly, logLik(fit1.nlrq)
> 
> yields
> 
> 'log Lik.'  (df=0)
> 
> Can someone advise? (The output for deviance does exist and is a number...)
> 
> As an alternative, I could perhaps calculate pseudo R2. I think this
> would be [1 - (deviance of fitted model/ deviance of null model)] but
> don't know how to obtain the deviance for the relevant null models.
> Can someone offer code or advice on this front?
> 
> Perhaps someone has a more desirable alternative altogether for
> comparing among non-nested, nonlinear, quantile regression models.
> 
> I am new to R and to R-help, please advise of posting mistakes or
> missing information!
> 
> sessionInfo is as follows:
> 
> R version 3.0.0 (2013-04-03)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] quantreg_4.98 SparseM_1.02
> 
> loaded via a namespace (and not attached):
> [1] tools_3.0.0
> 
> 
> 
> -- 
> Elsa Youngsteadt
> Research Associate
> Department of Entomology
> North Carolina State University
> Campus Box 7613
> Raleigh, NC 27695
> 919-515-1661
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Oct  8 17:52:26 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 8 Oct 2013 08:52:26 -0700
Subject: [R] problems with package COZIGAM
In-Reply-To: <B11DE93D7F439D4BA1E942572BA750308BC5C7E3@UDSMBX02.uds.nuigalway.ie>
References: <B11DE93D7F439D4BA1E942572BA750308BC5C79E@UDSMBX02.uds.nuigalway.ie>
	<13D21E69-FFEE-46F0-8D9A-71DE1C8711B0@comcast.net>
	<B11DE93D7F439D4BA1E942572BA750308BC5C7E3@UDSMBX02.uds.nuigalway.ie>
Message-ID: <2F1338F2-E861-491B-833D-777D82CA9704@comcast.net>


On Oct 8, 2013, at 8:14 AM, Lauria, Valentina wrote:

> Dear David,
> 
> Your answer does not really solve the problem as I have already downloaded the COZIGAM zip package (see my previous message).

My response was intended to raise questions that you have not yet considered. You should be asking yourself "why?".

There are a bunch of other questions still outstanding as well (which will become apparent if you ever should read the Posting Guide).  I suspect you will find that even if you post the code you used to do the package installation that we will not be able to offer further assistance. Removal of a package from CRAN means that there were problems with its compilation or installation on a standard R setup.

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

-- 
David.
> 
> Best Regards,
> Valentina
> 
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net] 
> Sent: 08 October 2013 16:06
> To: Lauria, Valentina
> Cc: r-help at r-project.org
> Subject: Re: [R] problems with package COZIGAM
> 
> 
> On Oct 8, 2013, at 7:03 AM, Lauria, Valentina wrote:
> 
>> Dear All I am having problems to install the package COZIGAM.
>> 
>> Despite I have the update version of R (3.0.2) when I try to load the package I cannot find it in the list of available packages.
>> 
>> If I try to install it from a local zip file I do get this error message:
>> 
>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>> cannot open the connection
>> In addition: Warning messages:
>> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>> cannot open compressed file 'COZIGAM_2.0-3.tar.gz/DESCRIPTION', probable reason 'No such file or directory'
>>> 
>> 
>> Could anyone help me?
> 
> The obvious google search produces this:
> 
> http://cran.r-project.org/web/packages/COZIGAM/index.html
>> 
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA


From gxg627 at bham.ac.uk  Tue Oct  8 17:11:53 2013
From: gxg627 at bham.ac.uk (Grace Garner)
Date: Tue, 08 Oct 2013 16:11:53 +0100
Subject: [R] Lattice z colours when using formula class
In-Reply-To: <5253C89E.4050407@bham.ac.uk>
References: <5253C89E.4050407@bham.ac.uk>
Message-ID: <525420B9.6000209@bham.ac.uk>

I've found one solution, which is to transform each matrix into a 1d 
array. This gives me the output I wanted.

Grace

On 08/10/2013 09:55, Grace Garner wrote:
> Dear all,
>
> I'm using Windows 7, R version 2.15.0 and lattice_0.20-6.
>
> I'm plotting observed data in lattice using wireframe(). I have 3
> matrices of observed values (Temp,Dist,Time) and I'm using the formula
> method (Temp~Dist*Time).
>
> How do I instruct wireframe to colour the plot surface based on the
> heights of my z data (Temp) only?
>
> At present I do not understand how the colours in the colourkey relate
> to either my z, x or y data.
>
> I include below my code:
>
> mycols<-colorRampPalette(c("dodgerblue", "firebrick"), space="rgb")
>
> wireframe(Temp~Dist*Time,
>             shade=F, drape=T, colorkey = T, col.regions=mycols(200),
> col="transparent")
>
> Thank you,
> Grace
>
>
>


From smartpink111 at yahoo.com  Tue Oct  8 17:05:59 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 8 Oct 2013 08:05:59 -0700 (PDT)
Subject: [R] Information Frequency problem calculation
In-Reply-To: <31167569.2357031381241228418.JavaMail.defaultUser@defaultHost>
References: <31167569.2357031381241228418.JavaMail.defaultUser@defaultHost>
Message-ID: <1381244759.52159.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Dear Jarod,

You can call me Arun.? 
a<- read.table(text="NAME1??? NAME2??? RNA
mauro??? francesco??? E234
luca??? giuseppe??? E5578
luca??? franco??? E5569
maria??? luca??? E4556
maria??? mauro??? E4556
luisa??? mara??? E4755
mara??? luca??? E234
luigi??? veronica??? E234
mauro??? veronica??? E235",sep="",header=TRUE,stringsAsFactors=FALSE)

res <- do.call(rbind,lapply(unique(c(a[,1],a[,2])),function(x) {data.frame(RESULTS= x,GROUP1= sum(a[,1] %in% x), GROUP2=sum(a[,2] %in% x),stringsAsFactors=FALSE)}))
res
#???? RESULTS GROUP1 GROUP2
#1????? mauro????? 2????? 1
#2?????? luca????? 2????? 2
#3????? maria????? 2????? 0
#4????? luisa????? 1????? 0
#5?????? mara????? 1????? 1
#6????? luigi????? 1????? 0
#7? francesco????? 0????? 1
#8?? giuseppe????? 0????? 1
#9???? franco????? 0????? 1
#10? veronica????? 0????? 2

A.K.





----- Original Message -----
From: "jarod_v6 at libero.it" <jarod_v6 at libero.it>
To: smartpink111 at yahoo.com
Cc: 
Sent: Tuesday, October 8, 2013 10:07 AM
Subject: Re: [R] Information Frequency problem calculation

Dear Master,

thanks for your help!!
I have this long database of breeder divide in two list. eache list have 
particular group rna identify (catcghory of birds)

GROUP1??? GROUP2??? 
NAME1??? NAME2??? RNA
mauro??? francesco??? E234
luca??? giuseppe??? E5578
luca??? franco??? E5569
maria??? luca??? E4556
maria??? mauro??? E4556"
luisa??? mara??? E4755
mara??? luca??? E234
luigi??? veronica??? E234
mauro??? veronica??? E235

What I want is to have a frequency of presence of all my data:
So :

RESULTS??? group1??? group2
MAURO ??? 2??? 1

I want know how many times one name it is found in group 1 or in group2 and 
how many times have different RNA (identify of group).
Thanks for help!!
Jarod

>----Messaggio originale----
>Da: smartpink111 at yahoo.com
>Data: 08/10/2013 15.12
>A: "jarod_v6 at libero.it"<jarod_v6 at libero.it>
>Ogg: Re: R: Re: [R] Information Frequency problem calculation
>
>Hi Jarod,
>
>Could you show your expected outcome as this is still confusing.? As I 
understand from your initial post, you are comparing two columns from your data 
frame (ie. Name1 and Name2).? My idea was to compare each entry of the first 
column and compare it with the full set of second column to see where they are 
the same.
>for example.
>a<- read.table(text="Name1 Name2 category
>mauro francesco E234
>luca? giuseppe? E5578
>luca? franco? E5569
>maria luca E4556
>maria mauro E4556",sep="",header=TRUE,stringsAsFactors=FALSE)
>
>?lapply(seq_len(nrow(a)),function(i) a[i,1]) 
>[[1]]
>[1] "mauro"
>
>[[2]]
>[1] "luca"
>
>[[3]]
>[1] "luca"
>
>[[4]]
>[1] "maria"
>
>[[5]]
>[1] "maria"
>
>
>lapply(seq_len(nrow(a)),function(i) sum(a[,2]%in% a[i,1])) #here, it 
calculates the sum of the number of matches for each entry of column 1.
>[[1]]
>[1] 1
>
>[[2]]
>[1] 1
>
>[[3]]
>[1] 1
>
>[[4]]
>[1] 0
>
>[[5]]
>[1] 0
>
>
>
>?I think this is not you wanted.? Your idea of? "ex mauro it is 
>presence on E234 and E4556 so I found 2 time 5 condition? and 1 time fo 
single 
>condition" is a bit confusing. ?
>
>Did you meant that "E4556" is repeated twice, so it should be 2 times?.? As I 
pointed out, if the expected result table is also shown, it would be easier to 
understand than words.
>
>
>A.K.
>
>
>
>
>
>
>----- Original Message -----
>From: "jarod_v6 at libero.it" <jarod_v6 at libero.it>
>To: smartpink111 at yahoo.com
>Cc: 
>Sent: Tuesday, October 8, 2013 3:57 AM
>Subject: R: Re: [R] Information Frequency problem calculation
>
>Thanks so much for your suggestion.. I have a little difficult to understand 
>the comand .. could you help me?
>So I interested in calculate the frequence of some names? ex mauro it is 
>presence on E234 and E4556 so I found 2 time 5 condition? and 1 time fo 
single 
>condition
>Tahanks for your help!!
>
>>----Messaggio originale----
>>Da: smartpink111 at yahoo.com
>>Data: 07/10/2013 18.45
>>A: "jarod_v6 at libero.it"<jarod_v6 at libero.it>
>>Cc: "R help"<r-help at r-project.org>
>>Ogg: Re: [R] Information Frequency problem calculation
>>
>>Hi,
>>Not sure what your expected output would be:
>>a<- read.table(text="Name1 Name2 category
>>mauro francesco E234
>>luca? giuseppe? E5578
>>luca? franco? E5569
>>maria luca E4556"
>maria?? mauro E4556
>
>
>
>,sep="",header=TRUE,stringsAsFactors=FALSE)
>>sapply(seq_len(nrow(a)),function(i) sum(a[,2] %in% a[i,1]))
>>#[1] 0 1 1 0
>>
>>
>>A.K.
>>
>>
>>
>>
>>
>>----- Original Message -----
>>From: "jarod_v6 at libero.it" <jarod_v6 at libero.it>
>>To: r-help at r-project.org
>>Cc: 
>>Sent: Monday, October 7, 2013 12:09 PM
>>Subject: [R] Information Frequency problem calculation
>>
>>Dear All,
>>
>>I Have a dataframe like that:
>>
>>Name1 Name2 category
>>
>>mauro francesco E234
>>luca?? giuseppe? E5578
>>luca?? franco? E5569
>>maria luca E4556
>>...
>>I would like to calculate the frequency of many time in my data I found? in 
>>the list name:
>>
>>a<-read.table("pippo.csv",header=T,sep="\t")
>>name1<-as.character(a[,1])
>>name2<-as.character(a[,2])
>>category<-as.character(a[,3])
>>
>>for(i in 1:lenght(name1)){
>>re <-which(name1 == name2)
>>
>>}
>>
>>So how can create a table of frequncy of many times I found a name in 
column 
>>one respect to the second ?
>>Thanks in advance for your help!
>>M.
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From smartpink111 at yahoo.com  Tue Oct  8 16:54:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 8 Oct 2013 07:54:35 -0700 (PDT)
Subject: [R] matrix of mean values
In-Reply-To: <CAMMD=S5_druNFxzGtK5bnqKB15HD04CskeCEpYKqQmRhE3u0Lw@mail.gmail.com>
References: <CAMMD=S5_druNFxzGtK5bnqKB15HD04CskeCEpYKqQmRhE3u0Lw@mail.gmail.com>
Message-ID: <1381244075.53183.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Try:

d1$value<-as.numeric(gsub(",","",as.character(d1$value)))
library(reshape2)
res <- dcast(d1,loc~variables,value.var="value",mean)
A.K.


----- Original Message -----
From: Nico Met <nicomet80 at gmail.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Tuesday, October 8, 2013 10:47 AM
Subject: [R] matrix of mean values

Dear all, I have a data set where I want to make a matrix of the mean
values using 3rd column (value). Where rows are unique ?loc? and columns
would be ?variables?. If there is one observation or no observation just
use ?NA?.



> dput(d1)

structure(list(loc = structure(c(6L, 9L, 9L, 9L, 9L, 4L, 4L,

4L, 4L, 4L, 4L, 13L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L,

7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 10L,

10L, 10L, 10L, 10L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 1L,

3L, 3L, 3L, 2L), .Label = c("AX09_126", "AX09_628", "AX09_924",

"IALA08_3299", "JA08_246", "JA08_3299", "JA08_408", "JE08_246",

"JE08_3299", "JE08_408", "NO08_246", "NO08_408", "PP08_3299"), class =
"factor"),

? ? variables = structure(c(5L, 6L, 6L, 6L, 6L, 6L, 5L, 5L, 5L,

? ? 7L, 7L, 7L, 7L, 4L, 4L, 4L, 4L, 4L, 2L, 2L, 2L, 2L, 3L, 3L,

? ? 3L, 3L, 3L, 3L, 1L, 1L, 1L, 2L, 1L, 5L, 5L, 5L, 6L, 6L, 7L,

? ? 7L, 7L, 7L, 7L, 7L, 7L, 3L, 7L, 4L, 4L, 4L, 7L, 7L, 7L, 7L

? ? ), .Label = c("i", "r", "s", "t", "x", "y", "z"), class = "factor"),

? ? value = structure(c(1L, 21L, 2L, 1L, 30L, 32L, 4L, 32L, 5L,

? ? 20L, 5L, 1L, 24L, 12L, 26L, 24L, 12L, 15L, 26L, 14L, 15L,

? ? 23L, 13L, 11L, 23L, 25L, 23L, 6L, 7L, 3L, 8L, 19L, 3L, 19L,

? ? 28L, 16L, 18L, 18L, 17L, 31L, 29L, 10L, 27L, 22L, 9L, 22L,

? ? 22L, 9L, 9L, 35L, 33L, 33L, 33L, 34L), .Label = c("0", "0,3333",

? ? "142,1", "1506,00006", "1520,66664", "170,36", "18,6185",

? ? "19,2933", "20,2125", "20,7423", "225,94", "23,2245", "24,3526",

? ? "24,3685", "24,4593", "242,84", "25,7422", "26,34", "26,5989",

? ? "30,33336284", "36,33336608", "39,913", "41,4933", "43,9104",

? ? "47,1241", "49,3467", "49,5715", "50,0037", "50,7974", "53,6667",

? ? "56,2778", "76", "76,5", "77,6667", "82"), class = "factor")), .Names =
c("loc",

"variables", "value"), class = "data.frame", row.names = c(NA,

-54L))



Thanks



Nico

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From xie at yihui.name  Tue Oct  8 18:29:47 2013
From: xie at yihui.name (Yihui Xie)
Date: Tue, 8 Oct 2013 11:29:47 -0500
Subject: [R] rbenchmark: why is function benchmark back-quoted?
In-Reply-To: <52542686.3030103@uottawa.ca>
References: <52541A43.5040006@uottawa.ca>
	<d62f5820-714b-48f0-a5b0-a547fcbfff7a@email.android.com>
	<52542686.3030103@uottawa.ca>
Message-ID: <CANROs4e-W6==yvkoi0Xv3RR0A=BbE1hDag8m8hvRzbStBz19KA@mail.gmail.com>

I think there are two possibilities: (1) package.skeleton() can
produce this; (2) the package author prefers this style. Back-quoting
is often unnecessary, unless the object name is not valid without
back-quoting, e.g.,

> `a b` <- 1:2
> ls()
[1] "a b"
> a b
Error: unexpected symbol in "a b"
> `a b`
[1] 1 2

> %in%
Error: unexpected SPECIAL in "%in%"
> `%in%`
function (x, table)
match(x, table, nomatch = 0L) > 0L
<environment: namespace:base>


Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Tue, Oct 8, 2013 at 10:36 AM, Prof J C Nash (U30A) <nashjc at uottawa.ca> wrote:
> The function 'benchmark' which is the only one in package 'rbenchmark' has a
> back-quoted name in its first line
>
> `benchmark` <- function( ....
>
> I wondered whether this had specific importance. It appears not.
>
> JN
>
>
>
> On 13-10-08 11:15 AM, Jeff Newmiller wrote:
>>
>> Your use of the English language is failing to communicate. You mention
>> "the name" when "name" is not a proper noun. Are you referring to some
>> specific example?
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> "Prof J C Nash (U30A)" <nashjc at uottawa.ca> wrote:
>>>
>>> I'm wondering what the purpose of the back-quoting of the name is,
>>> since
>>> benchmark seems a valid name. The language reference does mention
>>> back-quoting names to make them syntactic names, but I found no
>>> explanation of the "why".
>>>
>>> Can someone give a concise reason?
>>>
>>> JN


From barbara.rogo at uniroma1.it  Tue Oct  8 18:34:41 2013
From: barbara.rogo at uniroma1.it (Barbara Rogo)
Date: Tue, 8 Oct 2013 18:34:41 +0200
Subject: [R] Plot with date
Message-ID: <CAL+pVGjSGNOd8wbp6inu6k4SD+dgqo5a5a_MgHBPcLuu01ONOA@mail.gmail.com>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/d71ae868/attachment.pl>

From renger at vannieuwkoop.ch  Tue Oct  8 19:29:50 2013
From: renger at vannieuwkoop.ch (Renger van Nieuwkoop)
Date: Tue, 8 Oct 2013 17:29:50 +0000
Subject: [R] tables with row sorted numerically although factors
Message-ID: <5E17CCD4AACE3A4C8CFF411186AE8190319BE7E6@EXDAG30-N2.hostallapps.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/2748ee8c/attachment.pl>

From ruipbarradas at sapo.pt  Tue Oct  8 19:53:41 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 08 Oct 2013 18:53:41 +0100
Subject: [R] tables with row sorted numerically although factors
In-Reply-To: <5E17CCD4AACE3A4C8CFF411186AE8190319BE7E6@EXDAG30-N2.hostallapps.net>
References: <5E17CCD4AACE3A4C8CFF411186AE8190319BE7E6@EXDAG30-N2.hostallapps.net>
Message-ID: <525446A5.4020601@sapo.pt>

Hello,

First of all, there's no need for data.frame(cbind(...)). data.frame() 
only will do the job, and it's less error prone.

As for the question, since the column Nodes is to become a factor, why 
use as.character()? Without it the problem is solved:


data      <- data.frame(Nodes,Values)
data$Nodes<- factor(data$Nodes) # necessary to get factors for tabular

tabular(Nodes  ~ Values*mean, data=data)


Hope this helps,

Rui Barradas

Em 08-10-2013 18:29, Renger van Nieuwkoop escreveu:
> Hi
> I am using the package tables and want to have the rows in the numerical order and not in the alphabetical order:
>
> library(tables)
> Nodes     <- c(1,10,20,2)
> Values    <- c(1,2,3,4)
> Data      <- data.frame(cbind(Nodes,Values))
> data$Nodes<- as.factor(as.character(data$Nodes)) # necessary to get factors for tabular
>
> tabular(Nodes  ~ Values*mean, data=data)
>
>         Values
>   Nodes mean
>   1     1
>   10    2
>   2     4
>   20    3
>
> And what I want is this:
>
>         Values
>   Nodes mean
>   1     1
>   2     4
>   10    2
>   20    3
>
> Any idea how to do this? (the solution is not to write 01, 02, 10, 20, because I use Nodes in lot of places elsewhere, where I can't use 01, etc.)
>
> Cheers
>
> Renger
>
>
>
>
> _________________________________________
> Renger van Nieuwkoop
> Centre of Economic Research (CER-ETH)
> Z?richbergstrasse 18 (ZUE)
> CH - 8032 Z?rich
> +41 44 632 02 63
> mailto: rengerv at etzh.ch
> blog.modelworks.ch
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Tue Oct  8 19:57:17 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 8 Oct 2013 10:57:17 -0700
Subject: [R] tables with row sorted numerically although factors
In-Reply-To: <5E17CCD4AACE3A4C8CFF411186AE8190319BE7E6@EXDAG30-N2.hostallapps.net>
References: <5E17CCD4AACE3A4C8CFF411186AE8190319BE7E6@EXDAG30-N2.hostallapps.net>
Message-ID: <34E7D386-35CD-4403-9F7E-27748AD16613@comcast.net>


On Oct 8, 2013, at 10:29 AM, Renger van Nieuwkoop wrote:

> Hi
> I am using the package tables and want to have the rows in the numerical order and not in the alphabetical order:
> 
> library(tables)
> Nodes     <- c(1,10,20,2)
> Values    <- c(1,2,3,4)
> Data      <- data.frame(cbind(Nodes,Values))
> data$Nodes<- as.factor(as.character(data$Nodes)) # necessary to get factors for tabular
> 
> tabular(Nodes  ~ Values*mean, data=data)
> 
>       Values
> Nodes mean
> 1     1
> 10    2
> 2     4
> 20    3
> 
> And what I want is this:

Ypu are failing to pay attention to capitalization of "Data" and not using the levels argument to factor() as you should be:

Data$Nodes<- factor(Data$Nodes, levels=unique(Nodes[order(Nodes)]))
 # using the numeric order rather than the lexigraphic order
tabular(Nodes  ~ Values*mean, data=Data)


> 
>       Values
> Nodes mean
> 1     1
> 2     4
> 10    2
> 20    3
> 
> Any idea how to do this? (the solution is not to write 01, 02, 10, 20, because I use Nodes in lot of places elsewhere, where I can't use 01, etc.)
> 
> Cheers
> 
> Renger
> 

David Winsemius
Alameda, CA, USA


From 538280 at gmail.com  Tue Oct  8 19:59:59 2013
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 8 Oct 2013 11:59:59 -0600
Subject: [R] tables with row sorted numerically although factors
In-Reply-To: <5E17CCD4AACE3A4C8CFF411186AE8190319BE7E6@EXDAG30-N2.hostallapps.net>
References: <5E17CCD4AACE3A4C8CFF411186AE8190319BE7E6@EXDAG30-N2.hostallapps.net>
Message-ID: <CAFEqCdzw=Gsf4iANi_mArSrSbCnuJ82Qj9o2X13fgien=sH-CQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/c279514a/attachment.pl>

From HDoran at air.org  Tue Oct  8 21:46:41 2013
From: HDoran at air.org (Doran, Harold)
Date: Tue, 8 Oct 2013 19:46:41 +0000
Subject: [R] Writing Generic (Extractor) Functions
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6866440209C@DC1VEX10MB001.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/0acbd1dc/attachment.pl>

From ligges at statistik.tu-dortmund.de  Tue Oct  8 20:08:13 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 08 Oct 2013 20:08:13 +0200
Subject: [R]
 =?windows-1252?q?What_is_the_difference_between_Reduce=28=85?=
 =?windows-1252?q?=29_and_do=2Ecall=28=85=29_=3F?=
In-Reply-To: <CAPccJQEEqbT9kSimUN1BVrv49m_ho_i8e-=95c1Qx7DWk7KNrQ@mail.gmail.com>
References: <CAPccJQEEqbT9kSimUN1BVrv49m_ho_i8e-=95c1Qx7DWk7KNrQ@mail.gmail.com>
Message-ID: <52544A0D.9000205@statistik.tu-dortmund.de>

Reduce will rbind 2 elements and then the result with the next element 
of the list --- while do.call just applies rbind once on all elements of 
the list at the same time.

Uwe Ligges




On 08.10.2013 11:22, Asis Hallab wrote:
> Dear R-Experts,
>
> using both do.call(?) and Reduce(?), I wonder about the differences of both.
> Please consider the following example:
>
> m <- matrix( 1:9, ncol=3 )
> lst <- list( m, 2*m, 3*m )
>
> rbind( lst )
> # Returns
>          [,1]      [,2]      [,3]
> tmp.lst Integer,9 Numeric,9 Numeric,9
>
> do.call( 'rbind', tmp.lst )
> # Returns
>        [,1] [,2] [,3]
>   [1,]    1    4    7
>   [2,]    2    5    8
>   [3,]    3    6    9
>   [4,]    2    8   14
>   [5,]    4   10   16
>   [6,]    6   12   18
>   [7,]    3   12   21
>   [8,]    6   15   24
>   [9,]    9   18   27
>
> Reduce( rbind, tmp.lst )
> # Returns the same
>        [,1] [,2] [,3]
>   [1,]    1    4    7
>   [2,]    2    5    8
>   [3,]    3    6    9
>   [4,]    2    8   14
>   [5,]    4   10   16
>   [6,]    6   12   18
>   [7,]    3   12   21
>   [8,]    6   15   24
>   [9,]    9   18   27
>
> So, what is the difference between Reduce and do.call and when best to
> use which?
>
> Your help will be much appreciated.
>
> Kind regards!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Tue Oct  8 20:15:06 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 08 Oct 2013 20:15:06 +0200
Subject: [R] Plot with date
In-Reply-To: <CAL+pVGjSGNOd8wbp6inu6k4SD+dgqo5a5a_MgHBPcLuu01ONOA@mail.gmail.com>
References: <CAL+pVGjSGNOd8wbp6inu6k4SD+dgqo5a5a_MgHBPcLuu01ONOA@mail.gmail.com>
Message-ID: <52544BAA.8080707@statistik.tu-dortmund.de>

See ?axis.Date

Uwe Ligges


On 08.10.2013 18:34, Barbara Rogo wrote:
> I have to built a graphic with a time series of returns, but it have not a
> frequency (for example monthly in one year). On the x of the graphic I need
> to see only the year and not all the date (for example, "1996-01-02" ,
> 1996).
> How I can do this????
> Thank you
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Tue Oct  8 18:43:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 8 Oct 2013 09:43:16 -0700 (PDT)
Subject: [R] R: Re: R: Re:  Information Frequency problem calculation
In-Reply-To: <24611615.2406301381247318441.JavaMail.defaultUser@defaultHost>
References: <24611615.2406301381247318441.JavaMail.defaultUser@defaultHost>
Message-ID: <1381250596.45920.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Dear Jarod,

How about this?


a<- read.table(text="NAME1??? NAME2??? RNA
mauro??? francesco??? E234
luca??? giuseppe??? E5578
luca??? franco??? E5569
maria??? luca??? E4556
maria??? mauro??? E4556
luisa??? mara??? E4755
mara??? luca??? E234
luigi??? veronica??? E234
mauro??? veronica??? E235
francesco mauro????? E236
mauro francesco? E234
luca?? giuseppe? E5576",sep="",header=TRUE,stringsAsFactors=FALSE)
vec1<- as.character(interaction(a[,1:2],sep="_"))

cbind(freq=sapply(split(a,vec1),function(x) nrow(unique(x))))
#??????????????? freq
#francesco_mauro??? 1
#luca_franco??????? 1
#luca_giuseppe????? 2
#luigi_veronica???? 1
#luisa_mara???????? 1
#mara_luca????????? 1
#maria_luca???????? 1
#maria_mauro??????? 1
#mauro_francesco??? 1
#mauro_veronica???? 1

A.K.


----- Original Message -----
From: "jarod_v6 at libero.it" <jarod_v6 at libero.it>
To: smartpink111 at yahoo.com
Cc: 
Sent: Tuesday, October 8, 2013 11:48 AM
Subject: R: Re: R: Re: [R] Information Frequency problem calculation

Dear Master, I want to count separate it is another category

>----Messaggio originale----
>Da: smartpink111 at yahoo.com
>Data: 08/10/2013 17.30
>A: "jarod_v6 at libero.it"<jarod_v6 at libero.it>
>Ogg: Re: R: Re: [R] Information Frequency problem calculation
>
>I have another doubt.? If you have "francesco- mauro" (francesco in 1st 
column and mauro in 2nd column) and the RNA category is say E238.? Would you 
count the sum of groups as 2 for "mauro-francesco" or do they count as 
separate?
>
>
>


From HDoran at air.org  Tue Oct  8 22:36:56 2013
From: HDoran at air.org (Doran, Harold)
Date: Tue, 8 Oct 2013 20:36:56 +0000
Subject: [R] Writing Generic (Extractor) Functions
In-Reply-To: <CAAjq1mci5REas052w-zQ=SHOskbbyP6b1wqxHOgJFzoOUz4zvg@mail.gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6866440209C@DC1VEX10MB001.air.org>
	<CAAjq1mci5REas052w-zQ=SHOskbbyP6b1wqxHOgJFzoOUz4zvg@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD68664403170@DC1VEX10MB001.air.org>

Chapter 7 of Writing R Extensions

http://cran.r-project.org/doc/manuals/R-exts.html#Generic-functions-and-methods

-----Original Message-----
From: grettke at gmail.com [mailto:grettke at gmail.com] On Behalf Of Grant Rettke
Sent: Tuesday, October 08, 2013 4:31 PM
To: Doran, Harold
Cc: r-help at r-project.org
Subject: Re: [R] Writing Generic (Extractor) Functions

What is the URL for the section that you are referencing?

On Tue, Oct 8, 2013 at 2:46 PM, Doran, Harold <HDoran at air.org> wrote:
> The Writing R Extensions guide has a good section on writing generic functions and methods. However, has anyone generated any additional tutorials, presentations, notes, etc that extend this topic?
>
> Perhaps showing additional examples of what works well and what risks to avoid.
>
> Thanks,
> Harold
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Grant Rettke | ACM, AMA, COG, IEEE
grettke at acm.org | http://www.wisdomandwonder.com/ ?Wisdom begins in wonder.? --Socrates ((? (x) (x x)) (? (x) (x x))) ?Life has become immeasurably better since I have been forced to stop taking it seriously.? --Thompson

From ggrothendieck at gmail.com  Tue Oct  8 23:01:29 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 8 Oct 2013 17:01:29 -0400
Subject: [R] Summary functions in sqldf() XXXX
In-Reply-To: <CAPRGo-k32Gwv6P1Fdd33LK0Uux69Jro032xoiGMDRO7HMLdqhw@mail.gmail.com>
References: <CAPRGo-k32Gwv6P1Fdd33LK0Uux69Jro032xoiGMDRO7HMLdqhw@mail.gmail.com>
Message-ID: <CAP01uRk6dKkZx_oQhVAmZcCoS-+mi682Eqhedee0-67CtUWBJg@mail.gmail.com>

On Tue, Oct 8, 2013 at 11:46 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> Hi everyone,
>
> Is it possible to obtain the 1st & 3rd quartiles & the median in a sqldf()
> select statement? If so, can you please provide the summary fn code?


See the list of functions in Example15 on the sqldf home page:

https://code.google.com/p/sqldf/#Example_15._Use_of_RSQLite.extfuns_library_functions

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From grettke at acm.org  Tue Oct  8 22:31:12 2013
From: grettke at acm.org (Grant Rettke)
Date: Tue, 8 Oct 2013 15:31:12 -0500
Subject: [R] Writing Generic (Extractor) Functions
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6866440209C@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6866440209C@DC1VEX10MB001.air.org>
Message-ID: <CAAjq1mci5REas052w-zQ=SHOskbbyP6b1wqxHOgJFzoOUz4zvg@mail.gmail.com>

What is the URL for the section that you are referencing?

On Tue, Oct 8, 2013 at 2:46 PM, Doran, Harold <HDoran at air.org> wrote:
> The Writing R Extensions guide has a good section on writing generic functions and methods. However, has anyone generated any additional tutorials, presentations, notes, etc that extend this topic?
>
> Perhaps showing additional examples of what works well and what risks to avoid.
>
> Thanks,
> Harold
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Grant Rettke | ACM, AMA, COG, IEEE
grettke at acm.org | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson


From carl at witthoft.com  Tue Oct  8 23:35:07 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Tue, 08 Oct 2013 17:35:07 -0400
Subject: [R] parallels package -can't create cluster
Message-ID: <52547A8B.8080707@witthoft.com>

I am trying to use the parallel package, and found that makeCluster 
hangs (and no apparent actions have taken place). This is Windows7-64, 
"Enterprise", R 3.0.1 .

I've traced the hang to the following line in newPSOCKnode :

con <- socketConnection("localhost", port = port, server = TRUE,
     blocking = TRUE, open = "a+b", timeout = timeout)
That command stalls. My suspicion is this is due to some "overzealous IT 
rules" laid down on our work computers, but would welcome any 
suggestions as to how to trace (and fix) the source of the problem.

While in debug mode, I did a dump just before the socketConnection call:

Browse[3]> ls.str()
arg :  chr "parallel:::.slaveRSOCK()"
cmd :  chr 
"\"C:/Users/carl.witthoft/Documents/R/R-3.0.1/bin/x64/Rscript\" -e 
\"parallel:::.slaveRSOCK()\" MASTER=localhost PORT=11017 OUT="| 
__truncated__
env :  chr "MASTER=localhost PORT=11017 OUT=/dev/null TIMEOUT=2592000 
METHODS=TRUE XDR=TRUE"
machine :  chr "localhost"
manual :  logi FALSE
master :  chr "localhost"
methods :  logi TRUE
options : <environment: 0x000000000ccac6a0>
outfile :  chr "/dev/null"
port :  int 11017
rank :  int 1
renice :  int NA
rscript :  chr 
"\"C:/Users/carl.witthoft/Documents/R/R-3.0.1/bin/x64/Rscript\""
timeout :  num 2592000
useXDR :  logi TRUE

Other possibly useful info:

I opened a shell and ran
netsh advfirewall firewall add rule name="Open Port 11017" dir=in 
action=allow protocol=TCP localport=11017

and got an "OK" response. I ran netstat -a -n and found the following line:

TCP 0.0.0.0:11017 0.0.0.0:0 LISTENING

But running makePSOCKcluster still hangs at the same place.

NEXT: I tried running R from the command line (via cygwin bash), and the 
error message I get is

Error in loadhistory(file) : no history mechanism available Execution 
halted

, after which ctrl-C returns me to the R-prompt.


-- 

Sent from a parallel universe almost, but not entirely,
nothing at all like this one.


From irasharenow100 at yahoo.com  Wed Oct  9 01:02:27 2013
From: irasharenow100 at yahoo.com (Ira Sharenow)
Date: Tue, 08 Oct 2013 16:02:27 -0700
Subject: [R] iconv question: SQL Server 2005 to R
Message-ID: <52548F03.2030504@yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/992135f3/attachment.pl>

From vksingh.iiitb at gmail.com  Wed Oct  9 05:13:48 2013
From: vksingh.iiitb at gmail.com (Vivek Singh)
Date: Wed, 9 Oct 2013 11:13:48 +0800
Subject: [R] R function for Bisecting K-means algorithm
In-Reply-To: <CAFgDSD6CXm2fpE55PyW0RmKyACZY6UPAZsFg1UFQistOmELW7Q@mail.gmail.com>
References: <CAFgDSD6CXm2fpE55PyW0RmKyACZY6UPAZsFg1UFQistOmELW7Q@mail.gmail.com>
Message-ID: <CAFgDSD6T2DmMNO5=L9LYGajbm_Rp5Z15=qRKvHAT=f9vNF6xYw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/50c00c26/attachment.pl>

From gunter.berton at gene.com  Wed Oct  9 06:37:05 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 8 Oct 2013 21:37:05 -0700
Subject: [R] R function for Bisecting K-means algorithm
In-Reply-To: <CAFgDSD6T2DmMNO5=L9LYGajbm_Rp5Z15=qRKvHAT=f9vNF6xYw@mail.gmail.com>
References: <CAFgDSD6CXm2fpE55PyW0RmKyACZY6UPAZsFg1UFQistOmELW7Q@mail.gmail.com>
	<CAFgDSD6T2DmMNO5=L9LYGajbm_Rp5Z15=qRKvHAT=f9vNF6xYw@mail.gmail.com>
Message-ID: <CACk-te20Yyu1bA6afZ2+qTcaC931eS88fb2y5ayZMEj6AHuzdg@mail.gmail.com>

Probably not. I would guess that most (or all) of us have no clue what
"bisecting" a k-means algorithm means. You might have more luck if you
explain yourself more clearly (but probably not from me in any case).

Is this an R question, by the way? This is not a statistics list --
it's an R programming help list.

Cheers,
-- Bert

On Tue, Oct 8, 2013 at 8:13 PM, Vivek Singh <vksingh.iiitb at gmail.com> wrote:
> Any help on this?
>
> Regards,
> Vivek
>
>
> On Tue, Oct 8, 2013 at 2:36 PM, Vivek Singh <vksingh.iiitb at gmail.com> wrote:
>
>> Hi All,
>>
>> Can someone please tell me* R function for Bisecting K-means algorithm*.
>> I have used *kmeans() *function but not getting good results.
>>
>> Please help.
>>
>> --
>> Thanks and Regards,
>>
>> Vivek Kumar Singh
>>
>> Research Assistant,
>> School of Computing,
>> National University of Singapore
>> Mobile:(0065) 82721535
>>
>
>
>
> --
> Thanks and Regards,
>
> Vivek Kumar Singh
>
> Research Assistant,
> School of Computing,
> National University of Singapore
> Mobile:(0065) 82721535
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From shuklvineet at gmail.com  Wed Oct  9 08:02:04 2013
From: shuklvineet at gmail.com (Vineet Shukla)
Date: Wed, 9 Oct 2013 11:32:04 +0530
Subject: [R] Fwd: how to check the accuracy for maxent ?
In-Reply-To: <CA+hec4RHzbxU65rZ5-A_Z1-GbPYOWF6iQ+W9jsR-uJd5PsWE+g@mail.gmail.com>
References: <CA+hec4RHzbxU65rZ5-A_Z1-GbPYOWF6iQ+W9jsR-uJd5PsWE+g@mail.gmail.com>
Message-ID: <CA+hec4Rgt-pQF8yv9-qCuPqjW-7=uJyEaDd2VwCh1z4wzWVe3w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/7b48a2e5/attachment.pl>

From aviad.klein at gmail.com  Wed Oct  9 08:43:03 2013
From: aviad.klein at gmail.com (Aviad Klein)
Date: Wed, 9 Oct 2013 09:43:03 +0300
Subject: [R] Parsing useragent in R
Message-ID: <CANQR1GHGEtzdwNHvua2OxhPCcCEvBBVUkn1mvf_UnjJEue760g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/0ec8f34f/attachment.pl>

From lauriebayet at gmail.com  Wed Oct  9 10:23:16 2013
From: lauriebayet at gmail.com (laurie bayet)
Date: Wed, 9 Oct 2013 10:23:16 +0200
Subject: [R] mixed model MANOVA? does it even exist?
Message-ID: <CAGHpV7xP62ayzUH9vER0JwuEKzrOB2oAwkGNv7E9Egs9n8Yg-A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/57b0f7e6/attachment.pl>

From ripley at stats.ox.ac.uk  Wed Oct  9 11:16:08 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 09 Oct 2013 10:16:08 +0100
Subject: [R] iconv question: SQL Server 2005 to R
In-Reply-To: <52548F03.2030504@yahoo.com>
References: <52548F03.2030504@yahoo.com>
Message-ID: <52551ED8.7050701@stats.ox.ac.uk>

'Unicode' is a not an encoding.  As the help says

fileEncoding: character string: if non-empty declares the encoding used
           on a file (not a connection) so the character data can be
           re-encoded.  See the ?Encoding? section of the help for
           ?file?, the ?R Data Import/Export Manual? and ?Note?.

The first of the cross references explains this.

On 09/10/2013 00:02, Ira Sharenow wrote:
> A colleague is sending me quite a few files that have been saved with MS
> SQL Server 2005. I am using R 2.15.1 on Windows 7.

See the posting guide: your R update is overdue as there have been 5 
releases since then.

> I am trying to read in the files using standard techniques. Although the
> file has a csv extension when I go to Excel or WordPad and do SAVE AS I
> see that it is Unicode Text. Notepad indicates that the encoding is
> Unicode. Right now I have to do a few things from within Excel (such as
> Text to Columns) and eventually save as a true csv file before I can
> read it into R and then use it.
>
> Is there an easy way to solve this from within R? I am also open to easy
> SQL Server 2005 solutions.
>
> I tried the following from within R.
>
> testDF = read.table("Info06.csv", header = TRUE, sep = ",")
>
>> testDF2 =  iconv(x = testDF, from = "Unicode", to = "")
>
> Error in iconv(x = testDF, from = "Unicode", to = "") :
>
> unsupported conversion from 'Unicode' to '' in codepage 1252
>
> # The next line did not produce an error message
>
>> testDF3 =  iconv(x = testDF, from = "UTF-8" , to = "")
>
>> testDF3[1:6,  1:3]
>
> Error in testDF3[1:6, 1:3] : incorrect number of dimensions
>
> # The next line did not produce an error message
>
>> testDF4 =  iconv(x = testDF, from = "macroman" , to = "")
>
>> testDF4[1:6,  1:3]
>
> Error in testDF4[1:6, 1:3] : incorrect number of dimensions
>
>>   Encoding(testDF3)
>
> [1] "unknown"
>
>>   Encoding(testDF4)
>
> [1] "unknown"
>
> This is the first few lines from WordPad
>
> Date,StockID,Price,MktCap,ADV,SectorID,Days,A1,std1,std2
>
> 2006-01-03
> 00:00:00.000, at Stock1,2.53,467108197.38,567381.144444444,4,133.14486997089,-0.0162107939626307,0.0346283580367959,0.0126471695454834
>
> 2006-01-03
> 00:00:00.000, at Stock2,1.3275,829803070.531114,6134778.93292,5,124.632223896458,0.071513138376339,0.0410694546850102,0.0172091268025929
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Wed Oct  9 11:32:18 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 9 Oct 2013 11:32:18 +0200
Subject: [R] mixed model MANOVA? does it even exist?
In-Reply-To: <CAGHpV7xP62ayzUH9vER0JwuEKzrOB2oAwkGNv7E9Egs9n8Yg-A@mail.gmail.com>
References: <CAGHpV7xP62ayzUH9vER0JwuEKzrOB2oAwkGNv7E9Egs9n8Yg-A@mail.gmail.com>
Message-ID: <3035C929-F8FF-4FAD-88DD-8F29EB623DFD@gmail.com>

As a matter of principle, yes, multivariate mixed models do exist, look at the last bit of example(manova) (in reasonably recent versions of R).

In practice, it often doesn't really buy you much. It just gives a joint test for all the DVs, the estimates are the same as in separate analyses. 

The tricky bit is usually to define precisely what the research question is: Do you want to know whether the predictors affect the marginal distributions of Y1, Y2,... or are you interested in conditional effects given other DVs (aka test for additional information)? The latter case leads to regression models where other DVs are entered as covariates.

There's no issue with having categorical variables as predictors in multiple regression in R, dummy variables are created internally. But if you are considering mixed models, presumably you have a random effect that needs to be included?

-pd

On Oct 9, 2013, at 10:23 , laurie bayet wrote:

> Hi,
> 
> Sorry to bother you again.
> 
> I would like to estimate the effect of several categorical factors (two
> between subjects and one within subjects) on two continuous dependent
> variables that probably covary, with subjects as a  random effect. *I want
> to control for the covariance between those two DVs when estimating the
> effects of the categorical predictors** on those two DVs*. The thing is, i
> know the predictors have an effect on DV1, and i know DV2 covaries with
> DV1, so it would be "cheating" to simply estimate the effect of the
> predictors on DV2 because those effects could be indirect (via DV1), right ?
> 
> I see two solutions :
> 
> *One solution would be a mixed model MANOVA (if that even exists)*. But i
> don't know how to run a mixed model MANOVA, i tried to do it with
> Statistica but couldn't find the right module (I know how to declare two
> DVs and run a GLM, but *I don't know if the covariance between my two DVs
> is automatically controlled for*). Same thing with R. I tried to ask a
> question on Statistica's forum with no answer, tried looking around in the
> manuals with no improvement.
> 
> *A backup solution would be a multiple regression* (regressing DV2 against
> DV1 with the categorical predictors). But i am not sure how to implement a
> mixed model, which function i should use and besides, it would be *much
> less convenient because one of my categorical predictors has three
> levels*(so i would have to split it and make it two predictors,
> right?).
> 
> Thank you for any help at all !
> 
> Cheers,
> 
> L.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wewolski at gmail.com  Wed Oct  9 11:34:57 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Wed, 9 Oct 2013 11:34:57 +0200
Subject: [R] how to pairs plot without axes
Message-ID: <CAAjnpdjBufDmMeqyMj2M01CZEjwc6P3_aaH-NW8ar=epan+ccA@mail.gmail.com>

In the pairs help is an example how to plot the correlation as txt.
How do I get rid of the axes
in the upper panel?

regards



## put (absolute) correlations on the upper panels,
## with size proportional to the correlations.
panel.cor <- function(x, y, digits = 3, prefix = "", cex.cor,axis=F, ...)
{
  tt<-cbind(x,y)
  idx<-apply(tt,1,function(x){sum(is.na(x))==0})
  x<-x[idx]
  y<-y[idx]
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y))
  print(r)
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste0(prefix, txt)
  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, cex = r^20*cex.cor)
}


-- 
Witold Eryk Wolski


From nalimilan at club.fr  Wed Oct  9 11:37:16 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Wed, 09 Oct 2013 11:37:16 +0200
Subject: [R] iconv question: SQL Server 2005 to R
In-Reply-To: <52548F03.2030504@yahoo.com>
References: <52548F03.2030504@yahoo.com>
Message-ID: <1381311436.2948.57.camel@milan>

Le mardi 08 octobre 2013 ? 16:02 -0700, Ira Sharenow a ?crit :
> A colleague is sending me quite a few files that have been saved with MS 
> SQL Server 2005. I am using R 2.15.1 on Windows 7.
> 
> I am trying to read in the files using standard techniques. Although the 
> file has a csv extension when I go to Excel or WordPad and do SAVE AS I 
> see that it is Unicode Text. Notepad indicates that the encoding is 
> Unicode. Right now I have to do a few things from within Excel (such as 
> Text to Columns) and eventually save as a true csv file before I can 
> read it into R and then use it.
> 
> Is there an easy way to solve this from within R? I am also open to easy 
> SQL Server 2005 solutions.
>
> I tried the following from within R.
> 
> testDF = read.table("Info06.csv", header = TRUE, sep = ",")
> 
> > testDF2 =  iconv(x = testDF, from = "Unicode", to = "")
> 
> Error in iconv(x = testDF, from = "Unicode", to = "") :
> 
> unsupported conversion from 'Unicode' to '' in codepage 1252
> 
> # The next line did not produce an error message
> 
> > testDF3 =  iconv(x = testDF, from = "UTF-8" , to = "")
> 
> > testDF3[1:6,  1:3]
> 
> Error in testDF3[1:6, 1:3] : incorrect number of dimensions
> 
> # The next line did not produce an error message
> 
> > testDF4 =  iconv(x = testDF, from = "macroman" , to = "")
> 
> > testDF4[1:6,  1:3]
> 
> Error in testDF4[1:6, 1:3] : incorrect number of dimensions
> 
> >  Encoding(testDF3)
> 
> [1] "unknown"
> 
> >  Encoding(testDF4)
> 
> [1] "unknown"
> 
> This is the first few lines from WordPad
> 
> Date,StockID,Price,MktCap,ADV,SectorID,Days,A1,std1,std2
> 
> 2006-01-03 
> 00:00:00.000, at Stock1,2.53,467108197.38,567381.144444444,4,133.14486997089,-0.0162107939626307,0.0346283580367959,0.0126471695454834
> 
> 2006-01-03 
> 00:00:00.000, at Stock2,1.3275,829803070.531114,6134778.93292,5,124.632223896458,0.071513138376339,0.0410694546850102,0.0172091268025929
What's the actual problem? You did not state any. Do you get accentuated
characters that are not printed correctly after importing the file? In
the two lines above it does not look like there would be any non-ASCII
characters in this file, so encoding would not matter.


Regards


From rolf.turner at vodafone.co.nz  Wed Oct  9 12:26:01 2013
From: rolf.turner at vodafone.co.nz (Rolf Turner)
Date: Wed, 09 Oct 2013 23:26:01 +1300
Subject: [R] Testing.
Message-ID: <52552F39.4010701@vodafone.co.nz>

Please ignore.  My apologies for the noise.

cheers,

Rolf Turner


From pedro.carmona at uv.es  Wed Oct  9 10:46:16 2013
From: pedro.carmona at uv.es (=?ISO-8859-1?Q?Pedro_Carmona_Ib=E1=F1ez?=)
Date: Wed, 9 Oct 2013 10:46:16 +0200
Subject: [R] How can I use the predict function in R in a logistic
 regression fitted years ago?
Message-ID: <CAHhGfjZU0c-yKWbfkiGR0XML+NvpDFoBPmZ5_3EnRfoN4=G0=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/64967870/attachment.pl>

From cmartin at uc.edu.ve  Tue Oct  8 16:35:19 2013
From: cmartin at uc.edu.ve (Carlos M. Martinez Manrique)
Date: Tue, 8 Oct 2013 10:05:19 -0430
Subject: [R] =?utf-8?q?=5BR-pkgs=5D_A_new_version_of_the_package_=E2=80=9C?=
 =?utf-8?q?TestSurvRec=E2=80=9D_is_now_available_on_CRAN?=
In-Reply-To: <1066770146.1892580.1381242742199.JavaMail.root@uc.edu.ve>
Message-ID: <83174111.1898895.1381242919289.JavaMail.root@uc.edu.ve>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131008/d45017b1/attachment.pl>
-------------- next part --------------
_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From lauriebayet at gmail.com  Wed Oct  9 11:43:58 2013
From: lauriebayet at gmail.com (laurie bayet)
Date: Wed, 9 Oct 2013 11:43:58 +0200
Subject: [R] mixed model MANOVA? does it even exist?
In-Reply-To: <3035C929-F8FF-4FAD-88DD-8F29EB623DFD@gmail.com>
References: <CAGHpV7xP62ayzUH9vER0JwuEKzrOB2oAwkGNv7E9Egs9n8Yg-A@mail.gmail.com>
	<3035C929-F8FF-4FAD-88DD-8F29EB623DFD@gmail.com>
Message-ID: <CAGHpV7wH0d57z=bRS6TKU5N9z-rkNKfdnPqogC6Nz+DhPwJVgQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/def78177/attachment.pl>

From gdsayshi at gmail.com  Wed Oct  9 11:54:41 2013
From: gdsayshi at gmail.com (Gaurav Dasgupta)
Date: Wed, 9 Oct 2013 15:24:41 +0530
Subject: [R] How to write R data frame to HDFS using rhdfs?
Message-ID: <CACq8Ys1fxO1J=bny_Td3oODE6Of4MadXgHbYRu3WQ0VS1SWFdw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/3a533af6/attachment.pl>

From gyjt at leeds.ac.uk  Wed Oct  9 12:23:42 2013
From: gyjt at leeds.ac.uk (Joey Talbot)
Date: Wed, 9 Oct 2013 11:23:42 +0100
Subject: [R] Dutilleul's method with covarying parameters
Message-ID: <647B0E0197C0AA46870ABA4B3C83579201F783788AB0@HERMES8.ds.leeds.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/8373e92a/attachment.pl>

From praveensripati at gmail.com  Wed Oct  9 13:31:49 2013
From: praveensripati at gmail.com (Praveen Sripati)
Date: Wed, 9 Oct 2013 12:31:49 +0100
Subject: [R] Error while running MR using rmr2
Message-ID: <CADYHM8zz152Xz1T2e5so8cO1EZb7UUFjRUxtccZRTwXe6fuC1Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/2f335a11/attachment.pl>

From ron at hub.yellowbank.com  Wed Oct  9 13:50:20 2013
From: ron at hub.yellowbank.com (Ronald Peterson)
Date: Wed, 9 Oct 2013 07:50:20 -0400
Subject: [R] select unique by multiple values
Message-ID: <CAJPRK8ap3s6bKuh3GXmpuY02hXvK+3hPiwzRjHaMNVJ2mxEc9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/cecada75/attachment.pl>

From S.Ellison at lgcgroup.com  Wed Oct  9 14:22:07 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Wed, 9 Oct 2013 13:22:07 +0100
Subject: [R] How can I use the predict function in R in a logistic
 regression fitted years ago?
In-Reply-To: <CAHhGfjZU0c-yKWbfkiGR0XML+NvpDFoBPmZ5_3EnRfoN4=G0=w@mail.gmail.com>
References: <CAHhGfjZU0c-yKWbfkiGR0XML+NvpDFoBPmZ5_3EnRfoN4=G0=w@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487E426CC@GOLD.corp.lgc-group.com>



> Suppose that you have a logistic equation regression (binary model) from an
> old model that you estimated some years ago. Therefore you know the
> parameters ?k (k = 1, 2, ..., p) because they were estimated in the
> past.
> But you don't have the data that were used to fit the model.
> 
> My question is: can I introduce this old estimated logistic model in R as
> an object (corresponding to a logistic regression model)?

You have not said how you fitted the model, so you could have anything from an lm() object to glm, passing through various max likelihood and optimisation routines on the way, so the answer is properly 'maybe'.

Having said that, for most practical purposes I think the answer is in practice 'no'. All the predict methods would require you to construct an object with the right class, containing as a minimum the parts of the object used by the relevant predict() method. For example, if you look at the code in predict.glm, one of the more common logistic modelling tools, that passes the fitted object to predict.lm and then uses an inverse link function to bring the predictions back into the binomial family space. So you will at least need to create enough of an object to keep predict.lm happy. That in turn will need things like the terms object, the contrasts, the call offset and so on. It also uses the object's residuals (for their length, if nothing else) and of course if you want standard errors on fit or prediction you'll need other things. Without the data that will all be very problematic and very tedious to invent.

It would be far quicker to write a simple function that does the prediction for you from the parameters.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From cleberchaves at gmail.com  Wed Oct  9 14:33:53 2013
From: cleberchaves at gmail.com (Cleber Chaves)
Date: Wed, 9 Oct 2013 09:33:53 -0300
Subject: [R] lme slopes and intercepts differences
Message-ID: <CAF-5dnt+0Y1rULVs4fn7Th-SHrGt8JpLzGwof_ho04HRyCa9JQ@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/4487b1cf/attachment.pl>

From carl at witthoft.com  Wed Oct  9 14:46:22 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Wed, 9 Oct 2013 05:46:22 -0700 (PDT)
Subject: [R] parallels package -can't create cluster
In-Reply-To: <52547A8B.8080707@witthoft.com>
References: <52547A8B.8080707@witthoft.com>
Message-ID: <1381322782227-4677891.post@n4.nabble.com>

Never mind -- after getting detailed help at SO,  I rebooted  Windows and 
makeCluster() worked just fine.  I have no idea what cruft in my system was
getting in the way, but all's well.





--
View this message in context: http://r.789695.n4.nabble.com/parallels-package-can-t-create-cluster-tp4677850p4677891.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Wed Oct  9 15:26:13 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Oct 2013 06:26:13 -0700 (PDT)
Subject: [R] Correlating data after changing one observation for one
	variable
Message-ID: <1381325173.83666.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

trees <-? structure(list(Girth = c(8.3, 8.6, 8.8, 10.5, 10.7, 10.8, 11, 
11, 11.1, 11.2, 11.3, 11.4, 11.4, 11.7, 12, 12.9, 12.9, 13.3, 
13.7, 13.8, 14, 14.2, 14.5, 16, 16.3, 17.3, 17.5, 17.9, 18, 18, 
20.6), Height = c(70L, 65L, 63L, 72L, 81L, 83L, 66L, 75L, 80L, 
75L, 79L, 76L, 76L, 69L, 75L, 74L, 85L, 86L, 71L, 64L, 78L, 80L, 
74L, 72L, 77L, 81L, 82L, 80L, 80L, 80L, 87L), Volume = c(10.3, 
10.3, 10.2, 16.4, 18.8, 19.7, 15.6, 18.2, 22.6, 19.9, 24.2, 21, 
21.4, 21.3, 19.1, 22.2, 33.8, 27.4, 25.7, 24.9, 34.5, 31.7, 36.3, 
38.3, 42.6, 55.4, 55.7, 58.3, 51.5, 51, 77)), .Names = c("Girth", 
"Height", "Volume"), row.names = c("1", "2", "3", "4", "5", "6", 
"7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", 
"18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", 
"29", "30", "31"), class = "data.frame")


with(trees,cor(Volume,Height))
#[1] 0.5982497
?with(trees,cor(Volume,Girth))
#[1] 0.9671194

?trees$Volume[31]<- 35


with(trees,cor(Volume,Girth))
#[1] 0.9012941
?with(trees,cor(Volume,Height))
[1] 0.5298093


#Looks like you ?attach() trees


attach(trees)

?cor(Volume,Height)
#[1] 0.5298093
?cor(Volume,Girth)
#[1] 0.9012941



trees[31,3] <- 77


You need to attach() again
attach(trees)

?cor(Volume,Height)
#[1] 0.5982497
?cor(Volume,Girth)
#[1] 0.9671194


It is better not to use ?attach().? Try using ?with()


A.K.


After having changed the last observation for Volume from 77.0 to 35, 

> trees[31,3]<-35 
> trees 
? ?Girth Height Volume 
1 ? ?8.3 ? ? 70 ? 10.3 
2 ? ?8.6 ? ? 65 ? 10.3 
3 ? ?8.8 ? ? 63 ? 10.2 
4 ? 10.5 ? ? 72 ? 16.4 
5 ? 10.7 ? ? 81 ? 18.8 
6 ? 10.8 ? ? 83 ? 19.7 
7 ? 11.0 ? ? 66 ? 15.6 
8 ? 11.0 ? ? 75 ? 18.2 
9 ? 11.1 ? ? 80 ? 22.6 
10 ?11.2 ? ? 75 ? 19.9 
11 ?11.3 ? ? 79 ? 24.2 
12 ?11.4 ? ? 76 ? 21.0 
13 ?11.4 ? ? 76 ? 21.4 
14 ?11.7 ? ? 69 ? 21.3 
15 ?12.0 ? ? 75 ? 19.1 
16 ?12.9 ? ? 74 ? 22.2 
17 ?12.9 ? ? 85 ? 33.8 
18 ?13.3 ? ? 86 ? 27.4 
19 ?13.7 ? ? 71 ? 25.7 
20 ?13.8 ? ? 64 ? 24.9 
21 ?14.0 ? ? 78 ? 34.5 
22 ?14.2 ? ? 80 ? 31.7 
23 ?14.5 ? ? 74 ? 36.3 
24 ?16.0 ? ? 72 ? 38.3 
25 ?16.3 ? ? 77 ? 42.6 
26 ?17.3 ? ? 81 ? 55.4 
27 ?17.5 ? ? 82 ? 55.7 
28 ?17.9 ? ? 80 ? 58.3 
29 ?18.0 ? ? 80 ? 51.5 
30 ?18.0 ? ? 80 ? 51.0 
31 ?20.6 ? ? 87 ? 35.0 

the correlation coefficient does not change, which it should... 
earlier: 
> cor(Volume, Girth) 
[1] 0.9671194 
> cor(Volume, Height) 
[1] 0.5982497 

and after changing value: 
> cor(Volume, Girth) 
[1] 0.9671194 
> cor(Volume, Height) 
[1] 0.5982497 

Why is this? 
Thanks in advance ;) 
Victoria


From carnellr at battelle.org  Wed Oct  9 15:37:15 2013
From: carnellr at battelle.org (Rob Carnell)
Date: Wed, 9 Oct 2013 13:37:15 +0000
Subject: [R] Latin Hypercube Sample and transformation to uniformly
	distributed integers or classes
References: <CABsGe_xZmJS4YSpzB9VX3hjSKdsxC7A37ZzL_V1Z+X8rOrYFJA@mail.gmail.com>
Message-ID: <loom.20131009T153321-487@post.gmane.org>

Johannes Radinger <johannesradinger <at> gmail.com> writes:

> 
> Hi,
> 
> I'd like to use Latin Hypercube Sampling (LHC) in the the context of
> uncertainty / sensitivity analysis of a complex model with approximately 
10
> input variables. With the LHC approach I'd like to generate parameter
> combinations for my model input variables.
> Therefore I came across an simple example here on the mailing list (
> https://stat.ethz.ch/pipermail/r-help/2011-June/279931.html):
> 
> Easy Example
> Parameter 1: normal(1, 2)
> Parameter 2: normal(3, 4)
> Parameter 3: uniform(5, 10)
> 
> require(lhs)
> N <- 1000
> x <- randomLHS(N, 3)
> y <- x
> y[,1] <- qnorm(x[,1], 1, 2)
> y[,2] <- qnorm(x[,2], 3, 4)
> y[,3] <- qunif(x[,3], 5, 10)
> 
> par(mfrow=c(2,2))
> apply(x, 2, hist)
> 
> par(mfrow=c(2,2))
> apply(y, 2, hist)
> 
> However, some of my parameters are uniformly distributed integer values
> and/or uniformly distributed classes. So, for example one input parameter
> can be "yellow", "green", "red" with equal probability. Of course these
> attributes can be transformed into integers (1,2,3) with a uniform
> distribution.
> 
> So far I've tried to use the round function:
> 
> y[,3] <- round(qunif(x[,3], 5, 10))
> 
> which does not sample the 1 and 10 eqally to 2:8 (this is discussed 
already
> somewhere else here on the list in another context, and the function
> sample() is suggested). How can this be applied here and how can a column
> of the lhs-output be transformed in e.g integers 1:10 or the three colors
> as mentioned above?
> 
> thanks,
> 
> Johannes
> 
> 	[[alternative HTML version deleted]]
> 
> 

Johannes,

I would modify my example (quoted above) as follows to meet your needs.  
Please feel free to email me directly about the lhs package if necessary.

require(lhs)
N <- 1000
set.seed(1919)

x <- randomLHS(N, 4)
y <- x
# uniform on 1-10
y[,1] <- ceiling(qunif(x[,1], 0, 10))
# three colors 1,2,3
y[,2] <- ceiling(qunif(x[,2], 0, 3))
# other distributions
y[,3] <- qunif(x[,3], 5, 10)
y[,4] <- qnorm(x[,4], 0, 2)

par(mfrow=c(2,2))
dummy <- apply(x, 2, hist, main="")

par(mfrow=c(2,2))
plot(1:10, c(table(y[,1])), type="h", col="blue", lwd=2, ylim=c(0,120), 
ylab="Frequency", xlab="y[,1]")
plot(1:3, c(table(y[,2])), type="h", col="blue", lwd=2, ylim=c(0,400), 
ylab="Frequency", xlab="y[,2]")
hist(y[,3], main="")
hist(y[,4], main="")

# change to color names
z <- as.data.frame(y)
z[,2] <- factor(y[,2], labels=c("R","G","B"))
z[1:10,]

Rob


From smartpink111 at yahoo.com  Wed Oct  9 15:38:46 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Oct 2013 06:38:46 -0700 (PDT)
Subject: [R] Remove the help information when R console starts
Message-ID: <1381325926.20289.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Check this link (not tested):


http://stackoverflow.com/questions/7771577/clear-startup-screen-in-r-rstudio

A.K.


I just want to remove the help information when I start R console.


From smartpink111 at yahoo.com  Wed Oct  9 15:56:07 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Oct 2013 06:56:07 -0700 (PDT)
Subject: [R] select unique by multiple values
Message-ID: <1381326967.74914.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi,

Not sure about your expected output.

xyz<- list(x=c(8,6,9,0,0,3,9,7,1,9),y=c(1,2,9,5,1,2,0,9,2,9),z=c(5,6,9,0,5,1,1,7,3,4))
indx<-sort(unique(unlist(lapply(xyz[1:2],function(u) which(!duplicated(u))),use.names=FALSE)))
?xyz[1:2]<-lapply(xyz[1:2],function(u) u[!duplicated(u)])
?xyz[3]$z<- xyz[3]$z[indx]
?xyz
#$x
#[1] 8 6 9 0 3 7 1
#
#$y
#[1] 1 2 9 5 0
#
#$z
#[1] 5 6 9 0 1 1 7 3

A.K.


New to R here. ?Lots of fun. ?Still rather green though. 

I'd like to select unique items from a list that looks like this (for 
example): 

> xyz 
$x 
?[1] 8 6 9 0 0 3 9 7 1 9 
$y 
?[1] 1 2 9 5 1 2 0 9 2 9 
$z 
?[1] 5 6 9 0 5 1 1 7 3 4 

I'd like to select unique (x,y), while preserving association with z 
values. ?When there are duplicate (x,y) pairs, it doesn't really matter 
which (x,y,z) triplet gets preserved - selecting the first would be fine, 
but any other way to do it would be fine also. ?It /would/ be handy to also 
get a list of the rejected triplets, if that's possible. ?Ideas? 

Thanks! 

R


From therneau at mayo.edu  Wed Oct  9 16:36:06 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 09 Oct 2013 09:36:06 -0500
Subject: [R] frailtypack
In-Reply-To: <mailman.23.1381312807.9477.r-help@r-project.org>
References: <mailman.23.1381312807.9477.r-help@r-project.org>
Message-ID: <525569D6.2000404@mayo.edu>

I can't comment on frailtypack issues, but would like to mention that coxme will handle 
nested models, contrary to the statement below that "frailtypack is perhaps the only .... 
for nested survival data".
To reprise the original post's model

    cgd.nfm <- coxme(Surv(Tstart, Tstop, Status) ~ Treatment + (1 | Center/ID), data=cgd.ag)


And a note to the poster-- you should reprise the original message to which you are 
responding.


Terry Therneau

On 10/09/2013 05:00 AM, r-help-request at r-project.org wrote:
> Hello,
>
> I am encountering very similar problems with frailtypack (only, it seems, 3
> years later).  I would be incredibly grateful if you would be willing to
> share any solutions you happened upon for the problem you mention. I have a
> datafile that is even longer than yours (over 15000 events). Events follow a
> two-level nesting structure. When I attempt to run the nested survival model
> in frailtypack the program either stops running entirely or produces an
> error message. I have contacted the frailtypack maintainer but have not yet
> received a response.  It seems that frailtypack is perhaps the only
> widely-available platform for the analysis of nested survival data, so the
> seeming bugginess of this program is troubling.  Please let me know if you
> ended up coming up with a solution to your problem or, alternatively,
> another program able to run the nested analysis. Thank you so much!
>


From 538280 at gmail.com  Wed Oct  9 17:08:20 2013
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 9 Oct 2013 09:08:20 -0600
Subject: [R] How can I use the predict function in R in a logistic
 regression fitted years ago?
In-Reply-To: <CAHhGfjZU0c-yKWbfkiGR0XML+NvpDFoBPmZ5_3EnRfoN4=G0=w@mail.gmail.com>
References: <CAHhGfjZU0c-yKWbfkiGR0XML+NvpDFoBPmZ5_3EnRfoN4=G0=w@mail.gmail.com>
Message-ID: <CAFEqCdwNA-d_ZgHf6offOgsGvYqYBQbapgXLy9fPxL9nr-rNpg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/a572f4d7/attachment.pl>

From irasharenow100 at yahoo.com  Wed Oct  9 19:40:55 2013
From: irasharenow100 at yahoo.com (Ira Sharenow)
Date: Wed, 09 Oct 2013 10:40:55 -0700
Subject: [R] iconv question: SQL Server 2005 to R
In-Reply-To: <1381311436.2948.57.camel@milan>
References: <52548F03.2030504@yahoo.com> <1381311436.2948.57.camel@milan>
Message-ID: <52559527.4000200@yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/0726f881/attachment.pl>

From smartpink111 at yahoo.com  Wed Oct  9 20:24:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Oct 2013 11:24:45 -0700 (PDT)
Subject: [R] select unique by multiple values
In-Reply-To: <CAJPRK8Zb8pTO9u1dbB5iZZcRMnfOA3+-mQjw08Br7ZnNx-avcQ@mail.gmail.com>
References: <1381326967.74914.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAJPRK8Zb8pTO9u1dbB5iZZcRMnfOA3+-mQjw08Br7ZnNx-avcQ@mail.gmail.com>
Message-ID: <1381343085.44147.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this is what you are looking for.

indx<- xyz[[1]]==xyz[[2]]
indx1<- which(indx)[duplicated(xyz[[1]][indx])]

lapply(xyz,function(u) u[-indx1])
$x
[1] 8 6 9 0 0 3 9 7 1

$y
[1] 1 2 9 5 1 2 0 9 2

$z
[1] 5 6 9 0 5 1 1 7 3

?lapply(xyz, function(u) u[indx1])
$x
[1] 9

$y
[1] 9

$z
[1] 4
A.K.


________________________________
From: Ronald Peterson <ron at hub.yellowbank.com>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Wednesday, October 9, 2013 1:52 PM
Subject: Re: [R] select unique by multiple values



Thanks. ?That's not quite what I'm looking for, but it's good see different ways to slice and dice data.

In my example, the one duplicated x,y pair would 9,9, so I would want to reduce the original list to

> xyz
$x
?[1] 8 6 9 0 0 3 9 7 1
$y

?[1] 1 2 9 5 1 2 0 9 2
$z

?[1] 5 6 9 0 5 1 1 7 3

and if it were also possible to get the xyz values that were removed that would be perfect. ?e.g.

$x
[1] 9
$y
[1] 9
$z
[1] 4

Does that make sense?

(my data is in a form accepted by the deldir package, fwiw)

Best,

R.




On Wed, Oct 9, 2013 at 9:56 AM, arun <smartpink111 at yahoo.com> wrote:


>
>Hi,
>
>Not sure about your expected output.
>
>xyz<- list(x=c(8,6,9,0,0,3,9,7,1,9),y=c(1,2,9,5,1,2,0,9,2,9),z=c(5,6,9,0,5,1,1,7,3,4))
>indx<-sort(unique(unlist(lapply(xyz[1:2],function(u) which(!duplicated(u))),use.names=FALSE)))
>?xyz[1:2]<-lapply(xyz[1:2],function(u) u[!duplicated(u)])
>?xyz[3]$z<- xyz[3]$z[indx]
>?xyz
>#$x
>#[1] 8 6 9 0 3 7 1
>#
>#$y
>#[1] 1 2 9 5 0
>#
>#$z
>#[1] 5 6 9 0 1 1 7 3
>
>A.K.
>
>
>
>New to R here. ?Lots of fun. ?Still rather green though.
>
>I'd like to select unique items from a list that looks like this (for
>example):
>
>> xyz
>$x
>?[1] 8 6 9 0 0 3 9 7 1 9
>$y
>?[1] 1 2 9 5 1 2 0 9 2 9
>$z
>?[1] 5 6 9 0 5 1 1 7 3 4
>
>I'd like to select unique (x,y), while preserving association with z
>values. ?When there are duplicate (x,y) pairs, it doesn't really matter
>which (x,y,z) triplet gets preserved - selecting the first would be fine,
>but any other way to do it would be fine also. ?It /would/ be handy to also
>get a list of the rejected triplets, if that's possible. ?Ideas?
>
>Thanks!
>
>R
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


-- 
-Ron-


From bhh at xs4all.nl  Wed Oct  9 20:49:29 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 9 Oct 2013 20:49:29 +0200
Subject: [R] select unique by multiple values
In-Reply-To: <CAJPRK8ap3s6bKuh3GXmpuY02hXvK+3hPiwzRjHaMNVJ2mxEc9Q@mail.gmail.com>
References: <CAJPRK8ap3s6bKuh3GXmpuY02hXvK+3hPiwzRjHaMNVJ2mxEc9Q@mail.gmail.com>
Message-ID: <48656F31-BD0B-43C0-A56D-D8F052E71AAC@xs4all.nl>


On 09-10-2013, at 13:50, Ronald Peterson <ron at hub.yellowbank.com> wrote:

> Hi,
> 
> New to R here.  Lots of fun.  Still rather green though.
> 
> I'd like to select unique items from a list that looks like this (for
> example):
> 
>> xyz
> $x
> [1] 8 6 9 0 0 3 9 7 1 9
> $y
> [1] 1 2 9 5 1 2 0 9 2 9
> $z
> [1] 5 6 9 0 5 1 1 7 3 4
> 
> I'd like to select unique (x,y), while preserving association with z
> values.  When there are duplicate (x,y) pairs, it doesn't really matter
> which (x,y,z) triplet gets preserved - selecting the first would be fine,
> but any other way to do it would be fine also.  It /would/ be handy to also
> get a list of the rejected triplets, if that's possible.  Ideas?

You could try this

A <- cbind(xyz[[1]],xyz[[2]])
A

indx <- which(duplicated(A))
indx

lapply(xyz,function(u) u[-indx])
lapply(xyz,function(u) u[indx])


Berend


From walt at dataanalyticscorp.com  Wed Oct  9 14:11:10 2013
From: walt at dataanalyticscorp.com (Data Analytics Corp.)
Date: Wed, 09 Oct 2013 08:11:10 -0400
Subject: [R] Formula documentation
Message-ID: <525547DE.1020900@dataanalyticscorp.com>

Hi,

I recall that the form for an R formula statement has a formal name and 
a reference, perhaps in the computer science area.  I'm referring to a 
statement such as Y ~ x1 + x2 + x3.  Does anyone know the name for this 
form and where it came from?  I would like to use this in a presentation 
I'm planning.

Thanks,

Walt

________________________

Walter R. Paczkowski, Ph.D.
Data Analytics Corp.
44 Hamilton Lane
Plainsboro, NJ 08536
________________________
(V) 609-936-8999
(F) 609-936-3733
walt at dataanalyticscorp.com
www.dataanalyticscorp.com


From B.Ward at uea.ac.uk  Wed Oct  9 15:53:16 2013
From: B.Ward at uea.ac.uk (Benjamin Ward (ENV))
Date: Wed, 9 Oct 2013 13:53:16 +0000
Subject: [R] Small p from binomial probability function.
Message-ID: <142413609C0A60488585AB47438ECD9D015BE871@ueastfexch01.UEA.AC.UK>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/960c5384/attachment.pl>

From valentina.lauria at nuigalway.ie  Wed Oct  9 16:40:15 2013
From: valentina.lauria at nuigalway.ie (Lauria, Valentina)
Date: Wed, 9 Oct 2013 14:40:15 +0000
Subject: [R] habitat mapping of sharks
Message-ID: <B11DE93D7F439D4BA1E942572BA750308BC5C931@UDSMBX02.uds.nuigalway.ie>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/1209962f/attachment.pl>

From ryan.r.morrison at me.com  Wed Oct  9 19:20:14 2013
From: ryan.r.morrison at me.com (Ryan Morrison)
Date: Wed, 09 Oct 2013 11:20:14 -0600
Subject: [R] Using "cpquery" function from bnlearn package inside loop
Message-ID: <FC83770D-B396-4FE8-9E30-7506E14A9ACB@me.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/5ac281cc/attachment.pl>

From cef24 at pitt.edu  Wed Oct  9 19:20:55 2013
From: cef24 at pitt.edu (cf2059)
Date: Wed, 9 Oct 2013 10:20:55 -0700 (PDT)
Subject: [R] frailtypack
In-Reply-To: <525569D6.2000404@mayo.edu>
References: <1282061687542-2328606.post@n4.nabble.com>
	<525569D6.2000404@mayo.edu>
Message-ID: <1381339255578-4677907.post@n4.nabble.com>

Thank you very much for responding.  Yes, I incorrectly stated that
frailtypack was the only widely available software for the analysis of
nested frailty models.    When I initially began my search to identify
software well suited to nested frailty analysis, Frailtypack dominated the
google results.  While this package seems to be widely publicized on the
internet, I have not thus far found it to be well suited to analysis with my
large dataset.

I would like to use coxme to analyze my data, as it appears to have far
fewer idiosyncrasies than Frailtypack. However, at the moment I am
struggling to 1) achieve model convergence with even a basic shared frailty
model and 2) produce the correct code for the nested frailty model.   My
dataset involves recurrent events clustered within individuals (ID) and
individuals then clustered within groups of three (GroupNum). One
independent variable (Alcohol) varies by group and another (Gender) varies
by individual.  I ultimately aim to produce a nested frailty model that
includes one random intercept variance term at the level of the individual
and one at the level of the group.  I have already produced results for a
basic shared frailty model using SAS NLMIXED--a model that accounts for
clustering only at the level of the Group using group-level predictors
(Alcohol)--but so far I have not been able to achieve convergence for this
same model using coxme. I suspect that supplying the program with starting
values might be useful, but I am not familiar enough with the program code
to do so. Any suggestions would be very much appreciated. I am new to
survival analysis as well as the R software program.

##Basic Shared Frailty Model
> cgd.nfm <- coxme(Surv(Duration, Censoring) ~ Alcohol + (1 | ID),
> data=mydata)
> summary(cgd.nfm)
                 Length Class           Mode    
coefficients         1  -none-          numeric 
frail                1  -none-          list    
penalty              1  -none-          numeric 
loglik               3  -none-          numeric 
variance             1  bdsmatrix       S4      
df                   2  -none-          numeric 
hmat                 1  gchol.bdsmatrix S4      
iter                 2  -none-          numeric 
control              9  -none-          list    
u                  709  -none-          numeric 
means                1  -none-          numeric 
scale                1  -none-          numeric 
linear.predictor 15831  -none-          numeric 
vcoef                1  -none-          list    
n                    2  -none-          numeric 
terms                3  terms           call    
formulaList          2  -none-          list    
y                31662  Surv            numeric 
call                 3  -none-          call    
ties                 1  -none-          character
 
Nested Frailty Model 
> cgd.nfm <- coxme(Surv(Duration, Censoring) ~ Alcohol*Gender + (1 |
> GroupNum/ID), data=mydata)
> summary(cgd.nfm)
                 Length Class           Mode    
coefficients         1  -none-          numeric 
frail                2  -none-          list    
penalty              1  -none-          numeric 
loglik               3  -none-          numeric 
variance             1  bdsmatrix       S4      
df                   2  -none-          numeric 
hmat                 1  gchol.bdsmatrix S4      
iter                 2  -none-          numeric 
control              9  -none-          list    
u                  947  -none-          numeric 
means                1  -none-          numeric 
scale                1  -none-          numeric 
linear.predictor 15831  -none-          numeric 
vcoef                2  -none-          list    
n                    2  -none-          numeric 
terms                3  terms           call    
formulaList          2  -none-          list    
y                31662  Surv            numeric 
call                 3  -none-          call    
ties                 1  -none-          character

Terry Therneau-2 wrote
> I can't comment on frailtypack issues, but would like to mention that
> coxme will handle 
> nested models, contrary to the statement below that "frailtypack is
> perhaps the only .... 
> for nested survival data".
> To reprise the original post's model
> 
>     cgd.nfm <- coxme(Surv(Tstart, Tstop, Status) ~ Treatment + (1 |
> Center/ID), data=cgd.ag)
> 
> 
> And a note to the poster-- you should reprise the original message to
> which you are 
> responding.
> 
> 
> Terry Therneau
> 
> On 10/09/2013 05:00 AM, 

> r-help-request@

>  wrote:
>> Hello,
>>
>> I am encountering very similar problems with frailtypack (only, it seems,
>> 3
>> years later).  I would be incredibly grateful if you would be willing to
>> share any solutions you happened upon for the problem you mention. I have
>> a
>> datafile that is even longer than yours (over 15000 events). Events
>> follow a
>> two-level nesting structure. When I attempt to run the nested survival
>> model
>> in frailtypack the program either stops running entirely or produces an
>> error message. I have contacted the frailtypack maintainer but have not
>> yet
>> received a response.  It seems that frailtypack is perhaps the only
>> widely-available platform for the analysis of nested survival data, so
>> the
>> seeming bugginess of this program is troubling.  Please let me know if
>> you
>> ended up coming up with a solution to your problem or, alternatively,
>> another program able to run the nested analysis. Thank you so much!
>>
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/frailtypack-tp2328606p4677907.html
Sent from the R help mailing list archive at Nabble.com.


From ron at hub.yellowbank.com  Wed Oct  9 19:52:51 2013
From: ron at hub.yellowbank.com (Ronald Peterson)
Date: Wed, 9 Oct 2013 13:52:51 -0400
Subject: [R] select unique by multiple values
In-Reply-To: <1381326967.74914.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1381326967.74914.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CAJPRK8Zb8pTO9u1dbB5iZZcRMnfOA3+-mQjw08Br7ZnNx-avcQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/7f1e5fbe/attachment.pl>

From ron at hub.yellowbank.com  Wed Oct  9 21:06:29 2013
From: ron at hub.yellowbank.com (Ronald Peterson)
Date: Wed, 9 Oct 2013 15:06:29 -0400
Subject: [R] select unique by multiple values
In-Reply-To: <48656F31-BD0B-43C0-A56D-D8F052E71AAC@xs4all.nl>
References: <CAJPRK8ap3s6bKuh3GXmpuY02hXvK+3hPiwzRjHaMNVJ2mxEc9Q@mail.gmail.com>
	<48656F31-BD0B-43C0-A56D-D8F052E71AAC@xs4all.nl>
Message-ID: <CAJPRK8bwffRyaA4hVYJ8SB49Me3RNf6j--Qs2sjEDSwjusuyhQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/3f8cf4b1/attachment.pl>

From ryan.r.morrison at me.com  Wed Oct  9 22:26:14 2013
From: ryan.r.morrison at me.com (Ryan Morrison)
Date: Wed, 09 Oct 2013 14:26:14 -0600
Subject: [R] Using "cpquery" function from bnlearn package inside loop
Message-ID: <923FD3C9-1010-4CFB-800F-624A5621E457@me.com>

Hi everyone, 

I'm attempting to use the bnlearn package to calculate conditional probabilities, and I'm running into a problem when the "cpquery" function is used within a loop. I've created an example, shown below, using data included with the package. When using the cpquery function in a loop, a variable created in the loop ("evi" in the example) is not recognized by the function. I receive the error: 

Error in parse(text = evi) : object 'evi' not found 

The creation steps of "evi" are based on examples provided by the author. 

Any help you could provide would be great. I'm eager to find a way that I can apply the cpquery function for a large number of observations. 

library(bnlearn) 
data(learning.test) 
fitted = bn.fit(hc(learning.test), learning.test) 

bn.function <- function(network, evidence_data) { 
  a <- NULL 
  b <- nrow(evidence_data) 
  for (i in 1:b) { 
    evi <- paste("(", names(evidence_data), "=='", 
               sapply(evidence_data[i,], as.character), "')", 
               sep = "", collapse = " & ") 
    a[i] <- cpquery(network, (C=='c'), eval(parse(text=evi))) 
  } 
  return(a) 
} 

test <- bn.function(fitted, learning.test) 

Thanks for your help!

From gunter.berton at gene.com  Wed Oct  9 22:43:39 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 9 Oct 2013 13:43:39 -0700
Subject: [R] select unique by multiple values
In-Reply-To: <48656F31-BD0B-43C0-A56D-D8F052E71AAC@xs4all.nl>
References: <CAJPRK8ap3s6bKuh3GXmpuY02hXvK+3hPiwzRjHaMNVJ2mxEc9Q@mail.gmail.com>
	<48656F31-BD0B-43C0-A56D-D8F052E71AAC@xs4all.nl>
Message-ID: <CACk-te1RqkzaahO+wy1WZzg1B-uj2BMBiRDqmvXvPCSqvTbwKg@mail.gmail.com>

On Wed, Oct 9, 2013 at 11:49 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>
> On 09-10-2013, at 13:50, Ronald Peterson <ron at hub.yellowbank.com> wrote:
>
>> Hi,
>>
>> New to R here.  Lots of fun.  Still rather green though.
>>
>> I'd like to select unique items from a list that looks like this (for
>> example):
>>
>>> xyz
>> $x
>> [1] 8 6 9 0 0 3 9 7 1 9
>> $y
>> [1] 1 2 9 5 1 2 0 9 2 9
>> $z
>> [1] 5 6 9 0 5 1 1 7 3 4
>>
>> I'd like to select unique (x,y), while preserving association with z
>> values.  When there are duplicate (x,y) pairs, it doesn't really matter
>> which (x,y,z) triplet gets preserved - selecting the first would be fine,
>> but any other way to do it would be fine also.  It /would/ be handy to also
>> get a list of the rejected triplets, if that's possible.  Ideas?
>
> You could try this
>
> A <- cbind(xyz[[1]],xyz[[2]])
> A
>
> indx <- which(duplicated(A))
> indx
>
> lapply(xyz,function(u) u[-indx])
> lapply(xyz,function(u) u[indx])

or even

indx <- duplicated(A))
lapply(xyz,function(u) u[!indx])
lapply(xyz,function(u) u[indx])

Fear not logical indexing!

;-)

-- Bert

>
>
> Berend
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From murdoch.duncan at gmail.com  Wed Oct  9 22:52:53 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 09 Oct 2013 16:52:53 -0400
Subject: [R] Formula documentation
In-Reply-To: <525547DE.1020900@dataanalyticscorp.com>
References: <525547DE.1020900@dataanalyticscorp.com>
Message-ID: <5255C225.3050801@gmail.com>

On 13-10-09 8:11 AM, Data Analytics Corp. wrote:
> Hi,
>
> I recall that the form for an R formula statement has a formal name and
> a reference, perhaps in the computer science area.  I'm referring to a
> statement such as Y ~ x1 + x2 + x3.  Does anyone know the name for this
> form and where it came from?  I would like to use this in a presentation
> I'm planning.

Do you mean the reference given in the ?formula help page?

Duncan Murdoch

>
> Thanks,
>
> Walt
>
> ________________________
>
> Walter R. Paczkowski, Ph.D.
> Data Analytics Corp.
> 44 Hamilton Lane
> Plainsboro, NJ 08536
> ________________________
> (V) 609-936-8999
> (F) 609-936-3733
> walt at dataanalyticscorp.com
> www.dataanalyticscorp.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Wed Oct  9 22:56:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Oct 2013 13:56:16 -0700 (PDT)
Subject: [R] Add function to each row excluding certain columns
Message-ID: <1381352176.52518.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
example1<- as.matrix(read.table("example1.txt",header=TRUE,stringsAsFactors=FALSE,sep="\t",row.names=1,check.names=FALSE))
example2 <- example1 
example1New <- cbind(example1, `MAX without Restriction`=apply(example1[,1:4],1,max,na.rm=TRUE))
#or
library(matrixStats)
`MAX without Restriction`<- rowMaxs(example2[ ,colnames(example2)[!grepl("Restriction", colnames(example2))]],na.rm=TRUE)
?example2New <- cbind(example2, `MAX without Restriction`)
?identical(example1New,example2New)
#[1] TRUE


A.K.


Hello 

I've got a matrix of the following form 

? ? ? ? BARN	BCGE	BCVN	BEAN	Restriction 1	Restriction 2	Restriction 3	Restriction 4	Restriction 5 
alpha.1	0.000172449	7.87E-05	-0.003271044	0.000921609	9.28E-19	2.00E-05	-0.000608211	NA	NA 
alpha.2	0.000896744	0.000579453	-0.000623357	0.001260358	-1.36E-19	-5.22E-05	NA	NA	NA 
alpha.3	0.000832748	0.00076229	0.002170229	0.001159895	3.09E-19	-7.86E-05	NA	NA	NA 
alpha.4	0.000920545	NA	0.001680433	0.000459149	-3.08E-19	-3.59E-05	NA	NA	NA 
alpha.5	0.001385238	0.000527484	0.000593311	0.000549358	7.72E-19	-6.99E-05	NA	NA	NA 
alpha.6	0.000644262	0.000305714	-0.00044514	0.000407448	-9.68E-20	-5.56E-05	NA	NA	NA 
alpha.7	-0.00022808	-0.00017047	0.000109545	0.000601197	0	3.50E-05	NA	NA	NA 
alpha.8	-1.16E-05	-0.000105657	0.001403036	0.00058719	3.88E-19	8.64E-06	NA	NA	NA 
alpha.9	0.000633559	-4.33E-05	0.000724611	0.000841646	-4.82E-20	-3.29E-05	NA	NA	NA 

(see also file) 


Now I'd like to calculate the maximal value of each row, but
 exclude Restriction 1-5. An add a new column to the given matrix with 
the name 'MAX without Restriction' and the max of each row. 

I tried 

max<-apply(example1,1,function(x)max(x)) 
new<-cbind(example,max) 


but it gave a strange output, also I couldn't manage to exclude the columns Restriction 1-5. 

Thank you for your help!! 



From l_rohner at gmx.ch  Wed Oct  9 23:18:43 2013
From: l_rohner at gmx.ch (laro)
Date: Wed, 9 Oct 2013 14:18:43 -0700 (PDT)
Subject: [R] Add function to each row excluding certain columns
In-Reply-To: <1381352176.52518.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1381350376862-4677914.post@n4.nabble.com>
	<1381352176.52518.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1381353523739-4677926.post@n4.nabble.com>

Thank you for the fast answer!

Is there any way to use the first solution way, but work with the column
names instead of the number of the column. Because in further calculation I
need to drop more columns than just the restriction ones and the real
dataset has to many columns to work with the position of the column.

Kind regards



--
View this message in context: http://r.789695.n4.nabble.com/Add-function-to-each-row-excluding-certain-columns-tp4677914p4677926.html
Sent from the R help mailing list archive at Nabble.com.


From rstirnemann at gmail.com  Wed Oct  9 23:35:23 2013
From: rstirnemann at gmail.com (Rebecca Stirnemann)
Date: Thu, 10 Oct 2013 10:35:23 +1300
Subject: [R] Help required graphing factors with predicted model settings
Message-ID: <CACBnbk4Ur4sdLSqar34o9ZEazq4JFhSkSCoBgPCku+zrs_h-pw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/7d00cea6/attachment.pl>

From smartpink111 at yahoo.com  Wed Oct  9 23:57:12 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Oct 2013 14:57:12 -0700 (PDT)
Subject: [R] Add function to each row excluding certain columns
In-Reply-To: <1381352176.52518.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1381352176.52518.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1381355832.54442.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
No problem.
It depends upon how many columns you want to delete, or if they have any common names as in "Restriction"

example1<- as.matrix(read.table("example1.txt",header=TRUE,stringsAsFactors=FALSE,sep="\t",row.names=1,check.names=FALSE))
indx<- which(!grepl("Restriction", colnames(example1))) 

indx
#[1] 1 2 3 4
# Changing names of some of the columns
colnames(example1)[8:9] <- paste("CARP", 1:2)

colnames(example1)
#[1] "BARN"????????? "BCGE"????????? "BCVN"????????? "BEAN"???????? 
#[5] "Restriction 1" "Restriction 2" "Restriction 3" "CARP 1"?????? 
#[9] "CARP 2"??? 

#Using the previous code:
indx<- which(!grepl("Restriction", colnames(example1))) 
?indx
#[1] 1 2 3 4 8 9


#Remove both "Restriction" and "CARP" columns
?indxNew <- which(!grepl("Restriction|CARP", colnames(example1)))
?indxNew
#[1] 1 2 3 4


example1New <- cbind(example1,`MAX without Restriction`=apply(example1[,indxNew],1,max,na.rm=TRUE))

#If there is any specific pattern that is followed for the removal process, you should mention.
#For example, removing every 3rd column or so:
indx2<- colnames(example1)[(((seq_len(ncol(example1))-1)%%3)+1)!=3]
indx2
#[1] "BARN"????????? "BCGE"????????? "BEAN"????????? "Restriction 1"
#[5] "Restriction 3" "CARP 1"????

apply(example1[,indx2],1,max,na.rm=TRUE)



A.K.





Thank you for the fast answer! 

Is there any way to use the first solution way, but work with 
the column names instead of the number of the column. Because in further
 calculation I need to drop more columns than just the restriction ones 
and the real dataset has to many columns to work with the position of 
the column. 

Kind regards 
----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, October 9, 2013 4:56 PM
Subject: Re: Add function to each row excluding certain columns

Hi,
Try:
example1<- as.matrix(read.table("example1.txt",header=TRUE,stringsAsFactors=FALSE,sep="\t",row.names=1,check.names=FALSE))
example2 <- example1 
example1New <- cbind(example1, `MAX without Restriction`=apply(example1[,1:4],1,max,na.rm=TRUE))
#or
library(matrixStats)
`MAX without Restriction`<- rowMaxs(example2[ ,colnames(example2)[!grepl("Restriction", colnames(example2))]],na.rm=TRUE)
?example2New <- cbind(example2, `MAX without Restriction`)
?identical(example1New,example2New)
#[1] TRUE


A.K.


Hello 

I've got a matrix of the following form 

? ? ? ? BARN??? BCGE??? BCVN??? BEAN??? Restriction 1??? Restriction 2??? Restriction 3??? Restriction 4??? Restriction 5 
alpha.1??? 0.000172449??? 7.87E-05??? -0.003271044??? 0.000921609??? 9.28E-19??? 2.00E-05??? -0.000608211??? NA??? NA 
alpha.2??? 0.000896744??? 0.000579453??? -0.000623357??? 0.001260358??? -1.36E-19??? -5.22E-05??? NA??? NA??? NA 
alpha.3??? 0.000832748??? 0.00076229??? 0.002170229??? 0.001159895??? 3.09E-19??? -7.86E-05??? NA??? NA??? NA 
alpha.4??? 0.000920545??? NA??? 0.001680433??? 0.000459149??? -3.08E-19??? -3.59E-05??? NA??? NA??? NA 
alpha.5??? 0.001385238??? 0.000527484??? 0.000593311??? 0.000549358??? 7.72E-19??? -6.99E-05??? NA??? NA??? NA 
alpha.6??? 0.000644262??? 0.000305714??? -0.00044514??? 0.000407448??? -9.68E-20??? -5.56E-05??? NA??? NA??? NA 
alpha.7??? -0.00022808??? -0.00017047??? 0.000109545??? 0.000601197??? 0??? 3.50E-05??? NA??? NA??? NA 
alpha.8??? -1.16E-05??? -0.000105657??? 0.001403036??? 0.00058719??? 3.88E-19??? 8.64E-06??? NA??? NA??? NA 
alpha.9??? 0.000633559??? -4.33E-05??? 0.000724611??? 0.000841646??? -4.82E-20??? -3.29E-05??? NA??? NA??? NA 

(see also file) 


Now I'd like to calculate the maximal value of each row, but
exclude Restriction 1-5. An add a new column to the given matrix with 
the name 'MAX without Restriction' and the max of each row. 

I tried 

max<-apply(example1,1,function(x)max(x)) 
new<-cbind(example,max) 


but it gave a strange output, also I couldn't manage to exclude the columns Restriction 1-5. 

Thank you for your help!! 



From l_rohner at gmx.ch  Wed Oct  9 22:26:16 2013
From: l_rohner at gmx.ch (laro)
Date: Wed, 9 Oct 2013 13:26:16 -0700 (PDT)
Subject: [R] Add function to each row excluding certain columns
Message-ID: <1381350376862-4677914.post@n4.nabble.com>

Hello

I've got a matrix of the following form

	BARN	BCGE	BCVN	BEAN	Restriction 1	Restriction 2	Restriction 3	Restriction 4
Restriction 5
alpha.1	0.000172449	7.87E-05	-0.003271044	0.000921609	9.28E-19	2.00E-05
-0.000608211	NA	NA
alpha.2	0.000896744	0.000579453	-0.000623357	0.001260358	-1.36E-19	-5.22E-05
NA	NA	NA
alpha.3	0.000832748	0.00076229	0.002170229	0.001159895	3.09E-19	-7.86E-05	NA
NA	NA
alpha.4	0.000920545	NA	0.001680433	0.000459149	-3.08E-19	-3.59E-05	NA	NA	NA
alpha.5	0.001385238	0.000527484	0.000593311	0.000549358	7.72E-19	-6.99E-05
NA	NA	NA
alpha.6	0.000644262	0.000305714	-0.00044514	0.000407448	-9.68E-20	-5.56E-05
NA	NA	NA
alpha.7	-0.00022808	-0.00017047	0.000109545	0.000601197	0	3.50E-05	NA	NA	NA
alpha.8	-1.16E-05	-0.000105657	0.001403036	0.00058719	3.88E-19	8.64E-06	NA
NA	NA
alpha.9	0.000633559	-4.33E-05	0.000724611	0.000841646	-4.82E-20	-3.29E-05	NA
NA	NA

(see also file)


Now I'd like to calculate the maximal value of each row, but exclude
Restriction 1-5. An add a new column to the given matrix with the name 'MAX
without Restriction' and the mean of each row.

I tried 

max<-apply(example1,1,function(x)max(x))
new<-cbind(example,max)


but it gave a strange output, also I couldn't manage to exclude the columns
Restriction 1-5.

Thank you for your help!!

example1.txt <http://r.789695.n4.nabble.com/file/n4677914/example1.txt>  




--
View this message in context: http://r.789695.n4.nabble.com/Add-function-to-each-row-excluding-certain-columns-tp4677914.html
Sent from the R help mailing list archive at Nabble.com.


From l_rohner at gmx.ch  Thu Oct 10 00:31:52 2013
From: l_rohner at gmx.ch (laro)
Date: Wed, 9 Oct 2013 15:31:52 -0700 (PDT)
Subject: [R] Add function to each row excluding certain columns
In-Reply-To: <1381355832.54442.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1381350376862-4677914.post@n4.nabble.com>
	<1381352176.52518.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1381355832.54442.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1381357912235-4677934.post@n4.nabble.com>

Thank you again! But somehow the which(function) didn't work...
The problem is, that the columns I want to drop in further calculations will
not have the same name, that's why I'm looking for a solution to make a
vector of the columns that should be omitted, like

omit<-c("Restriction 1","Restriction 2")

and then simple add the function max to the rows, withour the listed columns
in omit (I know this doesn't work, but something like this)

example1New <- cbind(example1, `MAX without
Restriction`=apply(example1[,-omit],1,max,na.rm=TRUE))

Is there any way?

Kind regards



--
View this message in context: http://r.789695.n4.nabble.com/Add-function-to-each-row-excluding-certain-columns-tp4677914p4677934.html
Sent from the R help mailing list archive at Nabble.com.


From gybrg at leeds.ac.uk  Thu Oct 10 00:39:14 2013
From: gybrg at leeds.ac.uk (Benjamin Gillespie)
Date: Wed, 9 Oct 2013 23:39:14 +0100
Subject: [R] Possible loop/ if statement query
Message-ID: <894643FDEA3A854A89B3E828737E2B1F016520962902@HERMES8.ds.leeds.ac.uk>

Dear r genii,

I hope you can help.

I have vector 'b':

b=c((1:10),sort(1:9,decreasing=TRUE),(2:12),sort(6:11,decreasing=TRUE),(7:13))

and, from 'b' I wish to create vector 'c':

c=c(	NA,NA,NA,NA,NA,NA,1,1,1,1,1,1,1,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2,2,2,2,2,2,2,2,2,2,2,NA,3,3,3,3,3,3,3)

The rules I want to use to create 'c' are:

A numeric of equal to, or over 7 in 'b' needs to result in a numeric (i.e. not NA) in 'c';
A numeric of less than 7 in 'b' needs to result in "NA" in 'c';
Where 'groups' of numerics equal to, or over 7 in 'b' are present (i.e. next to each other in the list), the numerics produced in 'c' all need to be the same;
Each 'group' of numerics in 'b' must result in a unique numeric  in 'c' (and, ideally, they should run in sequence as in 'c' above (1,2,3...).

If anyone has any idea where to start on this or can crack it I'll be most grateful!!

Many thanks in advance, 

Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o

From dwinsemius at comcast.net  Thu Oct 10 00:52:29 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 9 Oct 2013 15:52:29 -0700
Subject: [R] Add function to each row excluding certain columns
In-Reply-To: <1381357912235-4677934.post@n4.nabble.com>
References: <1381350376862-4677914.post@n4.nabble.com>
	<1381352176.52518.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1381355832.54442.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1381357912235-4677934.post@n4.nabble.com>
Message-ID: <EB75003F-200A-420B-955F-05C6F230B785@comcast.net>


On Oct 9, 2013, at 3:31 PM, laro wrote:

> Thank you again! But somehow the which(function) didn't work...
> The problem is, that the columns I want to drop in further calculations will
> not have the same name, that's why I'm looking for a solution to make a
> vector of the columns that should be omitted, like
> 
> omit<-c("Restriction 1","Restriction 2")
> 
> and then simple add the function max to the rows, withour the listed columns
> in omit (I know this doesn't work, but something like this)
> 
> example1New <- cbind(example1, `MAX without
> Restriction`=apply(example1[,-omit],1,max,na.rm=TRUE))

The "-" operator does not succeed in de-selecting named columns when using the"[" function:

Try instead:

example1New <- cbind(example1,
                     `MAX withoutRestriction` =
                          apply(example1[, ! names(example) %in% omit], 1, max,na.rm=TRUE))

The other alternative (to exclude all columns with "Restriction" in their names would be:

   ...(  example1[, -grep("Restriction", names(example) ) ]

Or:

   subset(example, select = -omit)


I think you should abandon the back-tick tricks you are using to preserve spaces in dataframe or matrix column names. I think they will cause problems for you in the future.

> 
> Is there any way?
> 
> Kind regards
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Add-function-to-each-row-excluding-certain-columns-tp4677914p4677934.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Thu Oct 10 01:01:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Oct 2013 16:01:24 -0700 (PDT)
Subject: [R] Add function to each row excluding certain columns
In-Reply-To: <1381355832.54442.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1381352176.52518.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1381355832.54442.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1381359684.70086.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
!colnames(example1)%in%omit
#[1]? TRUE? TRUE? TRUE? TRUE FALSE FALSE? TRUE? TRUE? TRUE


?cbind(example1, `MAX without Restriction`=apply(example1[,!colnames(example1)%in% omit],1,max,na.rm=TRUE)) 
A.K.


Thank you again! But somehow the which(function) didn't work... 
The problem is, that the columns I want to drop in further 
calculations will not have the same name, that's why I'm looking for a 
solution to make a vector of the columns that should be omitted, like 

omit<-c("Restriction 1","Restriction 2") 

and then simple add the function max to the rows, withour the 
listed columns in omit (I know this doesn't work, but something like 
this) 

example1New <- cbind(example1, `MAX without Restriction`=apply(example1[,-omit],1,max,na.rm=TRUE)) 

Is there any way? 

Kind regards 
----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, October 9, 2013 5:57 PM
Subject: Re: Add function to each row excluding certain columns

Hi,
No problem.
It depends upon how many columns you want to delete, or if they have any common names as in "Restriction"

example1<- as.matrix(read.table("example1.txt",header=TRUE,stringsAsFactors=FALSE,sep="\t",row.names=1,check.names=FALSE))
indx<- which(!grepl("Restriction", colnames(example1))) 

indx
#[1] 1 2 3 4
# Changing names of some of the columns
colnames(example1)[8:9] <- paste("CARP", 1:2)

colnames(example1)
#[1] "BARN"????????? "BCGE"????????? "BCVN"????????? "BEAN"???????? 
#[5] "Restriction 1" "Restriction 2" "Restriction 3" "CARP 1"?????? 
#[9] "CARP 2"??? 

#Using the previous code:
indx<- which(!grepl("Restriction", colnames(example1))) 
?indx
#[1] 1 2 3 4 8 9


#Remove both "Restriction" and "CARP" columns
?indxNew <- which(!grepl("Restriction|CARP", colnames(example1)))
?indxNew
#[1] 1 2 3 4


example1New <- cbind(example1,`MAX without Restriction`=apply(example1[,indxNew],1,max,na.rm=TRUE))

#If there is any specific pattern that is followed for the removal process, you should mention.
#For example, removing every 3rd column or so:
indx2<- colnames(example1)[(((seq_len(ncol(example1))-1)%%3)+1)!=3]
indx2
#[1] "BARN"????????? "BCGE"????????? "BEAN"????????? "Restriction 1"
#[5] "Restriction 3" "CARP 1"????

apply(example1[,indx2],1,max,na.rm=TRUE)



A.K.





Thank you for the fast answer! 

Is there any way to use the first solution way, but work with 
the column names instead of the number of the column. Because in further
calculation I need to drop more columns than just the restriction ones 
and the real dataset has to many columns to work with the position of 
the column. 

Kind regards 
----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 

Sent: Wednesday, October 9, 2013 4:56 PM
Subject: Re: Add function to each row excluding certain columns

Hi,
Try:
example1<- as.matrix(read.table("example1.txt",header=TRUE,stringsAsFactors=FALSE,sep="\t",row.names=1,check.names=FALSE))
example2 <- example1 
example1New <- cbind(example1, `MAX without Restriction`=apply(example1[,1:4],1,max,na.rm=TRUE))
#or
library(matrixStats)
`MAX without Restriction`<- rowMaxs(example2[ ,colnames(example2)[!grepl("Restriction", colnames(example2))]],na.rm=TRUE)
?example2New <- cbind(example2, `MAX without Restriction`)
?identical(example1New,example2New)
#[1] TRUE


A.K.


Hello 

I've got a matrix of the following form 

? ? ? ? BARN??? BCGE??? BCVN??? BEAN??? Restriction 1??? Restriction 2??? Restriction 3??? Restriction 4??? Restriction 5 
alpha.1??? 0.000172449??? 7.87E-05??? -0.003271044??? 0.000921609??? 9.28E-19??? 2.00E-05??? -0.000608211??? NA??? NA 
alpha.2??? 0.000896744??? 0.000579453??? -0.000623357??? 0.001260358??? -1.36E-19??? -5.22E-05??? NA??? NA??? NA 
alpha.3??? 0.000832748??? 0.00076229??? 0.002170229??? 0.001159895??? 3.09E-19??? -7.86E-05??? NA??? NA??? NA 
alpha.4??? 0.000920545??? NA??? 0.001680433??? 0.000459149??? -3.08E-19??? -3.59E-05??? NA??? NA??? NA 
alpha.5??? 0.001385238??? 0.000527484??? 0.000593311??? 0.000549358??? 7.72E-19??? -6.99E-05??? NA??? NA??? NA 
alpha.6??? 0.000644262??? 0.000305714??? -0.00044514??? 0.000407448??? -9.68E-20??? -5.56E-05??? NA??? NA??? NA 
alpha.7??? -0.00022808??? -0.00017047??? 0.000109545??? 0.000601197??? 0??? 3.50E-05??? NA??? NA??? NA 
alpha.8??? -1.16E-05??? -0.000105657??? 0.001403036??? 0.00058719??? 3.88E-19??? 8.64E-06??? NA??? NA??? NA 
alpha.9??? 0.000633559??? -4.33E-05??? 0.000724611??? 0.000841646??? -4.82E-20??? -3.29E-05??? NA??? NA??? NA 

(see also file) 


Now I'd like to calculate the maximal value of each row, but
exclude Restriction 1-5. An add a new column to the given matrix with 
the name 'MAX without Restriction' and the max of each row. 

I tried 

max<-apply(example1,1,function(x)max(x)) 
new<-cbind(example,max) 


but it gave a strange output, also I couldn't manage to exclude the columns Restriction 1-5. 

Thank you for your help!! 



From mic.cipi at gmail.com  Thu Oct 10 02:35:52 2013
From: mic.cipi at gmail.com (michele caseposta)
Date: Wed, 9 Oct 2013 20:35:52 -0400
Subject: [R]  Biclustering issues with biclust()
Message-ID: <31FABAD2-E842-4E25-A6DE-3D431A37896C@gmail.com>

Hello everyone,
I am trying to test some biclustering algorithms, and I am using the package biclust.
I tried to bicluster a very simple matrix, and it seems that I cannot obtain what I was expecting, even though the cluster, to me, seem pretty obvious.
The code is the following:

mat1<- matrix(c( 5,1,2,9,2,8,5,10,1,4,
                 1,10,2,2,2,2,1,4,3,8,
                 4,9,3,3,3,3,9,6,0,1,
                 9,6,4,4,4,4,5,4,5,6,
                 2,0,5,5,5,5,1,4,5,6,
                 5,6,3,7,0,3,2,4,5,6,
                 6,4,8,5,4,9,9,4,5,6,
                 7,7,7,7,0,8,2,4,5,6,
                 7,7,7,7,5,8,4,5,2,8,
                 7,7,7,7,9,1,3,8,4,1
), ncol=10)

If you see this matrix, it has a sub matrix of only "7", and two sub matrices with perfectly correlated rows.
It seems to me that every biclustering algorithm should return at least those three clusters, but so far I had no luck.
I tried the BCCC method, the BCPlaid, BCXmotifs, and BCSpectral.
I did not try the BCBimax (it seems that it requires a logical matrix), BCQuest (questionnaires).
None of the used methods was able to retrieve what I was expecting. BCCC performs better than the others, as it finds "something".
The code I used is the following:

resBC  <- biclust(stdm(mat1), method=BCCC(), delta=1*10^-2,alpha=10^-5)
for(i in 1:resBC at Number){
  bcs <- simpleBc(data=mat1,bicResult=resBC, clusterNo=i)
  print(bcs$bcMat)
}

where the function stdm is the following (I read somewhere to use stdize() on the matrix):

> stdm
function(x){
  
  require(pls)
  xs <-stdize(x)
  rowdim <- dim(xs)[1]
  coldim <- dim(xs)[2]
  standardMatrix <- matrix(as.numeric(xs), nrow=rowdim, ncol=coldim)
  rownames(standardMatrix) <- rownames(xs)
  colnames(standardMatrix) <- colnames(xs)
  standardMatrix
}

Without stdm not even BCCC can find anything.

Am I missing something?

Best,
Michele

 

From smartpink111 at yahoo.com  Thu Oct 10 04:24:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 9 Oct 2013 19:24:26 -0700 (PDT)
Subject: [R] Possible loop/ if statement query
In-Reply-To: <1381364394.34823.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <894643FDEA3A854A89B3E828737E2B1F016520962902@HERMES8.ds.leeds.ac.uk>
	<1381364394.34823.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1381371866.95009.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try:
b1<- b

b1[!b1>=7]<- NA

lst1 <- split(b1,cumsum(c(0,abs(diff(b>=7)))))
?indx <- as.logical(((seq_along(lst1)-1)%%2))


lst1[indx]<- lapply(seq_along(lst1[indx]),function(i) {lst1[indx][[i]]<- rep(i,length(lst1[indx][[i]]))})
?C2 <- unlist(lst1,use.names=FALSE)

?all.equal(c1,C2)
#[1] TRUE


A.K.

----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Benjamin Gillespie <gybrg at leeds.ac.uk>
Cc: 
Sent: Wednesday, October 9, 2013 8:19 PM
Subject: Re: [R] Possible loop/ if statement query

Hi,

There should be a simpler way with cumsum(diff()).


b=c((1:10),sort(1:9,decreasing=TRUE),(2:12),sort(6:11,decreasing=TRUE),(7:13))
b1<- b
c1=c( NA,NA,NA,NA,NA,NA,1,1,1,1,1,1,1,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2,2,2,2,2,2,2,2,2,2,2,NA,3,3,3,3,3,3,3) 

?
?rl1<- rle(b1>=7)
?indx1<-(cumsum(rl1$lengths)+1)[!rl1$values]
?indx2<-(cumsum(rl1$lengths))[rl1$values]
b1[!b1>=7] <- NA

?lst1<- split(sort(c(indx1,indx2)),((seq_along(sort(c(indx1,indx2)))-1)%/%2)+1)
mat1<- sapply(seq_along(lst1),function(i) {x<- lst1[[i]];? b1[seq(x[1],x[2])]<- i; b1? })

indx2New<- !is.na(mat1[,2]) & mat1[,2]==2
?indx3New<- !is.na(mat1[,3]) & mat1[,3]==3
?mat1[!is.na(mat1[,1]) & mat1[,1]>3,1] <- c(mat1[,2][indx2New],mat1[,3][indx3New])
?all.equal(c1,mat1[,1])
#[1] TRUE


A.K.





----- Original Message -----
From: Benjamin Gillespie <gybrg at leeds.ac.uk>
To: "r-help at R-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, October 9, 2013 6:39 PM
Subject: [R] Possible loop/ if statement query

Dear r genii,

I hope you can help.

I have vector 'b':

b=c((1:10),sort(1:9,decreasing=TRUE),(2:12),sort(6:11,decreasing=TRUE),(7:13))

and, from 'b' I wish to create vector 'c':

c=c(??? NA,NA,NA,NA,NA,NA,1,1,1,1,1,1,1,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2,2,2,2,2,2,2,2,2,2,2,NA,3,3,3,3,3,3,3)

The rules I want to use to create 'c' are:

A numeric of equal to, or over 7 in 'b' needs to result in a numeric (i.e. not NA) in 'c';
A numeric of less than 7 in 'b' needs to result in "NA" in 'c';
Where 'groups' of numerics equal to, or over 7 in 'b' are present (i.e. next to each other in the list), the numerics produced in 'c' all need to be the same;
Each 'group' of numerics in 'b' must result in a unique numeric? in 'c' (and, ideally, they should run in sequence as in 'c' above (1,2,3...).

If anyone has any idea where to start on this or can crack it I'll be most grateful!!

Many thanks in advance, 

Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jeffrey.flint at gmail.com  Thu Oct 10 04:04:53 2013
From: jeffrey.flint at gmail.com (Jeffrey Flint)
Date: Wed, 9 Oct 2013 19:04:53 -0700
Subject: [R] makeCluster help needed
In-Reply-To: <52470EAA.7090003@statistik.tu-dortmund.de>
References: <CALbUM4MVAXRUGn0gJ8ziRe+HjDC0aRRPE1R9UE4OLnAkVSoDdQ@mail.gmail.com>
	<52470EAA.7090003@statistik.tu-dortmund.de>
Message-ID: <CALbUM4P2xQOWk_EFLCfCefw8oE53+T0eaNohvc5zqvHFuvfkkw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131009/ee4f716c/attachment.pl>

From cs_2002 at hotmail.com  Thu Oct 10 01:43:04 2013
From: cs_2002 at hotmail.com (b. alzahrani)
Date: Thu, 10 Oct 2013 00:43:04 +0100
Subject: [R] AES algorithm package
In-Reply-To: <5255E346.1070505@utoronto.ca>
References: <mailman.2872.1381341944.4612.r-help@r-project.org>
	<DUB126-W18C85E8C4B9C74687F915801D0@phx.gbl>
	<5255E346.1070505@utoronto.ca>
Message-ID: <DUB401-EAS2182B5B3FF64F65461C354B801D0@phx.gbl>

Hi
Is there any implementation for AES encryption algorithm in R?

Thanks

Bander


From darylm at uw.edu  Thu Oct 10 05:36:14 2013
From: darylm at uw.edu (Daryl Morris)
Date: Wed, 09 Oct 2013 20:36:14 -0700
Subject: [R] knitr and functions generating latex
Message-ID: <525620AE.5000109@uw.edu>

Hi,

I have what I think should be a basic question on knitr.  I am just 
moving to knitr, and previously I had created functions which 
automatically created latex wrappers for many (100s) figures.  I also 
have other functions which automatically create pages worth of latex tables.

The knitr method seems to be to write this figure code by hand.

Is there a way to use my pre-existing functions to output latex into the 
.Rnw document?  So far, everything I've tried isn't doing it. (I've been 
modifying the functions to output big strings of latex instead of 
writing files, and trying various methods to print that output into the 
.Rnw file).

It feels like this should be easy... the output of the R-block is latex.


thanks, Daryl


From jim at bitwrit.com.au  Thu Oct 10 06:33:56 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 10 Oct 2013 15:33:56 +1100
Subject: [R] Help required graphing factors with predicted model settings
In-Reply-To: <CACBnbk4Ur4sdLSqar34o9ZEazq4JFhSkSCoBgPCku+zrs_h-pw@mail.gmail.com>
References: <CACBnbk4Ur4sdLSqar34o9ZEazq4JFhSkSCoBgPCku+zrs_h-pw@mail.gmail.com>
Message-ID: <52562E34.6000308@bitwrit.com.au>

On 10/10/2013 08:35 AM, Rebecca Stirnemann wrote:
> Dear R wizards,
>
> Though I hate to do it after weeks of my code not working I need some help
> since I cant find an example which seems to work.
> I am trying to create a graph which show the probability of predation of a
> nest on one side (either 1 to 0) or (0% to 100%) on one side
> and grass height at the bottom. I want to then add my predicted lines from
> my glmr onto the graph for three habitat types.
>
> I would like to repeat this procedure 3 times for three different grass
> heights 25- 50- 100 to see the effect size.
>
> My data:
>     landusenumb landuse sitename rat ground.cover_lo  1  plantation
> far.leftroad_LHS 0 60  1 plantation far.leftroad_LHS 1 70  1 plantation
> far.leftroad_LHS 1 10  1 plantation far.leftroad_LHS 1 30  1 plantation
> far.leftroad_LHS 1 50  1 plantation far.leftroad_LHS 0 20  1 plantation
> far.leftroad_LHS 0 70  1 plantation far.leftroad_LHS 0 100  1 plantation
> far.leftroad_LHS 0 90
>
> #Graph
>
>
> #Fit model
>
> mod1<- glmer(frat ~ flandusenumb + ground.cover_lo + (1|fsite) ,family =
> binomial, data= mao1)
>
>
> #Calculate predicted values
>
> newdata1<- data.frame(ground.cover_lo = seq(0,10,length=100), flandusenumb
> = rep(1,2,3))
>
> pred34<- predict(mod1,newdata=newdata1,type="response")
>
>
>
> #Plot model predicted curves
>
> plot(c(0,100),c(0,1),type="n",xlab="grasscover",ylab="Probability of
> predation")
>
> lines(newdata1$frat,pred34,lwd=3,col="blue")
>
>
Hi Rebecca,
First, your sample data are a bit mangled, and should look like this:

mao1
landusenumb landuse    sitename rat ground.cover_lo
1           plantation far.leftroad_LHS   0      60
1           plantation far.leftroad_LHS   1      70
1           plantation far.leftroad_LHS   1      10
1           plantation far.leftroad_LHS   1      30
1           plantation far.leftroad_LHS   1      50
1           plantation far.leftroad_LHS   0      20
1           plantation far.leftroad_LHS   0      70
1           plantation far.leftroad_LHS   0     100
1           plantation far.leftroad_LHS   0      90

If you want the predicted values with ground cover as above, then:

ground.cover_lo = c(25,50,100)

The variable names in the first model don't match those in the data 
frame, but I assume these were typos. What does "pred34" look like? This 
will tell you what function you should be using to plot it.

Jim


From xie at yihui.name  Thu Oct 10 06:35:39 2013
From: xie at yihui.name (Yihui Xie)
Date: Wed, 9 Oct 2013 23:35:39 -0500
Subject: [R] knitr and functions generating latex
In-Reply-To: <525620AE.5000109@uw.edu>
References: <525620AE.5000109@uw.edu>
Message-ID: <CANROs4dhdvjtxiF4Nu__qWd7D26ovxF+NZQe+5_wbi0-eKHGTw@mail.gmail.com>

I think in most cases you are probably on the wrong track if you have
to generate LaTeX code for figures from R code (LaTeX tables are
another story), but your case might be different. You did not give a
specific example on why you had to do that, so I cannot give any
advice for now.

My best guess is

<<results='asis'>>=
whatever_your_figure_functions_are()
@

So please provide a minimal example, and avoid indefinite descriptions
like "seems" or "feels like" (in particular, "this should be easy"
made me feel my IQ suddenly dropped by 50%).

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Wed, Oct 9, 2013 at 10:36 PM, Daryl Morris <darylm at uw.edu> wrote:
> Hi,
>
> I have what I think should be a basic question on knitr.  I am just moving
> to knitr, and previously I had created functions which automatically created
> latex wrappers for many (100s) figures.  I also have other functions which
> automatically create pages worth of latex tables.
>
> The knitr method seems to be to write this figure code by hand.
>
> Is there a way to use my pre-existing functions to output latex into the
> .Rnw document?  So far, everything I've tried isn't doing it. (I've been
> modifying the functions to output big strings of latex instead of writing
> files, and trying various methods to print that output into the .Rnw file).
>
> It feels like this should be easy... the output of the R-block is latex.
>
>
> thanks, Daryl
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rstirnemann at gmail.com  Thu Oct 10 06:52:59 2013
From: rstirnemann at gmail.com (Rebecca Stirnemann)
Date: Thu, 10 Oct 2013 17:52:59 +1300
Subject: [R] Help required graphing factors with predicted model settings
In-Reply-To: <52562E34.6000308@bitwrit.com.au>
References: <CACBnbk4Ur4sdLSqar34o9ZEazq4JFhSkSCoBgPCku+zrs_h-pw@mail.gmail.com>
	<52562E34.6000308@bitwrit.com.au>
Message-ID: <CACBnbk5A1jkjJ4m8R00PTGbOMbDXLbp2Ju2Hzvge8fd_9w98qg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/71fb6ae5/attachment.pl>

From rstirnemann at gmail.com  Thu Oct 10 06:54:42 2013
From: rstirnemann at gmail.com (Rebecca Stirnemann)
Date: Thu, 10 Oct 2013 17:54:42 +1300
Subject: [R] Help required graphing factors with predicted model settings
In-Reply-To: <CACBnbk5A1jkjJ4m8R00PTGbOMbDXLbp2Ju2Hzvge8fd_9w98qg@mail.gmail.com>
References: <CACBnbk4Ur4sdLSqar34o9ZEazq4JFhSkSCoBgPCku+zrs_h-pw@mail.gmail.com>
	<52562E34.6000308@bitwrit.com.au>
	<CACBnbk5A1jkjJ4m8R00PTGbOMbDXLbp2Ju2Hzvge8fd_9w98qg@mail.gmail.com>
Message-ID: <CACBnbk5v2QuZit7qoCU68MMmQ6tvv_dqbWvvksfmj9TU5r6hXQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/de1dcab5/attachment.pl>

From jim at bitwrit.com.au  Thu Oct 10 07:17:58 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 10 Oct 2013 16:17:58 +1100
Subject: [R] Help required graphing factors with predicted model settings
In-Reply-To: <CACBnbk5A1jkjJ4m8R00PTGbOMbDXLbp2Ju2Hzvge8fd_9w98qg@mail.gmail.com>
References: <CACBnbk4Ur4sdLSqar34o9ZEazq4JFhSkSCoBgPCku+zrs_h-pw@mail.gmail.com>	<52562E34.6000308@bitwrit.com.au>
	<CACBnbk5A1jkjJ4m8R00PTGbOMbDXLbp2Ju2Hzvge8fd_9w98qg@mail.gmail.com>
Message-ID: <52563886.3010807@bitwrit.com.au>

On 10/10/2013 03:52 PM, Rebecca Stirnemann wrote:
> Thanks Jim for helping,
>
> Your sample data actually looks like my dataset. The one I put up looks
> strange for some reason so please ignore that.
> I have three landusenumb variables 1 2 and 3. is rep (1,2,3) correct?
>
> When I run the following code I am getting:
>
>  > mod1 <- glmer(frat ~ flandusenumb + ground.cover_lo + (1|fsite)
> ,family = binomial, data= mao1)
>  >
>  > #Calculate predicted values
>  > newdata1 <- data.frame(ground.cover_lo = c(25,50,100), flandusenumb =
> rep(1,2,3))
>  > pred34 <- predict(mod1,newdata=newdata1,type="response")
>
> Error in UseMethod("predict") :
>    no applicable method for 'predict' applied to an object of class "mer"
>
> Can you see what I am doing wrong?
> What I am aiming for is a graph which looks like this.
>
> Thanks
> Rebecca
>
Okay, so you aren't getting anything to plot. You will have to send your 
plot image directly to me, as R-help scrubs most images from emails.

I assume that "landusenumb" is the occasion of measurement (i.e. you 
have three repeated measurements). Perhaps you could calculate the three 
values from the initial model, remembering that the logarithm of the 
odds of predation is your response.

Jim


From ripley at stats.ox.ac.uk  Thu Oct 10 08:33:32 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Oct 2013 07:33:32 +0100
Subject: [R] iconv question: SQL Server 2005 to R
In-Reply-To: <1381311436.2948.57.camel@milan>
References: <52548F03.2030504@yahoo.com> <1381311436.2948.57.camel@milan>
Message-ID: <52564A3C.6080107@stats.ox.ac.uk>

On 09/10/2013 10:37, Milan Bouchet-Valat wrote:
> Le mardi 08 octobre 2013 ? 16:02 -0700, Ira Sharenow a ?crit :
>> A colleague is sending me quite a few files that have been saved with MS
>> SQL Server 2005. I am using R 2.15.1 on Windows 7.
>>
>> I am trying to read in the files using standard techniques. Although the
>> file has a csv extension when I go to Excel or WordPad and do SAVE AS I
>> see that it is Unicode Text. Notepad indicates that the encoding is
>> Unicode. Right now I have to do a few things from within Excel (such as
>> Text to Columns) and eventually save as a true csv file before I can
>> read it into R and then use it.
>>
>> Is there an easy way to solve this from within R? I am also open to easy
>> SQL Server 2005 solutions.
>>
>> I tried the following from within R.
>>
>> testDF = read.table("Info06.csv", header = TRUE, sep = ",")
>>
>>> testDF2 =  iconv(x = testDF, from = "Unicode", to = "")
>>
>> Error in iconv(x = testDF, from = "Unicode", to = "") :
>>
>> unsupported conversion from 'Unicode' to '' in codepage 1252
>>
>> # The next line did not produce an error message
>>
>>> testDF3 =  iconv(x = testDF, from = "UTF-8" , to = "")
>>
>>> testDF3[1:6,  1:3]
>>
>> Error in testDF3[1:6, 1:3] : incorrect number of dimensions
>>
>> # The next line did not produce an error message
>>
>>> testDF4 =  iconv(x = testDF, from = "macroman" , to = "")
>>
>>> testDF4[1:6,  1:3]
>>
>> Error in testDF4[1:6, 1:3] : incorrect number of dimensions
>>
>>>   Encoding(testDF3)
>>
>> [1] "unknown"
>>
>>>   Encoding(testDF4)
>>
>> [1] "unknown"
>>
>> This is the first few lines from WordPad
>>
>> Date,StockID,Price,MktCap,ADV,SectorID,Days,A1,std1,std2
>>
>> 2006-01-03
>> 00:00:00.000, at Stock1,2.53,467108197.38,567381.144444444,4,133.14486997089,-0.0162107939626307,0.0346283580367959,0.0126471695454834
>>
>> 2006-01-03
>> 00:00:00.000, at Stock2,1.3275,829803070.531114,6134778.93292,5,124.632223896458,0.071513138376339,0.0410694546850102,0.0172091268025929
> What's the actual problem? You did not state any. Do you get accentuated
> characters that are not printed correctly after importing the file? In
> the two lines above it does not look like there would be any non-ASCII
> characters in this file, so encoding would not matter.

It is most likely UCS-2.  That has embedded NULs, so the encoding does 
matter.  All 8-bit encodings extend ASCII: others do not, in general.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From stefanML at collocations.de  Thu Oct 10 10:37:31 2013
From: stefanML at collocations.de (Stefan Evert)
Date: Thu, 10 Oct 2013 10:37:31 +0200
Subject: [R] Small p from binomial probability function.
In-Reply-To: <142413609C0A60488585AB47438ECD9D015BE871@ueastfexch01.UEA.AC.UK>
References: <142413609C0A60488585AB47438ECD9D015BE871@ueastfexch01.UEA.AC.UK>
Message-ID: <45FE3A4B-86AB-49A4-B4E4-05B2479953A8@collocations.de>

Sounds like you want a 95% binomial confidence interval:

	binom.test(N, P)

will compute this for you, and you can get the bounds directly with

	binom.test(N, P)$conf.int

Actually, binom.test computes a two-sided confidence interval, which corresponds roughly to 2.5 and 97.5 percentages in your approach. It doesn't give you the 50% point either, but I don't think that's a meaningful quantity with a two-sided test.

Hope this helps,
Stefan


On 9 Oct 2013, at 15:53, Benjamin Ward (ENV) <B.Ward at uea.ac.uk> wrote:

> I got given some code that uses the R function pbionom:
> 
> p <- mut * t
> sumprobs <- pbinom( N, B, p ) * 1000
> 
> Which gives the output of a probability as a percentage like 5, 50, 95.
> 
> What the code currently does is find me the values of t I need, by using the above two code lines in a loop, each iteration it increaces t by one and runs the two lines. When sumprobs equals 5, it records the value t, then again when sumprobs is equal to 50, and again when sumprobs is equal to 95 - giving me three t values. This is not an efficient way of doing this if t is large. Is it possible to rearrange pbinom so it gives me the small p (made of mut*t) as the result of plugging in the sumprobs instead, and is there an R function that already does this?
> 
> Since pbinom is the binomial probability equation I suppose the question is - in more mathematical terminology - can I change this code so that instead of calculating the Probability of N successes given the number of trials and the probability of a single success, can I instead calculate the probability of a single success using the probability of N successes and number of trials, and the number of successes? Can R do this for me. So instead I plug in 5, 50, and 95, and then get the small p out?


From marco.scutari at gmail.com  Thu Oct 10 11:16:54 2013
From: marco.scutari at gmail.com (Marco Scutari)
Date: Thu, 10 Oct 2013 10:16:54 +0100
Subject: [R] Using "cpquery" function from bnlearn package inside loop
In-Reply-To: <923FD3C9-1010-4CFB-800F-624A5621E457@me.com>
References: <923FD3C9-1010-4CFB-800F-624A5621E457@me.com>
Message-ID: <CA+RJqXVC7inX4UKsy2cR=wLcP60CTDdyOMbCdcYtuR9GOMnN6Q@mail.gmail.com>

Dear Ryan,

On 9 October 2013 21:26, Ryan Morrison <ryan.r.morrison at me.com> wrote:
> I'm attempting to use the bnlearn package to calculate conditional probabilities, and
> I'm running into a problem when the "cpquery" function is used within a loop. I've
> created an example, shown below, using data included with the package. When
> using the cpquery function in a loop, a variable created in the loop ("evi" in the
> example) is not recognized by the function. I receive the error:
>
> Error in parse(text = evi) : object 'evi' not found
[snip]

Based on the second example you emailed me off-list, it appears to be
a scoping problem; that's why the same code works if it's not inside a
function. I will try to debug this soon, but I am not an expert in R
parsing mechanisms so it will take some time. In the mean time, you
can use cpquery(..., method = "lw") instead of the default
cpquery(..., method = "ls") if your query looks like the one in the
example. The former does not rely on unevaluated expressions, but
takes the conditioning values as a list, and it should work
regardless. However, if you do so I suggest you should install the
latest bugfix snapshot from bnlearn.com to avoid a few other bugs in
cpquery(..., method = "lw").

Cheers,
    Marco

-- 
Marco Scutari, Ph.D.
Research Associate, Genetics Institute (UGI)
University College London (UCL), United Kingdom


From vksingh.iiitb at gmail.com  Thu Oct 10 11:21:26 2013
From: vksingh.iiitb at gmail.com (Vivek Singh)
Date: Thu, 10 Oct 2013 17:21:26 +0800
Subject: [R] R function for Bisecting K-means algorithm
In-Reply-To: <CACk-te20Yyu1bA6afZ2+qTcaC931eS88fb2y5ayZMEj6AHuzdg@mail.gmail.com>
References: <CAFgDSD6CXm2fpE55PyW0RmKyACZY6UPAZsFg1UFQistOmELW7Q@mail.gmail.com>
	<CAFgDSD6T2DmMNO5=L9LYGajbm_Rp5Z15=qRKvHAT=f9vNF6xYw@mail.gmail.com>
	<CACk-te20Yyu1bA6afZ2+qTcaC931eS88fb2y5ayZMEj6AHuzdg@mail.gmail.com>
Message-ID: <CAFgDSD7=+pL3+cTF6PfNMy+UvMqJoPW6mhD3Mzxc4UTy-LKbBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/b29d6391/attachment.pl>

From ligges at statistik.tu-dortmund.de  Thu Oct 10 12:18:01 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 10 Oct 2013 12:18:01 +0200
Subject: [R] makeCluster help needed
In-Reply-To: <CALbUM4P2xQOWk_EFLCfCefw8oE53+T0eaNohvc5zqvHFuvfkkw@mail.gmail.com>
References: <CALbUM4MVAXRUGn0gJ8ziRe+HjDC0aRRPE1R9UE4OLnAkVSoDdQ@mail.gmail.com>
	<52470EAA.7090003@statistik.tu-dortmund.de>
	<CALbUM4P2xQOWk_EFLCfCefw8oE53+T0eaNohvc5zqvHFuvfkkw@mail.gmail.com>
Message-ID: <52567ED9.2040405@statistik.tu-dortmund.de>



On 10.10.2013 04:04, Jeffrey Flint wrote:
> Uwe,
>
> Good news. I installed 3.0.2, and the parallel package examples ran
> successfully.  This time a firewall window popped up.  Probably the
> firewall was the problem with the snow package too, but for some reason the
> window didn't pop up with the snow package.

Great new.

>
> Thanks for the suggestion to use "parallel".  I noticed that the package is
> brand new!  Or, at least the pdf help was written 9/25/13.


Not that new, just updated.

Best,
Uwe



> Jeff
>
>
>
>
> On Sat, Sep 28, 2013 at 10:15 AM, Uwe Ligges <
> ligges at statistik.tu-dortmund.de> wrote:
>
>> Can you please upgrade R to R-3.0.2 and use the parallel package?
>> And can you please explain why you want to start the workers manually? I'd
>> be happy to look into the details if you can reproduce the problem with a
>> recent version of R and the parallel package.
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>>
>>
>>
>> On 28.09.2013 03:20, Jeffrey Flint wrote:
>>
>>> This is in regards to the SNOW library.
>>>
>>> I'm using Windows.  The problem is that makeSOCKcluster hangs in R as well
>>> as the DOS command line.  Below I've shown that it completes the Rscript
>>> until it reaches the line "slaveLoop(master)" , at which point it hangs.
>>>
>>> =============================
>>>
>>> In R:
>>>
>>>   cl <-
>>>>
>>> makeSOCKcluster(names=c("**localhost","localhost"),**
>>> manual=T,outfile="jeff.log")
>>> Manually start worker on localhost with
>>>        C:/PROGRA~1/R/R-214~1.2/bin/**Rscript.exe "C:/Program
>>> Files/R/R-2.14.2/library/snow/**RSOCKnode.R" MASTER=localhost PORT=11590
>>> OUT=jeff.log SNOWLIB=C:/Program Files/R/R-2.14.2/library
>>> [HANGS]
>>> ==============================**==
>>>
>>> On the DOS Command Line:
>>>
>>> C:\Documents and Settings\Jeff>C:/PROGRA~1/R/R-**214~1.2/bin/Rscript.exe
>>> "C:/Program Files/R/R-2.14.2/library/snow/**RSOCKno
>>> de.R" MASTER=localhost PORT=11590 OUT=jeff.log SNOWLIB=C:/Program
>>> Files/R/R-2.14.2/library
>>> [HANGS]
>>> ^C
>>> C:\Documents and Settings\Jeff>type jeff.log
>>> starting worker for localhost:11590
>>>
>>> ==============================**======
>>>
>>>
>>> In the file RSOCKnode.R, stalls after last line, after executing
>>> "slaveLoop(master)".
>>>
>>>
>>>
>>>
>>> local({
>>>       master <- "localhost"
>>>       port <- "8765"
>>>       snowlib <- Sys.getenv("R_SNOW_LIB")
>>>       outfile <- Sys.getenv("R_SNOW_OUTFILE")
>>>
>>>       args <- commandArgs()
>>>       pos <- match("--args", args)
>>>       args <- args[-(1 : pos)]
>>>       for (a in args) {
>>>           pos <- regexpr("=", a)
>>>           name <- substr(a, 1, pos - 1)
>>>           value <- substr(a,pos + 1, nchar(a))
>>>           switch(name,
>>>                  MASTER = master <- value,
>>>                  PORT = port <- value,
>>>                  SNOWLIB = snowlib <- value,
>>>                  OUT = outfile <- value,
>>>                  RANK = rank <- value,
>>>                  TMPWS = tmpWsName <- value)
>>>       }
>>>       ##**** these should be passed as arguments to makeNWSmaster
>>>       Sys.setenv(MASTER = master)
>>>       Sys.setenv(PORT = port)
>>>       Sys.setenv(RANK = rank)
>>>       Sys.setenv(TMPWS = tmpWsName)
>>>
>>>       if (! (snowlib %in% .libPaths()))
>>>           .libPaths(c(snowlib, .libPaths()))
>>>       library(methods) ## because Rscript as of R 2.7.0 doesn't load
>>> methods
>>>       library(nws)
>>>       library(snow)
>>>
>>>       sinkWorkerOutput(outfile)
>>>       master <- makeNWSmaster()
>>>       sendData(master, "ping")
>>>       cat("starting NWS worker\n")
>>>       slaveLoop(master)
>>> })
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________**________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/**
>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>


From andreia.fonseca at gmail.com  Thu Oct 10 12:44:48 2013
From: andreia.fonseca at gmail.com (Andreia Fonseca)
Date: Thu, 10 Oct 2013 11:44:48 +0100
Subject: [R] help for compare regression coefficients across groups
Message-ID: <CAG43sE+fyDJxuOJidRayL8hGSOw+Auj7ug1_99isyKjWYJmURQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/e6ebe101/attachment.pl>

From i.petzev at gmail.com  Thu Oct 10 13:17:19 2013
From: i.petzev at gmail.com (ivan)
Date: Thu, 10 Oct 2013 13:17:19 +0200
Subject: [R] convert list of lists to simple list
Message-ID: <CAOrU2ZLx=gmTKtrj3eEYz_LwgQVyNGV3KnowBTWxeR624nN+qQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/64281204/attachment.pl>

From phgrosjean at sciviews.org  Thu Oct 10 13:37:11 2013
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Thu, 10 Oct 2013 13:37:11 +0200
Subject: [R] convert list of lists to simple list
In-Reply-To: <CAOrU2ZLx=gmTKtrj3eEYz_LwgQVyNGV3KnowBTWxeR624nN+qQ@mail.gmail.com>
References: <CAOrU2ZLx=gmTKtrj3eEYz_LwgQVyNGV3KnowBTWxeR624nN+qQ@mail.gmail.com>
Message-ID: <9540A7CA-9D64-4F4E-977F-67354E37D346@sciviews.org>


On 10 Oct 2013, at 13:17, ivan <i.petzev at gmail.com> wrote:

> test <- foreach(i = 1:3) %:%
>              foreach (j = 1:3) %do% {
>                 paste(i,j,sep=",")
>              }

Not easily reproducible, unless you write

#install.packages("foreach")
require(foreach)

in front of your code.

Here is a starting point:

unlist(test, recursive = FALSE)

? but you would probably need to build a recursive call of the function down to the last 'list level'. unlist(recursive = TRUE) goes one level too far.
Best,

Philippe Grosjean

From carl at witthoft.com  Thu Oct 10 13:41:42 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 10 Oct 2013 04:41:42 -0700 (PDT)
Subject: [R] Convert a factor to a numeric
In-Reply-To: <1381401584238-4677964.post@n4.nabble.com>
References: <1381401584238-4677964.post@n4.nabble.com>
Message-ID: <1381405302552-4677971.post@n4.nabble.com>

foo <- as.numeric(as.character(your_factors) ).

It's a common mistake to forget the first conversion, in which case you end
up with an integer sequence rather than the desired values.



--
View this message in context: http://r.789695.n4.nabble.com/Convert-a-factor-to-a-numeric-tp4677964p4677971.html
Sent from the R help mailing list archive at Nabble.com.


From carl at witthoft.com  Thu Oct 10 13:45:18 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 10 Oct 2013 04:45:18 -0700 (PDT)
Subject: [R] optimizing code
In-Reply-To: <1381402081921-4677966.post@n4.nabble.com>
References: <1381402081921-4677966.post@n4.nabble.com>
Message-ID: <1381405518777-4677972.post@n4.nabble.com>

FMRPROG wrote
> I am generating random numbers from a normal distribution using 
> [snip]
> 
> I need to optimize the speed WITHOUT using the rnorm function but have no
> idea how to do this. I assume I should minimise what goes in the loop?
> 
> Any help would be very much appreciated.

Looks like homework.  
Thus, only a hint:  any time you create something one at a time with a loop,
you almost certainly can create all "n" values by taking advantage of R's
built-in vectorization.  Every statement in your loops can be vectorized.




--
View this message in context: http://r.789695.n4.nabble.com/optimizing-code-tp4677966p4677972.html
Sent from the R help mailing list archive at Nabble.com.


From carl at witthoft.com  Thu Oct 10 13:49:04 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 10 Oct 2013 04:49:04 -0700 (PDT)
Subject: [R] vector where elements are functions evaluated at integers,
 but length of vector varies
In-Reply-To: <1381356348958-4677932.post@n4.nabble.com>
References: <1381356348958-4677932.post@n4.nabble.com>
Message-ID: <1381405744810-4677973.post@n4.nabble.com>


Hi,

I have two integers a and b (with a<b), as well as a function f(x). Is there
a way of getting the vector (f(a), ..., f(b)) from R without having to
explicitly write it out? as my a and b vary.

Thanks for your help
&lt;/quote>

What did you try?    Further, without knowing what your function f(x) is, we
can't tell you whether it accepts vector inputs.  




--
View this message in context: http://r.789695.n4.nabble.com/vector-where-elements-are-functions-evaluated-at-integers-but-length-of-vector-varies-tp4677932p4677973.html
Sent from the R help mailing list archive at Nabble.com.


From carl at witthoft.com  Thu Oct 10 13:52:42 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 10 Oct 2013 04:52:42 -0700 (PDT)
Subject: [R] makeCluster help needed
In-Reply-To: <CALbUM4P2xQOWk_EFLCfCefw8oE53+T0eaNohvc5zqvHFuvfkkw@mail.gmail.com>
References: <CALbUM4MVAXRUGn0gJ8ziRe+HjDC0aRRPE1R9UE4OLnAkVSoDdQ@mail.gmail.com>
	<52470EAA.7090003@statistik.tu-dortmund.de>
	<CALbUM4P2xQOWk_EFLCfCefw8oE53+T0eaNohvc5zqvHFuvfkkw@mail.gmail.com>
Message-ID: <1381405962902-4677974.post@n4.nabble.com>

Jeffrey Flint wrote
> Good news. I installed 3.0.2, and the parallel package examples ran
> successfully.  This time a firewall window popped up.  Probably the
> firewall was the problem with the snow package too, but for some reason
> the
> window didn't pop up with the snow package.
> 
> Thanks for the suggestion to use "parallel".  I noticed that the package
> is
> brand new!  Or, at least the pdf help was written 9/25/13.
> 
> Jeff

One thing to watch for that hung me (and R :-) ) up for a while is: make
sure your .Rprofile doesn't have any commands which are valid only in
interactive sessions.  I had "loadhistory()" which caused the worker
Rscript.exe to fail.  Replacing that line in .Rprofile with  
"if(interactive()) loadhistory() "  and all was well.




--
View this message in context: http://r.789695.n4.nabble.com/makeCluster-help-needed-tp4677156p4677974.html
Sent from the R help mailing list archive at Nabble.com.


From friendly at yorku.ca  Thu Oct 10 14:41:23 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 10 Oct 2013 08:41:23 -0400
Subject: [R] Help required graphing factors with predicted model settings
In-Reply-To: <CACBnbk5A1jkjJ4m8R00PTGbOMbDXLbp2Ju2Hzvge8fd_9w98qg@mail.gmail.com>
References: <CACBnbk4Ur4sdLSqar34o9ZEazq4JFhSkSCoBgPCku+zrs_h-pw@mail.gmail.com>
	<52562E34.6000308@bitwrit.com.au>
	<CACBnbk5A1jkjJ4m8R00PTGbOMbDXLbp2Ju2Hzvge8fd_9w98qg@mail.gmail.com>
Message-ID: <5256A073.8070008@yorku.ca>

Perhaps you are looking for the effects package, which can plot effects
(predicted values) for terms in mer objects from lme4?

library(effects)
?effect

library(lme4)
data(cake, package="lme4")
fm1 <- lmer(angle ~ recipe * temperature + (1|recipe:replicate), cake,
                    REML = FALSE)
plot(effect("recipe:temperature", fm1), grid=TRUE)
plot(Effect(c("recipe", "temperature"), fm1)) # equivalent


On 10/10/2013 12:52 AM, Rebecca Stirnemann wrote:
> Thanks Jim for helping,
>
> Your sample data actually looks like my dataset. The one I put up looks
> strange for some reason so please ignore that.
> I have three landusenumb variables 1 2 and 3. is rep (1,2,3) correct?
>
> When I run the following code I am getting:
>
>> mod1 <- glmer(frat ~ flandusenumb + ground.cover_lo + (1|fsite) ,family =
> binomial, data= mao1)
>>
>> #Calculate predicted values
>> newdata1 <- data.frame(ground.cover_lo = c(25,50,100), flandusenumb =
> rep(1,2,3))
>> pred34 <- predict(mod1,newdata=newdata1,type="response")
>
> Error in UseMethod("predict") :
>    no applicable method for 'predict' applied to an object of class "mer"
>
> Can you see what I am doing wrong?
> What I am aiming for is a graph which looks like this.
>
> Thanks
> Rebecca
>
>
>
>
>
>
> On Thu, Oct 10, 2013 at 5:33 PM, Jim Lemon <jim at bitwrit.com.au> wrote:
>
>> On 10/10/2013 08:35 AM, Rebecca Stirnemann wrote:
>>
>>> Dear R wizards,
>>>
>>> Though I hate to do it after weeks of my code not working I need some help
>>> since I cant find an example which seems to work.
>>> I am trying to create a graph which show the probability of predation of a
>>> nest on one side (either 1 to 0) or (0% to 100%) on one side
>>> and grass height at the bottom. I want to then add my predicted lines from
>>> my glmr onto the graph for three habitat types.
>>>
>>> I would like to repeat this procedure 3 times for three different grass
>>> heights 25- 50- 100 to see the effect size.
>>>
>>> My data:
>>>      landusenumb landuse sitename rat ground.cover_lo  1  plantation
>>> far.leftroad_LHS 0 60  1 plantation far.leftroad_LHS 1 70  1 plantation
>>> far.leftroad_LHS 1 10  1 plantation far.leftroad_LHS 1 30  1 plantation
>>> far.leftroad_LHS 1 50  1 plantation far.leftroad_LHS 0 20  1 plantation
>>> far.leftroad_LHS 0 70  1 plantation far.leftroad_LHS 0 100  1 plantation
>>> far.leftroad_LHS 0 90
>>>
>>> #Graph
>>>
>>>
>>> #Fit model
>>>
>>> mod1<- glmer(frat ~ flandusenumb + ground.cover_lo + (1|fsite) ,family =
>>> binomial, data= mao1)
>>>
>>>
>>> #Calculate predicted values
>>>
>>> newdata1<- data.frame(ground.cover_lo = seq(0,10,length=100), flandusenumb
>>> = rep(1,2,3))
>>>
>>> pred34<- predict(mod1,newdata=newdata1,**type="response")
>>>
>>>
>>>
>>> #Plot model predicted curves
>>>
>>> plot(c(0,100),c(0,1),type="n",**xlab="grasscover",ylab="**Probability of
>>> predation")
>>>
>>> lines(newdata1$frat,pred34,**lwd=3,col="blue")
>>>
>>>
>>>   Hi Rebecca,
>> First, your sample data are a bit mangled, and should look like this:
>>
>> mao1
>>
>> landusenumb landuse    sitename rat ground.cover_lo
>> 1           plantation far.leftroad_LHS   0      60
>> 1           plantation far.leftroad_LHS   1      70
>> 1           plantation far.leftroad_LHS   1      10
>> 1           plantation far.leftroad_LHS   1      30
>> 1           plantation far.leftroad_LHS   1      50
>> 1           plantation far.leftroad_LHS   0      20
>> 1           plantation far.leftroad_LHS   0      70
>> 1           plantation far.leftroad_LHS   0     100
>> 1           plantation far.leftroad_LHS   0      90
>>
>> If you want the predicted values with ground cover as above, then:
>>
>> ground.cover_lo = c(25,50,100)
>>
>> The variable names in the first model don't match those in the data frame,
>> but I assume these were typos. What does "pred34" look like? This will tell
>> you what function you should be using to plot it.
>>
>> Jim
>>
>
>
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From smartpink111 at yahoo.com  Thu Oct 10 15:02:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 10 Oct 2013 06:02:52 -0700 (PDT)
Subject: [R] Convert a factor to a numeric
Message-ID: <1381410172.15568.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
It is not clear whether all the variables are factor or only a few are..

dat<- read.table(text="a??????????????? coef?????????????? coef.l????????????? coef.h
1?? 1?? 0.005657825001254? 0.00300612956318132 0.00830952043932667
2?? 2 0.00634505314577229? 0.00334102345418614 0.00934908283735844
3?? 3 0.00368668099805019 0.000289702228748421 0.00708365976735195
4?? 4? 0.0056200291035751? 0.00209123538827368 0.00914882281887651
5?? 5 0.00636609791030242? 0.00269683889899591? 0.0100353569216089",sep="",colClasses=rep("factor",4)) 
dat1<- dat


?dat[] <- lapply(dat,function(x) as.numeric(as.character(x)))

str(dat)
#'data.frame':??? 5 obs. of? 4 variables:
# $ a???? : num? 1 2 3 4 5
# $ coef? : num? 0.00566 0.00635 0.00369 0.00562 0.00637
# $ coef.l: num? 0.00301 0.00334 0.00029 0.00209 0.0027
# $ coef.h: num? 0.00831 0.00935 0.00708 0.00915 0.01004


# With only a subset of variables in the dataset as factors
?dat1$a<- as.numeric(as.character(dat1$a))

?
dat1[sapply(dat1,is.factor)]<- lapply(dat1[sapply(dat1,is.factor)],function(x) as.numeric(as.character(x)))
?str(dat1)
#'data.frame':??? 5 obs. of? 4 variables:
# $ a???? : num? 1 2 3 4 5
# $ coef? : num? 0.00566 0.00635 0.00369 0.00562 0.00637
# $ coef.l: num? 0.00301 0.00334 0.00029 0.00209 0.0027
# $ coef.h: num? 0.00831 0.00935 0.00708 0.00915 0.01004
?
A.K.



I have a factor data frame which I want to convert to numeric without any change in contents. How could I do that? 


? ?a ? ? ? ? ? ? ? ?coef ? ? ? ? ? ? ? coef.l ? ? ? ? ? ? ?coef.h 
1 ? 1 ? 0.005657825001254 ?0.00300612956318132 0.00830952043932667 
2 ? 2 0.00634505314577229 ?0.00334102345418614 0.00934908283735844 
3 ? 3 0.00368668099805019 0.000289702228748421 0.00708365976735195 
4 ? 4 ?0.0056200291035751 ?0.00209123538827368 0.00914882281887651 
5 ? 5 0.00636609791030242 ?0.00269683889899591 ?0.0100353569216089


From deter088 at umn.edu  Thu Oct 10 15:09:00 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 10 Oct 2013 08:09:00 -0500
Subject: [R] Convert a factor to a numeric
In-Reply-To: <1381410172.15568.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1381410172.15568.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CAOLJphkoLMPXh3hG7aYvset4xwxisLZnJRxYrk9bYVq--c9htQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/a75be590/attachment.pl>

From cef24 at pitt.edu  Thu Oct 10 13:14:51 2013
From: cef24 at pitt.edu (cf2059)
Date: Thu, 10 Oct 2013 04:14:51 -0700 (PDT)
Subject: [R] frailtypack
In-Reply-To: <1381339255578-4677907.post@n4.nabble.com>
References: <1282061687542-2328606.post@n4.nabble.com>
	<525569D6.2000404@mayo.edu>
	<1381339255578-4677907.post@n4.nabble.com>
Message-ID: <1381403691417-4677967.post@n4.nabble.com>

I wanted to provide a follow-up post regarding the question of the coxme
program and nested (multilevel) frailty analysis. As it turns out, my
failure to produce results was a result of my own error.  The following
syntax seems to successfully produce results for a model accounting for both
clustering of recurrent events within individual (ID) and also individuals
within groups (GroupNum).   Given that my dataset is over 15,000 rows in
length, the success of the program is no small feat (I attempted a similar
nested analysis with this data in two other R programs, and in both cases R
stopped working during the procedure)

library(coxme)
cgd.nfm<- coxme(Surv(Duration, Censoring) ~ Alcohol*Gender + (1 |
GroupNum/ID), data=mydata) 
print(cgd.nfm)

My only remaining question concerns the relation between estimates provided
by coxme and those provided by a gamma shared frailty model run in SAS. 
When I run identical shared frailty models in coxme and NLMIXED in SAS, the
estimates of fixed effects in coxme are slightly lower and the standard
errors are slightly higher. In reading the ?Short Introduction to Coxme,? I
noticed mention of the Gaussian distribution. I wondered if differences in
the effects produced by coxme might be attributable to differences between
the Gaussian and the gamma distributions. (Forgive me if these questions are
misinformed or rudimentary?this is an entirely new field to me.)  I also
wondered if there was a way to adjust the syntax of coxme such that the
estimates more closely approximate those produced by NLMIXED or,
alternatively, if there are reasons for believing the results produced by
coxme would be superior.  


cf2059 wrote
> Thank you very much for responding.  Yes, I incorrectly stated that
> frailtypack was the only widely available software for the analysis of
> nested frailty models.    When I initially began my search to identify
> software well suited to nested frailty analysis, Frailtypack dominated the
> google results.  While this package seems to be widely publicized on the
> internet, I have not thus far found it to be well suited to analysis with
> my large dataset.
> 
> I would like to use coxme to analyze my data, as it appears to have far
> fewer idiosyncrasies than Frailtypack. However, at the moment I am
> struggling to 1) achieve model convergence with even a basic shared
> frailty model and 2) produce the correct code for the nested frailty
> model.   My dataset involves recurrent events clustered within individuals
> (ID) and individuals then clustered within groups of three (GroupNum). One
> independent variable (Alcohol) varies by group and another (Gender) varies
> by individual.  I ultimately aim to produce a nested frailty model that
> includes one random intercept variance term at the level of the individual
> and one at the level of the group.  I have already produced results for a
> basic shared frailty model using SAS NLMIXED--a model that accounts for
> clustering only at the level of the Group using group-level predictors
> (Alcohol)--but so far I have not been able to achieve convergence for this
> same model using coxme. I suspect that supplying the program with starting
> values might be useful, but I am not familiar enough with the program code
> to do so. Any suggestions would be very much appreciated. I am new to
> survival analysis as well as the R software program.
> 
> ##Basic Shared Frailty Model
>> cgd.nfm <- coxme(Surv(Duration, Censoring) ~ Alcohol + (1 | ID),
>> data=mydata)
>> summary(cgd.nfm)
>                  Length Class           Mode    
> coefficients         1  -none-          numeric 
> frail                1  -none-          list    
> penalty              1  -none-          numeric 
> loglik               3  -none-          numeric 
> variance             1  bdsmatrix       S4      
> df                   2  -none-          numeric 
> hmat                 1  gchol.bdsmatrix S4      
> iter                 2  -none-          numeric 
> control              9  -none-          list    
> u                  709  -none-          numeric 
> means                1  -none-          numeric 
> scale                1  -none-          numeric 
> linear.predictor 15831  -none-          numeric 
> vcoef                1  -none-          list    
> n                    2  -none-          numeric 
> terms                3  terms           call    
> formulaList          2  -none-          list    
> y                31662  Surv            numeric 
> call                 3  -none-          call    
> ties                 1  -none-          character
>  
> Nested Frailty Model 
>> cgd.nfm <- coxme(Surv(Duration, Censoring) ~ Alcohol*Gender + (1 |
>> GroupNum/ID), data=mydata)
>> summary(cgd.nfm)
>                  Length Class           Mode    
> coefficients         1  -none-          numeric 
> frail                2  -none-          list    
> penalty              1  -none-          numeric 
> loglik               3  -none-          numeric 
> variance             1  bdsmatrix       S4      
> df                   2  -none-          numeric 
> hmat                 1  gchol.bdsmatrix S4      
> iter                 2  -none-          numeric 
> control              9  -none-          list    
> u                  947  -none-          numeric 
> means                1  -none-          numeric 
> scale                1  -none-          numeric 
> linear.predictor 15831  -none-          numeric 
> vcoef                2  -none-          list    
> n                    2  -none-          numeric 
> terms                3  terms           call    
> formulaList          2  -none-          list    
> y                31662  Surv            numeric 
> call                 3  -none-          call    
> ties                 1  -none-          character
> Terry Therneau-2 wrote
>> I can't comment on frailtypack issues, but would like to mention that
>> coxme will handle 
>> nested models, contrary to the statement below that "frailtypack is
>> perhaps the only .... 
>> for nested survival data".
>> To reprise the original post's model
>> 
>>     cgd.nfm <- coxme(Surv(Tstart, Tstop, Status) ~ Treatment + (1 |
>> Center/ID), data=cgd.ag)
>> 
>> 
>> And a note to the poster-- you should reprise the original message to
>> which you are 
>> responding.
>> 
>> 
>> Terry Therneau
>> 
>> On 10/09/2013 05:00 AM, 

>> r-help-request@

>>  wrote:
>>> Hello,
>>>
>>> I am encountering very similar problems with frailtypack (only, it
>>> seems, 3
>>> years later).  I would be incredibly grateful if you would be willing to
>>> share any solutions you happened upon for the problem you mention. I
>>> have a
>>> datafile that is even longer than yours (over 15000 events). Events
>>> follow a
>>> two-level nesting structure. When I attempt to run the nested survival
>>> model
>>> in frailtypack the program either stops running entirely or produces an
>>> error message. I have contacted the frailtypack maintainer but have not
>>> yet
>>> received a response.  It seems that frailtypack is perhaps the only
>>> widely-available platform for the analysis of nested survival data, so
>>> the
>>> seeming bugginess of this program is troubling.  Please let me know if
>>> you
>>> ended up coming up with a solution to your problem or, alternatively,
>>> another program able to run the nested analysis. Thank you so much!
>>>
>> 
>> ______________________________________________

>> R-help@

>>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/frailtypack-tp2328606p4677967.html
Sent from the R help mailing list archive at Nabble.com.


From deter088 at umn.edu  Thu Oct 10 15:33:18 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 10 Oct 2013 08:33:18 -0500
Subject: [R] Convert a factor to a numeric
In-Reply-To: <1381411612.29399.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1381410172.15568.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAOLJphkoLMPXh3hG7aYvset4xwxisLZnJRxYrk9bYVq--c9htQ@mail.gmail.com>
	<1381411612.29399.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <CAOLJph=LUmQ3vdQ797v6kMjzGLT1BwcSkYnSbhKMqy9wEqNjCQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/72dfd73b/attachment.pl>

From deter088 at umn.edu  Thu Oct 10 15:41:10 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 10 Oct 2013 08:41:10 -0500
Subject: [R] Convert a factor to a numeric
In-Reply-To: <1381412229.87205.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1381410172.15568.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAOLJphkoLMPXh3hG7aYvset4xwxisLZnJRxYrk9bYVq--c9htQ@mail.gmail.com>
	<1381411612.29399.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CAOLJph=LUmQ3vdQ797v6kMjzGLT1BwcSkYnSbhKMqy9wEqNjCQ@mail.gmail.com>
	<1381412229.87205.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CAOLJph=5dEy-HBfPyaVkZyHghjMi2_C+Hg9Bz7KdbYe2+RCB_g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/9c2d32d9/attachment.pl>

From sophie_brugieres at mpipsykl.mpg.de  Thu Oct 10 15:17:21 2013
From: sophie_brugieres at mpipsykl.mpg.de (sophie_brugieres at mpipsykl.mpg.de)
Date: Thu, 10 Oct 2013 15:17:21 +0200 (CEST)
Subject: [R] Rcpp and mclapply
Message-ID: <56361.145.253.118.83.1381411041.squirrel@webmail.mpipsykl.mpg.de>

Dear all,

I have an R script that uses Rcpp, and I have been trying to parallelize
it using mclapply (I tried with the multicore and the parallel library)

Sometimes (not always, interestingly), the CPU use for each core drops,
usually so that the total over all cores reaches 100%, i.e., as fast as if
using just one single core fully. I tried my code directly from within
emacs, and also using a shell command - it happens either way.

I suspect there might be some interaction between Rcpp and the
multicore/parallel libraries. Did any R(cpp) user encounter such symptoms?

Sophie


From praveensripati at gmail.com  Thu Oct 10 11:34:10 2013
From: praveensripati at gmail.com (Praveen Sripati)
Date: Thu, 10 Oct 2013 10:34:10 +0100
Subject: [R] Error while running MR using rmr2
Message-ID: <CADYHM8wgGQri_3FrZuO8s7rTXV07474Szx9fVv9jgVJKRd2W0w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/b0aa514b/attachment.pl>

From smartpink111 at yahoo.com  Thu Oct 10 16:00:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 10 Oct 2013 07:00:33 -0700 (PDT)
Subject: [R] Convert a factor to a numeric
In-Reply-To: <CAOLJph=5dEy-HBfPyaVkZyHghjMi2_C+Hg9Bz7KdbYe2+RCB_g@mail.gmail.com>
References: <1381410172.15568.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAOLJphkoLMPXh3hG7aYvset4xwxisLZnJRxYrk9bYVq--c9htQ@mail.gmail.com>	<1381411612.29399.YahooMailNeo@web142602.mail.bf1.yahoo.com>	<CAOLJph=LUmQ3vdQ797v6kMjzGLT1BwcSkYnSbhKMqy9wEqNjCQ@mail.gmail.com>	<1381412229.87205.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAOLJph=5dEy-HBfPyaVkZyHghjMi2_C+Hg9Bz7KdbYe2+RCB_g@mail.gmail.com>
Message-ID: <1381413633.80252.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Also, BTW, dat.num() is matrix, but if you use lapply(), it is still a dataframe.? Anyway, it depends on what the OP really wants as output.
dat.num <- apply(dat, 2, FUN = function(x) as.numeric(as.character(x)))
?dat[] <- lapply(dat,function(x) as.numeric(as.character(x)))

?str(dat)
'data.frame':??? 5 obs. of? 4 variables:
?$ a???? : num? 1 2 3 4 5
?$ coef? : num? 0.00566 0.00635 0.00369 0.00562 0.00637
?$ coef.l: num? 0.00301 0.00334 0.00029 0.00209 0.0027
?$ coef.h: num? 0.00831 0.00935 0.00708 0.00915 0.01004

?str(dat.num)
?num [1:5, 1:4] 1 2 3 4 5 ...
?- attr(*, "dimnames")=List of 2
? ..$ : NULL
? ..$ : chr [1:4] "a" "coef" "coef.l" "coef.h"
as.data.frame(dat.num)

A.K.



On Thursday, October 10, 2013 9:41 AM, Charles Determan Jr <deter088 at umn.edu> wrote:

Firstly, please make sure to reply-all so the r-help list also receives these emails.

Second, I have just run this sequence as it provides an exact copy with each as numeric.? Use the apply function, it iterates over each column and converts each to numeric.

dat <- read.table(text="a??????????????? coef?????????????? coef.l????????????? coef.h
1?? 1?? 0.005657825001254? 0.00300612956318132 0.00830952043932667
2?? 2 0.00634505314577229? 0.00334102345418614 0.00934908283735844
3?? 3 0.00368668099805019 0.000289702228748421 0.00708365976735195
4?? 4? 0.0056200291035751? 0.00209123538827368 0.00914882281887651
5?? 5 0.00636609791030242? 0.00269683889899591? 0.0100353569216089",sep="",colClasses=rep("factor",4))

dat.num <- apply(dat, 2, FUN = function(x) as.numeric(as.character(x)))

Charles





On Thu, Oct 10, 2013 at 8:37 AM, arun <smartpink111 at yahoo.com> wrote:


>
>Looks like it is directly doing:
>as.numeric() without the as.character()
>For ex:
>?as.numeric(dat[,2])
>#[1] 3 4 1 2 5
>
>
>
>
>
>
>On Thursday, October 10, 2013 9:33 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
>
>I'm not honestly sure why data.matrix didn't work off hand.? Perhaps another user can shed some light on this.? An alternative is the following:
>
>apply(dat, 2, FUN = function(x) as.numeric(as.character(x)))
>
>
>
>
>On Thu, Oct 10, 2013 at 8:26 AM, arun <smartpink111 at yahoo.com> wrote:
>
>Did you mean to apply it like this or is it something else?
>>?data.matrix(dat) #
>>? a coef coef.l coef.h
>>1 1??? 3????? 4????? 2
>>2 2??? 4????? 5????? 4
>>3 3??? 1????? 1????? 1
>>4 4??? 2????? 2????? 3
>>5 5??? 5????? 3????? 5
>>
>>
>>A.K.
>>
>>
>>
>>
>>
>>
>>On Thursday, October 10, 2013 9:09 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
>>
>>data.matrix() should do the job for you
>>
>>Charles
>>
>>
>>
>>
>>On Thu, Oct 10, 2013 at 8:02 AM, arun <smartpink111 at yahoo.com> wrote:
>>
>>Hi,
>>>It is not clear whether all the variables are factor or only a few are..
>>>
>>>dat<- read.table(text="a??????????????? coef?????????????? coef.l????????????? coef.h
>>>1?? 1?? 0.005657825001254? 0.00300612956318132 0.00830952043932667
>>>2?? 2 0.00634505314577229? 0.00334102345418614 0.00934908283735844
>>>3?? 3 0.00368668099805019 0.000289702228748421 0.00708365976735195
>>>4?? 4? 0.0056200291035751? 0.00209123538827368 0.00914882281887651
>>>5?? 5 0.00636609791030242? 0.00269683889899591? 0.0100353569216089",sep="",colClasses=rep("factor",4))
>>>dat1<- dat
>>>
>>>
>>>?dat[] <- lapply(dat,function(x) as.numeric(as.character(x)))
>>>
>>>str(dat)
>>>#'data.frame':??? 5 obs. of? 4 variables:
>>># $ a???? : num? 1 2 3 4 5
>>># $ coef? : num? 0.00566 0.00635 0.00369 0.00562 0.00637
>>># $ coef.l: num? 0.00301 0.00334 0.00029 0.00209 0.0027
>>># $ coef.h: num? 0.00831 0.00935 0.00708 0.00915 0.01004
>>>
>>>
>>># With only a subset of variables in the dataset as factors
>>>?dat1$a<- as.numeric(as.character(dat1$a))
>>>
>>>?
>>>dat1[sapply(dat1,is.factor)]<- lapply(dat1[sapply(dat1,is.factor)],function(x) as.numeric(as.character(x)))
>>>?str(dat1)
>>>#'data.frame':??? 5 obs. of? 4 variables:
>>># $ a???? : num? 1 2 3 4 5
>>># $ coef? : num? 0.00566 0.00635 0.00369 0.00562 0.00637
>>># $ coef.l: num? 0.00301 0.00334 0.00029 0.00209 0.0027
>>># $ coef.h: num? 0.00831 0.00935 0.00708 0.00915 0.01004
>>>?
>>>A.K.
>>>
>>>
>>>
>>>I have a factor data frame which I want to convert to numeric without any change in contents. How could I do that?
>>>
>>>
>>>? ?a ? ? ? ? ? ? ? ?coef ? ? ? ? ? ? ? coef.l ? ? ? ? ? ? ?coef.h
>>>1 ? 1 ? 0.005657825001254 ?0.00300612956318132 0.00830952043932667
>>>2 ? 2 0.00634505314577229 ?0.00334102345418614 0.00934908283735844
>>>3 ? 3 0.00368668099805019 0.000289702228748421 0.00708365976735195
>>>4 ? 4 ?0.0056200291035751 ?0.00209123538827368 0.00914882281887651
>>>5 ? 5 0.00636609791030242 ?0.00269683889899591 ?0.0100353569216089
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
>
>--
>
>Charles Determan
>Integrated Biosciences PhD Candidate
>University of Minnesota
>


-- 

Charles Determan
Integrated Biosciences PhD Candidate
University of Minnesota


From jdnewmil at dcn.davis.CA.us  Thu Oct 10 16:15:14 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 10 Oct 2013 07:15:14 -0700
Subject: [R] Rcpp and mclapply
In-Reply-To: <56361.145.253.118.83.1381411041.squirrel@webmail.mpipsykl.mpg.de>
References: <56361.145.253.118.83.1381411041.squirrel@webmail.mpipsykl.mpg.de>
Message-ID: <2fb7d8a9-ff85-4d2d-9a07-468e8e75e92e@email.android.com>

I would bet that you are doing something in C++ that shares some resource between the workers and blocks all but one worker at a time.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

sophie_brugieres at mpipsykl.mpg.de wrote:
>Dear all,
>
>I have an R script that uses Rcpp, and I have been trying to
>parallelize
>it using mclapply (I tried with the multicore and the parallel library)
>
>Sometimes (not always, interestingly), the CPU use for each core drops,
>usually so that the total over all cores reaches 100%, i.e., as fast as
>if
>using just one single core fully. I tried my code directly from within
>emacs, and also using a shell command - it happens either way.
>
>I suspect there might be some interaction between Rcpp and the
>multicore/parallel libraries. Did any R(cpp) user encounter such
>symptoms?
>
>Sophie
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wewolski at gmail.com  Thu Oct 10 17:01:41 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Thu, 10 Oct 2013 17:01:41 +0200
Subject: [R] pairs plot
Message-ID: <CAAjnpdjovx2CrYqFkwqYZq068mTUDbJu2AWgHA=N0DACco2DVQ@mail.gmail.com>

my data are matrix with 3 numeric columns.

would like to have pairs plot
with scatterplots in the upper
with hist at the diag
and with correlation at the lower.

actually default pairs does almost what I want but looks semi awesome.
Especially, i didn't find out how to remove the axes from the lower
part where I do only want to display the numeric values correlations
there and somehow axes don't fit.

Hence I am looking at ggpairs from GGally
and calling it without parameters looks almost perfect :
but I cant find out how they got the Corr: in the upper, so I can't
put it in the lower,
and I do not know how to put the hist in the diag.

please help






-- 
Witold Eryk Wolski


From zev at zevross.com  Thu Oct 10 17:16:54 2013
From: zev at zevross.com (Zev Ross)
Date: Thu, 10 Oct 2013 11:16:54 -0400
Subject: [R] system2 commands with backslash
Message-ID: <5256C4E6.6070805@zevross.com>

Hi All,

I'm trying to edit a file in place using system2 and sed from within R. 
I can get my command to work unless there is a backslash in the command 
in which case I'm warned about an "unrecognized escape". So, for example:

system2("sed -i s/oldword/newword/g d:/junk/x/test.tex") # works fine
system2("sed -i s/oldword\s/newword/g d:/junk/x/test.tex") # does not 
work in R (the command works on the command line)

I've experimented with double slashes to escape the \s, I've tried the 
"shell" command, I've tried experimenting with shQuote and can't seem to 
get around the "unrecognized escape" issue.

By the way, it would be preferable to have a solution that avoided using 
double backslashes etc because, unfortunately, in my real-world example, 
I'm actually replacing double slashes and would prefer not to have 
quadruple slashes etc.

I'm using Windows 7, 64 bit.

Zev

-- 
Zev Ross
ZevRoss Spatial Analysis
120 N Aurora, Suite 3A
Ithaca, NY 14850
607-277-0004 (phone)
zev at zevross.com


From B.Ward at uea.ac.uk  Thu Oct 10 16:56:37 2013
From: B.Ward at uea.ac.uk (Benjamin Ward (ENV))
Date: Thu, 10 Oct 2013 14:56:37 +0000
Subject: [R] Small p from binomial probability function.
In-Reply-To: <45FE3A4B-86AB-49A4-B4E4-05B2479953A8@collocations.de>
References: <142413609C0A60488585AB47438ECD9D015BE871@ueastfexch01.UEA.AC.UK>,
	<45FE3A4B-86AB-49A4-B4E4-05B2479953A8@collocations.de>
Message-ID: <142413609C0A60488585AB47438ECD9D015BEA44@ueastfexch01.UEA.AC.UK>

Hi,

Thank you for your answers, I'm not completely sure if it's to bino.test I need or the uniroot. Perhaps I should explain more the idea behind the code and the actual task I'm trying to do. The idea is to calculate a confidence interval as to the age of two DNA sequences which have diverged, where I know the number of mutations that happened in them, and I know the mutation rate.

The binomial probability can be used since, mutations have a probability of occurring or being observed so many times in a sequence. This is dependent on the length of the DNA stretch (which equates to the number of trials since each base is a possibility of observing a mutation), the probability of a single mutation occurring which is p = t * u, since more time means a higher probability a mutation may have occurred.  

So my code, using pbinom, is supposed to calculate the probability that my DNA stretches contain the number of mutations observed P(X = k), given their size (trials) and the probability of a single mutation (p = t * u). However I'm interested in finding t: t is what is unknown, so the loop repeatedly evaluates the calculation, increasing t each time and checking P(X=k), when it is 0.05, 0.50 and 0.95, we record t.

Ideally I'd like to rearrange this so I can get the probability of a single success (mutation) p, and then divide by the mutation rate to get my t. My supervisor gave my the loopy code but I imagine there is a way to plug in P(X=k) as 0.05 and 0.95 and get my upper and lower t estimates.

According to the R built in docs:

binom.test
Description:

     Performs an exact test of a simple null hypothesis about the
     probability of success in a Bernoulli experiment.

Perhaps this is the one I need rather than uniroot?

Best,
Ben.


________________________________________
From: Stefan Evert [stefanML at collocations.de]
Sent: 10 October 2013 09:37
To: R-help Mailing List
Cc: Benjamin Ward (ENV)
Subject: Re: [R] Small p from binomial probability function.

Sounds like you want a 95% binomial confidence interval:

        binom.test(N, P)

will compute this for you, and you can get the bounds directly with

        binom.test(N, P)$conf.int

Actually, binom.test computes a two-sided confidence interval, which corresponds roughly to 2.5 and 97.5 percentages in your approach. It doesn't give you the 50% point either, but I don't think that's a meaningful quantity with a two-sided test.

Hope this helps,
Stefan


On 9 Oct 2013, at 15:53, Benjamin Ward (ENV) <B.Ward at uea.ac.uk> wrote:

> I got given some code that uses the R function pbionom:
>
> p <- mut * t
> sumprobs <- pbinom( N, B, p ) * 1000
>
> Which gives the output of a probability as a percentage like 5, 50, 95.
>
> What the code currently does is find me the values of t I need, by using the above two code lines in a loop, each iteration it increaces t by one and runs the two lines. When sumprobs equals 5, it records the value t, then again when sumprobs is equal to 50, and again when sumprobs is equal to 95 - giving me three t values. This is not an efficient way of doing this if t is large. Is it possible to rearrange pbinom so it gives me the small p (made of mut*t) as the result of plugging in the sumprobs instead, and is there an R function that already does this?
>
> Since pbinom is the binomial probability equation I suppose the question is - in more mathematical terminology - can I change this code so that instead of calculating the Probability of N successes given the number of trials and the probability of a single success, can I instead calculate the probability of a single success using the probability of N successes and number of trials, and the number of successes? Can R do this for me. So instead I plug in 5, 50, and 95, and then get the small p out?



From lauriebayet at gmail.com  Thu Oct 10 17:02:28 2013
From: lauriebayet at gmail.com (laurie bayet)
Date: Thu, 10 Oct 2013 17:02:28 +0200
Subject: [R] mixed model MANOVA? does it even exist?
In-Reply-To: <CAGHpV7wH0d57z=bRS6TKU5N9z-rkNKfdnPqogC6Nz+DhPwJVgQ@mail.gmail.com>
References: <CAGHpV7xP62ayzUH9vER0JwuEKzrOB2oAwkGNv7E9Egs9n8Yg-A@mail.gmail.com>
	<3035C929-F8FF-4FAD-88DD-8F29EB623DFD@gmail.com>
	<CAGHpV7wH0d57z=bRS6TKU5N9z-rkNKfdnPqogC6Nz+DhPwJVgQ@mail.gmail.com>
Message-ID: <CAGHpV7x7aQUpzF1ZUP_uyV2hQC5GgMHDAFTQ9T9mwSY8F38NCA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/a648b6aa/attachment.pl>

From sophie_brugieres at mpipsykl.mpg.de  Thu Oct 10 17:07:13 2013
From: sophie_brugieres at mpipsykl.mpg.de (sophie_brugieres at mpipsykl.mpg.de)
Date: Thu, 10 Oct 2013 17:07:13 +0200 (CEST)
Subject: [R] Rcpp and mclapply
In-Reply-To: <2fb7d8a9-ff85-4d2d-9a07-468e8e75e92e@email.android.com>
References: <56361.145.253.118.83.1381411041.squirrel@webmail.mpipsykl.mpg.de>
	<2fb7d8a9-ff85-4d2d-9a07-468e8e75e92e@email.android.com>
Message-ID: <39529.145.253.118.83.1381417633.squirrel@webmail.mpipsykl.mpg.de>

Dear Jeff,

I had suspected something along those lines initially, however, as I had
stated, this only happens sometimes ...

Here is a partial top showing two of my calls:

17404 sophie    20   0 12.4g  11g 1996 R  100  4.6   5:50.11 R
17405 sophie    20   0 12.4g  11g 2016 R  100  4.6   5:49.86 R
17408 sophie    20   0 12.4g  11g 2016 R  100  4.6   5:49.13 R
17411 sophie    20   0 12.4g  11g 2016 R  100  4.6   5:48.39 R
17412 sophie    20   0 12.4g  11g 2016 R  100  4.6   5:48.14 R
 1461 sophie    20   0 12.7g  11g 2016 R    2  4.7  25:19.27 R
 1465 sophie    20   0 12.7g  11g 2016 R    2  4.7  25:19.05 R
 1476 sophie    20   0 12.7g  11g 2016 R    2  4.7  25:18.73 R
 1486 sophie    20   0 12.7g  11g 2016 R    2  4.7  25:18.39 R
 1491 sophie    20   0 12.7g  11g 2016 R    2  4.7  25:18.24 R

the ones in the 1400 range come from one call, the ones with 17000 from
another ...

It seems to be linked to the console instance that the call is made from
in a way that I cannot grasp yet.

Still puzzled ...

    Sophie

> I would bet that you are doing something in C++ that shares some resource
> between the workers and blocks all but one worker at a time.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> sophie_brugieres at mpipsykl.mpg.de wrote:
>>Dear all,
>>
>>I have an R script that uses Rcpp, and I have been trying to
>>parallelize
>>it using mclapply (I tried with the multicore and the parallel library)
>>
>>Sometimes (not always, interestingly), the CPU use for each core drops,
>>usually so that the total over all cores reaches 100%, i.e., as fast as
>>if
>>using just one single core fully. I tried my code directly from within
>>emacs, and also using a shell command - it happens either way.
>>
>>I suspect there might be some interaction between Rcpp and the
>>multicore/parallel libraries. Did any R(cpp) user encounter such
>>symptoms?
>>
>>Sophie
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>
>


From MXH191 at bham.ac.uk  Thu Oct 10 17:09:24 2013
From: MXH191 at bham.ac.uk (Mash Hamid)
Date: Thu, 10 Oct 2013 15:09:24 +0000
Subject: [R] Problems with R
Message-ID: <AC17B0FD8CEB8444824648A95638A60DAC6D8B0E@mbx05.adf.bham.ac.uk>

Hi,

I have recently installed R and am trying to do some work on it. To be honest I'm finding it a PAIN to you. I use Mac and I can open stata dta. files in R despite using the commands suggested to me and I have been trying to get figure out how to do reduced rank regression on it and the manual is not very useful.

Can you help?

Thanks,

Mash


From jdnewmil at dcn.davis.CA.us  Thu Oct 10 17:56:25 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 10 Oct 2013 08:56:25 -0700
Subject: [R] Rcpp and mclapply
In-Reply-To: <39529.145.253.118.83.1381417633.squirrel@webmail.mpipsykl.mpg.de>
References: <56361.145.253.118.83.1381411041.squirrel@webmail.mpipsykl.mpg.de>
	<2fb7d8a9-ff85-4d2d-9a07-468e8e75e92e@email.android.com>
	<39529.145.253.118.83.1381417633.squirrel@webmail.mpipsykl.mpg.de>
Message-ID: <a2277cd5-8f85-435b-9eee-3d259a6fbe3e@email.android.com>

I cannot imagine how the calling process will affect this. If you want further help I think you will need to provide a reproducible example and info as requested by the Posting Guide.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

sophie_brugieres at mpipsykl.mpg.de wrote:
>Dear Jeff,
>
>I had suspected something along those lines initially, however, as I
>had
>stated, this only happens sometimes ...
>
>Here is a partial top showing two of my calls:
>
>17404 sophie    20   0 12.4g  11g 1996 R  100  4.6   5:50.11 R
>17405 sophie    20   0 12.4g  11g 2016 R  100  4.6   5:49.86 R
>17408 sophie    20   0 12.4g  11g 2016 R  100  4.6   5:49.13 R
>17411 sophie    20   0 12.4g  11g 2016 R  100  4.6   5:48.39 R
>17412 sophie    20   0 12.4g  11g 2016 R  100  4.6   5:48.14 R
> 1461 sophie    20   0 12.7g  11g 2016 R    2  4.7  25:19.27 R
> 1465 sophie    20   0 12.7g  11g 2016 R    2  4.7  25:19.05 R
> 1476 sophie    20   0 12.7g  11g 2016 R    2  4.7  25:18.73 R
> 1486 sophie    20   0 12.7g  11g 2016 R    2  4.7  25:18.39 R
> 1491 sophie    20   0 12.7g  11g 2016 R    2  4.7  25:18.24 R
>
>the ones in the 1400 range come from one call, the ones with 17000 from
>another ...
>
>It seems to be linked to the console instance that the call is made
>from
>in a way that I cannot grasp yet.
>
>Still puzzled ...
>
>    Sophie
>
>> I would bet that you are doing something in C++ that shares some
>resource
>> between the workers and blocks all but one worker at a time.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> sophie_brugieres at mpipsykl.mpg.de wrote:
>>>Dear all,
>>>
>>>I have an R script that uses Rcpp, and I have been trying to
>>>parallelize
>>>it using mclapply (I tried with the multicore and the parallel
>library)
>>>
>>>Sometimes (not always, interestingly), the CPU use for each core
>drops,
>>>usually so that the total over all cores reaches 100%, i.e., as fast
>as
>>>if
>>>using just one single core fully. I tried my code directly from
>within
>>>emacs, and also using a shell command - it happens either way.
>>>
>>>I suspect there might be some interaction between Rcpp and the
>>>multicore/parallel libraries. Did any R(cpp) user encounter such
>>>symptoms?
>>>
>>>Sophie
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>


From Michael.Laviolette at dhhs.state.nh.us  Thu Oct 10 19:16:05 2013
From: Michael.Laviolette at dhhs.state.nh.us (Michael.Laviolette at dhhs.state.nh.us)
Date: Thu, 10 Oct 2013 13:16:05 -0400
Subject: [R] Using calibrate for raking (survey package)
In-Reply-To: <3f24_3e3a_4ebdc085_5e9b_4eb7_89c8_82d31fee4eac@hznsmtp2inf.oit.nh.gov>
References: <3f24_3e3a_4ebdc085_5e9b_4eb7_89c8_82d31fee4eac@hznsmtp2inf.oit.nh.gov>
Message-ID: <OF6A462186.ECEA872E-ON85257C00.005DB94C-85257C00.005EC1FE@dhhs.state.nh.us>

I'm studying the calibration function in the survey package in preparation
for raking some survey data. Results from the rake function below agree
with other sources. When I run calibrate, I get a warning message and the M
and F weights seem to be reversed. Even allowing for that, the deviation
between calibrated and raked weights is much more than I expected. I see
that in the calibrate function "population" is supposed to be a vector or
table, but can't figure out how to adjust. Can you clarify? Thanks.

-M. Laviolette

satisfy <- c(2,5,2,3,4,3,3,3,4,2,2,3,2,3,4,3,3,2,3,3,4,3,3,3,2,
             3,3,3,2,1,4,4,3,3,2,3,4,2,3,3,3,5,3,1,4,3,3,4,4,2,
             3,3,3,5,4,4,5,3,4,4,5,3,3,4,3,3,3,3,2,4,4,3,3,4,3,
             2,4,4,3,4,4,4,5,3,3,4,4,4,3,2,2,4,3,4,3,4,4,3,3,3,
             3,4,4,4,4,3,3,3,3,2,3,3,2,2,5,4,5,2,4,4,4,3,4,4,2,
             4,4,3,4,3,4,2,3,3,2,4,3,4,4,3,5,2,4,4,3,4,5,3,3,3,
             3,2,3,4,4,4,2,4,4,2,3,5,2,2,3,3,3,3,3,4,4,3,3,4,4,
             4,4,4,4,4,4,3,2,3,3,3,3,4,4,4,3,3,4,3,4,4,4,3,3,2)

Gender <-  c(1,2,1,1,2,1,1,2,1,2,1,1,2,1,1,1,1,2,2,1,2,1,1,2,1,
             2,1,1,2,2,1,1,2,1,2,2,1,1,1,1,2,1,1,1,1,1,1,1,2,1,
             1,1,1,1,2,1,1,2,2,2,2,2,2,2,2,2,1,1,1,1,2,1,2,1,2,
             1,1,2,1,1,2,1,1,1,1,1,1,2,1,1,2,2,2,2,1,1,2,2,1,2,
             1,1,2,1,2,1,2,2,1,1,1,2,1,1,1,2,1,1,2,1,2,2,2,1,1,
             2,2,1,1,1,2,1,2,1,2,2,1,1,1,2,2,1,2,2,2,2,1,2,2,1,
             2,1,2,1,1,2,2,1,1,1,2,2,1,2,2,2,1,2,2,1,1,1,2,2,2,
             1,2,1,2,2,2,2,1,1,2,1,1,1,2,1,1,2,2,1,1,1,1,2,1,1)

Age <-     c(2,3,2,1,2,2,2,2,3,2,2,1,2,2,2,2,2,2,2,2,2,2,2,3,2,
             3,3,3,1,2,2,3,2,2,2,1,3,2,2,2,2,2,2,3,2,2,2,2,2,1,
             3,3,2,3,2,2,2,2,2,2,2,3,2,2,1,2,2,2,1,2,2,3,2,2,1,
             2,2,1,2,2,1,2,2,2,2,2,2,2,3,2,2,1,3,2,2,2,3,2,2,2,
             3,1,2,1,2,2,1,2,2,2,2,2,2,1,2,2,3,1,2,2,2,2,2,2,2,
             2,3,1,1,2,1,2,2,2,2,2,2,2,2,1,3,2,2,2,1,2,1,1,2,1,
             2,1,1,2,2,2,2,2,2,2,2,3,2,1,2,1,1,2,3,3,1,3,3,2,2,
             2,2,2,2,2,2,2,3,2,3,3,2,2,2,3,1,2,1,2,3,2,2,2,3,2)

emp.dat <- data.frame(Gender = factor(Gender, labels = c("M", "F")),
                      Age = factor(Age, labels =  c("<30", "30-44", "45
+")),
                      satisfy)
pop.gender <- data.frame(Gender = c("M", "F"), Freq = c(3800, 6200))
pop.age <- data.frame(Age = c("<30", "30-44", "45+"),
                      Freq = c(2000, 5000, 3000))

library(survey)
emp.svy <- svydesign(ids = ~0, strata = NULL, weights = ~rep(50, 200),
                     data = emp.dat)
rake.svy <- rake(emp.svy, list(~Gender, ~Age), list(pop.gender, pop.age))

cal.svy <- calibrate(emp.svy,
                     formula = list(~Gender, ~Age),
                     population = list(pop.gender, pop.age), cal.fun =
"raking")
# Warning message:
#   In regcalibrate.survey.design2(design, formula, population,
aggregate.stage # = aggregate.stage,  :Sample and population totals have
different names.

# check weights--M and F seem reversed when "calibrate" used
library(reshape2)
check1 <- with(rake.svy, cbind(variables, weight = 1/prob))
dcast(check1, Gender~Age, sum, value.var = "weight", margins = TRUE)
check2 <- with(cal.svy, cbind(variables, weight = 1/prob))
dcast(check2, Gender~Age, sum, value.var = "weight", margins = TRUE)


From istazahn at gmail.com  Thu Oct 10 19:16:00 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 10 Oct 2013 13:16:00 -0400
Subject: [R] Problems with R
In-Reply-To: <AC17B0FD8CEB8444824648A95638A60DAC6D8B0E@mbx05.adf.bham.ac.uk>
References: <AC17B0FD8CEB8444824648A95638A60DAC6D8B0E@mbx05.adf.bham.ac.uk>
Message-ID: <CA+vqiLEWv8cXSuyA-Ucyg-XKmP7yS9JaBD17NpMKJg3mdwHsiQ@mail.gmail.com>

On Thu, Oct 10, 2013 at 11:09 AM, Mash Hamid <MXH191 at bham.ac.uk> wrote:
>
> Hi,
>
> I have recently installed R and am trying to do some work on it. To be honest I'm finding it a PAIN to you.


To me?


>
> I use Mac and I can open stata dta. files in R


Great, glad to hear it's working!


>
> despite using the commands suggested to me


Or maybe not... What did you try? What went wrong?


>
> and I have been trying to get figure out how to do reduced rank regression on it and the manual is not very useful.


The first hit when googling for "R reduced rank regression" suggests
that the VGAM package provides reduced rank regression models.

Hope this helps,
Ista

>
>
> Can you help?
>
> Thanks,
>
> Mash
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From katakagi at bu.edu  Thu Oct 10 20:39:11 2013
From: katakagi at bu.edu (Ken Takagi)
Date: Thu, 10 Oct 2013 18:39:11 +0000
Subject: [R] Looking for package to solve for exponent using newton's method
Message-ID: <loom.20131010T203432-304@post.gmane.org>

Hi,
I'm looking for an R function/package that will let me solve problems of the
type:

13 = 2^x + 3^x.

The answer to this example is x = 2, but I'm looking for solutions when x
isn't so easily determined. Looking around, it seems that there is no
algebraic solution for x, unless I'm mistaken.  Does anyone know a good
package to solve these types of problems? Are there built in functions to do
this?

Thanks!


From simona.augyte at uconn.edu  Thu Oct 10 17:58:38 2013
From: simona.augyte at uconn.edu (Simona Augyte)
Date: Thu, 10 Oct 2013 11:58:38 -0400
Subject: [R] installing package gstat
Message-ID: <CAHh0FZDiGoincCyL697-WTKa5Pvmerc7xbVYfQWoP3naKeP3RA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/57b9ee44/attachment.pl>

From karl.fetter at gmail.com  Thu Oct 10 18:00:07 2013
From: karl.fetter at gmail.com (Karl Fetter)
Date: Thu, 10 Oct 2013 12:00:07 -0400
Subject: [R] order() not producing results as I expect
Message-ID: <CACZQHzwMuUBUfqqMArYu=Hx71E35afy9oS4dQHa4JOVD8jJXeQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/930fb982/attachment.pl>

From murdoch.duncan at gmail.com  Thu Oct 10 20:56:24 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 10 Oct 2013 14:56:24 -0400
Subject: [R] order() not producing results as I expect
In-Reply-To: <CACZQHzwMuUBUfqqMArYu=Hx71E35afy9oS4dQHa4JOVD8jJXeQ@mail.gmail.com>
References: <CACZQHzwMuUBUfqqMArYu=Hx71E35afy9oS4dQHa4JOVD8jJXeQ@mail.gmail.com>
Message-ID: <5256F858.3040004@gmail.com>

On 10/10/2013 12:00 PM, Karl Fetter wrote:
> Hello,
>
> I'm using R version 3.0.0 on a mac. I'm having trouble getting order to
> behave as I expect it should. I'm trying to sort a data.frame according to
> a character vector. I'm able to sort the data.frame, but it retruns an
> unexpected result. I have no idea where the order that is being produced
> comes from.

It comes from gen.names, which is not a column of your dataset.  I think 
you'll have to give us something reproducible before we can help you.

Duncan Murdoch

>
> Any ideas on how to properly order a data frame by a character vector?
>
> Here is the current order of the data frame (called str.dat):
>
> > head(str.dat)
>     str.names POPINFO POPFLAG LOCDATA Loc1 Loc2 Loc3 ind.names
> 1 alba1.pop3       3       0       1   12    3    2     alba1
> 2 alba2.pop3       3       0       1    3    3    2     alba2
> 3 alch1.pop4       4       0       2    2    3    2     alch1
> 4 alch2.pop4       4       0       2    2    3    2     alch2
> 5 alco1.pop4       4       0       3    3    3    2     alco1
> 6 alco2.pop4       4       0       3    3    3    2     alco2
>
>
>
> Here's the order I expect it to be in when I use order:
>
> > head(data.frame(gen.names))
>    gen.names
> 1     magv1
> 2     magv2
> 3     magv3
> 4     magv4
> 5       lc1
> 6       lc2
>
>
> Here's the order I'm getting:
>
> > head(str.dat[order(gen.names),])
>       str.names POPINFO POPFLAG LOCDATA Loc1 Loc2 Loc3 ind.names
> 111 ncle2.pop5       5       0      39    3    3    2     ncle2
> 112 ncle3.pop5       5       0      39    2    2    2     ncle3
> 146 wvma1.pop8       8       0      57    3    3    2     wvma1
> 145 wvfa2.pop8       8       0      56    3    3    2     wvfa2
> 55  flse6.pop2       2       0      19    2    5    4     flse6
> 54  flse5.pop2       2       0      19    2    5    4     flse5
>
>
>
>
> Many thanks,
>
> Karl
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Oct 10 20:59:15 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 10 Oct 2013 14:59:15 -0400
Subject: [R] Looking for package to solve for exponent using newton's
 method
In-Reply-To: <loom.20131010T203432-304@post.gmane.org>
References: <loom.20131010T203432-304@post.gmane.org>
Message-ID: <5256F903.2040209@gmail.com>

On 10/10/2013 2:39 PM, Ken Takagi wrote:
> Hi,
> I'm looking for an R function/package that will let me solve problems of the
> type:
>
> 13 = 2^x + 3^x.
>
> The answer to this example is x = 2, but I'm looking for solutions when x
> isn't so easily determined. Looking around, it seems that there is no
> algebraic solution for x, unless I'm mistaken.  Does anyone know a good
> package to solve these types of problems? Are there built in functions to do
> this?

You can get approximate solutions using uniroot:

 > uniroot(function(x) 2^x + 3^x - 13, c(0, 10))
$root
[1] 1.99998

$f.root
[1] -0.0002581592

$iter
[1] 10

$estim.prec
[1] 6.103516e-05


From bhh at xs4all.nl  Thu Oct 10 21:03:00 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 10 Oct 2013 21:03:00 +0200
Subject: [R] Looking for package to solve for exponent using newton's
	method
In-Reply-To: <loom.20131010T203432-304@post.gmane.org>
References: <loom.20131010T203432-304@post.gmane.org>
Message-ID: <A12B1F57-A38F-470D-A6D7-479F94125BC0@xs4all.nl>


On 10-10-2013, at 20:39, Ken Takagi <katakagi at bu.edu> wrote:

> Hi,
> I'm looking for an R function/package that will let me solve problems of the
> type:
> 
> 13 = 2^x + 3^x.
> 
> The answer to this example is x = 2, but I'm looking for solutions when x
> isn't so easily determined. Looking around, it seems that there is no
> algebraic solution for x, unless I'm mistaken.  Does anyone know a good
> package to solve these types of problems? Are there built in functions to do
> this?
> 

Univariate equations can be solved with uniroot, available in base R.

You can also use package nleqslv for this but that is intended for systems of nonlinear equations.
It does however solve your equation.
There is also BB which is especially intended for large sparse systems.

Berend


From katakagi at bu.edu  Thu Oct 10 21:06:33 2013
From: katakagi at bu.edu (Ken Takagi)
Date: Thu, 10 Oct 2013 19:06:33 +0000
Subject: [R] Looking for package to solve for exponent using newton's
	method
References: <loom.20131010T203432-304@post.gmane.org>
	<5256F903.2040209@gmail.com>
Message-ID: <loom.20131010T210330-924@post.gmane.org>

Thanks!  That's just what I needed.


From jdnewmil at dcn.davis.CA.us  Thu Oct 10 21:45:12 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 10 Oct 2013 12:45:12 -0700
Subject: [R] Looking for package to solve for exponent using newton's
	method
In-Reply-To: <loom.20131010T203432-304@post.gmane.org>
References: <loom.20131010T203432-304@post.gmane.org>
Message-ID: <37e40b58-b297-446b-b1b3-647e24a9797e@email.android.com>

?uniroot
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Ken Takagi <katakagi at bu.edu> wrote:
>Hi,
>I'm looking for an R function/package that will let me solve problems
>of the
>type:
>
>13 = 2^x + 3^x.
>
>The answer to this example is x = 2, but I'm looking for solutions when
>x
>isn't so easily determined. Looking around, it seems that there is no
>algebraic solution for x, unless I'm mistaken.  Does anyone know a good
>package to solve these types of problems? Are there built in functions
>to do
>this?
>
>Thanks!
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From epgreen at gmail.com  Thu Oct 10 21:01:42 2013
From: epgreen at gmail.com (Eric Green)
Date: Thu, 10 Oct 2013 12:01:42 -0700 (PDT)
Subject: [R] Bootstrap (bootSem) causes R to crash
In-Reply-To: <000001ce2592$6dc89d40$4959d7c0$@mcmaster.ca>
References: <1363784149641-4661900.post@n4.nabble.com>
	<1363799864468-4661944.post@n4.nabble.com>
	<000001ce2592$6dc89d40$4959d7c0$@mcmaster.ca>
Message-ID: <e3f1c861-450e-43b9-871b-e60ac97e4bdb@googlegroups.com>

Hi everyone, 

I'd like to report a similar experience. When I attempt to run the first 
CFA example in bootSem(), specifically the line:

system.time(boot.cnes <- bootSem(sem.cnes, R=100, Cov=hcor, data=CNES))


R crashes and I get a notice about X11. I copied my sessionInfo() below. 

Any ideas for a workaround?

Thanks
Eric


R version 3.0.1 (2013-05-16)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods   
base     

other attached packages:
 [1] polycor_0.7-8    sfsmisc_1.0-23   mvtnorm_0.9-9996 corrgram_1.5    
 [5] seriation_1.0-11 colorspace_1.2-3 gclus_1.3.1      TSP_1.0-8       
 [9] cluster_1.14.4   GGally_0.4.4     reshape_0.8.4    plyr_1.8        
[13] ggplot2_0.9.3.1  xtable_1.7-1     xlsx_0.5.1       xlsxjars_0.5.0  
[17] rJava_0.9-4      nFactors_2.3.3   lattice_0.20-23  boot_1.3-9      
[21] sem_3.1-3        matrixcalc_1.0-3 MASS_7.3-29      psych_1.3.10    
[25] foreign_0.8-55   knitr_1.5        formatR_0.9     

loaded via a namespace (and not attached):
 [1] dichromat_2.0-0    digest_0.6.3       evaluate_0.5       gtable_0.1.2 
     
 [5] labeling_0.2       munsell_0.4.2      proto_0.3-10       
RColorBrewer_1.0-5
 [9] reshape2_1.2.2     scales_0.2.3       stringr_0.6.2      tools_3.0.1   
    


On Wednesday, March 20, 2013 1:43:26 PM UTC-4, John Fox wrote:
>
> Dear pedtroabq, 
>
> I think that it's impossible to know from the information given why R 
> crashes when bootSem() is called a second time after it worked the first 
> time (which is how I interpret the message that you reference). I don't 
> think that bootSem() is doing anything unusual -- it simply refits the 
> model 
> to bootstrap samples and uses try() to intercept model-fitting failures on 
> the bootstrap replications. 
>
> Also, although it's not relevant to the problem, it's odd not to store the 
> object returned by bootSem() in a variable, which is perhaps what the 
> author 
> of the message means by (2). 
>
> bootSem() does use a Tk progress bar, and I suppose that it's possible 
> that 
> Tcl/Tk for X-Windows or X-Windows itself isn't installed, and that's the 
> source of the error, but I read (1) as implying that the first call to 
> bootSem() worked. bootSem() only uses a Tk progress var if tcltk is 
> loaded, 
> but I don't believe on the Mac that this insures that the tcltk package 
> actually works. If this is indeed the source of the problem, I should 
> probably avoid the Tk progress bar under Mac OS X because of the 
> inadequate 
> support out of the box for the tcltk package on that platform. 
>
> Best, 
>  John 
>
> ----------------------------------------------- 
> John Fox 
> Senator McMaster Professor of Social Statistics 
> Department of Sociology 
> McMaster University 
> Hamilton, Ontario, Canada 
>
>
>
>
>
> > -----Original Message----- 
> > From: r-help-... at r-project.org <javascript:> [mailto:r-help-... at r-<javascript:> 
> > project.org] On Behalf Of pedroabg 
> > Sent: Wednesday, March 20, 2013 1:18 PM 
> > To: r-h... at r-project.org <javascript:> 
> > Subject: Re: [R] Bootstrap (bootSem) causes R to crash 
> > 
> > I think we didn't receive this on the list. 
> > 
> > 
> > 
> > -- 
> > View this message in context: http://r.789695.n4.nabble.com/Bootstrap- 
> > bootSem-causes-R-to-crash-tp4661900p4661944.html 
> > Sent from the R help mailing list archive at Nabble.com. 
> > 
> > ______________________________________________ 
> > R-h... at r-project.org <javascript:> mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-help 
> > PLEASE do read the posting guide http://www.R-project.org/posting- 
> > guide.html 
> > and provide commented, minimal, self-contained, reproducible code. 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From sherisaddy at gmail.com  Thu Oct 10 21:40:16 2013
From: sherisaddy at gmail.com (Sheri)
Date: Thu, 10 Oct 2013 15:40:16 -0400
Subject: [R] Help with expression()
Message-ID: <CABf=2VH5+kJU1rkbQmW+xgftm1dK2dpRfkXLj0uaBRQpK3T2dA@mail.gmail.com>

Hi everyone,

I am hoping someone can help with my attempted use of the expression
function. I have a long series of text and variable to paste together
including a degree symbol. The text is to be placed on my scatter plot
using the mtext function.

Using expression like this:

changetext = expression(paste("Change from ",mini," to ", maxi, ":",
diff ,degree,"C",collapse=""))

does not evaluate my user defined variables - mini,maxi, and diff -
just printing them out as words

Using expression like this:

changetext = paste("Change from ",mini," to ", maxi, ":", diff
,expression(degree,"C"),collapse="")

prints the text twice and does not evaluate the degree symbol.

I have tried to place the expression alone in a variable and then run the paste:

degsym = expression(degree,"C")
changetext = paste("Change from ",mini," to ", maxi, ":", diff
,degsym,collapse="")

giving me the same result as the second option

Is there any way I can use the expression function as in the first
example but still have R evaluate my user defined variables?

Thanks!
Sheri


From tea3rd at gmail.com  Thu Oct 10 22:51:44 2013
From: tea3rd at gmail.com (Thomas Adams)
Date: Thu, 10 Oct 2013 16:51:44 -0400
Subject: [R] installing package gstat
In-Reply-To: <CAHh0FZDiGoincCyL697-WTKa5Pvmerc7xbVYfQWoP3naKeP3RA@mail.gmail.com>
References: <CAHh0FZDiGoincCyL697-WTKa5Pvmerc7xbVYfQWoP3naKeP3RA@mail.gmail.com>
Message-ID: <CAGxgkWjayHUg81CnyUKP5GkfxzhEr=odM23jOPLtORLOG45MGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/cc200bf8/attachment.pl>

From david at revolutionanalytics.com  Thu Oct 10 23:08:06 2013
From: david at revolutionanalytics.com (David Smith)
Date: Thu, 10 Oct 2013 14:08:06 -0700
Subject: [R] Revolutions Blog: September roundup
Message-ID: <CABgvEC9QS2AHFA83=jQ8DH1HEDC-yDh-1XoLOg0EZZYD=C6CUg@mail.gmail.com>

Revolution Analytics staff write about R every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of September:

Todd Schneider wrote an algorithm in R to find the "most convex" US
state (it's NY), and created an animation to show how it works:
http://bit.ly/19qzJ2O

Rob Hyndman (of the "forecast" package) describes how R-based
forecasting saved the Australian government millions, in a video
describing his new online course: http://bit.ly/19qzGnO

Revolution Analytics sponsored more than 60 local R user groups in
2013, and is now taking sponsorships applications for 2014:
http://bit.ly/19qzJ2L

R 3.0.2 is now available, with bug fixes and improved documentation
support: http://bit.ly/19qzJ2N

Some tips for data scientists on using R as part of a command-line
tool chain: http://bit.ly/19qzJ2M

Replay of a Google Hangout panel discussion on how open-source
software including R is changing business: http://bit.ly/19qzGnN

Hortonworks shares some resources for getting started with Data
Science and R: http://bit.ly/19qzJ2R

R represented 57% of the software supplements to the Journal of
Computational and Graphical Statistics over the past year:
http://bit.ly/19qzGE5

On Talk Like a Pirate Day -- Rrrr! -- R was used to chart real-life
pirate attacks (http://bit.ly/19qzGnQ), create a pun-inspired pirate
flag (http://bit.ly/19qzJ2S), and the Revolution Analytics staff had
some pirate fun (http://bit.ly/19qzJ2T).

Revolution Analytics partners with Teradata to bring R and big-data
statistics into the database: http://bit.ly/19qzJ2U

An article in Datanami discusses R in Hadoop: http://bit.ly/19qzJ2X

Reports from the alpha test of the Revolution Analytics' RevoScaleR
package running in Hadoop: http://bit.ly/19qzGE9

A survey of JSM attendees reveals concerns about data privacy and
ethical frameworks for data use: http://bit.ly/19qzJ2V

Coursera's online R courses are back on: Computing for Data Analysis
started on September 23, and Data Analysis starts on October 28:
http://bit.ly/19qzGE7

A neat R-based animation shows the progression of a
Metropolis-Hastings algorithm for Bayesian estimation:
http://bit.ly/19qzGE8

R was mentioned in articles in Data Informed and TechRepublic:
http://bit.ly/19qzGEa

There are now more than 125 R user groups worldwide, as this map
shows: http://bit.ly/19qzJ2W

Slides from two recent Revolution Analytics presentations on:
high-performance predictive analytics in R and Hadoop; and Big Data,
Big Analytics http://bit.ly/19qzJ2Y

A tutorial on how to set up R, Hadoop and RHadoop on a single
workstation/laptop (for learning or testing): http://bit.ly/19qzJ2Z

R is named the top language for data science for the third year
running in the KDNuggets poll: http://bit.ly/19qzJ30

Some non-R stories in the past month included: some terrible data
visualizations (http://bit.ly/19qzGEb), a data visualization of
checkins in SF (http://bit.ly/19qzJ31), paintings of a retro sci-fi
Sweden (http://bit.ly/19qzJje), and software for making 3-D models
from 2-D images (http://bit.ly/19qzGEc).

Meeting times for local R user groups (http://bit.ly/eC5YQe) can be
found on the updated R Community Calendar at: http://bit.ly/bb3naW

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com . Don't forget you can also
follow the blog using an RSS reader, or by following me on Twitter
(I'm @revodavid).

Cheers,
# David
-- 
David M Smith <david at revolutionanalytics.com>
VP of Marketing, Revolution Analytics  http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Seattle WA, USA)
Twitter: @revodavid
We're hiring! www.revolutionanalytics.com/careers


From soconnor at lakeheadu.ca  Thu Oct 10 22:08:17 2013
From: soconnor at lakeheadu.ca (Sheri O'Connor)
Date: Thu, 10 Oct 2013 16:08:17 -0400
Subject: [R] Help with expression()
Message-ID: <CABf=2VFJgBHsMYt4p-YJLca9BJEe1yLrfZ_RWwqhSwsJTv69xQ@mail.gmail.com>

Hi everyone,

I am hoping someone can help with my attempted use of the expression
function. I have a long series of text and variable to paste together
including a degree symbol. The text is to be placed on my scatter plot
using the mtext function.

Using expression like this:

changetext = expression(paste("Change from ",mini," to ", maxi, ":",
diff ,degree,"C",collapse=""))

does not evaluate my user defined variables - mini,maxi, and diff -
just printing them out as words

Using expression like this:

changetext = paste("Change from ",mini," to ", maxi, ":", diff
,expression(degree,"C"),collapse="")

prints the text twice and does not evaluate the degree symbol.

I have tried to place the expression alone in a variable and then run the paste:

degsym = expression(degree,"C")
changetext = paste("Change from ",mini," to ", maxi, ":", diff
,degsym,collapse="")

giving me the same result as the second option

Is there any way I can use the expression function as in the first
example but still have R evaluate my user defined variables?

Thanks!
Sheri

---
Sheri O'Connor
M.Sc Candidate
Department of Biology
Lakehead University  - Thunder Bay/Orillia
500 University Avenue
Orillia, ON L3V 0B9


From praveensripati at gmail.com  Thu Oct 10 22:41:19 2013
From: praveensripati at gmail.com (Praveen Sripati)
Date: Thu, 10 Oct 2013 21:41:19 +0100
Subject: [R] Error while running MR using rmr2
Message-ID: <CADYHM8wWd6NhNu2b0=kb12pjR1kHCgmhkeiyG52J8t_j+uikbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/97e0ab02/attachment.pl>

From jim at bitwrit.com.au  Thu Oct 10 23:40:10 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 11 Oct 2013 08:40:10 +1100
Subject: [R] pairs plot
In-Reply-To: <CAAjnpdjovx2CrYqFkwqYZq068mTUDbJu2AWgHA=N0DACco2DVQ@mail.gmail.com>
References: <CAAjnpdjovx2CrYqFkwqYZq068mTUDbJu2AWgHA=N0DACco2DVQ@mail.gmail.com>
Message-ID: <52571EBA.1050607@bitwrit.com.au>

On 10/11/2013 02:01 AM, Witold E Wolski wrote:
> my data are matrix with 3 numeric columns.
>
> would like to have pairs plot
> with scatterplots in the upper
> with hist at the diag
> and with correlation at the lower.
>
> actually default pairs does almost what I want but looks semi awesome.
> Especially, i didn't find out how to remove the axes from the lower
> part where I do only want to display the numeric values correlations
> there and somehow axes don't fit.
>
> Hence I am looking at ggpairs from GGally
> and calling it without parameters looks almost perfect :
> but I cant find out how they got the Corr: in the upper, so I can't
> put it in the lower,
> and I do not know how to put the hist in the diag.
>
Hi Witold,
The example below is roughly what you want, I think. This could be 
wrapped up in a function similar to "pairs" and I might do this in 
future if I get the time.

wwdat<-data.frame(a=seq(1,5,length.out=20)+rnorm(20),
  b=seq(1,4,length.out=20)+rnorm(20),c=rnorm(20))
require(plotrix)
panes(matrix(1:9,nrow=3,byrow=TRUE),c(1.2,1,1.2),c(1.2,1,1.2))
# plot 1
par(mar=c(0,3,3,0))
hist(wwdat$a,xaxt="n",xlab="",ylab="",main="")
box()
# plot 2
par(mar=c(0,0,3,0))
plot(wwdat$a,wwdat$b,xaxt="n",yaxt="n",xlab="",ylab="")
axis(3)
# plot 3
par(mar=c(0,0,3,3))
plot(wwdat$a,wwdat$c,xaxt="n",yaxt="n",xlab="",ylab="")
axis(3)
axis(4)
# plot 4
par(mar=c(0,3,0,0))
plot(0,0,xlim=c(-1,1),ylim=c(-1,1),xaxt="n",yaxt="n",xlab="",ylab="",type="n")
text(0,0,round(cor(wwdat$a,wwdat$b),2),cex=2.5)
# plot 5
par(mar=c(0,0,0,0))
hist(wwdat$b,xaxt="n",yaxt="n",xlab="",ylab="",main="")
# plot 6
par(mar=c(0,0,0,3))
plot(wwdat$b,wwdat$c,xaxt="n",yaxt="n",xlab="",ylab="")
axis(4)
# plot 7
par(mar=c(3,3,0,0))
plot(0,0,xlim=c(-1,1),ylim=c(-1,1),xaxt="n",yaxt="n",xlab="",ylab="",type="n")
text(0,0,round(cor(wwdat$c,wwdat$a),2),cex=2.5)
# plot 8
par(mar=c(3,0,0,0))
plot(0,0,xlim=c(-1,1),ylim=c(-1,1),xaxt="n",yaxt="n",xlab="",ylab="",type="n")
text(0,0,round(cor(wwdat$c,wwdat$b),2),cex=2.5)
# plot 9
par(mar=c(3,0,0,3))
hist(wwdat$c,xaxt="n",yaxt="n",xlab="",ylab="",main="")
axis(4)
box()

Jim


From gybrg at leeds.ac.uk  Thu Oct 10 23:56:31 2013
From: gybrg at leeds.ac.uk (Benjamin Gillespie)
Date: Thu, 10 Oct 2013 22:56:31 +0100
Subject: [R] Possible loop/ if statement query
In-Reply-To: <1381371866.95009.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <894643FDEA3A854A89B3E828737E2B1F016520962902@HERMES8.ds.leeds.ac.uk>
	<1381364394.34823.YahooMailNeo@web142606.mail.bf1.yahoo.com>,
	<1381371866.95009.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <894643FDEA3A854A89B3E828737E2B1F016520962909@HERMES8.ds.leeds.ac.uk>

Fantastic - once again, thanks Arun - your knowledge is very impressive!

Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o
________________________________________
From: arun [smartpink111 at yahoo.com]
Sent: 10 October 2013 03:24
To: Benjamin Gillespie
Cc: R help
Subject: Re: [R] Possible loop/ if statement query

Hi,
Try:
b1<- b

b1[!b1>=7]<- NA

lst1 <- split(b1,cumsum(c(0,abs(diff(b>=7)))))
 indx <- as.logical(((seq_along(lst1)-1)%%2))


lst1[indx]<- lapply(seq_along(lst1[indx]),function(i) {lst1[indx][[i]]<- rep(i,length(lst1[indx][[i]]))})
 C2 <- unlist(lst1,use.names=FALSE)

 all.equal(c1,C2)
#[1] TRUE


A.K.

----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Benjamin Gillespie <gybrg at leeds.ac.uk>
Cc:
Sent: Wednesday, October 9, 2013 8:19 PM
Subject: Re: [R] Possible loop/ if statement query

Hi,

There should be a simpler way with cumsum(diff()).


b=c((1:10),sort(1:9,decreasing=TRUE),(2:12),sort(6:11,decreasing=TRUE),(7:13))
b1<- b
c1=c( NA,NA,NA,NA,NA,NA,1,1,1,1,1,1,1,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2,2,2,2,2,2,2,2,2,2,2,NA,3,3,3,3,3,3,3)


 rl1<- rle(b1>=7)
 indx1<-(cumsum(rl1$lengths)+1)[!rl1$values]
 indx2<-(cumsum(rl1$lengths))[rl1$values]
b1[!b1>=7] <- NA

 lst1<- split(sort(c(indx1,indx2)),((seq_along(sort(c(indx1,indx2)))-1)%/%2)+1)
mat1<- sapply(seq_along(lst1),function(i) {x<- lst1[[i]];  b1[seq(x[1],x[2])]<- i; b1  })

indx2New<- !is.na(mat1[,2]) & mat1[,2]==2
 indx3New<- !is.na(mat1[,3]) & mat1[,3]==3
 mat1[!is.na(mat1[,1]) & mat1[,1]>3,1] <- c(mat1[,2][indx2New],mat1[,3][indx3New])
 all.equal(c1,mat1[,1])
#[1] TRUE


A.K.





----- Original Message -----
From: Benjamin Gillespie <gybrg at leeds.ac.uk>
To: "r-help at R-project.org" <r-help at r-project.org>
Cc:
Sent: Wednesday, October 9, 2013 6:39 PM
Subject: [R] Possible loop/ if statement query

Dear r genii,

I hope you can help.

I have vector 'b':

b=c((1:10),sort(1:9,decreasing=TRUE),(2:12),sort(6:11,decreasing=TRUE),(7:13))

and, from 'b' I wish to create vector 'c':

c=c(    NA,NA,NA,NA,NA,NA,1,1,1,1,1,1,1,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2,2,2,2,2,2,2,2,2,2,2,NA,3,3,3,3,3,3,3)

The rules I want to use to create 'c' are:

A numeric of equal to, or over 7 in 'b' needs to result in a numeric (i.e. not NA) in 'c';
A numeric of less than 7 in 'b' needs to result in "NA" in 'c';
Where 'groups' of numerics equal to, or over 7 in 'b' are present (i.e. next to each other in the list), the numerics produced in 'c' all need to be the same;
Each 'group' of numerics in 'b' must result in a unique numeric  in 'c' (and, ideally, they should run in sequence as in 'c' above (1,2,3...).

If anyone has any idea where to start on this or can crack it I'll be most grateful!!

Many thanks in advance,

Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Oct 11 00:19:59 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 10 Oct 2013 22:19:59 +0000
Subject: [R] Help with expression()
In-Reply-To: <CABf=2VFJgBHsMYt4p-YJLca9BJEe1yLrfZ_RWwqhSwsJTv69xQ@mail.gmail.com>
References: <CABf=2VFJgBHsMYt4p-YJLca9BJEe1yLrfZ_RWwqhSwsJTv69xQ@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C349D6D@PA-MBX01.na.tibco.com>

> changetext = expression(paste("Change from ",mini," to ", maxi, ":",
> diff ,degree,"C",collapse=""))
> 
> does not evaluate my user defined variables - mini,maxi, and diff -
> just printing them out as words

bquote() can do it: put the variables which should be evaluated in .().  E.g.,
    mini <- 13
    maxi <- 97
    diff <- maxi - mini
    plot(0, 0, main=bquote("Change from" ~ .(mini) ~ "to" ~ .(maxi) * ":" ~ .(diff) ~ degree ~ "C"))

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Sheri O'Connor
> Sent: Thursday, October 10, 2013 1:08 PM
> To: R-help at r-project.org
> Subject: [R] Help with expression()
> 
> Hi everyone,
> 
> I am hoping someone can help with my attempted use of the expression
> function. I have a long series of text and variable to paste together
> including a degree symbol. The text is to be placed on my scatter plot
> using the mtext function.
> 
> Using expression like this:
> 
> changetext = expression(paste("Change from ",mini," to ", maxi, ":",
> diff ,degree,"C",collapse=""))
> 
> does not evaluate my user defined variables - mini,maxi, and diff -
> just printing them out as words
> 
> Using expression like this:
> 
> changetext = paste("Change from ",mini," to ", maxi, ":", diff
> ,expression(degree,"C"),collapse="")
> 
> prints the text twice and does not evaluate the degree symbol.
> 
> I have tried to place the expression alone in a variable and then run the paste:
> 
> degsym = expression(degree,"C")
> changetext = paste("Change from ",mini," to ", maxi, ":", diff
> ,degsym,collapse="")
> 
> giving me the same result as the second option
> 
> Is there any way I can use the expression function as in the first
> example but still have R evaluate my user defined variables?
> 
> Thanks!
> Sheri
> 
> ---
> Sheri O'Connor
> M.Sc Candidate
> Department of Biology
> Lakehead University  - Thunder Bay/Orillia
> 500 University Avenue
> Orillia, ON L3V 0B9
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Fri Oct 11 00:21:48 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 10 Oct 2013 15:21:48 -0700
Subject: [R] Problems with R
In-Reply-To: <AC17B0FD8CEB8444824648A95638A60DAC6D8B0E@mbx05.adf.bham.ac.uk>
References: <AC17B0FD8CEB8444824648A95638A60DAC6D8B0E@mbx05.adf.bham.ac.uk>
Message-ID: <29b65896-e68b-43fe-a266-7f5e8c9a7ce0@email.android.com>

Wow, that really sounds terrible. Is someone making you use R? For my tasks it is generally an improvement over other tools. Sometimes it can be a bit puzzling, but often the result works more reliably and it gives me warnings when my data are messed up. If you have a better tool for your work, perhaps you should use that.

If you want help on this list, complaining is not going to be very productive, though. In addition to telling us what you are trying to accomplish, you need to show us what you are doing so we can point out where you are going wrong.  You might find http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example helpful.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Mash Hamid <MXH191 at bham.ac.uk> wrote:
>Hi,
>
>I have recently installed R and am trying to do some work on it. To be
>honest I'm finding it a PAIN to you. I use Mac and I can open stata
>dta. files in R despite using the commands suggested to me and I have
>been trying to get figure out how to do reduced rank regression on it
>and the manual is not very useful.
>
>Can you help?
>
>Thanks,
>
>Mash
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gybrg at leeds.ac.uk  Fri Oct 11 00:35:29 2013
From: gybrg at leeds.ac.uk (Benjamin Gillespie)
Date: Thu, 10 Oct 2013 23:35:29 +0100
Subject: [R] Splitting times into groups based on a range of times
Message-ID: <894643FDEA3A854A89B3E828737E2B1F01652096290B@HERMES8.ds.leeds.ac.uk>

Hi all,

I hope you can help with this one!

I have a dataframe: 'df' that consists of a vector of times: 'dt2' and a vector of group id's: 'group':

dates2=rep("01/02/13",times=8)
times2=c("12:00:00","12:30:00","12:45:00","13:15:00","13:30:00","14:00:00","14:45:00","17:30:00")
y =paste(dates2, times2)
dt2=strptime(y, "%m/%d/%y %H:%M:%S")
group=c(1,1,2,2,3,3,4,4)
df=data.frame(dt2,group)

I also have a vector: 'dt' which is a series of times:

dates=rep("01/02/13",times=20)
times=c("12:00:00","12:15:00","12:30:00","12:45:00","13:00:00","13:15:00","13:30:00","13:45:00","14:00:00","14:15:00","14:30:00","14:45:00","15:00:00","15:15:00","15:30:00","15:45:00","16:00:00","16:15:00","16:30:00","16:45:00","17:00:00","17:15:00","17:30:00","17:45:00")
x =paste(dates, times)
dt=strptime(x, "%m/%d/%y %H:%M:%S")

I wish to create a vector which looks like 'id':

id=c(1,1,1,2,2,2,3,3,3,0,0,4,4,4,4,4,4,4,4,4,4,4,4,0)

The rules I wish to follow to create 'id' are:

1. If a value in 'dt' is either equal to, or, within the range of times within group x in dataframe 'df', then, the value in 'id' will equal x.

So, for example, in 'df', group 4 is between the times of "14:45:00" and "17:30:00" on the "01/02/13". Thus, the 12th to 23rd value in 'id' equals 4 as these values correspond to times within 'dt' that are equal to and within the range of  "14:45:00" and "17:30:00" on the "01/02/13".

If this doesn't make sense, please ask,

I'm not sure where to even start with this... possibly the 'cut' function?

Many thanks in advance,

Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o

From epgreen at gmail.com  Fri Oct 11 00:38:50 2013
From: epgreen at gmail.com (Eric Green)
Date: Thu, 10 Oct 2013 18:38:50 -0400
Subject: [R] Bootstrap (bootSem) causes R to crash
In-Reply-To: <e3f1c861-450e-43b9-871b-e60ac97e4bdb@googlegroups.com>
References: <1363784149641-4661900.post@n4.nabble.com>
	<1363799864468-4661944.post@n4.nabble.com>
	<000001ce2592$6dc89d40$4959d7c0$@mcmaster.ca>
	<e3f1c861-450e-43b9-871b-e60ac97e4bdb@googlegroups.com>
Message-ID: <BEE261EBE3DD41649E299DD1EDF09EC8@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/1ad178f4/attachment.pl>

From davidmarino838 at gmail.com  Fri Oct 11 02:02:26 2013
From: davidmarino838 at gmail.com (Marino David)
Date: Fri, 11 Oct 2013 08:02:26 +0800
Subject: [R] Gaussian Quadrature for arbitrary PDF
Message-ID: <CABmD0bEYbM350tYxQTuRLv2ddNq+8pOu6KqTrhTbdNMzb61iuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/00e6c674/attachment.pl>

From spencer.graves at structuremonitoring.com  Fri Oct 11 02:19:54 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Thu, 10 Oct 2013 17:19:54 -0700
Subject: [R] Gaussian Quadrature for arbitrary PDF
In-Reply-To: <CABmD0bEYbM350tYxQTuRLv2ddNq+8pOu6KqTrhTbdNMzb61iuA@mail.gmail.com>
References: <CABmD0bEYbM350tYxQTuRLv2ddNq+8pOu6KqTrhTbdNMzb61iuA@mail.gmail.com>
Message-ID: <5257442A.3030807@structuremonitoring.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/c61700fc/attachment.pl>

From spencer.graves at structuremonitoring.com  Fri Oct 11 02:31:46 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Thu, 10 Oct 2013 17:31:46 -0700
Subject: [R] Gaussian Quadrature for arbitrary PDF
In-Reply-To: <CABmD0bEYbM350tYxQTuRLv2ddNq+8pOu6KqTrhTbdNMzb61iuA@mail.gmail.com>
References: <CABmD0bEYbM350tYxQTuRLv2ddNq+8pOu6KqTrhTbdNMzb61iuA@mail.gmail.com>
Message-ID: <525746F2.80903@structuremonitoring.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/9374c8df/attachment.pl>

From davidmarino838 at gmail.com  Fri Oct 11 02:47:56 2013
From: davidmarino838 at gmail.com (Marino David)
Date: Fri, 11 Oct 2013 08:47:56 +0800
Subject: [R] Gaussian Quadrature for arbitrary PDF
In-Reply-To: <525746F2.80903@structuremonitoring.com>
References: <CABmD0bEYbM350tYxQTuRLv2ddNq+8pOu6KqTrhTbdNMzb61iuA@mail.gmail.com>
	<525746F2.80903@structuremonitoring.com>
Message-ID: <CABmD0bHQstzG+YEboF7upiJoTKjhjy6TPNHYpnkXRKRcChs+og@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/e89eaa92/attachment.pl>

From rolf.turner at vodafone.co.nz  Fri Oct 11 03:11:29 2013
From: rolf.turner at vodafone.co.nz (Rolf Turner)
Date: Fri, 11 Oct 2013 14:11:29 +1300
Subject: [R] Small p from binomial probability function.
In-Reply-To: <142413609C0A60488585AB47438ECD9D015BEA44@ueastfexch01.UEA.AC.UK>
References: <142413609C0A60488585AB47438ECD9D015BE871@ueastfexch01.UEA.AC.UK>,
	<45FE3A4B-86AB-49A4-B4E4-05B2479953A8@collocations.de>
	<142413609C0A60488585AB47438ECD9D015BEA44@ueastfexch01.UEA.AC.UK>
Message-ID: <52575041.2090304@vodafone.co.nz>



It is mysterious to me why the procedure proposed by Stefan Evert works.
It appears to work --- once you modify the call to binom.test() to have the
correct syntax.  In a sequence of 1000  trials with random values of N, x,
and p0, the answers from Evert's procedure agreed with the answer given
by uniroot() to within +/- 3.045e-05.

However your question was (in effect) how to solve the equation

     Pr(X <= x) = p0

for p, where X ~ Binom(N,p), with N and x known.  What this has to do with
confidence intervals for p is, to my mind at least, completely opaque.
In contrast it is obvious why the procedure using uniroot() works.

I would suggest that you stick with the uniroot() procedure in that it is
readily comprehensible.

     cheers,

     Rolf Turner

On 10/11/13 03:56, Benjamin Ward (ENV) wrote:
> Hi,
>
> Thank you for your answers, I'm not completely sure if it's to bino.test I need or the uniroot. Perhaps I should explain more the idea behind the code and the actual task I'm trying to do. The idea is to calculate a confidence interval as to the age of two DNA sequences which have diverged, where I know the number of mutations that happened in them, and I know the mutation rate.
>
> The binomial probability can be used since, mutations have a probability of occurring or being observed so many times in a sequence. This is dependent on the length of the DNA stretch (which equates to the number of trials since each base is a possibility of observing a mutation), the probability of a single mutation occurring which is p = t * u, since more time means a higher probability a mutation may have occurred.
>
> So my code, using pbinom, is supposed to calculate the probability that my DNA stretches contain the number of mutations observed P(X = k), given their size (trials) and the probability of a single mutation (p = t * u). However I'm interested in finding t: t is what is unknown, so the loop repeatedly evaluates the calculation, increasing t each time and checking P(X=k), when it is 0.05, 0.50 and 0.95, we record t.
>
> Ideally I'd like to rearrange this so I can get the probability of a single success (mutation) p, and then divide by the mutation rate to get my t. My supervisor gave my the loopy code but I imagine there is a way to plug in P(X=k) as 0.05 and 0.95 and get my upper and lower t estimates.
>
> According to the R built in docs:
>
> binom.test
> Description:
>
>       Performs an exact test of a simple null hypothesis about the
>       probability of success in a Bernoulli experiment.
>
> Perhaps this is the one I need rather than uniroot?
>
> Best,
> Ben.
>
>
> ________________________________________
> From: Stefan Evert [stefanML at collocations.de]
> Sent: 10 October 2013 09:37
> To: R-help Mailing List
> Cc: Benjamin Ward (ENV)
> Subject: Re: [R] Small p from binomial probability function.
>
> Sounds like you want a 95% binomial confidence interval:
>
>          binom.test(N, P)
>
> will compute this for you, and you can get the bounds directly with
>
>          binom.test(N, P)$conf.int
>
> Actually, binom.test computes a two-sided confidence interval, which corresponds roughly to 2.5 and 97.5 percentages in your approach. It doesn't give you the 50% point either, but I don't think that's a meaningful quantity with a two-sided test.
>
> Hope this helps,
> Stefan
>
>
> On 9 Oct 2013, at 15:53, Benjamin Ward (ENV) <B.Ward at uea.ac.uk> wrote:
>
>> I got given some code that uses the R function pbionom:
>>
>> p <- mut * t
>> sumprobs <- pbinom( N, B, p ) * 1000
>>
>> Which gives the output of a probability as a percentage like 5, 50, 95.
>>
>> What the code currently does is find me the values of t I need, by using the above two code lines in a loop, each iteration it increaces t by one and runs the two lines. When sumprobs equals 5, it records the value t, then again when sumprobs is equal to 50, and again when sumprobs is equal to 95 - giving me three t values. This is not an efficient way of doing this if t is large. Is it possible to rearrange pbinom so it gives me the small p (made of mut*t) as the result of plugging in the sumprobs instead, and is there an R function that already does this?
>>
>> Since pbinom is the binomial probability equation I suppose the question is - in more mathematical terminology - can I change this code so that instead of calculating the Probability of N successes given the number of trials and the probability of a single success, can I instead calculate the probability of a single success using the probability of N successes and number of trials, and the number of successes? Can R do this for me. So instead I plug in 5, 50, and 95, and then get the small p out?


From smartpink111 at yahoo.com  Fri Oct 11 03:29:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 10 Oct 2013 18:29:58 -0700 (PDT)
Subject: [R] Splitting times into groups based on a range of times
In-Reply-To: <894643FDEA3A854A89B3E828737E2B1F01652096290B@HERMES8.ds.leeds.ac.uk>
References: <894643FDEA3A854A89B3E828737E2B1F01652096290B@HERMES8.ds.leeds.ac.uk>
Message-ID: <1381454998.88168.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi Ben,

I would look into ?findInterval() or ?cut() for an easier solution.
indx<- match(df[,1],as.POSIXct(dt))
?indx2<- unique(df[,2])
lst1<- lapply(split(indx,((seq_along(indx)-1)%/%2)+1),function(x) seq(x[1], x[2]))
?res <- unlist(lapply(seq_along(lst1),function(i) {
??? ??? ??? ??? ??? ??? ??? val<-rep(indx2[i],length(lst1[[i]]))
???????????????????????????????????????????????????? names(val)<-lst1[[i]]
?????????????????????????????????????????????????????????? val
??? ??? ??? ??? ??? ??? ??? ? }))
res1<-res[match(seq_along(dt),names(res))]
?res1[is.na(res1)]<- 0
?names(res1)<- NULL
?res1
# [1] 1 1 1 2 2 2 3 3 3 0 0 4 4 4 4 4 4 4 4 4 4 4 4 0
identical(id,res1)
#[1] TRUE




On Thursday, October 10, 2013 8:10 PM, Benjamin Gillespie <gybrg at leeds.ac.uk> wrote:
Hi all,

I hope you can help with this one!

I have a dataframe: 'df' that consists of a vector of times: 'dt2' and a vector of group id's: 'group':

dates2=rep("01/02/13",times=8)
times2=c("12:00:00","12:30:00","12:45:00","13:15:00","13:30:00","14:00:00","14:45:00","17:30:00")
y =paste(dates2, times2)
dt2=strptime(y, "%m/%d/%y %H:%M:%S")
group=c(1,1,2,2,3,3,4,4)
df=data.frame(dt2,group)

I also have a vector: 'dt' which is a series of times:

dates=rep("01/02/13",times=20)
times=c("12:00:00","12:15:00","12:30:00","12:45:00","13:00:00","13:15:00","13:30:00","13:45:00","14:00:00","14:15:00","14:30:00","14:45:00","15:00:00","15:15:00","15:30:00","15:45:00","16:00:00","16:15:00","16:30:00","16:45:00","17:00:00","17:15:00","17:30:00","17:45:00")
x =paste(dates, times)
dt=strptime(x, "%m/%d/%y %H:%M:%S")

I wish to create a vector which looks like 'id':

id=c(1,1,1,2,2,2,3,3,3,0,0,4,4,4,4,4,4,4,4,4,4,4,4,0)

The rules I wish to follow to create 'id' are:

1. If a value in 'dt' is either equal to, or, within the range of times within group x in dataframe 'df', then, the value in 'id' will equal x.

So, for example, in 'df', group 4 is between the times of "14:45:00" and "17:30:00" on the "01/02/13". Thus, the 12th to 23rd value in 'id' equals 4 as these values correspond to times within 'dt' that are equal to and within the range of? "14:45:00" and "17:30:00" on the "01/02/13".

If this doesn't make sense, please ask,

I'm not sure where to even start with this... possibly the 'cut' function?

Many thanks in advance,

Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From rolf.turner at vodafone.co.nz  Fri Oct 11 03:36:35 2013
From: rolf.turner at vodafone.co.nz (Rolf Turner)
Date: Fri, 11 Oct 2013 14:36:35 +1300
Subject: [R] Small p from binomial probability function.
In-Reply-To: <142413609C0A60488585AB47438ECD9D015BEA44@ueastfexch01.UEA.AC.UK>
References: <142413609C0A60488585AB47438ECD9D015BE871@ueastfexch01.UEA.AC.UK>,
	<45FE3A4B-86AB-49A4-B4E4-05B2479953A8@collocations.de>
	<142413609C0A60488585AB47438ECD9D015BEA44@ueastfexch01.UEA.AC.UK>
Message-ID: <52575623.3000606@vodafone.co.nz>



I've figured it out.  It ***is*** "obvious" why Evert's procedure works.
Once you hold your head at the correct angle, as my first year calculus 
lecturer
used to say.

The binom.test() confidence interval gives you the value of a random 
variable
say "U" (for "upper") such that

     Pr(U < p) = p0

where U is a function of the observed binomial random variable, say U = 
h(X).

The observed value of U is h(x), where x is the observed value of X.

Now we want p such that Pr(X <= x) = p0 where X ~ Binom(N,p).

But when X ~ Binom(N,p),

     Pr(U <= p) = p0, i.e
     Pr(h(X) <= p) = p0, so if we take p = h(x) we have
     Pr(h(X) <= h(x)) = p0, whence
     Pr(X <= x) = p0 as desired.

Still twists my head, but.

     cheers,

     Rolf Turner


From dwinsemius at comcast.net  Fri Oct 11 03:38:38 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 10 Oct 2013 18:38:38 -0700
Subject: [R] help for compare regression coefficients across groups
In-Reply-To: <CAG43sE+fyDJxuOJidRayL8hGSOw+Auj7ug1_99isyKjWYJmURQ@mail.gmail.com>
References: <CAG43sE+fyDJxuOJidRayL8hGSOw+Auj7ug1_99isyKjWYJmURQ@mail.gmail.com>
Message-ID: <96822F47-D9A1-4F5E-BC13-491031C8972D@comcast.net>


On Oct 10, 2013, at 3:44 AM, Andreia Fonseca wrote:

> Dear all
> 
> I have data related to cell count across time in 2 different types of
> cells. I have transformed the count data using a log
> and I want to test the H0: B cell_ttype1=Bcell_type2  across time
> 
> for that I am fitting the following model
> 
> fit_all<-lm(data$count~data$cell_type+data$time+data$cell_type*data$time)
> 
> the output is
> 
> Coefficients:
>                             Estimate Std. Error t value Pr(>|t|)
> (Intercept)                 1.0450021  0.0286824  36.434   <2e-16 ***
> data$cell_typeOV           -0.0456669  0.0405631  -1.126    0.271
> data$time                   0.0115620  0.0004815  24.015   <2e-16 ***
> data$cell_typeOV:data$time -0.0009764  0.0006809  -1.434    0.164
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> Residual standard error: 0.06318 on 26 degrees of freedom
> Multiple R-squared:  0.9764,    Adjusted R-squared:  0.9737
> F-statistic: 358.8 on 3 and 26 DF,  p-value: < 2.2e-16
> 
> 
> inspite the fact that the p-value of he interaction is >0.05 may I still
> conclude that B cell_ttype1 is different from Bcell_type2 because the
> p-value of the fit is lower<0.05?

You have offered the output of an interaction model and only provided the Wald statistics on terms, which is a situation where those values are usually meaningless. Furthermore,  you have not described the study or the data in any detail. You should seek competent local consultation at your institution. If you get an answer based only on this information, that should result in a lower opinion (in the Bayesian sense) of the competence of the responder.

-- 
David.

> 
> Thanks in advance for your help.
> 
> With kind regards,
> 
> Andreia
> 
> -- 
> ---------------------------------------------------------------------------------------------
> Andreia J. Amaral, PhD
> BioFIG - Center for Biodiversity, Functional and Integrative Genomics
> Instituto de Medicina Molecular
> University of Lisbon
> Tel: +352 217500000 (ext. office: 28253)
> email:andreiaamaral at fm.ul.pt ; andreiaamaral at fc.ul.pt
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From valkremk at gmail.com  Fri Oct 11 04:35:11 2013
From: valkremk at gmail.com (Val)
Date: Thu, 10 Oct 2013 22:35:11 -0400
Subject: [R] summary and plot
Message-ID: <CAJOiR6aMDLedaq9RkEbzJio_VP+p2a1qGuJpUS=c2wdtEQa_QQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/b05a0577/attachment.pl>

From rmh at temple.edu  Fri Oct 11 05:04:41 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 10 Oct 2013 23:04:41 -0400
Subject: [R] summary and plot
In-Reply-To: <CAJOiR6aMDLedaq9RkEbzJio_VP+p2a1qGuJpUS=c2wdtEQa_QQ@mail.gmail.com>
References: <CAJOiR6aMDLedaq9RkEbzJio_VP+p2a1qGuJpUS=c2wdtEQa_QQ@mail.gmail.com>
Message-ID: <CAGx1TMDt1k8HGqjX+z0-F5zZd-LxA1ocMV+RqCMAWF9GFup5VA@mail.gmail.com>

## I would use the likert function in the HH package

## if necessary
## install.packages("HH")
## install.packages("reshape")

library(HH)

library(reshape)


pop <- read.table(header=TRUE, text="
city year sex  obs
1      1990  M  25
1      1990  F   32
1      1991  M  15
1      1991  F   22
2      1990  M  42
2      1990  F  36
2      1991  M  12
2      1991  F  16
")

popwide <- cast(val, city + year ~ sex, value="obs")
popwide

likert(city ~ F + M | year, data=popwide, as.percent=TRUE,
       main="F M population by city within year")

likert(year ~ F + M | city, data=popwide, as.percent=TRUE,
       main="F M population by year within city")

## Rich

On Thu, Oct 10, 2013 at 10:35 PM, Val <valkremk at gmail.com> wrote:
> Hi All,
>
> I have a  huge data set with the following type;
>   city year sex  obs
> 1      1990  M  25
> 1      1990  F   32
> 1      1991  M  15
> 1      1991  F   22
> 2      1990  M  42
> 2      1990  F  36
> 2      1991  M  12
> 2      1991  F  16
>
> I want to calculate the percentage of M and F  by city, year and year
> within city and also plot.
> city 1    total Male= 40;  total female= 54;
>                    %M= 40/(40+54)=42.6
>                     %F= 54/(40+54)=57.4
>
> and so on.
>
> Can any body help me out?
>
> Thanks in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Fri Oct 11 05:19:41 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 10 Oct 2013 23:19:41 -0400
Subject: [R] summary and plot
In-Reply-To: <CAGx1TMDt1k8HGqjX+z0-F5zZd-LxA1ocMV+RqCMAWF9GFup5VA@mail.gmail.com>
References: <CAJOiR6aMDLedaq9RkEbzJio_VP+p2a1qGuJpUS=c2wdtEQa_QQ@mail.gmail.com>
	<CAGx1TMDt1k8HGqjX+z0-F5zZd-LxA1ocMV+RqCMAWF9GFup5VA@mail.gmail.com>
Message-ID: <CAGx1TMDwRahzdGwDurwYJ7kFZ2r_3u84BZuYSDiS_38csMLsWA@mail.gmail.com>

This is better for plotting the percents

likert(city ~ F + M | year, data=popwide, as.percent="noRightAxis",
       main="F M population by city within year")

likert(year ~ F + M | city, data=popwide, as.percent="noRightAxis",
       main="F M population by year within city")


We can also plot the populations

likert(city ~ F + M | year, data=popwide,
       main="F M population by city within year")

likert(year ~ F + M | city, data=popwide,
       main="F M population by year within city")


The row count totals in the percent plots in my previous email belong
only to the first panel.
This is a bug that I will need to fix.

Rich

On Thu, Oct 10, 2013 at 11:04 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> ## I would use the likert function in the HH package
>
> ## if necessary
> ## install.packages("HH")
> ## install.packages("reshape")
>
> library(HH)
>
> library(reshape)
>
>
> pop <- read.table(header=TRUE, text="
> city year sex  obs
> 1      1990  M  25
> 1      1990  F   32
> 1      1991  M  15
> 1      1991  F   22
> 2      1990  M  42
> 2      1990  F  36
> 2      1991  M  12
> 2      1991  F  16
> ")
>
> popwide <- cast(val, city + year ~ sex, value="obs")
> popwide
>
> likert(city ~ F + M | year, data=popwide, as.percent=TRUE,
>        main="F M population by city within year")
>
> likert(year ~ F + M | city, data=popwide, as.percent=TRUE,
>        main="F M population by year within city")
>
> ## Rich
>
> On Thu, Oct 10, 2013 at 10:35 PM, Val <valkremk at gmail.com> wrote:
>> Hi All,
>>
>> I have a  huge data set with the following type;
>>   city year sex  obs
>> 1      1990  M  25
>> 1      1990  F   32
>> 1      1991  M  15
>> 1      1991  F   22
>> 2      1990  M  42
>> 2      1990  F  36
>> 2      1991  M  12
>> 2      1991  F  16
>>
>> I want to calculate the percentage of M and F  by city, year and year
>> within city and also plot.
>> city 1    total Male= 40;  total female= 54;
>>                    %M= 40/(40+54)=42.6
>>                     %F= 54/(40+54)=57.4
>>
>> and so on.
>>
>> Can any body help me out?
>>
>> Thanks in advance
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Oct 11 05:28:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 10 Oct 2013 20:28:22 -0700 (PDT)
Subject: [R] summary and plot
In-Reply-To: <CAJOiR6aMDLedaq9RkEbzJio_VP+p2a1qGuJpUS=c2wdtEQa_QQ@mail.gmail.com>
References: <CAJOiR6aMDLedaq9RkEbzJio_VP+p2a1qGuJpUS=c2wdtEQa_QQ@mail.gmail.com>
Message-ID: <1381462102.64388.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
May be:
dat1<- read.table(text="city year sex? obs
1????? 1990? M? 25
1????? 1990? F? 32
1????? 1991? M? 15
1????? 1991? F? 22
2????? 1990? M? 42
2????? 1990? F? 36
2????? 1991? M? 12
2????? 1991? F? 16",sep="",header=TRUE,stringsAsFactors=FALSE)

library(plyr)
#by city
?d1 <- ddply(dat1,.(city),summarize,Tot=sum(obs))
?d2 <- ddply(dat1,.(city,sex),summarize,Tot=sum(obs))
?res <- merge(d1,d2,by="city")
?res$percent <- round((res$Tot.y/res$Tot.x)*100,1)
library(plotrix)
?plot(percent~city,data=res,type="p")
?thigmophobe.labels(res$city,res$percent,labels=res$sex)


#by year
d1 <- ddply(dat1,.(year),summarize,Tot=sum(obs))
?d2 <- ddply(dat1,.(year,sex),summarize,Tot=sum(obs))
?res2 <- merge(d1,d2,by="year")
?res2$percent <- round((res2$Tot.y/res2$Tot.x)*100,1)

plot(percent~year,data=res2,type="p",xaxt="n")
?axis(1,at=res2$year,labels=res2$year)
? thigmophobe.labels(res2$year,res2$percent,labels=res2$sex)

A.K.




On Thursday, October 10, 2013 10:37 PM, Val <valkremk at gmail.com> wrote:
Hi All,

I have a? huge data set with the following type;
? city year sex? obs
1? ? ? 1990? M? 25
1? ? ? 1990? F?  32
1? ? ? 1991? M? 15
1? ? ? 1991? F?  22
2? ? ? 1990? M? 42
2? ? ? 1990? F? 36
2? ? ? 1991? M? 12
2? ? ? 1991? F? 16

I want to calculate the percentage of M and F? by city, year and year
within city and also plot.
city 1? ? total Male= 40;? total female= 54;
? ? ? ? ? ? ? ? ?  %M= 40/(40+54)=42.6
? ? ? ? ? ? ? ? ? ? %F= 54/(40+54)=57.4

and so on.

Can any body help me out?

Thanks in advance

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From nilsson.henric at gmail.com  Thu Oct 10 23:55:20 2013
From: nilsson.henric at gmail.com (Henric Winell)
Date: Thu, 10 Oct 2013 23:55:20 +0200
Subject: [R] Permutation tests in {coin}
In-Reply-To: <CAO7OmOh_iobkDuP1OasQt3LJvR9U-70f2Oxb4fY40w0KQcW0vA@mail.gmail.com>
References: <CAO7OmOh_iobkDuP1OasQt3LJvR9U-70f2Oxb4fY40w0KQcW0vA@mail.gmail.com>
Message-ID: <52572248.60805@gmail.com>

Lars Bishop skrev 2013-10-05 22:17:
> Hello,
>
> I'm trying to get familiar with the coin package for doing
> permutation tests. I'm not sure I understand the documentation
> regarding the difference between distribution = "asymptotic" and
> "approximate" in the function independence_test.

The use of "asymptotic" or "approximate" leads to two different 
approximations of the exact conditional distribution under the null 
hypothesis.

The basis of 'coin' is a multivariate linear test statistic, and it can 
be shown (Strasser and Weber, 1999) that its conditional distribution is 
asymptotically normally distributed under the null hypothesis 
("asymptotic").  Alternatively, another approximative conditional null 
distribution can be obtained using conditional Monte Carlo procedures 
("approximate").

> Are permutations of the test statistic actually computed in the
> asymptotic case, or only when the distribution is specified as
> approximate?

In the asymptotic case, the univariate normal distribution is used when 
the test statistic is a scalar and the chi-squared distribution is used 
when the test statistics is a quadratic form.  For a multivariate 
maximum-type test, permutations may be used in the asymptotic case but 
only in the sense that probabilities from the corresponding multivariate 
normal distribution are obtained by numerical integration using Monte 
Carlo procedures.  In the latter case, the 'mvtnorm' package is used and 
further details can be found in its documentation.

In the approximate case, permutations are always used irrespective of 
the type of test statistic.

> When should I use each option?

You should only use "asymptotic" in situations where you trust the
asymptotic approximation. ;-)  In all other cases, use "approximate" or,
if possible, "exact".


HTH,
Henric



>
> Thanks Lars.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________ R-help at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
> read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From njlr at sun.ac.za  Fri Oct 11 00:08:21 2013
From: njlr at sun.ac.za (Le Roux, NJ, Prof <njlr@sun.ac.za>)
Date: Thu, 10 Oct 2013 22:08:21 +0000
Subject: [R] Assessing compiled code in base packages
Message-ID: <5C66091D3267C34685DA58B8786C90DF286040C4@STBEXMB01.stb.sun.ac.za>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/645b9558/attachment.pl>

From soconnor at lakeheadu.ca  Fri Oct 11 01:11:39 2013
From: soconnor at lakeheadu.ca (Sheri O'Connor)
Date: Thu, 10 Oct 2013 19:11:39 -0400
Subject: [R] Help with expression()
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C349D6D@PA-MBX01.na.tibco.com>
References: <CABf=2VFJgBHsMYt4p-YJLca9BJEe1yLrfZ_RWwqhSwsJTv69xQ@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C349D6D@PA-MBX01.na.tibco.com>
Message-ID: <CABf=2VEw7UQFnmixhBUPuSryQZv5p+eVUEc6f5XV6jbuQx--WA@mail.gmail.com>

Thanks very much! bquote() did the trick!

on Thu, Oct 10, 2013 at 6:19 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> changetext = expression(paste("Change from ",mini," to ", maxi, ":",
>> diff ,degree,"C",collapse=""))
>>
>> does not evaluate my user defined variables - mini,maxi, and diff -
>> just printing them out as words
>
> bquote() can do it: put the variables which should be evaluated in .().  E.g.,
>     mini <- 13
>     maxi <- 97
>     diff <- maxi - mini
>     plot(0, 0, main=bquote("Change from" ~ .(mini) ~ "to" ~ .(maxi) * ":" ~ .(diff) ~ degree ~ "C"))
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Sheri O'Connor
>> Sent: Thursday, October 10, 2013 1:08 PM
>> To: R-help at r-project.org
>> Subject: [R] Help with expression()
>>
>> Hi everyone,
>>
>> I am hoping someone can help with my attempted use of the expression
>> function. I have a long series of text and variable to paste together
>> including a degree symbol. The text is to be placed on my scatter plot
>> using the mtext function.
>>
>> Using expression like this:
>>
>> changetext = expression(paste("Change from ",mini," to ", maxi, ":",
>> diff ,degree,"C",collapse=""))
>>
>> does not evaluate my user defined variables - mini,maxi, and diff -
>> just printing them out as words
>>
>> Using expression like this:
>>
>> changetext = paste("Change from ",mini," to ", maxi, ":", diff
>> ,expression(degree,"C"),collapse="")
>>
>> prints the text twice and does not evaluate the degree symbol.
>>
>> I have tried to place the expression alone in a variable and then run the paste:
>>
>> degsym = expression(degree,"C")
>> changetext = paste("Change from ",mini," to ", maxi, ":", diff
>> ,degsym,collapse="")
>>
>> giving me the same result as the second option
>>
>> Is there any way I can use the expression function as in the first
>> example but still have R evaluate my user defined variables?
>>
>> Thanks!
>> Sheri
>>
>> ---
>> Sheri O'Connor
>> M.Sc Candidate
>> Department of Biology
>> Lakehead University  - Thunder Bay/Orillia
>> 500 University Avenue
>> Orillia, ON L3V 0B9
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From irasharenow100 at yahoo.com  Fri Oct 11 06:45:24 2013
From: irasharenow100 at yahoo.com (Ira Sharenow)
Date: Thu, 10 Oct 2013 21:45:24 -0700
Subject: [R] iconv question: SQL Server 2005 to R
In-Reply-To: <52564A3C.6080107@stats.ox.ac.uk>
References: <52548F03.2030504@yahoo.com> <1381311436.2948.57.camel@milan>
	<52564A3C.6080107@stats.ox.ac.uk>
Message-ID: <52578264.4080801@yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131010/aee394dc/attachment.pl>

From Alex.Johnson at theaa.com  Fri Oct 11 10:04:32 2013
From: Alex.Johnson at theaa.com (Johnson, Alex)
Date: Fri, 11 Oct 2013 09:04:32 +0100
Subject: [R]  automation of an R script to run
Message-ID: <6DBEEF9C09ACF64B8BCFE8F66EDA1B1F05622725@aa-exb01.theaa.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/6e671d05/attachment.pl>

From michel.arnaud at cirad.fr  Fri Oct 11 11:01:37 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Fri, 11 Oct 2013 11:01:37 +0200
Subject: [R] ggplot2 : to change the title of legend
Message-ID: <5257BE71.2050304@cirad.fr>

Hello
I don't arrive to change the title of the legend
My code is :
library(ggplot2)
ma <- max(General$AgeChangCat) ; mi <- min(General$AgeChangCat)
Test$Recrutement <- factor(Test$CadNonCadRecrut)
p <-
ggplot(Test, aes(x=factor(Cat1), y=AgeChangCat )) +
ylim(mi,ma) +
geom_point() +
geom_boxplot(aes(fill = Recrutement)) +
labs(title = "Age", x="cat?gorie", y="Age") +
theme(legend.position = c(0.1,0.9), legend.background = 
element_rect(colour = "black"))
p

any idea ?

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From nalimilan at club.fr  Fri Oct 11 11:43:35 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Fri, 11 Oct 2013 11:43:35 +0200
Subject: [R] iconv question: SQL Server 2005 to R
In-Reply-To: <52578264.4080801@yahoo.com>
References: <52548F03.2030504@yahoo.com> <1381311436.2948.57.camel@milan>
	<52564A3C.6080107@stats.ox.ac.uk> <52578264.4080801@yahoo.com>
Message-ID: <1381484615.2948.105.camel@milan>

Le jeudi 10 octobre 2013 ? 21:45 -0700, Ira Sharenow a ?crit :
> Thanks for the suggestion. From R version 3.0.2, I tried
> 
>  
> 
> > testDF7 =  iconv(x = test07 , from = "UCS-2", to = "")
> 
> > Encoding(testDF7)
> 
> [1] "unknown"
> 
>  
> 
> > testDF7[1:6]
> 
> [1] NA NA NA NA NA NA
> 
>  
> 
> So using "UCS-2" produced the same results as before.
> 
>  
> 
> I do not think there are any NA values. I cleaned up the csv file from
> within Excel. Then read it into R
> 
> > sum(is.na(workingDF)) 
> 
> [1] 0
> 
>  
> 
> Also the Excel COUNTBLANK function gave me zero.
In a previous message, Brian told you to use the 'fileEncoding' argument
to read.table(). Please do that.


Regards

> On 10/9/2013 11:33 PM, Prof Brian Ripley wrote:
> 
> > On 09/10/2013 10:37, Milan Bouchet-Valat wrote: 
> > > Le mardi 08 octobre 2013 ? 16:02 -0700, Ira Sharenow a ?crit : 
> > > > A colleague is sending me quite a few files that have been saved
> > > > with MS 
> > > > SQL Server 2005. I am using R 2.15.1 on Windows 7. 
> > > > 
> > > > I am trying to read in the files using standard techniques.
> > > > Although the 
> > > > file has a csv extension when I go to Excel or WordPad and do
> > > > SAVE AS I 
> > > > see that it is Unicode Text. Notepad indicates that the encoding
> > > > is 
> > > > Unicode. Right now I have to do a few things from within Excel
> > > > (such as 
> > > > Text to Columns) and eventually save as a true csv file before I
> > > > can 
> > > > read it into R and then use it. 
> > > > 
> > > > Is there an easy way to solve this from within R? I am also open
> > > > to easy 
> > > > SQL Server 2005 solutions. 
> > > > 
> > > > I tried the following from within R. 
> > > > 
> > > > testDF = read.table("Info06.csv", header = TRUE, sep = ",") 
> > > > 
> > > > > testDF2 =  iconv(x = testDF, from = "Unicode", to = "") 
> > > > 
> > > > Error in iconv(x = testDF, from = "Unicode", to = "") : 
> > > > 
> > > > unsupported conversion from 'Unicode' to '' in codepage 1252 
> > > > 
> > > > # The next line did not produce an error message 
> > > > 
> > > > > testDF3 =  iconv(x = testDF, from = "UTF-8" , to = "") 
> > > > 
> > > > > testDF3[1:6,  1:3] 
> > > > 
> > > > Error in testDF3[1:6, 1:3] : incorrect number of dimensions 
> > > > 
> > > > # The next line did not produce an error message 
> > > > 
> > > > > testDF4 =  iconv(x = testDF, from = "macroman" , to = "") 
> > > > 
> > > > > testDF4[1:6,  1:3] 
> > > > 
> > > > Error in testDF4[1:6, 1:3] : incorrect number of dimensions 
> > > > 
> > > > >   Encoding(testDF3) 
> > > > 
> > > > [1] "unknown" 
> > > > 
> > > > >   Encoding(testDF4) 
> > > > 
> > > > [1] "unknown" 
> > > > 
> > > > This is the first few lines from WordPad 
> > > > 
> > > > Date,StockID,Price,MktCap,ADV,SectorID,Days,A1,std1,std2 
> > > > 
> > > > 2006-01-03 
> > > > 00:00:00.000, at Stock1,2.53,467108197.38,567381.144444444,4,133.14486997089,-0.0162107939626307,0.0346283580367959,0.0126471695454834 
> > > > 
> > > > 2006-01-03 
> > > > 00:00:00.000, at Stock2,1.3275,829803070.531114,6134778.93292,5,124.632223896458,0.071513138376339,0.0410694546850102,0.0172091268025929 
> > > What's the actual problem? You did not state any. Do you get
> > > accentuated 
> > > characters that are not printed correctly after importing the
> > > file? In 
> > > the two lines above it does not look like there would be any
> > > non-ASCII 
> > > characters in this file, so encoding would not matter. 
> > 
> > It is most likely UCS-2.  That has embedded NULs, so the encoding
> > does matter.  All 8-bit encodings extend ASCII: others do not, in
> > general. 
> > 
> > 
>


From ajdamico at gmail.com  Fri Oct 11 12:31:20 2013
From: ajdamico at gmail.com (Anthony Damico)
Date: Fri, 11 Oct 2013 06:31:20 -0400
Subject: [R] automation of an R script to run
In-Reply-To: <6DBEEF9C09ACF64B8BCFE8F66EDA1B1F05622725@aa-exb01.theaa.local>
References: <6DBEEF9C09ACF64B8BCFE8F66EDA1B1F05622725@aa-exb01.theaa.local>
Message-ID: <CAOwvMDxLF1-Kza5abU-cwdZOffiK_NzD=LMhR9xEZ_gw+wqW7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/a0c091a3/attachment.pl>

From rstirnemann at gmail.com  Fri Oct 11 13:00:31 2013
From: rstirnemann at gmail.com (Rebecca Stirnemann)
Date: Sat, 12 Oct 2013 00:00:31 +1300
Subject: [R] How to altering the colour of confidence intervals in a lattice.
Message-ID: <CACBnbk7opi=NKatS0dAH97PHseQfJ8-ycqjM5TkjRUL5-Ok=Xw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131012/e04f1f80/attachment.pl>

From Olivier.Eterradossi at mines-ales.fr  Fri Oct 11 14:08:57 2013
From: Olivier.Eterradossi at mines-ales.fr (Olivier Eterradossi)
Date: Fri, 11 Oct 2013 12:08:57 +0000
Subject: [R] behaviour of read.xls (gdata package) when worksheet
	usesuser-defined cells formats
Message-ID: <D2481C4481A28E4DB7720AE86BE937616DC260D6@SRV-AME-EX2KX.personnel.mines-ales.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/8467882e/attachment.pl>

From S.Ellison at lgcgroup.com  Fri Oct 11 14:22:27 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Fri, 11 Oct 2013 13:22:27 +0100
Subject: [R] Problems with R
In-Reply-To: <AC17B0FD8CEB8444824648A95638A60DAC6D8B0E@mbx05.adf.bham.ac.uk>
References: <AC17B0FD8CEB8444824648A95638A60DAC6D8B0E@mbx05.adf.bham.ac.uk>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487E43078@GOLD.corp.lgc-group.com>

> I have recently installed R and am trying to do some work on it. 
Congratulations; you are learning one of (possibly the) world's most powerful statistics environments.

> To be honest I'm finding it a PAIN to [use?]. 
You can have cheap, powerful, easy to use statistics software. Pick any two. 
Hm. On second thoughts, pick any one. All really powerful statistics software costs a lot in learning time even if it's free to install.
But the initial barriers subside quite fast with determination. I recall it took me about two days to work out how to get a one-way ANOVA done, but once I had a five-factor ANOVA with partial nesting was a breeze.
 
> Can you help?
With great power comes great responsibility.
Have you read the posting guide for this mailing list and carried out all of the steps indicated in "Do your homework before posting"? Especially the bit about reading the relevant books and literature that explain and give examples of what different packages do?
Also look at the bit about posting reproducible code so that folk can see what you're attempting to do. Without that, the only help anyone can reasonably give is to tell you to read and follow the posting guide. 

S





*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From friendly at yorku.ca  Fri Oct 11 14:31:38 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 11 Oct 2013 08:31:38 -0400
Subject: [R] Help required graphing factors with predicted model settings
In-Reply-To: <CACBnbk4+oo=C9NA71NsBRaaV1VuwndZvyFf-c5uFvL+GidzW8A@mail.gmail.com>
References: <CACBnbk4Ur4sdLSqar34o9ZEazq4JFhSkSCoBgPCku+zrs_h-pw@mail.gmail.com>
	<52562E34.6000308@bitwrit.com.au>
	<CACBnbk5A1jkjJ4m8R00PTGbOMbDXLbp2Ju2Hzvge8fd_9w98qg@mail.gmail.com>
	<5256A073.8070008@yorku.ca>
	<CACBnbk4+oo=C9NA71NsBRaaV1VuwndZvyFf-c5uFvL+GidzW8A@mail.gmail.com>
Message-ID: <5257EFAA.9020908@yorku.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/48114b44/attachment.pl>

From petr.pikal at precheza.cz  Fri Oct 11 14:58:00 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 11 Oct 2013 12:58:00 +0000
Subject: [R] ggplot2 : to change the title of legend
In-Reply-To: <5257BE71.2050304@cirad.fr>
References: <5257BE71.2050304@cirad.fr>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B968B6@SRVEXCHMBX.precheza.cz>

Hi

I usually use scale....

something like
scale_fill_discrete(name = "Fancy Title")
shall do the trick

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Arnaud Michel
> Sent: Friday, October 11, 2013 11:02 AM
> To: R help
> Subject: [R] ggplot2 : to change the title of legend
> 
> Hello
> I don't arrive to change the title of the legend My code is :
> library(ggplot2)
> ma <- max(General$AgeChangCat) ; mi <- min(General$AgeChangCat)
> Test$Recrutement <- factor(Test$CadNonCadRecrut) p <- ggplot(Test,
> aes(x=factor(Cat1), y=AgeChangCat )) +
> ylim(mi,ma) +
> geom_point() +
> geom_boxplot(aes(fill = Recrutement)) +
> labs(title = "Age", x="cat?gorie", y="Age") + theme(legend.position =
> c(0.1,0.9), legend.background = element_rect(colour = "black")) p
> 
> any idea ?
> 
> --
> Michel ARNAUD
> Charg? de mission aupr?s du DRH
> DGDRD-Drh - TA 174/04
> Av Agropolis 34398 Montpellier cedex 5
> tel : 04.67.61.75.38
> fax : 04.67.61.57.87
> port: 06.47.43.55.31
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Fri Oct 11 15:06:18 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 11 Oct 2013 13:06:18 +0000
Subject: [R] Possible loop/ if statement query
In-Reply-To: <894643FDEA3A854A89B3E828737E2B1F016520962902@HERMES8.ds.leeds.ac.uk>
References: <894643FDEA3A854A89B3E828737E2B1F016520962902@HERMES8.ds.leeds.ac.uk>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B968C6@SRVEXCHMBX.precheza.cz>

Hi

not sure if it is the most efficient and clever solution

ifelse(b<7, NA, cumsum(c(0,diff(!(b<7)))==1))

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Benjamin Gillespie
> Sent: Thursday, October 10, 2013 12:39 AM
> To: r-help at R-project.org
> Subject: [R] Possible loop/ if statement query
> 
> Dear r genii,
> 
> I hope you can help.
> 
> I have vector 'b':
> 
> b=c((1:10),sort(1:9,decreasing=TRUE),(2:12),sort(6:11,decreasing=TRUE),
> (7:13))
> 
> and, from 'b' I wish to create vector 'c':
> 
> c=c(
> 	NA,NA,NA,NA,NA,NA,1,1,1,1,1,1,1,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,
> 2,2,2,2,2,2,2,2,2,2,2,NA,3,3,3,3,3,3,3)
> 
> The rules I want to use to create 'c' are:
> 
> A numeric of equal to, or over 7 in 'b' needs to result in a numeric
> (i.e. not NA) in 'c'; A numeric of less than 7 in 'b' needs to result
> in "NA" in 'c'; Where 'groups' of numerics equal to, or over 7 in 'b'
> are present (i.e. next to each other in the list), the numerics
> produced in 'c' all need to be the same; Each 'group' of numerics in
> 'b' must result in a unique numeric  in 'c' (and, ideally, they should
> run in sequence as in 'c' above (1,2,3...).
> 
> If anyone has any idea where to start on this or can crack it I'll be
> most grateful!!
> 
> Many thanks in advance,
> 
> Ben Gillespie, Research Postgraduate
> o-------------------------------------------------------------------o
> School of Geography, University of Leeds, Leeds, LS2 9JT o-------------
> ------------------------------------------------------o
> Tel: +44(0)113 34 33345
> Mob: +44(0)770 868 7641
> o-------------------------------o
> http://www.geog.leeds.ac.uk/
> o-------------------------------------o
> @RiversBenG
> o--------------o
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From steven.ranney at gmail.com  Fri Oct 11 15:26:08 2013
From: steven.ranney at gmail.com (Steven Ranney)
Date: Fri, 11 Oct 2013 07:26:08 -0600
Subject: [R] Create sequential vector for values in another column
Message-ID: <CANDt99oCb1a8YT0mHfYPNf2GCKEF2sX+-BTzTx3L7w_JDsojOA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/c545823c/attachment.pl>

From michel.arnaud at cirad.fr  Fri Oct 11 15:27:41 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Fri, 11 Oct 2013 15:27:41 +0200
Subject: [R] ggplot2 : to change the title of legend
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B968B6@SRVEXCHMBX.precheza.cz>
References: <5257BE71.2050304@cirad.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B968B6@SRVEXCHMBX.precheza.cz>
Message-ID: <5257FCCD.4070204@cirad.fr>

OK It is right
Thank you Petr
Michel
Le 11/10/2013 14:58, PIKAL Petr a ?crit :
> Hi
>
> I usually use scale....
>
> something like
> scale_fill_discrete(name = "Fancy Title")
> shall do the trick
>
> Regards
> Petr
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Arnaud Michel
>> Sent: Friday, October 11, 2013 11:02 AM
>> To: R help
>> Subject: [R] ggplot2 : to change the title of legend
>>
>> Hello
>> I don't arrive to change the title of the legend My code is :
>> library(ggplot2)
>> ma <- max(General$AgeChangCat) ; mi <- min(General$AgeChangCat)
>> Test$Recrutement <- factor(Test$CadNonCadRecrut) p <- ggplot(Test,
>> aes(x=factor(Cat1), y=AgeChangCat )) +
>> ylim(mi,ma) +
>> geom_point() +
>> geom_boxplot(aes(fill = Recrutement)) +
>> labs(title = "Age", x="cat?gorie", y="Age") + theme(legend.position =
>> c(0.1,0.9), legend.background = element_rect(colour = "black")) p
>>
>> any idea ?
>>
>> --
>> Michel ARNAUD
>> Charg? de mission aupr?s du DRH
>> DGDRD-Drh - TA 174/04
>> Av Agropolis 34398 Montpellier cedex 5
>> tel : 04.67.61.75.38
>> fax : 04.67.61.57.87
>> port: 06.47.43.55.31
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From smartpink111 at yahoo.com  Fri Oct 11 15:43:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 11 Oct 2013 06:43:28 -0700 (PDT)
Subject: [R] Create sequential vector for values in another column
In-Reply-To: <1381498580.16406.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <CANDt99oCb1a8YT0mHfYPNf2GCKEF2sX+-BTzTx3L7w_JDsojOA@mail.gmail.com>
	<1381498580.16406.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1381499008.44200.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Also,

it might be faster to use ?data.table()
library(data.table)
?dt1<- data.table(dat1,key='id.name')
dt1[,x:=seq(.N),by='id.name']
A.K.


On , arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
dat1<- 

structure(list(id.name = c(123.45, 123.45, 123.45, 123.45, 234.56, 
234.56, 234.56, 234.56, 234.56, 234.56, 234.56, 345.67, 345.67, 
345.67, 456.78, 456.78, 456.78, 456.78, 456.78, 456.78, 456.78, 
456.78, 456.78)), .Names = "id.name", class = "data.frame", row.names = c(NA, 
-23L))
dat1$x <- with(dat1,ave(id.name,id.name,FUN=seq))
A.K.



On Friday, October 11, 2013 9:28 AM, Steven Ranney <steven.ranney at gmail.com> wrote:
Hello all -

I have an example column in a dataFrame

id.name
123.45
123.45
123.45
123.45
234.56
234.56
234.56
234.56
234.56
234.56
234.56
345.67
345.67
345.67
456.78
456.78
456.78
456.78
456.78
456.78
456.78
456.78
456.78
...
[truncated]

And I'd like to create a second vector of sequential values (i.e., 1:N) for
each unique id.name value.? In other words, I need

id.name? x
123.45?? 1
123.45?? 2
123.45?? 3
123.45?? 4
234.56?? 1
234.56?? 2
234.56?? 3
234.56?? 4
234.56?? 5
234.56?? 6
234.56?? 7
345.67?? 1
345.67?? 2
345.67?? 3
456.78?? 1
456.78?? 2
456.78?? 3
456.78?? 4
456.78?? 5
456.78?? 6
456.78?? 7
456.78?? 8
456.78?? 9

The number of unique id.name values is different; for some values, nrow()
may be 42 and for others it may be 36, etc.

The only way I could think of to do this is with two nested for loops.? I
tried it but because this data set is so large (nrow = 112,679 with 2,161
unique values of id.name), it took several hours to run.

Is there an easier way to create this vector?? I'd appreciate your thoughts.

Thanks -

SR
Steven H. Ranney

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From marine.regis at hotmail.fr  Fri Oct 11 15:45:10 2013
From: marine.regis at hotmail.fr (Marine Regis)
Date: Fri, 11 Oct 2013 15:45:10 +0200
Subject: [R] Mixed models with overdispersion
Message-ID: <DUB115-W630F024BEEA8BBFD6DD32CE21F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/fdb04aff/attachment.pl>

From epgreen at gmail.com  Fri Oct 11 15:46:32 2013
From: epgreen at gmail.com (Eric Green)
Date: Fri, 11 Oct 2013 09:46:32 -0400
Subject: [R] Bootstrap (bootSem) causes R to crash
In-Reply-To: <BEE261EBE3DD41649E299DD1EDF09EC8@gmail.com>
References: <1363784149641-4661900.post@n4.nabble.com>
	<1363799864468-4661944.post@n4.nabble.com>
	<000001ce2592$6dc89d40$4959d7c0$@mcmaster.ca>
	<e3f1c861-450e-43b9-871b-e60ac97e4bdb@googlegroups.com>
	<BEE261EBE3DD41649E299DD1EDF09EC8@gmail.com>
Message-ID: <AF851FFB61C0457DB27743ECDAFB432E@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/0622aad3/attachment.pl>

From vksingh.iiitb at gmail.com  Fri Oct 11 15:48:36 2013
From: vksingh.iiitb at gmail.com (vivek)
Date: Fri, 11 Oct 2013 21:48:36 +0800
Subject: [R] automation of an R script to run
In-Reply-To: <6DBEEF9C09ACF64B8BCFE8F66EDA1B1F05622725@aa-exb01.theaa.local>
References: <6DBEEF9C09ACF64B8BCFE8F66EDA1B1F05622725@aa-exb01.theaa.local>
Message-ID: <001201cec688$973073f0$c5915bd0$@gmail.com>


Steps:

1. write your code in R command line format
2. save to a .sh file
3. Add to cron of linux machine

Regards,
Vivek
-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Johnson, Alex
Sent: Friday, October 11, 2013 4:05 PM
To: r-help at r-project.org
Subject: [R] automation of an R script to run

Hi,

 

I was wondering if there is there a way you can schedule an R script to run
automatically through a scheduled task in windows or similar?..

Would R have to be open on the user's PC or could it be closed providing we
pointed it correctly at R?...


Thank you

 

Alex

 

Alex Johnson

Operational Research Analyst

The AA

01256 492133 / Ext 622133

 

Automobile Association Developments Limited. Registered office: Fanum House,
Basing View, Basingstoke, RG21 4EA. Registered in England and Wales Number:
01878835 

 

"To our Members we're the 4th Emergency Service"
This electronic message contains information from The Au...{{dropped:8}}


From petr.pikal at precheza.cz  Fri Oct 11 15:49:24 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 11 Oct 2013 13:49:24 +0000
Subject: [R] Create sequential vector for values in another column
In-Reply-To: <CANDt99oCb1a8YT0mHfYPNf2GCKEF2sX+-BTzTx3L7w_JDsojOA@mail.gmail.com>
References: <CANDt99oCb1a8YT0mHfYPNf2GCKEF2sX+-BTzTx3L7w_JDsojOA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B96A06@SRVEXCHMBX.precheza.cz>

Hi

I named your data test

test$x<-1
test$x<-unlist(lapply(split(test$x, test$id.name), cumsum))
> test
   id.name x
1   123.45 1
2   123.45 2
3   123.45 3
4   123.45 4
5   234.56 1
6   234.56 2
7   234.56 3
8   234.56 4
9   234.56 5
10  234.56 6
11  234.56 7
12  345.67 1
13  345.67 2
14  345.67 3
15  456.78 1
16  456.78 2
17  456.78 3
18  456.78 4
19  456.78 5
20  456.78 6
21  456.78 7
22  456.78 8
23  456.78 9
>
Two comments:
This works only when your data are sorted
Beware of FAQ 7.31

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Steven Ranney
> Sent: Friday, October 11, 2013 3:26 PM
> To: r-help at r-project.org
> Subject: [R] Create sequential vector for values in another column
> 
> Hello all -
> 
> I have an example column in a dataFrame
> 
> id.name
> 123.45
> 123.45
> 123.45
> 123.45
> 234.56
> 234.56
> 234.56
> 234.56
> 234.56
> 234.56
> 234.56
> 345.67
> 345.67
> 345.67
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> ...
> [truncated]
> 
> And I'd like to create a second vector of sequential values (i.e., 1:N)
> for each unique id.name value.  In other words, I need
> 
> id.name  x
> 123.45   1
> 123.45   2
> 123.45   3
> 123.45   4
> 234.56   1
> 234.56   2
> 234.56   3
> 234.56   4
> 234.56   5
> 234.56   6
> 234.56   7
> 345.67   1
> 345.67   2
> 345.67   3
> 456.78   1
> 456.78   2
> 456.78   3
> 456.78   4
> 456.78   5
> 456.78   6
> 456.78   7
> 456.78   8
> 456.78   9
> 
> The number of unique id.name values is different; for some values,
> nrow() may be 42 and for others it may be 36, etc.
> 
> The only way I could think of to do this is with two nested for loops.
> I tried it but because this data set is so large (nrow = 112,679 with
> 2,161 unique values of id.name), it took several hours to run.
> 
> Is there an easier way to create this vector?  I'd appreciate your
> thoughts.
> 
> Thanks -
> 
> SR
> Steven H. Ranney
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Fri Oct 11 15:58:03 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 11 Oct 2013 15:58:03 +0200
Subject: [R] Create sequential vector for values in another column
In-Reply-To: <CANDt99oCb1a8YT0mHfYPNf2GCKEF2sX+-BTzTx3L7w_JDsojOA@mail.gmail.com>
References: <CANDt99oCb1a8YT0mHfYPNf2GCKEF2sX+-BTzTx3L7w_JDsojOA@mail.gmail.com>
Message-ID: <A72C9624-EA9D-449B-BF5D-7507A9B4E499@xs4all.nl>


On 11-10-2013, at 15:26, Steven Ranney <steven.ranney at gmail.com> wrote:

> Hello all -
> 
> I have an example column in a dataFrame
> 
> id.name
> 123.45
> 123.45
> 123.45
> 123.45
> 234.56
> 234.56
> 234.56
> 234.56
> 234.56
> 234.56
> 234.56
> 345.67
> 345.67
> 345.67
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> ...
> [truncated]
> 
> And I'd like to create a second vector of sequential values (i.e., 1:N) for
> each unique id.name value.  In other words, I need
> 
> id.name  x
> 123.45   1
> 123.45   2
> 123.45   3
> 123.45   4
> 234.56   1
> 234.56   2
> 234.56   3
> 234.56   4
> 234.56   5
> 234.56   6
> 234.56   7
> 345.67   1
> 345.67   2
> 345.67   3
> 456.78   1
> 456.78   2
> 456.78   3
> 456.78   4
> 456.78   5
> 456.78   6
> 456.78   7
> 456.78   8
> 456.78   9
> 
> The number of unique id.name values is different; for some values, nrow()
> may be 42 and for others it may be 36, etc.
> 
> The only way I could think of to do this is with two nested for loops.  I
> tried it but because this data set is so large (nrow = 112,679 with 2,161
> unique values of id.name), it took several hours to run.
> 
> Is there an easier way to create this vector?  I'd appreciate your thoughts.

I named your dataframe dat1.
You can also do this

unlist(sapply(rle(dat1$id.name)$lengths, function(k) 1:k ))

And as Petr told you: beware of FAQ 7.31

Berend


From irasharenow100 at yahoo.com  Fri Oct 11 16:27:59 2013
From: irasharenow100 at yahoo.com (Ira Sharenow)
Date: Fri, 11 Oct 2013 07:27:59 -0700
Subject: [R] iconv question: SQL Server 2005 to R
In-Reply-To: <1381484615.2948.105.camel@milan>
References: <52548F03.2030504@yahoo.com> <1381311436.2948.57.camel@milan>
	<52564A3C.6080107@stats.ox.ac.uk> <52578264.4080801@yahoo.com>
	<1381484615.2948.105.camel@milan>
Message-ID: <52580AEF.8060303@yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/8663d0fc/attachment.pl>

From smartpink111 at yahoo.com  Fri Oct 11 16:50:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 11 Oct 2013 07:50:33 -0700 (PDT)
Subject: [R] Splitting times into groups based on a range of times
In-Reply-To: <1381454998.88168.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <894643FDEA3A854A89B3E828737E2B1F01652096290B@HERMES8.ds.leeds.ac.uk>
	<1381454998.88168.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1381503033.68071.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Also,

df1 <- do.call(rbind,lapply(split(df,df$group),function(x) data.frame(dt2=seq(x[1,1],x[nrow(x),1],by="15 min"),group=x[1,2])))
id1<- df1[,2][match(as.POSIXct(dt),df1[,1])]
?id1[is.na(id1)]<- 0
?identical(id1,id)
#[1] TRUE
A.K,


On Thursday, October 10, 2013 9:29 PM, arun <smartpink111 at yahoo.com> wrote:
Hi Ben,

I would look into ?findInterval() or ?cut() for an easier solution.
indx<- match(df[,1],as.POSIXct(dt))
?indx2<- unique(df[,2])
lst1<- lapply(split(indx,((seq_along(indx)-1)%/%2)+1),function(x) seq(x[1], x[2]))
?res <- unlist(lapply(seq_along(lst1),function(i) {
??? ??? ??? ??? ??? ??? ??? val<-rep(indx2[i],length(lst1[[i]]))
???????????????????????????????????????????????????? names(val)<-lst1[[i]]
?????????????????????????????????????????????????????????? val
??? ??? ??? ??? ??? ??? ??? ? }))
res1<-res[match(seq_along(dt),names(res))]
?res1[is.na(res1)]<- 0
?names(res1)<- NULL
?res1
# [1] 1 1 1 2 2 2 3 3 3 0 0 4 4 4 4 4 4 4 4 4 4 4 4 0
identical(id,res1)
#[1] TRUE





On Thursday, October 10, 2013 8:10 PM, Benjamin Gillespie <gybrg at leeds.ac.uk> wrote:
Hi all,

I hope you can help with this one!

I have a dataframe: 'df' that consists of a vector of times: 'dt2' and a vector of group id's: 'group':

dates2=rep("01/02/13",times=8)
times2=c("12:00:00","12:30:00","12:45:00","13:15:00","13:30:00","14:00:00","14:45:00","17:30:00")
y =paste(dates2, times2)
dt2=strptime(y, "%m/%d/%y %H:%M:%S")
group=c(1,1,2,2,3,3,4,4)
df=data.frame(dt2,group)

I also have a vector: 'dt' which is a series of times:

dates=rep("01/02/13",times=20)
times=c("12:00:00","12:15:00","12:30:00","12:45:00","13:00:00","13:15:00","13:30:00","13:45:00","14:00:00","14:15:00","14:30:00","14:45:00","15:00:00","15:15:00","15:30:00","15:45:00","16:00:00","16:15:00","16:30:00","16:45:00","17:00:00","17:15:00","17:30:00","17:45:00")
x =paste(dates, times)
dt=strptime(x, "%m/%d/%y %H:%M:%S")

I wish to create a vector which looks like 'id':

id=c(1,1,1,2,2,2,3,3,3,0,0,4,4,4,4,4,4,4,4,4,4,4,4,0)

The rules I wish to follow to create 'id' are:

1. If a value in 'dt' is either equal to, or, within the range of times within group x in dataframe 'df', then, the value in 'id' will equal x.

So, for example, in 'df', group 4 is between the times of "14:45:00" and "17:30:00" on the "01/02/13". Thus, the 12th to 23rd value in 'id' equals 4 as these values correspond to times within 'dt' that are equal to and within the range of? "14:45:00" and "17:30:00" on the "01/02/13".

If this doesn't make sense, please ask,

I'm not sure where to even start with this... possibly the 'cut' function?

Many thanks in advance,

Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From pdalgd at gmail.com  Fri Oct 11 17:03:08 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 11 Oct 2013 17:03:08 +0200
Subject: [R] order() not producing results as I expect
In-Reply-To: <5256F858.3040004@gmail.com>
References: <CACZQHzwMuUBUfqqMArYu=Hx71E35afy9oS4dQHa4JOVD8jJXeQ@mail.gmail.com>
	<5256F858.3040004@gmail.com>
Message-ID: <74340B41-4C35-460B-B609-75C481541561@gmail.com>


I'd wager that the problem lies in the expectations. Karl: Read up on what order() actually does; it is not what I think you think it does. 

Perhaps 

str.dat[match(gen.names, str.dat$ind.names),]

or

rownames(str.dat) <- str.dat$ind.names
str.dat[gen.names,]

was intended? (Both untested, some adjustment may be required.)

-pd

On Oct 10, 2013, at 20:56 , Duncan Murdoch wrote:

> On 10/10/2013 12:00 PM, Karl Fetter wrote:
>> Hello,
>> 
>> I'm using R version 3.0.0 on a mac. I'm having trouble getting order to
>> behave as I expect it should. I'm trying to sort a data.frame according to
>> a character vector. I'm able to sort the data.frame, but it retruns an
>> unexpected result. I have no idea where the order that is being produced
>> comes from.
> 
> It comes from gen.names, which is not a column of your dataset.  I think you'll have to give us something reproducible before we can help you.
> 
> Duncan Murdoch
> 
>> 
>> Any ideas on how to properly order a data frame by a character vector?
>> 
>> Here is the current order of the data frame (called str.dat):
>> 
>> > head(str.dat)
>>    str.names POPINFO POPFLAG LOCDATA Loc1 Loc2 Loc3 ind.names
>> 1 alba1.pop3       3       0       1   12    3    2     alba1
>> 2 alba2.pop3       3       0       1    3    3    2     alba2
>> 3 alch1.pop4       4       0       2    2    3    2     alch1
>> 4 alch2.pop4       4       0       2    2    3    2     alch2
>> 5 alco1.pop4       4       0       3    3    3    2     alco1
>> 6 alco2.pop4       4       0       3    3    3    2     alco2
>> 
>> 
>> 
>> Here's the order I expect it to be in when I use order:
>> 
>> > head(data.frame(gen.names))
>>   gen.names
>> 1     magv1
>> 2     magv2
>> 3     magv3
>> 4     magv4
>> 5       lc1
>> 6       lc2
>> 
>> 
>> Here's the order I'm getting:
>> 
>> > head(str.dat[order(gen.names),])
>>      str.names POPINFO POPFLAG LOCDATA Loc1 Loc2 Loc3 ind.names
>> 111 ncle2.pop5       5       0      39    3    3    2     ncle2
>> 112 ncle3.pop5       5       0      39    2    2    2     ncle3
>> 146 wvma1.pop8       8       0      57    3    3    2     wvma1
>> 145 wvfa2.pop8       8       0      56    3    3    2     wvfa2
>> 55  flse6.pop2       2       0      19    2    5    4     flse6
>> 54  flse5.pop2       2       0      19    2    5    4     flse5
>> 
>> 
>> 
>> 
>> Many thanks,
>> 
>> Karl
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From nashjc at uottawa.ca  Fri Oct 11 17:11:53 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Fri, 11 Oct 2013 11:11:53 -0400
Subject: [R] Looking for package to solve for exponent using newton's
 method
In-Reply-To: <525814C3.4060607@uottawa.ca>
References: <525814C3.4060607@uottawa.ca>
Message-ID: <52581539.4000709@uottawa.ca>

And if you need some extra digits:

require(Rmpfr)
testfn<-function(x){2^x+3^x-13}
myint<-c(mpfr(-5,precBits=1000),mpfr(5,precBits=1000))
myroot<-unirootR(testfn, myint, tol=1e-30)
myroot

John Nash

On 13-10-11 06:00 AM, r-help-request at r-project.org wrote:
> Message: 33
> Date: Thu, 10 Oct 2013 21:03:00 +0200
> From: Berend Hasselman<bhh at xs4all.nl>
> To: Ken Takagi<katakagi at bu.edu>
> Cc:r-help at stat.math.ethz.ch
> Subject: Re: [R] Looking for package to solve for exponent using
> 	newton's	method
> Message-ID:<A12B1F57-A38F-470D-A6D7-479F94125BC0 at xs4all.nl>
> Content-Type: text/plain; charset="us-ascii"
>
>
> On 10-10-2013, at 20:39, Ken Takagi<katakagi at bu.edu>  wrote:
>
>> >Hi,
>> >I'm looking for an R function/package that will let me solve problems of the
>> >type:
>> >
>> >13 = 2^x + 3^x.
>> >
>> >The answer to this example is x = 2, but I'm looking for solutions when x
>> >isn't so easily determined. Looking around, it seems that there is no
>> >algebraic solution for x, unless I'm mistaken.  Does anyone know a good
>> >package to solve these types of problems? Are there built in functions to do
>> >this?
>> >
> Univariate equations can be solved with uniroot, available in base R.
>
> You can also use package nleqslv for this but that is intended for systems of nonlinear equations.
> It does however solve your equation.
> There is also BB which is especially intended for large sparse systems.
>
> Berend
>


From S.Ellison at lgcgroup.com  Fri Oct 11 17:19:13 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Fri, 11 Oct 2013 16:19:13 +0100
Subject: [R] order() not producing results as I expect
In-Reply-To: <CACZQHzwMuUBUfqqMArYu=Hx71E35afy9oS4dQHa4JOVD8jJXeQ@mail.gmail.com>
References: <CACZQHzwMuUBUfqqMArYu=Hx71E35afy9oS4dQHa4JOVD8jJXeQ@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487E43224@GOLD.corp.lgc-group.com>



> -----Original Message-----
> I'm using R version 3.0.0 on a mac. I'm having trouble getting order to
> behave as I expect it should. I'm trying to sort a data.frame according
> to  a character vector. I'm able to sort the data.frame, but it retruns an
> unexpected result. I have no idea where the order that is being
> produced comes from.
You've asked for the data frame in the order that would put gen.names in increasing value order. But the order you expect gen.names to be in after ordering is not in increasing-value order. Assuming no missing row numbers in str.dat, it looks like gen.names[111] is the first value in the order you have asked for, gen.names[112] the second (or a tie), gen.names[146] the third and so on.

So it sounds to me as if you're asking R for something you didn't want (not uncommon, btw).

And with no visible relation between the values in gen.names in your email and the values in str.dat, I'm afraid I can't see why there should be any relationship at all, never mind why you aren't getting it.

As an aside, when you asked for order(gen.names), you do realise that you have asked for the order of the whole data frame and not just the vector gen.names$gen.names, yes? In this case that's equivalent as you have a single-column data frame, but in general that might not be a very good idea.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From dwinsemius at comcast.net  Fri Oct 11 17:58:56 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 11 Oct 2013 08:58:56 -0700
Subject: [R] system2 commands with backslash
In-Reply-To: <5256C4E6.6070805@zevross.com>
References: <5256C4E6.6070805@zevross.com>
Message-ID: <FE51F261-F92B-481D-AE76-B56AA1387337@comcast.net>


On Oct 10, 2013, at 8:16 AM, Zev Ross wrote:

> Hi All,
> 
> I'm trying to edit a file in place using system2 and sed from within R. I can get my command to work unless there is a backslash in the command in which case I'm warned about an "unrecognized escape". So, for example:
> 
> system2("sed -i s/oldword/newword/g d:/junk/x/test.tex") # works fine
> system2("sed -i s/oldword\s/newword/g d:/junk/x/test.tex") # does not work in R (the command works on the command line)
> 
> I've experimented with double slashes to escape the \s,

Wouldn't you want to double the backslashes instead?

> I've tried the "shell" command, I've tried experimenting with shQuote and can't seem to get around the "unrecognized escape" issue.
> 
> By the way, it would be preferable to have a solution that avoided using double backslashes etc because, unfortunately, in my real-world example, I'm actually replacing double slashes and would prefer not to have quadruple slashes etc.
> 
> I'm using Windows 7, 64 bit.
> 
> Zev
> 
> -- 
> Zev Ross
> ZevRoss Spatial Analysis
> 120 N Aurora, Suite 3A
> Ithaca, NY 14850
> 607-277-0004 (phone)
> zev at zevross.com
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From hill0093 at umn.edu  Fri Oct 11 18:48:36 2013
From: hill0093 at umn.edu (Hurr)
Date: Fri, 11 Oct 2013 09:48:36 -0700 (PDT)
Subject: [R] labeling abscissa using a function of the plotted scale
Message-ID: <1381510115791-4678075.post@n4.nabble.com>

Is it easy or difficult to label the abscissa of a scatter graph as
1/trueScaleValue at that point?




--
View this message in context: http://r.789695.n4.nabble.com/labeling-abscissa-using-a-function-of-the-plotted-scale-tp4678075.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Fri Oct 11 18:49:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 11 Oct 2013 09:49:48 -0700 (PDT)
Subject: [R] matrix values linked to vector index
Message-ID: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

In the example you showed:

m1<- matrix(0,length(vec),max(vec))
1*!upper.tri(m1)

#or
?m1[!upper.tri(m1)] <-? rep(rep(1,length(vec)),vec)

#But, in a case like below, perhaps:
vec1<- c(3,4,5)

?m2<- matrix(0,length(vec1),max(vec1))
?indx <- cbind(rep(seq_along(vec1),vec1),unlist(tapply(vec1,list(vec1),FUN=seq),use.names=FALSE))
m2[indx]<- 1
?m2
#???? [,1] [,2] [,3] [,4] [,5]
#[1,]??? 1??? 1??? 1??? 0??? 0
#[2,]??? 1??? 1??? 1??? 1??? 0
#[3,]??? 1??? 1??? 1??? 1??? 1




A.K.


Hi- 

I'd like to create a matrix of 0's and 1's where the number of 
1's in each row defined by the value indexed in another vector, and 
where the (value-1) is back-filled by 0's. 

For example, given the following vector: 
vec= c(1,2,3) 

I'd like to produce a matrix with dimensions (length(vec), max(vec)): 

1,0,0 
1,1,0 
1,1,1 

Thank you!


From wdunlap at tibco.com  Fri Oct 11 18:50:54 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 11 Oct 2013 16:50:54 +0000
Subject: [R] Create sequential vector for values in another column
In-Reply-To: <1381499008.44200.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CANDt99oCb1a8YT0mHfYPNf2GCKEF2sX+-BTzTx3L7w_JDsojOA@mail.gmail.com>
	<1381498580.16406.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1381499008.44200.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C349F96@PA-MBX01.na.tibco.com>

At this point 3 functions have been suggested and I'll add a 4th:
  f1 <- function(x)unlist(lapply(unname(split(rep.int(1L,length(x)), x)), cumsum))
  f2 <- function(x)unlist(sapply(rle(x)$lengths, function(k) 1:k ))
  f3 <- function(x)ave(x,x,FUN=seq)
  f4 <- function(x)ave(seq_along(x), x, FUN=seq_along)
You can compare their results with ftest (as long as their results have the
same lengths):
  ftest <- function(x) {
     data.frame(x, f1=f1(x), f2=f2(x), f3=f3(x), f4=f4(x))
  }
They all return the same result for the Steven's sample data, which is numeric
and in sorted order:
  x0 <- c(123.45, 123.45, 123.45, 123.45, 234.56, 
               234.56, 234.56, 234.56, 234.56, 234.56, 234.56, 345.67, 345.67, 
               345.67, 456.78, 456.78, 456.78, 456.78, 456.78, 456.78, 456.78, 
              456.78, 456.78)
However, f1() gives the wrong answer if x is not sorted:
  > ftest(c(30,30,30, 20,20))
     x f1 f2 f3 f4
  1 30  1  1  1  1
  2 30  2  2  2  2
  3 30  1  3  3  3
  4 20  2  1  1  1
  5 20  3  2  2  2

f1() and f2() give the wrong answer if the groups are split up in the data
  > ftest(c(10,10, 8,8,8, 10,10,10)) # 10's not contiguous
     x f1 f2 f3 f4
  1 10  1  1  1  1
  2 10  2  2  2  2
  3  8  3  1  1  1
  4  8  1  2  2  2
  5  8  2  3  3  3
  6 10  3  1  3  3
  7 10  4  2  4  4
  8 10  5  3  5  5
(It is not clear what result the OP wants here.)

f3() gives the wrong answer if x is not numeric
  > f3(c("a","a","a", "b","b"))
  [1] "1" "2" "3" "1" "2"

f3() also gives an ominous warning if there is singleton in x (be
  > f3(c(1,1,1, 11))
  [1] 1 2 3 1
  Warning message:
  In `split<-.default`(`*tmp*`, g, value = lapply(split(x, g), FUN)) :
    number of items to replace is not a multiple of replacement length

f2() fails to give an answer if x is a factor
  > f2(factor(c("x","y","z")))
  Error in rle(x) : 'x' must be an atomic vector

I think f4 gives the correct result for all those cases.

I think all of the above call lapply(split()) at some point and that can use
a lot of memory when there are lots of unique values in x.  You can use
a sort-based algorithm to avoid that problem.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of arun
> Sent: Friday, October 11, 2013 6:43 AM
> To: Steven Ranney; r-help at r-project.org
> Subject: Re: [R] Create sequential vector for values in another column
> 
> 
> 
> Also,
> 
> it might be faster to use ?data.table()
> library(data.table)
> ?dt1<- data.table(dat1,key='id.name')
> dt1[,x:=seq(.N),by='id.name']
> A.K.
> 
> 
> On , arun <smartpink111 at yahoo.com> wrote:
> Hi,
> Try:
> dat1<-
> 
> structure(list(id.name = c(123.45, 123.45, 123.45, 123.45, 234.56,
> 234.56, 234.56, 234.56, 234.56, 234.56, 234.56, 345.67, 345.67,
> 345.67, 456.78, 456.78, 456.78, 456.78, 456.78, 456.78, 456.78,
> 456.78, 456.78)), .Names = "id.name", class = "data.frame", row.names = c(NA,
> -23L))
> dat1$x <- with(dat1,ave(id.name,id.name,FUN=seq))
> A.K.
> 
> 
> 
> On Friday, October 11, 2013 9:28 AM, Steven Ranney <steven.ranney at gmail.com>
> wrote:
> Hello all -
> 
> I have an example column in a dataFrame
> 
> id.name
> 123.45
> 123.45
> 123.45
> 123.45
> 234.56
> 234.56
> 234.56
> 234.56
> 234.56
> 234.56
> 234.56
> 345.67
> 345.67
> 345.67
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> 456.78
> ...
> [truncated]
> 
> And I'd like to create a second vector of sequential values (i.e., 1:N) for
> each unique id.name value.? In other words, I need
> 
> id.name? x
> 123.45?? 1
> 123.45?? 2
> 123.45?? 3
> 123.45?? 4
> 234.56?? 1
> 234.56?? 2
> 234.56?? 3
> 234.56?? 4
> 234.56?? 5
> 234.56?? 6
> 234.56?? 7
> 345.67?? 1
> 345.67?? 2
> 345.67?? 3
> 456.78?? 1
> 456.78?? 2
> 456.78?? 3
> 456.78?? 4
> 456.78?? 5
> 456.78?? 6
> 456.78?? 7
> 456.78?? 8
> 456.78?? 9
> 
> The number of unique id.name values is different; for some values, nrow()
> may be 42 and for others it may be 36, etc.
> 
> The only way I could think of to do this is with two nested for loops.? I
> tried it but because this data set is so large (nrow = 112,679 with 2,161
> unique values of id.name), it took several hours to run.
> 
> Is there an easier way to create this vector?? I'd appreciate your thoughts.
> 
> Thanks -
> 
> SR
> Steven H. Ranney
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Oct 11 19:23:02 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 11 Oct 2013 17:23:02 +0000
Subject: [R] Create sequential vector for values in another column
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C349F96@PA-MBX01.na.tibco.com>
References: <CANDt99oCb1a8YT0mHfYPNf2GCKEF2sX+-BTzTx3L7w_JDsojOA@mail.gmail.com>
	<1381498580.16406.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1381499008.44200.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C349F96@PA-MBX01.na.tibco.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C349FD9@PA-MBX01.na.tibco.com>

> I think all of the above call lapply(split()) at some point and that can use
> a lot of memory when there are lots of unique values in x.  You can use
> a sort-based algorithm to avoid that problem.

E.g.,

Sequence <-
function(nvec) {
    # like base::sequence, but faster for long nvec.  If sum(nvec)>=2^31
    # it will mess up.
   seq_len(sum(nvec)) - rep(cumsum(c(0L,nvec[-length(nvec)])), nvec)
}
f5 <-
function(x){
   ux <- unique(x)
   code <- match(x, ux)
   retval <- integer(length(x))
   retval[order(code)] <- Sequence(tabulate(code))
   retval
}

> x <- sample(rep(1:10e6, each=2)) # 10 million groups of size 2, unsorted
> system.time(r4 <- f4(x))
   user  system elapsed 
 216.74    0.29  217.14 
> system.time(r5 <- f5(x))
   user  system elapsed 
  17.26    0.01   17.27 
> identical(r4,r5)
[1] TRUE

If you know your groups are contiguous you can modify that to be faster still.

All these methods mess up if there are NA's in the data.  It is probably best
to run them on the NA-less part of the data as in
  > x <- c(10,10,10,NA,10, 20,20, 10, NA)
  > id <- integer(length(x)) + NA
  > id[!is.na(x)] <- f5(x[!is.na(x)])
  > id
  [1]  1  2  3 NA  4  1  2  5 NA
    
Don't memorize this algorithm: store the function under a name
like withinGroupSequenceNo and call the function when needed.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of William Dunlap
> Sent: Friday, October 11, 2013 9:51 AM
> To: arun; Steven Ranney; r-help at r-project.org
> Subject: Re: [R] Create sequential vector for values in another column
> 
> At this point 3 functions have been suggested and I'll add a 4th:
>   f1 <- function(x)unlist(lapply(unname(split(rep.int(1L,length(x)), x)), cumsum))
>   f2 <- function(x)unlist(sapply(rle(x)$lengths, function(k) 1:k ))
>   f3 <- function(x)ave(x,x,FUN=seq)
>   f4 <- function(x)ave(seq_along(x), x, FUN=seq_along)
> You can compare their results with ftest (as long as their results have the
> same lengths):
>   ftest <- function(x) {
>      data.frame(x, f1=f1(x), f2=f2(x), f3=f3(x), f4=f4(x))
>   }
> They all return the same result for the Steven's sample data, which is numeric
> and in sorted order:
>   x0 <- c(123.45, 123.45, 123.45, 123.45, 234.56,
>                234.56, 234.56, 234.56, 234.56, 234.56, 234.56, 345.67, 345.67,
>                345.67, 456.78, 456.78, 456.78, 456.78, 456.78, 456.78, 456.78,
>               456.78, 456.78)
> However, f1() gives the wrong answer if x is not sorted:
>   > ftest(c(30,30,30, 20,20))
>      x f1 f2 f3 f4
>   1 30  1  1  1  1
>   2 30  2  2  2  2
>   3 30  1  3  3  3
>   4 20  2  1  1  1
>   5 20  3  2  2  2
> 
> f1() and f2() give the wrong answer if the groups are split up in the data
>   > ftest(c(10,10, 8,8,8, 10,10,10)) # 10's not contiguous
>      x f1 f2 f3 f4
>   1 10  1  1  1  1
>   2 10  2  2  2  2
>   3  8  3  1  1  1
>   4  8  1  2  2  2
>   5  8  2  3  3  3
>   6 10  3  1  3  3
>   7 10  4  2  4  4
>   8 10  5  3  5  5
> (It is not clear what result the OP wants here.)
> 
> f3() gives the wrong answer if x is not numeric
>   > f3(c("a","a","a", "b","b"))
>   [1] "1" "2" "3" "1" "2"
> 
> f3() also gives an ominous warning if there is singleton in x (be
>   > f3(c(1,1,1, 11))
>   [1] 1 2 3 1
>   Warning message:
>   In `split<-.default`(`*tmp*`, g, value = lapply(split(x, g), FUN)) :
>     number of items to replace is not a multiple of replacement length
> 
> f2() fails to give an answer if x is a factor
>   > f2(factor(c("x","y","z")))
>   Error in rle(x) : 'x' must be an atomic vector
> 
> I think f4 gives the correct result for all those cases.
> 
> I think all of the above call lapply(split()) at some point and that can use
> a lot of memory when there are lots of unique values in x.  You can use
> a sort-based algorithm to avoid that problem.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> > Of arun
> > Sent: Friday, October 11, 2013 6:43 AM
> > To: Steven Ranney; r-help at r-project.org
> > Subject: Re: [R] Create sequential vector for values in another column
> >
> >
> >
> > Also,
> >
> > it might be faster to use ?data.table()
> > library(data.table)
> > ?dt1<- data.table(dat1,key='id.name')
> > dt1[,x:=seq(.N),by='id.name']
> > A.K.
> >
> >
> > On , arun <smartpink111 at yahoo.com> wrote:
> > Hi,
> > Try:
> > dat1<-
> >
> > structure(list(id.name = c(123.45, 123.45, 123.45, 123.45, 234.56,
> > 234.56, 234.56, 234.56, 234.56, 234.56, 234.56, 345.67, 345.67,
> > 345.67, 456.78, 456.78, 456.78, 456.78, 456.78, 456.78, 456.78,
> > 456.78, 456.78)), .Names = "id.name", class = "data.frame", row.names = c(NA,
> > -23L))
> > dat1$x <- with(dat1,ave(id.name,id.name,FUN=seq))
> > A.K.
> >
> >
> >
> > On Friday, October 11, 2013 9:28 AM, Steven Ranney <steven.ranney at gmail.com>
> > wrote:
> > Hello all -
> >
> > I have an example column in a dataFrame
> >
> > id.name
> > 123.45
> > 123.45
> > 123.45
> > 123.45
> > 234.56
> > 234.56
> > 234.56
> > 234.56
> > 234.56
> > 234.56
> > 234.56
> > 345.67
> > 345.67
> > 345.67
> > 456.78
> > 456.78
> > 456.78
> > 456.78
> > 456.78
> > 456.78
> > 456.78
> > 456.78
> > 456.78
> > ...
> > [truncated]
> >
> > And I'd like to create a second vector of sequential values (i.e., 1:N) for
> > each unique id.name value.? In other words, I need
> >
> > id.name? x
> > 123.45?? 1
> > 123.45?? 2
> > 123.45?? 3
> > 123.45?? 4
> > 234.56?? 1
> > 234.56?? 2
> > 234.56?? 3
> > 234.56?? 4
> > 234.56?? 5
> > 234.56?? 6
> > 234.56?? 7
> > 345.67?? 1
> > 345.67?? 2
> > 345.67?? 3
> > 456.78?? 1
> > 456.78?? 2
> > 456.78?? 3
> > 456.78?? 4
> > 456.78?? 5
> > 456.78?? 6
> > 456.78?? 7
> > 456.78?? 8
> > 456.78?? 9
> >
> > The number of unique id.name values is different; for some values, nrow()
> > may be 42 and for others it may be 36, etc.
> >
> > The only way I could think of to do this is with two nested for loops.? I
> > tried it but because this data set is so large (nrow = 112,679 with 2,161
> > unique values of id.name), it took several hours to run.
> >
> > Is there an easier way to create this vector?? I'd appreciate your thoughts.
> >
> > Thanks -
> >
> > SR
> > Steven H. Ranney
> >
> > ??? [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hb at biostat.ucsf.edu  Fri Oct 11 19:24:50 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 11 Oct 2013 10:24:50 -0700
Subject: [R] system2 commands with backslash
In-Reply-To: <FE51F261-F92B-481D-AE76-B56AA1387337@comcast.net>
References: <5256C4E6.6070805@zevross.com>
	<FE51F261-F92B-481D-AE76-B56AA1387337@comcast.net>
Message-ID: <CAFDcVCRfNFQQYcq4wEsZF-nn4uoY68SPsFut5wfo1SKAcdnAfQ@mail.gmail.com>

system2("sed", args=c("-i", "s/oldword\\s/newword/g", "d:/junk/x/test.tex"))

/Henrik

On Fri, Oct 11, 2013 at 8:58 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Oct 10, 2013, at 8:16 AM, Zev Ross wrote:
>
>> Hi All,
>>
>> I'm trying to edit a file in place using system2 and sed from within R. I can get my command to work unless there is a backslash in the command in which case I'm warned about an "unrecognized escape". So, for example:
>>
>> system2("sed -i s/oldword/newword/g d:/junk/x/test.tex") # works fine
>> system2("sed -i s/oldword\s/newword/g d:/junk/x/test.tex") # does not work in R (the command works on the command line)
>>
>> I've experimented with double slashes to escape the \s,
>
> Wouldn't you want to double the backslashes instead?
>
>> I've tried the "shell" command, I've tried experimenting with shQuote and can't seem to get around the "unrecognized escape" issue.
>>
>> By the way, it would be preferable to have a solution that avoided using double backslashes etc because, unfortunately, in my real-world example, I'm actually replacing double slashes and would prefer not to have quadruple slashes etc.
>>
>> I'm using Windows 7, 64 bit.
>>
>> Zev
>>
>> --
>> Zev Ross
>> ZevRoss Spatial Analysis
>> 120 N Aurora, Suite 3A
>> Ithaca, NY 14850
>> 607-277-0004 (phone)
>> zev at zevross.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at structuremonitoring.com  Fri Oct 11 19:35:56 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Fri, 11 Oct 2013 10:35:56 -0700
Subject: [R] Gaussian Quadrature for arbitrary PDF
In-Reply-To: <CABmD0bHQstzG+YEboF7upiJoTKjhjy6TPNHYpnkXRKRcChs+og@mail.gmail.com>
References: <CABmD0bEYbM350tYxQTuRLv2ddNq+8pOu6KqTrhTbdNMzb61iuA@mail.gmail.com>
	<525746F2.80903@structuremonitoring.com>
	<CABmD0bHQstzG+YEboF7upiJoTKjhjy6TPNHYpnkXRKRcChs+og@mail.gmail.com>
Message-ID: <525836FC.9050508@structuremonitoring.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/2a3e6e08/attachment.pl>

From zev at zevross.com  Fri Oct 11 19:41:04 2013
From: zev at zevross.com (Zev Ross)
Date: Fri, 11 Oct 2013 13:41:04 -0400
Subject: [R] system2 commands with backslash
In-Reply-To: <CAFDcVCRfNFQQYcq4wEsZF-nn4uoY68SPsFut5wfo1SKAcdnAfQ@mail.gmail.com>
References: <5256C4E6.6070805@zevross.com>
	<FE51F261-F92B-481D-AE76-B56AA1387337@comcast.net>
	<CAFDcVCRfNFQQYcq4wEsZF-nn4uoY68SPsFut5wfo1SKAcdnAfQ@mail.gmail.com>
Message-ID: <52583830.9040406@zevross.com>

Thanks to Henrik and David for responses. Both were right. A small edit 
to my description of the problem (which has now been solved). I said 
that the first version of system2 ( system2("sed -i s/oldword/newword/g 
d:/junk/x/test.tex")) worked fine but in fact it was not working, it 
just wasn't giving me an error.

Both of these work:

system("sed -i 's/oldword\\s/oldword/g' d:/junk/x/test.tex")
system2("sed", args=c("-i", "s/oldword\\s/newword/g", 
"d:/junk/x/test.tex"))

Thanks again,

Zev

On 10/11/2013 1:24 PM, Henrik Bengtsson wrote:
> system2("sed", args=c("-i", "s/oldword\\s/newword/g", "d:/junk/x/test.tex"))
>
> /Henrik
>
> On Fri, Oct 11, 2013 at 8:58 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>> On Oct 10, 2013, at 8:16 AM, Zev Ross wrote:
>>
>>> Hi All,
>>>
>>> I'm trying to edit a file in place using system2 and sed from within R. I can get my command to work unless there is a backslash in the command in which case I'm warned about an "unrecognized escape". So, for example:
>>>
>>> system2("sed -i s/oldword/newword/g d:/junk/x/test.tex") # works fine
>>> system2("sed -i s/oldword\s/newword/g d:/junk/x/test.tex") # does not work in R (the command works on the command line)
>>>
>>> I've experimented with double slashes to escape the \s,
>> Wouldn't you want to double the backslashes instead?
>>
>>> I've tried the "shell" command, I've tried experimenting with shQuote and can't seem to get around the "unrecognized escape" issue.
>>>
>>> By the way, it would be preferable to have a solution that avoided using double backslashes etc because, unfortunately, in my real-world example, I'm actually replacing double slashes and would prefer not to have quadruple slashes etc.
>>>
>>> I'm using Windows 7, 64 bit.
>>>
>>> Zev
>>>
>>> --
>>> Zev Ross
>>> ZevRoss Spatial Analysis
>>> 120 N Aurora, Suite 3A
>>> Ithaca, NY 14850
>>> 607-277-0004 (phone)
>>> zev at zevross.com
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Zev Ross
ZevRoss Spatial Analysis
120 N Aurora, Suite 3A
Ithaca, NY 14850
607-277-0004 (phone)
zev at zevross.com


From 538280 at gmail.com  Fri Oct 11 19:45:13 2013
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 11 Oct 2013 11:45:13 -0600
Subject: [R] automation of an R script to run
In-Reply-To: <6DBEEF9C09ACF64B8BCFE8F66EDA1B1F05622725@aa-exb01.theaa.local>
References: <6DBEEF9C09ACF64B8BCFE8F66EDA1B1F05622725@aa-exb01.theaa.local>
Message-ID: <CAFEqCdy+kjQb5P-2-GbkJdYD-vCFTHV6QONe3QRAecgrt8Ev1g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/e819679c/attachment.pl>

From ligges at statistik.tu-dortmund.de  Fri Oct 11 19:50:11 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 11 Oct 2013 19:50:11 +0200
Subject: [R] Help with expression()
In-Reply-To: <CABf=2VH5+kJU1rkbQmW+xgftm1dK2dpRfkXLj0uaBRQpK3T2dA@mail.gmail.com>
References: <CABf=2VH5+kJU1rkbQmW+xgftm1dK2dpRfkXLj0uaBRQpK3T2dA@mail.gmail.com>
Message-ID: <52583A53.8010904@statistik.tu-dortmund.de>

On 10.10.2013 21:40, Sheri wrote:
> Hi everyone,
>
> I am hoping someone can help with my attempted use of the expression
> function. I have a long series of text and variable to paste together
> including a degree symbol. The text is to be placed on my scatter plot
> using the mtext function.
>
> Using expression like this:
>
> changetext = expression(paste("Change from ",mini," to ", maxi, ":",
> diff ,degree,"C",collapse=""))
>
> does not evaluate my user defined variables - mini,maxi, and diff -
> just printing them out as words
>
> Using expression like this:
>
> changetext = paste("Change from ",mini," to ", maxi, ":", diff
> ,expression(degree,"C"),collapse="")
>
> prints the text twice and does not evaluate the degree symbol.
>
> I have tried to place the expression alone in a variable and then run the paste:
>
> degsym = expression(degree,"C")
> changetext = paste("Change from ",mini," to ", maxi, ":", diff
> ,degsym,collapse="")
>
> giving me the same result as the second option
>
> Is there any way I can use the expression function as in the first
> example but still have R evaluate my user defined variables?
>
> Thanks!
> Sheri

I'd rather use substitute for substitution of the symbols and get:



plot(1, main = substitute("Change from " * mini * " to " * maxi * ": " * 
diff * degree * "C", list(mini=mini, maxi=maxi,diff=diff)))

Best,
Uwe Ligges


From dan.abner99 at gmail.com  Fri Oct 11 20:59:23 2013
From: dan.abner99 at gmail.com (Dan Abner)
Date: Fri, 11 Oct 2013 14:59:23 -0400
Subject: [R] Looping over names of multiple data frames in an R for() loop
	XXXX
Message-ID: <CAPRGo-n03++5PczFAwWX9JYtdMUp_PZQ5N3zdyo8T-jzv34jcQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/feab1f81/attachment.pl>

From jholtman at gmail.com  Fri Oct 11 21:11:09 2013
From: jholtman at gmail.com (jim holtman)
Date: Fri, 11 Oct 2013 15:11:09 -0400
Subject: [R] Looping over names of multiple data frames in an R for()
	loop XXXX
In-Reply-To: <CAPRGo-n03++5PczFAwWX9JYtdMUp_PZQ5N3zdyo8T-jzv34jcQ@mail.gmail.com>
References: <CAPRGo-n03++5PczFAwWX9JYtdMUp_PZQ5N3zdyo8T-jzv34jcQ@mail.gmail.com>
Message-ID: <CAAxdm-7YGo9Fsahr_C2BxgdMgXhPPWHFGfmTqavLFULf23YoYw@mail.gmail.com>

I think you want 'assign' at that point.  Would suggest using a 'list'
to store the input instead of unique named objects.  'list's are
easier to manage.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Oct 11, 2013 at 2:59 PM, Dan Abner <dan.abner99 at gmail.com> wrote:
> Hi everybody,
>
> I thought I was using the get() fn correctly here to loop over multiple
> data frame names in an R for() loop. Can someone advise?
>
>
>> miss<-c("#NULL!","999")
>> d<-c("d1","d2","d3","d4")
>>
>> for(i in 1:4){
> +
> + miss1<-ifelse(i<=2,miss[1],miss[2])
> + miss1
> +
> + get(d[i])<-read.csv(paste("C:\\DATA\\Data\\Original\\",dsn[i],sep=""),
> + na.strings=c(miss1,"999999999"))
> +
> + head(get(d[i]))
> +
> + write.csv(get(d[i]),paste("C:\\DATA\\Data\\",dsn[i],sep=""),
> + na=".")
> +
> + }
> Error in get(d[i]) <- read.csv(paste("C:\\DATA\\Data\\Original\\", dsn[i],
> :
>   could not find function "get<-"
>>
>
> Thanks!
>
> Dan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marco.scutari at gmail.com  Fri Oct 11 21:25:53 2013
From: marco.scutari at gmail.com (Marco Scutari)
Date: Fri, 11 Oct 2013 20:25:53 +0100
Subject: [R] Using "cpquery" function from bnlearn package inside loop
In-Reply-To: <ED2C9BF9-B9F0-4F06-B452-3459FA11DFEE@me.com>
References: <923FD3C9-1010-4CFB-800F-624A5621E457@me.com>
	<CA+RJqXVC7inX4UKsy2cR=wLcP60CTDdyOMbCdcYtuR9GOMnN6Q@mail.gmail.com>
	<ED2C9BF9-B9F0-4F06-B452-3459FA11DFEE@me.com>
Message-ID: <CA+RJqXXHhUK4kY5-DzTFxbQYwAYqDfYLVqwciMxRibQJdaG4Rw@mail.gmail.com>

Dear Ryan,

On 11 October 2013 16:50, Ryan Morrison <ryan.r.morrison at me.com> wrote:
> The cpquery function is definitely easier to use given that my evidence is
> contained in lists.

For the record, this is not a general solution to the bug. It's true
that likelihood weighting (method = "lw") is easier to use in a
programmatic way, but it is much more limited in the events you can
use for conditioning. Logic sampling (method = "ls") accepts an
arbitrary R expression as a conditioning event; likelihood weighting
at the moment accepts only a single instantiation of the conditioning
variables.

Cheers,
    Marco

-- 
Marco Scutari, Ph.D.
Research Associate, Genetics Institute (UGI)
University College London (UCL), United Kingdom


From marco.scutari at gmail.com  Fri Oct 11 22:25:33 2013
From: marco.scutari at gmail.com (Marco Scutari)
Date: Fri, 11 Oct 2013 21:25:33 +0100
Subject: [R] Using "cpquery" function from bnlearn package inside loop
In-Reply-To: <37790474-901D-4601-9C46-22C112F0F1F7@me.com>
References: <923FD3C9-1010-4CFB-800F-624A5621E457@me.com>
	<CA+RJqXVC7inX4UKsy2cR=wLcP60CTDdyOMbCdcYtuR9GOMnN6Q@mail.gmail.com>
	<ED2C9BF9-B9F0-4F06-B452-3459FA11DFEE@me.com>
	<CA+RJqXXHhUK4kY5-DzTFxbQYwAYqDfYLVqwciMxRibQJdaG4Rw@mail.gmail.com>
	<37790474-901D-4601-9C46-22C112F0F1F7@me.com>
Message-ID: <CA+RJqXUG7MWRMnmPRCLzxNKi-BbtmtA+6W9fL-_yEsS+AcE4yg@mail.gmail.com>

Dear Ryan,

On 11 October 2013 20:44, Ryan Morrison <ryan.r.morrison at me.com> wrote:
> Thanks for the clarification. For my immediate purposes I think using the likelihood
> weighting method will suffice. I'm calculating conditional probabilities based on a
> single instantiation each time I use the function. The evidence I use for instantiation
> changes for each i+1 in my loop, and a new probability is computed using the new
> evidence. Since I'm using a single instantiation of the conditioning variables for each
> calculation in my loop, I believe the likelihood weighting method will work. Don't
> hesitate to correct me if I'm wrong.

>From your description, likelihood weighting should be fine.

Cheers,
    Marco

-- 
Marco Scutari, Ph.D.
Research Associate, Genetics Institute (UGI)
University College London (UCL), United Kingdom


From djmuser at gmail.com  Fri Oct 11 22:41:18 2013
From: djmuser at gmail.com (Dennis Murphy)
Date: Fri, 11 Oct 2013 13:41:18 -0700
Subject: [R] matrix values linked to vector index
In-Reply-To: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CADv2QyFOi1wwfdR06pw1pOZoBOwjSs4sDuS27g41VbFBK3h5bQ@mail.gmail.com>

Attempting to follow the OP's conditions and assuming I understood
them correctly, here is one way to wrap this up into a function:

makeMat <- function(x)
{
    stopifnot(is.integer(x))
    nr <- length(x)
    nc <- max(x)

    # Initialize a matrix of zeros
    m <- matrix(0, nr, nc)
    # Conditionally replace with ones
    for(i in seq_len(nr)) if(x[i] != 0)  m[i, 1:x[i]] <- 1
    m
}

## Examples:
x1 <- 1:3
x2 <- as.integer(c(2, 0, 4, 3, 1))
x3 <- c(2, 1, 2.2)

makeMat(x1)
makeMat(x2)
makeMat(x3)
makeMat(4:6)


On Fri, Oct 11, 2013 at 9:49 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
>
> In the example you showed:
>
> m1<- matrix(0,length(vec),max(vec))
> 1*!upper.tri(m1)
>
> #or
>  m1[!upper.tri(m1)] <-  rep(rep(1,length(vec)),vec)
>
> #But, in a case like below, perhaps:
> vec1<- c(3,4,5)
>
>  m2<- matrix(0,length(vec1),max(vec1))
>  indx <- cbind(rep(seq_along(vec1),vec1),unlist(tapply(vec1,list(vec1),FUN=seq),use.names=FALSE))
> m2[indx]<- 1
>  m2
> #     [,1] [,2] [,3] [,4] [,5]
> #[1,]    1    1    1    0    0
> #[2,]    1    1    1    1    0
> #[3,]    1    1    1    1    1
>
>
>
>
> A.K.
>
>
> Hi-
>
> I'd like to create a matrix of 0's and 1's where the number of
> 1's in each row defined by the value indexed in another vector, and
> where the (value-1) is back-filled by 0's.
>
> For example, given the following vector:
> vec= c(1,2,3)
>
> I'd like to produce a matrix with dimensions (length(vec), max(vec)):
>
> 1,0,0
> 1,1,0
> 1,1,1
>
> Thank you!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Oct 11 22:43:13 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 11 Oct 2013 13:43:13 -0700
Subject: [R] labeling abscissa using a function of the plotted scale
In-Reply-To: <1381510115791-4678075.post@n4.nabble.com>
References: <1381510115791-4678075.post@n4.nabble.com>
Message-ID: <273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>


On Oct 11, 2013, at 9:48 AM, Hurr wrote:

> Is it easy or difficult to label the abscissa of a scatter graph as
> 1/trueScaleValue at that point?

It's easy.

?axis

> 
> --
> View this message in context: http://r.789695.n4.nabble.com/labeling-abscissa-using-a-function-of-the-plotted-scale-tp4678075.html

-- 

David Winsemius
Alameda, CA, USA


From gunter.berton at gene.com  Fri Oct 11 23:17:28 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 11 Oct 2013 14:17:28 -0700
Subject: [R] matrix values linked to vector index
In-Reply-To: <CADv2QyFOi1wwfdR06pw1pOZoBOwjSs4sDuS27g41VbFBK3h5bQ@mail.gmail.com>
References: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CADv2QyFOi1wwfdR06pw1pOZoBOwjSs4sDuS27g41VbFBK3h5bQ@mail.gmail.com>
Message-ID: <CACk-te0fhGoetSh6y=JaKj_oXXe7pw12=K2+cposkd5D6zGUOg@mail.gmail.com>

simpler (and sloppier) but with **no looping or apply's **

**IFF* the matrix is structured as in the OP's example, then lower.tri
(or upper.tri) should be used:

n <- 4 ## number of columns in matrix -- note that I changed it from
the example; does not have to be square

x <- 1:3 ## the number of 1's per row
lower.tri(matrix(0,nr=length(x),nc=n),diagA=TRUE)+0

A general, fast, but **tricky** way to do it that depends on knowing
that a matrix is just a vector in column major order is to generate
the vector using rep and then structure it as a matrix. eg.

x <- c(3,2,1,4) ## your vector of indices
n <- 4 ## number of columns in matrix ## does not have to be square
matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)

    [,1] [,2] [,3] [,4]
[1,]    1    1    1    0
[2,]    1    1    0    0
[3,]    1    0    0    0
[4,]    1    1    1    1


Cheers,
Bert

On Fri, Oct 11, 2013 at 1:41 PM, Dennis Murphy <djmuser at gmail.com> wrote:
> Attempting to follow the OP's conditions and assuming I understood
> them correctly, here is one way to wrap this up into a function:
>
> makeMat <- function(x)
> {
>     stopifnot(is.integer(x))
>     nr <- length(x)
>     nc <- max(x)
>
>     # Initialize a matrix of zeros
>     m <- matrix(0, nr, nc)
>     # Conditionally replace with ones
>     for(i in seq_len(nr)) if(x[i] != 0)  m[i, 1:x[i]] <- 1
>     m
> }
>
> ## Examples:
> x1 <- 1:3
> x2 <- as.integer(c(2, 0, 4, 3, 1))
> x3 <- c(2, 1, 2.2)
>
> makeMat(x1)
> makeMat(x2)
> makeMat(x3)
> makeMat(4:6)
>
>
> On Fri, Oct 11, 2013 at 9:49 AM, arun <smartpink111 at yahoo.com> wrote:
>> Hi,
>>
>> In the example you showed:
>>
>> m1<- matrix(0,length(vec),max(vec))
>> 1*!upper.tri(m1)
>>
>> #or
>>  m1[!upper.tri(m1)] <-  rep(rep(1,length(vec)),vec)
>>
>> #But, in a case like below, perhaps:
>> vec1<- c(3,4,5)
>>
>>  m2<- matrix(0,length(vec1),max(vec1))
>>  indx <- cbind(rep(seq_along(vec1),vec1),unlist(tapply(vec1,list(vec1),FUN=seq),use.names=FALSE))
>> m2[indx]<- 1
>>  m2
>> #     [,1] [,2] [,3] [,4] [,5]
>> #[1,]    1    1    1    0    0
>> #[2,]    1    1    1    1    0
>> #[3,]    1    1    1    1    1
>>
>>
>>
>>
>> A.K.
>>
>>
>> Hi-
>>
>> I'd like to create a matrix of 0's and 1's where the number of
>> 1's in each row defined by the value indexed in another vector, and
>> where the (value-1) is back-filled by 0's.
>>
>> For example, given the following vector:
>> vec= c(1,2,3)
>>
>> I'd like to produce a matrix with dimensions (length(vec), max(vec)):
>>
>> 1,0,0
>> 1,1,0
>> 1,1,1
>>
>> Thank you!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From smartpink111 at yahoo.com  Fri Oct 11 23:30:59 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 11 Oct 2013 14:30:59 -0700 (PDT)
Subject: [R] matrix values linked to vector index
In-Reply-To: <CADv2QyFOi1wwfdR06pw1pOZoBOwjSs4sDuS27g41VbFBK3h5bQ@mail.gmail.com>
References: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CADv2QyFOi1wwfdR06pw1pOZoBOwjSs4sDuS27g41VbFBK3h5bQ@mail.gmail.com>
Message-ID: <1381527059.26094.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Thanks Dennis.? I noticed I didn't take the "0" value into consideration and also didn't check the unsorted vector.vec1<- c(2,4,1)


is.numeric(vec1)
#[1] TRUE

makeMat(as.integer(vec1))

makeMatrix2<- function(x){
?if(is.numeric(x)){
x <- as.integer(round(x))
x}
stopifnot(is.integer(x))
m1<- matrix(0,length(x),max(x))
?indx <- cbind(rep(seq_along(x),x),seq_len(sum(x))-rep(cumsum(c(0L,x[-length(x)])),x))
m1[indx]<- 1
m1}


identical(makeMat(x1),makeMatrix2(x1))
#[1] TRUE
?identical(makeMat(x2),makeMatrix2(x2))
#[1] TRUE
?identical(makeMat(x3),makeMatrix2(x3))
#Error: is.integer(x) is not TRUE

makeMatrix2(x3)
#???? [,1] [,2]
#[1,]??? 1??? 1
#[2,]??? 1??? 0
#[3,]??? 1??? 1


?identical(makeMat(4:6),makeMatrix2(4:6))
#[1] TRUE

x4 <- c("a",1,3)
identical(makeMat(x4),makeMatrix2(x4))
#Error: is.integer(x) is not TRUE

A.K.










On Friday, October 11, 2013 4:41 PM, Dennis Murphy <djmuser at gmail.com> wrote:
Attempting to follow the OP's conditions and assuming I understood
them correctly, here is one way to wrap this up into a function:

makeMat <- function(x)
{
? ? stopifnot(is.integer(x))
? ? nr <- length(x)
? ? nc <- max(x)

? ? # Initialize a matrix of zeros
? ? m <- matrix(0, nr, nc)
? ? # Conditionally replace with ones
? ? for(i in seq_len(nr)) if(x[i] != 0)? m[i, 1:x[i]] <- 1
? ? m
}

## Examples:
x1 <- 1:3
x2 <- as.integer(c(2, 0, 4, 3, 1))
x3 <- c(2, 1, 2.2)

makeMat(x1)
makeMat(x2)
makeMat(x3)
makeMat(4:6)



On Fri, Oct 11, 2013 at 9:49 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
>
> In the example you showed:
>
> m1<- matrix(0,length(vec),max(vec))
> 1*!upper.tri(m1)
>
> #or
>? m1[!upper.tri(m1)] <-? rep(rep(1,length(vec)),vec)
>
> #But, in a case like below, perhaps:
> vec1<- c(3,4,5)
>
>? m2<- matrix(0,length(vec1),max(vec1))
>? indx <- cbind(rep(seq_along(vec1),vec1),unlist(tapply(vec1,list(vec1),FUN=seq),use.names=FALSE))
> m2[indx]<- 1
>? m2
> #? ?  [,1] [,2] [,3] [,4] [,5]
> #[1,]? ? 1? ? 1? ? 1? ? 0? ? 0
> #[2,]? ? 1? ? 1? ? 1? ? 1? ? 0
> #[3,]? ? 1? ? 1? ? 1? ? 1? ? 1
>
>
>
>
> A.K.
>
>
> Hi-
>
> I'd like to create a matrix of 0's and 1's where the number of
> 1's in each row defined by the value indexed in another vector, and
> where the (value-1) is back-filled by 0's.
>
> For example, given the following vector:
> vec= c(1,2,3)
>
> I'd like to produce a matrix with dimensions (length(vec), max(vec)):
>
> 1,0,0
> 1,1,0
> 1,1,1
>
> Thank you!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From gybrg at leeds.ac.uk  Fri Oct 11 23:43:34 2013
From: gybrg at leeds.ac.uk (Benjamin Gillespie)
Date: Fri, 11 Oct 2013 22:43:34 +0100
Subject: [R] Splitting times into groups based on a range of times
In-Reply-To: <1381454998.88168.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <894643FDEA3A854A89B3E828737E2B1F01652096290B@HERMES8.ds.leeds.ac.uk>,
	<1381454998.88168.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <894643FDEA3A854A89B3E828737E2B1F01652096290E@HERMES8.ds.leeds.ac.uk>

Hi Arun,

Many thanks for that solution; it works well :)

I also have some data where times and dates don't follow a 15 min intervals, so, for example:

dates=rep("01/02/13",times=20)
times=c("12:03:50","12:15:32","12:29:08","12:45:09","13:01:00","13:14:06","13:30:20","13:47:00","13:58:00","14:15:02","14:30:03","14:46:00","15:02:00","15:15:30","15:32:50","15:45:04","16:00:04","16:15:60","16:30:03","16:45:04","17:00:50","17:15:03","17:28:06","17:45:00")
x =paste(dates, times)
dt=strptime(x, "%m/%d/%y %H:%M:%S")

dates2=rep("01/02/13",times=8)
times2=c("12:00:00","12:30:00","12:45:00","13:15:00","13:30:00","14:00:00","14:45:00","17:30:00")
y =paste(dates2, times2)
dt2=strptime(y, "%m/%d/%y %H:%M:%S")
group=c(1,1,2,2,3,3,4,4)
df=data.frame(dt2,group)

id=c(1,1,1,2,2,2,3,3,3,0,0,4,4,4,4,4,4,4,4,4,4,4,4,0)
final.df=data.frame(dt,id)

Would you be able to suggest any workarounds for a situation like this?

Many thanks in advance,

Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o
________________________________________
From: arun [smartpink111 at yahoo.com]
Sent: 11 October 2013 02:29
To: Benjamin Gillespie
Cc: R help
Subject: Re: [R] Splitting times into groups based on a range of times

Hi Ben,

I would look into ?findInterval() or ?cut() for an easier solution.
indx<- match(df[,1],as.POSIXct(dt))
 indx2<- unique(df[,2])
lst1<- lapply(split(indx,((seq_along(indx)-1)%/%2)+1),function(x) seq(x[1], x[2]))
 res <- unlist(lapply(seq_along(lst1),function(i) {
                            val<-rep(indx2[i],length(lst1[[i]]))
                                                     names(val)<-lst1[[i]]
                                                           val
                              }))
res1<-res[match(seq_along(dt),names(res))]
 res1[is.na(res1)]<- 0
 names(res1)<- NULL
 res1
# [1] 1 1 1 2 2 2 3 3 3 0 0 4 4 4 4 4 4 4 4 4 4 4 4 0
identical(id,res1)
#[1] TRUE




On Thursday, October 10, 2013 8:10 PM, Benjamin Gillespie <gybrg at leeds.ac.uk> wrote:
Hi all,

I hope you can help with this one!

I have a dataframe: 'df' that consists of a vector of times: 'dt2' and a vector of group id's: 'group':

dates2=rep("01/02/13",times=8)
times2=c("12:00:00","12:30:00","12:45:00","13:15:00","13:30:00","14:00:00","14:45:00","17:30:00")
y =paste(dates2, times2)
dt2=strptime(y, "%m/%d/%y %H:%M:%S")
group=c(1,1,2,2,3,3,4,4)
df=data.frame(dt2,group)

I also have a vector: 'dt' which is a series of times:

dates=rep("01/02/13",times=20)
times=c("12:00:00","12:15:00","12:30:00","12:45:00","13:00:00","13:15:00","13:30:00","13:45:00","14:00:00","14:15:00","14:30:00","14:45:00","15:00:00","15:15:00","15:30:00","15:45:00","16:00:00","16:15:00","16:30:00","16:45:00","17:00:00","17:15:00","17:30:00","17:45:00")
x =paste(dates, times)
dt=strptime(x, "%m/%d/%y %H:%M:%S")

I wish to create a vector which looks like 'id':

id=c(1,1,1,2,2,2,3,3,3,0,0,4,4,4,4,4,4,4,4,4,4,4,4,0)

The rules I wish to follow to create 'id' are:

1. If a value in 'dt' is either equal to, or, within the range of times within group x in dataframe 'df', then, the value in 'id' will equal x.

So, for example, in 'df', group 4 is between the times of "14:45:00" and "17:30:00" on the "01/02/13". Thus, the 12th to 23rd value in 'id' equals 4 as these values correspond to times within 'dt' that are equal to and within the range of  "14:45:00" and "17:30:00" on the "01/02/13".

If this doesn't make sense, please ask,

I'm not sure where to even start with this... possibly the 'cut' function?

Many thanks in advance,

Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Oct 11 23:43:51 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 11 Oct 2013 14:43:51 -0700 (PDT)
Subject: [R] matrix values linked to vector index
In-Reply-To: <CACk-te0fhGoetSh6y=JaKj_oXXe7pw12=K2+cposkd5D6zGUOg@mail.gmail.com>
References: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<CADv2QyFOi1wwfdR06pw1pOZoBOwjSs4sDuS27g41VbFBK3h5bQ@mail.gmail.com>
	<CACk-te0fhGoetSh6y=JaKj_oXXe7pw12=K2+cposkd5D6zGUOg@mail.gmail.com>
Message-ID: <1381527831.1314.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Seems like a bug in the code:
x<- c(3,4,1)
n<- 3
?matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
#Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument
?n<- 4
?matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
#Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument

x2
[1] 2 0 4 3 1
> matrix(rep(rep(c(1,0),n),rbind(x2,n-x2)),nc=n,byr=TRUE)
Error in rep(rep(c(1, 0), n), rbind(x2, n - x2)) : 
? invalid 'times' argument


A.K.




On Friday, October 11, 2013 5:17 PM, Bert Gunter <gunter.berton at gene.com> wrote:
simpler (and sloppier) but with **no looping or apply's **

**IFF* the matrix is structured as in the OP's example, then lower.tri
(or upper.tri) should be used:

n <- 4 ## number of columns in matrix -- note that I changed it from
the example; does not have to be square

x <- 1:3 ## the number of 1's per row
lower.tri(matrix(0,nr=length(x),nc=n),diagA=TRUE)+0

A general, fast, but **tricky** way to do it that depends on knowing
that a matrix is just a vector in column major order is to generate
the vector using rep and then structure it as a matrix. eg.

x <- c(3,2,1,4) ## your vector of indices
n <- 4 ## number of columns in matrix ## does not have to be square
matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)

? ? [,1] [,2] [,3] [,4]
[1,]? ? 1? ? 1? ? 1? ? 0
[2,]? ? 1? ? 1? ? 0? ? 0
[3,]? ? 1? ? 0? ? 0? ? 0
[4,]? ? 1? ? 1? ? 1? ? 1


Cheers,
Bert

On Fri, Oct 11, 2013 at 1:41 PM, Dennis Murphy <djmuser at gmail.com> wrote:
> Attempting to follow the OP's conditions and assuming I understood
> them correctly, here is one way to wrap this up into a function:
>
> makeMat <- function(x)
> {
>? ?  stopifnot(is.integer(x))
>? ?  nr <- length(x)
>? ?  nc <- max(x)
>
>? ?  # Initialize a matrix of zeros
>? ?  m <- matrix(0, nr, nc)
>? ?  # Conditionally replace with ones
>? ?  for(i in seq_len(nr)) if(x[i] != 0)? m[i, 1:x[i]] <- 1
>? ?  m
> }
>
> ## Examples:
> x1 <- 1:3
> x2 <- as.integer(c(2, 0, 4, 3, 1))
> x3 <- c(2, 1, 2.2)
>
> makeMat(x1)
> makeMat(x2)
> makeMat(x3)
> makeMat(4:6)
>
>
> On Fri, Oct 11, 2013 at 9:49 AM, arun <smartpink111 at yahoo.com> wrote:
>> Hi,
>>
>> In the example you showed:
>>
>> m1<- matrix(0,length(vec),max(vec))
>> 1*!upper.tri(m1)
>>
>> #or
>>? m1[!upper.tri(m1)] <-? rep(rep(1,length(vec)),vec)
>>
>> #But, in a case like below, perhaps:
>> vec1<- c(3,4,5)
>>
>>? m2<- matrix(0,length(vec1),max(vec1))
>>? indx <- cbind(rep(seq_along(vec1),vec1),unlist(tapply(vec1,list(vec1),FUN=seq),use.names=FALSE))
>> m2[indx]<- 1
>>? m2
>> #? ?  [,1] [,2] [,3] [,4] [,5]
>> #[1,]? ? 1? ? 1? ? 1? ? 0? ? 0
>> #[2,]? ? 1? ? 1? ? 1? ? 1? ? 0
>> #[3,]? ? 1? ? 1? ? 1? ? 1? ? 1
>>
>>
>>
>>
>> A.K.
>>
>>
>> Hi-
>>
>> I'd like to create a matrix of 0's and 1's where the number of
>> 1's in each row defined by the value indexed in another vector, and
>> where the (value-1) is back-filled by 0's.
>>
>> For example, given the following vector:
>> vec= c(1,2,3)
>>
>> I'd like to produce a matrix with dimensions (length(vec), max(vec)):
>>
>> 1,0,0
>> 1,1,0
>> 1,1,1
>>
>> Thank you!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374



From gybrg at leeds.ac.uk  Fri Oct 11 23:43:46 2013
From: gybrg at leeds.ac.uk (Benjamin Gillespie)
Date: Fri, 11 Oct 2013 22:43:46 +0100
Subject: [R] Possible loop/ if statement query
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B968C6@SRVEXCHMBX.precheza.cz>
References: <894643FDEA3A854A89B3E828737E2B1F016520962902@HERMES8.ds.leeds.ac.uk>,
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B968C6@SRVEXCHMBX.precheza.cz>
Message-ID: <894643FDEA3A854A89B3E828737E2B1F01652096290F@HERMES8.ds.leeds.ac.uk>

Nice, thanks Petr :)


Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o
________________________________________
From: PIKAL Petr [petr.pikal at precheza.cz]
Sent: 11 October 2013 14:06
To: Benjamin Gillespie; r-help at R-project.org
Subject: RE: Possible loop/ if statement query

Hi

not sure if it is the most efficient and clever solution

ifelse(b<7, NA, cumsum(c(0,diff(!(b<7)))==1))

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Benjamin Gillespie
> Sent: Thursday, October 10, 2013 12:39 AM
> To: r-help at R-project.org
> Subject: [R] Possible loop/ if statement query
>
> Dear r genii,
>
> I hope you can help.
>
> I have vector 'b':
>
> b=c((1:10),sort(1:9,decreasing=TRUE),(2:12),sort(6:11,decreasing=TRUE),
> (7:13))
>
> and, from 'b' I wish to create vector 'c':
>
> c=c(
>       NA,NA,NA,NA,NA,NA,1,1,1,1,1,1,1,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,
> 2,2,2,2,2,2,2,2,2,2,2,NA,3,3,3,3,3,3,3)
>
> The rules I want to use to create 'c' are:
>
> A numeric of equal to, or over 7 in 'b' needs to result in a numeric
> (i.e. not NA) in 'c'; A numeric of less than 7 in 'b' needs to result
> in "NA" in 'c'; Where 'groups' of numerics equal to, or over 7 in 'b'
> are present (i.e. next to each other in the list), the numerics
> produced in 'c' all need to be the same; Each 'group' of numerics in
> 'b' must result in a unique numeric  in 'c' (and, ideally, they should
> run in sequence as in 'c' above (1,2,3...).
>
> If anyone has any idea where to start on this or can crack it I'll be
> most grateful!!
>
> Many thanks in advance,
>
> Ben Gillespie, Research Postgraduate
> o-------------------------------------------------------------------o
> School of Geography, University of Leeds, Leeds, LS2 9JT o-------------
> ------------------------------------------------------o
> Tel: +44(0)113 34 33345
> Mob: +44(0)770 868 7641
> o-------------------------------o
> http://www.geog.leeds.ac.uk/
> o-------------------------------------o
> @RiversBenG
> o--------------o
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From aanas at feps.edu.eg  Fri Oct 11 13:54:08 2013
From: aanas at feps.edu.eg (Aya Anas)
Date: Fri, 11 Oct 2013 14:54:08 +0300
Subject: [R] Singular matrix
Message-ID: <CAB=y=yNrbnpAcwcKQumBBq+sGKu0gnuk6Cgqr3y8gs9qBfFUhQ@mail.gmail.com>

Dear all,
I am using the DEoptim package. My optimization syntax has three decesion
variables. If I increase the upper bound of the first or third variables,I
get an error related to singularity of a matrix. However, I need to
increase the upper bound of the first and third variables. The true bounds
for the the three variables are (0,+inf), (0,1) and (0,+inf). However, The
syntax gives errors even when I set the upper bounds  for the first and
third variables =10 only . The syntax runs without errors, when I set the
upper bound <="5" for the third variable for example. The first variable
even needs a smaller upper bound to run succesfully. I don't know how could
I handle this problem?could anybody help me to increase the bound of the
first and third variables to a reasonable large number, without having this
error?

"*The syntax is attached*".

-- 
Best Regards
Aya
Faculty of Economics & Political Science
Cairo University
Tel:(202)35728055-(202)35728116-(202)35736608-(202)35736605
Fax:(202)35711020
Follow us on twitter:https://twitter.com/fepsnews

From simon.keusen at student.unisg.ch  Fri Oct 11 14:45:47 2013
From: simon.keusen at student.unisg.ch (Mubar)
Date: Fri, 11 Oct 2013 05:45:47 -0700 (PDT)
Subject: [R] R plotting
Message-ID: <1381495546828-4678056.post@n4.nabble.com>

Hi

I have a question regarding plots in R. I have data from the S&P 500 in the
format:

date           close     change
1980-01-07  109.92   3.4

I plotted the data with plot(spdata$date, log(spdata$close), type="p")

Now I want to ad the colors green and red to the data frame. if the change
is positive it should be green, if negative, red. Also the colors should be
in the plot. I tried to do this with the ifelse function, but seem to be
stuck.

Can anyone help me with this?

Thanks a lot!




--
View this message in context: http://r.789695.n4.nabble.com/R-plotting-tp4678056.html
Sent from the R help mailing list archive at Nabble.com.


From ryan.r.morrison at me.com  Fri Oct 11 17:50:25 2013
From: ryan.r.morrison at me.com (Ryan Morrison)
Date: Fri, 11 Oct 2013 09:50:25 -0600
Subject: [R] Using "cpquery" function from bnlearn package inside loop
In-Reply-To: <CA+RJqXVC7inX4UKsy2cR=wLcP60CTDdyOMbCdcYtuR9GOMnN6Q@mail.gmail.com>
References: <923FD3C9-1010-4CFB-800F-624A5621E457@me.com>
	<CA+RJqXVC7inX4UKsy2cR=wLcP60CTDdyOMbCdcYtuR9GOMnN6Q@mail.gmail.com>
Message-ID: <ED2C9BF9-B9F0-4F06-B452-3459FA11DFEE@me.com>

Thanks Marco,

The cpquery function is definitely easier to use given that my evidence is contained in lists. 

Thanks for your help!

---
Ryan

Ryan Morrison, PE
PhD Candidate
University of New Mexico
Department of Civil Engineering
Centennial Engineering Center, Room 3057
Phone: 505-633-5506
Email: rmorriso at unm.edu
www.ryanmorrison.org


On Oct 10, 2013, at 3:16 AM, Marco Scutari <marco.scutari at gmail.com> wrote:

> Dear Ryan,
> 
> On 9 October 2013 21:26, Ryan Morrison <ryan.r.morrison at me.com> wrote:
>> I'm attempting to use the bnlearn package to calculate conditional probabilities, and
>> I'm running into a problem when the "cpquery" function is used within a loop. I've
>> created an example, shown below, using data included with the package. When
>> using the cpquery function in a loop, a variable created in the loop ("evi" in the
>> example) is not recognized by the function. I receive the error:
>> 
>> Error in parse(text = evi) : object 'evi' not found
> [snip]
> 
> Based on the second example you emailed me off-list, it appears to be
> a scoping problem; that's why the same code works if it's not inside a
> function. I will try to debug this soon, but I am not an expert in R
> parsing mechanisms so it will take some time. In the mean time, you
> can use cpquery(..., method = "lw") instead of the default
> cpquery(..., method = "ls") if your query looks like the one in the
> example. The former does not rely on unevaluated expressions, but
> takes the conditioning values as a list, and it should work
> regardless. However, if you do so I suggest you should install the
> latest bugfix snapshot from bnlearn.com to avoid a few other bugs in
> cpquery(..., method = "lw").
> 
> Cheers,
>    Marco
> 
> -- 
> Marco Scutari, Ph.D.
> Research Associate, Genetics Institute (UGI)
> University College London (UCL), United Kingdom


From thibaulth at gmail.com  Fri Oct 11 18:49:31 2013
From: thibaulth at gmail.com (Thibault Helleputte)
Date: Fri, 11 Oct 2013 18:49:31 +0200
Subject: [R] Updating RSQLite fails
Message-ID: <CALhjJH2QQS4+_zV2Rmk5s+kH0-UpsVCn6yePPyn5+OBNs35Ksw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/8b396a01/attachment.pl>

From ryan.r.morrison at me.com  Fri Oct 11 21:44:43 2013
From: ryan.r.morrison at me.com (Ryan Morrison)
Date: Fri, 11 Oct 2013 13:44:43 -0600
Subject: [R] Using "cpquery" function from bnlearn package inside loop
In-Reply-To: <CA+RJqXXHhUK4kY5-DzTFxbQYwAYqDfYLVqwciMxRibQJdaG4Rw@mail.gmail.com>
References: <923FD3C9-1010-4CFB-800F-624A5621E457@me.com>
	<CA+RJqXVC7inX4UKsy2cR=wLcP60CTDdyOMbCdcYtuR9GOMnN6Q@mail.gmail.com>
	<ED2C9BF9-B9F0-4F06-B452-3459FA11DFEE@me.com>
	<CA+RJqXXHhUK4kY5-DzTFxbQYwAYqDfYLVqwciMxRibQJdaG4Rw@mail.gmail.com>
Message-ID: <37790474-901D-4601-9C46-22C112F0F1F7@me.com>

Hi Marco,

Thanks for the clarification. For my immediate purposes I think using the likelihood weighting method will suffice. I'm calculating conditional probabilities based on a single instantiation each time I use the function. The evidence I use for instantiation changes for each i+1 in my loop, and a new probability is computed using the new evidence. Since I'm using a single instantiation of the conditioning variables for each calculation in my loop, I believe the likelihood weighting method will work. Don't hesitate to correct me if I'm wrong.

Thanks,

---
Ryan

On Oct 11, 2013, at 1:25 PM, Marco Scutari <marco.scutari at gmail.com> wrote:

> Dear Ryan,
> 
> On 11 October 2013 16:50, Ryan Morrison <ryan.r.morrison at me.com> wrote:
>> The cpquery function is definitely easier to use given that my evidence is
>> contained in lists.
> 
> For the record, this is not a general solution to the bug. It's true
> that likelihood weighting (method = "lw") is easier to use in a
> programmatic way, but it is much more limited in the events you can
> use for conditioning. Logic sampling (method = "ls") accepts an
> arbitrary R expression as a conditioning event; likelihood weighting
> at the moment accepts only a single instantiation of the conditioning
> variables.
> 
> Cheers,
>    Marco
> 
> -- 
> Marco Scutari, Ph.D.
> Research Associate, Genetics Institute (UGI)
> University College London (UCL), United Kingdom


From smartpink111 at yahoo.com  Sat Oct 12 00:19:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 11 Oct 2013 15:19:09 -0700 (PDT)
Subject: [R] Splitting times into groups based on a range of times
In-Reply-To: <894643FDEA3A854A89B3E828737E2B1F01652096290E@HERMES8.ds.leeds.ac.uk>
References: <894643FDEA3A854A89B3E828737E2B1F01652096290B@HERMES8.ds.leeds.ac.uk>,
	<1381454998.88168.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<894643FDEA3A854A89B3E828737E2B1F01652096290E@HERMES8.ds.leeds.ac.uk>
Message-ID: <1381529949.21646.YahooMailNeo@web142602.mail.bf1.yahoo.com>



Hi Ben,
No problem.
Try:
df1 <- do.call(rbind,lapply(split(df,df$group),function(x) { data.frame(dt2=dt[dt>=x[1,1] & dt<x[length(x),1]],group=x[1,2]) }))

id1 <- df1[,2][match(as.POSIXct(dt),df1[,1])]
id1[is.na(id1)]<- 0
?identical(id,id1)
#[1] TRUE

A.K.


On Friday, October 11, 2013 5:43 PM, Benjamin Gillespie <gybrg at leeds.ac.uk> wrote:
Hi Arun,

Many thanks for that solution; it works well :)

I also have some data where times and dates don't follow a 15 min intervals, so, for example:

dates=rep("01/02/13",times=20)
times=c("12:03:50","12:15:32","12:29:08","12:45:09","13:01:00","13:14:06","13:30:20","13:47:00","13:58:00","14:15:02","14:30:03","14:46:00","15:02:00","15:15:30","15:32:50","15:45:04","16:00:04","16:15:60","16:30:03","16:45:04","17:00:50","17:15:03","17:28:06","17:45:00")
x =paste(dates, times)
dt=strptime(x, "%m/%d/%y %H:%M:%S")

dates2=rep("01/02/13",times=8)
times2=c("12:00:00","12:30:00","12:45:00","13:15:00","13:30:00","14:00:00","14:45:00","17:30:00")
y =paste(dates2, times2)
dt2=strptime(y, "%m/%d/%y %H:%M:%S")
group=c(1,1,2,2,3,3,4,4)
df=data.frame(dt2,group)

id=c(1,1,1,2,2,2,3,3,3,0,0,4,4,4,4,4,4,4,4,4,4,4,4,0)
final.df=data.frame(dt,id)

Would you be able to suggest any workarounds for a situation like this?

Many thanks in advance,

Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o
________________________________________

From: arun [smartpink111 at yahoo.com]
Sent: 11 October 2013 02:29
To: Benjamin Gillespie
Cc: R help
Subject: Re: [R] Splitting times into groups based on a range of times

Hi Ben,

I would look into ?findInterval() or ?cut() for an easier solution.
indx<- match(df[,1],as.POSIXct(dt))
indx2<- unique(df[,2])
lst1<- lapply(split(indx,((seq_along(indx)-1)%/%2)+1),function(x) seq(x[1], x[2]))
res <- unlist(lapply(seq_along(lst1),function(i) {
? ? ? ? ? ? ? ? ? ? ? ? ? ? val<-rep(indx2[i],length(lst1[[i]]))
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  names(val)<-lst1[[i]]
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  val
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? }))
res1<-res[match(seq_along(dt),names(res))]
res1[is.na(res1)]<- 0
names(res1)<- NULL
res1
# [1] 1 1 1 2 2 2 3 3 3 0 0 4 4 4 4 4 4 4 4 4 4 4 4 0
identical(id,res1)
#[1] TRUE




On Thursday, October 10, 2013 8:10 PM, Benjamin Gillespie <gybrg at leeds.ac.uk> wrote:
Hi all,

I hope you can help with this one!

I have a dataframe: 'df' that consists of a vector of times: 'dt2' and a vector of group id's: 'group':

dates2=rep("01/02/13",times=8)
times2=c("12:00:00","12:30:00","12:45:00","13:15:00","13:30:00","14:00:00","14:45:00","17:30:00")
y =paste(dates2, times2)
dt2=strptime(y, "%m/%d/%y %H:%M:%S")
group=c(1,1,2,2,3,3,4,4)
df=data.frame(dt2,group)

I also have a vector: 'dt' which is a series of times:

dates=rep("01/02/13",times=20)
times=c("12:00:00","12:15:00","12:30:00","12:45:00","13:00:00","13:15:00","13:30:00","13:45:00","14:00:00","14:15:00","14:30:00","14:45:00","15:00:00","15:15:00","15:30:00","15:45:00","16:00:00","16:15:00","16:30:00","16:45:00","17:00:00","17:15:00","17:30:00","17:45:00")
x =paste(dates, times)
dt=strptime(x, "%m/%d/%y %H:%M:%S")

I wish to create a vector which looks like 'id':

id=c(1,1,1,2,2,2,3,3,3,0,0,4,4,4,4,4,4,4,4,4,4,4,4,0)

The rules I wish to follow to create 'id' are:

1. If a value in 'dt' is either equal to, or, within the range of times within group x in dataframe 'df', then, the value in 'id' will equal x.

So, for example, in 'df', group 4 is between the times of "14:45:00" and "17:30:00" on the "01/02/13". Thus, the 12th to 23rd value in 'id' equals 4 as these values correspond to times within 'dt' that are equal to and within the range of? "14:45:00" and "17:30:00" on the "01/02/13".

If this doesn't make sense, please ask,

I'm not sure where to even start with this... possibly the 'cut' function?

Many thanks in advance,

Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From hill0093 at umn.edu  Sat Oct 12 00:28:41 2013
From: hill0093 at umn.edu (Hurr)
Date: Fri, 11 Oct 2013 15:28:41 -0700 (PDT)
Subject: [R] rjava be-carefuls
Message-ID: <1381530521780-4678102.post@n4.nabble.com>

I have a java class with routines (and their tests) that I would like to 
use in R so I don't have to have two copies of important subroutines.
I have looked at rjava, but can't grasp it all and don't know what are
the important items to observe first so I don't get into too much 
trouble later. I would appreciate any pointers from some knowlegeable
people. They are so-far just methods concerning strings, doubles, and 
integers. And of course pass-by-value, not by reference.




--
View this message in context: http://r.789695.n4.nabble.com/rjava-be-carefuls-tp4678102.html
Sent from the R help mailing list archive at Nabble.com.


From hill0093 at umn.edu  Sat Oct 12 00:30:14 2013
From: hill0093 at umn.edu (Hurr)
Date: Fri, 11 Oct 2013 15:30:14 -0700 (PDT)
Subject: [R] labeling abscissa using a function of the plotted scale
In-Reply-To: <273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>
References: <1381510115791-4678075.post@n4.nabble.com>
	<273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>
Message-ID: <1381530614663-4678103.post@n4.nabble.com>

Thanks.




--
View this message in context: http://r.789695.n4.nabble.com/labeling-abscissa-using-a-function-of-the-plotted-scale-tp4678075p4678103.html
Sent from the R help mailing list archive at Nabble.com.


From jim at bitwrit.com.au  Sat Oct 12 01:07:18 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 12 Oct 2013 10:07:18 +1100
Subject: [R] R plotting
In-Reply-To: <1381495546828-4678056.post@n4.nabble.com>
References: <1381495546828-4678056.post@n4.nabble.com>
Message-ID: <525884A6.4090509@bitwrit.com.au>

On 10/11/2013 11:45 PM, Mubar wrote:
> Hi
>
> I have a question regarding plots in R. I have data from the S&P 500 in the
> format:
>
> date           close     change
> 1980-01-07  109.92   3.4
>
> I plotted the data with plot(spdata$date, log(spdata$close), type="p")
>
> Now I want to ad the colors green and red to the data frame. if the change
> is positive it should be green, if negative, red. Also the colors should be
> in the plot. I tried to do this with the ifelse function, but seem to be
> stuck.
>
Hi Mubar,
I think this will get you what you want:

plot(spdata$date,log(spdata$close),type="p",
  col=(spdata$change>=0)+2)

Jim


From Paul.Prew at ecolab.com  Sat Oct 12 05:13:15 2013
From: Paul.Prew at ecolab.com (Prew, Paul)
Date: Fri, 11 Oct 2013 22:13:15 -0500
Subject: [R] using ddply with segmented regression
Message-ID: <A780DAF149F5C24EBDFC048B071023B91B8C8423C5@useagan5503p.global.ecolab.corp>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/365e1c2a/attachment.pl>

From emfales at uw.edu  Sat Oct 12 00:39:23 2013
From: emfales at uw.edu (Emily Jean Fales)
Date: Fri, 11 Oct 2013 15:39:23 -0700
Subject: [R] How do you add the x-bar (mean of x) symbol and show a
 calculated mean in the title of a histogram?
Message-ID: <CACycjg9WKXrF1BwBd_mDmmC2eN3gkuF1AZZF8er5korGP0168g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/fdea9108/attachment.pl>

From jmmaxwell at wsu.edu  Sat Oct 12 00:22:57 2013
From: jmmaxwell at wsu.edu (Maxwell, John McFarland)
Date: Fri, 11 Oct 2013 22:22:57 +0000
Subject: [R] MCP solver
Message-ID: <9FE87F5AC4D0164989FD7A9C468C114EF41D55@EXMB-02.ad.wsu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131011/46daf350/attachment.pl>

From r.turner at auckland.ac.nz  Sat Oct 12 07:23:00 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 12 Oct 2013 18:23:00 +1300
Subject: [R] How do you add the x-bar (mean of x) symbol and show a
 calculated mean in the title of a histogram?
In-Reply-To: <CACycjg9WKXrF1BwBd_mDmmC2eN3gkuF1AZZF8er5korGP0168g@mail.gmail.com>
References: <CACycjg9WKXrF1BwBd_mDmmC2eN3gkuF1AZZF8er5korGP0168g@mail.gmail.com>
Message-ID: <5258DCB4.4030009@auckland.ac.nz>

On 10/12/13 11:39, Emily Jean Fales wrote:
> I am trying to get the calculated mean and the symbol of x-bar to show in
> the title of multiple histograms in R. Here is the code I have for one of
> the histograms:
>   hist(outcome[,11], main= "Heart Attack (expression(bar(x))) =
> (mean(outcome[,11]))", xlab ="30-day Death Rate", xlim = c(min(hist_min),
> max(hist_max)))
>
> but the symbol will not sow up in the title just the words I have typed
> do...I am not a programmer and new to R (obviously), so any help is
> appreciated!

You are being confronted with the mysteries of plotmath() which are 
opaque to us
ordinary mortals.  My approach is to remember vaguely a few tricks and 
then invoke
these tricks in a hammer-and-hope manner until something works.

For your problem the main trick is to use bquote() and the ".()" 
function.  Oh, yeah.
And paste the literal bit, i.e. "Heart Attack" onto the mathematical 
bit.  E.g.:

set.seed(42)
xxx <- rnorm(300,10,2)
hist(xxx,main=bquote(paste("Heart Attack  ", bar(x) == .(mean(xxx)))))

There are probably better ways.  And don't ask me for an explanation; it 
just seems
to work.

HTH

     cheers,

     Rolf Turner


From gunter.berton at gene.com  Sat Oct 12 07:40:06 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 11 Oct 2013 22:40:06 -0700
Subject: [R] matrix values linked to vector index
In-Reply-To: <1381527831.1314.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CADv2QyFOi1wwfdR06pw1pOZoBOwjSs4sDuS27g41VbFBK3h5bQ@mail.gmail.com>
	<CACk-te0fhGoetSh6y=JaKj_oXXe7pw12=K2+cposkd5D6zGUOg@mail.gmail.com>
	<1381527831.1314.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CACk-te37xmyZkmPMnxphEC9Qxtv8buva4qVtD0r7gy+2N1LeoA@mail.gmail.com>

Your examples are the problem:

On Fri, Oct 11, 2013 at 2:43 PM, arun <smartpink111 at yahoo.com> wrote:
> Seems like a bug in the code:
> x<- c(3,4,1)
> n<- 3
>  matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
> #Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument

## This can't work since x specifies 4 1's in the second row but you
have specified a 3 column matrix with n.

>  n<- 4
>  matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
> #Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument

Yes, this shows that my claim that non-square matrices also work is
false. I leave it as an exercise to fix it so that it works for
non-square matrices.

Cheers,
Bert



> x2
> [1] 2 0 4 3 1
>> matrix(rep(rep(c(1,0),n),rbind(x2,n-x2)),nc=n,byr=TRUE)
> Error in rep(rep(c(1, 0), n), rbind(x2, n - x2)) :
>   invalid 'times' argument
>
>
> A.K.
>
>
>
>
> On Friday, October 11, 2013 5:17 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> simpler (and sloppier) but with **no looping or apply's **
>
> **IFF* the matrix is structured as in the OP's example, then lower.tri
> (or upper.tri) should be used:
>
> n <- 4 ## number of columns in matrix -- note that I changed it from
> the example; does not have to be square
>
> x <- 1:3 ## the number of 1's per row
> lower.tri(matrix(0,nr=length(x),nc=n),diagA=TRUE)+0
>
> A general, fast, but **tricky** way to do it that depends on knowing
> that a matrix is just a vector in column major order is to generate
> the vector using rep and then structure it as a matrix. eg.
>
> x <- c(3,2,1,4) ## your vector of indices
> n <- 4 ## number of columns in matrix ## does not have to be square
> matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>
>     [,1] [,2] [,3] [,4]
> [1,]    1    1    1    0
> [2,]    1    1    0    0
> [3,]    1    0    0    0
> [4,]    1    1    1    1
>
>
> Cheers,
> Bert
>
> On Fri, Oct 11, 2013 at 1:41 PM, Dennis Murphy <djmuser at gmail.com> wrote:
>> Attempting to follow the OP's conditions and assuming I understood
>> them correctly, here is one way to wrap this up into a function:
>>
>> makeMat <- function(x)
>> {
>>     stopifnot(is.integer(x))
>>     nr <- length(x)
>>     nc <- max(x)
>>
>>     # Initialize a matrix of zeros
>>     m <- matrix(0, nr, nc)
>>     # Conditionally replace with ones
>>     for(i in seq_len(nr)) if(x[i] != 0)  m[i, 1:x[i]] <- 1
>>     m
>> }
>>
>> ## Examples:
>> x1 <- 1:3
>> x2 <- as.integer(c(2, 0, 4, 3, 1))
>> x3 <- c(2, 1, 2.2)
>>
>> makeMat(x1)
>> makeMat(x2)
>> makeMat(x3)
>> makeMat(4:6)
>>
>>
>> On Fri, Oct 11, 2013 at 9:49 AM, arun <smartpink111 at yahoo.com> wrote:
>>> Hi,
>>>
>>> In the example you showed:
>>>
>>> m1<- matrix(0,length(vec),max(vec))
>>> 1*!upper.tri(m1)
>>>
>>> #or
>>>  m1[!upper.tri(m1)] <-  rep(rep(1,length(vec)),vec)
>>>
>>> #But, in a case like below, perhaps:
>>> vec1<- c(3,4,5)
>>>
>>>  m2<- matrix(0,length(vec1),max(vec1))
>>>  indx <- cbind(rep(seq_along(vec1),vec1),unlist(tapply(vec1,list(vec1),FUN=seq),use.names=FALSE))
>>> m2[indx]<- 1
>>>  m2
>>> #     [,1] [,2] [,3] [,4] [,5]
>>> #[1,]    1    1    1    0    0
>>> #[2,]    1    1    1    1    0
>>> #[3,]    1    1    1    1    1
>>>
>>>
>>>
>>>
>>> A.K.
>>>
>>>
>>> Hi-
>>>
>>> I'd like to create a matrix of 0's and 1's where the number of
>>> 1's in each row defined by the value indexed in another vector, and
>>> where the (value-1) is back-filled by 0's.
>>>
>>> For example, given the following vector:
>>> vec= c(1,2,3)
>>>
>>> I'd like to produce a matrix with dimensions (length(vec), max(vec)):
>>>
>>> 1,0,0
>>> 1,1,0
>>> 1,1,1
>>>
>>> Thank you!
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From gunter.berton at gene.com  Sat Oct 12 07:46:26 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 11 Oct 2013 22:46:26 -0700
Subject: [R] Singular matrix
In-Reply-To: <CAB=y=yNrbnpAcwcKQumBBq+sGKu0gnuk6Cgqr3y8gs9qBfFUhQ@mail.gmail.com>
References: <CAB=y=yNrbnpAcwcKQumBBq+sGKu0gnuk6Cgqr3y8gs9qBfFUhQ@mail.gmail.com>
Message-ID: <CACk-te1_16tdgKic724BHAkQLWsQkTQp7tHKZbgCrgK6T746Qg@mail.gmail.com>

You have posted neither code nor your data, contrary to what the
posting guide asks.

 How do you expect anyone to help?

Cheers,
Bert

On Fri, Oct 11, 2013 at 4:54 AM, Aya Anas <aanas at feps.edu.eg> wrote:
> Dear all,
> I am using the DEoptim package. My optimization syntax has three decesion
> variables. If I increase the upper bound of the first or third variables,I
> get an error related to singularity of a matrix. However, I need to
> increase the upper bound of the first and third variables. The true bounds
> for the the three variables are (0,+inf), (0,1) and (0,+inf). However, The
> syntax gives errors even when I set the upper bounds  for the first and
> third variables =10 only . The syntax runs without errors, when I set the
> upper bound <="5" for the third variable for example. The first variable
> even needs a smaller upper bound to run succesfully. I don't know how could
> I handle this problem?could anybody help me to increase the bound of the
> first and third variables to a reasonable large number, without having this
> error?
>
> "*The syntax is attached*".
>
> --
> Best Regards
> Aya
> Faculty of Economics & Political Science
> Cairo University
> Tel:(202)35728055-(202)35728116-(202)35736608-(202)35736605
> Fax:(202)35711020
> Follow us on twitter:https://twitter.com/fepsnews
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From gunter.berton at gene.com  Sat Oct 12 07:58:53 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 11 Oct 2013 22:58:53 -0700
Subject: [R] How do you add the x-bar (mean of x) symbol and show a
 calculated mean in the title of a histogram?
In-Reply-To: <5258DCB4.4030009@auckland.ac.nz>
References: <CACycjg9WKXrF1BwBd_mDmmC2eN3gkuF1AZZF8er5korGP0168g@mail.gmail.com>
	<5258DCB4.4030009@auckland.ac.nz>
Message-ID: <CACk-te2ZbRP8ijw6FCXwKK7xmxQjrDR3gLi_Dtmao+9Jv9tb8Q@mail.gmail.com>

Better, I don't know...

But alternatively, and maybe thinning the fog a bit:

set.seed(42)
xxx <- rnorm(300,10,2)
hist(xxx,main=bquote(Heart~~Attack~~~~bar(x) == .(mean(xxx))))


Cheers,
Bert

On Fri, Oct 11, 2013 at 10:23 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 10/12/13 11:39, Emily Jean Fales wrote:
>>
>> I am trying to get the calculated mean and the symbol of x-bar to show in
>> the title of multiple histograms in R. Here is the code I have for one of
>> the histograms:
>>   hist(outcome[,11], main= "Heart Attack (expression(bar(x))) =
>> (mean(outcome[,11]))", xlab ="30-day Death Rate", xlim = c(min(hist_min),
>> max(hist_max)))
>>
>> but the symbol will not sow up in the title just the words I have typed
>> do...I am not a programmer and new to R (obviously), so any help is
>> appreciated!
>
>
> You are being confronted with the mysteries of plotmath() which are opaque
> to us
> ordinary mortals.  My approach is to remember vaguely a few tricks and then
> invoke
> these tricks in a hammer-and-hope manner until something works.
>
> For your problem the main trick is to use bquote() and the ".()" function.
> Oh, yeah.
> And paste the literal bit, i.e. "Heart Attack" onto the mathematical bit.
> E.g.:
>
> set.seed(42)
> xxx <- rnorm(300,10,2)
> hist(xxx,main=bquote(paste("Heart Attack  ", bar(x) == .(mean(xxx)))))
>
> There are probably better ways.  And don't ask me for an explanation; it
> just seems
> to work.
>
> HTH
>
>     cheers,
>
>     Rolf Turner
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From smartpink111 at yahoo.com  Sat Oct 12 08:11:49 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 11 Oct 2013 23:11:49 -0700 (PDT)
Subject: [R] How do you add the x-bar (mean of x) symbol and show a
	calculated mean in the title of a histogram?
In-Reply-To: <5258DCB4.4030009@auckland.ac.nz>
References: <CACycjg9WKXrF1BwBd_mDmmC2eN3gkuF1AZZF8er5korGP0168g@mail.gmail.com>
	<5258DCB4.4030009@auckland.ac.nz> 
Message-ID: <1381558309.42185.YahooMailNeo@web142602.mail.bf1.yahoo.com>


Hi,
A slight modification would be:
hist(xxx,main=bquote("Heart Attack " ~ bar(x) == .(mean(xxx))))
#or use ?substitute()
hist(xxx,main=substitute("Heart Attack "~ bar(x) == mx,list(mx=mean(xxx))))

A.K.


On Saturday, October 12, 2013 1:26 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
On 10/12/13 11:39, Emily Jean Fales wrote:
> I am trying to get the calculated mean and the symbol of x-bar to show in
> the title of multiple histograms in R. Here is the code I have for one of
> the histograms:
>?? hist(outcome[,11], main= "Heart Attack (expression(bar(x))) =
> (mean(outcome[,11]))", xlab ="30-day Death Rate", xlim = c(min(hist_min),
> max(hist_max)))
>
> but the symbol will not sow up in the title just the words I have typed
> do...I am not a programmer and new to R (obviously), so any help is
> appreciated!

You are being confronted with the mysteries of plotmath() which are 
opaque to us
ordinary mortals.? My approach is to remember vaguely a few tricks and 
then invoke
these tricks in a hammer-and-hope manner until something works.

For your problem the main trick is to use bquote() and the ".()" 
function.? Oh, yeah.
And paste the literal bit, i.e. "Heart Attack" onto the mathematical 
bit.? E.g.:

set.seed(42)
xxx <- rnorm(300,10,2)
hist(xxx,main=bquote(paste("Heart Attack? ", bar(x) == .(mean(xxx)))))

There are probably better ways.? And don't ask me for an explanation; it 
just seems
to work.

HTH

? ?? cheers,

? ?? Rolf Turner


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sat Oct 12 08:41:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 11 Oct 2013 23:41:33 -0700 (PDT)
Subject: [R] using ddply with segmented regression
In-Reply-To: <A780DAF149F5C24EBDFC048B071023B91B8C8423C5@useagan5503p.global.ecolab.corp>
References: <A780DAF149F5C24EBDFC048B071023B91B8C8423C5@useagan5503p.global.ecolab.corp>
Message-ID: <1381560093.44823.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,
Try:

segmentf_df <- function(df) {
out.lm<-lm(deltaWgt~Cycle, data=df)
segmented(out.lm,seg.Z=~Cycle, psi=(Cycle=NA),control=seg.control(stop.if.error=FALSE,n.boot=0))
}

library(plyr)
library(segmented)

dlply(df,.(Lot.Run),segmentf_df)
$`J062431-1`
Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
??? control = seg.control(stop.if.error = FALSE, n.boot = 0))

Meaningful coefficients of the linear terms:
(Intercept)??????? Cycle???? U1.Cycle???? U2.Cycle? 
???? 38.480??????? 1.130?????? -2.760??????? 1.497? 

Estimated Break-Point(s) psi1.Cycle psi2.Cycle : 3.732 5.056 

$`J062431-2`
Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
??? control = seg.control(stop.if.error = FALSE, n.boot = 0))

Meaningful coefficients of the linear terms:
(Intercept)??????? Cycle???? U1.Cycle???? U2.Cycle? 
??? 48.4300????? -3.2500?????? 3.0905????? -0.6555? 

Estimated Break-Point(s) psi1.Cycle psi2.Cycle :? 2.12 22.15 

attr(,"split_type")
[1] "data.frame"
attr(,"split_labels")
??? Lot.Run
1 J062431-1
2 J062431-2


#or

dlply(df,.(Lot.Run),function(x) segmentf_df(x))
#or
lapply(split(df,df$Lot.Run,drop=TRUE),function(x) segmentf_df(x))


A.K.


On Friday, October 11, 2013 11:16 PM, "Prew, Paul" <Paul.Prew at ecolab.com> wrote:
Hello,

I?m unsuccessfully trying to apply piecewise linear regression over each of 22 groups.? The data structure of the reproducible toy dataset is below.? I?m using the ?segmented? package, it worked fine with a data set that containing only one group (?Lot.Run?).

$ Cycle?  : int? 1 2 3 4 5 6 7 8 9 10 ...
$ Lot.Run : Factor w/ 22 levels "J062431-1","J062431-2",..: 1 1 1 1 1 1 1 1 1 1 ...
$ deltaWgt: num? 38.7 42.6 41 42.3 40.6 ...

I am new to ?segmented?, and also new to ?plyr?, which is how I?m trying to apply this segmented regression to the 22 Lot.Run groups.? Within a Lot.Run, the piecewise linear regressions are deltaWgt vs. Cycle.

#####? define the linear regression #####
out.lm<-lm(deltaWgt~Cycle, data=Test50.df)

#####? define the function called by dlply? #####
? ? ?  #####? find cutpoints via bootstrapping, fit the piecewise regressions? #####
segmentf_df <- function(df) {
segmented(out.lm,seg.Z=~Cycle, psi=(Cycle=NA),control=seg.control(stop.if.error=FALSE,n.boot=0)), data = df)
}

at this point, there?s an? error message
23] ERROR: <text>

#####? repeat for each Lot.Run group?  #####
dlply(Test50.df, .(Lot.Run), segmentf_df)

at this point, there?s an? error message
[28] ERROR:
object 'segmentf_df' not found

Any suggestions?
Thanks, Paul

> dput(Test50.df)
structure(list(Cycle = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
23L, 24L, 25L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
25L), Lot.Run = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("J062431-1",
"J062431-2", "J062431-3", "J062432-1", "J062432-2", "J062433-1",
"J062433-2", "J062433-3", "Lot 1-1", "Lot 1-2", "Lot 2-1", "Lot 2-2",
"Lot 2-3", "Lot 3-1", "Lot 3-2", "Lot 3-3", "P041231-1", "P041231-2",
"P041531-1", "P041531-2", "P041531-3", "P041531-4"), class = "factor"),
? ? deltaWgt = c(38.69, 42.58, 40.95, 42.26, 40.63, 41.61, 36.73,
? ? 41.28, 39.98, 40.63, 39.66, 39.98, 40.95, 38.36, 39.01, 39,
? ? 38.03, 39.66, 37.7, 39.66, 40.63, 38.03, 37.71, 36.73, 37.7,
? ? 45.18, 41.93, 42.59, 39.98, 40.95, 42.91, 38.03, 40.96, 39,
? ? 41.61, 39.33, 43.88, 39.98, 38.68, 38.68, 36.08, 39.99, 38.35,
? ? 40.31, 40.63, 38.68, 37.05, 38.36, 35.43, 36.73)), .Names = c("Cycle",
"Lot.Run", "deltaWgt"), row.names = c(1L, 2L, 3L, 4L, 5L, 6L,
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
20L, 21L, 22L, 23L, 24L, 25L, 207L, 208L, 209L, 210L, 211L, 212L,
213L, 214L, 215L, 216L, 217L, 218L, 219L, 220L, 221L, 222L, 223L,
224L, 225L, 226L, 227L, 228L, 229L, 230L, 231L), class = "data.frame")




Paul Prew?  ?? Statistician
651-795-5942?  ??  fax 651-204-7504
Ecolab Research Center?  ?? Mail Stop ESC-F4412-A
655 Lone Oak Drive?  ??  Eagan, MN 55121-1560




CONFIDENTIALITY NOTICE: This e-mail communication and any attachments may contain proprietary and privileged information for the use of the designated recipients named above. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.

??? [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sat Oct 12 10:02:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 12 Oct 2013 01:02:11 -0700 (PDT)
Subject: [R] matrix values linked to vector index
In-Reply-To: <CACk-te37xmyZkmPMnxphEC9Qxtv8buva4qVtD0r7gy+2N1LeoA@mail.gmail.com>
References: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<CADv2QyFOi1wwfdR06pw1pOZoBOwjSs4sDuS27g41VbFBK3h5bQ@mail.gmail.com>	<CACk-te0fhGoetSh6y=JaKj_oXXe7pw12=K2+cposkd5D6zGUOg@mail.gmail.com>	<1381527831.1314.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CACk-te37xmyZkmPMnxphEC9Qxtv8buva4qVtD0r7gy+2N1LeoA@mail.gmail.com>
Message-ID: <1381564931.43800.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Modified Bert's solution for non-square matrices.? For the tested vectors, it worked.? There, could still be some bugs.

x1<- c(3,2,1,4)
?x2<- c(2,0,4,3,1)
x3 <- c(2, 1, 2.2)
x4 <- c("a",1,3)

makeMat3 <- function(x,n){
??????????? if(is.numeric(x)){
x <- as.integer(round(x))
x}
stopifnot(is.integer(x))
indx<-rep(rep(c(1,0),n),c(as.vector(rbind(x,n-x)),rep(c(0,n),n-length(x))))
?matrix(indx[seq_len(length(indx)-(n*(n-length(x))))],nc=n,byr=TRUE)
}
makeMat3(x1,4)
makeMat3(x1,5)
makeMat3(x1,6)
makeMat3(x1,7)


makeMat3(x2,7)
makeMat3(x2,6)
makeMat3(x2,4) # as length of vector > n
#Error in rep(c(0, n), n - length(x)) : invalid 'times' argument

makeMat3(x3,4)
makeMat3(x3,5)

?makeMat3(x4,4)
#Error: is.integer(x) is not TRUE

makeMat3(c(4,0,1,0,6),6)

A.K.



On Saturday, October 12, 2013 1:40 AM, Bert Gunter <gunter.berton at gene.com> wrote:
Your examples are the problem:

On Fri, Oct 11, 2013 at 2:43 PM, arun <smartpink111 at yahoo.com> wrote:
> Seems like a bug in the code:
> x<- c(3,4,1)
> n<- 3
>? matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
> #Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument

## This can't work since x specifies 4 1's in the second row but you
have specified a 3 column matrix with n.

>? n<- 4
>? matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
> #Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument

Yes, this shows that my claim that non-square matrices also work is
false. I leave it as an exercise to fix it so that it works for
non-square matrices.

Cheers,
Bert



> x2
> [1] 2 0 4 3 1
>> matrix(rep(rep(c(1,0),n),rbind(x2,n-x2)),nc=n,byr=TRUE)
> Error in rep(rep(c(1, 0), n), rbind(x2, n - x2)) :
>?  invalid 'times' argument
>
>
> A.K.
>
>
>
>
> On Friday, October 11, 2013 5:17 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> simpler (and sloppier) but with **no looping or apply's **
>
> **IFF* the matrix is structured as in the OP's example, then lower.tri
> (or upper.tri) should be used:
>
> n <- 4 ## number of columns in matrix -- note that I changed it from
> the example; does not have to be square
>
> x <- 1:3 ## the number of 1's per row
> lower.tri(matrix(0,nr=length(x),nc=n),diagA=TRUE)+0
>
> A general, fast, but **tricky** way to do it that depends on knowing
> that a matrix is just a vector in column major order is to generate
> the vector using rep and then structure it as a matrix. eg.
>
> x <- c(3,2,1,4) ## your vector of indices
> n <- 4 ## number of columns in matrix ## does not have to be square
> matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>
>? ?  [,1] [,2] [,3] [,4]
> [1,]? ? 1? ? 1? ? 1? ? 0
> [2,]? ? 1? ? 1? ? 0? ? 0
> [3,]? ? 1? ? 0? ? 0? ? 0
> [4,]? ? 1? ? 1? ? 1? ? 1
>
>
> Cheers,
> Bert
>
> On Fri, Oct 11, 2013 at 1:41 PM, Dennis Murphy <djmuser at gmail.com> wrote:
>> Attempting to follow the OP's conditions and assuming I understood
>> them correctly, here is one way to wrap this up into a function:
>>
>> makeMat <- function(x)
>> {
>>? ?  stopifnot(is.integer(x))
>>? ?  nr <- length(x)
>>? ?  nc <- max(x)
>>
>>? ?  # Initialize a matrix of zeros
>>? ?  m <- matrix(0, nr, nc)
>>? ?  # Conditionally replace with ones
>>? ?  for(i in seq_len(nr)) if(x[i] != 0)? m[i, 1:x[i]] <- 1
>>? ?  m
>> }
>>
>> ## Examples:
>> x1 <- 1:3
>> x2 <- as.integer(c(2, 0, 4, 3, 1))
>> x3 <- c(2, 1, 2.2)
>>
>> makeMat(x1)
>> makeMat(x2)
>> makeMat(x3)
>> makeMat(4:6)
>>
>>
>> On Fri, Oct 11, 2013 at 9:49 AM, arun <smartpink111 at yahoo.com> wrote:
>>> Hi,
>>>
>>> In the example you showed:
>>>
>>> m1<- matrix(0,length(vec),max(vec))
>>> 1*!upper.tri(m1)
>>>
>>> #or
>>>? m1[!upper.tri(m1)] <-? rep(rep(1,length(vec)),vec)
>>>
>>> #But, in a case like below, perhaps:
>>> vec1<- c(3,4,5)
>>>
>>>? m2<- matrix(0,length(vec1),max(vec1))
>>>? indx <- cbind(rep(seq_along(vec1),vec1),unlist(tapply(vec1,list(vec1),FUN=seq),use.names=FALSE))
>>> m2[indx]<- 1
>>>? m2
>>> #? ?  [,1] [,2] [,3] [,4] [,5]
>>> #[1,]? ? 1? ? 1? ? 1? ? 0? ? 0
>>> #[2,]? ? 1? ? 1? ? 1? ? 1? ? 0
>>> #[3,]? ? 1? ? 1? ? 1? ? 1? ? 1
>>>
>>>
>>>
>>>
>>> A.K.
>>>
>>>
>>> Hi-
>>>
>>> I'd like to create a matrix of 0's and 1's where the number of
>>> 1's in each row defined by the value indexed in another vector, and
>>> where the (value-1) is back-filled by 0's.
>>>
>>> For example, given the following vector:
>>> vec= c(1,2,3)
>>>
>>> I'd like to produce a matrix with dimensions (length(vec), max(vec)):
>>>
>>> 1,0,0
>>> 1,1,0
>>> 1,1,1
>>>
>>> Thank you!
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374

>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374



From nalimilan at club.fr  Sat Oct 12 12:08:12 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sat, 12 Oct 2013 12:08:12 +0200
Subject: [R] Updating RSQLite fails
In-Reply-To: <CALhjJH2QQS4+_zV2Rmk5s+kH0-UpsVCn6yePPyn5+OBNs35Ksw@mail.gmail.com>
References: <CALhjJH2QQS4+_zV2Rmk5s+kH0-UpsVCn6yePPyn5+OBNs35Ksw@mail.gmail.com>
Message-ID: <1381572492.2948.123.camel@milan>

Le vendredi 11 octobre 2013 ? 18:49 +0200, Thibault Helleputte a ?crit :
> Hello,
> 
> Working on an ubuntu 13.04 with a sessionInfo() specified below, I try to
> update my packages, and RSQLite update consistently fails like this:
> 
> > update.packages(checkBuilt=TRUE, ask=FALSE)
> Warning: package 'RUnit' in library '/usr/lib/R/site-library' will not be
> updated
> trying URL 'http://cran.rstudio.com/src/contrib/RSQLite_0.11.4.tar.gz'
> Content type 'application/x-gzip' length 1599919 bytes (1.5 Mb)
> opened URL
> ==================================================
> downloaded 1.5 Mb
> 
> * installing *source* package RSQLite ...
> ** package RSQLite successfully unpacked and MD5 sums checked
> checking for gcc... gcc -std=gnu99
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc -std=gnu99 accepts -g... yes
> checking for gcc -std=gnu99 option to accept ISO C89... none needed
> checking how to run the C preprocessor... gcc -std=gnu99 -E
> checking for gcc... (cached) gcc -std=gnu99
> checking whether we are using the GNU C compiler... (cached) yes
> checking whether gcc -std=gnu99 accepts -g... (cached) yes
> checking for gcc -std=gnu99 option to accept ISO C89... (cached) none needed
> checking for library containing fdatasync... none required
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DRSQLITE_USE_BUNDLED_SQLITE
> -DSQLITE_ENABLE_RTREE -DSQLITE_ENABLE_FTS3 -DSQLITE_ENABLE_FTS3_PARENTHESIS
> -DSQLITE_SOUNDEX -DSQLITE_MAX_VARIABLE_NUMBER=40000
> -DSQLITE_MAX_COLUMN=30000 -DTHREADSAFE=0     -fpic  -O3 -pipe  -g  -c
> RS-DBI.c -o RS-DBI.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DRSQLITE_USE_BUNDLED_SQLITE
> -DSQLITE_ENABLE_RTREE -DSQLITE_ENABLE_FTS3 -DSQLITE_ENABLE_FTS3_PARENTHESIS
> -DSQLITE_SOUNDEX -DSQLITE_MAX_VARIABLE_NUMBER=40000
> -DSQLITE_MAX_COLUMN=30000 -DTHREADSAFE=0     -fpic  -O3 -pipe  -g  -c
> RS-SQLite.c -o RS-SQLite.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DRSQLITE_USE_BUNDLED_SQLITE
> -DSQLITE_ENABLE_RTREE -DSQLITE_ENABLE_FTS3 -DSQLITE_ENABLE_FTS3_PARENTHESIS
> -DSQLITE_SOUNDEX -DSQLITE_MAX_VARIABLE_NUMBER=40000
> -DSQLITE_MAX_COLUMN=30000 -DTHREADSAFE=0     -fpic  -O3 -pipe  -g  -c
> param_binding.c -o param_binding.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DRSQLITE_USE_BUNDLED_SQLITE
> -DSQLITE_ENABLE_RTREE -DSQLITE_ENABLE_FTS3 -DSQLITE_ENABLE_FTS3_PARENTHESIS
> -DSQLITE_SOUNDEX -DSQLITE_MAX_VARIABLE_NUMBER=40000
> -DSQLITE_MAX_COLUMN=30000 -DTHREADSAFE=0     -fpic  -O3 -pipe  -g  -c
> sqlite-all.c -o sqlite-all.o
> sqlite-all.c:1:35: warning: extra tokens at end of #ifdef directive
> [enabled by default]
> gcc: internal compiler error: Killed (program cc1)
> Please submit a full bug report,
> with preprocessed source if appropriate.
> See <file:///usr/share/doc/gcc-4.7/README.Bugs> for instructions.
I think you should do what the error message suggests: report this to
gcc developers, giving them a link to the package source and
instructions to reproduce the problem. This is clearly not a bug in R.

Now, if you want to work around this, maybe you should try to find a
newer or older version of gcc for your distribution. If you have enabled
testing updates repository, go back to the tested ones.


Regards

> make: *** [sqlite-all.o] Error 4
> ubuntu at ip-10-226-133-215:~$ ERROR: compilation failed for package RSQLite
> * removing /usr/lib/R/site-library/RSQLite
> * restoring previous /usr/lib/R/site-library/RSQLite
> 
> 
> SESSION INFO:
> 
> > sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 
> I tried also to install RSQLite via r-cran-rsqlite, but the it installs me
> the 0.11.1 instead of 0.11.4.
> 
> Any idea of how to get things right?
> 
> Thx
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kannan at iitb.ac.in  Sat Oct 12 05:40:35 2013
From: kannan at iitb.ac.in (kannan at iitb.ac.in)
Date: Sat, 12 Oct 2013 03:40:35 +0000
Subject: [R] Introductory screencast tutorials on R
Message-ID: <dMUTSUWK.1381549235.2734390.kannan@iitb.ac.in>

We have created two introductory screencast tutorials on R, using
RStudio, and released them under a CC license.  These are available at
http://www.spoken-tutorial.org/list_videos?view=1&foss=R&language=all -
one may view them on a web browser or download them - without any
registration, whatsoever.  We refer to these as Spoken Tutorials.

We hope to add more tutorials to this series.  We welcome your comments
and criticism.  We also invite your participation.  This effort is
funded by the Indian Government.


From j.winter at tu-berlin.de  Sat Oct 12 15:33:29 2013
From: j.winter at tu-berlin.de (Winter, Jan-Christoph)
Date: Sat, 12 Oct 2013 13:33:29 +0000
Subject: [R] export glht to LaTeX
Message-ID: <632DC273F0AF9345BC5AA487C9247A1C01304E2015@EX-MB3.tubit.win.tu-berlin.de>

Hi,

I want to export the result of glht  in R into a LaTeX table, such as that result:

Linear Hypotheses:
                                           Estimate Std.     Error z value Pr(>|z|)    
Group1 - Group2 == 0   -0.14007    0.01589  -8.813   <0.001 "***"
Group1 - Group3 == 0    -0.09396    0.01575  -5.965   <0.001 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
(Adjusted p values reported -- single-step method)

I'm aware of libraries like stargazer, xtable, texreg, reporttools, memisc and apsrtable, but none of them does the job for glht :(

Does anyone have any hints?

Thanks and best regards
Jan Winter

From gunter.berton at gene.com  Sat Oct 12 17:37:19 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 12 Oct 2013 08:37:19 -0700
Subject: [R] matrix values linked to vector index
In-Reply-To: <1381564931.43800.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CADv2QyFOi1wwfdR06pw1pOZoBOwjSs4sDuS27g41VbFBK3h5bQ@mail.gmail.com>
	<CACk-te0fhGoetSh6y=JaKj_oXXe7pw12=K2+cposkd5D6zGUOg@mail.gmail.com>
	<1381527831.1314.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CACk-te37xmyZkmPMnxphEC9Qxtv8buva4qVtD0r7gy+2N1LeoA@mail.gmail.com>
	<1381564931.43800.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CACk-te05WDMo9bmRFvP+-W4WefmnJFKWTQOX=cm9AB8KUFsq_w@mail.gmail.com>

This seems to do it, but as I mentioned in my original post, my
"solution" was tricky. Thinking about it some more, I now realize that
it was too tricky and has the additional flaw of using underlying
representations of objects rather than their exposed interfaces -- i.e
it treats a matrix as a vector.

Here is, I think, a much better solution that treats a matrix as a
matrix by making use of a not-often-enough-used technique (mea culpa!)
of matrix indexing. It obviously needs to be cleaned up to check
inputs, etc. , but I think it should work. Feel free to publish and
clean up bugs.

makemx <- function(x,n)
{
  out <- matrix(0, nr=length(x), nc=n)
  ix <- cbind(rep(seq_along(x),x),unlist(sapply(x,seq_len)))
  out[ix]<- 1
  out
}

> makemx(c(3,2,1,4),4)
     [,1] [,2] [,3] [,4]
[1,]    1    1    1    0
[2,]    1    1    0    0
[3,]    1    0    0    0
[4,]    1    1    1    1
> makemx(c(3,2,1,4),5)
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    1    1    0    0
[2,]    1    1    0    0    0
[3,]    1    0    0    0    0
[4,]    1    1    1    1    0

Cheers,
Bert


On Sat, Oct 12, 2013 at 1:02 AM, arun <smartpink111 at yahoo.com> wrote:
>
>
> Modified Bert's solution for non-square matrices.  For the tested vectors, it worked.  There, could still be some bugs.
>
> x1<- c(3,2,1,4)
>  x2<- c(2,0,4,3,1)
> x3 <- c(2, 1, 2.2)
> x4 <- c("a",1,3)
>
> makeMat3 <- function(x,n){
>             if(is.numeric(x)){
> x <- as.integer(round(x))
> x}
> stopifnot(is.integer(x))
> indx<-rep(rep(c(1,0),n),c(as.vector(rbind(x,n-x)),rep(c(0,n),n-length(x))))
>  matrix(indx[seq_len(length(indx)-(n*(n-length(x))))],nc=n,byr=TRUE)
> }
> makeMat3(x1,4)
> makeMat3(x1,5)
> makeMat3(x1,6)
> makeMat3(x1,7)
>
>
> makeMat3(x2,7)
> makeMat3(x2,6)
> makeMat3(x2,4) # as length of vector > n
> #Error in rep(c(0, n), n - length(x)) : invalid 'times' argument
>
> makeMat3(x3,4)
> makeMat3(x3,5)
>
>  makeMat3(x4,4)
> #Error: is.integer(x) is not TRUE
>
> makeMat3(c(4,0,1,0,6),6)
>
> A.K.
>
>
>
> On Saturday, October 12, 2013 1:40 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> Your examples are the problem:
>
> On Fri, Oct 11, 2013 at 2:43 PM, arun <smartpink111 at yahoo.com> wrote:
>> Seems like a bug in the code:
>> x<- c(3,4,1)
>> n<- 3
>>  matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>> #Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument
>
> ## This can't work since x specifies 4 1's in the second row but you
> have specified a 3 column matrix with n.
>
>>  n<- 4
>>  matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>> #Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument
>
> Yes, this shows that my claim that non-square matrices also work is
> false. I leave it as an exercise to fix it so that it works for
> non-square matrices.
>
> Cheers,
> Bert
>
>
>
>> x2
>> [1] 2 0 4 3 1
>>> matrix(rep(rep(c(1,0),n),rbind(x2,n-x2)),nc=n,byr=TRUE)
>> Error in rep(rep(c(1, 0), n), rbind(x2, n - x2)) :
>>   invalid 'times' argument
>>
>>
>> A.K.
>>
>>
>>
>>
>> On Friday, October 11, 2013 5:17 PM, Bert Gunter <gunter.berton at gene.com> wrote:
>> simpler (and sloppier) but with **no looping or apply's **
>>
>> **IFF* the matrix is structured as in the OP's example, then lower.tri
>> (or upper.tri) should be used:
>>
>> n <- 4 ## number of columns in matrix -- note that I changed it from
>> the example; does not have to be square
>>
>> x <- 1:3 ## the number of 1's per row
>> lower.tri(matrix(0,nr=length(x),nc=n),diagA=TRUE)+0
>>
>> A general, fast, but **tricky** way to do it that depends on knowing
>> that a matrix is just a vector in column major order is to generate
>> the vector using rep and then structure it as a matrix. eg.
>>
>> x <- c(3,2,1,4) ## your vector of indices
>> n <- 4 ## number of columns in matrix ## does not have to be square
>> matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>>
>>     [,1] [,2] [,3] [,4]
>> [1,]    1    1    1    0
>> [2,]    1    1    0    0
>> [3,]    1    0    0    0
>> [4,]    1    1    1    1
>>
>>
>> Cheers,
>> Bert
>>
>> On Fri, Oct 11, 2013 at 1:41 PM, Dennis Murphy <djmuser at gmail.com> wrote:
>>> Attempting to follow the OP's conditions and assuming I understood
>>> them correctly, here is one way to wrap this up into a function:
>>>
>>> makeMat <- function(x)
>>> {
>>>     stopifnot(is.integer(x))
>>>     nr <- length(x)
>>>     nc <- max(x)
>>>
>>>     # Initialize a matrix of zeros
>>>     m <- matrix(0, nr, nc)
>>>     # Conditionally replace with ones
>>>     for(i in seq_len(nr)) if(x[i] != 0)  m[i, 1:x[i]] <- 1
>>>     m
>>> }
>>>
>>> ## Examples:
>>> x1 <- 1:3
>>> x2 <- as.integer(c(2, 0, 4, 3, 1))
>>> x3 <- c(2, 1, 2.2)
>>>
>>> makeMat(x1)
>>> makeMat(x2)
>>> makeMat(x3)
>>> makeMat(4:6)
>>>
>>>
>>> On Fri, Oct 11, 2013 at 9:49 AM, arun <smartpink111 at yahoo.com> wrote:
>>>> Hi,
>>>>
>>>> In the example you showed:
>>>>
>>>> m1<- matrix(0,length(vec),max(vec))
>>>> 1*!upper.tri(m1)
>>>>
>>>> #or
>>>>  m1[!upper.tri(m1)] <-  rep(rep(1,length(vec)),vec)
>>>>
>>>> #But, in a case like below, perhaps:
>>>> vec1<- c(3,4,5)
>>>>
>>>>  m2<- matrix(0,length(vec1),max(vec1))
>>>>  indx <- cbind(rep(seq_along(vec1),vec1),unlist(tapply(vec1,list(vec1),FUN=seq),use.names=FALSE))
>>>> m2[indx]<- 1
>>>>  m2
>>>> #     [,1] [,2] [,3] [,4] [,5]
>>>> #[1,]    1    1    1    0    0
>>>> #[2,]    1    1    1    1    0
>>>> #[3,]    1    1    1    1    1
>>>>
>>>>
>>>>
>>>>
>>>> A.K.
>>>>
>>>>
>>>> Hi-
>>>>
>>>> I'd like to create a matrix of 0's and 1's where the number of
>>>> 1's in each row defined by the value indexed in another vector, and
>>>> where the (value-1) is back-filled by 0's.
>>>>
>>>> For example, given the following vector:
>>>> vec= c(1,2,3)
>>>>
>>>> I'd like to produce a matrix with dimensions (length(vec), max(vec)):
>>>>
>>>> 1,0,0
>>>> 1,1,0
>>>> 1,1,1
>>>>
>>>> Thank you!
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> (650) 467-7374
>
>>
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From lars52r at gmail.com  Sat Oct 12 18:01:40 2013
From: lars52r at gmail.com (Lars Bishop)
Date: Sat, 12 Oct 2013 12:01:40 -0400
Subject: [R] Order of factors with facets in ggplot2
Message-ID: <CAO7OmOh51COUNzL09MBW84DY9n6W0bx0egP4vb0G=pT+rJzPAw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131012/3812adf5/attachment.pl>

From smartpink111 at yahoo.com  Sat Oct 12 18:04:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 12 Oct 2013 09:04:10 -0700 (PDT)
Subject: [R] matrix values linked to vector index
In-Reply-To: <CACk-te05WDMo9bmRFvP+-W4WefmnJFKWTQOX=cm9AB8KUFsq_w@mail.gmail.com>
References: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<CADv2QyFOi1wwfdR06pw1pOZoBOwjSs4sDuS27g41VbFBK3h5bQ@mail.gmail.com>	<CACk-te0fhGoetSh6y=JaKj_oXXe7pw12=K2+cposkd5D6zGUOg@mail.gmail.com>	<1381527831.1314.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<CACk-te37xmyZkmPMnxphEC9Qxtv8buva4qVtD0r7gy+2N1LeoA@mail.gmail.com>	<1381564931.43800.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CACk-te05WDMo9bmRFvP+-W4WefmnJFKWTQOX=cm9AB8KUFsq_w@mail.gmail.com>
Message-ID: <1381593850.91602.YahooMailNeo@web142603.mail.bf1.yahoo.com>

This looks better.? My previous solution (makeMatrix2) also did the matrix indexing? without using sapply() route.? Replacing the max(x) by n for non-symmetric matrix:

makeMatrix2<- function(x,n){ #including "n"
?if(is.numeric(x)){
x <- as.integer(round(x))
x}
stopifnot(is.integer(x))
m1<- matrix(0,length(x),n) #change max(x) to n
?indx <- cbind(rep(seq_along(x),x),seq_len(sum(x))-rep(cumsum(c(0L,x[-length(x)])),x))
m1[indx]<- 1
m1}

identical(makeMatrix2(x3,4),makemx(x3,4))
#[1] TRUE

?identical(makeMatrix2(x1,5),makemx(x1,5))
#[1] TRUE

identical(makeMatrix2(x2,7),makemx(x2,7))
#[1] TRUE

A.K.






On Saturday, October 12, 2013 11:37 AM, Bert Gunter <gunter.berton at gene.com> wrote:
This seems to do it, but as I mentioned in my original post, my
"solution" was tricky. Thinking about it some more, I now realize that
it was too tricky and has the additional flaw of using underlying
representations of objects rather than their exposed interfaces -- i.e
it treats a matrix as a vector.

Here is, I think, a much better solution that treats a matrix as a
matrix by making use of a not-often-enough-used technique (mea culpa!)
of matrix indexing. It obviously needs to be cleaned up to check
inputs, etc. , but I think it should work. Feel free to publish and
clean up bugs.

makemx <- function(x,n)
{
? out <- matrix(0, nr=length(x), nc=n)
? ix <- cbind(rep(seq_along(x),x),unlist(sapply(x,seq_len)))
? out[ix]<- 1
? out
}

> makemx(c(3,2,1,4),4)
? ?  [,1] [,2] [,3] [,4]
[1,]? ? 1? ? 1? ? 1? ? 0
[2,]? ? 1? ? 1? ? 0? ? 0
[3,]? ? 1? ? 0? ? 0? ? 0
[4,]? ? 1? ? 1? ? 1? ? 1
> makemx(c(3,2,1,4),5)
? ?  [,1] [,2] [,3] [,4] [,5]
[1,]? ? 1? ? 1? ? 1? ? 0? ? 0
[2,]? ? 1? ? 1? ? 0? ? 0? ? 0
[3,]? ? 1? ? 0? ? 0? ? 0? ? 0
[4,]? ? 1? ? 1? ? 1? ? 1? ? 0

Cheers,
Bert


On Sat, Oct 12, 2013 at 1:02 AM, arun <smartpink111 at yahoo.com> wrote:
>
>
> Modified Bert's solution for non-square matrices.? For the tested vectors, it worked.? There, could still be some bugs.
>
> x1<- c(3,2,1,4)
>? x2<- c(2,0,4,3,1)
> x3 <- c(2, 1, 2.2)
> x4 <- c("a",1,3)
>
> makeMat3 <- function(x,n){
>? ? ? ? ? ?  if(is.numeric(x)){
> x <- as.integer(round(x))
> x}
> stopifnot(is.integer(x))
> indx<-rep(rep(c(1,0),n),c(as.vector(rbind(x,n-x)),rep(c(0,n),n-length(x))))
>? matrix(indx[seq_len(length(indx)-(n*(n-length(x))))],nc=n,byr=TRUE)
> }
> makeMat3(x1,4)
> makeMat3(x1,5)
> makeMat3(x1,6)
> makeMat3(x1,7)
>
>
> makeMat3(x2,7)
> makeMat3(x2,6)
> makeMat3(x2,4) # as length of vector > n
> #Error in rep(c(0, n), n - length(x)) : invalid 'times' argument
>
> makeMat3(x3,4)
> makeMat3(x3,5)
>
>? makeMat3(x4,4)
> #Error: is.integer(x) is not TRUE
>
> makeMat3(c(4,0,1,0,6),6)
>
> A.K.
>
>
>
> On Saturday, October 12, 2013 1:40 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> Your examples are the problem:
>
> On Fri, Oct 11, 2013 at 2:43 PM, arun <smartpink111 at yahoo.com> wrote:
>> Seems like a bug in the code:
>> x<- c(3,4,1)
>> n<- 3
>>? matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>> #Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument
>
> ## This can't work since x specifies 4 1's in the second row but you
> have specified a 3 column matrix with n.
>
>>? n<- 4
>>? matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>> #Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument
>
> Yes, this shows that my claim that non-square matrices also work is
> false. I leave it as an exercise to fix it so that it works for
> non-square matrices.
>
> Cheers,
> Bert
>
>
>
>> x2
>> [1] 2 0 4 3 1
>>> matrix(rep(rep(c(1,0),n),rbind(x2,n-x2)),nc=n,byr=TRUE)
>> Error in rep(rep(c(1, 0), n), rbind(x2, n - x2)) :
>>?  invalid 'times' argument
>>
>>
>> A.K.
>>
>>
>>
>>
>> On Friday, October 11, 2013 5:17 PM, Bert Gunter <gunter.berton at gene.com> wrote:
>> simpler (and sloppier) but with **no looping or apply's **
>>
>> **IFF* the matrix is structured as in the OP's example, then lower.tri
>> (or upper.tri) should be used:
>>
>> n <- 4 ## number of columns in matrix -- note that I changed it from
>> the example; does not have to be square
>>
>> x <- 1:3 ## the number of 1's per row
>> lower.tri(matrix(0,nr=length(x),nc=n),diagA=TRUE)+0
>>
>> A general, fast, but **tricky** way to do it that depends on knowing
>> that a matrix is just a vector in column major order is to generate
>> the vector using rep and then structure it as a matrix. eg.
>>
>> x <- c(3,2,1,4) ## your vector of indices
>> n <- 4 ## number of columns in matrix ## does not have to be square
>> matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>>
>>? ?  [,1] [,2] [,3] [,4]
>> [1,]? ? 1? ? 1? ? 1? ? 0
>> [2,]? ? 1? ? 1? ? 0? ? 0
>> [3,]? ? 1? ? 0? ? 0? ? 0
>> [4,]? ? 1? ? 1? ? 1? ? 1
>>
>>
>> Cheers,
>> Bert
>>
>> On Fri, Oct 11, 2013 at 1:41 PM, Dennis Murphy <djmuser at gmail.com> wrote:
>>> Attempting to follow the OP's conditions and assuming I understood
>>> them correctly, here is one way to wrap this up into a function:
>>>
>>> makeMat <- function(x)
>>> {
>>>? ?  stopifnot(is.integer(x))
>>>? ?  nr <- length(x)
>>>? ?  nc <- max(x)
>>>
>>>? ?  # Initialize a matrix of zeros
>>>? ?  m <- matrix(0, nr, nc)
>>>? ?  # Conditionally replace with ones
>>>? ?  for(i in seq_len(nr)) if(x[i] != 0)? m[i, 1:x[i]] <- 1
>>>? ?  m
>>> }
>>>
>>> ## Examples:
>>> x1 <- 1:3
>>> x2 <- as.integer(c(2, 0, 4, 3, 1))
>>> x3 <- c(2, 1, 2.2)
>>>
>>> makeMat(x1)
>>> makeMat(x2)
>>> makeMat(x3)
>>> makeMat(4:6)
>>>
>>>
>>> On Fri, Oct 11, 2013 at 9:49 AM, arun <smartpink111 at yahoo.com> wrote:
>>>> Hi,
>>>>
>>>> In the example you showed:
>>>>
>>>> m1<- matrix(0,length(vec),max(vec))
>>>> 1*!upper.tri(m1)
>>>>
>>>> #or
>>>>? m1[!upper.tri(m1)] <-? rep(rep(1,length(vec)),vec)
>>>>
>>>> #But, in a case like below, perhaps:
>>>> vec1<- c(3,4,5)
>>>>
>>>>? m2<- matrix(0,length(vec1),max(vec1))
>>>>? indx <- cbind(rep(seq_along(vec1),vec1),unlist(tapply(vec1,list(vec1),FUN=seq),use.names=FALSE))
>>>> m2[indx]<- 1
>>>>? m2
>>>> #? ?  [,1] [,2] [,3] [,4] [,5]
>>>> #[1,]? ? 1? ? 1? ? 1? ? 0? ? 0
>>>> #[2,]? ? 1? ? 1? ? 1? ? 1? ? 0
>>>> #[3,]? ? 1? ? 1? ? 1? ? 1? ? 1
>>>>
>>>>
>>>>
>>>>
>>>> A.K.
>>>>
>>>>
>>>> Hi-
>>>>
>>>> I'd like to create a matrix of 0's and 1's where the number of
>>>> 1's in each row defined by the value indexed in another vector, and
>>>> where the (value-1) is back-filled by 0's.
>>>>
>>>> For example, given the following vector:
>>>> vec= c(1,2,3)
>>>>
>>>> I'd like to produce a matrix with dimensions (length(vec), max(vec)):
>>>>
>>>> 1,0,0
>>>> 1,1,0
>>>> 1,1,1
>>>>
>>>> Thank you!
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> (650) 467-7374

>
>>
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374



From smartpink111 at yahoo.com  Sat Oct 12 18:25:01 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 12 Oct 2013 09:25:01 -0700 (PDT)
Subject: [R] matrix values linked to vector index
In-Reply-To: <1381593850.91602.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<CADv2QyFOi1wwfdR06pw1pOZoBOwjSs4sDuS27g41VbFBK3h5bQ@mail.gmail.com>	<CACk-te0fhGoetSh6y=JaKj_oXXe7pw12=K2+cposkd5D6zGUOg@mail.gmail.com>	<1381527831.1314.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<CACk-te37xmyZkmPMnxphEC9Qxtv8buva4qVtD0r7gy+2N1LeoA@mail.gmail.com>	<1381564931.43800.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CACk-te05WDMo9bmRFvP+-W4WefmnJFKWTQOX=cm9AB8KUFsq_w@mail.gmail.com>
	<1381593850.91602.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1381595101.75451.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Some speed comparison:


set.seed(124)
?xtest<- sample(0:9,1e7,replace=TRUE)
system.time({res1 <- makemx(xtest,9)}) 
#?? user? system elapsed 
# 51.124?? 0.812? 52.039 
?system.time({res2 <- makeMatrix2(xtest,9)}) 
#?? user? system elapsed 
#? 3.460?? 0.168?? 3.631 


identical(res1,res2)
#[1] TRUE


Also, it looks like there is some bugs still in the "makeMat3"
system.time({res3 <- makeMat3(xtest,9)})
#Error in rep(c(0, n), n - length(x)) : invalid 'times' argument
#Timing stopped at: 0.616 0 0.616 


A.K.


On Saturday, October 12, 2013 12:06 PM, arun <smartpink111 at yahoo.com> wrote:
This looks better.? My previous solution (makeMatrix2) also did the matrix indexing? without using sapply() route.? Replacing the max(x) by n for non-symmetric matrix:

makeMatrix2<- function(x,n){ #including "n"
?if(is.numeric(x)){
x <- as.integer(round(x))
x}
stopifnot(is.integer(x))
m1<- matrix(0,length(x),n) #change max(x) to n
?indx <- cbind(rep(seq_along(x),x),seq_len(sum(x))-rep(cumsum(c(0L,x[-length(x)])),x))
m1[indx]<- 1
m1}

identical(makeMatrix2(x3,4),makemx(x3,4))
#[1] TRUE

?identical(makeMatrix2(x1,5),makemx(x1,5))
#[1] TRUE

identical(makeMatrix2(x2,7),makemx(x2,7))
#[1] TRUE

A.K.






On Saturday, October 12, 2013 11:37 AM, Bert Gunter <gunter.berton at gene.com> wrote:
This seems to do it, but as I mentioned in my original post, my
"solution" was tricky. Thinking about it some more, I now realize that
it was too tricky and has the additional flaw of using underlying
representations of objects rather than their exposed interfaces -- i.e
it treats a matrix as a vector.

Here is, I think, a much better solution that treats a matrix as a
matrix by making use of a not-often-enough-used technique (mea culpa!)
of matrix indexing. It obviously needs to be cleaned up to check
inputs, etc. , but I think it should work. Feel free to publish and
clean up bugs.

makemx <- function(x,n)
{
? out <- matrix(0, nr=length(x), nc=n)
? ix <- cbind(rep(seq_along(x),x),unlist(sapply(x,seq_len)))
? out[ix]<- 1
? out
}

> makemx(c(3,2,1,4),4)
? ?? [,1] [,2] [,3] [,4]
[1,]? ? 1? ? 1? ? 1? ? 0
[2,]? ? 1? ? 1? ? 0? ? 0
[3,]? ? 1? ? 0? ? 0? ? 0
[4,]? ? 1? ? 1? ? 1? ? 1
> makemx(c(3,2,1,4),5)
? ?? [,1] [,2] [,3] [,4] [,5]
[1,]? ? 1? ? 1? ? 1? ? 0? ? 0
[2,]? ? 1? ? 1? ? 0? ? 0? ? 0
[3,]? ? 1? ? 0? ? 0? ? 0? ? 0
[4,]? ? 1? ? 1? ? 1? ? 1? ? 0

Cheers,
Bert


On Sat, Oct 12, 2013 at 1:02 AM, arun <smartpink111 at yahoo.com> wrote:
>
>
> Modified Bert's solution for non-square matrices.? For the tested vectors, it worked.? There, could still be some bugs.
>
> x1<- c(3,2,1,4)
>? x2<- c(2,0,4,3,1)
> x3 <- c(2, 1, 2.2)
> x4 <- c("a",1,3)
>
> makeMat3 <- function(x,n){
>? ? ? ? ? ?? if(is.numeric(x)){
> x <- as.integer(round(x))
> x}
> stopifnot(is.integer(x))
> indx<-rep(rep(c(1,0),n),c(as.vector(rbind(x,n-x)),rep(c(0,n),n-length(x))))
>? matrix(indx[seq_len(length(indx)-(n*(n-length(x))))],nc=n,byr=TRUE)
> }
> makeMat3(x1,4)
> makeMat3(x1,5)
> makeMat3(x1,6)
> makeMat3(x1,7)
>
>
> makeMat3(x2,7)
> makeMat3(x2,6)
> makeMat3(x2,4) # as length of vector > n
> #Error in rep(c(0, n), n - length(x)) : invalid 'times' argument
>
> makeMat3(x3,4)
> makeMat3(x3,5)
>
>? makeMat3(x4,4)
> #Error: is.integer(x) is not TRUE
>
> makeMat3(c(4,0,1,0,6),6)
>
> A.K.
>
>
>
> On Saturday, October 12, 2013 1:40 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> Your examples are the problem:
>
> On Fri, Oct 11, 2013 at 2:43 PM, arun <smartpink111 at yahoo.com> wrote:
>> Seems like a bug in the code:
>> x<- c(3,4,1)
>> n<- 3
>>? matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>> #Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument
>
> ## This can't work since x specifies 4 1's in the second row but you
> have specified a 3 column matrix with n.
>
>>? n<- 4
>>? matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>> #Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument
>
> Yes, this shows that my claim that non-square matrices also work is
> false. I leave it as an exercise to fix it so that it works for
> non-square matrices.
>
> Cheers,
> Bert
>
>
>
>> x2
>> [1] 2 0 4 3 1
>>> matrix(rep(rep(c(1,0),n),rbind(x2,n-x2)),nc=n,byr=TRUE)
>> Error in rep(rep(c(1, 0), n), rbind(x2, n - x2)) :
>>?? invalid 'times' argument
>>
>>
>> A.K.
>>
>>
>>
>>
>> On Friday, October 11, 2013 5:17 PM, Bert Gunter <gunter.berton at gene.com> wrote:
>> simpler (and sloppier) but with **no looping or apply's **
>>
>> **IFF* the matrix is structured as in the OP's example, then lower.tri
>> (or upper.tri) should be used:
>>
>> n <- 4 ## number of columns in matrix -- note that I changed it from
>> the example; does not have to be square
>>
>> x <- 1:3 ## the number of 1's per row
>> lower.tri(matrix(0,nr=length(x),nc=n),diagA=TRUE)+0
>>
>> A general, fast, but **tricky** way to do it that depends on knowing
>> that a matrix is just a vector in column major order is to generate
>> the vector using rep and then structure it as a matrix. eg.
>>
>> x <- c(3,2,1,4) ## your vector of indices
>> n <- 4 ## number of columns in matrix ## does not have to be square
>> matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>>
>>? ?? [,1] [,2] [,3] [,4]
>> [1,]? ? 1? ? 1? ? 1? ? 0
>> [2,]? ? 1? ? 1? ? 0? ? 0
>> [3,]? ? 1? ? 0? ? 0? ? 0
>> [4,]? ? 1? ? 1? ? 1? ? 1
>>
>>
>> Cheers,
>> Bert
>>
>> On Fri, Oct 11, 2013 at 1:41 PM, Dennis Murphy <djmuser at gmail.com> wrote:
>>> Attempting to follow the OP's conditions and assuming I understood
>>> them correctly, here is one way to wrap this up into a function:
>>>
>>> makeMat <- function(x)
>>> {
>>>? ?? stopifnot(is.integer(x))
>>>? ?? nr <- length(x)
>>>? ?? nc <- max(x)
>>>
>>>? ?? # Initialize a matrix of zeros
>>>? ?? m <- matrix(0, nr, nc)
>>>? ?? # Conditionally replace with ones
>>>? ?? for(i in seq_len(nr)) if(x[i] != 0)? m[i, 1:x[i]] <- 1
>>>? ?? m
>>> }
>>>
>>> ## Examples:
>>> x1 <- 1:3
>>> x2 <- as.integer(c(2, 0, 4, 3, 1))
>>> x3 <- c(2, 1, 2.2)
>>>
>>> makeMat(x1)
>>> makeMat(x2)
>>> makeMat(x3)
>>> makeMat(4:6)
>>>
>>>
>>> On Fri, Oct 11, 2013 at 9:49 AM, arun <smartpink111 at yahoo.com> wrote:
>>>> Hi,
>>>>
>>>> In the example you showed:
>>>>
>>>> m1<- matrix(0,length(vec),max(vec))
>>>> 1*!upper.tri(m1)
>>>>
>>>> #or
>>>>? m1[!upper.tri(m1)] <-? rep(rep(1,length(vec)),vec)
>>>>
>>>> #But, in a case like below, perhaps:
>>>> vec1<- c(3,4,5)
>>>>
>>>>? m2<- matrix(0,length(vec1),max(vec1))
>>>>? indx <- cbind(rep(seq_along(vec1),vec1),unlist(tapply(vec1,list(vec1),FUN=seq),use.names=FALSE))
>>>> m2[indx]<- 1
>>>>? m2
>>>> #? ?? [,1] [,2] [,3] [,4] [,5]
>>>> #[1,]? ? 1? ? 1? ? 1? ? 0? ? 0
>>>> #[2,]? ? 1? ? 1? ? 1? ? 1? ? 0
>>>> #[3,]? ? 1? ? 1? ? 1? ? 1? ? 1
>>>>
>>>>
>>>>
>>>>
>>>> A.K.
>>>>
>>>>
>>>> Hi-
>>>>
>>>> I'd like to create a matrix of 0's and 1's where the number of
>>>> 1's in each row defined by the value indexed in another vector, and
>>>> where the (value-1) is back-filled by 0's.
>>>>
>>>> For example, given the following vector:
>>>> vec= c(1,2,3)
>>>>
>>>> I'd like to produce a matrix with dimensions (length(vec), max(vec)):
>>>>
>>>> 1,0,0
>>>> 1,1,0
>>>> 1,1,1
>>>>
>>>> Thank you!
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> (650) 467-7374

>
>>
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374



______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From grettke at acm.org  Sat Oct 12 16:10:07 2013
From: grettke at acm.org (Grant Rettke)
Date: Sat, 12 Oct 2013 09:10:07 -0500
Subject: [R] Introductory screencast tutorials on R
In-Reply-To: <dMUTSUWK.1381549235.2734390.kannan@iitb.ac.in>
References: <dMUTSUWK.1381549235.2734390.kannan@iitb.ac.in>
Message-ID: <CAAjq1mf9Wj2yOVw-wL0y1U+bbkxc8VMSUB0kw+_YKfMXLraiEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131012/a0198c2d/attachment.pl>

From anna.berg1986 at hotmail.com  Sat Oct 12 17:12:01 2013
From: anna.berg1986 at hotmail.com (anna berg)
Date: Sat, 12 Oct 2013 17:12:01 +0200
Subject: [R] Loop over factor returns NA
Message-ID: <BAY176-W32B1B0E42845A0064D0D7AF5180@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131012/0d00f112/attachment.pl>

From smartpink111 at yahoo.com  Sat Oct 12 19:28:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 12 Oct 2013 10:28:16 -0700 (PDT)
Subject: [R] matrix values linked to vector index
In-Reply-To: <1381597253.33936.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<CADv2QyFOi1wwfdR06pw1pOZoBOwjSs4sDuS27g41VbFBK3h5bQ@mail.gmail.com>	<CACk-te0fhGoetSh6y=JaKj_oXXe7pw12=K2+cposkd5D6zGUOg@mail.gmail.com>	<1381527831.1314.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<CACk-te37xmyZkmPMnxphEC9Qxtv8buva4qVtD0r7gy+2N1LeoA@mail.gmail.com>	<1381564931.43800.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CACk-te05WDMo9bmRFvP+-W4WefmnJFKWTQOX=cm9AB8KUFsq_w@mail.gmail.com>	<1381593850.91602.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1381595101.75451.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1381597253.33936.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1381598896.33513.YahooMailNeo@web142605.mail.bf1.yahoo.com>






Apologies, in case it is double posting (I think my previous message didn't make it to the list)


Hope the new version of `makeMat3` is bug free:
makeMat3 <- function(x,n){
??????????? if(is.numeric(x)){
x <- as.integer(round(x))
x}
stopifnot(is.integer(x))
if(length(x)>=n & max(x)<=n){
indx<-rep(rep(c(1,0),max(length(x),n)),rbind(x,n-x))

m1<-? matrix(indx,nc=n,byr=TRUE)
}

else if(length(x) < n) {
indx<-rep(rep(c(1,0),n),c(as.vector(rbind(x,n-x)),rep(c(0,n),n-length(x))))
?m1<-matrix(indx[seq_len(length(indx)-(n*(n-length(x))))],nc=n,byr=TRUE)
}
else print(paste("Not possible: Number of columns less than the maximum value of ", max(x), "or length of vector"))
m1
}

?system.time(res3<- makeMat3(xtest,9))
#?? user? system elapsed 
?# 1.908?? 0.328?? 2.237 
?identical(res3,res2)
#[1] TRUE

identical(makemx(x3,4),makeMat3(x3,4))
#[1] TRUE
?identical(makemx(x2,5),makeMat3(x2,5))
#[1] TRUE
?identical(makemx(x2,14),makeMat3(x2,14))
#[1] TRUE
?makemx(x2,3)
#Error in out[ix] <- 1 : subscript out of bounds
?makeMat3(x2,3)
#[1] "Not possible: Number of columns less than the maximum value of? 4 or length of vector"
#Error in makeMat3(x2, 3) : object 'm1' not found



A.K.




On Saturday, October 12, 2013 12:28 PM, arun <smartpink111 at yahoo.com> wrote:
Some speed comparison:


set.seed(124)
?xtest<- sample(0:9,1e7,replace=TRUE)
system.time({res1 <- makemx(xtest,9)}) 
#?? user? system elapsed 
# 51.124?? 0.812? 52.039 
?system.time({res2 <- makeMatrix2(xtest,9)}) 
#?? user? system elapsed 
#? 3.460?? 0.168?? 3.631 


identical(res1,res2)
#[1] TRUE


Also, it looks like there is some bugs still in the "makeMat3"
system.time({res3 <- makeMat3(xtest,9)})
#Error in rep(c(0, n), n - length(x)) : invalid 'times' argument
#Timing stopped at: 0.616 0 0.616 


A.K.


On Saturday, October 12, 2013 12:06 PM, arun <smartpink111 at yahoo.com> wrote:
This looks better.? My previous solution (makeMatrix2) also did the matrix indexing? without using sapply() route.? Replacing the max(x) by n for non-symmetric matrix:

makeMatrix2<- function(x,n){ #including "n"
?if(is.numeric(x)){
x <- as.integer(round(x))
x}
stopifnot(is.integer(x))
m1<- matrix(0,length(x),n) #change max(x) to n
?indx <- cbind(rep(seq_along(x),x),seq_len(sum(x))-rep(cumsum(c(0L,x[-length(x)])),x))
m1[indx]<- 1
m1}

identical(makeMatrix2(x3,4),makemx(x3,4))
#[1] TRUE

?identical(makeMatrix2(x1,5),makemx(x1,5))
#[1] TRUE

identical(makeMatrix2(x2,7),makemx(x2,7))
#[1] TRUE

A.K.






On Saturday, October 12, 2013 11:37 AM, Bert Gunter <gunter.berton at gene.com> wrote:
This seems to do it, but as I mentioned in my original post, my
"solution" was tricky. Thinking about it some more, I now realize that
it was too tricky and has the additional flaw of using underlying
representations of objects rather than their exposed interfaces -- i.e
it treats a matrix as a vector.

Here is, I think, a much better solution that treats a matrix as a
matrix by making use of a not-often-enough-used technique (mea culpa!)
of matrix indexing. It obviously needs to be cleaned up to check
inputs, etc. , but I think it should work. Feel free to publish and
clean up bugs.

makemx <- function(x,n)
{
? out <- matrix(0, nr=length(x), nc=n)
? ix <- cbind(rep(seq_along(x),x),unlist(sapply(x,seq_len)))
? out[ix]<- 1
? out
}

> makemx(c(3,2,1,4),4)
? ?? [,1] [,2] [,3] [,4]
[1,]? ? 1? ? 1? ? 1? ? 0
[2,]? ? 1? ? 1? ? 0? ? 0
[3,]? ? 1? ? 0? ? 0? ? 0
[4,]? ? 1? ? 1? ? 1? ? 1
> makemx(c(3,2,1,4),5)
? ?? [,1] [,2] [,3] [,4] [,5]
[1,]? ? 1? ? 1? ? 1? ? 0? ? 0
[2,]? ? 1? ? 1? ? 0? ? 0? ? 0
[3,]? ? 1? ? 0? ? 0? ? 0? ? 0
[4,]? ? 1? ? 1? ? 1? ? 1? ? 0

Cheers,
Bert


On Sat, Oct 12, 2013 at 1:02 AM, arun <smartpink111 at yahoo.com> wrote:
>
>
> Modified Bert's solution for non-square matrices.? For the tested vectors, it worked.? There, could still be some bugs.
>
> x1<- c(3,2,1,4)
>? x2<- c(2,0,4,3,1)
> x3 <- c(2, 1, 2.2)
> x4 <- c("a",1,3)
>
> makeMat3 <- function(x,n){
>? ? ? ? ? ?? if(is.numeric(x)){
> x <- as.integer(round(x))
> x}
> stopifnot(is.integer(x))
> indx<-rep(rep(c(1,0),n),c(as.vector(rbind(x,n-x)),rep(c(0,n),n-length(x))))
>? matrix(indx[seq_len(length(indx)-(n*(n-length(x))))],nc=n,byr=TRUE)
> }
> makeMat3(x1,4)
> makeMat3(x1,5)
> makeMat3(x1,6)
> makeMat3(x1,7)
>
>
> makeMat3(x2,7)
> makeMat3(x2,6)
> makeMat3(x2,4) # as length of vector > n
> #Error in rep(c(0, n), n - length(x)) : invalid 'times' argument
>
> makeMat3(x3,4)
> makeMat3(x3,5)
>
>? makeMat3(x4,4)
> #Error: is.integer(x) is not TRUE
>
> makeMat3(c(4,0,1,0,6),6)
>
> A.K.
>
>
>
> On Saturday, October 12, 2013 1:40 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> Your examples are the problem:
>
> On Fri, Oct 11, 2013 at 2:43 PM, arun <smartpink111 at yahoo.com> wrote:
>> Seems like a bug in the code:
>> x<- c(3,4,1)
>> n<- 3
>>? matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>> #Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument
>
> ## This can't work since x specifies 4 1's in the second row but you
> have specified a 3 column matrix with n.
>
>>? n<- 4
>>? matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>> #Error in rep(rep(c(1, 0), n), rbind(x, n - x)) : invalid 'times' argument
>
> Yes, this shows that my claim that non-square matrices also work is
> false. I leave it as an exercise to fix it so that it works for
> non-square matrices.
>
> Cheers,
> Bert
>
>
>
>> x2
>> [1] 2 0 4 3 1
>>> matrix(rep(rep(c(1,0),n),rbind(x2,n-x2)),nc=n,byr=TRUE)
>> Error in rep(rep(c(1, 0), n), rbind(x2, n - x2)) :
>>?? invalid 'times' argument
>>
>>
>> A.K.
>>
>>
>>
>>
>> On Friday, October 11, 2013 5:17 PM, Bert Gunter <gunter.berton at gene.com> wrote:
>> simpler (and sloppier) but with **no looping or apply's **
>>
>> **IFF* the matrix is structured as in the OP's example, then lower.tri
>> (or upper.tri) should be used:
>>
>> n <- 4 ## number of columns in matrix -- note that I changed it from
>> the example; does not have to be square
>>
>> x <- 1:3 ## the number of 1's per row
>> lower.tri(matrix(0,nr=length(x),nc=n),diagA=TRUE)+0
>>
>> A general, fast, but **tricky** way to do it that depends on knowing
>> that a matrix is just a vector in column major order is to generate
>> the vector using rep and then structure it as a matrix. eg.
>>
>> x <- c(3,2,1,4) ## your vector of indices
>> n <- 4 ## number of columns in matrix ## does not have to be square
>> matrix(rep(rep(c(1,0),n),rbind(x,n-x)),nc=n,byr=TRUE)
>>
>>? ?? [,1] [,2] [,3] [,4]
>> [1,]? ? 1? ? 1? ? 1? ? 0
>> [2,]? ? 1? ? 1? ? 0? ? 0
>> [3,]? ? 1? ? 0? ? 0? ? 0
>> [4,]? ? 1? ? 1? ? 1? ? 1
>>
>>
>> Cheers,
>> Bert
>>
>> On Fri, Oct 11, 2013 at 1:41 PM, Dennis Murphy <djmuser at gmail.com> wrote:
>>> Attempting to follow the OP's conditions and assuming I understood
>>> them correctly, here is one way to wrap this up into a function:
>>>
>>> makeMat <- function(x)
>>> {
>>>? ?? stopifnot(is.integer(x))
>>>? ?? nr <- length(x)
>>>? ?? nc <- max(x)
>>>
>>>? ?? # Initialize a matrix of zeros
>>>? ?? m <- matrix(0, nr, nc)
>>>? ?? # Conditionally replace with ones
>>>? ?? for(i in seq_len(nr)) if(x[i] != 0)? m[i, 1:x[i]] <- 1
>>>? ?? m
>>> }
>>>
>>> ## Examples:
>>> x1 <- 1:3
>>> x2 <- as.integer(c(2, 0, 4, 3, 1))
>>> x3 <- c(2, 1, 2.2)
>>>
>>> makeMat(x1)
>>> makeMat(x2)
>>> makeMat(x3)
>>> makeMat(4:6)
>>>
>>>
>>> On Fri, Oct 11, 2013 at 9:49 AM, arun <smartpink111 at yahoo.com> wrote:
>>>> Hi,
>>>>
>>>> In the example you showed:
>>>>
>>>> m1<- matrix(0,length(vec),max(vec))
>>>> 1*!upper.tri(m1)
>>>>
>>>> #or
>>>>? m1[!upper.tri(m1)] <-? rep(rep(1,length(vec)),vec)
>>>>
>>>> #But, in a case like below, perhaps:
>>>> vec1<- c(3,4,5)
>>>>
>>>>? m2<- matrix(0,length(vec1),max(vec1))
>>>>? indx <- cbind(rep(seq_along(vec1),vec1),unlist(tapply(vec1,list(vec1),FUN=seq),use.names=FALSE))
>>>> m2[indx]<- 1
>>>>? m2
>>>> #? ?? [,1] [,2] [,3] [,4] [,5]
>>>> #[1,]? ? 1? ? 1? ? 1? ? 0? ? 0
>>>> #[2,]? ? 1? ? 1? ? 1? ? 1? ? 0
>>>> #[3,]? ? 1? ? 1? ? 1? ? 1? ? 1
>>>>
>>>>
>>>>
>>>>
>>>> A.K.
>>>>
>>>>
>>>> Hi-
>>>>
>>>> I'd like to create a matrix of 0's and 1's where the number of
>>>> 1's in each row defined by the value indexed in another vector, and
>>>> where the (value-1) is back-filled by 0's.
>>>>
>>>> For example, given the following vector:
>>>> vec= c(1,2,3)
>>>>
>>>> I'd like to produce a matrix with dimensions (length(vec), max(vec)):
>>>>
>>>> 1,0,0
>>>> 1,1,0
>>>> 1,1,1
>>>>
>>>> Thank you!
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> (650) 467-7374

>
>>
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374




______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Oct 12 19:46:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 12 Oct 2013 10:46:16 -0700 (PDT)
Subject: [R] Loop over factor returns NA
In-Reply-To: <BAY176-W32B1B0E42845A0064D0D7AF5180@phx.gbl>
References: <BAY176-W32B1B0E42845A0064D0D7AF5180@phx.gbl>
Message-ID: <1381599976.12428.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Not sure if you have any restrictions in using ?lapply().
AB <- read.table(text="
????? time??????? x??????? y????? z??????? gene????? part
1? 03:27:58??? 1????? 2??????? 3??????? grom??????? 1
2? 03:27:58??? 2????? 3??????? 4??????? grom??????? 1
3? 03:27:58??? 3????? 4??????? 5??????? grom??????? 1
4? 04:44:23??? 12????? 13????? 14????? grom??????? 2
5? 04:44:23??? 13????? 14????? 15????? grom??????? 2
6? 04:44:23??? 14????? 15????? 16????? grom??????? 2
7? 04:44:23??? 15????? 16????? 17????? grom??????? 2
8? 06:23:45? 101??? 102??? 103??? vir??????????? 3
9? 06:23:45? 102??? 103??? 104??? vir??????????? 3
10 06:23:45? 103??? 104??? 105??? vir??????????? 3",sep="",header=TRUE,stringsAsFactors=FALSE)? 

str(AB)
#'data.frame':??? 10 obs. of? 6 variables:
# $ time: chr? "03:27:58" "03:27:58" "03:27:58" "04:44:23" ...
# $ x?? : int? 1 2 3 12 13 14 15 101 102 103
# $ y?? : int? 2 3 4 13 14 15 16 102 103 104
# $ z?? : int? 3 4 5 14 15 16 17 103 104 105
# $ gene: chr? "grom" "grom" "grom" "grom" ...
# $ part: int? 1 1 1 2 2 2 2 3 3 3


#It is not clear from the example whether you have multiple 'gene` within 'part' or 'time'.


res1 <- do.call(rbind,lapply(split(AB,AB$part),function(u) {
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? sdx<- sd(u$x)
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ????sdy<- sd(u$y)
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ????sdz <- sd(u$z)
???? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? tab<- data.frame(sdx,sdy,sdz,gene=u$gene[1],stringsAsFactors=FALSE)
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? }))
#Similarly for time

res2 <- do.call(rbind,lapply(split(AB,AB$time),function(u) {
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? sdx<- sd(u$x)
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ????sdy<- sd(u$y)
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ????sdz <- sd(u$z)
???? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? tab<- data.frame(sdx,sdy,sdz,gene=u$gene[1],stringsAsFactors=FALSE)
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? }))
?str(res1)
#'data.frame':??? 3 obs. of? 4 variables:
# $ sdx : num? 1 1.29 1
# $ sdy : num? 1 1.29 1
# $ sdz : num? 1 1.29 1
# $ gene: chr? "grom" "grom" "vir"

#Use
?write.table()

A.K.




On Saturday, October 12, 2013 11:12 AM, anna berg <anna.berg1986 at hotmail.com> wrote:
Dear R users,

I am pretty new to programming in R. So I guess there is some obvious mistake I am making. I hope you can help me.
I have a data frame that looks like this:

>? AB
? ? ? ? time? ? ? ? x? ? ? ? y? ? ?  z? ? ? ?  gene? ? ?  part
1?  03:27:58? ?  1? ? ?  2? ? ? ? 3? ? ? ? grom? ? ? ?  1
2?  03:27:58? ?  2? ? ?  3? ? ? ? 4? ? ? ? grom? ? ? ?  1
3?  03:27:58? ?  3? ? ?  4? ? ? ? 5? ? ? ? grom? ? ? ?  1
4?  04:44:23? ? 12? ? ? 13? ? ? 14? ? ? grom? ? ? ?  2
5?  04:44:23? ? 13? ? ? 14? ? ? 15? ? ? grom? ? ? ?  2
6?  04:44:23? ? 14? ? ? 15? ? ? 16? ? ? grom? ? ? ?  2
7?  04:44:23? ? 15? ? ? 16? ? ? 17? ? ? grom? ? ? ?  2
8?  06:23:45?  101? ?  102? ? 103? ? vir? ? ? ? ? ?  3
9?  06:23:45?  102? ?  103? ? 104? ? vir? ? ? ? ? ?  3
10 06:23:45?  103? ?  104? ? 105? ? vir? ? ? ? ? ?  3

Now I want to apply a loop (here a simplified version; I know that I could do this easily with tapply, but for the other things that I want to do with the loop (e.g. weighted mean of time series after fast fourier transformation) I would rather like to use a loop). 
Note that "time" and "part" are actually the same, just one is a factor and the the other is a number.
Here is the loop that works fine and returns the result as I want (the important part here is: Intervall <- AB[AB$part==i,]):

for(i in 1:length(unique(AB$time)))? 
{
? ? Intervall <- AB[AB$part==i,]
? ? attach(Intervall)
? ? # Standart deviation
? ? sdx? <-sd(x)
? ? sdy? <-sd(y)
? ? sdz? <-sd(z)
? ? # Add Behavior
? ?  gene <- as.character(Intervall[1,5])
? ? # Construct a table
? ? ? tab <-c(sdx, sdy, sdz, gene)
? ? ? write(tab, file=paste("VariableTable.txt", sep=""),
? ? ? ? ? ? ?  ncolumns=4,sep=",", append=TRUE)
? ? detach(Intervall)
}? # end of for loop

The result looks like this and is fine:

1,1,1,grom
1.3,1.3,1.3,grom
1,1,1,vir

My problem is, that I used the "part" column only to run the loop, but I actually want to use the time column to run the loop. But when I replace 

Intervall <- AB[AB$part==i,]
with
Intervall <- AB[AB$time==i,]

then the resulting table only contains NA.

I also tried to use Intervall <- AB[x==i,]

x <- as.factor(AB$part) --> which works fine as well
x <- as.factor(AB$time) --> which returns only NA 
x <- unique(AB$time) ---> which returns only NA
x <- levels(unique(AB$time) --> which returns only NA
x <- seq(unique(AB$time) ---> which returns the standard deviation of the entire column (not the single parts) 

What do I do wrong? And how can i fix it?

Thank you so much in advance.

Kind regards,
Anna

??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From istazahn at gmail.com  Sat Oct 12 21:23:37 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 12 Oct 2013 15:23:37 -0400
Subject: [R] Order of factors with facets in ggplot2
In-Reply-To: <CAO7OmOh51COUNzL09MBW84DY9n6W0bx0egP4vb0G=pT+rJzPAw@mail.gmail.com>
References: <CAO7OmOh51COUNzL09MBW84DY9n6W0bx0egP4vb0G=pT+rJzPAw@mail.gmail.com>
Message-ID: <CA+vqiLEMLWk3dPt2721YNBJyP-ZvU+sVazOwuEHqOcczF2GSNg@mail.gmail.com>

On Sat, Oct 12, 2013 at 12:01 PM, Lars Bishop <lars52r at gmail.com> wrote:
> Hello,
>
>
> I'd like to produce a ggplot where the order of factors within facets is
> based on the average of another variable.
>
>
> Here's a reproducible example. My problem is that the factors are ordered
> similarly in both facets. I would like to have, within each facet of `f1',
> boxplots for 'x' within each factor `f2', where the boxplots are ordered
> based on the average of x within each facet.

I think this is impossible if you keep your data in a single
data.frame, because there can only be one order of the factor levels.
You may have to split it out into separate data.frames, like this:

df.1 <- subset(df, f1 == "A")
df.2 <- subset(df, f1 == "B")

df.1$f2 <- reorder(df.1$f2, df.1$Avg_x)
df.2$f2 <- reorder(df.2$f2, df.2$Avg_x)

ggplot(mapping = aes(x=f2, y=x)) +
    geom_boxplot(data=df.1) +
    geom_boxplot(data=df.2) +
    stat_summary(data = df.1, fun.y=mean, geom="point", col = "red") +
    stat_summary(data = df.2, fun.y=mean, geom="point", col = "red") +
    facet_wrap(~ f1, scale = "free", ncol = 1)

Best,
Ista

>
>
> So in this case, for facet A: the order should be M4, M1, M3, M2; and for
> facet B: M4, M2, M1, M3
>
>
> library(ggplot2)
>
> library(plyr)
>
>
> set.seed(1)
>
> f1 <- sample(c("A", "B"), 100, replace= T)
>
> f2 <- gl(4, 25, labels = paste("M", 1:4, sep=""))
>
> x <- runif(100)
>
> df <- data.frame(f1, f2, x)
>
> #df <- df[order(df[,1]), ]
>
> df <- ddply(df, ~ f1 + f2, transform, Avg_x = mean(x))
>
>
> myplot <- ggplot(df, aes(x=reorder(f2, Avg_x), x)) + geom_boxplot() +
>
>   facet_wrap(~ f1, scale = "free", ncol = 1) +
>
>   stat_summary(fun.y=mean, geom="point", col = "red")
>
> myplot
>
>
> Thanks in advance for any help!
>
> Lars.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Oct 12 22:23:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 12 Oct 2013 13:23:24 -0700 (PDT)
Subject: [R] Order of factors with facets in ggplot2
In-Reply-To: <CAO7OmOh51COUNzL09MBW84DY9n6W0bx0egP4vb0G=pT+rJzPAw@mail.gmail.com>
References: <CAO7OmOh51COUNzL09MBW84DY9n6W0bx0egP4vb0G=pT+rJzPAw@mail.gmail.com>
Message-ID: <1381609404.53747.YahooMailNeo@web142602.mail.bf1.yahoo.com>



Hi,

As you using library(plyr), you may try:
library(ggplot2)
library(plyr)
df2 <- df
d1 <- dlply(df2,.(f1),function(u) {
??? ??? ??? ??? u$f2<- reorder(u$f2,u$Avg_x)
??? ??? ??? ??? ggplot(mapping=aes(x=f2,y=x))+
??? ??? ??? ??? geom_boxplot(data=u)+stat_summary(data=u,fun.y=mean,geom="point",col="red")+
??? ??? ??? ??? facet_wrap(~f1,scale="free",ncol=1)})
library(gridExtra)
grid.arrange(d1$A,d1$B,nrow=2)
# grid.arrange(d1$A,d1$B,nrow=2,main=textGrob("Facet grouping",gp=gpar(fontsize=15,font=1)))

A.K.


On Saturday, October 12, 2013 12:03 PM, Lars Bishop <lars52r at gmail.com> wrote:
Hello,


I'd like to produce a ggplot where the order of factors within facets is
based on the average of another variable.


Here's a reproducible example. My problem is that the factors are ordered
similarly in both facets. I would like to have, within each facet of `f1',
boxplots for 'x' within each factor `f2', where the boxplots are ordered
based on the average of x within each facet.


So in this case, for facet A: the order should be M4, M1, M3, M2; and for
facet B: M4, M2, M1, M3


library(ggplot2)

library(plyr)


set.seed(1)

f1 <- sample(c("A", "B"), 100, replace= T)

f2 <- gl(4, 25, labels = paste("M", 1:4, sep=""))

x <- runif(100)

df <- data.frame(f1, f2, x)

#df <- df[order(df[,1]), ]

df <- ddply(df, ~ f1 + f2, transform, Avg_x = mean(x))


myplot <- ggplot(df, aes(x=reorder(f2, Avg_x), x)) + geom_boxplot() +

? facet_wrap(~ f1, scale = "free", ncol = 1) +

? stat_summary(fun.y=mean, geom="point", col = "red")

myplot


Thanks in advance for any help!

Lars.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From sreckojoksimovic at gmail.com  Sun Oct 13 01:41:48 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Sat, 12 Oct 2013 16:41:48 -0700
Subject: [R] lmerTest
Message-ID: <CAM8BP_nng_enr8r38RLQT-wCDwEy99HgNih0f=v=TMBbrAbuYQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131012/f29cee56/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Sun Oct 13 02:43:31 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 12 Oct 2013 17:43:31 -0700
Subject: [R] lmerTest
In-Reply-To: <CAM8BP_nng_enr8r38RLQT-wCDwEy99HgNih0f=v=TMBbrAbuYQ@mail.gmail.com>
References: <CAM8BP_nng_enr8r38RLQT-wCDwEy99HgNih0f=v=TMBbrAbuYQ@mail.gmail.com>
Message-ID: <232a9a41-e8ab-4bcd-b5e8-162d678ed0c1@email.android.com>

Any idea what could be the problem? Hmmm...  posting in html? No reproducible example? Not posting on R-sig-ME? Just some ideas... reading the Posting Guide might be helpful to you.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

srecko joksimovic <sreckojoksimovic at gmail.com> wrote:
>Hi,
>
>I'm trying to user lmer function from lmerTest package because, if I
>understood correectly, it allows to make better inference than lmer
>method
>from lme4 package. However, whatever I do I keep getting this error:
>
>Error in lme4::lFormula(formula = mark ~ ssCount + sTime+  :  rank of X
>=
>1660 < ncol(X) = 1895
>
>any ideas what could be a problem?
>
>thanks,
>Srecko
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sreckojoksimovic at gmail.com  Sun Oct 13 02:52:25 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Sat, 12 Oct 2013 17:52:25 -0700
Subject: [R] lmerTest
In-Reply-To: <232a9a41-e8ab-4bcd-b5e8-162d678ed0c1@email.android.com>
References: <CAM8BP_nng_enr8r38RLQT-wCDwEy99HgNih0f=v=TMBbrAbuYQ@mail.gmail.com>
	<232a9a41-e8ab-4bcd-b5e8-162d678ed0c1@email.android.com>
Message-ID: <CAM8BP_k4pY2_1EHVp59CVJKX68tgCti=iejPV6R0tSnguHGkrg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131012/bff4210d/attachment.pl>

From rmh at temple.edu  Sun Oct 13 03:09:11 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sat, 12 Oct 2013 21:09:11 -0400
Subject: [R] export glht to LaTeX
In-Reply-To: <632DC273F0AF9345BC5AA487C9247A1C01304E2015@EX-MB3.tubit.win.tu-berlin.de>
References: <632DC273F0AF9345BC5AA487C9247A1C01304E2015@EX-MB3.tubit.win.tu-berlin.de>
Message-ID: <CAGx1TMAg=CPQE8_cwsihQJPhZi8oT0N7QeQi3m01BQZ3_8EPZg@mail.gmail.com>

The trick for latexing glht objects is recognizing that they are very complex.
It is necessary to isolate the part you want first,
then the latex() function in Hmisc works very well.

This example is based on one of the examples in ?glht

library(Hmisc)
library(multcomp)

  ### set up a one-way ANOVA
  amod <- aov(breaks ~ tension, data = warpbreaks)

  ### set up all-pair comparisons for factor `tension'
  ### using a symbolic description (`type' argument
  ### to `contrMat()')
  amod.glht <- glht(amod, linfct = mcp(tension = "Tukey"))

latex(confint(amod.glht)$confint, dec=3)

Look at
   str(amod.glht)
   str(confint(amod.glht))
   multcomp:::print.glht
   multcomp:::print.confint.glht
to see the details.


Rich

On Sat, Oct 12, 2013 at 9:33 AM, Winter, Jan-Christoph
<j.winter at tu-berlin.de> wrote:
> Hi,
>
> I want to export the result of glht  in R into a LaTeX table, such as that result:
>
> Linear Hypotheses:
>                                            Estimate Std.     Error z value Pr(>|z|)
> Group1 - Group2 == 0   -0.14007    0.01589  -8.813   <0.001 "***"
> Group1 - Group3 == 0    -0.09396    0.01575  -5.965   <0.001 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> (Adjusted p values reported -- single-step method)
>
> I'm aware of libraries like stargazer, xtable, texreg, reporttools, memisc and apsrtable, but none of them does the job for glht :(
>
> Does anyone have any hints?
>
> Thanks and best regards
> Jan Winter
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Sun Oct 13 05:46:48 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 13 Oct 2013 14:46:48 +1100
Subject: [R] Loop over factor returns NA
In-Reply-To: <BAY176-W32B1B0E42845A0064D0D7AF5180@phx.gbl>
References: <BAY176-W32B1B0E42845A0064D0D7AF5180@phx.gbl>
Message-ID: <525A17A8.9080107@bitwrit.com.au>

On 10/13/2013 02:12 AM, anna berg wrote:
> Dear R users,
>
> I am pretty new to programming in R. So I guess there is some obvious mistake I am making. I hope you can help me.
> I have a data frame that looks like this:
>
>>   AB
>          time        x        y       z         gene       part
> 1   03:27:58     1       2        3        grom         1
> 2   03:27:58     2       3        4        grom         1
> 3   03:27:58     3       4        5        grom         1
> 4   04:44:23    12      13      14      grom         2
> 5   04:44:23    13      14      15      grom         2
> 6   04:44:23    14      15      16      grom         2
> 7   04:44:23    15      16      17      grom         2
> 8   06:23:45   101     102    103    vir             3
> 9   06:23:45   102     103    104    vir             3
> 10 06:23:45   103     104    105    vir             3
>
> Now I want to apply a loop (here a simplified version; I know that I could do this easily with tapply, but for the other things that I want to do with the loop (e.g. weighted mean of time series after fast fourier transformation) I would rather like to use a loop).
> Note that "time" and "part" are actually the same, just one is a factor and the the other is a number.
> Here is the loop that works fine and returns the result as I want (the important part here is: Intervall<- AB[AB$part==i,]):
>
>   for(i in 1:length(unique(AB$time)))
>   {
>      Intervall<- AB[AB$part==i,]
>      attach(Intervall)
>      # Standart deviation
>      sdx<-sd(x)
>      sdy<-sd(y)
>      sdz<-sd(z)
>      # Add Behavior
>       gene<- as.character(Intervall[1,5])
>      # Construct a table
>        tab<-c(sdx, sdy, sdz, gene)
>        write(tab, file=paste("VariableTable.txt", sep=""),
>                 ncolumns=4,sep=",", append=TRUE)
>      detach(Intervall)
>   }  # end of for loop
>
> The result looks like this and is fine:
>
> 1,1,1,grom
> 1.3,1.3,1.3,grom
> 1,1,1,vir
>
> My problem is, that I used the "part" column only to run the loop, but I actually want to use the time column to run the loop. But when I replace
>
> Intervall<- AB[AB$part==i,]
> with
> Intervall<- AB[AB$time==i,]
>
> then the resulting table only contains NA.
>
> I also tried to use Intervall<- AB[x==i,]
>
> x<- as.factor(AB$part) -->  which works fine as well
> x<- as.factor(AB$time) -->  which returns only NA
> x<- unique(AB$time) --->  which returns only NA
> x<- levels(unique(AB$time) -->  which returns only NA
> x<- seq(unique(AB$time) --->  which returns the standard deviation of the entire column (not the single parts)
>
Hi Anna,
If "time" is a factor, then perhaps:

for(i in unique(AB$time)) {
...

this should also work if "time" is a character vector. I would look at:

unique(AB$time)

to see what is there.

Jim


From hwborchers at googlemail.com  Sun Oct 13 08:32:04 2013
From: hwborchers at googlemail.com (Hans W Borchers)
Date: Sun, 13 Oct 2013 06:32:04 +0000
Subject: [R] MCP solver
References: <9FE87F5AC4D0164989FD7A9C468C114EF41D55@EXMB-02.ad.wsu.edu>
Message-ID: <loom.20131013T082413-519@post.gmane.org>

Maxwell, John McFarland <jmmaxwell <at> wsu.edu> writes:

> Hello,
> 
> I'm trying to find a solver that will work for the mixed complementarity 
> problem (MCP). I've searched the CRAN task view page on optimization and 
> mathematical programming as well as many google searches to no avail.
> Does anyone know if there is an MCP solver available for R?
> 
> Thanks very much,
> 
> JM

The problem class of 'mixed complementary problems' is quite big and 
encompasses difficult optimization problems such as nonlinear systems of 
equations, nonlinear optimization problems, or optimization with equality 
constraints, among others.

There is no solver or package in R that will solve 'mixed complementary 
problems' in general. Perhaps your problem can be cast into a more specialized 
form that is accessible to one of the available solvers. Otherwise, GAMS has 
its own module for solving MCP problems.


From gergely at snowl.net  Sun Oct 13 12:37:40 2013
From: gergely at snowl.net (=?ISO-8859-1?Q?Gergely_Dar=F3czi?=)
Date: Sun, 13 Oct 2013 12:37:40 +0200
Subject: [R] Hungarian R User's Group: ggplot2 - The Grammar of Graphics
Message-ID: <CAPvvxJX2ovwc9DDF9yaA1FGhEPYBOSnKJu79-i2EWc4CLKVLiQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131013/d127eea6/attachment.pl>

From ligges at statistik.tu-dortmund.de  Sun Oct 13 14:45:31 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 13 Oct 2013 14:45:31 +0200
Subject: [R] lmerTest
In-Reply-To: <CAM8BP_k4pY2_1EHVp59CVJKX68tgCti=iejPV6R0tSnguHGkrg@mail.gmail.com>
References: <CAM8BP_nng_enr8r38RLQT-wCDwEy99HgNih0f=v=TMBbrAbuYQ@mail.gmail.com>	<232a9a41-e8ab-4bcd-b5e8-162d678ed0c1@email.android.com>
	<CAM8BP_k4pY2_1EHVp59CVJKX68tgCti=iejPV6R0tSnguHGkrg@mail.gmail.com>
Message-ID: <525A95EB.2090809@statistik.tu-dortmund.de>



On 13.10.2013 02:52, srecko joksimovic wrote:
> ok, ok... thanks.
> I'll try with R-sig-ME

Or for short, you are trying to estimate more coefficients than you have 
degrees of freedom which is what
rank of X = 1660 < ncol(X) = 1895
tries to tell us.

Best,
Uwe Ligges


>
> On Sat, Oct 12, 2013 at 5:43 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>wrote:
>
>> Any idea what could be the problem? Hmmm...  posting in html? No
>> reproducible example? Not posting on R-sig-ME? Just some ideas... reading
>> the Posting Guide might be helpful to you.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> srecko joksimovic <sreckojoksimovic at gmail.com> wrote:
>>> Hi,
>>>
>>> I'm trying to user lmer function from lmerTest package because, if I
>>> understood correectly, it allows to make better inference than lmer
>>> method
>> >from lme4 package. However, whatever I do I keep getting this error:
>>>
>>> Error in lme4::lFormula(formula = mark ~ ssCount + sTime+  :  rank of X
>>> =
>>> 1660 < ncol(X) = 1895
>>>
>>> any ideas what could be a problem?
>>>
>>> thanks,
>>> Srecko
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ch.haeni at gmail.com  Sun Oct 13 09:55:29 2013
From: ch.haeni at gmail.com (=?ISO-8859-1?Q?Christoph_H=E4ni?=)
Date: Sun, 13 Oct 2013 09:55:29 +0200
Subject: [R] matrix values linked to vector index
In-Reply-To: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CAOKy5g9CeaZPh=W4jpiGm9QDbD_GOX=X5bZ_0i85ZF5rtk+zoA@mail.gmail.com>

Just a further suggestion:

vec <- c(3,2,5,0,1)

mat <- t(sapply(vec,">=",1:max(vec)))

ifelse(mat,1,0)


Cheers,
Christoph

2013/10/11 arun <smartpink111 at yahoo.com>:
> Hi,
>
> In the example you showed:
>
> m1<- matrix(0,length(vec),max(vec))
> 1*!upper.tri(m1)
>
> #or
>  m1[!upper.tri(m1)] <-  rep(rep(1,length(vec)),vec)
>
> #But, in a case like below, perhaps:
> vec1<- c(3,4,5)
>
>  m2<- matrix(0,length(vec1),max(vec1))
>  indx <- cbind(rep(seq_along(vec1),vec1),unlist(tapply(vec1,list(vec1),FUN=seq),use.names=FALSE))
> m2[indx]<- 1
>  m2
> #     [,1] [,2] [,3] [,4] [,5]
> #[1,]    1    1    1    0    0
> #[2,]    1    1    1    1    0
> #[3,]    1    1    1    1    1
>
>
>
>
> A.K.
>
>
> Hi-
>
> I'd like to create a matrix of 0's and 1's where the number of
> 1's in each row defined by the value indexed in another vector, and
> where the (value-1) is back-filled by 0's.
>
> For example, given the following vector:
> vec= c(1,2,3)
>
> I'd like to produce a matrix with dimensions (length(vec), max(vec)):
>
> 1,0,0
> 1,1,0
> 1,1,1
>
> Thank you!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sun Oct 13 16:22:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 13 Oct 2013 07:22:25 -0700 (PDT)
Subject: [R] matrix values linked to vector index
In-Reply-To: <CAOKy5g9CeaZPh=W4jpiGm9QDbD_GOX=X5bZ_0i85ZF5rtk+zoA@mail.gmail.com>
References: <1381510188.88647.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAOKy5g9CeaZPh=W4jpiGm9QDbD_GOX=X5bZ_0i85ZF5rtk+zoA@mail.gmail.com>
Message-ID: <1381674145.74479.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Also:
mat+0
#or


mat*1

#However, sapply() based solutions would be slower in large matrices.

#Speed
makeMat3 <- function(x,n){
??????????? if(is.numeric(x)){
x <- as.integer(round(x))
x}
stopifnot(is.integer(x))
if(length(x)>=n & max(x)<=n){
indx<-rep(rep(c(1,0),max(length(x),n)),rbind(x,n-x))

m1<-? matrix(indx,nc=n,byr=TRUE)
}

else if(length(x) < n) {
indx<-rep(rep(c(1,0),n),c(as.vector(rbind(x,n-x)),rep(c(0,n),n-length(x))))
?m1<-matrix(indx[seq_len(length(indx)-(n*(n-length(x))))],nc=n,byr=TRUE)
}
else print(paste("Not possible: Number of columns less than the maximum value of ", max(x), "or length of vector"))
m1
}

set.seed(124)
? xtest<- sample(0:9,1e7,replace=TRUE)
?system.time(res3<- makeMat3(xtest,9))
#?? user? system elapsed 
?# 2.000?? 0.528?? 2.533 
?system.time({res4<- t(sapply(xtest,">=",1:max(xtest)))
?res4<- res4*1})
#?? user? system elapsed 
# 42.648?? 0.728? 43.461 
identical(res3,res4)
#[1] TRUE

A.K.


On Sunday, October 13, 2013 3:55 AM, Christoph H?ni <ch.haeni at gmail.com> wrote:
Just a further suggestion:

vec <- c(3,2,5,0,1)

mat <- t(sapply(vec,">=",1:max(vec)))

ifelse(mat,1,0)


Cheers,
Christoph


2013/10/11 arun <smartpink111 at yahoo.com>:
> Hi,
>
> In the example you showed:
>
> m1<- matrix(0,length(vec),max(vec))
> 1*!upper.tri(m1)
>
> #or
>? m1[!upper.tri(m1)] <-? rep(rep(1,length(vec)),vec)
>
> #But, in a case like below, perhaps:
> vec1<- c(3,4,5)
>
>? m2<- matrix(0,length(vec1),max(vec1))
>? indx <- cbind(rep(seq_along(vec1),vec1),unlist(tapply(vec1,list(vec1),FUN=seq),use.names=FALSE))
> m2[indx]<- 1
>? m2
> #? ?  [,1] [,2] [,3] [,4] [,5]
> #[1,]? ? 1? ? 1? ? 1? ? 0? ? 0
> #[2,]? ? 1? ? 1? ? 1? ? 1? ? 0
> #[3,]? ? 1? ? 1? ? 1? ? 1? ? 1
>
>
>
>
> A.K.
>
>
> Hi-
>
> I'd like to create a matrix of 0's and 1's where the number of
> 1's in each row defined by the value indexed in another vector, and
> where the (value-1) is back-filled by 0's.
>
> For example, given the following vector:
> vec= c(1,2,3)
>
> I'd like to produce a matrix with dimensions (length(vec), max(vec)):
>
> 1,0,0
> 1,1,0
> 1,1,1
>
> Thank you!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From sreckojoksimovic at gmail.com  Sun Oct 13 17:06:50 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Sun, 13 Oct 2013 08:06:50 -0700
Subject: [R] lmerTest
In-Reply-To: <525A95EB.2090809@statistik.tu-dortmund.de>
References: <CAM8BP_nng_enr8r38RLQT-wCDwEy99HgNih0f=v=TMBbrAbuYQ@mail.gmail.com>
	<232a9a41-e8ab-4bcd-b5e8-162d678ed0c1@email.android.com>
	<CAM8BP_k4pY2_1EHVp59CVJKX68tgCti=iejPV6R0tSnguHGkrg@mail.gmail.com>
	<525A95EB.2090809@statistik.tu-dortmund.de>
Message-ID: <CAM8BP_=xj8PYN88f4c6Tqr7RNjFCXb3jQ59G2+jy8=BWM_4-sw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131013/03f933f9/attachment.pl>

From smartpink111 at yahoo.com  Sun Oct 13 17:51:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 13 Oct 2013 08:51:10 -0700 (PDT)
Subject: [R] [Urgent]replace several rows in matrix with a vector
Message-ID: <1381679470.81865.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
a <- matrix(0,100,3) 
a1<- a
a2 <- a
somerows<- 1:5
b1<- t(replicate(length(somerows),b))
?a[somerows,]<- b1
head(a)

#or
?b2<- rep(b,each=length(somerows))
?a1[somerows,]<- b2

head(a1)
?identical(a,a1)
#[1] TRUE

?somerows2<- c(2,4,7,8,11,14)
?b3 <- rep(b,each=length(somerows2))
?a2[somerows2,] <- b3
head(a2,15)



A.K.

hi all, 

what i want to ask is how to replace rows with a vetor without looping. 

for example, I have one matrix like this, 

a<-matrix(0,100,3) 

and then, I want to replace some of rows with this vector, 

b<-c(1,2,3) 

when I use below code, the result is what I want, 

a[somerows,]<-t(b) 

result of a[somerows,] is 

1 ?2 ?1 
2 ?3 ?2 
3 ?1 ?3 
1 ?2 ?1 
2 ?3 ?2 
3 ?1 ?3 
1 ?2 ?1 


actually I want this format below, 

1 2 3 
1 2 3 
1 2 3 
1 2 3 
1 2 3 
1 2 3 

how can I solve this problem? 

Thanks,


From mi2kelgrum at yahoo.com  Sun Oct 13 18:41:29 2013
From: mi2kelgrum at yahoo.com (Mikkel Grum)
Date: Sun, 13 Oct 2013 09:41:29 -0700 (PDT)
Subject: [R] RODBC not connecting from my Mac
Message-ID: <1381682489.70706.YahooMailNeo@web126204.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131013/39225821/attachment.pl>

From byron_dom at yahoo.com  Sun Oct 13 19:53:35 2013
From: byron_dom at yahoo.com (Byron Dom)
Date: Sun, 13 Oct 2013 10:53:35 -0700 (PDT)
Subject: [R] How can I use a script "l" (LaTeX \ell) in mathematical
	annotation of plots?
Message-ID: <1381686815.6320.YahooMailNeo@web142802.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131013/83fcd833/attachment.pl>

From ripley at stats.ox.ac.uk  Sun Oct 13 22:06:11 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 13 Oct 2013 21:06:11 +0100
Subject: [R] How can I use a script "l" (LaTeX \ell) in mathematical
 annotation of plots?
In-Reply-To: <1381686815.6320.YahooMailNeo@web142802.mail.bf1.yahoo.com>
References: <1381686815.6320.YahooMailNeo@web142802.mail.bf1.yahoo.com>
Message-ID: <525AFD33.1070600@stats.ox.ac.uk>

On 13/10/2013 18:53, Byron Dom wrote:
> Due to convention a script "l" - $$\ell$$ (LaTeX \ell) is used to represent a certain quantity in something I'm working on. I'm unable to figure out how to use it in R. It's not included in the list on ?plotmath.
>
> Can anyone tell me how to use it?  Its unicode is U+2113. This page has a list of various encodings of it: http://www.fileformat.info/info/unicode/char/2113/encoding.htm.  Is there a way to include it by using one of these encodings somehow?
> 	[[alternative HTML version deleted]]

What do you want to do with it?  plotmath is about plotting, but you 
have not otherwise mentioned that, let alone the device on which you 
want to plot.

Read the help for plotmath: on some plot devices, just use "\u2113".  It 
is not AFAICS in the Adobe symbol encoding.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From David.Epstein at warwick.ac.uk  Sun Oct 13 23:04:50 2013
From: David.Epstein at warwick.ac.uk (David Epstein)
Date: Sun, 13 Oct 2013 22:04:50 +0100
Subject: [R] using a variable for a column name in a formula
Message-ID: <BAF722F7-259C-4036-A123-FEFC37E58BFB@warwick.ac.uk>

lm(height ~ ., data=X)
works fine.

However
nnn <- "height" ;  lm(nnn ~ . ,data=X)
fails

How do I write such a formula, which depends on the value of a string variable like nnn above?

A typical application might be a program that takes a data frame containing only numerical data, and figures out which of the columns can be best predicted from all the other columns.
 
Thanks
David


From sarah.goslee at gmail.com  Sun Oct 13 23:40:09 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 13 Oct 2013 17:40:09 -0400
Subject: [R] using a variable for a column name in a formula
In-Reply-To: <BAF722F7-259C-4036-A123-FEFC37E58BFB@warwick.ac.uk>
References: <BAF722F7-259C-4036-A123-FEFC37E58BFB@warwick.ac.uk>
Message-ID: <CAM_vjun-ehFnhPnL+_72JaaZzxmcTsWrvztp3AjLBu5eRm9A7A@mail.gmail.com>

This being R, there are likely other ways, but I use:

lm(as.formula(paste(nnn, "~ .")),data=X)


Sarah

On Sun, Oct 13, 2013 at 5:04 PM, David Epstein
<David.Epstein at warwick.ac.uk> wrote:
> lm(height ~ ., data=X)
> works fine.
>
> However
> nnn <- "height" ;  lm(nnn ~ . ,data=X)
> fails
>
> How do I write such a formula, which depends on the value of a string variable like nnn above?
>
> A typical application might be a program that takes a data frame containing only numerical data, and figures out which of the columns can be best predicted from all the other columns.
>
> Thanks
> David
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From smartpink111 at yahoo.com  Sun Oct 13 23:53:18 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 13 Oct 2013 14:53:18 -0700 (PDT)
Subject: [R] using a variable for a column name in a formula
In-Reply-To: <BAF722F7-259C-4036-A123-FEFC37E58BFB@warwick.ac.uk>
References: <BAF722F7-259C-4036-A123-FEFC37E58BFB@warwick.ac.uk>
Message-ID: <1381701198.60319.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,

May be:
set.seed(24)
?X <- data.frame(weight=sample(100:250,20,replace=TRUE),height=sample(140:190,20,replace=TRUE))
Others <- colnames(X)[!colnames(X)%in%"height"]
?nnn <- "height"
res <- lm(formula(paste(nnn,"~",paste(Others, sep="+"))),data=X)
?res1<- lm(height~.,data=X)

#or
res2<- lm(get(nnn)~get(Others),data=X) #needs some renaming of rownames


?identical(coef(summary(res)),coef(summary(res1)))
#[1] TRUE
A.K.


On Sunday, October 13, 2013 5:06 PM, David Epstein <David.Epstein at warwick.ac.uk> wrote:
lm(height ~ ., data=X)
works fine.

However
nnn <- "height" ;? lm(nnn ~ . ,data=X)
fails

How do I write such a formula, which depends on the value of a string variable like nnn above?

A typical application might be a program that takes a data frame containing only numerical data, and figures out which of the columns can be best predicted from all the other columns.

Thanks
David

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Mon Oct 14 00:00:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 13 Oct 2013 15:00:26 -0700 (PDT)
Subject: [R] using a variable for a column name in a formula
In-Reply-To: <1381701198.60319.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <BAF722F7-259C-4036-A123-FEFC37E58BFB@warwick.ac.uk>
	<1381701198.60319.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1381701626.76266.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Sorry, a mistake in the code:
#should be "collapse" instead of "sep"
res <- lm(formula(paste(nnn,"~",paste(Others, collapse="+"))),data=X)


A.K.


On Sunday, October 13, 2013 5:55 PM, arun <smartpink111 at yahoo.com> wrote:


Hi,

May be:
set.seed(24)
?X <- data.frame(weight=sample(100:250,20,replace=TRUE),height=sample(140:190,20,replace=TRUE))
Others <- colnames(X)[!colnames(X)%in%"height"]
?nnn <- "height"
res <- lm(formula(paste(nnn,"~",paste(Others, sep="+"))),data=X)
?res1<- lm(height~.,data=X)

#or
res2<- lm(get(nnn)~get(Others),data=X) #needs some renaming of rownames


?identical(coef(summary(res)),coef(summary(res1)))
#[1] TRUE
A.K.


On Sunday, October 13, 2013 5:06 PM, David Epstein <David.Epstein at warwick.ac.uk> wrote:
lm(height ~ ., data=X)
works fine.

However
nnn <- "height" ;? lm(nnn ~ . ,data=X)
fails

How do I write such a formula, which depends on the value of a string variable like nnn above?

A typical application might be a program that takes a data frame containing only numerical data, and figures out which of the columns can be best predicted from all the other columns.

Thanks
David

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From p_connolly at slingshot.co.nz  Mon Oct 14 00:05:01 2013
From: p_connolly at slingshot.co.nz (p_connolly)
Date: Mon, 14 Oct 2013 11:05:01 +1300
Subject: [R] using a variable for a column name in a formula
In-Reply-To: <BAF722F7-259C-4036-A123-FEFC37E58BFB@warwick.ac.uk>
References: <BAF722F7-259C-4036-A123-FEFC37E58BFB@warwick.ac.uk>
Message-ID: <089f959a40d0ebfcd61f465590bab27d@slingshot.co.nz>

On 2013-10-14 10:04, David Epstein wrote:
> lm(height ~ ., data=X)
> works fine.
> 
> However
> nnn <- "height" ;  lm(nnn ~ . ,data=X)
> fails
> 
> How do I write such a formula, which depends on the value of a string
> variable like nnn above?

as.formula() with paste() could work, but from where you are now, try
lm(get(nnn) ~ . ,data=X)


HTH

> 
> A typical application might be a program that takes a data frame
> containing only numerical data, and figures out which of the columns
> can be best predicted from all the other columns.
> 
> Thanks
> David
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mi2kelgrum at yahoo.com  Mon Oct 14 00:11:27 2013
From: mi2kelgrum at yahoo.com (Mikkel Grum)
Date: Sun, 13 Oct 2013 15:11:27 -0700 (PDT)
Subject: [R] Loop over factor returns NA
In-Reply-To: <BAY176-W32B1B0E42845A0064D0D7AF5180@phx.gbl>
References: <BAY176-W32B1B0E42845A0064D0D7AF5180@phx.gbl>
Message-ID: <1381702287.58716.YahooMailNeo@web126202.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131013/84595514/attachment.pl>

From smartpink111 at yahoo.com  Mon Oct 14 00:13:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 13 Oct 2013 15:13:03 -0700 (PDT)
Subject: [R] using a variable for a column name in a formula
In-Reply-To: <089f959a40d0ebfcd61f465590bab27d@slingshot.co.nz>
References: <BAF722F7-259C-4036-A123-FEFC37E58BFB@warwick.ac.uk>
	<089f959a40d0ebfcd61f465590bab27d@slingshot.co.nz>
Message-ID: <1381702383.89105.YahooMailNeo@web142604.mail.bf1.yahoo.com>


Hi,
I am getting this:

#Using an example dataset:
set.seed(24)
?X <- data.frame(weight=sample(100:250,20,replace=TRUE),height=sample(140:190,20,replace=TRUE))

nnn <- "height"

res <- lm(as.formula(paste(nnn, "~.")),data=X)
?res2 <- lm(get(nnn) ~ . ,data=X)
?coef(res)
?(Intercept)?????? weight 
169.24873241? -0.03881928 


coef(res2)
? (Intercept)??????? weight??????? height 
-7.890309e-14? 1.518345e-17? 1.000000e+00 
A.K.


On Sunday, October 13, 2013 6:06 PM, p_connolly <p_connolly at slingshot.co.nz> wrote:
On 2013-10-14 10:04, David Epstein wrote:
> lm(height ~ ., data=X)
> works fine.
> 
> However
> nnn <- "height" ;? lm(nnn ~ . ,data=X)
> fails
> 
> How do I write such a formula, which depends on the value of a string
> variable like nnn above?

as.formula() with paste() could work, but from where you are now, try
lm(get(nnn) ~ . ,data=X)


HTH

> 
> A typical application might be a program that takes a data frame
> containing only numerical data, and figures out which of the columns
> can be best predicted from all the other columns.
> 
> Thanks
> David
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From mi2kelgrum at yahoo.com  Mon Oct 14 00:27:26 2013
From: mi2kelgrum at yahoo.com (Mikkel Grum)
Date: Sun, 13 Oct 2013 15:27:26 -0700 (PDT)
Subject: [R] Looping over names of multiple data frames in an R for()
	loop	XXXX
In-Reply-To: <CAPRGo-n03++5PczFAwWX9JYtdMUp_PZQ5N3zdyo8T-jzv34jcQ@mail.gmail.com>
References: <CAPRGo-n03++5PczFAwWX9JYtdMUp_PZQ5N3zdyo8T-jzv34jcQ@mail.gmail.com>
Message-ID: <1381703246.53506.YahooMailNeo@web126203.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131013/a6a90612/attachment.pl>

From mi2kelgrum at yahoo.com  Mon Oct 14 01:15:26 2013
From: mi2kelgrum at yahoo.com (Mikkel Grum)
Date: Sun, 13 Oct 2013 16:15:26 -0700 (PDT)
Subject: [R] Loop over factor returns NA
In-Reply-To: <BAY176-W32B1B0E42845A0064D0D7AF5180@phx.gbl>
References: <BAY176-W32B1B0E42845A0064D0D7AF5180@phx.gbl>
Message-ID: <1381706126.73722.YahooMailNeo@web126201.mail.ne1.yahoo.com>

You'll need to tell us what class you time variable is in, e.g. the output of str(AB), but the following might work: for (i in unique(as.character(AB$time)) {
Intervall <- AB[as.character(AB$time) ==i, ]
...
} Depending on the format, as.numeric( ) might work too. Regards
Mikkel 



On Saturday, October 12, 2013 12:16 PM, anna berg <anna.berg1986 at hotmail.com> wrote:
Dear R users,

I am pretty new to programming in R. So I guess there is some obvious mistake I am making. I hope you can help me.
I have a data frame that looks like this:

>? AB
? ? ? ? time? ? ? ? x? ? ? ? y? ? ?  z? ? ? ?  gene? ? ?  part
1?  03:27:58? ?  1? ? ?  2? ? ? ? 3? ? ? ? grom? ? ? ?  1
2?  03:27:58? ?  2? ? ?  3? ? ? ? 4? ? ? ? grom? ? ? ?  1
3?  03:27:58? ?  3? ? ?  4? ? ? ? 5? ? ? ? grom? ? ? ?  1
4?  04:44:23? ? 12? ? ? 13? ? ? 14? ? ? grom? ? ? ?  2
5?  04:44:23? ? 13? ? ? 14? ? ? 15? ? ? grom? ? ? ?  2
6?  04:44:23? ? 14? ? ? 15? ? ? 16? ? ? grom? ? ? ?  2
7?  04:44:23? ? 15? ? ? 16? ? ? 17? ? ? grom? ? ? ?  2
8?  06:23:45?  101? ?  102? ? 103? ? vir? ? ? ? ? ?  3
9?  06:23:45?  102? ?  103? ? 104? ? vir? ? ? ? ? ?  3
10 06:23:45?  103? ?  104? ? 105? ? vir? ? ? ? ? ?  3

Now I want to apply a loop (here a simplified version; I know that I could do this easily with tapply, but for the other things that I want to do with the loop (e.g. weighted mean of time series after fast fourier transformation) I would rather like to use a loop). 
Note that "time" and "part" are actually the same, just one is a factor and the the other is a number.
Here is the loop that works fine and returns the result as I want (the important part here is: Intervall <- AB[AB$part==i,]):

for(i in 1:length(unique(AB$time)))? 
{
? ? Intervall <- AB[AB$part==i,]
? ? attach(Intervall)
? ? # Standart deviation
? ? sdx? <-sd(x)
? ? sdy? <-sd(y)
? ? sdz? <-sd(z)
? ? # Add Behavior
? ?  gene <- as.character(Intervall[1,5])
? ? # Construct a table
? ? ? tab <-c(sdx, sdy, sdz, gene)
? ? ? write(tab, file=paste("VariableTable.txt", sep=""),
? ? ? ? ? ? ?  ncolumns=4,sep=",", append=TRUE)
? ? detach(Intervall)
}? # end of for loop

The result looks like this and is fine:

1,1,1,grom
1.3,1.3,1.3,grom
1,1,1,vir

My problem is, that I used the "part" column only to run the loop, but I actually want to use the time column to run the loop. But when I replace 

Intervall <- AB[AB$part==i,]
with
Intervall <- AB[AB$time==i,]

then the resulting table only contains NA.

I also tried to use Intervall <- AB[x==i,]

x <- as.factor(AB$part) --> which works fine as well
x <- as.factor(AB$time) --> which returns only NA 
x <- unique(AB$time) ---> which returns only NA
x <- levels(unique(AB$time) --> which returns only NA
x <- seq(unique(AB$time) ---> which returns the standard deviation of the entire column (not the single parts) 

What do I do wrong? And how can i fix it?

Thank you so much in advance.

Kind regards,
Anna

??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From mi2kelgrum at yahoo.com  Mon Oct 14 01:13:34 2013
From: mi2kelgrum at yahoo.com (Mikkel Grum)
Date: Sun, 13 Oct 2013 16:13:34 -0700 (PDT)
Subject: [R] RODBC on Mac
Message-ID: <1381706014.11881.YahooMailNeo@web126206.mail.ne1.yahoo.com>

iODBC appears no longer to come standard with OSX, so I installed unixodbc and set it up following instructions here:?http://www.boriel.com/en/2013/01/16/postgresql-odbc-connection-from-mac-os-x/

I connected to my remote database with isql -v mydsn. No problem. Then I tried from R:

> library(RODBC)
> pg <- odbcConnect("mydsn") ?# waited for a couple of minutes before pressing Ctrl-C
^C
There were 50 or more warnings (use warnings() to see the first 50)
> warnings()[1:2]
Warning messages:
1: In odbcDriverConnect("DSN=mydsn") :
? [RODBC] ERROR: state IM002, code 1606406032, message [iODBC][Driver Manager]Data source name not found and no default driver specified. Driver could not be loaded
2: In odbcDriverConnect("DSN=mydsn") :
? [RODBC] ERROR: state IM002, code 1606406032, message [iODBC][Driver Manager]Data source name not found and no default driver specified. Driver could not be loaded

It looks like RODBC might only work with iODBC on the Mac. Is that the case? I haven't been able to configure iODBC correctly, and therefore haven't been able to test whether that would work with RODBC. Any chance that I can get RODBC to work with unixodbc? Any other information that would be useful in resolving it?

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] C/UTF-8/C/C/C/C

attached base packages:
[1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base ? ??

other attached packages:
[1] RODBC_1.3-8

Regards
Mikkel


PS. Apologies for repeating this message. I previously sent it with HTML formatting.


From longoc at cca.ufsc.br  Mon Oct 14 02:13:47 2013
From: longoc at cca.ufsc.br (longoc at cca.ufsc.br)
Date: Sun, 13 Oct 2013 21:13:47 -0300
Subject: [R] ENMCA in EnQuireR problems!
Message-ID: <20131013211347.g0dmimdd748oow48@webmail.cca.ufsc.br>

Hello,

I am a post-doc of the Federal University of Santa Catarina State  
(UFSC). Last year, used EnQuireR for hirarchical cluster analisis and  
end up very well. I formated my computer couple months ago and  
installed R again as
version x64 3.0.2. have new data which ENMCA function of EnQuireR  
package is not running.

R seems to be fine as it runs funcions of other packages. Even MCA  
fuction of EnQuireR is working well. This makes me understand that R  
is reading my data. In EnQuireR, after selecting the clusters, it run  
up to
the two graphics and then stop in Device 3 with some error messages . Even
the file exemple "tea" the ENMCA fuction is not running.

What I did was:

b<-read.table("AbdonMCA_20131004.csv",header=T,row.names=1,sep=";",dec=",",na.string="nan")

There is no problem to open the file. It runs frequency distribution  
by summary" and other statistics.


What I did was:

b<-read.table("AbdonMCA_20131004.csv",header=T,row.names=1,sep=";",dec=",",na.string="nan")

It opens with no problem. Run frequency distribution by "summary" and  
other statistics.
However, when it do the cluster analysis, it stops as soon as it gets  
Device 3 with the following error msg:

> b.res<-ENMCA(b[,1:5])
Erro em if (del == 0 && to == 0) return(to) :
   absent value where TRUE/FALSE is need
Al?m disso: There were 50 or more warnings (use warnings() to see the  
first 50)

OR SOMETHINGS:

Erro em seq.default(-ylimit, ylimit, 0.01 * ylimit) :
   'from' cannot be NA, NaN or infinite
Al?m disso: There were 50 or more warnings (use warnings() to see the  
first 50)


For your information, data has some missing values. I have the R x64  
3.0.2.  I use Windows 64bits.

I do appreciate any suggestion.

Regards

Cibele


From smartpink111 at yahoo.com  Mon Oct 14 05:38:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 13 Oct 2013 20:38:58 -0700 (PDT)
Subject: [R] Splitting times into groups based on a range of times
In-Reply-To: <894643FDEA3A854A89B3E828737E2B1F016520962910@HERMES8.ds.leeds.ac.uk>
References: <894643FDEA3A854A89B3E828737E2B1F01652096290B@HERMES8.ds.leeds.ac.uk>,
	<1381454998.88168.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<894643FDEA3A854A89B3E828737E2B1F01652096290E@HERMES8.ds.leeds.ac.uk>,
	<1381529949.21646.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<894643FDEA3A854A89B3E828737E2B1F016520962910@HERMES8.ds.leeds.ac.uk>
Message-ID: <1381721938.9956.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi Ben,

It looks like the condition is not met in majority of the split elements.? So, when you create a dataframe with the a column with 0 element and another column with an element, it shows the Error message.
data.frame(dt2=NULL,group=1)
#Error in data.frame(dt2 = NULL, group = 1) : 
?# arguments imply differing number of rows: 0, 1


You can do this:
lst1 <- split(df.new,df.new$start.end.group)
lst2 <- lapply(lst1,function(x){dt2=dt.new[dt.new>=x[1,1] & dt.new < x[length(x),1]]})
lst3 <- lst2[lapply(lst2,length)>0]

df1.new <- do.call(rbind,lapply(lst1[names(lst1)%in% names(lst3)],function(x) {data.frame(dt2=dt.new[dt.new>= x[1,1] & dt.new < x[length(x),1]],group=x[1,2])}))


#You could also do this from `lst3` and create groups as the names of the list elements as both are the same.
?head(df1.new)
#???????????????????? dt2 group
#61.1 2012-08-02 19:16:14??? 61
#61.2 2012-08-02 19:18:14??? 61
#61.3 2012-08-02 19:20:14??? 61
#61.4 2012-08-02 19:22:14??? 61
#61.5 2012-08-02 19:24:14??? 61
#61.6 2012-08-02 19:26:14??? 61
?tail(df1.new[df1.new$group==61,],2)
#?????????????????????? dt2 group
#61.366 2012-08-03 07:26:14??? 61
#61.367 2012-08-03 07:28:14??? 61




lst1[[61]]
? # ???????????? dt2.new start.end.group
#61? 2012-08-02 19:15:00????????????? 61
#200 2012-08-03 07:30:00????????????? 61


? A.K.






On Sunday, October 13, 2013 3:55 PM, Benjamin Gillespie <gybrg at leeds.ac.uk> wrote:
Hi Arun,

This is great - it works perfectly for the data I provided you.

However, I've spent almost all today trying to apply it to my real world dataset... and for some reason I keep getting the error: "Error in data.frame(dt2 = dt.new[dt.new >= x[1, 1] & dt.new < x[length(x),? : arguments imply differing number of rows: 0, 1" when trying to build df1.

It's quite odd and I can't figure out why!!

I have attached my script file and two data files. logger2.csv is used to create 'df' and discharge.csv is used to define the 'floods' (it includes river discharge data) which are then assigned ID's. As before, I want to then assign these flood id's to the relevant times in 'df'.


From mi2kelgrum at yahoo.com  Mon Oct 14 05:35:23 2013
From: mi2kelgrum at yahoo.com (Mikkel Grum)
Date: Sun, 13 Oct 2013 20:35:23 -0700 (PDT)
Subject: [R] R plotting
In-Reply-To: <1381495546828-4678056.post@n4.nabble.com>
References: <1381495546828-4678056.post@n4.nabble.com>
Message-ID: <1381721723.65456.YahooMailNeo@web126205.mail.ne1.yahoo.com>

Hi

This seems to work:
spdata$color <- ifelse(spdata$change < 0, "red", "green")
plot(spdata$date, log(spdata$close), col = spdata$color)

Regards
Mikkel


On Friday, October 11, 2013 5:14 PM, Mubar <simon.keusen at student.unisg.ch> wrote:
Hi

I have a question regarding plots in R. I have data from the S&P 500 in the
format:

date? ? ? ? ?  close? ?  change
1980-01-07? 109.92?  3.4

I plotted the data with plot(spdata$date, log(spdata$close), type="p")

Now I want to ad the colors green and red to the data frame. if the change
is positive it should be green, if negative, red. Also the colors should be
in the plot. I tried to do this with the ifelse function, but seem to be
stuck.

Can anyone help me with this?

Thanks a lot!




--
View this message in context: http://r.789695.n4.nabble.com/R-plotting-tp4678056.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From sham3287 at gmail.com  Mon Oct 14 06:09:54 2013
From: sham3287 at gmail.com (Shameem Akhtar)
Date: Mon, 14 Oct 2013 09:39:54 +0530
Subject: [R] R help
Message-ID: <CADb+ogAZqybwvsmb6EyWx_ys484vQm1Wur381pSNKKJt1a=Sog@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131014/10e80161/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Mon Oct 14 08:50:45 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 13 Oct 2013 23:50:45 -0700
Subject: [R] R help
In-Reply-To: <CADb+ogAZqybwvsmb6EyWx_ys484vQm1Wur381pSNKKJt1a=Sog@mail.gmail.com>
References: <CADb+ogAZqybwvsmb6EyWx_ys484vQm1Wur381pSNKKJt1a=Sog@mail.gmail.com>
Message-ID: <26628e4e-fb2d-4132-a485-e6bb2a4113d0@email.android.com>

Why? I assume you posted because you want help with something, but it is going to be very difficult to help if you don't know the most basic things about R or this mailing list.
Spreadsheet: R can import data from a spreadsheet, but the corresponding native terminology in R is "data.frame" or "matrix" depending on what kind of data you are working with. This is important because R does not behave at all like a spreadsheet and you will confuse us and yourself if you get this mixed up.
For loop: It is unusual to do most calculations in R with for loops. It is almost always better to use vector calculations and indexing. Read the Introduction to R document that comes with R. In particular, per your question, logical indexing or the subset function can be used to find particular values.
If else: There are two forms of if-else in R. The if function is used for choosing among code blocks, while the ifelse function is used for vector calculations. I imagine you were thinking of the former, but in many cases the latter is more appropriate.
Mailing list: Please read the Posting Guide. Posting in HTML is strongly discouraged, as it makes a mess of R code. Learn how to send plain text emails. Also, this is not a homework help forum, so if this is related to a class then get help there because we don't know what your instructor thinks is fair help. Finally, please show us what you have already tried including input data (this is known as providing a reproducible example).
If this all seems a bit much then you are probably in the wrong place. It takes some effort to make sure your question is understood using only email. Fortunately, once you learn the basics of the R language it is possible to communicate very precisely in email.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Shameem Akhtar <sham3287 at gmail.com> wrote:
>Dear,
>             I want to use for loop and if..else condition together for
>finding such value from a two column in a spreadsheet.
>
>
>
>
>
>
>Thanks & Regards
>Shameem Akhtar
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon Oct 14 09:41:19 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 14 Oct 2013 09:41:19 +0200
Subject: [R] using a variable for a column name in a formula
In-Reply-To: <CAM_vjun-ehFnhPnL+_72JaaZzxmcTsWrvztp3AjLBu5eRm9A7A@mail.gmail.com>
References: <BAF722F7-259C-4036-A123-FEFC37E58BFB@warwick.ac.uk>
	<CAM_vjun-ehFnhPnL+_72JaaZzxmcTsWrvztp3AjLBu5eRm9A7A@mail.gmail.com>
Message-ID: <9CF1D697-BD69-4068-A271-28D75BBE5E35@gmail.com>


On Oct 13, 2013, at 23:40 , Sarah Goslee wrote:

> This being R, there are likely other ways, but I use:
> 
> lm(as.formula(paste(nnn, "~ .")),data=X)
> 

That'll do for most purposes, but fortune("parse") applies. In particular: What happens if nnn is like "weight (kg)"?

I'd prefer to do a little computing on the language, as in

fml <- dummy ~ .
fml[[2]] <- as.name(nnn)
lm(fml, data=X)

[bquote() can be useful too, just beware that the result needs as.formula to become one, i.e. 

nnsym <- as.name(nnn)
fml <- as.formula(bquote(.(nnsym) ~ .))

It saves you the trouble of having to figure out how to index your way into the formula, which in the present case isn't really hard, but it will be if you need to substitute something in a complicated right hand side.]

-pd

> 
> Sarah
> 
> On Sun, Oct 13, 2013 at 5:04 PM, David Epstein
> <David.Epstein at warwick.ac.uk> wrote:
>> lm(height ~ ., data=X)
>> works fine.
>> 
>> However
>> nnn <- "height" ;  lm(nnn ~ . ,data=X)
>> fails
>> 
>> How do I write such a formula, which depends on the value of a string variable like nnn above?
>> 
>> A typical application might be a program that takes a data frame containing only numerical data, and figures out which of the columns can be best predicted from all the other columns.
>> 
>> Thanks
>> David
>> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From zemlys at gmail.com  Sat Oct 12 12:44:43 2013
From: zemlys at gmail.com (Vaidotas Zemlys)
Date: Sat, 12 Oct 2013 13:44:43 +0300
Subject: [R] [R-pkgs] new package 'midasr'
Message-ID: <905536DC-D16E-40F9-AEC3-0C7A485D57A5@gmail.com>

Dear list members,

A new package, called *midasr* (version 0.1), is now available on 
CRAN: http://cran.r-project.org/package=midasr

This package provides econometric methods for working with mixed frequency data. The package provides tools for estimating the time series MIDAS regression, where the response and explanatory variables are of different frequency, e.g. quarterly vs monthly. The fitted regression model can be tested for adequacy and then used for forecasting. More specifically, the following main functions are available:

   * midas_r -- MIDAS regression estimation using non-linear least squares.
   * mls -- time series embedding to lower frequency, flexible function for specifying MIDAS models.
   * hAh.test and hAhr.test -- adequacy testing of MIDAS regression.
   * forecast -- forecasting MIDAS regression.
   * midasr_ic_table -- lag selection using information criteria.
   * average_forecast -- calculate weighted forecast combination.
   * select_and_forecast -- perform model selection and then use the selected model for forecasting.

The package provides the usual methods for generic functions which can be used on fitted MIDAS regression object: summary, coef, residuals, deviance, fitted, predict, logLik. It also has additional methods for estimating robust standard errors: estfun and bread.

The package also provides all the popular MIDAS regression restrictions such as normalized Almon exponential lag, normalized beta lag and etc.

The package has the project webpage (http://mpiktas.github.io/midasr/) and you can follow its development on github (https://github.com/mpiktas/midasr).

The detailed description of the package features can be found in the user guide. The user guide, all of the code examples in the user guide and some additional examples together with the user guide .Rnw file can be found in the midasr-user-guide github repository (https://github.com/mpiktas/midasr-user-guide/).

Comments and suggestions would be greatly appreciated.

Vaidotas Zemlys
http://mif.vu.lt/~zemlys

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From andrej.g.miller at web.de  Mon Oct 14 09:49:06 2013
From: andrej.g.miller at web.de (Andrej)
Date: Mon, 14 Oct 2013 00:49:06 -0700 (PDT)
Subject: [R] Comparing two groups
Message-ID: <1381736946485-4678190.post@n4.nabble.com>

Hi,
this might sound trivial, but I'm pretty new to R and statistics in general. 
What I want to do is to compare two data values. The hook is, that they are
non-normally distributed and that one value is five times as big as the
other. The box-plots look like this 
<http://r.789695.n4.nabble.com/file/n4678190/mixture_vs_monoculture.png>  .
Ignore the number at the bottom. I want to know if those two are
significantly different from one another. I tried it with the wilcox-test
(because it is advertised as a non-parametric test), but get a p-value of
0.0009 and naturally don't quite believe it to be true.
Do you have any suggestions how I can handle that problem?

Andrej



--
View this message in context: http://r.789695.n4.nabble.com/Comparing-two-groups-tp4678190.html
Sent from the R help mailing list archive at Nabble.com.


From paladini at trustindata.de  Mon Oct 14 10:33:14 2013
From: paladini at trustindata.de (paladini at trustindata.de)
Date: Mon, 14 Oct 2013 10:33:14 +0200
Subject: [R] Transform plot3d grafics in to executable files
Message-ID: <20131014103314.Horde.GvTFpk_ymYFkrdC-ZKpo8g9@webmail.df.eu>

Hello,
I did some nice grafics using plot 3d and scatter3d. Is there a,  
hopefully not too complicated way, to transform these dynamic,  
three-dimensional and interactive grafics in a kind of
executable file? I want to show and send them via e-mail to projekt  
partners who don`t use GNU R and who are not used to do programming.  
So the result should be quite comfortable to execute for them in  
windows.

I hope my question is not too naive.


Thanking you in anticipation and best regards

Claudia


From petr.pikal at precheza.cz  Mon Oct 14 12:07:39 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 14 Oct 2013 10:07:39 +0000
Subject: [R] Comparing two groups
In-Reply-To: <1381736946485-4678190.post@n4.nabble.com>
References: <1381736946485-4678190.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B96D50@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Andrej
> Sent: Monday, October 14, 2013 9:49 AM
> To: r-help at r-project.org
> Subject: [R] Comparing two groups
> 
> Hi,
> this might sound trivial, but I'm pretty new to R and statistics in
> general.

So why not start with some statistical textbook? There are plenty of them available in CRAN.

> What I want to do is to compare two data values. The hook is, that they
> are non-normally distributed and that one value is five times as big as
> the other. The box-plots look like this
> <http://r.789695.n4.nabble.com/file/n4678190/mixture_vs_monoculture.png
> >  .
> Ignore the number at the bottom. I want to know if those two are
> significantly different from one another. I tried it with the wilcox-
> test (because it is advertised as a non-parametric test), but get a p-
> value of
> 0.0009 and naturally don't quite believe it to be true.

Why? What leads you to this statement? Some other tests? Some other results?

> Do you have any suggestions how I can handle that problem?

You can try some normalising procedure like Box-Cox.

function (x, lambda, inv = F) 
{
    if (!inv) {
        if (missing(lambda)) 
            log(x)
        else (x^lambda - 1)/lambda
    }
    else (lambda * x + 1)^(1/lambda)
  }

or boxcox from MASS package.

and then to use standard t.test, but you will probably gat quite similar result as with wilcox.test.

Regards
Petr

> 
> Andrej
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Comparing-
> two-groups-tp4678190.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Alex.Johnson at theaa.com  Mon Oct 14 14:39:30 2013
From: Alex.Johnson at theaa.com (Johnson, Alex)
Date: Mon, 14 Oct 2013 13:39:30 +0100
Subject: [R] automation of an R script to run
In-Reply-To: <CAFEqCdy+kjQb5P-2-GbkJdYD-vCFTHV6QONe3QRAecgrt8Ev1g@mail.gmail.com>
References: <6DBEEF9C09ACF64B8BCFE8F66EDA1B1F05622725@aa-exb01.theaa.local>
	<CAFEqCdy+kjQb5P-2-GbkJdYD-vCFTHV6QONe3QRAecgrt8Ev1g@mail.gmail.com>
Message-ID: <6DBEEF9C09ACF64B8BCFE8F66EDA1B1F05622753@aa-exb01.theaa.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131014/1ffd776f/attachment.pl>

From dan.abner99 at gmail.com  Mon Oct 14 17:09:58 2013
From: dan.abner99 at gmail.com (Dan Abner)
Date: Mon, 14 Oct 2013 11:09:58 -0400
Subject: [R] Passing multiple object names to a user-defined R fn XXXX
Message-ID: <CAPRGo-md6FoV98K4_ZXtmmo3HCfW9D4X0QGn8gEe3p1hs1uzCw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131014/0f927726/attachment.pl>

From michel.arnaud at cirad.fr  Mon Oct 14 17:27:35 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Mon, 14 Oct 2013 17:27:35 +0200
Subject: [R] add points on an existant ggplot from another dataframe
In-Reply-To: <D2481C4481A28E4DB7720AE86BE937616DC260D6@SRV-AME-EX2KX.personnel.mines-ales.fr>
References: <D2481C4481A28E4DB7720AE86BE937616DC260D6@SRV-AME-EX2KX.personnel.mines-ales.fr>
Message-ID: <525C0D67.8080901@cirad.fr>

Hello
I had draw the results of PCA (Principal Components Analysis) (1)
Is it possible to put on this graphic the 75% ellipse confidence of each 
sex calculated by dataEllipse (library(car)) ?

My code is
1) PCA data frame with 169 rows and 2 columns
library(ggplot2)
p <- ggplot(PCA, aes(x=F1, y=F2 ))
p + geom_point(aes(colour = Sexe, shape = Sexe), size=3) +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0) +
labs(title = "ACP",
x = "Facteur 1", y = "Facteur 2",fill = "Sexe") +
theme(legend.position = c(0.95,0.95),
legend.background = element_rect(colour = "black"))

2) library(car)
XH <- dataEllipse(
X1[ACP$Sexe=="H"],
X2[ACP$Sexe=="H"],
levels=0.75, lty=2, add=TRUE, plot.points=FALSE, center.cex=0, col=4)

XF <- dataEllipse(
X1[ACP$Sexe=="F"],
X2[ACP$Sexe=="F"],
levels=0.75, lty=2, add=TRUE, plot.points=FALSE, center.cex=0, col=2)

XH and XF are two matrix with 2 columns and 52 rows
Thank you for your help

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From hill0093 at umn.edu  Mon Oct 14 17:29:02 2013
From: hill0093 at umn.edu (Hurr)
Date: Mon, 14 Oct 2013 08:29:02 -0700 (PDT)
Subject: [R] rjava be-carefuls
In-Reply-To: <1381530521780-4678102.post@n4.nabble.com>
References: <1381530521780-4678102.post@n4.nabble.com>
Message-ID: <1381764542184-4678201.post@n4.nabble.com>

No answers in the three days. Does anyone use rjava?
If no one uses it, then I am afraid to try.
Or is it extremely easy?




--
View this message in context: http://r.789695.n4.nabble.com/rjava-be-carefuls-tp4678102p4678201.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Mon Oct 14 17:31:16 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 14 Oct 2013 15:31:16 +0000
Subject: [R] Passing multiple object names to a user-defined R fn XXXX
In-Reply-To: <CAPRGo-md6FoV98K4_ZXtmmo3HCfW9D4X0QGn8gEe3p1hs1uzCw@mail.gmail.com>
References: <CAPRGo-md6FoV98K4_ZXtmmo3HCfW9D4X0QGn8gEe3p1hs1uzCw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B96EAF@SRVEXCHMBX.precheza.cz>

Hi

I will not answer your question directly but instead I have some recommendation for you. If you can put these data frames to one list object when you creates them, you can save yourself a lot of troubles.

some.list<-vector("list", n)
for (i in 1:n) {
some.list[[i]] <- some extensive computation or reading files
}

then you can use lapply/sapply/for cycle to make any computation directly on list.

I use R for more than 10 years and I do not remember any situation when I would need to create multiple objects in "n1":"nx" naming manner.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Dan Abner
> Sent: Monday, October 14, 2013 5:10 PM
> To: r-help at r-project.org
> Subject: [R] Passing multiple object names to a user-defined R fn XXXX
> 
> Hi all,
> 
> I am attempting to write an R fn that will accept multiple (but varying
> on how many) objects (usually data frames) as inputs and return summary
> output.
> 
> What is the best way to pass the object names to the fn (I have thought
> of
> 2 options below) AND how do I then use the names inside the fn to
> reference the actual object (I assume that I would need something like
> get(x[1]) for example to have "d1" resolve the the object d1. Correct?
> 
> The 1st option I thought of was to pass the object names as a character
> vector in the call to the fn:
> 
> set.matrix<-df.set(c("d1","d2","d3","d4","d5","d6","d7","d8"),by="ID")
> 2nd option: Is something like this possible:
> 
> set.matrix<-df.set(c(d1,d2,d3,d4,d5,d6,d7,d8),by="ID")
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Mon Oct 14 17:33:50 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 14 Oct 2013 11:33:50 -0400
Subject: [R] add points on an existant ggplot from another dataframe
In-Reply-To: <525C0D67.8080901@cirad.fr>
References: <D2481C4481A28E4DB7720AE86BE937616DC260D6@SRV-AME-EX2KX.personnel.mines-ales.fr>
	<525C0D67.8080901@cirad.fr>
Message-ID: <CA+vqiLEc_Zz7Bha2s41EJU56q0BKSzjwPzbySUFY9fr-1PoNww@mail.gmail.com>

Michael,
Do not cross-post! I've answered this question on the ggplot2 list.

On Mon, Oct 14, 2013 at 11:27 AM, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
> Hello
> I had draw the results of PCA (Principal Components Analysis) (1)
> Is it possible to put on this graphic the 75% ellipse confidence of each sex
> calculated by dataEllipse (library(car)) ?
>
> My code is
> 1) PCA data frame with 169 rows and 2 columns
> library(ggplot2)
> p <- ggplot(PCA, aes(x=F1, y=F2 ))
> p + geom_point(aes(colour = Sexe, shape = Sexe), size=3) +
> geom_hline(yintercept = 0) +
> geom_vline(xintercept = 0) +
> labs(title = "ACP",
> x = "Facteur 1", y = "Facteur 2",fill = "Sexe") +
> theme(legend.position = c(0.95,0.95),
> legend.background = element_rect(colour = "black"))
>
> 2) library(car)
> XH <- dataEllipse(
> X1[ACP$Sexe=="H"],
> X2[ACP$Sexe=="H"],
> levels=0.75, lty=2, add=TRUE, plot.points=FALSE, center.cex=0, col=4)
>
> XF <- dataEllipse(
> X1[ACP$Sexe=="F"],
> X2[ACP$Sexe=="F"],
> levels=0.75, lty=2, add=TRUE, plot.points=FALSE, center.cex=0, col=2)
>
> XH and XF are two matrix with 2 columns and 52 rows
> Thank you for your help
>
> --
> Michel ARNAUD
> Charg? de mission aupr?s du DRH
> DGDRD-Drh - TA 174/04
> Av Agropolis 34398 Montpellier cedex 5
> tel : 04.67.61.75.38
> fax : 04.67.61.57.87
> port: 06.47.43.55.31
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Mon Oct 14 17:43:10 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 14 Oct 2013 16:43:10 +0100
Subject: [R] Passing multiple object names to a user-defined R fn XXXX
In-Reply-To: <CAPRGo-md6FoV98K4_ZXtmmo3HCfW9D4X0QGn8gEe3p1hs1uzCw@mail.gmail.com>
References: <CAPRGo-md6FoV98K4_ZXtmmo3HCfW9D4X0QGn8gEe3p1hs1uzCw@mail.gmail.com>
Message-ID: <525C110E.40205@sapo.pt>

Hello,

You should put all those data frames in a list and then use the list 
(just one object).
But if you have several objects in your workspace and need to write a 
function that accepts a varying number of arguments, use the dots argument:

df.set <- function(..., by){
	dots <- list(...)  # all those objects in a list
	for(d in dots)
		print(summary(d))
	invisible(NULL)
}

d1 <- data.frame(x = 1:4, y = 5:8)
d2 <- data.frame(a = 1:10, b = 11:20)

df.set(d1, d2)


Note that I don't use c(d1, d2), it will give something completely 
different. c() has unwanted side effects. Try it.


Hope this helps,

Rui Barradas

Em 14-10-2013 16:09, Dan Abner escreveu:
> Hi all,
>
> I am attempting to write an R fn that will accept multiple (but varying on
> how many) objects (usually data frames) as inputs and return summary output.
>
> What is the best way to pass the object names to the fn (I have thought of
> 2 options below) AND how do I then use the names inside the fn to reference
> the actual object (I assume that I would need something like get(x[1]) for
> example to have "d1" resolve the the object d1. Correct?
>
> The 1st option I thought of was to pass the object names as a character
> vector in the call to the fn:
>
> set.matrix<-df.set(c("d1","d2","d3","d4","d5","d6","d7","d8"),by="ID")
> 2nd option: Is something like this possible:
>
> set.matrix<-df.set(c(d1,d2,d3,d4,d5,d6,d7,d8),by="ID")
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tring at gvdnet.dk  Mon Oct 14 17:52:58 2013
From: tring at gvdnet.dk (Troels Ring)
Date: Mon, 14 Oct 2013 17:52:58 +0200
Subject: [R] simple postscript question
Message-ID: <525C135A.9040904@gvdnet.dk>

Dear friends - following instructions via google I managed to have the 
following eps accepted well in words - but I cannot get a decent 
postscript print from Gswiew, latest edition. The ylab is printed only 
in half, the par(mar seems inconsequential. I hope you will forgive this 
simple question.
Best wishes
Troels Ring
Aalborg, Denmark
Windows 7, R 3.0.1

postscript(file="fig1.eps", horizontal = FALSE, onefile = FALSE,
pagecentre=TRUE,paper = "special",colormodel = "rgb",width=8,height=8)
par(cex=1.25,cex.lab=1.25,cex.axis=1.5,mar=c(5.1,5,4,2))
xyplot(Ammonium+SID~time|GRP,comb1,type=c("p","smooth"),
ylab="Ammonium excretion (line) and SID excretion (stippled), mmol/day")
dev.off()

I use BullGuard Spamfilter to keep my inbox clean.
It is completely free: www.bullguard.com/freespamfilter


From gunter.berton at gene.com  Mon Oct 14 17:59:21 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 14 Oct 2013 08:59:21 -0700
Subject: [R] Passing multiple object names to a user-defined R fn XXXX
In-Reply-To: <525C110E.40205@sapo.pt>
References: <CAPRGo-md6FoV98K4_ZXtmmo3HCfW9D4X0QGn8gEe3p1hs1uzCw@mail.gmail.com>
	<525C110E.40205@sapo.pt>
Message-ID: <CACk-te0v3iMdJyAHtZGRx89HSU8RtWGUW00XXF=bfQkg1sP2yg@mail.gmail.com>

A minor quibble.

I would argue that R best practice would be to keep the summarization
and printing separate; viz

df.set <- function(...){
        dots <- list(...)  # all those objects in a list

}

On Mon, Oct 14, 2013 at 8:43 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> You should put all those data frames in a list and then use the list (just
> one object).
> But if you have several objects in your workspace and need to write a
> function that accepts a varying number of arguments, use the dots argument:
>
> df.set <- function(..., by){
>         dots <- list(...)  # all those objects in a list
>         for(d in dots)
>                 print(summary(d))
>         invisible(NULL)
> }
>
> d1 <- data.frame(x = 1:4, y = 5:8)
> d2 <- data.frame(a = 1:10, b = 11:20)
>
> df.set(d1, d2)
>
>
> Note that I don't use c(d1, d2), it will give something completely
> different. c() has unwanted side effects. Try it.
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 14-10-2013 16:09, Dan Abner escreveu:
>>
>> Hi all,
>>
>> I am attempting to write an R fn that will accept multiple (but varying on
>> how many) objects (usually data frames) as inputs and return summary
>> output.
>>
>> What is the best way to pass the object names to the fn (I have thought of
>> 2 options below) AND how do I then use the names inside the fn to
>> reference
>> the actual object (I assume that I would need something like get(x[1]) for
>> example to have "d1" resolve the the object d1. Correct?
>>
>> The 1st option I thought of was to pass the object names as a character
>> vector in the call to the fn:
>>
>> set.matrix<-df.set(c("d1","d2","d3","d4","d5","d6","d7","d8"),by="ID")
>> 2nd option: Is something like this possible:
>>
>> set.matrix<-df.set(c(d1,d2,d3,d4,d5,d6,d7,d8),by="ID")
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From gunter.berton at gene.com  Mon Oct 14 18:01:13 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 14 Oct 2013 09:01:13 -0700
Subject: [R] Passing multiple object names to a user-defined R fn XXXX
In-Reply-To: <CACk-te0v3iMdJyAHtZGRx89HSU8RtWGUW00XXF=bfQkg1sP2yg@mail.gmail.com>
References: <CAPRGo-md6FoV98K4_ZXtmmo3HCfW9D4X0QGn8gEe3p1hs1uzCw@mail.gmail.com>
	<525C110E.40205@sapo.pt>
	<CACk-te0v3iMdJyAHtZGRx89HSU8RtWGUW00XXF=bfQkg1sP2yg@mail.gmail.com>
Message-ID: <CACk-te2OAWY_1ZRctsAQL-Zp-Wwjj-kuaDFYYc+n1QOGAuCrKw@mail.gmail.com>

Sorry about the previous partial message. My email screwed up. Here's
the complete message:

df.set <- function(...){
        dots <- list(...)  # all those objects in a list
        lapply(dots,summary)
}

Cheers,
Bert

On Mon, Oct 14, 2013 at 8:59 AM, Bert Gunter <bgunter at gene.com> wrote:
> A minor quibble.
>
> I would argue that R best practice would be to keep the summarization
> and printing separate; viz
>
> df.set <- function(...){
>         dots <- list(...)  # all those objects in a list
>
> }
>
> On Mon, Oct 14, 2013 at 8:43 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>> Hello,
>>
>> You should put all those data frames in a list and then use the list (just
>> one object).
>> But if you have several objects in your workspace and need to write a
>> function that accepts a varying number of arguments, use the dots argument:
>>
>> df.set <- function(..., by){
>>         dots <- list(...)  # all those objects in a list
>>         for(d in dots)
>>                 print(summary(d))
>>         invisible(NULL)
>> }
>>
>> d1 <- data.frame(x = 1:4, y = 5:8)
>> d2 <- data.frame(a = 1:10, b = 11:20)
>>
>> df.set(d1, d2)
>>
>>
>> Note that I don't use c(d1, d2), it will give something completely
>> different. c() has unwanted side effects. Try it.
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 14-10-2013 16:09, Dan Abner escreveu:
>>>
>>> Hi all,
>>>
>>> I am attempting to write an R fn that will accept multiple (but varying on
>>> how many) objects (usually data frames) as inputs and return summary
>>> output.
>>>
>>> What is the best way to pass the object names to the fn (I have thought of
>>> 2 options below) AND how do I then use the names inside the fn to
>>> reference
>>> the actual object (I assume that I would need something like get(x[1]) for
>>> example to have "d1" resolve the the object d1. Correct?
>>>
>>> The 1st option I thought of was to pass the object names as a character
>>> vector in the call to the fn:
>>>
>>> set.matrix<-df.set(c("d1","d2","d3","d4","d5","d6","d7","d8"),by="ID")
>>> 2nd option: Is something like this possible:
>>>
>>> set.matrix<-df.set(c(d1,d2,d3,d4,d5,d6,d7,d8),by="ID")
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From rusa.sarka at gmail.com  Mon Oct 14 12:31:13 2013
From: rusa.sarka at gmail.com (=?UTF-8?B?xaDDoXJrYSBSdXPDoQ==?=)
Date: Mon, 14 Oct 2013 12:31:13 +0200
Subject: [R] singularity problem
Message-ID: <CANSYE6u=c+1-2k4XcxyggZkLcjzk5sgSpA9MZ=Q=x_RpW-ufPg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131014/2db0e77b/attachment.pl>

From Kile.Green at newcastle.ac.uk  Mon Oct 14 12:57:32 2013
From: Kile.Green at newcastle.ac.uk (Kile Green)
Date: Mon, 14 Oct 2013 10:57:32 +0000
Subject: [R] Help with combining functions
Message-ID: <71A9F37B694303439E0627F5D05323B56E2697@EXMBCT03.campus.ncl.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131014/5b5dbe4d/attachment.pl>

From valeria.muzzolini at uniud.it  Mon Oct 14 13:47:29 2013
From: valeria.muzzolini at uniud.it (Valeria Muzzolini)
Date: Mon, 14 Oct 2013 13:47:29 +0200
Subject: [R] repeat a linear regression model
Message-ID: <525BD9D1.9020706@uniud.it>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131014/adb4d100/attachment.pl>

From jmmaxwell at wsu.edu  Mon Oct 14 18:46:05 2013
From: jmmaxwell at wsu.edu (Maxwell, John McFarland)
Date: Mon, 14 Oct 2013 16:46:05 +0000
Subject: [R] MCP solver
In-Reply-To: <loom.20131013T082413-519@post.gmane.org>
References: <9FE87F5AC4D0164989FD7A9C468C114EF41D55@EXMB-02.ad.wsu.edu>
	<loom.20131013T082413-519@post.gmane.org>
Message-ID: <9FE87F5AC4D0164989FD7A9C468C114EF42139@EXMB-02.ad.wsu.edu>

Thanks for the response! The specific type of MCP I'm trying to solve is a square system of nonlinear equations with complementarity conditions (a computable general equilibrium model for predicting economic outcomes). The PATH solver in GAMS would certainly work for it, however as I don't have consistent access to GAMS or the PATH solver, I was hoping to find a way to run the model in R. I think the BB package could handle a system of nonlinear equations, but I'm not sure about the complementarity aspect. Is there a package that you know of that can do this?

Thanks again,

JM

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Hans W Borchers
Sent: Saturday, October 12, 2013 11:32 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] MCP solver

Maxwell, John McFarland <jmmaxwell <at> wsu.edu> writes:

> Hello,
> 
> I'm trying to find a solver that will work for the mixed 
> complementarity problem (MCP). I've searched the CRAN task view page 
> on optimization and mathematical programming as well as many google searches to no avail.
> Does anyone know if there is an MCP solver available for R?
> 
> Thanks very much,
> 
> JM

The problem class of 'mixed complementary problems' is quite big and encompasses difficult optimization problems such as nonlinear systems of equations, nonlinear optimization problems, or optimization with equality constraints, among others.

There is no solver or package in R that will solve 'mixed complementary problems' in general. Perhaps your problem can be cast into a more specialized form that is accessible to one of the available solvers. Otherwise, GAMS has its own module for solving MCP problems.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From vdemart at gmail.com  Mon Oct 14 15:52:35 2013
From: vdemart at gmail.com (Victor)
Date: Mon, 14 Oct 2013 15:52:35 +0200
Subject: [R] x12 doesn't work any longer
Message-ID: <84B471C0-DFBB-4C7B-BA28-C3DF54D4A739@gmail.com>

Context: Mac OS X 10.7 - R 3.0.2 GUI 1.62 Snow Leopard build (6558)

I had been using x12 for some time with no problem at all. every month I update the time series ricpesata (see below) and run the simple procedure below. Now adding the data of the last month, Sep.2013, 
x12 is complaining:

> library(x12)
> x<-x12(round(ricpesata,2), x12path="/Applications/x12arima/x12a", automdl=TRUE, decimals=2,  transform="log", outlier="all", forecast_years=2)
Error in .local(object, x12Parameter, x12BaseInfo, ...) : 
  unused arguments (x12path = "/Applications/x12arima/x12a", automdl = TRUE, decimals = 2, transform = "log", outlier = "all", forecast_years = 2)

where
> str(round(ricpesata,2))
 Time-Series [1:285] from 1990 to 2014: 20924 20559 19952 19366 19145 ...
>  

is the following timeseries:

          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug      Sep      Oct      Nov      Dec
1990 20924.30 20559.41 19952.28 19365.96 19145.28 19536.69 19791.74 15796.91 19690.72 19779.16 20444.38 20529.32
1991 21155.47 21613.96 20168.89 19584.45 19527.75 19765.04 20314.15 16116.04 20232.00 20391.31 21200.69 21093.83
1992 21570.88 21877.04 21129.40 .........

What does that error mean and what should I do?

Thanks in advance
Vittorio

From dwinsemius at comcast.net  Mon Oct 14 18:57:06 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 14 Oct 2013 09:57:06 -0700
Subject: [R] simple postscript question
In-Reply-To: <525C135A.9040904@gvdnet.dk>
References: <525C135A.9040904@gvdnet.dk>
Message-ID: <7EACDABD-22EE-44B5-A658-FF65CBDD5352@comcast.net>


On Oct 14, 2013, at 8:52 AM, Troels Ring wrote:

> Dear friends - following instructions via google I managed to have the following eps accepted well in words - but I cannot get a decent postscript print from Gswiew, latest edition. The ylab is printed only in half, the par(mar seems inconsequential. I hope you will forgive this simple question.
> Best wishes
> Troels Ring
> Aalborg, Denmark
> Windows 7, R 3.0.1
> 
> postscript(file="fig1.eps", horizontal = FALSE, onefile = FALSE,
> pagecentre=TRUE,paper = "special",colormodel = "rgb",width=8,height=8)
> par(cex=1.25,cex.lab=1.25,cex.axis=1.5,mar=c(5.1,5,4,2))
> xyplot(Ammonium+SID~time|GRP,comb1,type=c("p","smooth"),
> ylab="Ammonium excretion (line) and SID excretion (stippled), mmol/day")
> dev.off()
> 

`par` is used for base graphics. xyplot is a lattice/grid function. There are specific methods describe in the documentaiton of xyplot for handling par-type-settings in lattice functions.

Furthermore, you have not yet appreciated FAQ 7.22

--

David Winsemius
Alameda, CA, USA


From David.Howell at uvm.edu  Mon Oct 14 19:01:35 2013
From: David.Howell at uvm.edu (David C. Howell)
Date: Mon, 14 Oct 2013 11:01:35 -0600
Subject: [R] Extracting elements of model output
Message-ID: <525C236F.6010703@uvm.edu>

I am having difficulty extracting specific results from the model 
object. The following code shows where I am stuck.

I want to run resamplings of a data set. For each I want to extract a 
particular F for the contrasts. If I run a very simple model
(e.g. model1 <- aov(time~group) ) I can get the relevant coefficients, 
for example, by using "model1$coefficients". That's fine. But I don't 
want the coefficients of the model, I want the contrasts. So I tried
model2=summary(model1, split = list(group = list("1&3 vs 2"=1, "1 vs 3" 
= 2)))
This gives me the printout summary table that I want. i.e.

model2
Df Sum Sq Mean Sq F value Pr(>F)
group 2 4090 2045 8.081 0.000682 ***
group: 1&3 vs 2 1 1483 1484 5.863 0.017988 *
group: 1 vs 3 1 2606 2606 10.300 0.001987 **
Residuals 72 18219 253

That's the summary table that I want, but I want to extract, for example 
the F value of 5.863.

Looking at the structure of that object I get

str(model2)
List of 1
$ :Classes ?anova? and 'data.frame': 4 obs. of 5 variables:
..$ Df : Named num [1:4] 2 1 1 72
.. ..- attr(*, "names")= chr [1:4] "" "1&3 vs 2" "1 vs 3" ""
..$ Sum Sq : Named num [1:4] 4090 1483 2606 18219
.. ..- attr(*, "names")= chr [1:4] "" "1&3 vs 2" "1 vs 3" ""
..$ Mean Sq: Named num [1:4] 2045 1483 2606 253
.. ..- attr(*, "names")= chr [1:4] "" "1&3 vs 2" "1 vs 3" ""
..$ F value: Named num [1:4] 8.08 5.86 10.3 NA
.. ..- attr(*, "names")= chr [1:4] "" "1&3 vs 2" "1 vs 3" ""
..$ Pr(>F) : Named num [1:4] 0.000682 0.017988 0.001987 NA

What I would like to do is to request result$"F value[2]"
but that just gives "NULL."

I note that if I request the structure for model 1, the first element is 
$Df. But when I ask for the structure of model2, the first element is 
..$Df. I assume that those two dots represent an ellipsis, but nothing 
is ?str, ?attr, or other help screens tell me how to interpret and use 
..Df or any of the other elements.

Any help?

Thanks,
Dave Howell


From HDoran at air.org  Mon Oct 14 19:05:15 2013
From: HDoran at air.org (Doran, Harold)
Date: Mon, 14 Oct 2013 17:05:15 +0000
Subject: [R] repeat a linear regression model
In-Reply-To: <525BD9D1.9020706@uniud.it>
References: <525BD9D1.9020706@uniud.it>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686644075AD@DC1VEX10MB001.air.org>

Well, see the help page for by() or an apply() function. But, YIKES, maybe work with a statistician who can help you with the underlying issue. 

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Valeria Muzzolini
Sent: Monday, October 14, 2013 7:47 AM
To: r-help at r-project.org
Subject: [R] repeat a linear regression model

Hello,
I'd like to repeat a linear regression model for groups of rows that are identified by an ID number.
My table is like this:
ID 	Y 	X1 	X2 	X3 	X4
1 	555 	111 	222 	333 	456
1 	345 	234 	445 	543 	33
1 	456 	353 	453 	456 	333
2 	562 	118 	229 	340 	463
2 	352 	241 	452 	550 	40
2 	463 	360 	460 	463 	340
3 	....
	...
	...
	...
	....
3 	
	
	
	
	
3 	
	
	
	
	


I want to obtain an estimate of the linear model for each ID.
ex.   y = a1X1 + b1X2 + c1X3 + d1X4     where ID= 1
         y = a2X1 + b2X2 + c2X3 + d2X4    where ID= 2        and so on...

I'd like to obtain a table such this:

ID 	a 	b 	c 	d
1 	... 	... 	... 	..
2 	.. 	.. 	.. 	..
3 	.. 	.. 	.. 	..



Can you sugget me something?
Can I use a "for" script?
Thank you very much!
Valeria

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Mon Oct 14 19:07:00 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 14 Oct 2013 19:07:00 +0200
Subject: [R] MCP solver
In-Reply-To: <9FE87F5AC4D0164989FD7A9C468C114EF42139@EXMB-02.ad.wsu.edu>
References: <9FE87F5AC4D0164989FD7A9C468C114EF41D55@EXMB-02.ad.wsu.edu>
	<loom.20131013T082413-519@post.gmane.org>
	<9FE87F5AC4D0164989FD7A9C468C114EF42139@EXMB-02.ad.wsu.edu>
Message-ID: <5C650658-56BC-437C-8927-90C6EA7C5819@xs4all.nl>


On 14-10-2013, at 18:46, "Maxwell, John McFarland" <jmmaxwell at wsu.edu> wrote:

> Thanks for the response! The specific type of MCP I'm trying to solve is a square system of nonlinear equations with complementarity conditions (a computable general equilibrium model for predicting economic outcomes). The PATH solver in GAMS would certainly work for it, however as I don't have consistent access to GAMS or the PATH solver, I was hoping to find a way to run the model in R. I think the BB package could handle a system of nonlinear equations, but I'm not sure about the complementarity aspect. Is there a package that you know of that can do this?
> 

Besides BB, there is also package nleqslv which may be more suitable (it has Newton and Broyden solvers)(depending on the size of your system).
You could try a Fischer-Burmeister approach for the complementarity equations. You'ld have to do some searching on the internet to find how to do that.

Berend




> Thanks again,
> 
> JM
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Hans W Borchers
> Sent: Saturday, October 12, 2013 11:32 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] MCP solver
> 
> Maxwell, John McFarland <jmmaxwell <at> wsu.edu> writes:
> 
>> Hello,
>> 
>> I'm trying to find a solver that will work for the mixed 
>> complementarity problem (MCP). I've searched the CRAN task view page 
>> on optimization and mathematical programming as well as many google searches to no avail.
>> Does anyone know if there is an MCP solver available for R?
>> 
>> Thanks very much,
>> 
>> JM
> 
> The problem class of 'mixed complementary problems' is quite big and encompasses difficult optimization problems such as nonlinear systems of equations, nonlinear optimization problems, or optimization with equality constraints, among others.
> 
> There is no solver or package in R that will solve 'mixed complementary problems' in general. Perhaps your problem can be cast into a more specialized form that is accessible to one of the available solvers. Otherwise, GAMS has its own module for solving MCP problems.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Oct 14 19:13:12 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 14 Oct 2013 10:13:12 -0700
Subject: [R] Transform plot3d grafics in to executable files
In-Reply-To: <20131014103314.Horde.GvTFpk_ymYFkrdC-ZKpo8g9@webmail.df.eu>
References: <20131014103314.Horde.GvTFpk_ymYFkrdC-ZKpo8g9@webmail.df.eu>
Message-ID: <BCFDD89A-66A2-4F0E-8314-448794D572D0@comcast.net>


On Oct 14, 2013, at 1:33 AM, paladini at trustindata.de wrote:

> Hello,
> I did some nice grafics using plot 3d and scatter3d. Is there a, hopefully not too complicated way, to transform these dynamic, three-dimensional and interactive grafics in a kind of
> executable file? I want to show and send them via e-mail to projekt partners who don`t use GNU R and who are not used to do programming. So the result should be quite comfortable to execute for them in windows.
> 
> I hope my question is not too naive.

?rgl.snapshot
?play3d
?movie3d

-- 
David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Mon Oct 14 19:24:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 14 Oct 2013 10:24:47 -0700 (PDT)
Subject: [R] Help with combining functions
In-Reply-To: <71A9F37B694303439E0627F5D05323B56E2697@EXMBCT03.campus.ncl.ac.uk>
References: <71A9F37B694303439E0627F5D05323B56E2697@EXMBCT03.campus.ncl.ac.uk>
Message-ID: <1381771487.97372.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi,
Try:
?vec1 <- as.character(factor(1*(n%%3==0)+2*(n%%5==0)+3*(n%%15==0),labels=c("Other","heads","tails","headstails")))
?vec1[vec1=="Other"] <- which(vec1=="Other")
vec1[1:6]
#[1] "1"???? "2"???? "heads" "4"???? "tails" "heads"

A.K.


On Monday, October 14, 2013 12:57 PM, Kile Green <Kile.Green at newcastle.ac.uk> wrote:
Hi,



I am very new to 'R' ("discovered" it about 2 months ago) and have been trying to teach myself the language using online guides, however I am not a programmer or statistician and so progress is slow.



As an exercise, I have been trying to generate the numbers 1 to 100 and replace multiples of 3 with the text "heads", multiples of 5 with the text "tails" and multiples of both 3 and 5 with the text "headstails".



So far I have managed to write the functions individually with:

> n=c(1:100)

> a=replace(n,n%%3==0,"heads")
> b=replace(n,n%%5==0,"tails")
> c=replace(n,n%%15==0,"headstails")



I would like to combine these functions into a single process to produce an output along the lines of:

1,2,"heads",4,"tails","heads",7,8,"heads","tails"... etc



I tried the following, without success:



> replace(n,c(n%%3==0,n%%5==0,n%%15==0),c("heads","tails,"headstails"))



As an 'R' novice I don't really have an idea of how I should approach this problem and unfortunately I have had problems trying to apply the answers given to other replace() and c() questions to my example.



I would be grateful if someone could point me in the right direction or provide a similar example of combining simple functions without just giving the answer away - i'd like to learn how to use 'R', rather than just be told the answer.



Regards,



Kile

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Mon Oct 14 19:35:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 14 Oct 2013 10:35:41 -0700 (PDT)
Subject: [R] R Help-Implicit loop-lapply
Message-ID: <1381772141.44474.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,The conditions are not very clear.
set.seed(285)
?RN <- sample(1:100,20,replace=FALSE)
aList <- lapply(1:10,function(i) sample(RN,i,replace=FALSE)) 
?sapply(aList,tail,1)
# [1] 87 60 96 87 60 67 42 96 73 24

A.K.




I was wondering if I could obtain some help on how to do this. 



I feel as if I'm supposed to use the vector that i made with sample in order to use this function 

I've been trying 

aList <- lapply(1:10, RN) of course it doesn't work.


From bhh at xs4all.nl  Mon Oct 14 20:14:18 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 14 Oct 2013 20:14:18 +0200
Subject: [R] MCP solver
In-Reply-To: <9FE87F5AC4D0164989FD7A9C468C114EF42139@EXMB-02.ad.wsu.edu>
References: <9FE87F5AC4D0164989FD7A9C468C114EF41D55@EXMB-02.ad.wsu.edu>
	<loom.20131013T082413-519@post.gmane.org>
	<9FE87F5AC4D0164989FD7A9C468C114EF42139@EXMB-02.ad.wsu.edu>
Message-ID: <A0586B3B-0015-4D1A-B55A-4F7AE7A40AA9@xs4all.nl>


On 14-10-2013, at 18:46, "Maxwell, John McFarland" <jmmaxwell at wsu.edu> wrote:

> Thanks for the response! The specific type of MCP I'm trying to solve is a square system of nonlinear equations with complementarity conditions (a computable general equilibrium model for predicting economic outcomes). The PATH solver in GAMS would certainly work for it, however as I don't have consistent access to GAMS or the PATH solver, I was hoping to find a way to run the model in R. I think the BB package could handle a system of nonlinear equations, but I'm not sure about the complementarity aspect. Is there a package that you know of that can do this?


See the R-forge page: "Optimization and solving packages"   (http://r-forge.r-project.org/R/?group_id=395).
There is an R package GNE for "Computation of generalized Nash equilibria".
It might be able to handle MCP problems. Apparently the package has not been maintained/updated since february 2013.
It doesn't seem to build correctly in its current state.

You would have to contact the maintainer C. Dutang (see page http://r-forge.r-project.org/projects/optimizer/) for further information.

Berend Hasselman


From ruipbarradas at sapo.pt  Mon Oct 14 20:22:57 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 14 Oct 2013 19:22:57 +0100
Subject: [R] Extracting elements of model output
In-Reply-To: <525C236F.6010703@uvm.edu>
References: <525C236F.6010703@uvm.edu>
Message-ID: <525C3681.80809@sapo.pt>

Hello,

Inline.

Em 14-10-2013 18:01, David C. Howell escreveu:
> I am having difficulty extracting specific results from the model
> object. The following code shows where I am stuck.
>
> I want to run resamplings of a data set. For each I want to extract a
> particular F for the contrasts. If I run a very simple model
> (e.g. model1 <- aov(time~group) ) I can get the relevant coefficients,
> for example, by using "model1$coefficients". That's fine. But I don't
> want the coefficients of the model, I want the contrasts. So I tried
> model2=summary(model1, split = list(group = list("1&3 vs 2"=1, "1 vs 3"
> = 2)))
> This gives me the printout summary table that I want. i.e.
>
> model2
> Df Sum Sq Mean Sq F value Pr(>F)
> group 2 4090 2045 8.081 0.000682 ***
> group: 1&3 vs 2 1 1483 1484 5.863 0.017988 *
> group: 1 vs 3 1 2606 2606 10.300 0.001987 **
> Residuals 72 18219 253
>
> That's the summary table that I want, but I want to extract, for example
> the F value of 5.863.
>
> Looking at the structure of that object I get
>
> str(model2)
> List of 1
> $ :Classes ?anova? and 'data.frame': 4 obs. of 5 variables:
> ..$ Df : Named num [1:4] 2 1 1 72
> .. ..- attr(*, "names")= chr [1:4] "" "1&3 vs 2" "1 vs 3" ""
> ..$ Sum Sq : Named num [1:4] 4090 1483 2606 18219
> .. ..- attr(*, "names")= chr [1:4] "" "1&3 vs 2" "1 vs 3" ""
> ..$ Mean Sq: Named num [1:4] 2045 1483 2606 253
> .. ..- attr(*, "names")= chr [1:4] "" "1&3 vs 2" "1 vs 3" ""
> ..$ F value: Named num [1:4] 8.08 5.86 10.3 NA
> .. ..- attr(*, "names")= chr [1:4] "" "1&3 vs 2" "1 vs 3" ""
> ..$ Pr(>F) : Named num [1:4] 0.000682 0.017988 0.001987 NA
>
> What I would like to do is to request result$"F value[2]"
> but that just gives "NULL."
>
> I note that if I request the structure for model 1, the first element is
> $Df.

No, it's not. The first element is a data.frame, whose 4th column is the 
column you want. Using the first example in ?aov,

sm <- summary(aov(yield ~ block + N*P*K, npk))
sm[[1]]$`F value`  # note the backticks

# equivalent
sm[[1]][[4]]



Hope this helps,

Rui Barradas

  But when I ask for the structure of model2, the first element is
> ..$Df. I assume that those two dots represent an ellipsis, but nothing
> is ?str, ?attr, or other help screens tell me how to interpret and use
> ..Df or any of the other elements.
>
> Any help?
>
> Thanks,
> Dave Howell
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Mon Oct 14 20:46:44 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 14 Oct 2013 11:46:44 -0700 (PDT)
Subject: [R] repeat a linear regression model
In-Reply-To: <525BD9D1.9020706@uniud.it>
References: <525BD9D1.9020706@uniud.it>
Message-ID: <1381776404.16080.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
Please use ?dput() to show the example dataset:


dat <- structure(list(ID = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), Y = c(555L, 
345L, 456L, 552L, 342L, 452L, 555L, 345L, 456L, 552L, 342L, 452L, 
562L, 352L, 463L, 582L, 342L, 483L, 522L, 362L, 493L, 532L, 342L, 
423L), X1 = c(111L, 234L, 353L, 115L, 232L, 358L, 111L, 234L, 
353L, 115L, 232L, 358L, 118L, 251L, 320L, 138L, 211L, 320L, 128L, 
221L, 320L, 119L, 242L, 330L), X2 = c(222L, 445L, 453L, 222L, 
449L, 458L, 222L, 445L, 453L, 222L, 449L, 458L, 239L, 422L, 470L, 
219L, 422L, 410L, 239L, 492L, 470L, 219L, 432L, 460L), X3 = c(333L, 
543L, 456L, 343L, 524L, 458L, 333L, 543L, 456L, 343L, 524L, 458L, 
340L, 540L, 473L, 310L, 520L, 453L, 310L, 530L, 483L, 320L, 530L, 
413L), X4 = c(456L, 33L, 333L, 486L, 23L, 348L, 456L, 33L, 333L, 
486L, 23L, 348L, 463L, 40L, 330L, 423L, 43L, 310L, 433L, 45L, 
310L, 433L, 41L, 340L)), .Names = c("ID", "Y", "X1", "X2", "X3", 
"X4"), class = "data.frame", row.names = c(NA, -24L))


?res <- t(sapply(split(dat[,-1],dat$ID),function(x) coef(lm(Y~.,data=x))[-1]))
?colnames(res) <- letters[1:4]


#or

library(plyr)

?res1 <- ddply(dat,.(ID),function(x) coef(lm(Y~.,data=x[,-1])))[,-2]
?colnames(res1)[-1] <- colnames(res)


#or

res3 <- do.call(rbind,by(dat[,-1],dat[,1],function(x) coef(lm(Y~.,data=x))[-1]))
?colnames(res3) <- colnames(res)


A.K.




On Monday, October 14, 2013 1:00 PM, Valeria Muzzolini <valeria.muzzolini at uniud.it> wrote:
Hello,
I'd like to repeat a linear regression model for groups of rows that are 
identified by an ID number.
My table is like this:
ID ??? Y ??? X1 ??? X2 ??? X3 ??? X4
1 ??? 555 ??? 111 ??? 222 ??? 333 ??? 456
1 ??? 345 ??? 234 ??? 445 ??? 543 ??? 33
1 ??? 456 ??? 353 ??? 453 ??? 456 ??? 333
2 ??? 562 ??? 118 ??? 229 ??? 340 ??? 463
2 ??? 352 ??? 241 ??? 452 ??? 550 ??? 40
2 ??? 463 ??? 360 ??? 460 ??? 463 ??? 340
3 ??? ....
??? ...
??? ...
??? ...
??? ....
3 ??? 
??? 
??? 
??? 
??? 
3 ??? 
??? 
??? 
??? 
??? 


I want to obtain an estimate of the linear model for each ID.
ex.?  y = a1X1 + b1X2 + c1X3 + d1X4? ?  where ID= 1
? ? ? ?  y = a2X1 + b2X2 + c2X3 + d2X4? ? where ID= 2? ? ? ? and so on...

I'd like to obtain a table such this:

ID ??? a ??? b ??? c ??? d
1 ??? ... ??? ... ??? ... ??? ..
2 ??? .. ??? .. ??? .. ??? ..
3 ??? .. ??? .. ??? .. ??? ..



Can you sugget me something?
Can I use a "for" script?
Thank you very much!
Valeria

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From batholdy at googlemail.com  Mon Oct 14 20:49:53 2013
From: batholdy at googlemail.com (Martin Batholdy)
Date: Mon, 14 Oct 2013 20:49:53 +0200
Subject: [R] sequentially aggregating elements of a vector
Message-ID: <D594BEAE-87C8-4B99-9D95-87246E412CDE@googlemail.com>

Hi,

for labelling the stacked bars in a barplot, I need to sequentially sum up the elements of a vector.


Suppose I have;

x <- c(1,2,3,4)

(which correspond to the bar-width of stacked bars)

I need;

y <- c(1,3,6,11)


(which corresponds to the upper y-values for each bar).




What is the easiest way in R to get from x to y?
(Or more general; to add labels inside the bars in a stacked barplot)



thanks!


From ruipbarradas at sapo.pt  Mon Oct 14 21:15:25 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 14 Oct 2013 20:15:25 +0100
Subject: [R] sequentially aggregating elements of a vector
In-Reply-To: <D594BEAE-87C8-4B99-9D95-87246E412CDE@googlemail.com>
References: <D594BEAE-87C8-4B99-9D95-87246E412CDE@googlemail.com>
Message-ID: <525C42CD.4020200@sapo.pt>

Hello,

Try ?cumsum

cumsum(1:4)
[1]  1  3  6 10


Hope this helps,

Rui Barradas

Em 14-10-2013 19:49, Martin Batholdy escreveu:
> Hi,
>
> for labelling the stacked bars in a barplot, I need to sequentially sum up the elements of a vector.
>
>
> Suppose I have;
>
> x <- c(1,2,3,4)
>
> (which correspond to the bar-width of stacked bars)
>
> I need;
>
> y <- c(1,3,6,11)
>
>
> (which corresponds to the upper y-values for each bar).
>
>
>
>
> What is the easiest way in R to get from x to y?
> (Or more general; to add labels inside the bars in a stacked barplot)
>
>
>
> thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From batholdy at googlemail.com  Mon Oct 14 21:16:41 2013
From: batholdy at googlemail.com (Martin Batholdy)
Date: Mon, 14 Oct 2013 21:16:41 +0200
Subject: [R] sequentially aggregating elements of a vector
In-Reply-To: <1381777031.19211.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <D594BEAE-87C8-4B99-9D95-87246E412CDE@googlemail.com>
	<1381777031.19211.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <5E97513F-2CFD-4C56-8707-C9FE3DE25DCC@googlemail.com>

> The last element 11 in y is confusing.

sorry for the typo.
It is of course y <- c(1,3,6,10)


> cumsum(x)

thanks!


On Oct 14, 2013, at 20:57 , arun <smartpink111 at yahoo.com> wrote:

> The last element 11 in y is confusing.
> 
> cumsum(x)
> [1]  1  3  6 10
> A.K.
> 
> 
> On Monday, October 14, 2013 2:51 PM, Martin Batholdy <batholdy at googlemail.com> wrote:
> Hi,
> 
> for labelling the stacked bars in a barplot, I need to sequentially sum up the elements of a vector.
> 
> 
> Suppose I have;
> 
> x <- c(1,2,3,4)
> 
> (which correspond to the bar-width of stacked bars)
> 
> I need;
> 
> y <- c(1,3,6,11)
> 
> 
> (which corresponds to the upper y-values for each bar).
> 
> 
> 
> 
> What is the easiest way in R to get from x to y?
> (Or more general; to add labels inside the bars in a stacked barplot)
> 
> 
> 
> thanks!
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From r.turner at auckland.ac.nz  Mon Oct 14 21:35:34 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 15 Oct 2013 08:35:34 +1300
Subject: [R] singularity problem
In-Reply-To: <CANSYE6u=c+1-2k4XcxyggZkLcjzk5sgSpA9MZ=Q=x_RpW-ufPg@mail.gmail.com>
References: <CANSYE6u=c+1-2k4XcxyggZkLcjzk5sgSpA9MZ=Q=x_RpW-ufPg@mail.gmail.com>
Message-ID: <525C4786.1010104@auckland.ac.nz>

On 10/14/13 23:31, ??rka Rus? wrote:
> Dear R,
>
> I have a problem concerning the inverse of a matrix. My matrix is quite
> large and I extracted just linearly independent columns from the matrix.
> However, the function solve() still cannot invert the matrix - I get an
> error that it is computationally singular. Is there any way how to extract
> some columns from the matrix so that I could get the inverse?
> The probl?m is I can extract a "nonsingular" matrix but there is no point
> in doing it since I don't get the inverse.

Your question makes no sense to me.  If you just select certain columns 
of your matrix
the resulting matrix will no longer be square and inverting it is 
meaningless.

If you have a (numerically) non-singular matrix, then it can, by 
definition be inverted.
(And solve() will invert it for you.)

What are you actually trying to accomplish?

     cheers,

     Rolf Turner


From c-w.hoffmann at sunrise.ch  Mon Oct 14 21:59:39 2013
From: c-w.hoffmann at sunrise.ch (Christian Hoffmann)
Date: Mon, 14 Oct 2013 21:59:39 +0200
Subject: [R] there is no package called 'boot'
Message-ID: <525C4D2B.4070708@sunrise.ch>

Hi,

R CMD  mypackage  /Users/hoffmann/R/cwhmisc  check --as-cran

gives me

* checking Rd cross-references ... WARNING
Error in find.package(package, lib.loc) :
   there is no package called 'boot'

although there is no textual reference to 'boot' in my /R and /man 
within /cwhmisc nor any file of that name.

How could I possibly find the culprit?

TIA

C.

sessionInfo() > R version 3.0.1 (2013-05-16)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] C

attached base packages:
  [1] tools     tcltk     stats4    splines   parallel  datasets compiler
  [8] graphics  grDevices stats     grid      utils     methods base

other attached packages:
  [1] survival_2.37-4    spatial_7.3-6      rpart_4.1-1 nnet_7.3-6
  [5] nlme_3.1-109       foreign_0.8-53     codetools_0.2-8 cluster_1.14.4
  [9] class_7.3-7        Matrix_1.0-12      MASS_7.3-26 KernSmooth_2.23-10
[13] cwhmisc_4.1        lattice_0.20-15

-- 
Christian W. Hoffmann,
CH - 8915 Hausen am Albis, Switzerland
Rigiblickstrasse 15 b, Tel.+41-44-7640853
(!! c-w.hoffmann at sunrise.ch, <will be eliminated in the near future,
instead Bitte nicht mehr benutzen !!, stattdessen: >)
mailto: christian at echoffmann.ch
home: www.echoffmann.ch


From r.turner at auckland.ac.nz  Mon Oct 14 22:04:37 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 15 Oct 2013 09:04:37 +1300
Subject: [R] x12 doesn't work any longer
In-Reply-To: <84B471C0-DFBB-4C7B-BA28-C3DF54D4A739@gmail.com>
References: <84B471C0-DFBB-4C7B-BA28-C3DF54D4A739@gmail.com>
Message-ID: <525C4E55.2040104@auckland.ac.nz>

On 10/15/13 02:52, Victor wrote:
> Context: Mac OS X 10.7 - R 3.0.2 GUI 1.62 Snow Leopard build (6558)
>
> I had been using x12 for some time with no problem at all. every month I update the time series ricpesata (see below) and run the simple procedure below. Now adding the data of the last month, Sep.2013,
> x12 is complaining:
>
>> library(x12)
>> x<-x12(round(ricpesata,2), x12path="/Applications/x12arima/x12a", automdl=TRUE, decimals=2,  transform="log", outlier="all", forecast_years=2)
> Error in .local(object, x12Parameter, x12BaseInfo, ...) :
>    unused arguments (x12path = "/Applications/x12arima/x12a", automdl = TRUE, decimals = 2, transform = "log", outlier = "all", forecast_years = 2)
>
> where
>> str(round(ricpesata,2))
>   Time-Series [1:285] from 1990 to 2014: 20924 20559 19952 19366 19145 ...
>>   
> is the following timeseries:
>
>            Jan      Feb      Mar      Apr      May      Jun      Jul      Aug      Sep      Oct      Nov      Dec
> 1990 20924.30 20559.41 19952.28 19365.96 19145.28 19536.69 19791.74 15796.91 19690.72 19779.16 20444.38 20529.32
> 1991 21155.47 21613.96 20168.89 19584.45 19527.75 19765.04 20314.15 16116.04 20232.00 20391.31 21200.69 21093.83
> 1992 21570.88 21877.04 21129.40 .........
>
> What does that error mean
     Presumably it means what it says.
> and what should I do?

RTFM?  Mind you, TFM is incredibly opaque.

The arguments that you give to x12() do not appear to be arguments of 
that function.
Perhaps the usage has changed in the most recent update of the package.  
Without
adequate warning.

E.g., there is, as far as I can discern, no "x12path" argument to 
x12().  Whence it complains if
such an argument is supplied.  When one loads the x12 package one gets a 
message
saying that the path to the executables should be set using the function 
x12path().
I would suggest that you try that.  And then figure out how the other 
arguments that you
supply should really be handled.

Perhaps try contacting the package maintainer.   Good luck.

     cheers,

     Rolf Turner


From highstat at highstat.com  Mon Oct 14 22:08:20 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 14 Oct 2013 22:08:20 +0200
Subject: [R] Call of interest: mixed modelling course in Quebec City
Message-ID: <525C4F34.4030206@highstat.com>

This is a call of interest for: "Introduction to linear mixed effects 
modelling and GLMM course"

Where: Quebec City, Canada
When: 24 - 28 March 2014

Flyer: http://www.highstat.com/Courses/Flyer2014_03Quebec.pdf
General info: http://www.highstat.com/statscourse.htm


Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007)
2. Mixed effects models and extensions in ecology with R (2009)
3. A Beginner's Guide to R (2009)
4. Zero Inflated Models and GLMM with R (2012)
5. A Beginner's Guide to GAM (2012)
6. A Beginner's Guide to GLM and GLMM (2013)

Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From lorenzo.isella at gmail.com  Mon Oct 14 22:23:29 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Mon, 14 Oct 2013 22:23:29 +0200
Subject: [R] Image Classification in R
Message-ID: <op.w4yn9fwlzqkd1e@nirvana>

Dear All,
For a project I am given a set of images. They represent either healthy or  
tumoral tissue, but the specific nature of the images does not matter.
I need to train a classifier which is expected to tell me in which  
category (let's call it 0 vs 1) each image falls.
I am thinking about a random forest classifier, but I am uncertain about a  
couple of (fairly important) points

(1) The size of the images varies, so for instance the number of pixels is  
not the same for every image and as a consequence some methodologies (e.g.  
the PCA) when applied to these images will lead to results not immediately  
comparable. Is trying to blur/flatten the images a good idea to have  
always (artificially) the same size (number of pixels) for every image?
(2) Which features do you recommend to associate\calculate for every  
image? This is what I will use to train my model upon.

Any suggestion is welcome.
Cheers

Lorenzo


From gunter.berton at gene.com  Mon Oct 14 22:48:09 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 14 Oct 2013 13:48:09 -0700
Subject: [R] Image Classification in R
In-Reply-To: <op.w4yn9fwlzqkd1e@nirvana>
References: <op.w4yn9fwlzqkd1e@nirvana>
Message-ID: <CACk-te03qXVSBum+5iwmgutmrivFegtUr6=H4BZYnpJhEvMF7w@mail.gmail.com>

This is an R-help list. These are not questions about R. You should
talk to a local statistical expert instead of posting here.

Cheers,
Bert

On Mon, Oct 14, 2013 at 1:23 PM, Lorenzo Isella
<lorenzo.isella at gmail.com> wrote:
> Dear All,
> For a project I am given a set of images. They represent either healthy or
> tumoral tissue, but the specific nature of the images does not matter.
> I need to train a classifier which is expected to tell me in which category
> (let's call it 0 vs 1) each image falls.
> I am thinking about a random forest classifier, but I am uncertain about a
> couple of (fairly important) points
>
> (1) The size of the images varies, so for instance the number of pixels is
> not the same for every image and as a consequence some methodologies (e.g.
> the PCA) when applied to these images will lead to results not immediately
> comparable. Is trying to blur/flatten the images a good idea to have always
> (artificially) the same size (number of pixels) for every image?
> (2) Which features do you recommend to associate\calculate for every image?
> This is what I will use to train my model upon.
>
> Any suggestion is welcome.
> Cheers
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From smartpink111 at yahoo.com  Mon Oct 14 21:40:54 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 14 Oct 2013 12:40:54 -0700 (PDT)
Subject: [R] R Help-how to use sapply w/tapply
Message-ID: <1381779654.9493.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

(Please use ?dput() to share the example dataset. Avoid using images to show dataset. Also, please read the posting guide esp. regarding home work, assignments etc.)

res <- sapply(Gene[,-1],function(x) tapply(x,list(Gene$Genotype),mean))

#or
res2 <-? aggregate(.~Genotype, data=Gene,mean)


#or
library(plyr)
?res3 <- ddply(Gene,.(Genotype),numcolwise(mean))


identical(res2,res3)
#[1] TRUE


resNew <- data.frame(Genotype=rownames(res),res,stringsAsFactors=FALSE)
?attr(resNew,"row.names") <- attr(res2,"row.names")
?identical(resNew,res2)
#[1] TRUE


A.K.


So I'm having a problem with the part b of the assignment. 

This is the question 


This is how I solved 
Part A 


now for 
Part B 
Am i supposed to do something along the lines of 

sapply(tapply(Gene[ , ], Gene$Genotype), mean) 

This doesn't work.


From jeffrey.flint at gmail.com  Mon Oct 14 22:25:27 2013
From: jeffrey.flint at gmail.com (Jeffrey Flint)
Date: Mon, 14 Oct 2013 13:25:27 -0700
Subject: [R] project parallel help
Message-ID: <CALbUM4MeRpHMvxUJ7MGvjrLJdtS8bwhfuSxGMLJZKJPqc7VY6Q@mail.gmail.com>

I'm running package parallel in R-3.0.2.

Below are the execution times using system.time for when executing
serially versus in parallel (with 2 cores) using parRapply.


Serially:
   user  system elapsed
   4.67    0.03    4.71



Using package parallel:
   user  system elapsed
   3.82    0.12    6.50



There is evident improvement in the user cpu time, but a big jump in
the elapsed time.

In my code, I am executing a function on a 1000 row matrix 100 times,
with the data different each time of course.

The initial call to makeCluster cost 1.25 seconds in elapsed time.
I'm not concerned about the makeCluster time since that is a fixed
cost.  I am concerned about the additional 1.43 seconds in elapsed
time (6.50=1.43+1.25).

I am wondering if there is a way to structure the code to avoid
largely avoid the 1.43 second overhead.  For instance, perhaps I could
upload the function to both cores manually in order to avoid the
function being uploaded at each of the 100 iterations?    Also, I am
wondering if there is a way to avoid any copying that is occurring at
each of the 100 iterations?


Thank you.

Jeff Flint


From msuzen at gmail.com  Mon Oct 14 22:52:08 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Mon, 14 Oct 2013 22:52:08 +0200
Subject: [R] Image Classification in R
In-Reply-To: <op.w4yn9fwlzqkd1e@nirvana>
References: <op.w4yn9fwlzqkd1e@nirvana>
Message-ID: <CAPtbhHzAQetz-cmD_Ec4iKp7wYoENMC9m-_jFv21ynfi0Ji4UA@mail.gmail.com>

Hello Lorenzo, Try to locate related R packages from here:
http://cran.r-project.org/web/views/MedicalImaging.html

On 14 October 2013 22:23, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
> Dear All,
> For a project I am given a set of images. They represent either healthy or
> tumoral tissue, but the specific nature of the images does not matter.
> I need to train a classifier which is expected to tell me in which category
> (let's call it 0 vs 1) each image falls.
> I am thinking about a random forest classifier, but I am uncertain about a
> couple of (fairly important) points
>
> (1) The size of the images varies, so for instance the number of pixels is
> not the same for every image and as a consequence some methodologies (e.g.
> the PCA) when applied to these images will lead to results not immediately
> comparable. Is trying to blur/flatten the images a good idea to have always
> (artificially) the same size (number of pixels) for every image?
> (2) Which features do you recommend to associate\calculate for every image?
> This is what I will use to train my model upon.
>
> Any suggestion is welcome.
> Cheers
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Oct 14 23:35:39 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 14 Oct 2013 14:35:39 -0700
Subject: [R] project parallel help
In-Reply-To: <CALbUM4MeRpHMvxUJ7MGvjrLJdtS8bwhfuSxGMLJZKJPqc7VY6Q@mail.gmail.com>
References: <CALbUM4MeRpHMvxUJ7MGvjrLJdtS8bwhfuSxGMLJZKJPqc7VY6Q@mail.gmail.com>
Message-ID: <217f1ef8-2a1b-4304-a33d-11c64f85f83a@email.android.com>

Your question misses on several points in the Posting Guide so any answers are handicapped by you.

There is an overhead in using parallel processing, and the value of two cores is marginal at best. In general parallel by forking is more efficient than parallel by SNOW, but the former is not available on all operating systems. This is discussed in the vignette for the parallel package.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Jeffrey Flint <jeffrey.flint at gmail.com> wrote:
>I'm running package parallel in R-3.0.2.
>
>Below are the execution times using system.time for when executing
>serially versus in parallel (with 2 cores) using parRapply.
>
>
>Serially:
>   user  system elapsed
>   4.67    0.03    4.71
>
>
>
>Using package parallel:
>   user  system elapsed
>   3.82    0.12    6.50
>
>
>
>There is evident improvement in the user cpu time, but a big jump in
>the elapsed time.
>
>In my code, I am executing a function on a 1000 row matrix 100 times,
>with the data different each time of course.
>
>The initial call to makeCluster cost 1.25 seconds in elapsed time.
>I'm not concerned about the makeCluster time since that is a fixed
>cost.  I am concerned about the additional 1.43 seconds in elapsed
>time (6.50=1.43+1.25).
>
>I am wondering if there is a way to structure the code to avoid
>largely avoid the 1.43 second overhead.  For instance, perhaps I could
>upload the function to both cores manually in order to avoid the
>function being uploaded at each of the 100 iterations?    Also, I am
>wondering if there is a way to avoid any copying that is occurring at
>each of the 100 iterations?
>
>
>Thank you.
>
>Jeff Flint
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Paul.Prew at ecolab.com  Mon Oct 14 23:57:24 2013
From: Paul.Prew at ecolab.com (Prew, Paul)
Date: Mon, 14 Oct 2013 16:57:24 -0500
Subject: [R] using ddply with segmented regression
In-Reply-To: <1381560093.44823.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <A780DAF149F5C24EBDFC048B071023B91B8C8423C5@useagan5503p.global.ecolab.corp>
	<1381560093.44823.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <A780DAF149F5C24EBDFC048B071023B91F927790EC@useagan5503p.global.ecolab.corp>

Hello,  the code provided by arun did the trick.  Thank you very much, arun.  

 However, I'm now unsure of how to further process the results .  Looking at the vignette  aka "split-apply-combine". It appears that I could now create a dataframe from the list of results, and then run the results through the function plot.segmented to view the piecewise regressions by the grouping variable Lot.Run.  However, the list is not in the structure expected by ldply -- 

>SP.seg <- dlply((df,.(Lot.Run),segmentf_df)
>SP.out <- ldply(SP.seg)

[9] ERROR:
Results must be all atomic, or all data frames

>class(SP.seg)[[1]]
[1] "list"

>head(SP.seg)
$`J062431-1`
Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
    control = seg.control(stop.if.error = FALSE, n.boot = 0, 
        gap = FALSE, jt = FALSE, nonParam = TRUE))

Meaningful coefficients of the linear terms:
(Intercept)        Cycle     U1.Cycle     U2.Cycle     U3.Cycle     U4.Cycle     U5.Cycle     U6.Cycle  
   40.11786     -0.06664     -0.68539      0.49316      0.14955      0.03612      0.22257     -0.41166  
   U7.Cycle     U8.Cycle     U9.Cycle    U10.Cycle  
   -0.48365      0.37949      0.24945      0.06712  

Estimated Break-Point(s) psi1.Cycle psi2.Cycle psi3.Cycle psi4.Cycle psi5.Cycle psi6.Cycle psi7.Cycle psi8.Cycle psi9.Cycle psi10.Cycle :  19.67  34.31  51.02  72.10  97.94 117.20 130.10 147.10 155.70 160.40 

$`J062431-2`
Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
    control = seg.control(stop.if.error = FALSE, n.boot = 0, 
        gap = FALSE, jt = FALSE, nonParam = TRUE))

Meaningful coefficients of the linear terms:
(Intercept)        Cycle     U1.Cycle     U2.Cycle     U3.Cycle     U4.Cycle     U5.Cycle     U6.Cycle  
   40.11786     -0.06664     -0.68539      0.49316      0.14955      0.03612      0.22257     -0.41166  
   U7.Cycle     U8.Cycle     U9.Cycle    U10.Cycle  
   -0.48365      0.37949      0.24945      0.06712  

Estimated Break-Point(s) psi1.Cycle psi2.Cycle psi3.Cycle psi4.Cycle psi5.Cycle psi6.Cycle psi7.Cycle psi8.Cycle psi9.Cycle psi10.Cycle :  19.67  34.31  51.02  72.10  97.94 117.20 130.10 147.10 155.70 160.40

My hope was to eventually increase my understanding enough to create lattice plots using 'segment.plot' via ldply.  Will that even work with the output object from this segmented package?  

Thanks,Paul

Paul Prew  |  Statistician
651-795-5942?? |?? fax 651-204-7504 
Ecolab Research Center  | Mail Stop ESC-F4412-A 
655 Lone Oak Drive  |  Eagan, MN 55121-1560 

-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Saturday, October 12, 2013 1:42 AM
To: R help
Cc: Prew, Paul
Subject: Re: [R] using ddply with segmented regression



Hi,
Try:

segmentf_df <- function(df) {
out.lm<-lm(deltaWgt~Cycle, data=df)
segmented(out.lm,seg.Z=~Cycle, psi=(Cycle=NA),control=seg.control(stop.if.error=FALSE,n.boot=0))
}

library(plyr)
library(segmented)

dlply(df,.(Lot.Run),segmentf_df)
$`J062431-1`
Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
??? control = seg.control(stop.if.error = FALSE, n.boot = 0))

Meaningful coefficients of the linear terms:
(Intercept)??????? Cycle???? U1.Cycle???? U2.Cycle? 
???? 38.480??????? 1.130?????? -2.760??????? 1.497? 

Estimated Break-Point(s) psi1.Cycle psi2.Cycle : 3.732 5.056 

$`J062431-2`
Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
??? control = seg.control(stop.if.error = FALSE, n.boot = 0))

Meaningful coefficients of the linear terms:
(Intercept)??????? Cycle???? U1.Cycle???? U2.Cycle? 
??? 48.4300????? -3.2500?????? 3.0905????? -0.6555? 

Estimated Break-Point(s) psi1.Cycle psi2.Cycle :? 2.12 22.15 

attr(,"split_type")
[1] "data.frame"
attr(,"split_labels")
??? Lot.Run
1 J062431-1
2 J062431-2


#or

dlply(df,.(Lot.Run),function(x) segmentf_df(x))
#or
lapply(split(df,df$Lot.Run,drop=TRUE),function(x) segmentf_df(x))


A.K.


On Friday, October 11, 2013 11:16 PM, "Prew, Paul" <Paul.Prew at ecolab.com> wrote:
Hello,

I?m unsuccessfully trying to apply piecewise linear regression over each of 22 groups.? The data structure of the reproducible toy dataset is below.? I?m using the ?segmented? package, it worked fine with a data set that containing only one group (?Lot.Run?).

$ Cycle?  : int? 1 2 3 4 5 6 7 8 9 10 ...
$ Lot.Run : Factor w/ 22 levels "J062431-1","J062431-2",..: 1 1 1 1 1 1 1 1 1 1 ...
$ deltaWgt: num? 38.7 42.6 41 42.3 40.6 ...

I am new to ?segmented?, and also new to ?plyr?, which is how I?m trying to apply this segmented regression to the 22 Lot.Run groups.? Within a Lot.Run, the piecewise linear regressions are deltaWgt vs. Cycle.

#####? define the linear regression #####
out.lm<-lm(deltaWgt~Cycle, data=Test50.df)

#####? define the function called by dlply? #####
? ? ?  #####? find cutpoints via bootstrapping, fit the piecewise regressions? #####
segmentf_df <- function(df) {
segmented(out.lm,seg.Z=~Cycle, psi=(Cycle=NA),control=seg.control(stop.if.error=FALSE,n.boot=0)), data = df)
}

at this point, there?s an? error message
23] ERROR: <text>

#####? repeat for each Lot.Run group?  #####
dlply(Test50.df, .(Lot.Run), segmentf_df)

at this point, there?s an? error message
[28] ERROR:
object 'segmentf_df' not found

Any suggestions?
Thanks, Paul

> dput(Test50.df)
structure(list(Cycle = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
23L, 24L, 25L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
25L), Lot.Run = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("J062431-1",
"J062431-2", "J062431-3", "J062432-1", "J062432-2", "J062433-1",
"J062433-2", "J062433-3", "Lot 1-1", "Lot 1-2", "Lot 2-1", "Lot 2-2",
"Lot 2-3", "Lot 3-1", "Lot 3-2", "Lot 3-3", "P041231-1", "P041231-2",
"P041531-1", "P041531-2", "P041531-3", "P041531-4"), class = "factor"),
? ? deltaWgt = c(38.69, 42.58, 40.95, 42.26, 40.63, 41.61, 36.73,
? ? 41.28, 39.98, 40.63, 39.66, 39.98, 40.95, 38.36, 39.01, 39,
? ? 38.03, 39.66, 37.7, 39.66, 40.63, 38.03, 37.71, 36.73, 37.7,
? ? 45.18, 41.93, 42.59, 39.98, 40.95, 42.91, 38.03, 40.96, 39,
? ? 41.61, 39.33, 43.88, 39.98, 38.68, 38.68, 36.08, 39.99, 38.35,
? ? 40.31, 40.63, 38.68, 37.05, 38.36, 35.43, 36.73)), .Names = c("Cycle",
"Lot.Run", "deltaWgt"), row.names = c(1L, 2L, 3L, 4L, 5L, 6L,
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
20L, 21L, 22L, 23L, 24L, 25L, 207L, 208L, 209L, 210L, 211L, 212L,
213L, 214L, 215L, 216L, 217L, 218L, 219L, 220L, 221L, 222L, 223L,
224L, 225L, 226L, 227L, 228L, 229L, 230L, 231L), class = "data.frame")




Paul Prew?  ?? Statistician
651-795-5942?  ??  fax 651-204-7504
Ecolab Research Center?  ?? Mail Stop ESC-F4412-A
655 Lone Oak Drive?  ??  Eagan, MN 55121-1560




CONFIDENTIALITY NOTICE: This e-mail communication and any attachments may contain proprietary and privileged information for the use of the designated recipients named above. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.

??? [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



CONFIDENTIALITY NOTICE: This e-mail communication and any attachments may contain proprietary and privileged information for the use of the designated recipients named above. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.

From dwinsemius at comcast.net  Tue Oct 15 00:29:35 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 14 Oct 2013 15:29:35 -0700
Subject: [R] using ddply with segmented regression
In-Reply-To: <A780DAF149F5C24EBDFC048B071023B91F927790EC@useagan5503p.global.ecolab.corp>
References: <A780DAF149F5C24EBDFC048B071023B91B8C8423C5@useagan5503p.global.ecolab.corp>
	<1381560093.44823.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<A780DAF149F5C24EBDFC048B071023B91F927790EC@useagan5503p.global.ecolab.corp>
Message-ID: <F42E84B0-61EA-40ED-8207-B6E20F272041@comcast.net>


On Oct 14, 2013, at 2:57 PM, Prew, Paul wrote:

> Hello,  the code provided by arun did the trick.  Thank you very much, arun.  
> 
> However, I'm now unsure of how to further process the results .  Looking at the vignette  aka "split-apply-combine". It appears that I could now create a dataframe from the list of results, and then run the results through the function plot.segmented to view the piecewise regressions by the grouping variable Lot.Run.  However, the list is not in the structure expected by ldply -- 
> 
>> SP.seg <- dlply((df,.(Lot.Run),segmentf_df)

That wasn't the name of the dataframe you offered in the first post.... and this code could not possibly have not thrown an error since there are unmatched parens.

>> SP.out <- ldply(SP.seg)

So what function were you intending to be used in that call to ldply ...  after you fix the errors above? If you are using ldply to process the models with plot.segmented, then realize that the object returned will be an empty dataframe but hte plots will be done.

> 
> [9] ERROR:
> Results must be all atomic, or all data frames
> 
>> class(SP.seg)[[1]]
> [1] "list"
> 
>> head(SP.seg)
> $`J062431-1`
> Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
>    control = seg.control(stop.if.error = FALSE, n.boot = 0, 
>        gap = FALSE, jt = FALSE, nonParam = TRUE))
> 
> Meaningful coefficients of the linear terms:
> (Intercept)        Cycle     U1.Cycle     U2.Cycle     U3.Cycle     U4.Cycle     U5.Cycle     U6.Cycle  
>   40.11786     -0.06664     -0.68539      0.49316      0.14955      0.03612      0.22257     -0.41166  
>   U7.Cycle     U8.Cycle     U9.Cycle    U10.Cycle  
>   -0.48365      0.37949      0.24945      0.06712  
> 
> Estimated Break-Point(s) psi1.Cycle psi2.Cycle psi3.Cycle psi4.Cycle psi5.Cycle psi6.Cycle psi7.Cycle psi8.Cycle psi9.Cycle psi10.Cycle :  19.67  34.31  51.02  72.10  97.94 117.20 130.10 147.10 155.70 160.40 
> 
> $`J062431-2`
> Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
>    control = seg.control(stop.if.error = FALSE, n.boot = 0, 
>        gap = FALSE, jt = FALSE, nonParam = TRUE))
> 
> Meaningful coefficients of the linear terms:
> (Intercept)        Cycle     U1.Cycle     U2.Cycle     U3.Cycle     U4.Cycle     U5.Cycle     U6.Cycle  
>   40.11786     -0.06664     -0.68539      0.49316      0.14955      0.03612      0.22257     -0.41166  
>   U7.Cycle     U8.Cycle     U9.Cycle    U10.Cycle  
>   -0.48365      0.37949      0.24945      0.06712  
> 
> Estimated Break-Point(s) psi1.Cycle psi2.Cycle psi3.Cycle psi4.Cycle psi5.Cycle psi6.Cycle psi7.Cycle psi8.Cycle psi9.Cycle psi10.Cycle :  19.67  34.31  51.02  72.10  97.94 117.20 130.10 147.10 155.70 160.40
> 
> My hope was to eventually increase my understanding enough to create lattice plots using 'segment.plot' via ldply.  Will that even work with the output object from this segmented package?  

Hard to tell. You seem to be changing the names of your objects at random.

> 
> Thanks,Paul
> 
> Paul Prew  |  Statistician
> 651-795-5942   |   fax 651-204-7504 
> Ecolab Research Center  | Mail Stop ESC-F4412-A 
> 655 Lone Oak Drive  |  Eagan, MN 55121-1560 
> 
> -----Original Message-----
> From: arun [mailto:smartpink111 at yahoo.com] 
> Sent: Saturday, October 12, 2013 1:42 AM
> To: R help
> Cc: Prew, Paul
> Subject: Re: [R] using ddply with segmented regression
> 
> 
> 
> Hi,
> Try:
> 
> segmentf_df <- function(df) {
> out.lm<-lm(deltaWgt~Cycle, data=df)
> segmented(out.lm,seg.Z=~Cycle, psi=(Cycle=NA),control=seg.control(stop.if.error=FALSE,n.boot=0))
> }
> 
> library(plyr)
> library(segmented)
> 
> dlply(df,.(Lot.Run),segmentf_df)
> $`J062431-1`
> Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
>     control = seg.control(stop.if.error = FALSE, n.boot = 0))
> 
> Meaningful coefficients of the linear terms:
> (Intercept)        Cycle     U1.Cycle     U2.Cycle  
>      38.480        1.130       -2.760        1.497  
> 
> Estimated Break-Point(s) psi1.Cycle psi2.Cycle : 3.732 5.056 
> 
> $`J062431-2`
> Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
>     control = seg.control(stop.if.error = FALSE, n.boot = 0))
> 
> Meaningful coefficients of the linear terms:
> (Intercept)        Cycle     U1.Cycle     U2.Cycle  
>     48.4300      -3.2500       3.0905      -0.6555  
> 
> Estimated Break-Point(s) psi1.Cycle psi2.Cycle :  2.12 22.15 
> 
> attr(,"split_type")
> [1] "data.frame"
> attr(,"split_labels")
>     Lot.Run
> 1 J062431-1
> 2 J062431-2
> 
> 
> #or
> 
> dlply(df,.(Lot.Run),function(x) segmentf_df(x))
> #or
> lapply(split(df,df$Lot.Run,drop=TRUE),function(x) segmentf_df(x))
> 
> 
> A.K.
> 
> 
> On Friday, October 11, 2013 11:16 PM, "Prew, Paul" <Paul.Prew at ecolab.com> wrote:
> Hello,
> 
> I?m unsuccessfully trying to apply piecewise linear regression over each of 22 groups.  The data structure of the reproducible toy dataset is below.  I?m using the ?segmented? package, it worked fine with a data set that containing only one group (?Lot.Run?).
> 
> $ Cycle   : int  1 2 3 4 5 6 7 8 9 10 ...
> $ Lot.Run : Factor w/ 22 levels "J062431-1","J062431-2",..: 1 1 1 1 1 1 1 1 1 1 ...
> $ deltaWgt: num  38.7 42.6 41 42.3 40.6 ...
> 
> I am new to ?segmented?, and also new to ?plyr?, which is how I?m trying to apply this segmented regression to the 22 Lot.Run groups.  Within a Lot.Run, the piecewise linear regressions are deltaWgt vs. Cycle.
> 
> #####  define the linear regression #####
> out.lm<-lm(deltaWgt~Cycle, data=Test50.df)
> 
> #####  define the function called by dlply  #####
>        #####  find cutpoints via bootstrapping, fit the piecewise regressions  #####
> segmentf_df <- function(df) {
> segmented(out.lm,seg.Z=~Cycle, psi=(Cycle=NA),control=seg.control(stop.if.error=FALSE,n.boot=0)), data = df)
> }
> 
> at this point, there?s an  error message
> 23] ERROR: <text>
> 
> #####  repeat for each Lot.Run group   #####
> dlply(Test50.df, .(Lot.Run), segmentf_df)
> 
> at this point, there?s an  error message
> [28] ERROR:
> object 'segmentf_df' not found
> 
> Any suggestions?
> Thanks, Paul
> 
>> dput(Test50.df)
> structure(list(Cycle = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L), Lot.Run = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("J062431-1",
> "J062431-2", "J062431-3", "J062432-1", "J062432-2", "J062433-1",
> "J062433-2", "J062433-3", "Lot 1-1", "Lot 1-2", "Lot 2-1", "Lot 2-2",
> "Lot 2-3", "Lot 3-1", "Lot 3-2", "Lot 3-3", "P041231-1", "P041231-2",
> "P041531-1", "P041531-2", "P041531-3", "P041531-4"), class = "factor"),
>     deltaWgt = c(38.69, 42.58, 40.95, 42.26, 40.63, 41.61, 36.73,
>     41.28, 39.98, 40.63, 39.66, 39.98, 40.95, 38.36, 39.01, 39,
>     38.03, 39.66, 37.7, 39.66, 40.63, 38.03, 37.71, 36.73, 37.7,
>     45.18, 41.93, 42.59, 39.98, 40.95, 42.91, 38.03, 40.96, 39,
>     41.61, 39.33, 43.88, 39.98, 38.68, 38.68, 36.08, 39.99, 38.35,
>     40.31, 40.63, 38.68, 37.05, 38.36, 35.43, 36.73)), .Names = c("Cycle",
> "Lot.Run", "deltaWgt"), row.names = c(1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 207L, 208L, 209L, 210L, 211L, 212L,
> 213L, 214L, 215L, 216L, 217L, 218L, 219L, 220L, 221L, 222L, 223L,
> 224L, 225L, 226L, 227L, 228L, 229L, 230L, 231L), class = "data.frame")
> 
> 
> 


David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Tue Oct 15 00:08:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 14 Oct 2013 15:08:03 -0700 (PDT)
Subject: [R] R Help-how to use sapply w/tapply
In-Reply-To: <1381779654.9493.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1381779654.9493.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1381788483.28930.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:

Gene[,-1] <- lapply(Gene[,-1],function(x) {x[sample(length(x),1)] <- NA;x})

A.K.

I got it guys 

MeanofGenotype <-sapply(2:8, function(k) tapply(Gene[,k] , Gene$Genotype, mean)) 

I was wondering if now you guys can help me on how to insert a random NA to each column. 

The question is 

In the original data, for each numeric column, select randomly a
 number to set to NA. So, each column will have 11 numbers and one NA. 


On Monday, October 14, 2013 4:52 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,

(Please use ?dput() to share the example dataset. Avoid using images to show dataset. Also, please read the posting guide esp. regarding home work, assignments etc.)

res <- sapply(Gene[,-1],function(x) tapply(x,list(Gene$Genotype),mean))

#or
res2 <-? aggregate(.~Genotype, data=Gene,mean)


#or
library(plyr)
?res3 <- ddply(Gene,.(Genotype),numcolwise(mean))


identical(res2,res3)
#[1] TRUE


resNew <- data.frame(Genotype=rownames(res),res,stringsAsFactors=FALSE)
?attr(resNew,"row.names") <- attr(res2,"row.names")
?identical(resNew,res2)
#[1] TRUE


A.K.


So I'm having a problem with the part b of the assignment. 

This is the question 


This is how I solved 
Part A 


now for 
Part B 
Am i supposed to do something along the lines of 

sapply(tapply(Gene[ , ], Gene$Genotype), mean) 

This doesn't work.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Peter.Ellis at mbie.govt.nz  Tue Oct 15 00:07:34 2013
From: Peter.Ellis at mbie.govt.nz (Peter Ellis (Wellington))
Date: Mon, 14 Oct 2013 22:07:34 +0000
Subject: [R] access the OECD odata API from R
Message-ID: <A468281CDBEF1B4AA50301D9C1E886239859EC67@AKI2K113.wd.govt.nz>

Hi

Is there an existing R package (or perhaps someone has one in development?) that can access the OECD's public database API (see http://stats.oecd.org/OpenDataAPI/OData.html).  I'm thinking something equivalent to the WDI package that allows easy access to the World Bank's World Development Indicators.

Cheers
PE

Peter Ellis
MANAGER SECTOR PERFORMANCE

Institutions and System Performance; Science, Skills and Innovation
Ministry of Business, Innovation & Employment

peter.ellis at mbie.govt.nz | Telephone: +64 4 498 7448 | Mobile: +64 29 771 0135
33 Bowen Street, PO Box 1473, Wellington 6140

Note: my emails are monitored more frequently than voice mail, and response times to emails are typically eight working hours quicker.



http://newzealand.govt.nz/ - connecting you to New Zealand central & local government services

Any opinions expressed in this message are not necessarily those of the Ministry of Business, Innovation and Employment. This message and any files transmitted with it are confidential and solely for the use of the intended recipient. If you are not the intended recipient or the person responsible for delivery to the intended recipient, be advised that you have received this message in error and that any use is strictly prohibited. Please contact the sender and delete the message and any attachment from your computer.


From ecjbosu at aol.com  Tue Oct 15 00:32:29 2013
From: ecjbosu at aol.com (Joe W. Byers)
Date: Mon, 14 Oct 2013 17:32:29 -0500
Subject: [R] rjava be-carefuls
In-Reply-To: <1381530521780-4678102.post@n4.nabble.com>
References: <1381530521780-4678102.post@n4.nabble.com>
Message-ID: <l3hrdk$jms$1@ger.gmane.org>

Hurr,

You have not given us much to help with here.  You might try posting a 
specific problem here or on rosuda-devel users group, the developer 
group for rjava and other omegahat projects.

Otherwise, start programming and see what work. I am trying to get Jsoup 
and/or htmlunit to work with not much success.  Patience and perseverance.

Good luck
Joe W. Byers

On 10/11/2013 05:28 PM, Hurr wrote:
> I have a java class with routines (and their tests) that I would like to
> use in R so I don't have to have two copies of important subroutines.
> I have looked at rjava, but can't grasp it all and don't know what are
> the important items to observe first so I don't get into too much
> trouble later. I would appreciate any pointers from some knowlegeable
> people. They are so-far just methods concerning strings, doubles, and
> integers. And of course pass-by-value, not by reference.
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/rjava-be-carefuls-tp4678102.html
> Sent from the R help mailing list archive at Nabble.com.
>


From smartpink111 at yahoo.com  Tue Oct 15 00:50:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 14 Oct 2013 15:50:02 -0700 (PDT)
Subject: [R] using ddply with segmented regression
In-Reply-To: <A780DAF149F5C24EBDFC048B071023B91F927790EC@useagan5503p.global.ecolab.corp>
References: <A780DAF149F5C24EBDFC048B071023B91B8C8423C5@useagan5503p.global.ecolab.corp>
	<1381560093.44823.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<A780DAF149F5C24EBDFC048B071023B91F927790EC@useagan5503p.global.ecolab.corp>
Message-ID: <1381791002.38076.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi Paul,

No problem.

Try:

par(mfrow=c(1,2)) 
?ldply(SP.seg,plot)
#or
lapply(SP.seg,plot)

A.K.




On Monday, October 14, 2013 5:57 PM, "Prew, Paul" <Paul.Prew at ecolab.com> wrote:
Hello,? the code provided by arun did the trick.? Thank you very much, arun.? 

However, I'm now unsure of how to further process the results .? Looking at the vignette? aka "split-apply-combine". It appears that I could now create a dataframe from the list of results, and then run the results through the function plot.segmented to view the piecewise regressions by the grouping variable Lot.Run.? However, the list is not in the structure expected by ldply -- 

>SP.seg <- dlply((df,.(Lot.Run),segmentf_df)
>SP.out <- ldply(SP.seg)

[9] ERROR:
Results must be all atomic, or all data frames

>class(SP.seg)[[1]]
[1] "list"

>head(SP.seg)
$`J062431-1`
Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
? ? control = seg.control(stop.if.error = FALSE, n.boot = 0, 
? ? ? ? gap = FALSE, jt = FALSE, nonParam = TRUE))

Meaningful coefficients of the linear terms:
(Intercept)? ? ? ? Cycle? ?  U1.Cycle? ?  U2.Cycle? ?  U3.Cycle? ?  U4.Cycle? ?  U5.Cycle? ?  U6.Cycle? 
?  40.11786? ?  -0.06664? ?  -0.68539? ? ? 0.49316? ? ? 0.14955? ? ? 0.03612? ? ? 0.22257? ?  -0.41166? 
?  U7.Cycle? ?  U8.Cycle? ?  U9.Cycle? ? U10.Cycle? 
?  -0.48365? ? ? 0.37949? ? ? 0.24945? ? ? 0.06712? 

Estimated Break-Point(s) psi1.Cycle psi2.Cycle psi3.Cycle psi4.Cycle psi5.Cycle psi6.Cycle psi7.Cycle psi8.Cycle psi9.Cycle psi10.Cycle :? 19.67? 34.31? 51.02? 72.10? 97.94 117.20 130.10 147.10 155.70 160.40 

$`J062431-2`
Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
? ? control = seg.control(stop.if.error = FALSE, n.boot = 0, 
? ? ? ? gap = FALSE, jt = FALSE, nonParam = TRUE))

Meaningful coefficients of the linear terms:
(Intercept)? ? ? ? Cycle? ?  U1.Cycle? ?  U2.Cycle? ?  U3.Cycle? ?  U4.Cycle? ?  U5.Cycle? ?  U6.Cycle? 
?  40.11786? ?  -0.06664? ?  -0.68539? ? ? 0.49316? ? ? 0.14955? ? ? 0.03612? ? ? 0.22257? ?  -0.41166? 
?  U7.Cycle? ?  U8.Cycle? ?  U9.Cycle? ? U10.Cycle? 
?  -0.48365? ? ? 0.37949? ? ? 0.24945? ? ? 0.06712? 

Estimated Break-Point(s) psi1.Cycle psi2.Cycle psi3.Cycle psi4.Cycle psi5.Cycle psi6.Cycle psi7.Cycle psi8.Cycle psi9.Cycle psi10.Cycle :? 19.67? 34.31? 51.02? 72.10? 97.94 117.20 130.10 147.10 155.70 160.40

My hope was to eventually increase my understanding enough to create lattice plots using 'segment.plot' via ldply.? Will that even work with the output object from this segmented package?? 

Thanks,Paul

Paul Prew? |? Statistician
651-795-5942?? |?? fax 651-204-7504 
Ecolab Research Center? | Mail Stop ESC-F4412-A 
655 Lone Oak Drive? |? Eagan, MN 55121-1560 

-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Saturday, October 12, 2013 1:42 AM
To: R help
Cc: Prew, Paul
Subject: Re: [R] using ddply with segmented regression



Hi,
Try:

segmentf_df <- function(df) {
out.lm<-lm(deltaWgt~Cycle, data=df)
segmented(out.lm,seg.Z=~Cycle, psi=(Cycle=NA),control=seg.control(stop.if.error=FALSE,n.boot=0))
}

library(plyr)
library(segmented)

dlply(df,.(Lot.Run),segmentf_df)
$`J062431-1`
Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
??? control = seg.control(stop.if.error = FALSE, n.boot = 0))

Meaningful coefficients of the linear terms:
(Intercept)??????? Cycle???? U1.Cycle???? U2.Cycle? 
???? 38.480??????? 1.130?????? -2.760??????? 1.497? 

Estimated Break-Point(s) psi1.Cycle psi2.Cycle : 3.732 5.056 

$`J062431-2`
Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
??? control = seg.control(stop.if.error = FALSE, n.boot = 0))

Meaningful coefficients of the linear terms:
(Intercept)??????? Cycle???? U1.Cycle???? U2.Cycle? 
??? 48.4300????? -3.2500?????? 3.0905????? -0.6555? 

Estimated Break-Point(s) psi1.Cycle psi2.Cycle :? 2.12 22.15 

attr(,"split_type")
[1] "data.frame"
attr(,"split_labels")
??? Lot.Run
1 J062431-1
2 J062431-2


#or

dlply(df,.(Lot.Run),function(x) segmentf_df(x))
#or
lapply(split(df,df$Lot.Run,drop=TRUE),function(x) segmentf_df(x))


A.K.


On Friday, October 11, 2013 11:16 PM, "Prew, Paul" <Paul.Prew at ecolab.com> wrote:
Hello,

I?m unsuccessfully trying to apply piecewise linear regression over each of 22 groups.? The data structure of the reproducible toy dataset is below.? I?m using the ?segmented? package, it worked fine with a data set that containing only one group (?Lot.Run?).

$ Cycle?? : int? 1 2 3 4 5 6 7 8 9 10 ...
$ Lot.Run : Factor w/ 22 levels "J062431-1","J062431-2",..: 1 1 1 1 1 1 1 1 1 1 ...
$ deltaWgt: num? 38.7 42.6 41 42.3 40.6 ...

I am new to ?segmented?, and also new to ?plyr?, which is how I?m trying to apply this segmented regression to the 22 Lot.Run groups.? Within a Lot.Run, the piecewise linear regressions are deltaWgt vs. Cycle.

#####? define the linear regression #####
out.lm<-lm(deltaWgt~Cycle, data=Test50.df)

#####? define the function called by dlply? #####
? ? ?? #####? find cutpoints via bootstrapping, fit the piecewise regressions? #####
segmentf_df <- function(df) {
segmented(out.lm,seg.Z=~Cycle, psi=(Cycle=NA),control=seg.control(stop.if.error=FALSE,n.boot=0)), data = df)
}

at this point, there?s an? error message
23] ERROR: <text>

#####? repeat for each Lot.Run group?? #####
dlply(Test50.df, .(Lot.Run), segmentf_df)

at this point, there?s an? error message
[28] ERROR:
object 'segmentf_df' not found

Any suggestions?
Thanks, Paul

> dput(Test50.df)
structure(list(Cycle = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
23L, 24L, 25L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
25L), Lot.Run = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("J062431-1",
"J062431-2", "J062431-3", "J062432-1", "J062432-2", "J062433-1",
"J062433-2", "J062433-3", "Lot 1-1", "Lot 1-2", "Lot 2-1", "Lot 2-2",
"Lot 2-3", "Lot 3-1", "Lot 3-2", "Lot 3-3", "P041231-1", "P041231-2",
"P041531-1", "P041531-2", "P041531-3", "P041531-4"), class = "factor"),
? ? deltaWgt = c(38.69, 42.58, 40.95, 42.26, 40.63, 41.61, 36.73,
? ? 41.28, 39.98, 40.63, 39.66, 39.98, 40.95, 38.36, 39.01, 39,
? ? 38.03, 39.66, 37.7, 39.66, 40.63, 38.03, 37.71, 36.73, 37.7,
? ? 45.18, 41.93, 42.59, 39.98, 40.95, 42.91, 38.03, 40.96, 39,
? ? 41.61, 39.33, 43.88, 39.98, 38.68, 38.68, 36.08, 39.99, 38.35,
? ? 40.31, 40.63, 38.68, 37.05, 38.36, 35.43, 36.73)), .Names = c("Cycle",
"Lot.Run", "deltaWgt"), row.names = c(1L, 2L, 3L, 4L, 5L, 6L,
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
20L, 21L, 22L, 23L, 24L, 25L, 207L, 208L, 209L, 210L, 211L, 212L,
213L, 214L, 215L, 216L, 217L, 218L, 219L, 220L, 221L, 222L, 223L,
224L, 225L, 226L, 227L, 228L, 229L, 230L, 231L), class = "data.frame")




Paul Prew?? ?? Statistician
651-795-5942?? ??? fax 651-204-7504
Ecolab Research Center?? ?? Mail Stop ESC-F4412-A
655 Lone Oak Drive?? ??? Eagan, MN 55121-1560




CONFIDENTIALITY NOTICE: This e-mail communication and any attachments may contain proprietary and privileged information for the use of the designated recipients named above. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.

??? [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




CONFIDENTIALITY NOTICE: This e-mail communication and any attachments may contain proprietary and privileged information for the use of the designated recipients named above. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.



From Paul.Prew at ecolab.com  Tue Oct 15 01:23:04 2013
From: Paul.Prew at ecolab.com (Prew, Paul)
Date: Mon, 14 Oct 2013 18:23:04 -0500
Subject: [R] using ddply with segmented regression
In-Reply-To: <F42E84B0-61EA-40ED-8207-B6E20F272041@comcast.net>
References: <A780DAF149F5C24EBDFC048B071023B91B8C8423C5@useagan5503p.global.ecolab.corp>
	<1381560093.44823.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<A780DAF149F5C24EBDFC048B071023B91F927790EC@useagan5503p.global.ecolab.corp>
	<F42E84B0-61EA-40ED-8207-B6E20F272041@comcast.net>
Message-ID: <A780DAF149F5C24EBDFC048B071023B91F9277914F@useagan5503p.global.ecolab.corp>

Yes, David, sorry for the confusion.  I forgot arun had proposed a genericized solution, where the dataframe name was shortened from "Test50.df" to "df".  I could have replaced arun's 'df' references to 'Test50.df', but lazily changed my "Test50.df" to "df" and used arun's code verbatim.

The unmatched parenthesis you caught (cut&paste error) is fixed here:  SP.seg <- dlply(df,.(Lot.Run),segmentf_df)

>> SP.out <- ldply(SP.seg)

As for your (excerpted) question --
                 *So what function were you intending to be used in that call to ldply ...  If you are using ldply to process the models with plot.segmented, .. object returned will be an empty dataframe but the plots will be done.*

I wanted to look at the data frame first so I could understand the model output represented in row x column format.   Then I planned to try
     > ldply(SP.seg, segmented.plot)

  If the above printed out the 22 piecewise regressions individually, then the next step would be determining how they could be arranged in a 1-page lattice.  I think the chemist who generated the results would profit from that.  The 1-pager would require me investigating lattice or ggplot2.

Paul Prew  |  Statistician
651-795-5942?? |?? fax 651-204-7504 
Ecolab Research Center  | Mail Stop ESC-F4412-A 
655 Lone Oak Drive  |  Eagan, MN 55121-1560 


-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Monday, October 14, 2013 5:30 PM
To: Prew, Paul
Cc: arun; R help
Subject: Re: [R] using ddply with segmented regression


On Oct 14, 2013, at 2:57 PM, Prew, Paul wrote:

> Hello,  the code provided by arun did the trick.  Thank you very much, arun.  
> 
> However, I'm now unsure of how to further process the results .  
> Looking at the vignette  aka "split-apply-combine". It appears that I 
> could now create a dataframe from the list of results, and then run 
> the results through the function plot.segmented to view the piecewise 
> regressions by the grouping variable Lot.Run.  However, the list is 
> not in the structure expected by ldply --
> 
>> SP.seg <- dlply(df,.(Lot.Run),segmentf_df)

That wasn't the name of the dataframe you offered in the first post.... and this code could not possibly have not thrown an error since there are unmatched parens.

>> SP.out <- ldply(SP.seg)

So what function were you intending to be used in that call to ldply ...  after you fix the errors above? If you are using ldply to process the models with plot.segmented, then realize that the object returned will be an empty dataframe but hte plots will be done.

> 
> [9] ERROR:
> Results must be all atomic, or all data frames
> 
>> class(SP.seg)[[1]]
> [1] "list"
> 
>> head(SP.seg)
> $`J062431-1`
> Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
>    control = seg.control(stop.if.error = FALSE, n.boot = 0, 
>        gap = FALSE, jt = FALSE, nonParam = TRUE))
> 
> Meaningful coefficients of the linear terms:
> (Intercept)        Cycle     U1.Cycle     U2.Cycle     U3.Cycle     U4.Cycle     U5.Cycle     U6.Cycle  
>   40.11786     -0.06664     -0.68539      0.49316      0.14955      0.03612      0.22257     -0.41166  
>   U7.Cycle     U8.Cycle     U9.Cycle    U10.Cycle  
>   -0.48365      0.37949      0.24945      0.06712  
> 
> Estimated Break-Point(s) psi1.Cycle psi2.Cycle psi3.Cycle psi4.Cycle 
> psi5.Cycle psi6.Cycle psi7.Cycle psi8.Cycle psi9.Cycle psi10.Cycle :  
> 19.67  34.31  51.02  72.10  97.94 117.20 130.10 147.10 155.70 160.40
> 
> $`J062431-2`
> Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
>    control = seg.control(stop.if.error = FALSE, n.boot = 0, 
>        gap = FALSE, jt = FALSE, nonParam = TRUE))
> 
> Meaningful coefficients of the linear terms:
> (Intercept)        Cycle     U1.Cycle     U2.Cycle     U3.Cycle     U4.Cycle     U5.Cycle     U6.Cycle  
>   40.11786     -0.06664     -0.68539      0.49316      0.14955      0.03612      0.22257     -0.41166  
>   U7.Cycle     U8.Cycle     U9.Cycle    U10.Cycle  
>   -0.48365      0.37949      0.24945      0.06712  
> 
> Estimated Break-Point(s) psi1.Cycle psi2.Cycle psi3.Cycle psi4.Cycle 
> psi5.Cycle psi6.Cycle psi7.Cycle psi8.Cycle psi9.Cycle psi10.Cycle :  
> 19.67  34.31  51.02  72.10  97.94 117.20 130.10 147.10 155.70 160.40
> 
> My hope was to eventually increase my understanding enough to create lattice plots using 'segment.plot' via ldply.  Will that even work with the output object from this segmented package?  

Hard to tell. You seem to be changing the names of your objects at random.

> 
> Thanks,Paul
> 
> Paul Prew  |  Statistician
> 651-795-5942   |   fax 651-204-7504 
> Ecolab Research Center  | Mail Stop ESC-F4412-A
> 655 Lone Oak Drive  |  Eagan, MN 55121-1560
> 
> -----Original Message-----
> From: arun [mailto:smartpink111 at yahoo.com]
> Sent: Saturday, October 12, 2013 1:42 AM
> To: R help
> Cc: Prew, Paul
> Subject: Re: [R] using ddply with segmented regression
> 
> 
> 
> Hi,
> Try:
> 
> segmentf_df <- function(df) {
> out.lm<-lm(deltaWgt~Cycle, data=df)
> segmented(out.lm,seg.Z=~Cycle, 
> psi=(Cycle=NA),control=seg.control(stop.if.error=FALSE,n.boot=0))
> }
> 
> library(plyr)
> library(segmented)
> 
> dlply(df,.(Lot.Run),segmentf_df)
> $`J062431-1`
> Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
>     control = seg.control(stop.if.error = FALSE, n.boot = 0))
> 
> Meaningful coefficients of the linear terms:
> (Intercept)        Cycle     U1.Cycle     U2.Cycle  
>      38.480        1.130       -2.760        1.497  
> 
> Estimated Break-Point(s) psi1.Cycle psi2.Cycle : 3.732 5.056
> 
> $`J062431-2`
> Call: segmented.lm(obj = out.lm, seg.Z = ~Cycle, psi = (Cycle = NA), 
>     control = seg.control(stop.if.error = FALSE, n.boot = 0))
> 
> Meaningful coefficients of the linear terms:
> (Intercept)        Cycle     U1.Cycle     U2.Cycle  
>     48.4300      -3.2500       3.0905      -0.6555  
> 
> Estimated Break-Point(s) psi1.Cycle psi2.Cycle :  2.12 22.15
> 
> attr(,"split_type")
> [1] "data.frame"
> attr(,"split_labels")
>     Lot.Run
> 1 J062431-1
> 2 J062431-2
> 
> 
> #or
> 
> dlply(df,.(Lot.Run),function(x) segmentf_df(x)) #or
> lapply(split(df,df$Lot.Run,drop=TRUE),function(x) segmentf_df(x))
> 
> 
> A.K.
> 
> 
> On Friday, October 11, 2013 11:16 PM, "Prew, Paul" <Paul.Prew at ecolab.com> wrote:
> Hello,
> 
> I'm unsuccessfully trying to apply piecewise linear regression over each of 22 groups.  The data structure of the reproducible toy dataset is below.  I'm using the 'segmented' package, it worked fine with a data set that containing only one group ("Lot.Run").
> 
> $ Cycle   : int  1 2 3 4 5 6 7 8 9 10 ...
> $ Lot.Run : Factor w/ 22 levels "J062431-1","J062431-2",..: 1 1 1 1 1 1 1 1 1 1 ...
> $ deltaWgt: num  38.7 42.6 41 42.3 40.6 ...
> 
> I am new to 'segmented', and also new to 'plyr', which is how I'm trying to apply this segmented regression to the 22 Lot.Run groups.  Within a Lot.Run, the piecewise linear regressions are deltaWgt vs. Cycle.
> 
> #####  define the linear regression ##### out.lm<-lm(deltaWgt~Cycle, 
> data=Test50.df)
> 
> #####  define the function called by dlply  #####
>        #####  find cutpoints via bootstrapping, fit the piecewise 
> regressions  ##### segmentf_df <- function(df) { 
> segmented(out.lm,seg.Z=~Cycle, 
> psi=(Cycle=NA),control=seg.control(stop.if.error=FALSE,n.boot=0)), 
> data = df) }
> 
> at this point, there's an  error message 23] ERROR: <text>
> 
> #####  repeat for each Lot.Run group   #####
> dlply(Test50.df, .(Lot.Run), segmentf_df)
> 
> at this point, there's an  error message [28] ERROR:
> object 'segmentf_df' not found
> 
> Any suggestions?
> Thanks, Paul
> 
>> dput(Test50.df)
> structure(list(Cycle = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
> 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
> 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L), Lot.Run = 
> structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
> 2L, 2L), .Label = c("J062431-1", "J062431-2", "J062431-3", 
> "J062432-1", "J062432-2", "J062433-1", "J062433-2", "J062433-3", "Lot 
> 1-1", "Lot 1-2", "Lot 2-1", "Lot 2-2", "Lot 2-3", "Lot 3-1", "Lot 
> 3-2", "Lot 3-3", "P041231-1", "P041231-2", "P041531-1", "P041531-2", 
> "P041531-3", "P041531-4"), class = "factor"),
>     deltaWgt = c(38.69, 42.58, 40.95, 42.26, 40.63, 41.61, 36.73,
>     41.28, 39.98, 40.63, 39.66, 39.98, 40.95, 38.36, 39.01, 39,
>     38.03, 39.66, 37.7, 39.66, 40.63, 38.03, 37.71, 36.73, 37.7,
>     45.18, 41.93, 42.59, 39.98, 40.95, 42.91, 38.03, 40.96, 39,
>     41.61, 39.33, 43.88, 39.98, 38.68, 38.68, 36.08, 39.99, 38.35,
>     40.31, 40.63, 38.68, 37.05, 38.36, 35.43, 36.73)), .Names = 
> c("Cycle", "Lot.Run", "deltaWgt"), row.names = c(1L, 2L, 3L, 4L, 5L, 
> 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
> 21L, 22L, 23L, 24L, 25L, 207L, 208L, 209L, 210L, 211L, 212L, 213L, 
> 214L, 215L, 216L, 217L, 218L, 219L, 220L, 221L, 222L, 223L, 224L, 
> 225L, 226L, 227L, 228L, 229L, 230L, 231L), class = "data.frame")
> 
> 
> 


David Winsemius
Alameda, CA, USA



CONFIDENTIALITY NOTICE: This e-mail communication and an...{{dropped:7}}


From mlinchits at gmail.com  Tue Oct 15 01:27:16 2013
From: mlinchits at gmail.com (Maxim Linchits)
Date: Tue, 15 Oct 2013 03:27:16 +0400
Subject: [R] RStudio with Revolution-R
Message-ID: <CAGKs4siRxDYEf+iFXxb3ZAObrB6xHta0sGJWQ9FD-5n0Trfdjw@mail.gmail.com>

Hello,
Is it possible to use Revolution-R's multithreading capability with
RStudio as the IDE? Apparently, RevoR is available for Ubuntu,
although I am not sure if this is well-supported and up to date build.
I would be interested in combining the two on Windows and RHEL too.

(Another option is to try OpenBLAS I suppose)

Just out of curiosity, does MKL in RevolutionR make that much of a
difference with unmodified R code and standard R packages? Or does one
have to use some custom packages to get the the effect?

Thanks,
Max


From dwinsemius at comcast.net  Tue Oct 15 01:51:45 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 14 Oct 2013 16:51:45 -0700
Subject: [R] RStudio with Revolution-R
In-Reply-To: <CAGKs4siRxDYEf+iFXxb3ZAObrB6xHta0sGJWQ9FD-5n0Trfdjw@mail.gmail.com>
References: <CAGKs4siRxDYEf+iFXxb3ZAObrB6xHta0sGJWQ9FD-5n0Trfdjw@mail.gmail.com>
Message-ID: <834F6D49-5268-4112-BAF7-77516BC85005@comcast.net>


On Oct 14, 2013, at 4:27 PM, Maxim Linchits wrote:

> Hello,
> Is it possible to use Revolution-R's multithreading capability with
> RStudio as the IDE? Apparently, RevoR is available for Ubuntu,
> although I am not sure if this is well-supported and up to date build.
> I would be interested in combining the two on Windows and RHEL too.
> 
> (Another option is to try OpenBLAS I suppose)
> 
> Just out of curiosity, does MKL in RevolutionR make that much of a
> difference with unmodified R code and standard R packages? Or does one
> have to use some custom packages to get the the effect?

Isn't this the wrong mailing list for questions about these distributions? Don't you have a RevoR (or RStudio) mailing list?

-- 

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Tue Oct 15 01:59:49 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 14 Oct 2013 19:59:49 -0400
Subject: [R] Transform plot3d grafics in to executable files
In-Reply-To: <BCFDD89A-66A2-4F0E-8314-448794D572D0@comcast.net>
References: <20131014103314.Horde.GvTFpk_ymYFkrdC-ZKpo8g9@webmail.df.eu>
	<BCFDD89A-66A2-4F0E-8314-448794D572D0@comcast.net>
Message-ID: <525C8575.3010301@gmail.com>

On 13-10-14 1:13 PM, David Winsemius wrote:
>
> On Oct 14, 2013, at 1:33 AM, paladini at trustindata.de wrote:
>
>> Hello,
>> I did some nice grafics using plot 3d and scatter3d. Is there a, hopefully not too complicated way, to transform these dynamic, three-dimensional and interactive grafics in a kind of
>> executable file? I want to show and send them via e-mail to projekt partners who don`t use GNU R and who are not used to do programming. So the result should be quite comfortable to execute for them in windows.
>>
>> I hope my question is not too naive.
>
> ?rgl.snapshot
> ?play3d
> ?movie3d
>

Actually, ?writeWebGL is probably closer to what Claudia was after.

Duncan Murdoch


From jdnewmil at dcn.davis.CA.us  Tue Oct 15 02:02:18 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 14 Oct 2013 17:02:18 -0700
Subject: [R] RStudio with Revolution-R
In-Reply-To: <CAGKs4siRxDYEf+iFXxb3ZAObrB6xHta0sGJWQ9FD-5n0Trfdjw@mail.gmail.com>
References: <CAGKs4siRxDYEf+iFXxb3ZAObrB6xHta0sGJWQ9FD-5n0Trfdjw@mail.gmail.com>
Message-ID: <3d584021-bd70-4b99-8e2e-cc69740e55ae@email.android.com>

No disrespect intended to either software package... but why don't you ask this question on a forum where either of these software packages is on topic?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Maxim Linchits <mlinchits at gmail.com> wrote:
>Hello,
>Is it possible to use Revolution-R's multithreading capability with
>RStudio as the IDE? Apparently, RevoR is available for Ubuntu,
>although I am not sure if this is well-supported and up to date build.
>I would be interested in combining the two on Windows and RHEL too.
>
>(Another option is to try OpenBLAS I suppose)
>
>Just out of curiosity, does MKL in RevolutionR make that much of a
>difference with unmodified R code and standard R packages? Or does one
>have to use some custom packages to get the the effect?
>
>Thanks,
>Max
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jeffrey.flint at gmail.com  Tue Oct 15 03:10:42 2013
From: jeffrey.flint at gmail.com (Jeffrey Flint)
Date: Mon, 14 Oct 2013 18:10:42 -0700
Subject: [R] project parallel help
In-Reply-To: <217f1ef8-2a1b-4304-a33d-11c64f85f83a@email.android.com>
References: <CALbUM4MeRpHMvxUJ7MGvjrLJdtS8bwhfuSxGMLJZKJPqc7VY6Q@mail.gmail.com>
	<217f1ef8-2a1b-4304-a33d-11c64f85f83a@email.android.com>
Message-ID: <CALbUM4NQuTjBPMSS1zdt9=T_igs39O57d-+RDGbcGtBMDg-zww@mail.gmail.com>

Jeff:

Thank you for your response.  Please let me know how I can
"unhandicap" my question.  I tried my best to be concise.  Maybe this
will help:

> version
               _
platform       i386-w64-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          3
minor          0.2
year           2013
month          09
day            25
svn rev        63987
language       R
version.string R version 3.0.2 (2013-09-25)
nickname       Frisbee Sailing


I understand your comment about forking.  You are right that forking
is not available on windows.

What I am curious about is whether or not I can direct the execution
of the parallel package's functions to diminish the overhead.  My
guess is that there is overhead in copying the function to be executed
at each iteration and there is overhead in copying the data to be used
at each iteration.  Are there any paradigms in the package parallel to
reduce these overheads?  For instance, I could use clusterExport to
establish the function to be called.  But I don't know if there is a
technique whereby I could point to the data to be used by each CPU so
as to prevent a copy.

Jeff



On Mon, Oct 14, 2013 at 2:35 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Your question misses on several points in the Posting Guide so any answers are handicapped by you.
>
> There is an overhead in using parallel processing, and the value of two cores is marginal at best. In general parallel by forking is more efficient than parallel by SNOW, but the former is not available on all operating systems. This is discussed in the vignette for the parallel package.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> Jeffrey Flint <jeffrey.flint at gmail.com> wrote:
>>I'm running package parallel in R-3.0.2.
>>
>>Below are the execution times using system.time for when executing
>>serially versus in parallel (with 2 cores) using parRapply.
>>
>>
>>Serially:
>>   user  system elapsed
>>   4.67    0.03    4.71
>>
>>
>>
>>Using package parallel:
>>   user  system elapsed
>>   3.82    0.12    6.50
>>
>>
>>
>>There is evident improvement in the user cpu time, but a big jump in
>>the elapsed time.
>>
>>In my code, I am executing a function on a 1000 row matrix 100 times,
>>with the data different each time of course.
>>
>>The initial call to makeCluster cost 1.25 seconds in elapsed time.
>>I'm not concerned about the makeCluster time since that is a fixed
>>cost.  I am concerned about the additional 1.43 seconds in elapsed
>>time (6.50=1.43+1.25).
>>
>>I am wondering if there is a way to structure the code to avoid
>>largely avoid the 1.43 second overhead.  For instance, perhaps I could
>>upload the function to both cores manually in order to avoid the
>>function being uploaded at each of the 100 iterations?    Also, I am
>>wondering if there is a way to avoid any copying that is occurring at
>>each of the 100 iterations?
>>
>>
>>Thank you.
>>
>>Jeff Flint
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Tue Oct 15 04:22:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 14 Oct 2013 19:22:11 -0700 (PDT)
Subject: [R] Help with combining functions
In-Reply-To: <1381771487.97372.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <71A9F37B694303439E0627F5D05323B56E2697@EXMBCT03.campus.ncl.ac.uk>
	<1381771487.97372.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1381803731.40194.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Using ?replace()
?vec2 <- replace(n,c(n[n%%3==0 & !n%%5==0],n[!n%%3==0 & n%%5==0],n[n%%15==0]),c(rep(c("heads","tails","headstails"),c(sum(n%%3==0 & !n%%5==0),sum(!n%%3==0 & n%%5==0),sum(n%%15==0)))))
?identical(vec1,vec2)
#[1] TRUE

#or 
library(plyr)
vec3 <- mapvalues(n,c(n[n%%3==0 & !n%%5==0],n[!n%%3==0 & n%%5==0],n[n%%15==0]),c(rep(c("heads","tails","headstails"),c(sum(n%%3==0 & !n%%5==0),sum(!n%%3==0 & n%%5==0),sum(n%%15==0)))))
?identical(vec1,vec3)
#[1] TRUE

A.K.



On Monday, October 14, 2013 1:24 PM, arun <smartpink111 at yahoo.com> wrote:


Hi,
Try:
?vec1 <- as.character(factor(1*(n%%3==0)+2*(n%%5==0)+3*(n%%15==0),labels=c("Other","heads","tails","headstails")))
?vec1[vec1=="Other"] <- which(vec1=="Other")
vec1[1:6]
#[1] "1"???? "2"???? "heads" "4"???? "tails" "heads"

A.K.



On Monday, October 14, 2013 12:57 PM, Kile Green <Kile.Green at newcastle.ac.uk> wrote:
Hi,



I am very new to 'R' ("discovered" it about 2 months ago) and have been trying to teach myself the language using online guides, however I am not a programmer or statistician and so progress is slow.



As an exercise, I have been trying to generate the numbers 1 to 100 and replace multiples of 3 with the text "heads", multiples of 5 with the text "tails" and multiples of both 3 and 5 with the text "headstails".



So far I have managed to write the functions individually with:

> n=c(1:100)

> a=replace(n,n%%3==0,"heads")
> b=replace(n,n%%5==0,"tails")
> c=replace(n,n%%15==0,"headstails")



I would like to combine these functions into a single process to produce an output along the lines of:

1,2,"heads",4,"tails","heads",7,8,"heads","tails"... etc



I tried the following, without success:



> replace(n,c(n%%3==0,n%%5==0,n%%15==0),c("heads","tails,"headstails"))



As an 'R' novice I don't really have an idea of how I should approach this problem and unfortunately I have had problems trying to apply the answers given to other replace() and c() questions to my example.



I would be grateful if someone could point me in the right direction or provide a similar example of combining simple functions without just giving the answer away - i'd like to learn how to use 'R', rather than just be told the answer.



Regards,



Kile

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jdnewmil at dcn.davis.CA.us  Tue Oct 15 07:21:54 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 14 Oct 2013 22:21:54 -0700
Subject: [R] project parallel help
In-Reply-To: <CALbUM4NQuTjBPMSS1zdt9=T_igs39O57d-+RDGbcGtBMDg-zww@mail.gmail.com>
References: <CALbUM4MeRpHMvxUJ7MGvjrLJdtS8bwhfuSxGMLJZKJPqc7VY6Q@mail.gmail.com>
	<217f1ef8-2a1b-4304-a33d-11c64f85f83a@email.android.com>
	<CALbUM4NQuTjBPMSS1zdt9=T_igs39O57d-+RDGbcGtBMDg-zww@mail.gmail.com>
Message-ID: <771166ad-7e82-4be2-91be-a9e4c563a53f@email.android.com>

The session info is helpful. To the best of my knowledge there is no easy way to share memory between R processes other than forking. You can use clusterExport to make "global" copies of large data structures in each process and pass index values to your function to reduce copy costs at a price of extra data copies in each process that won't be used. Or you can copy distinct blocks of data to each process and use single threaded processing to loop over the blocks within the workers to reduce the number of calls to workers. However I don't claim to be an expert with the parallel package, so others may have better advice.  However, with two cores I don't usually get better than a 30% speedup... the best payoff comes with four or more workers working.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Jeffrey Flint <jeffrey.flint at gmail.com> wrote:
>Jeff:
>
>Thank you for your response.  Please let me know how I can
>"unhandicap" my question.  I tried my best to be concise.  Maybe this
>will help:
>
>> version
>               _
>platform       i386-w64-mingw32
>arch           i386
>os             mingw32
>system         i386, mingw32
>status
>major          3
>minor          0.2
>year           2013
>month          09
>day            25
>svn rev        63987
>language       R
>version.string R version 3.0.2 (2013-09-25)
>nickname       Frisbee Sailing
>
>
>I understand your comment about forking.  You are right that forking
>is not available on windows.
>
>What I am curious about is whether or not I can direct the execution
>of the parallel package's functions to diminish the overhead.  My
>guess is that there is overhead in copying the function to be executed
>at each iteration and there is overhead in copying the data to be used
>at each iteration.  Are there any paradigms in the package parallel to
>reduce these overheads?  For instance, I could use clusterExport to
>establish the function to be called.  But I don't know if there is a
>technique whereby I could point to the data to be used by each CPU so
>as to prevent a copy.
>
>Jeff
>
>
>
>On Mon, Oct 14, 2013 at 2:35 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> Your question misses on several points in the Posting Guide so any
>answers are handicapped by you.
>>
>> There is an overhead in using parallel processing, and the value of
>two cores is marginal at best. In general parallel by forking is more
>efficient than parallel by SNOW, but the former is not available on all
>operating systems. This is discussed in the vignette for the parallel
>package.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> Jeffrey Flint <jeffrey.flint at gmail.com> wrote:
>>>I'm running package parallel in R-3.0.2.
>>>
>>>Below are the execution times using system.time for when executing
>>>serially versus in parallel (with 2 cores) using parRapply.
>>>
>>>
>>>Serially:
>>>   user  system elapsed
>>>   4.67    0.03    4.71
>>>
>>>
>>>
>>>Using package parallel:
>>>   user  system elapsed
>>>   3.82    0.12    6.50
>>>
>>>
>>>
>>>There is evident improvement in the user cpu time, but a big jump in
>>>the elapsed time.
>>>
>>>In my code, I am executing a function on a 1000 row matrix 100 times,
>>>with the data different each time of course.
>>>
>>>The initial call to makeCluster cost 1.25 seconds in elapsed time.
>>>I'm not concerned about the makeCluster time since that is a fixed
>>>cost.  I am concerned about the additional 1.43 seconds in elapsed
>>>time (6.50=1.43+1.25).
>>>
>>>I am wondering if there is a way to structure the code to avoid
>>>largely avoid the 1.43 second overhead.  For instance, perhaps I
>could
>>>upload the function to both cores manually in order to avoid the
>>>function being uploaded at each of the 100 iterations?    Also, I am
>>>wondering if there is a way to avoid any copying that is occurring at
>>>each of the 100 iterations?
>>>
>>>
>>>Thank you.
>>>
>>>Jeff Flint
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>


From dayashka at gmail.com  Tue Oct 15 06:21:02 2013
From: dayashka at gmail.com (Dayashka Khan)
Date: Tue, 15 Oct 2013 09:21:02 +0500
Subject: [R] Help Call
Message-ID: <CAEucKOGSVp8sVPHC4jaROB52KoiN2zoVZcoWnBZavgA903j85g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/543ee4a8/attachment.pl>

From msuzen at gmail.com  Tue Oct 15 10:43:15 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Tue, 15 Oct 2013 10:43:15 +0200
Subject: [R] RStudio with Revolution-R
In-Reply-To: <CAGKs4siRxDYEf+iFXxb3ZAObrB6xHta0sGJWQ9FD-5n0Trfdjw@mail.gmail.com>
References: <CAGKs4siRxDYEf+iFXxb3ZAObrB6xHta0sGJWQ9FD-5n0Trfdjw@mail.gmail.com>
Message-ID: <CAPtbhHy=ayTr9fyS+dLmy3mfN7Xq8_-mg8xcDGLQbw4FDinEeA@mail.gmail.com>

On 15 October 2013 01:27, Maxim Linchits <mlinchits at gmail.com> wrote:
> Hello,
> Is it possible to use Revolution-R's multithreading capability with
> RStudio as the IDE? Apparently, RevoR is available for Ubuntu,

Wrong list!

But for reference:
http://stackoverflow.com/questions/10835122/multithreading-with-r


From optionsraghu at gmail.com  Tue Oct 15 11:53:35 2013
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Tue, 15 Oct 2013 10:53:35 +0100
Subject: [R] Contract Work
Message-ID: <CADgEnDmyp-n=rXTZ+F4tQmXD7vUVBrKo9qXfQ7wew54ZHrCE5A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/e760f2c2/attachment.pl>

From batholdy at googlemail.com  Tue Oct 15 12:32:34 2013
From: batholdy at googlemail.com (Martin Batholdy)
Date: Tue, 15 Oct 2013 12:32:34 +0200
Subject: [R] cluster option in stata for random intercept model in the R
	language?
Message-ID: <83D8EB37-5894-486F-ACDB-8800E9A6846A@googlemail.com>

Dear R-list,

I am currently working on a dataset with a colleague who uses stata.
We fit a random intercept model to the data (decisions clustered in participants) and get closely the same results in stata (using xtreg re) and R (using the lme4 or multilevel package).


Now in stata, there is an additional option for the regression to control for clustering; the vce(cluster clustvar) option, which changes the standard errors quite a bit.
(see http://www.stata.com/support/faqs/statistics/standard-errors-and-vce-cluster-option/ or http://www.stata.com/manuals13/xtxtreg.pdf).

Unfortunately I don't understand what this 'correction' does and why it yields different results.
First I thought it would control for autocorrelations over time (decisions), but if I model this directly with a random-intercept random-slope model, I don't get nearly the same results.

Can someone help me understand what stata is doing here?
And what would be the equivalent in R to get similar results?


thanks!


From stefan at inizio.se  Tue Oct 15 12:51:40 2013
From: stefan at inizio.se (Stefan Petersson)
Date: Tue, 15 Oct 2013 12:51:40 +0200
Subject: [R] R on Server without installation
Message-ID: <CAFy6Y8X7aTTDxA0tJNmMWYR+df4j+MmiW9z7N6V+H9gHs6kbaw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/e26fde05/attachment.pl>

From catalinroibu at gmail.com  Tue Oct 15 13:07:18 2013
From: catalinroibu at gmail.com (catalin roibu)
Date: Tue, 15 Oct 2013 14:07:18 +0300
Subject: [R] extract regression coefficients
Message-ID: <CAEW+BDKJ6Q9+ODB92=13YX_zF28zFv=KqD+LffDiRX97s8D2oA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/0f93aaca/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Tue Oct 15 13:53:12 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 15 Oct 2013 13:53:12 +0200 (MEST)
Subject: [R] bug(?) in str() with strict.width = "cut" when applied to
	dataframe with numeric component AND factor or character
	component with longerlevels/strings
Message-ID: <Pine.SOC.4.64.1310151248250.10890@solcom.hrz.uni-giessen.de>

Dear list subscribers,

here is a small artificial example to demonstrate the problem that I 
encountered when looking at the structure of a (larger) data frame that 
comprised (among other components)

a numeric component of elements of the order of > 10000, and

a factor or character component with longer levels/strings:


k <- 43      # length of levels or character strings
n <- 11      # number of rows of data frame
M <- 10000   # order of magnitude of numerical values

set.seed( 47) # to reproduce the following artificial character string
longer.char.string <- paste( sample( letters, k, replace = TRUE),
                              collapse = "")

X <- data.frame( A = 1:n * M,
                  B = rep( longer.char.string, n))


The following call to str() gives apparently a wrong result

str( X, strict.width = "cut")

'data.frame':   11 obs. of  2 variables:
  $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
  $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..


whereas the correct result appears for str( X) or if you decrease k to 42 
(isn't that "the answer"? ;-) ) or n to 10 or M to 1000 (or smaller, 
respectively).


I tried to dig into the entrails of str.default(), where the cause may 
lie, but got lost pretty soon. So, I am hoping that someone may already 
have a work-around or patch (or dares to dig further)? Thank you for any 
feedback!

  Best regards  --  Gerrit

PS:

> sessionInfo()

R version 3.0.2 (2013-09-25)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
[5] LC_TIME=German_Germany.1252

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets
[7] methods   base

other attached packages:
[1] nparcomp_2.0     multcomp_1.2-21  mvtnorm_0.9-9996
[4] car_2.0-19       Hmisc_3.12-2     Formula_1.1-1
[7] survival_2.37-4  fortunes_1.5-0

loaded via a namespace (and not attached):
[1] cluster_1.14.4  grid_3.0.2      lattice_0.20-23 MASS_7.3-29
[5] nnet_7.3-7      rpart_4.1-3     stats4_3.0.2    tools_3.0.2

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner


From dan.abner99 at gmail.com  Tue Oct 15 13:55:27 2013
From: dan.abner99 at gmail.com (Dan Abner)
Date: Tue, 15 Oct 2013 07:55:27 -0400
Subject: [R] Writing an R fn to produce random sequences of binaries XXXX
Message-ID: <CAPRGo-mLKOgAiOr2SEV+2oWAbYrVNdbThuautKz-PuYAxHGCbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/cac95c66/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Tue Oct 15 13:59:22 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 15 Oct 2013 13:59:22 +0200 (MEST)
Subject: [R] extract regression coefficients
In-Reply-To: <CAEW+BDKJ6Q9+ODB92=13YX_zF28zFv=KqD+LffDiRX97s8D2oA@mail.gmail.com>
References: <CAEW+BDKJ6Q9+ODB92=13YX_zF28zFv=KqD+LffDiRX97s8D2oA@mail.gmail.com>
Message-ID: <Pine.SOC.4.64.1310151358430.10890@solcom.hrz.uni-giessen.de>

Hello, Catalin,

check out

?coef

  Regards -- Gerrit


On Tue, 15 Oct 2013, catalin roibu wrote:

> Hello all!
> I have a problem with R. I want to extract regression coefficients from
> summary and use it for compute the theoretical values.
>
> How can I do that in R?
>
> thank you!
>
> best regards,
>
> -- 
> ---
> Catalin-Constantin ROIBU
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone     +4 0230 52 29 78, ext. 531
> mobile phone   +4 0745 53 18 01
>                       +4 0766 71 76 58
> FAX:                +4 0230 52 16 64
> silvic.usv.ro
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue Oct 15 14:17:14 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 15 Oct 2013 08:17:14 -0400
Subject: [R] Writing an R fn to produce random sequences of binaries XXXX
In-Reply-To: <CAPRGo-mLKOgAiOr2SEV+2oWAbYrVNdbThuautKz-PuYAxHGCbA@mail.gmail.com>
References: <CAPRGo-mLKOgAiOr2SEV+2oWAbYrVNdbThuautKz-PuYAxHGCbA@mail.gmail.com>
Message-ID: <525D324A.1030904@gmail.com>

On 13-10-15 7:55 AM, Dan Abner wrote:
> Hi all,
>
> I am attempting to write an R fn to produce a random sequence of 8 binaries
> (4 ordered pairs). I would like to parmeterize the fn so that it takes 2
> arguments: 1 that is an overall probability of a 1 vs. 0 and the other
> which controls the likelihood of 1s on the 1st vs. the 2nd element of the 4
> ordered pairs.
>
> Here are some examples:
>
>
>     *Voiced Probability Parm* *1st Element Probability Parm* *Average N of 1s
> * *Average N 1st Element 1s* * * *1* *1.5* *2* *2.5* *3* *3.5* *4*
> *4.5*
> 0.5 1 4 4 1 0 1 0 1 0 1 0  0.5 0 4 0 0 1 0 1 0 1 0 1  0.5 0.75 4 3 1 0 0 1 1
> 0 1 0  0.5 0.25 4 1 0 1 0 1 1 0 0 1  1 1 8 4 1 1 1 1 1 1 1 1  0 0 0 0 0 0 0
> 0 0 0 0 0  0.5 0.5 4 2 1 0 0 1 1 0 0 1
>
>
> Can anyone suggest an algorithm for this? I have a 1st draft of the fn
> definition, but my algorithm is not correct as I am not getting the average
> number of 1s (averaged over 10,000 sequences) correct.

A simple algorithm is to sample the 1st bit using rbinom(), then sample 
the second bit, again using rbinom, but with probability conditional on 
the value of the first bit.  But that requires a joint distribution, and 
you haven't given us enough information to construct one.

For example, here's a model where bit 2 is either independent of bit 1 
or forced to be equal to it, with theta being the probability of being 
forced to be equal.  This probably isn't the model you want, but you 
would just modify the bit2 line to give the correct conditional 
distribution based on what you do want.

p <- 0.7     # marginal prob of a 1
theta <- 0.5 # ratio of times bit 2 is equal to bit 1, versus
              # independent
bit1 <- rbinom(4, size=1, p)
bit2 <- rbinom(4, size=1, theta*bit1 + (1-theta)*p)
cbind(bit1, bit2)

Duncan Murdoch

>
> Thanks,
>
> Dan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Tue Oct 15 14:25:29 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 15 Oct 2013 13:25:29 +0100
Subject: [R] R on Server without installation
In-Reply-To: <CAFy6Y8X7aTTDxA0tJNmMWYR+df4j+MmiW9z7N6V+H9gHs6kbaw@mail.gmail.com>
References: <CAFy6Y8X7aTTDxA0tJNmMWYR+df4j+MmiW9z7N6V+H9gHs6kbaw@mail.gmail.com>
Message-ID: <525D3439.10600@stats.ox.ac.uk>

On 15/10/2013 11:51, Stefan Petersson wrote:
> Hi,
>
> I use a regular web hosting service to build a web site under windows .NET.
> Now I need statistical functionality on the site, and I would really like
> to use R for that. However, I'm not allowed to install anything (e.g. R) on
> the host. Are there any implementations/workarounds of R that doesn't need
> to be installed, just 'copied' to the server host?
>

Since this seems to be Windows, see the FAQ:
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#Can-I-run-R-from-a-CD-or-USB-drive_003f

> TIA
>
>    //  s
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please do: it points out to you the documentations already written.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Gerrit.Eichner at math.uni-giessen.de  Tue Oct 15 14:27:18 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 15 Oct 2013 14:27:18 +0200 (MEST)
Subject: [R] extract regression coefficients
In-Reply-To: <CAEW+BDK44EkmJemN3fXEjHQszwmDXcA90gR4QCgHMhhiQ7j1=g@mail.gmail.com>
References: <CAEW+BDKJ6Q9+ODB92=13YX_zF28zFv=KqD+LffDiRX97s8D2oA@mail.gmail.com>
	<Pine.SOC.4.64.1310151358430.10890@solcom.hrz.uni-giessen.de>
	<CAEW+BDK44EkmJemN3fXEjHQszwmDXcA90gR4QCgHMhhiQ7j1=g@mail.gmail.com>
Message-ID: <Pine.SOC.4.64.1310151423120.10890@solcom.hrz.uni-giessen.de>

Hello, Catalin,

fist: keep the reply on-list so that others can follow.

second: (see below)

On Tue, 15 Oct 2013, catalin roibu wrote:

> Hello!
> I try that! But I want to use them forward in the equation and I don't want
> to write every time when I change the values.

This way to unspecific to give you any hint. So, "PLEASE do read the 
posting guide http://www.R-project.org/posting-guide.html and provide 
commented, minimal, self-contained, reproducible code."

  Regards  --  Gerrit


> On 15 October 2013 14:59, Gerrit Eichner <Gerrit.Eichner at math.uni-giessen.de
>> wrote:
>
>> Hello, Catalin,
>>
>> check out
>>
>> ?coef
>>
>>  Regards -- Gerrit
>>
>>
>>
>> On Tue, 15 Oct 2013, catalin roibu wrote:
>>
>>  Hello all!
>>> I have a problem with R. I want to extract regression coefficients from
>>> summary and use it for compute the theoretical values.
>>>
>>> How can I do that in R?
>>>
>>> thank you!
>>>
>>> best regards,
>>>
>>> --
>>> ---
>>> Catalin-Constantin ROIBU
>>> Lecturer PhD, Forestry engineer
>>> Forestry Faculty of Suceava
>>> Str. Universitatii no. 13, Suceava, 720229, Romania
>>> office phone     +4 0230 52 29 78, ext. 531
>>> mobile phone   +4 0745 53 18 01
>>>                       +4 0766 71 76 58
>>> FAX:                +4 0230 52 16 64
>>> silvic.usv.ro
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________**________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/**
>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
>
> -- 
> ---
> Catalin-Constantin ROIBU
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone     +4 0230 52 29 78, ext. 531
> mobile phone   +4 0745 53 18 01
>                       +4 0766 71 76 58
> FAX:                +4 0230 52 16 64
> silvic.usv.ro


From murdoch.duncan at gmail.com  Tue Oct 15 14:45:54 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 15 Oct 2013 08:45:54 -0400
Subject: [R] R on Server without installation
In-Reply-To: <CAFy6Y8X7aTTDxA0tJNmMWYR+df4j+MmiW9z7N6V+H9gHs6kbaw@mail.gmail.com>
References: <CAFy6Y8X7aTTDxA0tJNmMWYR+df4j+MmiW9z7N6V+H9gHs6kbaw@mail.gmail.com>
Message-ID: <525D3902.40300@gmail.com>

On 13-10-15 6:51 AM, Stefan Petersson wrote:
> Hi,
>
> I use a regular web hosting service to build a web site under windows .NET.
> Now I need statistical functionality on the site, and I would really like
> to use R for that. However, I'm not allowed to install anything (e.g. R) on
> the host. Are there any implementations/workarounds of R that doesn't need
> to be installed, just 'copied' to the server host?
>

I suspect that your host will consider copying executables onto it to be 
equivalent to installing them, so I'd recommend asking them to install 
it for you.

The likely reason for the restriction is so that you can't create 
security holes; you'll need to be careful to run R in a way that allows 
you to ask it to do the things you want without allowing users to ask it 
to do whatever they want.

Duncan Murdoch


From ron_michael70 at yahoo.com  Tue Oct 15 15:24:59 2013
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Tue, 15 Oct 2013 21:24:59 +0800 (SGT)
Subject: [R] Finding solution for non-linear equations
Message-ID: <1381843499.34536.YahooMailBasic@web190503.mail.sg3.yahoo.com>

Hi,

I need to solve following simultaneous equations for A, B, Y1, Y2:

B * Phi(Y1 - A) + (1-B) * Phi(Y1 + A) = 0.05
B * Phi(Y2 - A) + (1-B) * Phi(Y2 + A) = 0.01

Y1 <= -1.65
Y2 >= -2.33

0 <= B <=1 

Phi is CDF for standard normal

If there is no unique solution, then I should be able to get some feassible solution(s)

Is there any way that using R I can achieve that?

Thanks for your time


From dwinsemius at comcast.net  Tue Oct 15 15:50:43 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 15 Oct 2013 06:50:43 -0700
Subject: [R] cluster option in stata for random intercept model in the R
	language?
In-Reply-To: <83D8EB37-5894-486F-ACDB-8800E9A6846A@googlemail.com>
References: <83D8EB37-5894-486F-ACDB-8800E9A6846A@googlemail.com>
Message-ID: <14A632CE-C504-499A-8452-5D9DA5BF6F6A@comcast.net>


On Oct 15, 2013, at 3:32 AM, Martin Batholdy wrote:

> Dear R-list,
>
> I am currently working on a dataset with a colleague who uses stata.
> We fit a random intercept model to the data (decisions clustered in  
> participants) and get closely the same results in stata (using xtreg  
> re) and R (using the lme4 or multilevel package).
>
>
> Now in stata, there is an additional option for the regression to  
> control for clustering; the vce(cluster clustvar) option, which  
> changes the standard errors quite a bit.
> (see http://www.stata.com/support/faqs/statistics/standard-errors-and-vce-cluster-option/ 
>  or http://www.stata.com/manuals13/xtxtreg.pdf).
>
> Unfortunately I don't understand what this 'correction' does and why  
> it yields different results.
> First I thought it would control for autocorrelations over time  
> (decisions), but if I model this directly with a random-intercept  
> random-slope model, I don't get nearly the same results.
>
> Can someone help me understand what stata is doing here?
> And what would be the equivalent in R to get similar results?

http://www.stata.com/statalist/


> _______
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From caciquesamurai at gmail.com  Tue Oct 15 16:27:12 2013
From: caciquesamurai at gmail.com (Raoni Rodrigues)
Date: Tue, 15 Oct 2013 11:27:12 -0300
Subject: [R] Data handling
Message-ID: <CAGtwFe0Baw3QzBd72+Gb2cyfymb4oEuV19o9quVd3eaUyN0KbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/ba2100ce/attachment.pl>

From gunter.berton at gene.com  Tue Oct 15 16:37:16 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 15 Oct 2013 07:37:16 -0700
Subject: [R] Finding solution for non-linear equations
In-Reply-To: <1381843499.34536.YahooMailBasic@web190503.mail.sg3.yahoo.com>
References: <1381843499.34536.YahooMailBasic@web190503.mail.sg3.yahoo.com>
Message-ID: <CACk-te02jXYX+C0JheKTp=UfFMhqhsqAhG9beQVfhNPm_QZj6w@mail.gmail.com>

Homework?

We don't do homework here.

Otherwise, the answer is yes, R can be used to do this.

Cheers,
Bert

On Tue, Oct 15, 2013 at 6:24 AM, Ron Michael <ron_michael70 at yahoo.com> wrote:
> Hi,
>
> I need to solve following simultaneous equations for A, B, Y1, Y2:
>
> B * Phi(Y1 - A) + (1-B) * Phi(Y1 + A) = 0.05
> B * Phi(Y2 - A) + (1-B) * Phi(Y2 + A) = 0.01
>
> Y1 <= -1.65
> Y2 >= -2.33
>
> 0 <= B <=1
>
> Phi is CDF for standard normal
>
> If there is no unique solution, then I should be able to get some feassible solution(s)
>
> Is there any way that using R I can achieve that?
>
> Thanks for your time
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From smartpink111 at yahoo.com  Tue Oct 15 16:38:55 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 15 Oct 2013 07:38:55 -0700 (PDT)
Subject: [R] matrix of mean values
In-Reply-To: <CAMMD=S4p4Hee4W6SFPa34yJwo7PS120_Ly5Yh1YGSOPArLRjUg@mail.gmail.com>
References: <CAMMD=S5_druNFxzGtK5bnqKB15HD04CskeCEpYKqQmRhE3u0Lw@mail.gmail.com>	<1381244075.53183.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<1381244163.66311.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAMMD=S6eHJQoVSZ5ZRJvp5LEE2=6TY4JVH8RxHUbbjCMURnOZQ@mail.gmail.com>	<1381251208.3018.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAMMD=S6y2buBsJc+Q8GxXrEXT=ZhtuVzUaCBENv8sbp_yabb_A@mail.gmail.com>	<1381253473.39852.YahooMailNeo@web142605.mail.bf1.yahoo.com>	<1381327756.50387.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAMMD=S54FC5NAhE8YjgrCy4vbMJWEw5dGM6FdBEwrndw0tN6KA@mail.gmail.com>	<1381411093.93070.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAMMD=S4p4Hee4W6SFPa34yJwo7PS120_Ly5Yh1YGSOPArLRjUg@mail.gmail.com>
Message-ID: <1381847935.99647.YahooMailNeo@web142605.mail.bf1.yahoo.com>




Hi Nico,
Try:

setAs("character", "num.commas", 
??????? function(from) as.numeric(gsub(",", "", from) ) )
d1 <- read.csv("cont.txt",header=TRUE,sep="\t",colClasses=c("numeric","character","num.commas"))
colnames(d1)[-3] <- c("loc","variables")
library(reshape2)
?res <- dcast(d1,loc~variables,value.var="value",mean)

row.names(res) <- res[,1]
?res1 <- as.matrix(res[,-1])
?dim(res1)
#[1] 129 190

A.K.

On Tuesday, October 15, 2013 8:07 AM, Nico Met <nicomet80 at gmail.com> wrote:

Hi Arun, many thanks. Here I attached the data.

Regards

Nico


From bhh at xs4all.nl  Tue Oct 15 17:18:11 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 15 Oct 2013 17:18:11 +0200
Subject: [R] Finding solution for non-linear equations
In-Reply-To: <1381843499.34536.YahooMailBasic@web190503.mail.sg3.yahoo.com>
References: <1381843499.34536.YahooMailBasic@web190503.mail.sg3.yahoo.com>
Message-ID: <147C88AF-A088-4BD7-8D0C-4DE871806A2D@xs4all.nl>


On 15-10-2013, at 15:24, Ron Michael <ron_michael70 at yahoo.com> wrote:

> Hi,
> 
> I need to solve following simultaneous equations for A, B, Y1, Y2:
> 
> B * Phi(Y1 - A) + (1-B) * Phi(Y1 + A) = 0.05
> B * Phi(Y2 - A) + (1-B) * Phi(Y2 + A) = 0.01
> 
> Y1 <= -1.65
> Y2 >= -2.33
> 
> 0 <= B <=1 
> 
> Phi is CDF for standard normal
> 
> If there is no unique solution, then I should be able to get some feassible solution(s)
> 
> Is there any way that using R I can achieve that?


You cannot solve a system of 2 equations with 4 unknowns (variables).
You can only try to find  4 values that get as close as possible (in whatever sense) to solving the system.

In other words you must define a function that returns some scalar measure of closeness to a solution.

Assuming this is homework I'll only give you a hint.

Have a look at the functions optim and constrOptim.
Both can do what you want and both are able to solve your problem.

good luck,

Berend


From rolf.kemper at renesas.com  Tue Oct 15 17:54:23 2013
From: rolf.kemper at renesas.com (rolf.kemper at renesas.com)
Date: Tue, 15 Oct 2013 17:54:23 +0200
Subject: [R] compute current values in a facet
Message-ID: <OF58A895D1.DD6E7EC9-ONC1257C05.00564ABB-C1257C05.005760C3@eu.necel.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/07fa6d01/attachment.pl>

From c.rowat at bham.ac.uk  Tue Oct 15 17:38:20 2013
From: c.rowat at bham.ac.uk (Colin Rowat)
Date: Tue, 15 Oct 2013 15:38:20 +0000
Subject: [R] plotting a marginal distribution on the plane behind a persp()
	plot
Message-ID: <BAE35083C4441B4E9975691D547496F9058913@EX3.adf.bham.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/df2bc666/attachment.pl>

From guinasso at tamu.edu  Tue Oct 15 18:15:18 2013
From: guinasso at tamu.edu (Norman Guinasso)
Date: Tue, 15 Oct 2013 11:15:18 -0500
Subject: [R]  Everything You Need for JEdit/R Edit Mode
Message-ID: <525D6A16.4050002@tamu.edu>

How can I find the mode files for jedit for R?

-- 
Norman L. Guinasso, Jr., Deputy Director
Geochemical and Environmental Research Group
College of Geosciences, Texas A&M University, MS3149
833 Graham Road, College Station TX 77845
(979)862-2323 ext. 114 fax: (979)862-2361 Cell: (979) 777-1580


From hnorpois at gmail.com  Tue Oct 15 16:23:47 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Tue, 15 Oct 2013 16:23:47 +0200
Subject: [R] plot: want only dots
Message-ID: <CAKyZeBv4FhrDNm9c6GJmvC3bHSCyKjp0x+Js-fPrSwKnKQpV_A@mail.gmail.com>

Hello,

I would like to plot some values referring to the genotype (which is 0,1
and 2).  My data is organised like this:

head (df)
  Genotype          z
1        0 0.07029379
2        0 2.15739115
3        0 0.51395897
4        0 0.48733029
5        0 0.15584074
6        0 0.27755294

I tried:
> plot (df)
And.
> plot (z ~ Genotype, data=df)

But it is always the same. As demonstrated in the attachment there are bars
with mean etc... But I want dots only. How does this work?

Thanks
Hermann

> dput (df)
structure(list(Genotype = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L), .Label = c("0",
"1", "2"), class = "factor"), z = c(0.0702937908415368, 2.15739115226985,
0.513958971085714, 0.487330287677455, 0.155840743875606, 0.277552938739661,
0.507384510251828, 9.25159831317385e-05, 0.420814150642641,
10.628270981371,
0.518650521289299, 0.644448203670876, 0.133539811585953, 0.248985608185673,
0.152636019877717, 0.00964805339859479, 7.57036184259711e-05,
0.649435257991169, 0.38951827610564, 75.6011068681301)), .Names =
c("Genotype",
"z"), row.names = c(NA, 20L), class = "data.frame")
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: zzz.png
Type: image/png
Size: 3771 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/cb40553a/attachment.png>

From smartpink111 at yahoo.com  Tue Oct 15 17:13:42 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 15 Oct 2013 08:13:42 -0700 (PDT)
Subject: [R] Data handling
In-Reply-To: <CAGtwFe0Baw3QzBd72+Gb2cyfymb4oEuV19o9quVd3eaUyN0KbA@mail.gmail.com>
References: <CAGtwFe0Baw3QzBd72+Gb2cyfymb4oEuV19o9quVd3eaUyN0KbA@mail.gmail.com>
Message-ID: <1381850022.65086.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Try:
?op <- options(digits.secs=4)

? TimeCC <- as.POSIXct(paste0(paste(teste[,1],teste[,2]), sub("^0","",teste[,3])),format="%m/%d/%y %H:%M:%OS")
options(op) #reset

A.K.


On Tuesday, October 15, 2013 10:29 AM, Raoni Rodrigues <caciquesamurai at gmail.com> wrote:
Hello all,

I'm having a problem with data handling. My input data is (dput in the
after the signature):

? ? Date? ?  Time Fraction
06/19/13 22:15:39?  0.3205
06/19/13 22:15:44?  0.3205
06/19/13 22:15:49?  0.3205
06/19/13 22:15:54?  0.3205
06/19/13 22:15:59?  0.3205
06/19/13 22:16:09?  0.3205

Date in format month/day/year, Time in HH:MM:SS and fraction represents the
fractions of seconds. I need to have a vector in a format year-month-day
hh:mm:ss.0000. Or, in format: format = "%F %H:%M:%OS4", as POSIXct class.

I made the the conversion step-by-step to have sure that nothing is missed
in the way:

> options (digits.sec = 4)
> getOption ("digits.sec")
[1] 4
> teste$Date1 = as.Date (teste$Date, format = "%m/%d/%y")
> class (teste$Date1)
[1] "Date"
> teste$Fraction = sub ("0.", "", teste$Fraction)
> teste$TimeC = paste (teste$Time, teste$Fraction, sep = ".")
> teste$TimeCC = paste (teste$Date1, teste$TimeC)

> head (teste)
? ? ? Date? ?  Time Fraction? ? ? Date1? ? ? ? TimeC? ? ? ? ? ? ? ? ? TimeCC
1 06/19/13 22:15:39? ?  .325 2013-06-19 22:15:39.325 2013-06-19
22:15:39.3205
2 06/19/13 22:15:44? ?  .325 2013-06-19 22:15:44.325 2013-06-19
22:15:44.3205
3 06/19/13 22:15:49? ?  .325 2013-06-19 22:15:49.325 2013-06-19
22:15:49.3205
4 06/19/13 22:15:54? ?  .325 2013-06-19 22:15:54.325 2013-06-19
22:15:54.3205
5 06/19/13 22:15:59? ?  .325 2013-06-19 22:15:59.325 2013-06-19
22:15:59.3205
6 06/19/13 22:16:09? ?  .325 2013-06-19 22:16:09.325 2013-06-19
22:16:09.3205

So far so well. The problem is when I tried to convert to POSIXct class. If
I use just:

teste$TimeCC = format (teste$TimeCC, format = "%F %H:%M:%OS4")
teste$TimeCC = as.POSIXct (teste$TimeCC)

I lost the fraction of seconds. If I use:

teste$TimeCC = as.POSIXct(strptime (teste$TimeCC, format = "%F %H:%M:%OS4"))

I lost all information and get just <NA>.

Thanks in advanced,

-- 
Raoni Rosa Rodrigues
Research Associate of Fish Transposition Center CTPeixes
Universidade Federal de Minas Gerais - UFMG
Brasil
rodrigues.raoni at gmail.com

dput of input data

structure(list(Date = c("06/19/13", "06/19/13", "06/19/13", "06/19/13",
"06/19/13", "06/19/13"), Time = c("22:15:39", "22:15:44", "22:15:49",
"22:15:54", "22:15:59", "22:16:09"), Fraction = c("0.3205", "0.3205",
"0.3205", "0.3205", "0.3205", "0.3205")), .Names = c("Date",
"Time", "Fraction"), row.names = c(NA, 6L), class = "data.frame")

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jholtman at gmail.com  Tue Oct 15 18:45:10 2013
From: jholtman at gmail.com (jim holtman)
Date: Tue, 15 Oct 2013 12:45:10 -0400
Subject: [R] Data handling
In-Reply-To: <CAGtwFe0Baw3QzBd72+Gb2cyfymb4oEuV19o9quVd3eaUyN0KbA@mail.gmail.com>
References: <CAGtwFe0Baw3QzBd72+Gb2cyfymb4oEuV19o9quVd3eaUyN0KbA@mail.gmail.com>
Message-ID: <CAAxdm-7uNQw20AuwnaxTMjL5k1WY+SrTbvntviPAshdSf0CkrA@mail.gmail.com>

Try this; your time is converted back to a character string if you
want to show the fractional part.

> x <- read.table(text = "    Date     Time Fraction
+  06/19/13 22:15:39   0.3205
+  06/19/13 22:15:44   0.3205
+  06/19/13 22:15:49   0.3205
+  06/19/13 22:15:54   0.3205
+  06/19/13 22:15:59   0.3205
+  06/19/13 22:16:09   0.3205", as.is = TRUE, header = TRUE)
>  x$newTime <- as.POSIXct(
+     paste0(x$Date, ' ', x$Time , '.', substring(x$Fraction, 3))
+     , format = "%m/%d/%y %H:%M:%OS"
+     )
>  x$formatted <- format(x$newTime, format = "%m/%d/%y %H:%M:%OS4")
>
>
>
> x
      Date     Time Fraction             newTime              formatted
1 06/19/13 22:15:39   0.3205 2013-06-19 22:15:39 06/19/13 22:15:39.3204
2 06/19/13 22:15:44   0.3205 2013-06-19 22:15:44 06/19/13 22:15:44.3204
3 06/19/13 22:15:49   0.3205 2013-06-19 22:15:49 06/19/13 22:15:49.3204
4 06/19/13 22:15:54   0.3205 2013-06-19 22:15:54 06/19/13 22:15:54.3204
5 06/19/13 22:15:59   0.3205 2013-06-19 22:15:59 06/19/13 22:15:59.3204
6 06/19/13 22:16:09   0.3205 2013-06-19 22:16:09 06/19/13 22:16:09.3204
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Tue, Oct 15, 2013 at 10:27 AM, Raoni Rodrigues
<caciquesamurai at gmail.com> wrote:
> Hello all,
>
> I'm having a problem with data handling. My input data is (dput in the
> after the signature):
>
>     Date     Time Fraction
>  06/19/13 22:15:39   0.3205
>  06/19/13 22:15:44   0.3205
>  06/19/13 22:15:49   0.3205
>  06/19/13 22:15:54   0.3205
>  06/19/13 22:15:59   0.3205
>  06/19/13 22:16:09   0.3205
>
> Date in format month/day/year, Time in HH:MM:SS and fraction represents the
> fractions of seconds. I need to have a vector in a format year-month-day
> hh:mm:ss.0000. Or, in format: format = "%F %H:%M:%OS4", as POSIXct class.
>
> I made the the conversion step-by-step to have sure that nothing is missed
> in the way:
>
>> options (digits.sec = 4)
>> getOption ("digits.sec")
> [1] 4
>> teste$Date1 = as.Date (teste$Date, format = "%m/%d/%y")
>> class (teste$Date1)
> [1] "Date"
>> teste$Fraction = sub ("0.", "", teste$Fraction)
>> teste$TimeC = paste (teste$Time, teste$Fraction, sep = ".")
>> teste$TimeCC = paste (teste$Date1, teste$TimeC)
>
>> head (teste)
>       Date     Time Fraction      Date1        TimeC                  TimeCC
> 1 06/19/13 22:15:39     .325 2013-06-19 22:15:39.325 2013-06-19
> 22:15:39.3205
> 2 06/19/13 22:15:44     .325 2013-06-19 22:15:44.325 2013-06-19
> 22:15:44.3205
> 3 06/19/13 22:15:49     .325 2013-06-19 22:15:49.325 2013-06-19
> 22:15:49.3205
> 4 06/19/13 22:15:54     .325 2013-06-19 22:15:54.325 2013-06-19
> 22:15:54.3205
> 5 06/19/13 22:15:59     .325 2013-06-19 22:15:59.325 2013-06-19
> 22:15:59.3205
> 6 06/19/13 22:16:09     .325 2013-06-19 22:16:09.325 2013-06-19
> 22:16:09.3205
>
> So far so well. The problem is when I tried to convert to POSIXct class. If
> I use just:
>
> teste$TimeCC = format (teste$TimeCC, format = "%F %H:%M:%OS4")
> teste$TimeCC = as.POSIXct (teste$TimeCC)
>
> I lost the fraction of seconds. If I use:
>
> teste$TimeCC = as.POSIXct(strptime (teste$TimeCC, format = "%F %H:%M:%OS4"))
>
> I lost all information and get just <NA>.
>
> Thanks in advanced,
>
> --
> Raoni Rosa Rodrigues
> Research Associate of Fish Transposition Center CTPeixes
> Universidade Federal de Minas Gerais - UFMG
> Brasil
> rodrigues.raoni at gmail.com
>
> dput of input data
>
> structure(list(Date = c("06/19/13", "06/19/13", "06/19/13", "06/19/13",
> "06/19/13", "06/19/13"), Time = c("22:15:39", "22:15:44", "22:15:49",
> "22:15:54", "22:15:59", "22:16:09"), Fraction = c("0.3205", "0.3205",
> "0.3205", "0.3205", "0.3205", "0.3205")), .Names = c("Date",
> "Time", "Fraction"), row.names = c(NA, 6L), class = "data.frame")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Tue Oct 15 18:47:07 2013
From: jholtman at gmail.com (jim holtman)
Date: Tue, 15 Oct 2013 12:47:07 -0400
Subject: [R] Data handling
In-Reply-To: <CAAxdm-7uNQw20AuwnaxTMjL5k1WY+SrTbvntviPAshdSf0CkrA@mail.gmail.com>
References: <CAGtwFe0Baw3QzBd72+Gb2cyfymb4oEuV19o9quVd3eaUyN0KbA@mail.gmail.com>
	<CAAxdm-7uNQw20AuwnaxTMjL5k1WY+SrTbvntviPAshdSf0CkrA@mail.gmail.com>
Message-ID: <CAAxdm-471ot0g0+P3ojxvSTzxhwDx+TmhoFHXPJxOaiYp+GXjg@mail.gmail.com>

FYI.

The fractional part is printed as '3204' instead of '3205' since with
POSIXct you only have accuracy to the millisecond for times around
now.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Tue, Oct 15, 2013 at 12:45 PM, jim holtman <jholtman at gmail.com> wrote:
> Try this; your time is converted back to a character string if you
> want to show the fractional part.
>
>> x <- read.table(text = "    Date     Time Fraction
> +  06/19/13 22:15:39   0.3205
> +  06/19/13 22:15:44   0.3205
> +  06/19/13 22:15:49   0.3205
> +  06/19/13 22:15:54   0.3205
> +  06/19/13 22:15:59   0.3205
> +  06/19/13 22:16:09   0.3205", as.is = TRUE, header = TRUE)
>>  x$newTime <- as.POSIXct(
> +     paste0(x$Date, ' ', x$Time , '.', substring(x$Fraction, 3))
> +     , format = "%m/%d/%y %H:%M:%OS"
> +     )
>>  x$formatted <- format(x$newTime, format = "%m/%d/%y %H:%M:%OS4")
>>
>>
>>
>> x
>       Date     Time Fraction             newTime              formatted
> 1 06/19/13 22:15:39   0.3205 2013-06-19 22:15:39 06/19/13 22:15:39.3204
> 2 06/19/13 22:15:44   0.3205 2013-06-19 22:15:44 06/19/13 22:15:44.3204
> 3 06/19/13 22:15:49   0.3205 2013-06-19 22:15:49 06/19/13 22:15:49.3204
> 4 06/19/13 22:15:54   0.3205 2013-06-19 22:15:54 06/19/13 22:15:54.3204
> 5 06/19/13 22:15:59   0.3205 2013-06-19 22:15:59 06/19/13 22:15:59.3204
> 6 06/19/13 22:16:09   0.3205 2013-06-19 22:16:09 06/19/13 22:16:09.3204
>>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Tue, Oct 15, 2013 at 10:27 AM, Raoni Rodrigues
> <caciquesamurai at gmail.com> wrote:
>> Hello all,
>>
>> I'm having a problem with data handling. My input data is (dput in the
>> after the signature):
>>
>>     Date     Time Fraction
>>  06/19/13 22:15:39   0.3205
>>  06/19/13 22:15:44   0.3205
>>  06/19/13 22:15:49   0.3205
>>  06/19/13 22:15:54   0.3205
>>  06/19/13 22:15:59   0.3205
>>  06/19/13 22:16:09   0.3205
>>
>> Date in format month/day/year, Time in HH:MM:SS and fraction represents the
>> fractions of seconds. I need to have a vector in a format year-month-day
>> hh:mm:ss.0000. Or, in format: format = "%F %H:%M:%OS4", as POSIXct class.
>>
>> I made the the conversion step-by-step to have sure that nothing is missed
>> in the way:
>>
>>> options (digits.sec = 4)
>>> getOption ("digits.sec")
>> [1] 4
>>> teste$Date1 = as.Date (teste$Date, format = "%m/%d/%y")
>>> class (teste$Date1)
>> [1] "Date"
>>> teste$Fraction = sub ("0.", "", teste$Fraction)
>>> teste$TimeC = paste (teste$Time, teste$Fraction, sep = ".")
>>> teste$TimeCC = paste (teste$Date1, teste$TimeC)
>>
>>> head (teste)
>>       Date     Time Fraction      Date1        TimeC                  TimeCC
>> 1 06/19/13 22:15:39     .325 2013-06-19 22:15:39.325 2013-06-19
>> 22:15:39.3205
>> 2 06/19/13 22:15:44     .325 2013-06-19 22:15:44.325 2013-06-19
>> 22:15:44.3205
>> 3 06/19/13 22:15:49     .325 2013-06-19 22:15:49.325 2013-06-19
>> 22:15:49.3205
>> 4 06/19/13 22:15:54     .325 2013-06-19 22:15:54.325 2013-06-19
>> 22:15:54.3205
>> 5 06/19/13 22:15:59     .325 2013-06-19 22:15:59.325 2013-06-19
>> 22:15:59.3205
>> 6 06/19/13 22:16:09     .325 2013-06-19 22:16:09.325 2013-06-19
>> 22:16:09.3205
>>
>> So far so well. The problem is when I tried to convert to POSIXct class. If
>> I use just:
>>
>> teste$TimeCC = format (teste$TimeCC, format = "%F %H:%M:%OS4")
>> teste$TimeCC = as.POSIXct (teste$TimeCC)
>>
>> I lost the fraction of seconds. If I use:
>>
>> teste$TimeCC = as.POSIXct(strptime (teste$TimeCC, format = "%F %H:%M:%OS4"))
>>
>> I lost all information and get just <NA>.
>>
>> Thanks in advanced,
>>
>> --
>> Raoni Rosa Rodrigues
>> Research Associate of Fish Transposition Center CTPeixes
>> Universidade Federal de Minas Gerais - UFMG
>> Brasil
>> rodrigues.raoni at gmail.com
>>
>> dput of input data
>>
>> structure(list(Date = c("06/19/13", "06/19/13", "06/19/13", "06/19/13",
>> "06/19/13", "06/19/13"), Time = c("22:15:39", "22:15:44", "22:15:49",
>> "22:15:54", "22:15:59", "22:16:09"), Fraction = c("0.3205", "0.3205",
>> "0.3205", "0.3205", "0.3205", "0.3205")), .Names = c("Date",
>> "Time", "Fraction"), row.names = c(NA, 6L), class = "data.frame")
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Tue Oct 15 18:47:42 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 15 Oct 2013 12:47:42 -0400
Subject: [R] plot: want only dots
In-Reply-To: <CAKyZeBv4FhrDNm9c6GJmvC3bHSCyKjp0x+Js-fPrSwKnKQpV_A@mail.gmail.com>
References: <CAKyZeBv4FhrDNm9c6GJmvC3bHSCyKjp0x+Js-fPrSwKnKQpV_A@mail.gmail.com>
Message-ID: <CAM_vju=kG_vAdjQT1=JgdE1QzoU-hjFHarD5XYX3aCktLF73Ww@mail.gmail.com>

Hi,

Genotype is a factor, and R is giving you the default type for that data type.

I changed your data frame to mydata because df() is a function, but see this:

> str(mydata)
'data.frame':    20 obs. of  2 variables:
 $ Genotype: Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 2 2 ...
 $ z       : num  0.0703 2.1574 0.514 0.4873 0.1558 ...

It sounds like you might want:

with(mydata, plot(as.numeric(as.character(Genotype)), z))

but if Genotype is best represented as a factor, that may not be the
most informative type of plot.

Sarah

On Tue, Oct 15, 2013 at 10:23 AM, Hermann Norpois <hnorpois at gmail.com> wrote:
> Hello,
>
> I would like to plot some values referring to the genotype (which is 0,1
> and 2).  My data is organised like this:
>
> head (df)
>   Genotype          z
> 1        0 0.07029379
> 2        0 2.15739115
> 3        0 0.51395897
> 4        0 0.48733029
> 5        0 0.15584074
> 6        0 0.27755294
>
> I tried:
>> plot (df)
> And.
>> plot (z ~ Genotype, data=df)
>
> But it is always the same. As demonstrated in the attachment there are bars
> with mean etc... But I want dots only. How does this work?
>
> Thanks
> Hermann
>
>> dput (df)
> structure(list(Genotype = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L), .Label = c("0",
> "1", "2"), class = "factor"), z = c(0.0702937908415368, 2.15739115226985,
> 0.513958971085714, 0.487330287677455, 0.155840743875606, 0.277552938739661,
> 0.507384510251828, 9.25159831317385e-05, 0.420814150642641,
> 10.628270981371,
> 0.518650521289299, 0.644448203670876, 0.133539811585953, 0.248985608185673,
> 0.152636019877717, 0.00964805339859479, 7.57036184259711e-05,
> 0.649435257991169, 0.38951827610564, 75.6011068681301)), .Names =
> c("Genotype",
> "z"), row.names = c(NA, 20L), class = "data.frame")
>>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Tue Oct 15 18:51:02 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 15 Oct 2013 12:51:02 -0400
Subject: [R] Everything You Need for JEdit/R Edit Mode
In-Reply-To: <525D6A16.4050002@tamu.edu>
References: <525D6A16.4050002@tamu.edu>
Message-ID: <CAM_vjuk5ChziRZZdgURFstoQ6nfS3Naxkx=VaDTV+QxkTHxEWA@mail.gmail.com>

Hi,

On Tue, Oct 15, 2013 at 12:15 PM, Norman Guinasso <guinasso at tamu.edu> wrote:
> How can I find the mode files for jedit for R?

This really isn't an R question, but is this what you're looking for?

http://www.stanford.edu/~cengel/cgi-bin/anthrospace/syntax-coloring-for-r-in-jedit

(I googled jedit R mode file - you might try that if the above link
doesn't actually answer your question, since your question didn't make
it clear what exactly you're looking for, at least to me.)

Sarah



-- 
Sarah Goslee
http://www.functionaldiversity.org


From murdoch.duncan at gmail.com  Tue Oct 15 18:59:46 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 15 Oct 2013 12:59:46 -0400
Subject: [R] plotting a marginal distribution on the plane behind a
 persp() plot
In-Reply-To: <BAE35083C4441B4E9975691D547496F9058913@EX3.adf.bham.ac.uk>
References: <BAE35083C4441B4E9975691D547496F9058913@EX3.adf.bham.ac.uk>
Message-ID: <525D7482.4070903@gmail.com>

On 15/10/2013 11:38 AM, Colin Rowat wrote:
> R'istas:
>
> I am trying to plot a marginal distribution on the plane behind a persp() plot.  My existing code is:
>
> library(MASS)
>
> X <- mvrnorm(1000,mu=c(0,0),Sigma=matrix(c(1,0,0,1),2))
>
> X.kde <- kde2d(X[,1],X[,2],n=25) # X.kde is list: $x 1*n, $y 1*n, $z n*n
>
> persp(X.kde,phi=30,theta=60,xlab="x_b",ylab="x_a",zlab="f") ->res
>
> Any suggestions are very appreciated.

I would suggest not using persp() (use rgl::persp3d instead), but you 
can do it in persp using the same technique as in the 2nd example in the 
?persp help page.   The difficulty with doing this is that persp() uses 
the painter's algorithm for hiding things, so if you want something 
hidden, you need to draw it first.  That's not always easy....

rgl::persp3d maintains a depth buffer so the order in which you draw 
things usually doesn't matter.  (The exception is with semi-transparent 
objects.)

Duncan Murdoch


From dcarlson at tamu.edu  Tue Oct 15 19:44:04 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 15 Oct 2013 12:44:04 -0500
Subject: [R] plot: want only dots
In-Reply-To: <CAM_vju=kG_vAdjQT1=JgdE1QzoU-hjFHarD5XYX3aCktLF73Ww@mail.gmail.com>
References: <CAKyZeBv4FhrDNm9c6GJmvC3bHSCyKjp0x+Js-fPrSwKnKQpV_A@mail.gmail.com>
	<CAM_vju=kG_vAdjQT1=JgdE1QzoU-hjFHarD5XYX3aCktLF73Ww@mail.gmail.com>
Message-ID: <01bc01cec9ce$23e10b00$6ba32100$@tamu.edu>

Are you looking for a stripchart?

stripchart(z~Genotype, mydata, vertical=TRUE, pch=1)

For details ?stripchart

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Sarah Goslee
Sent: Tuesday, October 15, 2013 11:48 AM
To: Hermann Norpois
Cc: r-help
Subject: Re: [R] plot: want only dots

Hi,

Genotype is a factor, and R is giving you the default type for
that data type.

I changed your data frame to mydata because df() is a function,
but see this:

> str(mydata)
'data.frame':    20 obs. of  2 variables:
 $ Genotype: Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 2 2
...
 $ z       : num  0.0703 2.1574 0.514 0.4873 0.1558 ...

It sounds like you might want:

with(mydata, plot(as.numeric(as.character(Genotype)), z))

but if Genotype is best represented as a factor, that may not be
the
most informative type of plot.

Sarah

On Tue, Oct 15, 2013 at 10:23 AM, Hermann Norpois
<hnorpois at gmail.com> wrote:
> Hello,
>
> I would like to plot some values referring to the genotype
(which is 0,1
> and 2).  My data is organised like this:
>
> head (df)
>   Genotype          z
> 1        0 0.07029379
> 2        0 2.15739115
> 3        0 0.51395897
> 4        0 0.48733029
> 5        0 0.15584074
> 6        0 0.27755294
>
> I tried:
>> plot (df)
> And.
>> plot (z ~ Genotype, data=df)
>
> But it is always the same. As demonstrated in the attachment
there are bars
> with mean etc... But I want dots only. How does this work?
>
> Thanks
> Hermann
>
>> dput (df)
> structure(list(Genotype = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L),
.Label = c("0",
> "1", "2"), class = "factor"), z = c(0.0702937908415368,
2.15739115226985,
> 0.513958971085714, 0.487330287677455, 0.155840743875606,
0.277552938739661,
> 0.507384510251828, 9.25159831317385e-05, 0.420814150642641,
> 10.628270981371,
> 0.518650521289299, 0.644448203670876, 0.133539811585953,
0.248985608185673,
> 0.152636019877717, 0.00964805339859479, 7.57036184259711e-05,
> 0.649435257991169, 0.38951827610564, 75.6011068681301)),
.Names =
> c("Genotype",
> "z"), row.names = c(NA, 20L), class = "data.frame")
>>

-- 
Sarah Goslee
http://www.functionaldiversity.org

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From rissa_r at gmx.ch  Tue Oct 15 18:55:38 2013
From: rissa_r at gmx.ch (rissa)
Date: Tue, 15 Oct 2013 09:55:38 -0700 (PDT)
Subject: [R] Problem with lapply
Message-ID: <1381856138636-4678290.post@n4.nabble.com>

Hi together
I'm pretty new to R, so excuse me if it is a basic question.
I have a big dataset (extract of it found in the attachment) of returns from
firms. I'd like to compute the Pearson correlation of each firm with the
"Market" and the corresponding p-Value. So I thought of making a list of
'cor.test's and then extract the needed values with a for loop. What I did
so far...
dataset=Testcor
dataset$DATE<-as.Date(dataset$DATE,"%Y-%m-%d")
firm.names=colnames(dataset)[2:length(colnames(dataset))]
cor.results1=lapply(firm.names,function(x)cor.test(as.formula(paste(firm.names[firm.names==x],Market)),data=dataset,na.action=na.exclude))

But I always get error messages like
Error in paste(firm.names[firm.names == x], Market) : 
  object 'Market' not found

or (when I attach dataset)
Error in parse(text = x) : <text>:1:6: unexpected numeric constant
1: PAXN NA


(Next step would have been something like
for(i in 1:ncol(cor.results1)){
  newmatrix[1,i]= cor.results1 [[i]]$estimate}
etc)
Could you please help me?

Thank you so much!
Rissa


Testcor.txt <http://r.789695.n4.nabble.com/file/n4678290/Testcor.txt>  



--
View this message in context: http://r.789695.n4.nabble.com/Problem-with-lapply-tp4678290.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Tue Oct 15 20:32:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 15 Oct 2013 11:32:48 -0700 (PDT)
Subject: [R] Problem with lapply
In-Reply-To: <1381856138636-4678290.post@n4.nabble.com>
References: <1381856138636-4678290.post@n4.nabble.com>
Message-ID: <1381861968.42451.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi,
Try:
Testcor <- read.table("Testcor.txt",sep="",header=TRUE,stringsAsFactors=FALSE)
Testcor$DATE <- as.Date(Testcor$DATE)
firm.names <- colnames(Testcor)[!grepl("DATE|Market",colnames(Testcor))]
res <- sapply(firm.names, function(x) {cor.results <- cor.test(Testcor[,x],Testcor[,"Market"],na.action=na.exclude); cor.results$estimate})
#? PAXN.cor???? PED.cor??? PEDP.cor????? PM.cor??? PRFN.cor??? PRWN.cor 
#-0.31113122 -0.09359550 -0.17056943? 0.40025112? 0.34385888? 0.17935045 
?# ?? ZG.cor??? ZUBN.cor??? ZURN.cor???? ZWM.cor 
?#0.20762797? 0.39238270? 0.74336028 -0.09166795 


A.K.




On Tuesday, October 15, 2013 1:57 PM, rissa <rissa_r at gmx.ch> wrote:
Hi together
I'm pretty new to R, so excuse me if it is a basic question.
I have a big dataset (extract of it found in the attachment) of returns from
firms. I'd like to compute the Pearson correlation of each firm with the
"Market" and the corresponding p-Value. So I thought of making a list of
'cor.test's and then extract the needed values with a for loop. What I did
so far...
dataset=Testcor
dataset$DATE<-as.Date(dataset$DATE,"%Y-%m-%d")
firm.names=colnames(dataset)[2:length(colnames(dataset))]
cor.results1=lapply(firm.names,function(x)cor.test(as.formula(paste(firm.names[firm.names==x],Market)),data=dataset,na.action=na.exclude))

But I always get error messages like
Error in paste(firm.names[firm.names == x], Market) : 
? object 'Market' not found

or (when I attach dataset)
Error in parse(text = x) : <text>:1:6: unexpected numeric constant
1: PAXN NA


(Next step would have been something like
for(i in 1:ncol(cor.results1)){
? newmatrix[1,i]= cor.results1 [[i]]$estimate}
etc)
Could you please help me?

Thank you so much!
Rissa


Testcor.txt <http://r.789695.n4.nabble.com/file/n4678290/Testcor.txt>? 



--
View this message in context: http://r.789695.n4.nabble.com/Problem-with-lapply-tp4678290.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jeffrey.flint at gmail.com  Tue Oct 15 20:42:57 2013
From: jeffrey.flint at gmail.com (Jeffrey Flint)
Date: Tue, 15 Oct 2013 11:42:57 -0700
Subject: [R] project parallel help
In-Reply-To: <771166ad-7e82-4be2-91be-a9e4c563a53f@email.android.com>
References: <CALbUM4MeRpHMvxUJ7MGvjrLJdtS8bwhfuSxGMLJZKJPqc7VY6Q@mail.gmail.com>
	<217f1ef8-2a1b-4304-a33d-11c64f85f83a@email.android.com>
	<CALbUM4NQuTjBPMSS1zdt9=T_igs39O57d-+RDGbcGtBMDg-zww@mail.gmail.com>
	<771166ad-7e82-4be2-91be-a9e4c563a53f@email.android.com>
Message-ID: <CALbUM4Ox259ncaYEyqOq=MNKF6=ahVtSCxfVBpccJG=8tiu8SQ@mail.gmail.com>

How can I copy distinct blocks of data to each process?

On Mon, Oct 14, 2013 at 10:21 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> The session info is helpful. To the best of my knowledge there is no easy way to share memory between R processes other than forking. You can use clusterExport to make "global" copies of large data structures in each process and pass index values to your function to reduce copy costs at a price of extra data copies in each process that won't be used. Or you can copy distinct blocks of data to each process and use single threaded processing to loop over the blocks within the workers to reduce the number of calls to workers. However I don't claim to be an expert with the parallel package, so others may have better advice.  However, with two cores I don't usually get better than a 30% speedup... the best payoff comes with four or more workers working.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> Jeffrey Flint <jeffrey.flint at gmail.com> wrote:
>>Jeff:
>>
>>Thank you for your response.  Please let me know how I can
>>"unhandicap" my question.  I tried my best to be concise.  Maybe this
>>will help:
>>
>>> version
>>               _
>>platform       i386-w64-mingw32
>>arch           i386
>>os             mingw32
>>system         i386, mingw32
>>status
>>major          3
>>minor          0.2
>>year           2013
>>month          09
>>day            25
>>svn rev        63987
>>language       R
>>version.string R version 3.0.2 (2013-09-25)
>>nickname       Frisbee Sailing
>>
>>
>>I understand your comment about forking.  You are right that forking
>>is not available on windows.
>>
>>What I am curious about is whether or not I can direct the execution
>>of the parallel package's functions to diminish the overhead.  My
>>guess is that there is overhead in copying the function to be executed
>>at each iteration and there is overhead in copying the data to be used
>>at each iteration.  Are there any paradigms in the package parallel to
>>reduce these overheads?  For instance, I could use clusterExport to
>>establish the function to be called.  But I don't know if there is a
>>technique whereby I could point to the data to be used by each CPU so
>>as to prevent a copy.
>>
>>Jeff
>>
>>
>>
>>On Mon, Oct 14, 2013 at 2:35 PM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us> wrote:
>>> Your question misses on several points in the Posting Guide so any
>>answers are handicapped by you.
>>>
>>> There is an overhead in using parallel processing, and the value of
>>two cores is marginal at best. In general parallel by forking is more
>>efficient than parallel by SNOW, but the former is not available on all
>>operating systems. This is discussed in the vignette for the parallel
>>package.
>>>
>>---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>Go...
>>>                                       Live:   OO#.. Dead: OO#..
>>Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>rocks...1k
>>>
>>---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> Jeffrey Flint <jeffrey.flint at gmail.com> wrote:
>>>>I'm running package parallel in R-3.0.2.
>>>>
>>>>Below are the execution times using system.time for when executing
>>>>serially versus in parallel (with 2 cores) using parRapply.
>>>>
>>>>
>>>>Serially:
>>>>   user  system elapsed
>>>>   4.67    0.03    4.71
>>>>
>>>>
>>>>
>>>>Using package parallel:
>>>>   user  system elapsed
>>>>   3.82    0.12    6.50
>>>>
>>>>
>>>>
>>>>There is evident improvement in the user cpu time, but a big jump in
>>>>the elapsed time.
>>>>
>>>>In my code, I am executing a function on a 1000 row matrix 100 times,
>>>>with the data different each time of course.
>>>>
>>>>The initial call to makeCluster cost 1.25 seconds in elapsed time.
>>>>I'm not concerned about the makeCluster time since that is a fixed
>>>>cost.  I am concerned about the additional 1.43 seconds in elapsed
>>>>time (6.50=1.43+1.25).
>>>>
>>>>I am wondering if there is a way to structure the code to avoid
>>>>largely avoid the 1.43 second overhead.  For instance, perhaps I
>>could
>>>>upload the function to both cores manually in order to avoid the
>>>>function being uploaded at each of the 100 iterations?    Also, I am
>>>>wondering if there is a way to avoid any copying that is occurring at
>>>>each of the 100 iterations?
>>>>
>>>>
>>>>Thank you.
>>>>
>>>>Jeff Flint
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>


From zmring at gmail.com  Tue Oct 15 20:59:31 2013
From: zmring at gmail.com (John Smith)
Date: Tue, 15 Oct 2013 14:59:31 -0400
Subject: [R] how to set pch in auto.key for splom
Message-ID: <CAPy-LLZbxKagNsBCH83yHPMpM==25pLpLLf3i3LszdNgFe_NLg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/898b84dd/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Tue Oct 15 21:05:29 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 15 Oct 2013 12:05:29 -0700
Subject: [R] project parallel help
In-Reply-To: <CALbUM4Ox259ncaYEyqOq=MNKF6=ahVtSCxfVBpccJG=8tiu8SQ@mail.gmail.com>
References: <CALbUM4MeRpHMvxUJ7MGvjrLJdtS8bwhfuSxGMLJZKJPqc7VY6Q@mail.gmail.com>
	<217f1ef8-2a1b-4304-a33d-11c64f85f83a@email.android.com>
	<CALbUM4NQuTjBPMSS1zdt9=T_igs39O57d-+RDGbcGtBMDg-zww@mail.gmail.com>
	<771166ad-7e82-4be2-91be-a9e4c563a53f@email.android.com>
	<CALbUM4Ox259ncaYEyqOq=MNKF6=ahVtSCxfVBpccJG=8tiu8SQ@mail.gmail.com>
Message-ID: <50accf43-f7a8-47ed-b403-ae76a1da6a8f@email.android.com>

As parameters. For example, if you have 100 simulations, set up a list of 4 distinct sets of data (1:25, 26:50, etc) and call the single-threaded processing function from parLapply iterated four times. Then each instance of the processing function won't return until it has completed 25 simulations.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Jeffrey Flint <jeffrey.flint at gmail.com> wrote:
>How can I copy distinct blocks of data to each process?
>
>On Mon, Oct 14, 2013 at 10:21 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> The session info is helpful. To the best of my knowledge there is no
>easy way to share memory between R processes other than forking. You
>can use clusterExport to make "global" copies of large data structures
>in each process and pass index values to your function to reduce copy
>costs at a price of extra data copies in each process that won't be
>used. Or you can copy distinct blocks of data to each process and use
>single threaded processing to loop over the blocks within the workers
>to reduce the number of calls to workers. However I don't claim to be
>an expert with the parallel package, so others may have better advice. 
>However, with two cores I don't usually get better than a 30%
>speedup... the best payoff comes with four or more workers working.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> Jeffrey Flint <jeffrey.flint at gmail.com> wrote:
>>>Jeff:
>>>
>>>Thank you for your response.  Please let me know how I can
>>>"unhandicap" my question.  I tried my best to be concise.  Maybe this
>>>will help:
>>>
>>>> version
>>>               _
>>>platform       i386-w64-mingw32
>>>arch           i386
>>>os             mingw32
>>>system         i386, mingw32
>>>status
>>>major          3
>>>minor          0.2
>>>year           2013
>>>month          09
>>>day            25
>>>svn rev        63987
>>>language       R
>>>version.string R version 3.0.2 (2013-09-25)
>>>nickname       Frisbee Sailing
>>>
>>>
>>>I understand your comment about forking.  You are right that forking
>>>is not available on windows.
>>>
>>>What I am curious about is whether or not I can direct the execution
>>>of the parallel package's functions to diminish the overhead.  My
>>>guess is that there is overhead in copying the function to be
>executed
>>>at each iteration and there is overhead in copying the data to be
>used
>>>at each iteration.  Are there any paradigms in the package parallel
>to
>>>reduce these overheads?  For instance, I could use clusterExport to
>>>establish the function to be called.  But I don't know if there is a
>>>technique whereby I could point to the data to be used by each CPU so
>>>as to prevent a copy.
>>>
>>>Jeff
>>>
>>>
>>>
>>>On Mon, Oct 14, 2013 at 2:35 PM, Jeff Newmiller
>>><jdnewmil at dcn.davis.ca.us> wrote:
>>>> Your question misses on several points in the Posting Guide so any
>>>answers are handicapped by you.
>>>>
>>>> There is an overhead in using parallel processing, and the value of
>>>two cores is marginal at best. In general parallel by forking is more
>>>efficient than parallel by SNOW, but the former is not available on
>all
>>>operating systems. This is discussed in the vignette for the parallel
>>>package.
>>>>
>>>---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>>Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live
>>>Go...
>>>>                                       Live:   OO#.. Dead: OO#..
>>>Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>rocks...1k
>>>>
>>>---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> Jeffrey Flint <jeffrey.flint at gmail.com> wrote:
>>>>>I'm running package parallel in R-3.0.2.
>>>>>
>>>>>Below are the execution times using system.time for when executing
>>>>>serially versus in parallel (with 2 cores) using parRapply.
>>>>>
>>>>>
>>>>>Serially:
>>>>>   user  system elapsed
>>>>>   4.67    0.03    4.71
>>>>>
>>>>>
>>>>>
>>>>>Using package parallel:
>>>>>   user  system elapsed
>>>>>   3.82    0.12    6.50
>>>>>
>>>>>
>>>>>
>>>>>There is evident improvement in the user cpu time, but a big jump
>in
>>>>>the elapsed time.
>>>>>
>>>>>In my code, I am executing a function on a 1000 row matrix 100
>times,
>>>>>with the data different each time of course.
>>>>>
>>>>>The initial call to makeCluster cost 1.25 seconds in elapsed time.
>>>>>I'm not concerned about the makeCluster time since that is a fixed
>>>>>cost.  I am concerned about the additional 1.43 seconds in elapsed
>>>>>time (6.50=1.43+1.25).
>>>>>
>>>>>I am wondering if there is a way to structure the code to avoid
>>>>>largely avoid the 1.43 second overhead.  For instance, perhaps I
>>>could
>>>>>upload the function to both cores manually in order to avoid the
>>>>>function being uploaded at each of the 100 iterations?    Also, I
>am
>>>>>wondering if there is a way to avoid any copying that is occurring
>at
>>>>>each of the 100 iterations?
>>>>>
>>>>>
>>>>>Thank you.
>>>>>
>>>>>Jeff Flint
>>>>>
>>>>>______________________________________________
>>>>>R-help at r-project.org mailing list
>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>PLEASE do read the posting guide
>>>>>http://www.R-project.org/posting-guide.html
>>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>
>>


From rissa_r at gmx.ch  Tue Oct 15 21:12:39 2013
From: rissa_r at gmx.ch (rissa)
Date: Tue, 15 Oct 2013 12:12:39 -0700 (PDT)
Subject: [R] Problem with lapply
In-Reply-To: <1381861968.42451.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1381856138636-4678290.post@n4.nabble.com>
	<1381861968.42451.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1381864359746-4678305.post@n4.nabble.com>

Thank you! Worked perfectly!

By the way: What was wrong with my original code?



--
View this message in context: http://r.789695.n4.nabble.com/Problem-with-lapply-tp4678290p4678305.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Tue Oct 15 21:24:21 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 15 Oct 2013 12:24:21 -0700 (PDT)
Subject: [R] how to set pch in auto.key for splom
In-Reply-To: <CAPy-LLZbxKagNsBCH83yHPMpM==25pLpLLf3i3LszdNgFe_NLg@mail.gmail.com>
References: <CAPy-LLZbxKagNsBCH83yHPMpM==25pLpLLf3i3LszdNgFe_NLg@mail.gmail.com>
Message-ID: <1381865061.46825.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,
May be this helps:
library(lattice)
splom(~iris[1:4], groups = iris$Species,pch=1:3, par.settings=list(superpose.symbol=list(pch=1:3)),auto.key = list(space = 'top',columns=3))

A.K.



On Tuesday, October 15, 2013 3:01 PM, John Smith <zmring at gmail.com> wrote:
Dear All,

I am using most current version of R (3.0.2) and lattice (0.20-24). But can
not set appropriate pch type with the following code. Could anyone help me?



splom(~iris[1:4], groups = iris$Species, pch=1:3, auto.key = list(space =
'top', columns = 3, pch=1:3))


Thanks

John

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From murdoch.duncan at gmail.com  Tue Oct 15 22:11:17 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 15 Oct 2013 16:11:17 -0400
Subject: [R] bug(?) in str() with strict.width = "cut" when applied to
 dataframe with numeric component AND factor or character component with
 longerlevels/strings
In-Reply-To: <Pine.SOC.4.64.1310151248250.10890@solcom.hrz.uni-giessen.de>
References: <Pine.SOC.4.64.1310151248250.10890@solcom.hrz.uni-giessen.de>
Message-ID: <525DA165.6050004@gmail.com>

On 15/10/2013 7:53 AM, Gerrit Eichner wrote:
> Dear list subscribers,
>
> here is a small artificial example to demonstrate the problem that I
> encountered when looking at the structure of a (larger) data frame that
> comprised (among other components)
>
> a numeric component of elements of the order of > 10000, and
>
> a factor or character component with longer levels/strings:
>
>
> k <- 43      # length of levels or character strings
> n <- 11      # number of rows of data frame
> M <- 10000   # order of magnitude of numerical values
>
> set.seed( 47) # to reproduce the following artificial character string
> longer.char.string <- paste( sample( letters, k, replace = TRUE),
>                                collapse = "")
>
> X <- data.frame( A = 1:n * M,
>                    B = rep( longer.char.string, n))
>
>
> The following call to str() gives apparently a wrong result
>
> str( X, strict.width = "cut")
>
> 'data.frame':   11 obs. of  2 variables:
>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>
>
> whereas the correct result appears for str( X) or if you decrease k to 42
> (isn't that "the answer"? ;-) ) or n to 10 or M to 1000 (or smaller,
> respectively).
>
>
> I tried to dig into the entrails of str.default(), where the cause may
> lie, but got lost pretty soon. So, I am hoping that someone may already
> have a work-around or patch (or dares to dig further)? Thank you for any
> feedback!

I can't reproduce this.  I don't have a 64 bit copy of 3.0.2 handy, but 
I don't see it in 64 bit 3.0.1, or 64 bit 3.0.2-patched, or various 32 
bit versions.

Is it reproducible for you?  It looks to me as though (if it isn't just 
something weird on your system, e.g. an old copy of str() in your 
workspace), it might be a memory protection problem:  something needed 
to be duplicated but wasn't.  But unless I can see it happen, I can't 
start to fix it.

Duncan Murdoch

>
>    Best regards  --  Gerrit
>
> PS:
>
> > sessionInfo()
>
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] splines   stats     graphics  grDevices utils     datasets
> [7] methods   base
>
> other attached packages:
> [1] nparcomp_2.0     multcomp_1.2-21  mvtnorm_0.9-9996
> [4] car_2.0-19       Hmisc_3.12-2     Formula_1.1-1
> [7] survival_2.37-4  fortunes_1.5-0
>
> loaded via a namespace (and not attached):
> [1] cluster_1.14.4  grid_3.0.2      lattice_0.20-23 MASS_7.3-29
> [5] nnet_7.3-7      rpart_4.1-3     stats4_3.0.2    tools_3.0.2
>
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
> Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Tue Oct 15 21:56:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 15 Oct 2013 12:56:35 -0700 (PDT)
Subject: [R] Problem with lapply
In-Reply-To: <1381864359746-4678305.post@n4.nabble.com>
References: <1381856138636-4678290.post@n4.nabble.com>	<1381861968.42451.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1381864359746-4678305.post@n4.nabble.com> 
Message-ID: <1381866995.73030.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,

No problem.
Regarding your code:

#changed name from 'dataset' to "Testcor"
#Your code

? firm.names=colnames(Testcor)[2:length(colnames(Testcor))]
?firm.names
# [1] "PAXN"?? "PED"??? "PEDP"?? "PM"???? "PRFN"?? "PRWN"?? "ZG"???? "ZUBN"? 
?#[9] "ZURN"?? "ZWM"??? "Market" #####includes "Market"

#If you look my code:
firm.names <- colnames(Testcor)[!grepl("DATE|Market",colnames(Testcor))]
?firm.names
# [1] "PAXN" "PED"? "PEDP" "PM"?? "PRFN" "PRWN" "ZG"?? "ZUBN" "ZURN" "ZWM" 

If you wanted to use the "formula" method:
res1 <- sapply(firm.names,function(x) { cor.results <- cor.test(as.formula(paste("~", paste(x,"Market", sep="+")) ),data=Testcor,na.action=na.exclude); cor.results$estimate})
res1
#?? PAXN.cor???? PED.cor??? PEDP.cor????? PM.cor??? PRFN.cor??? PRWN.cor 
#-0.31113122 -0.09359550 -0.17056943? 0.40025112? 0.34385888? 0.17935045 
?# ?? ZG.cor??? ZUBN.cor??? ZURN.cor???? ZWM.cor 
?#0.20762797? 0.39238270? 0.74336028 -0.09166795?
?identical(res,res1)
#[1] TRUE

#or just
res2 <- sapply(firm.names,function(x) { cor.test(~get(x) + Market,data=Testcor,na.action=na.exclude)$estimate })
?identical(res,res2)
#[1] TRUE



A.K.






On Tuesday, October 15, 2013 3:15 PM, rissa <rissa_r at gmx.ch> wrote:
Thank you! Worked perfectly!

By the way: What was wrong with my original code?



--
View this message in context: http://r.789695.n4.nabble.com/Problem-with-lapply-tp4678290p4678305.html

Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From zeleehom at gmail.com  Tue Oct 15 23:03:02 2013
From: zeleehom at gmail.com (Weijia Wang)
Date: Tue, 15 Oct 2013 17:03:02 -0400
Subject: [R] Assign date according to defined time interval
Message-ID: <CAHX9w5hQPT1sUPHHmBdAhwmjXpBFxBmE1KN1VVy+sNJEPC53Fg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/0a7f97e8/attachment.pl>

From smartpink111 at yahoo.com  Wed Oct 16 00:30:12 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 15 Oct 2013 15:30:12 -0700 (PDT)
Subject: [R] Math notation in a title
Message-ID: <1381876212.6819.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:
plot(1,main=bquote("Pareto Distribution: " ~ alpha == 2 * "," ~italic(y[m]) == 3))


A.K.


Hi, 

I'd like to put the following in a main title of a plot. 



Can someone show me how to do this? 

Thanks. 

D.


From peter.br.lomas at gmail.com  Wed Oct 16 00:49:48 2013
From: peter.br.lomas at gmail.com (Peter Lomas)
Date: Tue, 15 Oct 2013 16:49:48 -0600
Subject: [R] Math notation in a title
In-Reply-To: <1381876212.6819.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1381876212.6819.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <CAOHXzyVU5Yxi8ay_xnYd-esbEox2zq3Ex+-HyMd-J-ONS31L1w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/c8fbd9e6/attachment.pl>

From stockbeaver at ymail.com  Wed Oct 16 01:11:32 2013
From: stockbeaver at ymail.com (Stock Beaver)
Date: Tue, 15 Oct 2013 16:11:32 -0700 (PDT)
Subject: [R] A 'good' way to build a matrix from a sequence of integers?
Message-ID: <1381878692.84411.YahooMailNeo@web140004.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/11634aa8/attachment.pl>

From kevin.thorpe at utoronto.ca  Wed Oct 16 01:18:55 2013
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 15 Oct 2013 19:18:55 -0400
Subject: [R] A 'good' way to build a matrix from a sequence of integers?
In-Reply-To: <1381878692.84411.YahooMailNeo@web140004.mail.bf1.yahoo.com>
References: <1381878692.84411.YahooMailNeo@web140004.mail.bf1.yahoo.com>
Message-ID: <525DCD5F.5000304@utoronto.ca>

On 10/15/2013 07:11 PM, Stock Beaver wrote:
> # I understand that a good way to build a vector from a sequence of integers,
> # is to use syntax like this:
> myvec = c(1:99)

First, the c() is not needed here.

myvec <- 1:99

works just fine.

>
> # Here is the 'short' version of my question:
> # I want to understand a 'good' way to build a matrix from a sequence of integers.
>
> # If that question is not clear, here is a longer version:
>
> # Here is what I did for a 1D-matrix:
>
> # I pick the sequence 1:3
> # I build a vector:
> vec1x3 = c(1:3)
> vec1x3
> # I transform it into a 1 x 3 matrix:
> m1x3 = matrix(vec1x3, c(length(vec1x3),1))
> m1x3
> #      [,1]
> # [1,]    1
> # [2,]    2
> # [3,]    3
> # >
>
> # That was easy.
>
> # Next I want to expand from a 1 x 3 matrix to a 2 x 9 matrix
> # which contains all combinations of 1:3

I think you want expand.grid.

expand.grid(x1=1:3, x2=1:3)

>
> # So the first 4 rows would look like this:
> # 1 1
> # 1 2
> # 1 3 I call this a rowvec
> # 2 1
>
> # My first idea is write a loop like this:
>
> for (i in 1:3) {
>    for(j in 1:3) {
>      rowvec = c(i,j)
>      # Place rowvec in matrix
>    }
> }
>
> # I'm curious if a skilled R-person would do it differently?
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From smartpink111 at yahoo.com  Wed Oct 16 01:26:40 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 15 Oct 2013 16:26:40 -0700 (PDT)
Subject: [R] A 'good' way to build a matrix from a sequence of integers?
In-Reply-To: <1381878692.84411.YahooMailNeo@web140004.mail.bf1.yahoo.com>
References: <1381878692.84411.YahooMailNeo@web140004.mail.bf1.yahoo.com>
Message-ID: <1381879600.99263.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi,

You could use:
?as.matrix(expand.grid(vec1x3,vec1x3))
#or
as.matrix(expand.grid(rep(list(vec1x3),2)))
#or
library(gtools)
permutations(3, 2, vec1x3, repeats.allowed=TRUE)

A.K.



On Tuesday, October 15, 2013 7:14 PM, Stock Beaver <stockbeaver at ymail.com> wrote:
# I understand that a good way to build a vector from a sequence of integers,
# is to use syntax like this:
myvec = c(1:99)

# Here is the 'short' version of my question:
# I want to understand a 'good' way to build a matrix from a sequence of integers.

# If that question is not clear, here is a longer version:

# Here is what I did for a 1D-matrix:

# I pick the sequence 1:3
# I build a vector:
vec1x3 = c(1:3)
vec1x3
# I transform it into a 1 x 3 matrix:
m1x3 = matrix(vec1x3, c(length(vec1x3),1))
m1x3
#????? [,1]
# [1,]??? 1
# [2,]??? 2
# [3,]??? 3
# > 

# That was easy.

# Next I want to expand from a 1 x 3 matrix to a 2 x 9 matrix
# which contains all combinations of 1:3

# So the first 4 rows would look like this:
# 1 1
# 1 2
# 1 3 I call this a rowvec
# 2 1

# My first idea is write a loop like this:

for (i in 1:3) {
? for(j in 1:3) {
??? rowvec = c(i,j)
??? # Place rowvec in matrix
? }
}

# I'm curious if a skilled R-person would do it differently?
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Wed Oct 16 02:00:01 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 15 Oct 2013 17:00:01 -0700 (PDT)
Subject: [R] Assign date according to defined time interval
In-Reply-To: <CAHX9w5hQPT1sUPHHmBdAhwmjXpBFxBmE1KN1VVy+sNJEPC53Fg@mail.gmail.com>
References: <CAHX9w5hQPT1sUPHHmBdAhwmjXpBFxBmE1KN1VVy+sNJEPC53Fg@mail.gmail.com>
Message-ID: <1381881601.2929.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

Please use ?dput() to show the dataset.? Also, it is not clear about how you store the time interval.
dat <- read.table(text="
GroupID??????? Date
1????? 1????? 10-Dec-12
2????? 1????? 11-Dec-12
3????? 2????? 13-Dec-12
4????? 2????? 15-Dec-12
5????? 3????? 06-Dec-12
6????? 3????? 19-Dec-12",sep="",header=TRUE,stringsAsFactors=FALSE)



?dat2 <- data.frame(Week=1:2, from= c("9-Dec-12", "16-Dec-12"), to=c("15-Dec-12","22-Dec-12"),stringsAsFactors=FALSE)

#Check ?findInterval()

res <- t(sapply(split(dat,dat$GroupID), function(x) {
??? ??? ??? ??? ??? ??? ??? x$Date <-as.Date(x$Date,"%d-%b-%y")
??? ??? ??? ??? ??? ??? ??? ?unsplit(lapply(split(dat2,dat2$Week),function(y) {
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? y$from <- as.Date(y$from, "%d-%b-%y")
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ?y$to <- as.Date(y$to, "%d-%b-%y")
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ?sum(x$Date > y$from & x$Date <= y$to)}),
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? dat2$Week)
??? ??? ??? ??? ??? ??? ? }))

colnames(res) <- paste0("Week",1:2)
?res
#? Week1 Week2
#1???? 2???? 0
#2???? 2???? 0
#3???? 0???? 1


A.K.










On Tuesday, October 15, 2013 6:24 PM, Weijia Wang <zeleehom at gmail.com> wrote:
Hi, I have something very interesting:

Say I have this:

GroupID? ? ? ?  Date
1? ? ? 1? ? ?  10-Dec-12
2? ? ? 1? ? ?  11-Dec-12
3? ? ? 2? ? ?  13-Dec-12
4? ? ? 2? ? ?  15-Dec-12
5? ? ? 3? ? ?  06-Dec-12
6? ? ? 3? ? ?  19-Dec-12

Now, I have time interval,

week 1: from 9-Dec-12 to 15-Dec-12,

week 2: from 16-Dec-12 to 22-Dec-12, and so on.

Obviously, the 1st, 2nd, 3rd, 4th row falls to week 1, 5th rows should not
be counted, 6th row falls into week2.

Therefore, by GroupID, I will have

GroupID=1, Week1=2, Week2=0
GroupID=2, Week1=2, Week2=0
GroupID=3, Week1=0, Week2=1.

I just want to count the valid date that falls into a 7-day week interval,
and I shall have new variables for EACH WEEK, and the counts for dates that
fall into this week interval.

Can anyone please help me on programming this?

W

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From davidmarino838 at gmail.com  Wed Oct 16 02:37:42 2013
From: davidmarino838 at gmail.com (Marino David)
Date: Wed, 16 Oct 2013 08:37:42 +0800
Subject: [R] Gaussian Quadrature for arbitrary PDF
In-Reply-To: <525B8DE1.1080100@structuremonitoring.com>
References: <CABmD0bFpFHUCqsr-Sg2jhtNULCGQa3n_86a4HwA+WB0yBBvRZA@mail.gmail.com>
	<525B8DE1.1080100@structuremonitoring.com>
Message-ID: <CABmD0bEeygBwMEPOvX+FbJqjV6SnQ2E414cnRg1mMjr0KFNa1Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/98117612/attachment.pl>

From spencer.graves at structuremonitoring.com  Wed Oct 16 03:12:01 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Tue, 15 Oct 2013 18:12:01 -0700
Subject: [R] Gaussian Quadrature for arbitrary PDF
In-Reply-To: <CABmD0bEeygBwMEPOvX+FbJqjV6SnQ2E414cnRg1mMjr0KFNa1Q@mail.gmail.com>
References: <CABmD0bFpFHUCqsr-Sg2jhtNULCGQa3n_86a4HwA+WB0yBBvRZA@mail.gmail.com>
	<525B8DE1.1080100@structuremonitoring.com>
	<CABmD0bEeygBwMEPOvX+FbJqjV6SnQ2E414cnRg1mMjr0KFNa1Q@mail.gmail.com>
Message-ID: <525DE7E1.6030902@structuremonitoring.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/f68bce7b/attachment.pl>

From dwarnold45 at suddenlink.net  Tue Oct 15 19:52:40 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Tue, 15 Oct 2013 10:52:40 -0700 (PDT)
Subject: [R] Math notation in a title
Message-ID: <1381859560550-4678299.post@n4.nabble.com>

Hi,

I'd like to put the following in a main title of a plot.

<http://r.789695.n4.nabble.com/file/n4678299/junk.png> 

Can someone show me how to do this?

Thanks.

D.



--
View this message in context: http://r.789695.n4.nabble.com/Math-notation-in-a-title-tp4678299.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Wed Oct 16 05:48:04 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 15 Oct 2013 20:48:04 -0700 (PDT)
Subject: [R] some addition in the codes
In-Reply-To: <BLU170-W1267264B3E59C40C435A7D7891B0@phx.gbl>
References: <BLU170-W1267264B3E59C40C435A7D7891B0@phx.gbl>
Message-ID: <1381895284.74848.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi Eliza,

Some lines of code in the end didn't look very convincing for me.? (I didn't change it anyway). For example:
#####
?amata<-data.frame(amata)
aavg<-as.matrix(amata, ncol=1)
b<-aavg
sss<-(max(b)+max(amata))/2
####


Also, multiple objects of the same name were created through out the code, which makes it bit hard.


##solution

? Eliz <- load("/home/arunksa111/Downloads/Elizaaa.RData" )

Dm <- `Dm`
ffr <- `ffr`
?j <- `j`
?m <- `m`

d15<-Dm/mean(Dm) 
dr1<-ffr/mean(ffr) 
t<-as.matrix((d15)+(dr1))
w<-sqrt(t)
mat1<-w
zz<-w? ## multiple objects!!
rlst<- lapply(1:124,function(i) matrix(sort(as.matrix(zz)[i,],index.return=TRUE)$ix,ncol=1))


rlstN <- lapply(rlst,function(x) {
??? ??? ??? ??????? u<- x[2:8,1]
??? ??? ??? ??? mata <- m[,u]
??? ??? ??? ??? ?a <- matrix(rowMeans(mata),ncol=1)
??? ??? ??? ??? ?mat <- cbind(j,a)
??? ??? ??? ??? lst1<-lapply(split(mat,col(mat)),function(x){
??? ??? ??? ??? ??? ??? ??? big<- x>0.8*max(x)
??? ??? ??? ??? ??? ??? ??? ?n<- length(big)
??? ??? ??? ??? ??? ??? ??? startRunOfBigs<- which(c(big[1],!big[-n] & big[-1]))
??? ??? ??? ??? ??? ??? ??? endRunOfBigs<- which(c(big[-n] & !big[-1], big[n]))
??? ??? ??? ??? ??? index<- vapply(seq_along(startRunOfBigs),function(i) which.max(x[startRunOfBigs[i]:endRunOfBigs[i]])+startRunOfBigs[i]-1L,0L) ??? ??? ??? ??? ??? ??? index<-ifelse(sum(is.na(match(index,c(1,12))))==0 & x[index]!=max(x[index]), NA,index)
??? ??? ??? ??? ??? data.frame(Index=index[!is.na(index)],Value=x[index[!is.na(index)]])? 
??? ??? ??? ??? ??? })
??? ???????? ??? nm <- lapply(lst1,function(x) x$Index)
??? ??? ??? max_length<- max(unlist(lapply(nm,length)))
??? ??? ?????? nm_filled<-lapply(nm,function(x){
??? ??? ??? ??? ??? ans<- rep(NA,length=max_length)
???? ??? ??? ??? ??? ans[1:length(x)]<- x
??? ??? ??? ??? ??? return(ans)
??? ??? ??? ??? ??? })
??? ??? ??? xx<-do.call(cbind,nm_filled)? ##didn't see this part being used in the end
??? ??? ??? ?mat})


###Using a subset of list elements

srlstN <- rlstN[61:62]
library(hydroGOF)

res <-? lapply(srlstN, function(x) {
??? ??? ??? ??? ??? i<- as.list(fun3(x))
????????????????? xx<- do.call(cbind,i)
???????????????? xx<- t(xx)
???????????????? x1 <- matrix(xx,nrow=1)
???????????????? y <- matrix(0,nrow=125,ncol=125)
???????????????? y[lower.tri(y)]<- x1
???????????????? yy <- as.dist(y)
???????????????? list1<- lapply(seq_len(ncol(x)),function(j) t(apply(x,1,function(u) u[j]-u)))
???????????????? x2<- matrix(unlist(list1),ncol=15625)
???????????????? x2<- abs(x2)
???????????????? y1 <- colSums(x2,na.rm=FALSE)
??? ??? ??? ??? z1 <- matrix(y1,ncol=125)
???????????????? zz <- as.dist(z1)
??? ??? ??? ??? x3 <- apply(x,2,max)
???????????????? xx1 <- dist(x3) 

???????????????? xx1[yy==0] <-0
???????????????? ff <- zz+yy+xx1
???????????????? r <- matrix(sort(as.matrix(ff)[125,],index.return=TRUE)$ix,ncol=1)
??? ??? ??? ??? u1 <- r[2:8,1]
???????????????? mata <- x[,u1]
???????????????? amata <- data.frame(rowMeans(mata))
???????????????? aavg <- as.matrix(amata, ncol=1)
???????????????? sss <- (max(aavg)+max(amata))/2
????????????????? aavg[which(aavg==max(aavg))] <- sss
???????????????? mat2<- do.call(rbind,lapply(seq_len(ncol(x)), function(j){
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? RRR <- rmse(aavg,matrix(x[,j],ncol=1))
??????????????????????????????????????????????????????????????????????????? UUU <- NSE(aavg,matrix(x[,j],ncol=1))
???????????????????????????????????????????????????????????????????????????? cc <- sum(abs(aavg - x[,j]))
???????????????????????????????????????????????????????????????????????????? c(RRR,UUU,cc) 

??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? }))
???????????????? colnames(mat2) <- c("RRR","UUU","cc")
???????????????? mat2 

???????????? })
?head(res[[1]])
#?????????? RRR??????? UUU??????? cc
#[1,] 0.3830867? 0.5155312? 3.617801
#[2,] 0.5149736 -0.6779912? 4.194520
#[3,] 1.4246430 -1.3620793 15.116817
#[4,] 1.0875600 -1.4012783 11.170334
#[5,] 1.3309777 -0.8873588 14.078342
#[6,] 0.2056404? 0.9170877? 1.959848


A.K.









On Tuesday, October 15, 2013 12:08 PM, eliza botto <eliza_botto at hotmail.com> wrote:


Dear Arun,
You once helped prepared me following codes for my work. Now i automatically want to replace "61" in all the four steps indicated with ">>>>>" in the beginning, with 1,2,3,4........, 124 so that i have three lists in the end each for ?RRR, UU and cc.
Can it be done? I hope i am clear in my question.
Thanks in advance


Eliza

## d15 and dr1 are ?distance matrices of 8*8 dimensions


d15<-Dm/mean(Dm)?
dr1<-ffr/mean(ffr)?
t<-as.matrix((d15)+(dr1))
w<-sqrt(t)
mat1<-w
zz<-w
>>>>>r<-matrix(sort(as.matrix(zz)[61,],index.return=TRUE)$ix,ncol=1)
u<-r[c(2,3,4,5,6,7,8),1]
mata<-m[,c(u)]##(shifted)
amata<-apply(mata,1,mean)
amata<-data.frame(amata)
aavg<-as.matrix(amata, ncol=1)
a<-aavg

## j is matrix of 8 rows and 2 columns
m<-cbind(j,a)
mat<-m
?lst1<-lapply(split(mat,col(mat)),function(x){big<- x>0.8*max(x); n<- length(big);startRunOfBigs<- which(c(big[1],!big[-n] & big[-1])); endRunOfBigs<- which(c(big[-n] & !big[-1], big[n]));index<- vapply(seq_along(startRunOfBigs),function(i) which.max(x[startRunOfBigs[i]:endRunOfBigs[i]])+startRunOfBigs[i]-1L,0L); index<-ifelse(sum(is.na(match(index,c(1,12))))==0 & x[index]!=max(x[index]), NA,index);data.frame(Index=index[!is.na(index)],Value=x[index[!is.na(index)]]) ?})
?nm<-lapply(lst1,function(x)(x$Index))

max_length<- max(unlist(lapply(nm,length)))
nm_filled<-lapply(nm,function(x){ans<- rep(NA,length=max_length);
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ans[1:length(x)]<- x;
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? return(ans)})
xx<-do.call(cbind,nm_filled)

fun1<- function(x){
? ? big<- x>0.8*max(x)?
? ? n<- length(big)
? ? startRunOfBigs<- which(c(big[1],!big[-n] & big[-1]))
? ? endRunOfBigs<- which(c(big[-n] & !big[-1], big[n]))
? ? index<- vapply(seq_along(startRunOfBigs),function(i) which.max(x[startRunOfBigs[i]:endRunOfBigs[i]])+startRunOfBigs[i]-1L,0L)
? ? ?index<-ifelse(sum(is.na(match(index,c(1,12))))==0 & x[index]!=max(x[index]), NA,index)
? ? data.frame(Index=index[!is.na(index)],Value=x[index[!is.na(index)]])
? ? ?}

fun3<- function(mat){
? ? ? ? indmat<-combn(seq_len(ncol(mat)),2)
? ? lst1<- lapply(seq_len(ncol(indmat)),function(i) {mat[,indmat[,i]]}) ??
? ? names(lst1)<-as.character(interaction(as.data.frame(t(indmat)),sep="_",drop=TRUE)) ? ? ??
? ? lst2<- lapply(lst1,function(x) {x1<- apply(x,2,fun1)})

? ? lst3<- lapply(lst2,function(x) expand.grid(lapply(x,function(y) y[,1])))
? ? lst4<-lapply(lst3,function(x) unlist(x[which.min(apply(x,1,function(y) abs(diff(y)))),]) )
? ? lst5<- lapply(lst4,function(x){
? ? ? ? ? ? ? ? if(abs(diff(x))>(nrow(mat)/2)){
? ? ? ? ? ? ? ? nrow(mat)-abs(diff(x))
? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? ? ? ? ? else(abs(diff(x)))
? ? ? ? ? ? ? ? ? ? })

? ? lst6<- lapply(seq_along(lst5),function(i) {
? ? ? ? ? ? ? ? x2<-lst1[[i]]
? ? ? ? ? ? ? ? if(lst5[[i]]==0) {
? ? ? ? ? ? ? ? ? ? #indx1<- seq(length(x2[,2]))
? ? ? ? ? ? ? ? ? ? #sum(abs(x2[,1]-x2[indx1,2]))
? ? ? ? ? ? ?0 ? ? ######################## set to zero ? ? ? ? ? ? ? ? ? ??
? ? ? ? ? ? }
? ? ? ? ? ? ? ? else{
? ? ? ? ? ? ? ? ? ? lapply(seq(1+lst5[[i]]),function(j){x3<-x2[,2]
? ? ? ? ? ? ? ? ? ? ? ? ? ? indx1<-seq(length(x3)-(j-1))
? ? ? ? ? ? ? ? ? ? ? ? ? ? indx2<-c(setdiff(seq_along(x3),indx1),indx1)
? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(abs(x2[,1]-x2[indx2,2]))
? ? ? ? ? ? ? ? ? ? ? ? ? ? })
? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? }) ??

? ? names(lst6)<- names(lst1)
? ? lst7<-lapply(lst6,unlist)
? ? lst8<- lapply(lst7,function(x) {
? ? ? ? ? ? Seq1<-seq_along(x)
? ? ? ? ? ? if(length(Seq1)==1) x
? ? ? ? ? ? else if(length(Seq1)==2){
? ? ? ? ? ? ? ? ? ? ? ? sum(abs(x[1]-x[2])) ??
? ? ? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? else{
? ? ? ? ? ? ? ? ind<-rep(Seq1,each=2)[-1]
? ? ? ? ? ? ? ? ind1<-ind[-length(ind)]
? ? ? ? ? ? ? ? Reduce(`+`,lapply(split(ind1,(seq_along(ind1)-1)%/%2+1),function(i) {
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? abs(diff(x[i]))
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? })) ? ? ? ? ? ? ? ? ? ? ? ? ??
? ? ? ? ? ? ? ? }

? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? )
? ? lst9<-do.call(rbind,lst8)
? ? lst9 ? ? ??
? ? }

?fun3(m)



########

i<-as.list(fun3(m))
xx<-do.call(cbind, i)
xx<-t(xx)
x<-matrix(xx,nrow=1)
?y <- matrix(0, nrow=125, ncol=125)?
y[lower.tri(y)] <- x?
yy<-as.dist(y)

##===============
list1<-list()
for(i in 1:ncol(m)){
?list1[[i]]<-t(apply(m,1,function(x) x[i]-x))
?list1}
x<-list1
x<-matrix(unlist(x),ncol=15625)
x<-abs(x)
y<-colSums(x, na.rm=FALSE)
z<-matrix(y, ncol=125)
zz<-as.dist(z)
x<-apply(m, 2, max)
xx<-dist(x)
xx<-as.dist(xx)
xx[yy==0]<-0
ff<-((zz))+((yy))+((xx))
r<-matrix(sort(as.matrix(ff)[125,],index.return=TRUE)$ix,ncol=1)
u<-r[c(2,3,4,5,6,7,8),1]
mata<-m[,c(u)]##(shifted)
amata<-apply(mata,1,mean)
amata<-data.frame(amata)
aavg<-as.matrix(amata, ncol=1)
b<-aavg
sss<-(max(b)+max(amata))/2
b[which(b == max(b))]<-sss
library(hydroGOF)
>>>>>RRR<-rmse(b,matrix(m[,61],ncol=1))
>>>>>UUU<-NSE(b,matrix(m[,61],ncol=1))
>>>>>cc<-sum(abs(b-m[,61]))


From yuhanusa at gmail.com  Wed Oct 16 02:58:47 2013
From: yuhanusa at gmail.com (Y)
Date: Tue, 15 Oct 2013 20:58:47 -0400
Subject: [R] How to obtain restricted estimates from coxph()?
Message-ID: <CAHJ49wjvYnMqLF2gdhrVbyByOtDX-jEU0uSE=taXrwUGKfhWjA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131015/afa4fd2e/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Wed Oct 16 10:07:03 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 16 Oct 2013 10:07:03 +0200 (MEST)
Subject: [R] bug(?) in str() with strict.width = "cut" when
	appliedtodataframe with numeric component AND factor or
	character component withlongerlevels/strings
In-Reply-To: <525DA165.6050004@gmail.com>
References: <Pine.SOC.4.64.1310151248250.10890@solcom.hrz.uni-giessen.de>
	<525DA165.6050004@gmail.com>
Message-ID: <Pine.SOC.4.64.1310160952360.24848@solcom.hrz.uni-giessen.de>

Thanks, Duncan,

for the good (indirect) hint: after a restart of R the problem is -- 
fortunately :-) -- not reproducible anymore for me either. The R session 
had been running for a longer time and I recall doing some 
(system-related) things outside of R that may have interfered with it; I 
just forgot to take that possibility into consideration. :(

  Regards  --  Gerrit

On Tue, 15 Oct 2013, Duncan Murdoch wrote:

> On 15/10/2013 7:53 AM, Gerrit Eichner wrote:
>> Dear list subscribers,
>> 
>> here is a small artificial example to demonstrate the problem that I
>> encountered when looking at the structure of a (larger) data frame that
>> comprised (among other components)
>> 
>> a numeric component of elements of the order of > 10000, and
>> 
>> a factor or character component with longer levels/strings:
>> 
>> 
>> k <- 43      # length of levels or character strings
>> n <- 11      # number of rows of data frame
>> M <- 10000   # order of magnitude of numerical values
>> 
>> set.seed( 47) # to reproduce the following artificial character string
>> longer.char.string <- paste( sample( letters, k, replace = TRUE),
>>                                collapse = "")
>> 
>> X <- data.frame( A = 1:n * M,
>>                    B = rep( longer.char.string, n))
>> 
>> 
>> The following call to str() gives apparently a wrong result
>> 
>> str( X, strict.width = "cut")
>> 
>> 'data.frame':   11 obs. of  2 variables:
>>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>> 
>> 
>> whereas the correct result appears for str( X) or if you decrease k to 42
>> (isn't that "the answer"? ;-) ) or n to 10 or M to 1000 (or smaller,
>> respectively).
>> 
>> 
>> I tried to dig into the entrails of str.default(), where the cause may
>> lie, but got lost pretty soon. So, I am hoping that someone may already
>> have a work-around or patch (or dares to dig further)? Thank you for any
>> feedback!
>
> I can't reproduce this.  I don't have a 64 bit copy of 3.0.2 handy, but I 
> don't see it in 64 bit 3.0.1, or 64 bit 3.0.2-patched, or various 32 bit 
> versions.
>
> Is it reproducible for you?  It looks to me as though (if it isn't just 
> something weird on your system, e.g. an old copy of str() in your workspace), 
> it might be a memory protection problem:  something needed to be duplicated 
> but wasn't.  But unless I can see it happen, I can't start to fix it.
>
> Duncan Murdoch
>
>>
>>    Best regards  --  Gerrit
>> 
>> PS:
>> 
>> > sessionInfo()
>> 
>> R version 3.0.2 (2013-09-25)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> 
>> locale:
>> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
>> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
>> [5] LC_TIME=German_Germany.1252
>> 
>> attached base packages:
>> [1] splines   stats     graphics  grDevices utils     datasets
>> [7] methods   base
>> 
>> other attached packages:
>> [1] nparcomp_2.0     multcomp_1.2-21  mvtnorm_0.9-9996
>> [4] car_2.0-19       Hmisc_3.12-2     Formula_1.1-1
>> [7] survival_2.37-4  fortunes_1.5-0
>> 
>> loaded via a namespace (and not attached):
>> [1] cluster_1.14.4  grid_3.0.2      lattice_0.20-23 MASS_7.3-29
>> [5] nnet_7.3-7      rpart_4.1-3     stats4_3.0.2    tools_3.0.2
>> 
>> ---------------------------------------------------------------------
>> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
>> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
>> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
>> Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From PabloEmilio.Verde at uni-duesseldorf.de  Wed Oct 16 10:13:37 2013
From: PabloEmilio.Verde at uni-duesseldorf.de (Dr. Pablo E. Verde)
Date: Wed, 16 Oct 2013 10:13:37 +0200
Subject: [R] course: Bayesian Data Analysis with R and WinBUGS
Message-ID: <525E4AB1.90709@uni-duesseldorf.de>

Dear list members,

Best greetings and apologies for cross-posting. There are available 
places for the course:
"Bayesian Data Analysis with R and WinBUGS", please find the description
of the course below.

If you have any question don't hesitate to contact me.

Best regards,

Pablo

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
*Three days course in: Bayesian Data Analysis with R and WinBUGS
*Where: Linux Hotel, Essen-Horst, Germany
*When: 07.11-09.11.2013
*Instructor: Dr. Pablo E. Verde
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
*Target audience:
This course is for data analyst who are familiar with classical statistics
and they want to get a working knowledge in Bayesian analysis. This is a 
3 days
intensive training course with 8 hours per day including lecturing and 
exercises.
The course presentation is practical with many worked examples. Lectures 
are
given in English. Discussions can be in English, German or Spanish.
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
*Course content:
Day 1
*Lecture 1: Introduction to Bayesian Inference
*Lecture 2: Bayesian analysis for single parameter models
*Lecture 3: Prior distributions: univariate

Day 2
*Lecture 4: Bayesian analysis for multiple parameter models
*Lecture 5: An introduction to WinBUGS
*Lecture 6: Multivariate models with WinBUGS

Day 3
*Lecture 7: An introduction to MCMC computations
*Lecture 8: Bayesian regression with WinBUGS
*Lecture 9: Introduction to Hierarchical Statistical modeling

*Prices:
Public sector and commercial: 1088,85 Euro (three days course, included 
VAT)
Student:  675 Euro (three days course, included VAT). Some of the 
courses are
frequently fully booked. So please notice that you may have to try several
times, until you get a spare place.

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
**For more information, please contact: info at linuxhotel.de
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


From Gerrit.Eichner at math.uni-giessen.de  Wed Oct 16 10:59:22 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 16 Oct 2013 10:59:22 +0200 (MEST)
Subject: [R] bug(?) in str() with strict.width = "cut" when
	appliedtodataframe with numeric component AND factor or
	character component withlongerlevels/strings
In-Reply-To: <Pine.SOC.4.64.1310160952360.24848@solcom.hrz.uni-giessen.de>
References: <Pine.SOC.4.64.1310151248250.10890@solcom.hrz.uni-giessen.de>
	<525DA165.6050004@gmail.com>
	<Pine.SOC.4.64.1310160952360.24848@solcom.hrz.uni-giessen.de>
Message-ID: <Pine.SOC.4.64.1310161044450.24848@solcom.hrz.uni-giessen.de>

Dear Duncan,

unfortunately, I have to correct myself in that I _can_ reproduce the 
problem after changing the global width-option to 70, say: Using the data 
frame X from before with the 'factory-fresh' setting for width and 
executing


> str( X, strict.width = "cut")
'data.frame':   11 obs. of  2 variables:
  $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
  $ B: Factor w/ 1 level "zjtvorkmoydsepnxkabmeondrjaanutjmfxlgzmrbjp": 1 1 1 1..


produces the correct output. But


> oo <- options( width = 70)
> str( X, strict.width = "cut")
'data.frame':   11 obs. of  2 variables:
  $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
  $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..


is obviously the wrong output I reported previously. Restoring the old 
options "solves" the problem:


> options( oo)
> str( X, strict.width = "cut")
'data.frame':   11 obs. of  2 variables:
  $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
  $ B: Factor w/ 1 level "zjtvorkmoydsepnxkabmeondrjaanutjmfxlgzmrbjp": 1 1 1 1..


Is that reproducible for you?

   Regards  --  Gerrit


PS: "New" session info:

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
[5] LC_TIME=German_Germany.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] fortunes_1.5-0

loaded via a namespace (and not attached):
[1] tools_3.0.2





On Wed, 16 Oct 2013, Gerrit Eichner wrote:

> Thanks, Duncan,
>
> for the good (indirect) hint: after a restart of R the problem is -- 
> fortunately :-) -- not reproducible anymore for me either. The R session had 
> been running for a longer time and I recall doing some (system-related) 
> things outside of R that may have interfered with it; I just forgot to take 
> that possibility into consideration. :(
>
> Regards  --  Gerrit
>
> On Tue, 15 Oct 2013, Duncan Murdoch wrote:
>
>> On 15/10/2013 7:53 AM, Gerrit Eichner wrote:
>>> Dear list subscribers,
>>> 
>>> here is a small artificial example to demonstrate the problem that I
>>> encountered when looking at the structure of a (larger) data frame that
>>> comprised (among other components)
>>> 
>>> a numeric component of elements of the order of > 10000, and
>>> 
>>> a factor or character component with longer levels/strings:
>>> 
>>> 
>>> k <- 43      # length of levels or character strings
>>> n <- 11      # number of rows of data frame
>>> M <- 10000   # order of magnitude of numerical values
>>> 
>>> set.seed( 47) # to reproduce the following artificial character string
>>> longer.char.string <- paste( sample( letters, k, replace = TRUE),
>>>                                collapse = "")
>>> 
>>> X <- data.frame( A = 1:n * M,
>>>                    B = rep( longer.char.string, n))
>>> 
>>> 
>>> The following call to str() gives apparently a wrong result
>>> 
>>> str( X, strict.width = "cut")
>>> 
>>> 'data.frame':   11 obs. of  2 variables:
>>>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>>>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>>> 
>>> 
>>> whereas the correct result appears for str( X) or if you decrease k to 42
>>> (isn't that "the answer"? ;-) ) or n to 10 or M to 1000 (or smaller,
>>> respectively).
>>> 
>>> 
>>> I tried to dig into the entrails of str.default(), where the cause may
>>> lie, but got lost pretty soon. So, I am hoping that someone may already
>>> have a work-around or patch (or dares to dig further)? Thank you for any
>>> feedback!
>> 
>> I can't reproduce this.  I don't have a 64 bit copy of 3.0.2 handy, but I 
>> don't see it in 64 bit 3.0.1, or 64 bit 3.0.2-patched, or various 32 bit 
>> versions.
>> 
>> Is it reproducible for you?  It looks to me as though (if it isn't just 
>> something weird on your system, e.g. an old copy of str() in your 
>> workspace), it might be a memory protection problem:  something needed to 
>> be duplicated but wasn't.  But unless I can see it happen, I can't start to 
>> fix it.
>> 
>> Duncan Murdoch
>> 
>>>
>>>    Best regards  --  Gerrit
>>> 
>>> PS:
>>> 
>>> > sessionInfo()
>>> 
>>> R version 3.0.2 (2013-09-25)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> 
>>> locale:
>>> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
>>> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
>>> [5] LC_TIME=German_Germany.1252
>>> 
>>> attached base packages:
>>> [1] splines   stats     graphics  grDevices utils     datasets
>>> [7] methods   base
>>> 
>>> other attached packages:
>>> [1] nparcomp_2.0     multcomp_1.2-21  mvtnorm_0.9-9996
>>> [4] car_2.0-19       Hmisc_3.12-2     Formula_1.1-1
>>> [7] survival_2.37-4  fortunes_1.5-0
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] cluster_1.14.4  grid_3.0.2      lattice_0.20-23 MASS_7.3-29
>>> [5] nnet_7.3-7      rpart_4.1-3     stats4_3.0.2    tools_3.0.2
>>> 
>>> ---------------------------------------------------------------------
>>> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
>>> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
>>> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
>>> Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From mohammad.godarzi at gmail.com  Wed Oct 16 10:57:50 2013
From: mohammad.godarzi at gmail.com (Mohammad Goodarzi)
Date: Wed, 16 Oct 2013 10:57:50 +0200
Subject: [R] binding matrices
Message-ID: <CAO4=jh6Y5xY=fmb9axhiXX6ThcOw=omB7A=DyZZXTZO5FJ6g-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/a9db6791/attachment.pl>

From jholtman at gmail.com  Wed Oct 16 11:13:53 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Wed, 16 Oct 2013 05:13:53 -0400
Subject: [R] binding matrices
In-Reply-To: <CAO4=jh6Y5xY=fmb9axhiXX6ThcOw=omB7A=DyZZXTZO5FJ6g-w@mail.gmail.com>
References: <CAO4=jh6Y5xY=fmb9axhiXX6ThcOw=omB7A=DyZZXTZO5FJ6g-w@mail.gmail.com>
Message-ID: <3DBA624A-3894-4EA3-AB57-D093098D5977@gmail.com>

?rbind
?cbind

Sent from my iPad

On Oct 16, 2013, at 4:57, Mohammad Goodarzi <mohammad.godarzi at gmail.com> wrote:

> I have several matrices with the same size. I want to bind them one after
> another.
> Can you please let me know how to do it?
> 
> Best Regards,
> Mohammad
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Oct 16 11:24:53 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 16 Oct 2013 05:24:53 -0400
Subject: [R] bug(?) in str() with strict.width = "cut" when
 appliedtodataframe with numeric component AND factor or character component
 withlongerlevels/strings
In-Reply-To: <Pine.SOC.4.64.1310161044450.24848@solcom.hrz.uni-giessen.de>
References: <Pine.SOC.4.64.1310151248250.10890@solcom.hrz.uni-giessen.de>
	<525DA165.6050004@gmail.com>
	<Pine.SOC.4.64.1310160952360.24848@solcom.hrz.uni-giessen.de>
	<Pine.SOC.4.64.1310161044450.24848@solcom.hrz.uni-giessen.de>
Message-ID: <525E5B65.4060408@gmail.com>

On 13-10-16 4:59 AM, Gerrit Eichner wrote:
> Dear Duncan,
>
> unfortunately, I have to correct myself in that I _can_ reproduce the
> problem after changing the global width-option to 70, say: Using the data
> frame X from before with the 'factory-fresh' setting for width and
> executing
>
>
>> str( X, strict.width = "cut")
> 'data.frame':   11 obs. of  2 variables:
>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
>    $ B: Factor w/ 1 level "zjtvorkmoydsepnxkabmeondrjaanutjmfxlgzmrbjp": 1 1 1 1..
>
>
> produces the correct output. But
>
>
>> oo <- options( width = 70)
>> str( X, strict.width = "cut")
> 'data.frame':   11 obs. of  2 variables:
>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>
>
> is obviously the wrong output I reported previously. Restoring the old
> options "solves" the problem:
>
>
>> options( oo)
>> str( X, strict.width = "cut")
> 'data.frame':   11 obs. of  2 variables:
>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
>    $ B: Factor w/ 1 level "zjtvorkmoydsepnxkabmeondrjaanutjmfxlgzmrbjp": 1 1 1 1..
>
>
> Is that reproducible for you?

Yes, got it now.  I'll take a look.

Duncan Murdoch

>
>     Regards  --  Gerrit
>
>
> PS: "New" session info:
>
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] fortunes_1.5-0
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.2
>
>
>
>
>
> On Wed, 16 Oct 2013, Gerrit Eichner wrote:
>
>> Thanks, Duncan,
>>
>> for the good (indirect) hint: after a restart of R the problem is --
>> fortunately :-) -- not reproducible anymore for me either. The R session had
>> been running for a longer time and I recall doing some (system-related)
>> things outside of R that may have interfered with it; I just forgot to take
>> that possibility into consideration. :(
>>
>> Regards  --  Gerrit
>>
>> On Tue, 15 Oct 2013, Duncan Murdoch wrote:
>>
>>> On 15/10/2013 7:53 AM, Gerrit Eichner wrote:
>>>> Dear list subscribers,
>>>>
>>>> here is a small artificial example to demonstrate the problem that I
>>>> encountered when looking at the structure of a (larger) data frame that
>>>> comprised (among other components)
>>>>
>>>> a numeric component of elements of the order of > 10000, and
>>>>
>>>> a factor or character component with longer levels/strings:
>>>>
>>>>
>>>> k <- 43      # length of levels or character strings
>>>> n <- 11      # number of rows of data frame
>>>> M <- 10000   # order of magnitude of numerical values
>>>>
>>>> set.seed( 47) # to reproduce the following artificial character string
>>>> longer.char.string <- paste( sample( letters, k, replace = TRUE),
>>>>                                 collapse = "")
>>>>
>>>> X <- data.frame( A = 1:n * M,
>>>>                     B = rep( longer.char.string, n))
>>>>
>>>>
>>>> The following call to str() gives apparently a wrong result
>>>>
>>>> str( X, strict.width = "cut")
>>>>
>>>> 'data.frame':   11 obs. of  2 variables:
>>>>     $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>>>>     $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>>>>
>>>>
>>>> whereas the correct result appears for str( X) or if you decrease k to 42
>>>> (isn't that "the answer"? ;-) ) or n to 10 or M to 1000 (or smaller,
>>>> respectively).
>>>>
>>>>
>>>> I tried to dig into the entrails of str.default(), where the cause may
>>>> lie, but got lost pretty soon. So, I am hoping that someone may already
>>>> have a work-around or patch (or dares to dig further)? Thank you for any
>>>> feedback!
>>>
>>> I can't reproduce this.  I don't have a 64 bit copy of 3.0.2 handy, but I
>>> don't see it in 64 bit 3.0.1, or 64 bit 3.0.2-patched, or various 32 bit
>>> versions.
>>>
>>> Is it reproducible for you?  It looks to me as though (if it isn't just
>>> something weird on your system, e.g. an old copy of str() in your
>>> workspace), it might be a memory protection problem:  something needed to
>>> be duplicated but wasn't.  But unless I can see it happen, I can't start to
>>> fix it.
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>>     Best regards  --  Gerrit
>>>>
>>>> PS:
>>>>
>>>>> sessionInfo()
>>>>
>>>> R version 3.0.2 (2013-09-25)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
>>>> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
>>>> [5] LC_TIME=German_Germany.1252
>>>>
>>>> attached base packages:
>>>> [1] splines   stats     graphics  grDevices utils     datasets
>>>> [7] methods   base
>>>>
>>>> other attached packages:
>>>> [1] nparcomp_2.0     multcomp_1.2-21  mvtnorm_0.9-9996
>>>> [4] car_2.0-19       Hmisc_3.12-2     Formula_1.1-1
>>>> [7] survival_2.37-4  fortunes_1.5-0
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] cluster_1.14.4  grid_3.0.2      lattice_0.20-23 MASS_7.3-29
>>>> [5] nnet_7.3-7      rpart_4.1-3     stats4_3.0.2    tools_3.0.2
>>>>
>>>> ---------------------------------------------------------------------
>>>> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
>>>> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
>>>> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
>>>> Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Oct 16 11:44:15 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 16 Oct 2013 05:44:15 -0400
Subject: [R] bug(?) in str() with strict.width = "cut" when
 appliedtodataframe with numeric component AND factor or character component
 withlongerlevels/strings
In-Reply-To: <Pine.SOC.4.64.1310161044450.24848@solcom.hrz.uni-giessen.de>
References: <Pine.SOC.4.64.1310151248250.10890@solcom.hrz.uni-giessen.de>
	<525DA165.6050004@gmail.com>
	<Pine.SOC.4.64.1310160952360.24848@solcom.hrz.uni-giessen.de>
	<Pine.SOC.4.64.1310161044450.24848@solcom.hrz.uni-giessen.de>
Message-ID: <525E5FEF.6040101@gmail.com>

On 13-10-16 4:59 AM, Gerrit Eichner wrote:
> Dear Duncan,
>
> unfortunately, I have to correct myself in that I _can_ reproduce the
> problem after changing the global width-option to 70, say: Using the data
> frame X from before with the 'factory-fresh' setting for width and
> executing
>
>
>> str( X, strict.width = "cut")
> 'data.frame':   11 obs. of  2 variables:
>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
>    $ B: Factor w/ 1 level "zjtvorkmoydsepnxkabmeondrjaanutjmfxlgzmrbjp": 1 1 1 1..
>
>
> produces the correct output. But
>
>
>> oo <- options( width = 70)
>> str( X, strict.width = "cut")
> 'data.frame':   11 obs. of  2 variables:
>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>
>
> is obviously the wrong output I reported previously. Restoring the old
> options "solves" the problem:
>
>
>> options( oo)
>> str( X, strict.width = "cut")
> 'data.frame':   11 obs. of  2 variables:
>    $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
>    $ B: Factor w/ 1 level "zjtvorkmoydsepnxkabmeondrjaanutjmfxlgzmrbjp": 1 1 1 1..
>
>
> Is that reproducible for you?

It was a simple error in the code for str.default.  When both lines 
needed cutting, the code mixed them up.  Will soon be fixed in R-devel 
and R-patched.

Duncan Murdoch

>
>     Regards  --  Gerrit
>
>
> PS: "New" session info:
>
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] fortunes_1.5-0
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.2
>
>
>
>
>
> On Wed, 16 Oct 2013, Gerrit Eichner wrote:
>
>> Thanks, Duncan,
>>
>> for the good (indirect) hint: after a restart of R the problem is --
>> fortunately :-) -- not reproducible anymore for me either. The R session had
>> been running for a longer time and I recall doing some (system-related)
>> things outside of R that may have interfered with it; I just forgot to take
>> that possibility into consideration. :(
>>
>> Regards  --  Gerrit
>>
>> On Tue, 15 Oct 2013, Duncan Murdoch wrote:
>>
>>> On 15/10/2013 7:53 AM, Gerrit Eichner wrote:
>>>> Dear list subscribers,
>>>>
>>>> here is a small artificial example to demonstrate the problem that I
>>>> encountered when looking at the structure of a (larger) data frame that
>>>> comprised (among other components)
>>>>
>>>> a numeric component of elements of the order of > 10000, and
>>>>
>>>> a factor or character component with longer levels/strings:
>>>>
>>>>
>>>> k <- 43      # length of levels or character strings
>>>> n <- 11      # number of rows of data frame
>>>> M <- 10000   # order of magnitude of numerical values
>>>>
>>>> set.seed( 47) # to reproduce the following artificial character string
>>>> longer.char.string <- paste( sample( letters, k, replace = TRUE),
>>>>                                 collapse = "")
>>>>
>>>> X <- data.frame( A = 1:n * M,
>>>>                     B = rep( longer.char.string, n))
>>>>
>>>>
>>>> The following call to str() gives apparently a wrong result
>>>>
>>>> str( X, strict.width = "cut")
>>>>
>>>> 'data.frame':   11 obs. of  2 variables:
>>>>     $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>>>>     $ A: num  1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+..
>>>>
>>>>
>>>> whereas the correct result appears for str( X) or if you decrease k to 42
>>>> (isn't that "the answer"? ;-) ) or n to 10 or M to 1000 (or smaller,
>>>> respectively).
>>>>
>>>>
>>>> I tried to dig into the entrails of str.default(), where the cause may
>>>> lie, but got lost pretty soon. So, I am hoping that someone may already
>>>> have a work-around or patch (or dares to dig further)? Thank you for any
>>>> feedback!
>>>
>>> I can't reproduce this.  I don't have a 64 bit copy of 3.0.2 handy, but I
>>> don't see it in 64 bit 3.0.1, or 64 bit 3.0.2-patched, or various 32 bit
>>> versions.
>>>
>>> Is it reproducible for you?  It looks to me as though (if it isn't just
>>> something weird on your system, e.g. an old copy of str() in your
>>> workspace), it might be a memory protection problem:  something needed to
>>> be duplicated but wasn't.  But unless I can see it happen, I can't start to
>>> fix it.
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>>     Best regards  --  Gerrit
>>>>
>>>> PS:
>>>>
>>>>> sessionInfo()
>>>>
>>>> R version 3.0.2 (2013-09-25)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
>>>> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
>>>> [5] LC_TIME=German_Germany.1252
>>>>
>>>> attached base packages:
>>>> [1] splines   stats     graphics  grDevices utils     datasets
>>>> [7] methods   base
>>>>
>>>> other attached packages:
>>>> [1] nparcomp_2.0     multcomp_1.2-21  mvtnorm_0.9-9996
>>>> [4] car_2.0-19       Hmisc_3.12-2     Formula_1.1-1
>>>> [7] survival_2.37-4  fortunes_1.5-0
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] cluster_1.14.4  grid_3.0.2      lattice_0.20-23 MASS_7.3-29
>>>> [5] nnet_7.3-7      rpart_4.1-3     stats4_3.0.2    tools_3.0.2
>>>>
>>>> ---------------------------------------------------------------------
>>>> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
>>>> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
>>>> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
>>>> Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Wed Oct 16 12:04:16 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 16 Oct 2013 12:04:16 +0200
Subject: [R] Finding solution for non-linear equations
In-Reply-To: <147C88AF-A088-4BD7-8D0C-4DE871806A2D@xs4all.nl>
References: <1381843499.34536.YahooMailBasic@web190503.mail.sg3.yahoo.com>
	<147C88AF-A088-4BD7-8D0C-4DE871806A2D@xs4all.nl>
Message-ID: <39840F1C-6601-4D6E-A4E7-1ADDA998685A@gmail.com>


On Oct 15, 2013, at 17:18 , Berend Hasselman wrote:

> 
> On 15-10-2013, at 15:24, Ron Michael <ron_michael70 at yahoo.com> wrote:
> 
>> Hi,
>> 
>> I need to solve following simultaneous equations for A, B, Y1, Y2:
>> 
>> B * Phi(Y1 - A) + (1-B) * Phi(Y1 + A) = 0.05
>> B * Phi(Y2 - A) + (1-B) * Phi(Y2 + A) = 0.01
>> 
>> Y1 <= -1.65
>> Y2 >= -2.33
>> 
>> 0 <= B <=1 
>> 
>> Phi is CDF for standard normal
>> 
>> If there is no unique solution, then I should be able to get some feassible solution(s)
>> 
>> Is there any way that using R I can achieve that?
> 
> 
> You cannot solve a system of 2 equations with 4 unknowns (variables).
> You can only try to find  4 values that get as close as possible (in whatever sense) to solving the system.


Think again.... 

A=0, B=whatever, Y1=qnorm(.05), Y2=qnorm(.01)

(4 equations in 2 unknowns is generally harder.)

There are also solutions for A+Y1 = qnorm(.05), A+Y2 = qnorm(.01), B=0, etc. --- except that they will violate the constraints on at least one of Y1, Y2  (assuming that the constraints are actually the two qnorm()s rounded to two decimal places)!

The 65536$ question is whether there are nontrivial solutions, with Y1+/-A on different sides of  qnorm(.05), and consequently 0 < B < 1. I kind of suspect that there aren't any; for instance

> Y1 <- qnorm(.05)
> Y2 <- qnorm(.01)
> A <- .01
> B <- (pnorm(Y1+A)-0.05)/(pnorm(Y1+A)-pnorm(Y1-A))
> B*(pnorm(Y1-A))+(1-B)*pnorm(Y1+A)
[1] 0.05
> B*(pnorm(Y2-A))+(1-B)*pnorm(Y2+A)
[1] 0.01000091
> B*(pnorm(Y2+.001-A))+(1-B)*pnorm(Y2+.001+A)
[1] 0.01002759

Notice that we can get the first equation satisfied exactly, but then the 2nd one overshoots by an amount which is increasing in Y2. We could fix that by decreasing Y2 but that violates the constraint. 


-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From p.mulongeni at namibia.pharmaccess.org  Wed Oct 16 12:27:55 2013
From: p.mulongeni at namibia.pharmaccess.org (Pancho Mulongeni)
Date: Wed, 16 Oct 2013 10:27:55 +0000
Subject: [R] R reference group in Cape Town South Africa
Message-ID: <d54d01fb90b44b4c941d9d59f5068d55@AMSPR03MB291.eurprd03.prod.outlook.com>

Hi R users in Cape Town,
I will be starting the Epidemiology/Clinical Research program at the University of Cape Town in the Summer of Jan 2014 and so I am looking to meet any useRs. I assume there is a refeRence group in Cape Town?
Please do email me as I would love to corRespond with you,
Best

Pancho Mulongeni
Research Assistant
PharmAccess Foundation
1 Fouch? Street
Windhoek West
Windhoek
Namibia
?
Tel:?? +264 61 419 000
Fax:? +264 61 419 001/2
Mob: +264 81 4456 286


From katherine_gobin at yahoo.com  Wed Oct 16 13:01:09 2013
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Wed, 16 Oct 2013 19:01:09 +0800 (SGT)
Subject: [R] How to write an error to output
Message-ID: <1381921269.27387.YahooMailNeo@web193204.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/c0b7c125/attachment.pl>

From jholtman at gmail.com  Wed Oct 16 13:58:18 2013
From: jholtman at gmail.com (jim holtman)
Date: Wed, 16 Oct 2013 07:58:18 -0400
Subject: [R] How to write an error to output
In-Reply-To: <1381921269.27387.YahooMailNeo@web193204.mail.sg3.yahoo.com>
References: <1381921269.27387.YahooMailNeo@web193204.mail.sg3.yahoo.com>
Message-ID: <CAAxdm-5vnErQnMjE3h8Q=4UrEujLiCCK9fu-uLmEGc1gao19SQ@mail.gmail.com>

Will this work for you:


mydat = data.frame(A = c(19, 20, 19, 19, 19, 18, 16, 18, 19, 20), B =
c(19, 20, 20, 19, 20, 18, 19, 18, 17, 16))

if (length(mydat$A) > 10)

{
write.csv(data.frame(error = "A has length more than 10"),
'result.csv', row.names = FALSE)
stop("A has length more than 10")
}else

if (max(mydat$B) > 18)
{
write.csv(data.frame(error = "max B exceeds limit"), 'result.csv',
row.names = FALSE)
stop("max B exceeds limit")
}else

{result = mydat$A + mydat$B

    if (length(result) > 0)

{
         write.csv(data.frame(result = result), 'result.csv', row.names = FALSE)
         }
}

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Oct 16, 2013 at 7:01 AM, Katherine Gobin
<katherine_gobin at yahoo.com> wrote:
> Dear R forum,
>
> The example below is just an indicative one and I have constructed it. My real life data and conditions are different.
>
> I have a data.frame as given below
>
> mydat = data.frame(A = c(19, 20, 19, 19, 19, 18, 16, 18, 19, 20), B = c(19, 20, 20, 19, 20, 18, 19, 18, 17, 16))
>
> if (length(mydat$A) > 10)
>
> {
> stop("A has length more than 10")
> }else
>
> if (max(mydat$B) > 18)
> {
> stop("max B exceeds limit")
> }else
>
> {result = mydat$A + mydat$B
>
>     if (length(result) > 0)
>
> {
>          write.csv(data.frame(result = result), 'result.csv', row.names = FALSE)
>          }
> }
>
> # -----------------------------------------------------------------
>
> When i execute above code, I get message
>
> Error: max B exceeds limit
>
> If all conditions are met, obviously I am getting an output as result.csv
>
> If result.csv is generated, I am able to capture and show the output in front end. However, if the process couldn't be run owing to the violation of conditions, the error is produced. How do I capture this error (and express it as csv file) so that I can show it as a comment in front end.
>
> Kindly guide.
>
>
> Katherine
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From therneau at mayo.edu  Wed Oct 16 14:33:02 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 16 Oct 2013 07:33:02 -0500
Subject: [R] How to obtain restricted estimates from coxph()?
In-Reply-To: <mailman.21.1381917608.4459.r-help@r-project.org>
References: <mailman.21.1381917608.4459.r-help@r-project.org>
Message-ID: <525E877E.2050500@mayo.edu>



On 10/16/2013 05:00 AM, r-help-request at r-project.org wrote:
> Hello,
>
> I'm trying to use coxph() function to fit a very simple Cox proportional
> hazards regression model (only one covariate) but the parameter space is
> restricted to an open set (0, 1). Can I still obtain a valid estimate by
> using coxph function in this scenario? If yes, how? Any suggestion would be
> greatly appreciated. Thanks!!!

Easily:
    1.  Fit the unrestricted model.  If the solution is in 0-1 you are done.
    2.  If it is outside, fix the coefficient.  Say that the solution is 1.73, then the
optimal solution under contraint is 1.
        Redo the fit adding the paramters  "init=1, iter=0".  This forces the program to 
give the loglik and etc for the fixed coefficient of 1.0.

Terry Therneau


From yuhanusa at gmail.com  Wed Oct 16 11:50:44 2013
From: yuhanusa at gmail.com (Y)
Date: Wed, 16 Oct 2013 05:50:44 -0400
Subject: [R] How to obtain restricted estimates from coxph()?
Message-ID: <CAHJ49whMORYFB2i9yqm1TGdwpgODKRv8wq9Tyw3vpP8_v9gukw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/8907a352/attachment.pl>

From hnorpois at gmail.com  Wed Oct 16 11:39:07 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Wed, 16 Oct 2013 11:39:07 +0200
Subject: [R] plot: want only dots
In-Reply-To: <CAM_vju=kG_vAdjQT1=JgdE1QzoU-hjFHarD5XYX3aCktLF73Ww@mail.gmail.com>
References: <CAKyZeBv4FhrDNm9c6GJmvC3bHSCyKjp0x+Js-fPrSwKnKQpV_A@mail.gmail.com>
	<CAM_vju=kG_vAdjQT1=JgdE1QzoU-hjFHarD5XYX3aCktLF73Ww@mail.gmail.com>
Message-ID: <CAKyZeBvpAOLaDnugnpXjaxWFYPrsfhvsp=tdm4N1wkcNGGeang@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/c3306c01/attachment.pl>

From m.coulson at marlab.ac.uk  Wed Oct 16 12:47:57 2013
From: m.coulson at marlab.ac.uk (markw)
Date: Wed, 16 Oct 2013 03:47:57 -0700 (PDT)
Subject: [R] map with inset
Message-ID: <1381920477182-4678341.post@n4.nabble.com>

Hi, 

I am trying to put an inset of North America onto a finer-scale map and
cannot seem to get the two maps on the same plot.

the main map is:
map("worldHires", c("Canada", "USA"), xlim=c(-75, -52), ylim=c(40, 55),
col="gray90", fill=TRUE)
map.axes()
map('rivers', add=TRUE)
map.scale(-73, 54, relwidth=0.2, ratio=FALSE)
rect(-59.5, 46.5, -52,52)
text(-53,51.5,"A")
rect(-69, 43, -59.5,49.5)
text(-60, 49, "B") 

and in the bottom right corner I want the following map scaled so it doesn't
overlap with my main map:
map("worldHires", c("Canada", "USA"), xlim=c(-170, -50), ylim=c(24, 90),
proj="gilbert")

Any suggestions?

Mark



--
View this message in context: http://r.789695.n4.nabble.com/map-with-inset-tp4678341.html
Sent from the R help mailing list archive at Nabble.com.


From B.Ward at uea.ac.uk  Wed Oct 16 12:56:11 2013
From: B.Ward at uea.ac.uk (Benjamin Ward (ENV))
Date: Wed, 16 Oct 2013 10:56:11 +0000
Subject: [R] Small p from binomial probability function.
In-Reply-To: <52575041.2090304@vodafone.co.nz>
References: <142413609C0A60488585AB47438ECD9D015BE871@ueastfexch01.UEA.AC.UK>, 
	<45FE3A4B-86AB-49A4-B4E4-05B2479953A8@collocations.de>
	<142413609C0A60488585AB47438ECD9D015BEA44@ueastfexch01.UEA.AC.UK>,
	<52575041.2090304@vodafone.co.nz>
Message-ID: <142413609C0A60488585AB47438ECD9D015C0592@ueastfexch01.UEA.AC.UK>

Hi,

Thanks again for your answers, just so as I can get clear what is happening, with the uniroot method, I'm defining a function in which the binomial probability function pbinom is present but in addition p0 is subtracted from the result - in this case p0 is the large P I want to plug in so 0.05, 0.50 and 0.95, or even just 0.05 and 0.95? Then uniroot finds the root of this function and doing so find me the small p I need?

Best,
Ben.


________________________________________
From: Rolf Turner [rolf.turner at vodafone.co.nz]
Sent: 11 October 2013 02:11
To: Benjamin Ward (ENV)
Cc: Stefan Evert; R-help Mailing List
Subject: Re: [R] Small p from binomial probability function.

It is mysterious to me why the procedure proposed by Stefan Evert works.
It appears to work --- once you modify the call to binom.test() to have the
correct syntax.  In a sequence of 1000  trials with random values of N, x,
and p0, the answers from Evert's procedure agreed with the answer given
by uniroot() to within +/- 3.045e-05.

However your question was (in effect) how to solve the equation

     Pr(X <= x) = p0

for p, where X ~ Binom(N,p), with N and x known.  What this has to do with
confidence intervals for p is, to my mind at least, completely opaque.
In contrast it is obvious why the procedure using uniroot() works.

I would suggest that you stick with the uniroot() procedure in that it is
readily comprehensible.

     cheers,

     Rolf Turner

On 10/11/13 03:56, Benjamin Ward (ENV) wrote:
> Hi,
>
> Thank you for your answers, I'm not completely sure if it's to bino.test I need or the uniroot. Perhaps I should explain more the idea behind the code and the actual task I'm trying to do. The idea is to calculate a confidence interval as to the age of two DNA sequences which have diverged, where I know the number of mutations that happened in them, and I know the mutation rate.
>
> The binomial probability can be used since, mutations have a probability of occurring or being observed so many times in a sequence. This is dependent on the length of the DNA stretch (which equates to the number of trials since each base is a possibility of observing a mutation), the probability of a single mutation occurring which is p = t * u, since more time means a higher probability a mutation may have occurred.
>
> So my code, using pbinom, is supposed to calculate the probability that my DNA stretches contain the number of mutations observed P(X = k), given their size (trials) and the probability of a single mutation (p = t * u). However I'm interested in finding t: t is what is unknown, so the loop repeatedly evaluates the calculation, increasing t each time and checking P(X=k), when it is 0.05, 0.50 and 0.95, we record t.
>
> Ideally I'd like to rearrange this so I can get the probability of a single success (mutation) p, and then divide by the mutation rate to get my t. My supervisor gave my the loopy code but I imagine there is a way to plug in P(X=k) as 0.05 and 0.95 and get my upper and lower t estimates.
>
> According to the R built in docs:
>
> binom.test
> Description:
>
>       Performs an exact test of a simple null hypothesis about the
>       probability of success in a Bernoulli experiment.
>
> Perhaps this is the one I need rather than uniroot?
>
> Best,
> Ben.
>
>
> ________________________________________
> From: Stefan Evert [stefanML at collocations.de]
> Sent: 10 October 2013 09:37
> To: R-help Mailing List
> Cc: Benjamin Ward (ENV)
> Subject: Re: [R] Small p from binomial probability function.
>
> Sounds like you want a 95% binomial confidence interval:
>
>          binom.test(N, P)
>
> will compute this for you, and you can get the bounds directly with
>
>          binom.test(N, P)$conf.int
>
> Actually, binom.test computes a two-sided confidence interval, which corresponds roughly to 2.5 and 97.5 percentages in your approach. It doesn't give you the 50% point either, but I don't think that's a meaningful quantity with a two-sided test.
>
> Hope this helps,
> Stefan
>
>
> On 9 Oct 2013, at 15:53, Benjamin Ward (ENV) <B.Ward at uea.ac.uk> wrote:
>
>> I got given some code that uses the R function pbionom:
>>
>> p <- mut * t
>> sumprobs <- pbinom( N, B, p ) * 1000
>>
>> Which gives the output of a probability as a percentage like 5, 50, 95.
>>
>> What the code currently does is find me the values of t I need, by using the above two code lines in a loop, each iteration it increaces t by one and runs the two lines. When sumprobs equals 5, it records the value t, then again when sumprobs is equal to 50, and again when sumprobs is equal to 95 - giving me three t values. This is not an efficient way of doing this if t is large. Is it possible to rearrange pbinom so it gives me the small p (made of mut*t) as the result of plugging in the sumprobs instead, and is there an R function that already does this?
>>
>> Since pbinom is the binomial probability equation I suppose the question is - in more mathematical terminology - can I change this code so that instead of calculating the Probability of N successes given the number of trials and the probability of a single success, can I instead calculate the probability of a single success using the probability of N successes and number of trials, and the number of successes? Can R do this for me. So instead I plug in 5, 50, and 95, and then get the small p out?


From johnlinuxuser at yahoo.com  Wed Oct 16 15:32:08 2013
From: johnlinuxuser at yahoo.com (John linux-user)
Date: Wed, 16 Oct 2013 06:32:08 -0700 (PDT)
Subject: [R] how to merge GRange object?
In-Reply-To: <525E877E.2050500@mayo.edu>
References: <mailman.21.1381917608.4459.r-help@r-project.org>
	<525E877E.2050500@mayo.edu>
Message-ID: <1381930328.59230.YahooMailNeo@web120401.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/1943438f/attachment.pl>

From mtmorgan at fhcrc.org  Wed Oct 16 15:56:15 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 16 Oct 2013 06:56:15 -0700
Subject: [R] how to merge GRange object?
In-Reply-To: <1381930328.59230.YahooMailNeo@web120401.mail.ne1.yahoo.com>
References: <mailman.21.1381917608.4459.r-help@r-project.org>	<525E877E.2050500@mayo.edu>
	<1381930328.59230.YahooMailNeo@web120401.mail.ne1.yahoo.com>
Message-ID: <525E9AFF.2040108@fhcrc.org>

On 10/16/2013 06:32 AM, John linux-user wrote:
> Hello everyone,
>
> I am wondering how to simply merge two GRanges objects by range field and add the value by additional vector. For example, I have two objects below
>

Hi -- GRanges is from a Bioconductor package, so please ask on the Bioconductor 
mailing list

   http://bioconductor.org/help/mailing-list/

I think you might do hits = findOverlaps(obj1, obj2) to get indexes of 
overlapping ranges, then pmin(obj1[queryHits(obj1)], obj2[subjectHits(obj2)]) 
and pmax() to get start and end coordinates, and construct a new GRanges from 
those. If you provide an easily reproducile example (e.g., constructing some 
sample GRanges objects 'by hand' using GRanges()) and post to the Bioconductor 
mailing list you'll likely get a complete answer.

Martin

> obj1
>
> seqnames           ranges strand |       Val
>              <Rle>        <IRanges>  <Rle> | <integer>
>    [1] chr1_random [272531, 272571]      + |        88
>    [2] chr1_random [272871, 272911]      + |        45
>
> obj2
>   seqnames           ranges strand |       Val
>              <Rle>        <IRanges>  <Rle> | <integer>
>    [1] chr1_random [272531, 272581]      + |        800
>    [2] chr1_random [272850, 272911]      + |        450
>
> after merged, it should be an object as the following mergedObject and it would concern the differences in IRANGE data (e.g. 581 and 850 in obj2 above were different from those of obj1, which were 571 and 871 respectively)
>
> mergedObject
>
>   seqnames           ranges strand                 |         object2Val   object1Val
>              <Rle>        <IRanges>  <Rle>         |         <integer>     <integer>
>    [1] chr1_random [272531, 272581]      + |        800               88
>    [2] chr1_random [272850, 272911]      + |        450               45
>
>
>
>
>
> On Wednesday, October 16, 2013 8:31 AM, Terry Therneau <therneau at mayo.edu> wrote:
>
>
>
> On 10/16/2013 05:00 AM, r-help-request at r-project.org wrote:
>> Hello,
>>
>> I'm trying to use coxph() function to fit a very simple Cox proportional
>> hazards regression model (only one covariate) but the parameter space is
>> restricted to an open set (0, 1). Can I still obtain a valid estimate by
>> using coxph function in this scenario? If yes, how? Any suggestion would be
>> greatly appreciated. Thanks!!!
>
> Easily:
>      1.  Fit the unrestricted model.  If the solution is in 0-1 you are done.
>      2.  If it is outside, fix the coefficient.  Say that the solution is 1.73, then the
> optimal solution under contraint is 1.
>          Redo the fit adding the paramters  "init=1, iter=0".  This forces the program to
> give the loglik and etc for the fixed coefficient of 1.0.
>
> Terry Therneau
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From babakbsn at gmail.com  Wed Oct 16 16:07:34 2013
From: babakbsn at gmail.com (Babak Bastan)
Date: Wed, 16 Oct 2013 07:07:34 -0700
Subject: [R] new dprep package for windows
Message-ID: <CAF-JZQtPvm3p-JgvVT0rAdadbqWpm2E4TuHk_KFwwpAfMnLC_g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/1c861c2a/attachment.pl>

From tom.soyer at gmail.com  Wed Oct 16 16:54:00 2013
From: tom.soyer at gmail.com (tom soyer)
Date: Wed, 16 Oct 2013 09:54:00 -0500
Subject: [R] Is there something wrong with R version 3.0.2 (2013-09-25) --
 "Frisbee Sailing"?
Message-ID: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/848c6e9e/attachment.pl>

From nashjc at uottawa.ca  Wed Oct 16 17:03:22 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Wed, 16 Oct 2013 11:03:22 -0400
Subject: [R] Cleaning up workspace
Message-ID: <525EAABA.3040305@uottawa.ca>

In order to have a clean workspace at the start of each chapter of a 
book I'm "knit"ing I've written a little script as follows:

# chapclean.R
# This cleans up the R workspace
ilist<-c(".GlobalEnv", "package:stats", "package:graphics", 
"package:grDevices",
"package:utils", "package:datasets", "package:methods", "Autoloads",
"package:base")
print(ilist)
xlist<-search()[which(!(search() %in% ilist))]
print(xlist)
for (ff in xlist){
    cat("Detach ",ff," which is pos ",as.integer(which(ff == 
search())),"\n")
    detach(pos=as.integer(which(ff == search())), unload=TRUE) # ?? do 
we need unload
}
rm(list=ls())


This appears to "work" fine in my system -- session info is below, but I 
get 30 warnings of the type

30: In FUN(X[[2L]], ...) :
   Created a package name, ?2013-10-16 10:56:47?, when none found

Does anyone have ideas why the warnings are being generated?  I'd like 
to avoid suppressing them. Here's the session info.

R version 3.0.1 (2013-05-16)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.0.1
 >

John Nash


From pdalgd at gmail.com  Wed Oct 16 17:03:54 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 16 Oct 2013 17:03:54 +0200
Subject: [R] Is there something wrong with R version 3.0.2 (2013-09-25)
	-- "Frisbee Sailing"?
In-Reply-To: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
References: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
Message-ID: <53737400-8E43-44E4-B484-8A80D5D7CFA1@gmail.com>


On Oct 16, 2013, at 16:54 , tom soyer wrote:

> Hi,
> 
> pnorm(-1.53,0,1) under version 3.0.2 gives 0.05155075. I am pretty sure it
> should be 0.063. Is there something wrong with this version of R?

Not on my system (Mac OS X):

> pnorm(-1.53,0,1)
[1] 0.06300836

But check your typing, and/or eyesight, before blaming R:

> pnorm(-1.63,0,1)
[1] 0.05155075
> pnorm(-1.53,0.1)
[1] 0.05155075

-pd


> 
> I am using:
> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: i686-pc-linux-gnu (32-bit)
> 
> 
> -- 
> Tom
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Wed Oct 16 17:05:15 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 16 Oct 2013 08:05:15 -0700
Subject: [R] new dprep package for windows
In-Reply-To: <CAF-JZQtPvm3p-JgvVT0rAdadbqWpm2E4TuHk_KFwwpAfMnLC_g@mail.gmail.com>
References: <CAF-JZQtPvm3p-JgvVT0rAdadbqWpm2E4TuHk_KFwwpAfMnLC_g@mail.gmail.com>
Message-ID: <d5702b5b-f5d5-4f9b-8c52-60cd1bbad5bd@email.android.com>

Contact the maintainer? 

?maintainer

If that doesn't work (it doesn't seem to have worked for the CRAN volunteers), then download the source code from the archives and fix it? This may require you to learn more than you expected to but in some cases may be the only option.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Babak Bastan <babakbsn at gmail.com> wrote:
>Hi experts,
>
>I need the new version of   dprep package for windows. What I have
>found is
>version 1.
>
>if I am installing version 1 I get this error
>
>*Error: package ?dprep? was built before R 3.0.0: please re-install it*
>*
>*
>Is ther a new version of this package? if not what should I do?
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Wed Oct 16 17:06:21 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 16 Oct 2013 08:06:21 -0700
Subject: [R] Is there something wrong with R version 3.0.2 (2013-09-25)
 -- "Frisbee Sailing"?
In-Reply-To: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
References: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
Message-ID: <CACk-te1CSjEF9joMdZk2wkwb8EziC0=vco_YzVLR_jeXJdQ-Sw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/abb07abc/attachment.pl>

From murdoch.duncan at gmail.com  Wed Oct 16 17:07:08 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 16 Oct 2013 11:07:08 -0400
Subject: [R] Is there something wrong with R version 3.0.2 (2013-09-25)
 -- "Frisbee Sailing"?
In-Reply-To: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
References: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
Message-ID: <525EAB9C.1090405@gmail.com>

On 16/10/2013 10:54 AM, tom soyer wrote:
> Hi,
>
> pnorm(-1.53,0,1) under version 3.0.2 gives 0.05155075. I am pretty sure it
> should be 0.063. Is there something wrong with this version of R?
>
> I am using:
> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: i686-pc-linux-gnu (32-bit)
>

I can't reproduce this problem in Windows versions of 3.0.2.  I get the 
result 0.06300836.

Are you starting with a clean workspace?  If you have your own function 
called pnorm, it will take precedence.

Duncan Murdoch


From tom.soyer at gmail.com  Wed Oct 16 17:08:39 2013
From: tom.soyer at gmail.com (tom soyer)
Date: Wed, 16 Oct 2013 10:08:39 -0500
Subject: [R] Is there something wrong with R version 3.0.2 (2013-09-25)
 -- "Frisbee Sailing"?
In-Reply-To: <53737400-8E43-44E4-B484-8A80D5D7CFA1@gmail.com>
References: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
	<53737400-8E43-44E4-B484-8A80D5D7CFA1@gmail.com>
Message-ID: <CAACmW3ZdPJ0Mb6YPF9L0BC=FDmyE+vh9VikFKTxgV1nY+7w2Vw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/f6a6338b/attachment.pl>

From murdoch.duncan at gmail.com  Wed Oct 16 17:12:29 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 16 Oct 2013 11:12:29 -0400
Subject: [R] Cleaning up workspace
In-Reply-To: <525EAABA.3040305@uottawa.ca>
References: <525EAABA.3040305@uottawa.ca>
Message-ID: <525EACDD.7070005@gmail.com>

This has been reported before on the bug list 
(https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15481).  The 
message is coming from the methods package, but I don't know if it's a 
bug or ignorable.

Duncan Murdoch

On 16/10/2013 11:03 AM, Prof J C Nash (U30A) wrote:
> In order to have a clean workspace at the start of each chapter of a
> book I'm "knit"ing I've written a little script as follows:
>
> # chapclean.R
> # This cleans up the R workspace
> ilist<-c(".GlobalEnv", "package:stats", "package:graphics",
> "package:grDevices",
> "package:utils", "package:datasets", "package:methods", "Autoloads",
> "package:base")
> print(ilist)
> xlist<-search()[which(!(search() %in% ilist))]
> print(xlist)
> for (ff in xlist){
>      cat("Detach ",ff," which is pos ",as.integer(which(ff ==
> search())),"\n")
>      detach(pos=as.integer(which(ff == search())), unload=TRUE) # ?? do
> we need unload
> }
> rm(list=ls())
>
>
> This appears to "work" fine in my system -- session info is below, but I
> get 30 warnings of the type
>
> 30: In FUN(X[[2L]], ...) :
>     Created a package name, ?2013-10-16 10:56:47?, when none found
>
> Does anyone have ideas why the warnings are being generated?  I'd like
> to avoid suppressing them. Here's the session info.
>
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>    [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>    [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>    [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>    [7] LC_PAPER=C                 LC_NAME=C
>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.1
>   >
>
> John Nash
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Ted.Harding at wlandres.net  Wed Oct 16 17:13:00 2013
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Wed, 16 Oct 2013 16:13:00 +0100 (BST)
Subject: [R] Is there something wrong with R version 3.0.2 (2013-09-25)
	-- "Frisbee Sailing"?
In-Reply-To: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
Message-ID: <XFMail.20131016161300.Ted.Harding@wlandres.net>

On 16-Oct-2013 14:54:00 tom soyer wrote:
> Hi,
> 
> pnorm(-1.53,0,1) under version 3.0.2 gives 0.05155075. I am pretty sure it
> should be 0.063. Is there something wrong with this version of R?
> 
> I am using:
> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: i686-pc-linux-gnu (32-bit)
> -- 
> Tom

If you did exactly as you describe, then something is indeed wrong:

  pnorm(-1.53,0,1)
  # [1] 0.06300836
  [R version 2.11.0 (2010-04-22)]

as you expected.

However:

  qnorm(0.05155075)
  [1] -1.63

so maybe you mistyped "1.63" instead of "1.53"?

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 16-Oct-2013  Time: 16:12:56
This message was sent by XFMail


From rshepard at appl-ecosys.com  Wed Oct 16 17:00:51 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 16 Oct 2013 08:00:51 -0700 (PDT)
Subject: [R] Is there something wrong with R version 3.0.2 (2013-09-25)
 -- "Frisbee Sailing"?
In-Reply-To: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
References: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.00.1310160759590.16005@salmo.appl-ecosys.com>

On Wed, 16 Oct 2013, tom soyer wrote:

> pnorm(-1.53,0,1) under version 3.0.2 gives 0.05155075. I am pretty sure it
> should be 0.063. Is there something wrong with this version of R?

Tom,

   Running 3.0.2 here on Slackware:

> pnorm(-1.53,0,1)
[1] 0.06300836

Rich

-- 
Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
Applied Ecosystem Services, Inc.   |
<http://www.appl-ecosys.com>     Voice: 503-667-4517      Fax: 503-667-8863


From pdalgd at gmail.com  Wed Oct 16 17:17:00 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 16 Oct 2013 17:17:00 +0200
Subject: [R] new dprep package for windows
In-Reply-To: <CAF-JZQtPvm3p-JgvVT0rAdadbqWpm2E4TuHk_KFwwpAfMnLC_g@mail.gmail.com>
References: <CAF-JZQtPvm3p-JgvVT0rAdadbqWpm2E4TuHk_KFwwpAfMnLC_g@mail.gmail.com>
Message-ID: <DF12B065-97CF-4EDC-980E-6E118D081BEB@gmail.com>

Look at

http://cran.r-project.org/web/packages/dprep/index.html

and follow the link. You'll find that

(a) There is a newer version
(b) CRAN no longer carries binaries for this package, presumably because it won't build and the maintainer isn't maintaining it.

So, if you want it enough, you need to

(1) Learn how to build from sources on your platform
(2) Solve whatever issues prevented it from being built by CRAN

Instructions for (1) are in the manuals. Help with (2) might be available from the R-devel list (though not until you have made a serious effort to master (1)).

On Oct 16, 2013, at 16:07 , Babak Bastan wrote:

> Hi experts,
> 
> I need the new version of   dprep package for windows. What I have found is
> version 1.
> 
> if I am installing version 1 I get this error
> 
> *Error: package ?dprep? was built before R 3.0.0: please re-install it*
> *
> *
> Is ther a new version of this package? if not what should I do?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Wed Oct 16 17:47:59 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 16 Oct 2013 08:47:59 -0700
Subject: [R] Is there something wrong with R version 3.0.2 (2013-09-25)
	-- "Frisbee Sailing"?
In-Reply-To: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
References: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
Message-ID: <6ef360ae-219d-47de-acc6-0f7913f8c2f4@email.android.com>

I cannot confirm your report. I get 0.63  under 3.0.2 (2013-09-25), x86_64-pc-linux-gnu (64bit), and x686-pc-linux-gnu (32bit).
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

tom soyer <tom.soyer at gmail.com> wrote:
>Hi,
>
>pnorm(-1.53,0,1) under version 3.0.2 gives 0.05155075. I am pretty sure
>it
>should be 0.063. Is there something wrong with this version of R?
>
>I am using:
>R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>Copyright (C) 2013 The R Foundation for Statistical Computing
>Platform: i686-pc-linux-gnu (32-bit)


From goran.brostrom at umu.se  Wed Oct 16 15:55:06 2013
From: goran.brostrom at umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 16 Oct 2013 15:55:06 +0200
Subject: [R] How to obtain restricted estimates from coxph()?
In-Reply-To: <525E877E.2050500@mayo.edu>
References: <mailman.21.1381917608.4459.r-help@r-project.org>
	<525E877E.2050500@mayo.edu>
Message-ID: <525E9ABA.10200@umu.se>



On 2013-10-16 14:33, Terry Therneau wrote:
>
>
> On 10/16/2013 05:00 AM, r-help-request at r-project.org wrote:
>> Hello,
>>
>> I'm trying to use coxph() function to fit a very simple Cox proportional
>> hazards regression model (only one covariate) but the parameter space is
>> restricted to an open set (0, 1). Can I still obtain a valid estimate by
>> using coxph function in this scenario? If yes, how? Any suggestion would be
>> greatly appreciated. Thanks!!!
>
> Easily:
>      1.  Fit the unrestricted model.  If the solution is in 0-1 you are done.
>      2.  If it is outside, fix the coefficient.  Say that the solution is 1.73, then the
> optimal solution under contraint is 1.

OK, except for the small annoyance that 1 is not a member of the open 
set (interval) (0, 1). Maybe the answer is "No" in this case? Depends on 
what lies in the word 'valid'. If 'MLE', the answer is No.

>          Redo the fit adding the paramters  "init=1, iter=0".  This forces the program to
> give the loglik and etc for the fixed coefficient of 1.0.
>
> Terry Therneau
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ceoriley at gmail.com  Wed Oct 16 17:02:05 2013
From: ceoriley at gmail.com (CEO'Riley)
Date: Wed, 16 Oct 2013 10:02:05 -0500
Subject: [R] Is there something wrong with R version 3.0.2 (2013-09-25)
	-- "Frisbee Sailing"?
In-Reply-To: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
References: <CAACmW3bJ-143=vO_K-6S-1VQOm0HE8yg==U4QCPOTyQFu3=VZQ@mail.gmail.com>
Message-ID: <00ec01ceca80$ae0b16b0$0a214410$@gmail.com>

Tom, 

Under that same version on Windows 7, I receive the following:

> pnorm(-1.53,0,1) 
[1] 0.06300836


R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)


With gratitude,
CEO'Riley Jr.
Charles Ellis O'Riley Jr.

Ambition is a state of permanent dissatisfaction with the present

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of tom soyer
Sent: Wednesday, October 16, 2013 9:54 AM
To: r-help at r-project.org
Subject: [R] Is there something wrong with R version 3.0.2 (2013-09-25) --
"Frisbee Sailing"?

Hi,

pnorm(-1.53,0,1) under version 3.0.2 gives 0.05155075. I am pretty sure it
should be 0.063. Is there something wrong with this version of R?

I am using:
R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: i686-pc-linux-gnu (32-bit)


--
Tom

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Oct 16 18:31:16 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 16 Oct 2013 09:31:16 -0700
Subject: [R] Math notation in a title
In-Reply-To: <1381859560550-4678299.post@n4.nabble.com>
References: <1381859560550-4678299.post@n4.nabble.com>
Message-ID: <070EDC22-1A07-4FF8-BED6-0957E641C316@comcast.net>


On Oct 15, 2013, at 10:52 AM, David Arnold wrote:

> Hi,
> 
> I'd like to put the following in a main title of a plot.
> 
> <http://r.789695.n4.nabble.com/file/n4678299/junk.png> 
> 
> Can someone show me how to do this?

?plotmath

plot(1, main=expression("Pareto Distribution:"~alpha==2*","~italic(y)[italic(m)]==3) )

That italic-y is not as "cursive" as your example, but perhaps you can use a different font. If that is your desire then look at the last examples in ?points. (It always has seemed strange that so much useful stuff about text/font output is located in the help page for points, but there is a link to that page near the end ofhte ?plotmath page.)

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Oct 16 18:39:38 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 16 Oct 2013 09:39:38 -0700
Subject: [R] map with inset
In-Reply-To: <1381920477182-4678341.post@n4.nabble.com>
References: <1381920477182-4678341.post@n4.nabble.com>
Message-ID: <D2DB6310-F31F-4A1C-BBB9-B22A7B14B66B@comcast.net>


On Oct 16, 2013, at 3:47 AM, markw wrote:

> Hi, 
> 
> I am trying to put an inset of North America onto a finer-scale map and
> cannot seem to get the two maps on the same plot.
> 
> the main map is:
> map("worldHires", c("Canada", "USA"), xlim=c(-75, -52), ylim=c(40, 55),
> col="gray90", fill=TRUE)
> map.axes()
> map('rivers', add=TRUE)
> map.scale(-73, 54, relwidth=0.2, ratio=FALSE)
> rect(-59.5, 46.5, -52,52)
> text(-53,51.5,"A")
> rect(-69, 43, -59.5,49.5)
> text(-60, 49, "B") 
> 
> and in the bottom right corner I want the following map scaled so it doesn't
> overlap with my main map:
> map("worldHires", c("Canada", "USA"), xlim=c(-170, -50), ylim=c(24, 90),
> proj="gilbert")
> 
> Any suggestions?

Take a look at eitehr of TeachingDemos or Hmisc packages. I think they both have a `subplot` function (although the functions are not the same.)

-- 

David Winsemius
Alameda, CA, USA


From gunter.berton at gene.com  Wed Oct 16 18:54:00 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 16 Oct 2013 09:54:00 -0700
Subject: [R] map with inset
In-Reply-To: <D2DB6310-F31F-4A1C-BBB9-B22A7B14B66B@comcast.net>
References: <1381920477182-4678341.post@n4.nabble.com>
	<D2DB6310-F31F-4A1C-BBB9-B22A7B14B66B@comcast.net>
Message-ID: <CACk-te1wJPKY7_8T6UC6HpD66d0w4S3_eJDOqeptFr=CHQd9dg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/6ee4f420/attachment.pl>

From smartpink111 at yahoo.com  Wed Oct 16 19:48:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 16 Oct 2013 10:48:11 -0700 (PDT)
Subject: [R] Assign date according to defined time interval
In-Reply-To: <CAHX9w5imUBRrpTqpr-1wVp44QAoDT5UK81VCvXYRbeXoRYtE5A@mail.gmail.com>
References: <CAHX9w5hQPT1sUPHHmBdAhwmjXpBFxBmE1KN1VVy+sNJEPC53Fg@mail.gmail.com>	<1381881601.2929.YahooMailNeo@web142605.mail.bf1.yahoo.com>	<3E75CD86-BCC7-49C3-8C73-EE9CF3AEC4F1@gmail.com>	<1381886848.38390.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAHX9w5imUBRrpTqpr-1wVp44QAoDT5UK81VCvXYRbeXoRYtE5A@mail.gmail.com>
Message-ID: <1381945691.22943.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI Weijia,

Please check whether this is what you wanted.

Weijia <- load("/home/arunksa111/Downloads/arun_help.RData" )
a[sapply(a,is.factor)] <-lapply(a[sapply(a,is.factor)],as.character)
str(a)
?b[sapply(b,is.factor)] <- lapply(b[sapply(b,is.factor)],as.character)
str(b)
?b$DT_ETP <- as.Date(b$DT_ETP,"%d-%b-%y") 
?b$DT_END <- c(b$DT_ETP[-1]-1, b$DT_ETP[length(b$DT_ETP)]+6)
res <- do.call(rbind,lapply(split(a,list(a$COUNTRY,a$SITEID),drop=TRUE),function(x){
x$SCRNDT <- as.Date(x$SCRNDT, "%d-%b-%y") 
do.call(cbind,lapply(split(b,b$TMPT),function(y) {
?sum(x$SCRNDT>= y$DT_ETP & x$SCRNDT <= y$DT_ETP)
}))
?}))

?colnames(res) <- paste0("WEEK",colnames(res))



A.K.




On Wednesday, October 16, 2013 10:48 AM, Weijia Wang <zeleehom at gmail.com> wrote:

Hi, Arun

Here I attached a R object with two dataframes.

The first one is the one I need to count the number of dates that fall into a certain week interval.

For example, 

?? STUDYID COUNTRY SITEID SUBJID?? SCRNDT??? 
1 GRTMD101???? USA???? 13??????? 130101?? ?4-Dec-12?
2 GRTMD101???? USA???? 13?????? ?130102??? 4-Dec-12??? 
3 GRTMD101???? USA???? 13??????? 130103??? 4-Dec-12??
4 GRTMD101???? USA????? 6??????? ?60101??? ??5-Dec-12?
5 GRTMD101???? USA????? 5??????? ?50101??????5-Dec-12???
6 GRTMD101???? USA???? 13??????? 130104??? 6-Dec-12

So I will need to count number so dates under 'SCRNDT' for each unique 'SITEID' that falls into the 
following 'DT_ETP'

?STUDYID?????? DT_ETP??? TMPT 
1 GRTMD101?? 9-Nov-12?? ? 1???????
2 GRTMD101 ?16-Nov-12??? 2????
3 GRTMD101 ?23-Nov-12??? 3???????
4 GRTMD101 ?30-Nov-12??? 4????
5 GRTMD101 ? 7-Dec-12? ?? 5??????
6 GRTMD101 ?14-Dec-12??? 6???

For example, for site 13, the 1st and 2nd SCRNDT both are 4-Dec-12 that falls into the week from '30-Nov-12' to '7-Dec-12', then in the result dataset, it should say, 2 under the variable 'week 4', and the result data frame should look like this:

SITEID WEEK1 WEEK2 WEEK3 WEEK4.......WEEK64?? (The values are just an example)
???? 1?????????? 0??????????? 0????????? 1??????????? 2???????????????? 3
???? 2?????????? 1??????????? 2??????????3??????????? 5???????????????? 6
???? .???????????? .??????????? .?????????? .???????????? .???????????????? .

Here is a code I modified based on the one you sent me, but quite intuitively, and R returns an empty vector to me, lol, 


?library(plyr)
?res <- ddply(a,.(COUNTRY, SITEID), function(x) {
?????? ???? x$SCRNDT <-as.Date(x$SCRNDT,"%d-%b-%y")
???????????????????????????? ? unsplit(lapply(split(b,b$TMPT),function(y) {
????????numweek<-as.numeric(length(unique(b$TMPT)))
????????for (i in 1:numweek) {
???????????????????????????????????????? ????y$DT_ETP <- as.Date(y$DT_ETP, "%d-%b-%y")
???????????????????????????????????????? ????sum(x$SCRNDT > y$DT_ETP[i] & x$SCRNDT <= y$DT_ETP[i+1])}}),?
???????????? b$TMPT)})




I really hope you can teach me on this one again! Thank you so much!!

W





2013/10/15 arun <smartpink111 at yahoo.com>

HI Weijia,
>No problem.
>Let me know if it works.? One slight modification as I noticed that your weeks are not overlapping
>#change
>
>
>
>sum(x$Date > y$from & x$Date <= y$to)
>
>#to
>sum(x$Date >= y$from & x$Date <= y$to
>
>Regards,
>Arun
>
>
>
>
>
>
>On Tuesday, October 15, 2013 8:14 PM, Weijia wang <zeleehom at gmail.com> wrote:
>Thank you Arun! I will try it and get back to you! You are amazing!
>
>Weijia Wang
>
>
>> On Oct 15, 2013, at 8:00 PM, arun <smartpink111 at yahoo.com> wrote:
>>
>> Hi,
>>
>> Please use ?dput() to show the dataset.? Also, it is not clear about how you store the time interval.
>> dat <- read.table(text="
>> GroupID? ? ? ? Date
>> 1? ? ? 1? ? ? 10-Dec-12
>> 2? ? ? 1? ? ? 11-Dec-12
>> 3? ? ? 2? ? ? 13-Dec-12
>> 4? ? ? 2? ? ? 15-Dec-12
>> 5? ? ? 3? ? ? 06-Dec-12
>> 6? ? ? 3? ? ? 19-Dec-12",sep="",header=TRUE,stringsAsFactors=FALSE)
>>
>>
>>
>>? dat2 <- data.frame(Week=1:2, from= c("9-Dec-12", "16-Dec-12"), to=c("15-Dec-12","22-Dec-12"),stringsAsFactors=FALSE)
>>
>> #Check ?findInterval()
>>
>> res <- t(sapply(split(dat,dat$GroupID), function(x) {
>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ?x$Date <-as.Date(x$Date,"%d-%b-%y")
>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? unsplit(lapply(split(dat2,dat2$Week),function(y) {
>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?y$from <- as.Date(y$from, "%d-%b-%y")
>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? y$to <- as.Date(y$to, "%d-%b-%y")
>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(x$Date > y$from & x$Date <= y$to)}),
>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?dat2$Week)
>>? ? ? ? ? ? ? ? ? ? ? ? ? ?}))
>>
>> colnames(res) <- paste0("Week",1:2)
>>? res
>> #? Week1 Week2
>> #1? ? ?2? ? ?0
>> #2? ? ?2? ? ?0
>> #3? ? ?0? ? ?1
>>
>>
>> A.K.
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> On Tuesday, October 15, 2013 6:24 PM, Weijia Wang <zeleehom at gmail.com> wrote:
>> Hi, I have something very interesting:
>>
>> Say I have this:
>>
>> GroupID? ? ? ? ?Date
>> 1? ? ? 1? ? ? ?10-Dec-12
>> 2? ? ? 1? ? ? ?11-Dec-12
>> 3? ? ? 2? ? ? ?13-Dec-12
>> 4? ? ? 2? ? ? ?15-Dec-12
>> 5? ? ? 3? ? ? ?06-Dec-12
>> 6? ? ? 3? ? ? ?19-Dec-12
>>
>> Now, I have time interval,
>>
>> week 1: from 9-Dec-12 to 15-Dec-12,
>>
>> week 2: from 16-Dec-12 to 22-Dec-12, and so on.
>>
>> Obviously, the 1st, 2nd, 3rd, 4th row falls to week 1, 5th rows should not
>> be counted, 6th row falls into week2.
>>
>> Therefore, by GroupID, I will have
>>
>> GroupID=1, Week1=2, Week2=0
>> GroupID=2, Week1=2, Week2=0
>> GroupID=3, Week1=0, Week2=1.
>>
>> I just want to count the valid date that falls into a 7-day week interval,
>> and I shall have new variables for EACH WEEK, and the counts for dates that
>> fall into this week interval.
>>
>> Can anyone please help me on programming this?
>>
>> W
>>
>>? ? ?[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


-- 

--Sent via Gmail

Weijia Wang
Division of Epidemiology

Department of Population Health, School of Medicine
New York University, NY, 10016


From dwinsemius at comcast.net  Wed Oct 16 20:00:46 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 16 Oct 2013 11:00:46 -0700
Subject: [R] new dprep package for windows
In-Reply-To: <DF12B065-97CF-4EDC-980E-6E118D081BEB@gmail.com>
References: <CAF-JZQtPvm3p-JgvVT0rAdadbqWpm2E4TuHk_KFwwpAfMnLC_g@mail.gmail.com>
	<DF12B065-97CF-4EDC-980E-6E118D081BEB@gmail.com>
Message-ID: <C31C4382-6991-4F09-A09E-F6802A2DA3C7@comcast.net>


On Oct 16, 2013, at 8:17 AM, peter dalgaard wrote:

> Look at
> 
> http://cran.r-project.org/web/packages/dprep/index.html
> 
> and follow the link. You'll find that
> 
> (a) There is a newer version
> (b) CRAN no longer carries binaries for this package, presumably because it won't build and the maintainer isn't maintaining it.
> 
> So, if you want it enough, you need to
> 
> (1) Learn how to build from sources on your platform
> (2) Solve whatever issues prevented it from being built by CRAN
> 
> Instructions for (1) are in the manuals. Help with (2) might be available from the R-devel list (though not until you have made a serious effort to master (1)).
> 
> On Oct 16, 2013, at 16:07 , Babak Bastan wrote:
> 
>> Hi experts,
>> 
>> I need the new version of   dprep package for windows. What I have found is
>> version 1.
>> 
>> if I am installing version 1 I get this error
>> 
>> *Error: package ?dprep? was built before R 3.0.0: please re-install it*
>> *
>> *
>> Is ther a new version of this package? if not what should I do?

If you are intimidated by the requirement to learn to fix packages that have Cpp code in them (as this one does a single cpp routine) you could consider alternate routes to satisfaction. Do you need to have the entire package, or do you just need some of the R code that is not dependent on the compiled components of that package? If so, you can just unpack the tar.gz file and copy-paste or source() the needed code into your session.

You could also use a version of R (say r 2.13.x)  that doesn't require a NAMESPACE (since that is the reported failing when I attempted to compile it just now and someone on StackOverflow reported that it could be compiled frm source 2 years ago.) That's a decidedly inferior option. Adding a NAMESPACE isn't _that_ hard. 5000+ package atuhors seem to have mastered it. 


>> 	[[alternative HTML version deleted]]
>> 
(You should also learn to post in plain text.)

-- 
David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Wed Oct 16 20:12:26 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 16 Oct 2013 13:12:26 -0500
Subject: [R] map with inset
In-Reply-To: <CACk-te1wJPKY7_8T6UC6HpD66d0w4S3_eJDOqeptFr=CHQd9dg@mail.gmail.com>
References: <1381920477182-4678341.post@n4.nabble.com>	<D2DB6310-F31F-4A1C-BBB9-B22A7B14B66B@comcast.net>
	<CACk-te1wJPKY7_8T6UC6HpD66d0w4S3_eJDOqeptFr=CHQd9dg@mail.gmail.com>
Message-ID: <02d501ceca9b$44fa5080$ceeef180$@tamu.edu>

I've had difficulty getting subplot() to work with maps (the
TeachingDemos and Hmisc versions seem to be the same). This will
work, but there should be a better way. You have to print the
inset map first or you will get an error message.

require(maps)
require(mapdata)
Layout <- matrix(c(rep(2, 3), 1), 2, 2)
colSize <- c(2, 1.1)
rowSize <- c(2, 1)
layout(Layout, colSize, rowSize)

# Inset map is number 1
par(mar=c(4.5, 1, 1, 4))
map("worldHires", c("Canada", "USA"), xlim=c(-170, -50),
ylim=c(24, 90), proj="gilbert")
box()

# Main map is number 2
par(mar=c(4.1, 4.1, 4.1, 4.1))
map("worldHires", c("Canada", "USA"), xlim=c(-75, -52),
ylim=c(40, 55), col="gray90", fill=TRUE)
map.axes()
map('rivers', add=TRUE)
map.scale(-73, 54, relwidth=0.2, ratio=FALSE)
rect(-59.5, 46.5, -52,52)
text(-53,51.5,"A")
rect(-69, 43, -59.5,49.5)
text(-60, 49, "B") 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Wednesday, October 16, 2013 11:54 AM
To: David Winsemius
Cc: r-help at r-project.org; markw
Subject: Re: [R] map with inset

... and if that doesn't do it, check out the CRAN "spatial" task
view, The
"maptools" package  or others might have what you need with a
friendlier
interface.

Cheers,
Bert


On Wed, Oct 16, 2013 at 9:39 AM, David Winsemius
<dwinsemius at comcast.net>wrote:

>
> On Oct 16, 2013, at 3:47 AM, markw wrote:
>
> > Hi,
> >
> > I am trying to put an inset of North America onto a
finer-scale map and
> > cannot seem to get the two maps on the same plot.
> >
> > the main map is:
> > map("worldHires", c("Canada", "USA"), xlim=c(-75, -52),
ylim=c(40, 55),
> > col="gray90", fill=TRUE)
> > map.axes()
> > map('rivers', add=TRUE)
> > map.scale(-73, 54, relwidth=0.2, ratio=FALSE)
> > rect(-59.5, 46.5, -52,52)
> > text(-53,51.5,"A")
> > rect(-69, 43, -59.5,49.5)
> > text(-60, 49, "B")
> >
> > and in the bottom right corner I want the following map
scaled so it
> doesn't
> > overlap with my main map:
> > map("worldHires", c("Canada", "USA"), xlim=c(-170, -50),
ylim=c(24, 90),
> > proj="gilbert")
> >
> > Any suggestions?
>
> Take a look at eitehr of TeachingDemos or Hmisc packages. I
think they
> both have a `subplot` function (although the functions are not
the same.)
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From cjpauw at gmail.com  Wed Oct 16 20:18:55 2013
From: cjpauw at gmail.com (Christiaan Pauw)
Date: Wed, 16 Oct 2013 20:18:55 +0200
Subject: [R] Extract a predictors form constparty object (CHAID output) in R
Message-ID: <CAJESSmbdT5af79Z9rHgJ0NBiPJb2VnkGUZpar2Ghv80Ogriw9w@mail.gmail.com>

I have a large dataset (questionnaire results) of mostly categorical
variables. I have tested for dependency between the variables using
chi-square test. There are an incomprehensible number of dependencies.
I used the chaid() function in the CHAID package to detect
interactions and separate out (what I hope to be) the underlying
structure of these dependencies for each variable. What typically
happens is that the chi-square test will reveal a large number of
dependencies (say 10-20) for a variable and the chaid function will
reduce this to something much more comprehensible (say 3-5). What I
want to do is to extract the names of those variable that were shown
to be relevant in the chaid() results.

The chaid() output is in the form of a constparty object. My question
is how to extract the variable names associated with the nodes in such
an object.

Here is a self contained code example:

library(evtree) # for the ContraceptiveChoice dataset
library(CHAID)
library(vcd)
library(MASS)

data("ContraceptiveChoice")
longform <- formula(contraceptive_method_used ~ wifes_education +
                 husbands_education +  wifes_religion + wife_now_working +
                 husbands_occupation + standard_of_living_index +
media_exposure)
z <- chaid(longform, data = ContraceptiveChoice)
# plot(z)
z
# This is the part I want to do programatically
shortform <- formula(contraceptive_method_used ~ wifes_education +
husbands_occupation)
# The thing I want is a programatic way to extract 'shortform'  from 'z'

# Examples of use of 'shortfom'
loglm(shortform, data = ContraceptiveChoice)

Thanks in advance
Christiaan
-- 
Christiaan Pauw
Nova Institute
www.nova.org.za


From katherine_gobin at yahoo.com  Wed Oct 16 18:41:45 2013
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Thu, 17 Oct 2013 00:41:45 +0800 (SGT)
Subject: [R] How to write an error to output
In-Reply-To: <CAAxdm-5vnErQnMjE3h8Q=4UrEujLiCCK9fu-uLmEGc1gao19SQ@mail.gmail.com>
References: <1381921269.27387.YahooMailNeo@web193204.mail.sg3.yahoo.com>
	<CAAxdm-5vnErQnMjE3h8Q=4UrEujLiCCK9fu-uLmEGc1gao19SQ@mail.gmail.com>
Message-ID: <1381941705.82591.YahooMailNeo@web193206.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/866ccf7c/attachment.pl>

From curtisburkhalter at gmail.com  Wed Oct 16 20:30:32 2013
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Wed, 16 Oct 2013 14:30:32 -0400
Subject: [R] problem with MLE estimation using Kalman filter
Message-ID: <CAJmwvUYucBy0uQNG_-1thF0EUUS+r4EDFeTMOywsk4ucZAxW1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/8ec99cc7/attachment.pl>

From i.visser at uva.nl  Wed Oct 16 20:38:43 2013
From: i.visser at uva.nl (Ingmar Visser)
Date: Wed, 16 Oct 2013 20:38:43 +0200
Subject: [R] problem with MLE estimation using Kalman filter
In-Reply-To: <CAJmwvUYucBy0uQNG_-1thF0EUUS+r4EDFeTMOywsk4ucZAxW1A@mail.gmail.com>
References: <CAJmwvUYucBy0uQNG_-1thF0EUUS+r4EDFeTMOywsk4ucZAxW1A@mail.gmail.com>
Message-ID: <CABmqZHPeme6Kg9JN0GxuoKEggDOwv1E8X61owwg2DohnGsDO+Q@mail.gmail.com>

On Wed, Oct 16, 2013 at 8:30 PM, Curtis Burkhalter
<curtisburkhalter at gmail.com> wrote:
> I try to use the mle2 function written for R.  The error message states
> that the argument "minuslog1" is missing with no default, but I've


The argument is minuslogl

Note: l instead of 1

hth, Ingmar


From curtisburkhalter at gmail.com  Wed Oct 16 20:57:40 2013
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Wed, 16 Oct 2013 14:57:40 -0400
Subject: [R] problem with MLE estimation using Kalman filter
In-Reply-To: <CABmqZHPeme6Kg9JN0GxuoKEggDOwv1E8X61owwg2DohnGsDO+Q@mail.gmail.com>
References: <CAJmwvUYucBy0uQNG_-1thF0EUUS+r4EDFeTMOywsk4ucZAxW1A@mail.gmail.com>
	<CABmqZHPeme6Kg9JN0GxuoKEggDOwv1E8X61owwg2DohnGsDO+Q@mail.gmail.com>
Message-ID: <CAJmwvUZXEcASgku_TSNMQYBZWKaW9pmrTxdK98XG2_wa0b52iw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/24ff9bda/attachment.pl>

From smartpink111 at yahoo.com  Wed Oct 16 20:58:44 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 16 Oct 2013 11:58:44 -0700 (PDT)
Subject: [R] Assign date according to defined time interval
In-Reply-To: <1381949213.62884.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <CAHX9w5hQPT1sUPHHmBdAhwmjXpBFxBmE1KN1VVy+sNJEPC53Fg@mail.gmail.com>	<1381881601.2929.YahooMailNeo@web142605.mail.bf1.yahoo.com>	<3E75CD86-BCC7-49C3-8C73-EE9CF3AEC4F1@gmail.com>	<1381886848.38390.YahooMailNeo@web142606.mail.bf1.yahoo.com>	<CAHX9w5imUBRrpTqpr-1wVp44QAoDT5UK81VCvXYRbeXoRYtE5A@mail.gmail.com>	<1381945691.22943.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAHX9w5hN3=HgxzLD87rrNM0DyhMr=6totyou24dhZXA=PiySXg@mail.gmail.com>
	<1381949213.62884.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1381949924.46429.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi Weijia,
This will give you the rownames of the split variables.

lst1 <- split(a,list(a$COUNTRY,a$SITEID))


?res <- t(sapply(lst1,function(x) {
??? ??? ??? ??? x$SCRNDT <- as.Date(x$SCRNDT, "%d-%b-%y")
??? ??? ??? ??? unlist(lapply(split(b,b$TMPT),function(y){
??? ??? ??? ??? ? sum(x$SCRNDT >= y$DT_ETP & x$SCRNDT <= y$DT_END)
??? ??? ??? ??? ??? }))
??? ??? ??? ??? ?}))
?colnames(res) <- paste0("WEEK",colnames(res))
?res[5:8,1:4]
#????? WEEK1 WEEK2 WEEK3 WEEK4
#USA.5???? 0???? 0???? 0???? 4
#USA.6???? 0???? 0???? 0???? 1
#USA.8???? 0???? 0???? 0???? 0
#USA.9???? 0???? 0???? 0???? 0


A.K.




On , arun <smartpink111 at yahoo.com> wrote:
Yes, Sorry a typo.? I was in a hurry when I sent it.









On Wednesday, October 16, 2013 2:32 PM, Weijia Wang <zeleehom at gmail.com> wrote:

Arun

I think you mean 

?sum(x$SCRNDT>= y$DT_ETP & x$SCRNDT <= y$DT_END)

instead of DT_ETP at the end of this line, right?

W



2013/10/16 arun <smartpink111 at yahoo.com>

HI Weijia,
>
>Please check whether this is what you wanted.
>
>Weijia <- load("/home/arunksa111/Downloads/arun_help.RData" )
>a[sapply(a,is.factor)] <-lapply(a[sapply(a,is.factor)],as.character)
>str(a)
>?b[sapply(b,is.factor)] <- lapply(b[sapply(b,is.factor)],as.character)
>str(b)
>?b$DT_ETP <- as.Date(b$DT_ETP,"%d-%b-%y")
>?b$DT_END <- c(b$DT_ETP[-1]-1, b$DT_ETP[length(b$DT_ETP)]+6)
>res <- do.call(rbind,lapply(split(a,list(a$COUNTRY,a$SITEID),drop=TRUE),function(x){
>x$SCRNDT <- as.Date(x$SCRNDT, "%d-%b-%y")
>do.call(cbind,lapply(split(b,b$TMPT),function(y) {
>?sum(x$SCRNDT>= y$DT_ETP & x$SCRNDT <= y$DT_ETP)
>}))
>?}))
>
>?colnames(res) <- paste0("WEEK",colnames(res))
>
>
>
>A.K.
>
>
>
>
>
>On Wednesday, October 16, 2013 10:48 AM, Weijia Wang <zeleehom at gmail.com> wrote:
>
>Hi, Arun
>
>Here I attached a R object with two dataframes.
>
>The first one is the one I need to count the number of dates that fall into a certain week interval.
>
>For example,
>
>?? STUDYID COUNTRY SITEID SUBJID?? SCRNDT???
>1 GRTMD101???? USA???? 13??????? 130101?? ?4-Dec-12?
>2 GRTMD101???? USA???? 13?????? ?130102??? 4-Dec-12???
>3 GRTMD101???? USA???? 13??????? 130103??? 4-Dec-12??
>4 GRTMD101???? USA????? 6??????? ?60101??? ??5-Dec-12?
>5 GRTMD101???? USA????? 5??????? ?50101??????5-Dec-12???
>6 GRTMD101???? USA???? 13??????? 130104??? 6-Dec-12
>
>So I will need to count number so dates under 'SCRNDT' for each unique 'SITEID' that falls into the
>following 'DT_ETP'
>
>?STUDYID?????? DT_ETP??? TMPT
>1 GRTMD101?? 9-Nov-12?? ? 1???????
>2 GRTMD101 ?16-Nov-12??? 2????
>3 GRTMD101 ?23-Nov-12??? 3???????
>4 GRTMD101 ?30-Nov-12??? 4????
>5 GRTMD101 ? 7-Dec-12? ?? 5??????
>6 GRTMD101 ?14-Dec-12??? 6???
>
>For example, for site 13, the 1st and 2nd SCRNDT both are 4-Dec-12 that falls into the week from '30-Nov-12' to '7-Dec-12', then in the result dataset, it should say, 2 under the variable 'week 4', and the result data frame should look like this:
>
>SITEID WEEK1 WEEK2 WEEK3 WEEK4.......WEEK64?? (The values are just an example)
>???? 1?????????? 0??????????? 0????????? 1??????????? 2???????????????? 3
>???? 2?????????? 1??????????? 2??????????3??????????? 5???????????????? 6
>???? .???????????? .??????????? .?????????? .???????????? .???????????????? .
>
>Here is a code I modified based on the one you sent me, but quite intuitively, and R returns an empty vector to me, lol,
>
>
>?library(plyr)
>?res <- ddply(a,.(COUNTRY, SITEID), function(x) {
>?????? ???? x$SCRNDT <-as.Date(x$SCRNDT,"%d-%b-%y")
>???????????????????????????? ? unsplit(lapply(split(b,b$TMPT),function(y) {
>????????numweek<-as.numeric(length(unique(b$TMPT)))
>????????for (i in 1:numweek) {
>???????????????????????????????????????? ????y$DT_ETP <- as.Date(y$DT_ETP, "%d-%b-%y")
>???????????????????????????????????????? ????sum(x$SCRNDT > y$DT_ETP[i] & x$SCRNDT <= y$DT_ETP[i+1])}}),?
>???????????? b$TMPT)})
>
>
>
>
>I really hope you can teach me on this one again! Thank you so much!!
>
>W
>
>
>
>
>
>2013/10/15 arun <smartpink111 at yahoo.com>
>
>HI Weijia,
>>No problem.
>>Let me know if it works.? One slight modification as I noticed that your weeks are not overlapping
>>#change
>>
>>
>>
>>sum(x$Date > y$from & x$Date <= y$to)
>>
>>#to
>>sum(x$Date >= y$from & x$Date <= y$to
>>
>>Regards,
>>Arun
>>
>>
>>
>>
>>
>>
>>On Tuesday, October 15, 2013 8:14 PM, Weijia wang <zeleehom at gmail.com> wrote:
>>Thank you Arun! I will try it and get back to you! You are amazing!
>>
>>Weijia Wang
>>
>>
>>> On Oct 15, 2013, at 8:00 PM, arun <smartpink111 at yahoo.com> wrote:
>>>
>>> Hi,
>>>
>>> Please use ?dput() to show the dataset.? Also, it is not clear about how you store the time interval.
>>> dat <- read.table(text="
>>> GroupID? ? ? ? Date
>>> 1? ? ? 1? ? ? 10-Dec-12
>>> 2? ? ? 1? ? ? 11-Dec-12
>>> 3? ? ? 2? ? ? 13-Dec-12
>>> 4? ? ? 2? ? ? 15-Dec-12
>>> 5? ? ? 3? ? ? 06-Dec-12
>>> 6? ? ? 3? ? ? 19-Dec-12",sep="",header=TRUE,stringsAsFactors=FALSE)
>>>
>>>
>>>
>>>? dat2 <- data.frame(Week=1:2, from= c("9-Dec-12", "16-Dec-12"), to=c("15-Dec-12","22-Dec-12"),stringsAsFactors=FALSE)
>>>
>>> #Check ?findInterval()
>>>
>>> res <- t(sapply(split(dat,dat$GroupID), function(x) {
>>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ?x$Date <-as.Date(x$Date,"%d-%b-%y")
>>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? unsplit(lapply(split(dat2,dat2$Week),function(y) {
>>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?y$from <- as.Date(y$from, "%d-%b-%y")
>>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? y$to <- as.Date(y$to, "%d-%b-%y")
>>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sum(x$Date > y$from & x$Date <= y$to)}),
>>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?dat2$Week)
>>>? ? ? ? ? ? ? ? ? ? ? ? ? ?}))
>>>
>>> colnames(res) <- paste0("Week",1:2)
>>>? res
>>> #? Week1 Week2
>>> #1? ? ?2? ? ?0
>>> #2? ? ?2? ? ?0
>>> #3? ? ?0? ? ?1
>>>
>>>
>>> A.K.
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> On Tuesday, October 15, 2013 6:24 PM, Weijia Wang <zeleehom at gmail.com> wrote:
>>> Hi, I have something very interesting:
>>>
>>> Say I have this:
>>>
>>> GroupID? ? ? ? ?Date
>>> 1? ? ? 1? ? ? ?10-Dec-12
>>> 2? ? ? 1? ? ? ?11-Dec-12
>>> 3? ? ? 2? ? ? ?13-Dec-12
>>> 4? ? ? 2? ? ? ?15-Dec-12
>>> 5? ? ? 3? ? ? ?06-Dec-12
>>> 6? ? ? 3? ? ? ?19-Dec-12
>>>
>>> Now, I have time interval,
>>>
>>> week 1: from 9-Dec-12 to 15-Dec-12,
>>>
>>> week 2: from 16-Dec-12 to 22-Dec-12, and so on.
>>>
>>> Obviously, the 1st, 2nd, 3rd, 4th row falls to week 1, 5th rows should not
>>> be counted, 6th row falls into week2.
>>>
>>> Therefore, by GroupID, I will have
>>>
>>> GroupID=1, Week1=2, Week2=0
>>> GroupID=2, Week1=2, Week2=0
>>> GroupID=3, Week1=0, Week2=1.
>>>
>>> I just want to count the valid date that falls into a 7-day week interval,
>>> and I shall have new variables for EACH WEEK, and the counts for dates that
>>> fall into this week interval.
>>>
>>> Can anyone please help me on programming this?
>>>
>>> W
>>>
>>>? ? ?[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
>
>--
>
>--Sent via Gmail
>
>Weijia Wang
>Division of Epidemiology
>
>Department of Population Health, School of Medicine
>New York University, NY, 10016
>


-- 

--Sent via Gmail

Weijia Wang
Division of Epidemiology

Department of Population Health, School of Medicine
New York University, NY, 10016


From murdoch.duncan at gmail.com  Wed Oct 16 21:12:33 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 16 Oct 2013 15:12:33 -0400
Subject: [R] problem with MLE estimation using Kalman filter
In-Reply-To: <CAJmwvUZXEcASgku_TSNMQYBZWKaW9pmrTxdK98XG2_wa0b52iw@mail.gmail.com>
References: <CAJmwvUYucBy0uQNG_-1thF0EUUS+r4EDFeTMOywsk4ucZAxW1A@mail.gmail.com>	<CABmqZHPeme6Kg9JN0GxuoKEggDOwv1E8X61owwg2DohnGsDO+Q@mail.gmail.com>
	<CAJmwvUZXEcASgku_TSNMQYBZWKaW9pmrTxdK98XG2_wa0b52iw@mail.gmail.com>
Message-ID: <525EE521.5000401@gmail.com>

On 16/10/2013 2:57 PM, Curtis Burkhalter wrote:
> Thanks, that always gets me for some reason.  Now when I run it though I
> get an error message at the very end that states "could not find function
> "M.n". I don't understand why I'm getting this message b/c there is no
> where that calls a function named "M.n" and I don't define a function with
> that name either.

You have this in your code:

M.n(1-M.n/K)

I imagine you want a * in there:

M.n*(1 - M.n/K)

Duncan Murdoch

>
> Thanks
>
>
>
> On Wed, Oct 16, 2013 at 2:38 PM, Ingmar Visser <i.visser at uva.nl> wrote:
>
> > On Wed, Oct 16, 2013 at 8:30 PM, Curtis Burkhalter
> > <curtisburkhalter at gmail.com> wrote:
> > > I try to use the mle2 function written for R.  The error message states
> > > that the argument "minuslog1" is missing with no default, but I've
> >
> >
> > The argument is minuslogl
> >
> > Note: l instead of 1
> >
> > hth, Ingmar
> >
>
>
>


From curtisburkhalter at gmail.com  Wed Oct 16 21:21:11 2013
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Wed, 16 Oct 2013 15:21:11 -0400
Subject: [R] problem with MLE estimation using Kalman filter
In-Reply-To: <525EE521.5000401@gmail.com>
References: <CAJmwvUYucBy0uQNG_-1thF0EUUS+r4EDFeTMOywsk4ucZAxW1A@mail.gmail.com>
	<CABmqZHPeme6Kg9JN0GxuoKEggDOwv1E8X61owwg2DohnGsDO+Q@mail.gmail.com>
	<CAJmwvUZXEcASgku_TSNMQYBZWKaW9pmrTxdK98XG2_wa0b52iw@mail.gmail.com>
	<525EE521.5000401@gmail.com>
Message-ID: <CAJmwvUat_P-e4Fxsk=YFni7oZ5uUpniJqa6-vSHGEWL8UCbCvA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/289f088b/attachment.pl>

From karl.fetter at gmail.com  Wed Oct 16 20:59:02 2013
From: karl.fetter at gmail.com (Karl Fetter)
Date: Wed, 16 Oct 2013 14:59:02 -0400
Subject: [R] identifying which column an observation comes from?
Message-ID: <CACZQHzzUVkQs=2ysFzQHda1t8yz10VzYQk5TVrDSDgu81WUV9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/90fe44f2/attachment.pl>

From filewod at gmail.com  Wed Oct 16 21:08:59 2013
From: filewod at gmail.com (Ben Filewod)
Date: Wed, 16 Oct 2013 12:08:59 -0700 (PDT)
Subject: [R] Ylim problem - plot.correlog, ncf package
In-Reply-To: <1344699681439-4640044.post@n4.nabble.com>
References: <1344699681439-4640044.post@n4.nabble.com>
Message-ID: <e528200a-44e8-4592-aafe-bf909b4044bd@googlegroups.com>

Hi Pyh- having the same problem- did you ever find a solution?

Cheers,
Ben

On Saturday, August 11, 2012 8:41:21 AM UTC-7, Pyhrell wrote:
>
> Hi, 
>
> I'm doing cross-correlation correlograms with the ncf package. I have four 
> study sites ; four correlograms. 
> I'd like to get the same y scale for the four of them... only, using 
> "ylim=c(-1,1)" does not change the y scale never and I don't know why. I 
> tried with plot() too. 
>
> Is there another option to change the ylim in plots ? 
>
> Example with only one correlog (all work but ylim). They all have the same 
> form. 
>
> cross_calf2 <- correlog(calf2$X,calf2$Y, calf2$species1, calf2$species2, 
> increment=2) 
> plot.correlog(cross_calf2,ylim=c(-1,1)) 
>
> Thanks ! 
>
> Pyh. 
>
>
>
> -- 
> View this message in context: 
> http://r.789695.n4.nabble.com/Ylim-problem-plot-correlog-ncf-package-tp4640044.html 
> Sent from the R help mailing list archive at Nabble.com. 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From smartpink111 at yahoo.com  Wed Oct 16 21:49:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 16 Oct 2013 12:49:24 -0700 (PDT)
Subject: [R] identifying which column an observation comes from?
In-Reply-To: <CACZQHzzUVkQs=2ysFzQHda1t8yz10VzYQk5TVrDSDgu81WUV9Q@mail.gmail.com>
References: <CACZQHzzUVkQs=2ysFzQHda1t8yz10VzYQk5TVrDSDgu81WUV9Q@mail.gmail.com>
Message-ID: <1381952964.36108.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:

ind <- which(mat==1,arr.ind=TRUE)[,2]
dat1<- data.frame(Code=names(ind),ind=ind,stringsAsFactors=FALSE)
?row.names(dat1) <- 1:nrow(dat1)
A.K.





On Wednesday, October 16, 2013 3:29 PM, Karl Fetter <karl.fetter at gmail.com> wrote:
Hello,

I have a matrix of samples (rows) and haplotypes (columns), where 0
indicates that a sample does not posses that columns haplotype and 1
indicates it does. So sample1 has 0's for every column, except the column
that represents haplotype X, and it has a 1.


I want a length(sample) x 2 dataframe that tells me which samples have what
haplotype.

I need some way of identifying for every row, where is the 1? And then
print that information in a new column so I can see what row and which
haplotype.

Here is an example of what I mean:

mat <- matrix(data = c(1,0,0,0,1,0,0,0,1), nrow = 3, byrow = T)

rownames(mat) <- c("AL", "MS", "FL")

> mat

?  [,1] [,2] [,3]

AL? ? 1? ? 0? ? 0

MS? ? 0? ? 1? ? 0

FL? ? 0? ? 0? ? 1


How can I make a data frame like this:

AL 1

MS 2

FL 3


Thanks for your ideas and time,

Karl

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From gunter.berton at gene.com  Wed Oct 16 22:18:11 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 16 Oct 2013 13:18:11 -0700
Subject: [R] identifying which column an observation comes from?
In-Reply-To: <1381952964.36108.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CACZQHzzUVkQs=2ysFzQHda1t8yz10VzYQk5TVrDSDgu81WUV9Q@mail.gmail.com>
	<1381952964.36108.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CACk-te272==qOz2j5bDh3heTOuZX88SSKdU_iyjWeTraN1sGoA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/af90b04a/attachment.pl>

From smartpink111 at yahoo.com  Wed Oct 16 22:47:21 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 16 Oct 2013 13:47:21 -0700 (PDT)
Subject: [R] identifying which column an observation comes from?
In-Reply-To: <CACk-te272==qOz2j5bDh3heTOuZX88SSKdU_iyjWeTraN1sGoA@mail.gmail.com>
References: <CACZQHzzUVkQs=2ysFzQHda1t8yz10VzYQk5TVrDSDgu81WUV9Q@mail.gmail.com>	<1381952964.36108.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CACk-te272==qOz2j5bDh3heTOuZX88SSKdU_iyjWeTraN1sGoA@mail.gmail.com>
Message-ID: <1381956441.61776.YahooMailNeo@web142604.mail.bf1.yahoo.com>

In cases like these:

mat <- matrix(data = c(1,0,0,0,1,0,0,0,1,1,1,0), nrow = 3, byrow = T)
? rownames(mat) <- c("AL", "MS", "FL")

rowSums(col(mat) * mat)
#AL MS FL 
# 1? 1? 6 

A.K.




On Wednesday, October 16, 2013 4:18 PM, Bert Gunter <gunter.berton at gene.com> wrote:

?col

rowSums(col(mat) * mat)

produces a named vector that you can convert to a data frame if you like, although it's really not necessary.

Cheers,
Bert




On Wed, Oct 16, 2013 at 12:49 PM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>Try:
>
>ind <- which(mat==1,arr.ind=TRUE)[,2]
>dat1<- data.frame(Code=names(ind),ind=ind,stringsAsFactors=FALSE)
>?row.names(dat1) <- 1:nrow(dat1)
>A.K.
>
>
>
>
>
>On Wednesday, October 16, 2013 3:29 PM, Karl Fetter <karl.fetter at gmail.com> wrote:
>Hello,
>
>I have a matrix of samples (rows) and haplotypes (columns), where 0
>indicates that a sample does not posses that columns haplotype and 1
>indicates it does. So sample1 has 0's for every column, except the column
>that represents haplotype X, and it has a 1.
>
>
>I want a length(sample) x 2 dataframe that tells me which samples have what
>haplotype.
>
>I need some way of identifying for every row, where is the 1? And then
>print that information in a new column so I can see what row and which
>haplotype.
>
>Here is an example of what I mean:
>
>mat <- matrix(data = c(1,0,0,0,1,0,0,0,1), nrow = 3, byrow = T)
>
>rownames(mat) <- c("AL", "MS", "FL")
>
>> mat
>
>? ?[,1] [,2] [,3]
>
>AL? ? 1? ? 0? ? 0
>
>MS? ? 0? ? 1? ? 0
>
>FL? ? 0? ? 0? ? 1
>
>
>How can I make a data frame like this:
>
>AL 1
>
>MS 2
>
>FL 3
>
>
>Thanks for your ideas and time,
>
>Karl
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From rissa_r at gmx.ch  Wed Oct 16 20:23:25 2013
From: rissa_r at gmx.ch (rissa)
Date: Wed, 16 Oct 2013 11:23:25 -0700 (PDT)
Subject: [R] Problem with lapply
In-Reply-To: <1381866995.73030.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1381856138636-4678290.post@n4.nabble.com>
	<1381861968.42451.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1381864359746-4678305.post@n4.nabble.com>
	<1381866995.73030.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1381947805363-4678371.post@n4.nabble.com>

Ah ok, I see the problem! Thank you again!



--
View this message in context: http://r.789695.n4.nabble.com/Problem-with-lapply-tp4678290p4678371.html
Sent from the R help mailing list archive at Nabble.com.


From jfox at mcmaster.ca  Wed Oct 16 23:28:16 2013
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 16 Oct 2013 17:28:16 -0400
Subject: [R] Workshop: structural equation modeling in R
Message-ID: <004201cecab6$a0c50c50$e24f24f0$@mcmaster.ca>

Dear r-help list members,

I'm teaching a one-day workshop on "An Introduction to Structural Equation
Modeling with the sem Package for R" at McMaster University in Hamilton,
Ontario, Canada, on November 22. The workshop is open to non-McMaster
attendees at a small charge. Further information, including on how to
register, is in the attached poster.

Best,
 John

-----------------------------------------------
John Fox
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Fox-sem-poster.pdf
Type: application/pdf
Size: 28453 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/293634e4/attachment.pdf>

From charles.santana at gmail.com  Wed Oct 16 23:57:53 2013
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Wed, 16 Oct 2013 23:57:53 +0200
Subject: [R] Plot time series data irregularly hourly-spaced
Message-ID: <CAH-FEniLVhzw3s6m+0gOQL9-T1Gefw2ZCXWaMQXhCYJ4xRJX6Q@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/36fe249f/attachment.pl>

From r.turner at auckland.ac.nz  Thu Oct 17 00:15:58 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 17 Oct 2013 11:15:58 +1300
Subject: [R] Small p from binomial probability function.
In-Reply-To: <142413609C0A60488585AB47438ECD9D015C0592@ueastfexch01.UEA.AC.UK>
References: <142413609C0A60488585AB47438ECD9D015BE871@ueastfexch01.UEA.AC.UK>,
	<45FE3A4B-86AB-49A4-B4E4-05B2479953A8@collocations.de>
	<142413609C0A60488585AB47438ECD9D015BEA44@ueastfexch01.UEA.AC.UK>,
	<52575041.2090304@vodafone.co.nz>
	<142413609C0A60488585AB47438ECD9D015C0592@ueastfexch01.UEA.AC.UK>
Message-ID: <525F101E.30801@auckland.ac.nz>

On 10/16/13 23:56, Benjamin Ward (ENV) wrote:
> Hi,
>
> Thanks again for your answers, just so as I can get clear what is happening, with the uniroot method, I'm defining a function in which the binomial probability function pbinom is present but in addition p0 is subtracted from the result - in this case p0 is the large P I want to plug in so 0.05, 0.50 and 0.95, or even just 0.05 and 0.95? Then uniroot finds the root of this function and doing so find me the small p I need?

I believe that you have a correct understanding.  To beat it to death:

     * you want/need to solve an equation of the form

         f(p) = p0

        for p.

     * the uniroot() function solves equations of the form

         g(p) = 0

        for p

     * therefore define g(p) = f(p) - p0 and apply uniroot() to the 
function g(.).

HTH.

     cheers,

     Rolf Turner


From smartpink111 at yahoo.com  Thu Oct 17 01:00:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 16 Oct 2013 16:00:57 -0700 (PDT)
Subject: [R] Plot time series data irregularly hourly-spaced
In-Reply-To: <CAH-FEniLVhzw3s6m+0gOQL9-T1Gefw2ZCXWaMQXhCYJ4xRJX6Q@mail.gmail.com>
References: <CAH-FEniLVhzw3s6m+0gOQL9-T1Gefw2ZCXWaMQXhCYJ4xRJX6Q@mail.gmail.com>
Message-ID: <1381964457.8321.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

This may get you started.
testtime1 <- factor(testtime,levels=testtime)

?plot(as.numeric(testtime1),var,type="b",xlab="Time",ylab="Var",xaxt="n")
?axis(1,at= as.numeric(testtime1), labels=levels(testtime1)) ## labels are not spaced according to time interval

#Another idea would be: 

testtime2 <- strptime(testtime,"%H:%M:%S")
testtime2[testtime2$hour < 20] <- testtime2[testtime2$hour < 20]+ 24*60*60

?plot(testtime2,var,xaxt="n",type="b")
?axis.POSIXct(1,testtime2,format="%H:%M:%S")


A.K.




On Wednesday, October 16, 2013 6:00 PM, Charles Novaes de Santana <charles.santana at gmail.com> wrote:
Dear all,

I have a time series of data that I would like to represent in a plot. But
I am facing some problems to do it because the time is represented in
"hours", it can start in one day and end in another day, and it is not
regularly spaced.

My problem is that when I plot my data, my X-axis always starts from the
lower values of my time data. For example, I would like to plot data that
starts at 20:00:00 and ends at 01:00:00, but R considers that 01:00:00 is
lower than 21:00:00 and my plot is kind of "crossed over time".

Please try this example to see it graphically:

testtime<-c("20:00:00","22:10:00","22:20:00","23:15:00","23:43:00","00:00:00","00:51:00","01:00:00")
var<-runif(length(testtime),0,1)
plot(strptime(testtime,format="%H:%M:%S"),var,type="b",xlab="Time",ylab="Var")

In this case, I would like to have a plot that starts at 20:00:00 and ends
at 01:00:00.

Does anybody know how to make R understand that 00:00:00 comes after
20:00:00 in this case? Or at least does anybody know a tip to make a plot
with this kind of X-axis?

Thanks for your time and thanks in advance for any help.

Best regards,

Charles
-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From Jason.Law at portlandoregon.gov  Thu Oct 17 02:04:21 2013
From: Jason.Law at portlandoregon.gov (Law, Jason)
Date: Wed, 16 Oct 2013 17:04:21 -0700
Subject: [R] Plot time series data irregularly hourly-spaced
In-Reply-To: <CAH-FEniLVhzw3s6m+0gOQL9-T1Gefw2ZCXWaMQXhCYJ4xRJX6Q@mail.gmail.com>
References: <CAH-FEniLVhzw3s6m+0gOQL9-T1Gefw2ZCXWaMQXhCYJ4xRJX6Q@mail.gmail.com>
Message-ID: <0EFBC7C31DB4F24F8CAC48136A1762D70184EE24A708@MAIL2.rose.portland.local>

 You just need the date, otherwise how would it know what time comes first?  In strptime(), a date is being assumed.

Try this:

testtime<-c("20:00:00","22:10:00","22:20:00","23:15:00","23:43:00","00:00:00","00:51:00","01:00:00")
testday <- rep(Sys.Date() - c(1,0), times = c(5,3))
plot(as.POSIXct(paste(testday, testtime)), var)

Jason

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Charles Novaes de Santana
Sent: Wednesday, October 16, 2013 2:58 PM
To: r-help at r-project.org
Subject: [R] Plot time series data irregularly hourly-spaced

Dear all,

I have a time series of data that I would like to represent in a plot. But I am facing some problems to do it because the time is represented in "hours", it can start in one day and end in another day, and it is not regularly spaced.

My problem is that when I plot my data, my X-axis always starts from the lower values of my time data. For example, I would like to plot data that starts at 20:00:00 and ends at 01:00:00, but R considers that 01:00:00 is lower than 21:00:00 and my plot is kind of "crossed over time".

Please try this example to see it graphically:

testtime<-c("20:00:00","22:10:00","22:20:00","23:15:00","23:43:00","00:00:00","00:51:00","01:00:00")
var<-runif(length(testtime),0,1)
plot(strptime(testtime,format="%H:%M:%S"),var,type="b",xlab="Time",ylab="Var")

In this case, I would like to have a plot that starts at 20:00:00 and ends at 01:00:00.

Does anybody know how to make R understand that 00:00:00 comes after 20:00:00 in this case? Or at least does anybody know a tip to make a plot with this kind of X-axis?

Thanks for your time and thanks in advance for any help.

Best regards,

Charles
--
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Oct 17 02:34:29 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 17 Oct 2013 00:34:29 +0000
Subject: [R] Plot time series data irregularly hourly-spaced
In-Reply-To: <0EFBC7C31DB4F24F8CAC48136A1762D70184EE24A708@MAIL2.rose.portland.local>
References: <CAH-FEniLVhzw3s6m+0gOQL9-T1Gefw2ZCXWaMQXhCYJ4xRJX6Q@mail.gmail.com>
	<0EFBC7C31DB4F24F8CAC48136A1762D70184EE24A708@MAIL2.rose.portland.local>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0B89E@PA-MBX01.na.tibco.com>

You could bump up the day each time an hour was less than the previous one.  E.g.,
  testtime <- c("20:00:00","22:10:00","22:20:00","23:15:00","23:43:00","00:00:00","00:51:00","01:00:00")
  var <- seq_along(testtime) # so you know what the plot should look like
  # turn it ino a POSIXlt object so you can do arithmetic on it
  t <- strptime(testtime,format="%H:%M:%S")
  # now add a day each time t[i]<t[i-1]
  td <- t + .difftime(cumsum(c(FALSE, diff(t)<0)), units="days")
  # compare plots
  par(mfrow=c(2,1))
  plot(t,var,type="b",xlab="Time",ylab="Var")
  plot(td,var,type="b",xlab="Time",ylab="Var")
This is dicey because you may have skipped more than one day.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Law, Jason
> Sent: Wednesday, October 16, 2013 5:04 PM
> To: Charles Novaes de Santana; r-help at r-project.org
> Subject: Re: [R] Plot time series data irregularly hourly-spaced
> 
>  You just need the date, otherwise how would it know what time comes first?  In
> strptime(), a date is being assumed.
> 
> Try this:
> 
> testtime<-
> c("20:00:00","22:10:00","22:20:00","23:15:00","23:43:00","00:00:00","00:51:00","01:00:
> 00")
> testday <- rep(Sys.Date() - c(1,0), times = c(5,3))
> plot(as.POSIXct(paste(testday, testtime)), var)
> 
> Jason
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Charles Novaes de Santana
> Sent: Wednesday, October 16, 2013 2:58 PM
> To: r-help at r-project.org
> Subject: [R] Plot time series data irregularly hourly-spaced
> 
> Dear all,
> 
> I have a time series of data that I would like to represent in a plot. But I am facing some
> problems to do it because the time is represented in "hours", it can start in one day and
> end in another day, and it is not regularly spaced.
> 
> My problem is that when I plot my data, my X-axis always starts from the lower values of
> my time data. For example, I would like to plot data that starts at 20:00:00 and ends at
> 01:00:00, but R considers that 01:00:00 is lower than 21:00:00 and my plot is kind of
> "crossed over time".
> 
> Please try this example to see it graphically:
> 
> testtime<-
> c("20:00:00","22:10:00","22:20:00","23:15:00","23:43:00","00:00:00","00:51:00","01:00:
> 00")
> var<-runif(length(testtime),0,1)
> plot(strptime(testtime,format="%H:%M:%S"),var,type="b",xlab="Time",ylab="Var")
> 
> In this case, I would like to have a plot that starts at 20:00:00 and ends at 01:00:00.
> 
> Does anybody know how to make R understand that 00:00:00 comes after 20:00:00 in
> this case? Or at least does anybody know a tip to make a plot with this kind of X-axis?
> 
> Thanks for your time and thanks in advance for any help.
> 
> Best regards,
> 
> Charles
> --
> Um ax?! :)
> 
> --
> Charles Novaes de Santana, PhD
> http://www.imedea.uib-csic.es/~charles
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From yuhanusa at gmail.com  Thu Oct 17 01:08:01 2013
From: yuhanusa at gmail.com (Y)
Date: Wed, 16 Oct 2013 19:08:01 -0400
Subject: [R] How to obtain restricted estimates from coxph()?
In-Reply-To: <525E9ABA.10200@umu.se>
References: <mailman.21.1381917608.4459.r-help@r-project.org>
	<525E877E.2050500@mayo.edu> <525E9ABA.10200@umu.se>
Message-ID: <CAHJ49whqFq-pi64bH+Eq5F-v6mEy234ExTftEDykKUbYxK9aCQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131016/49986e4c/attachment.pl>

From tcharlton at aquafirma.com.au  Thu Oct 17 01:03:12 2013
From: tcharlton at aquafirma.com.au (timscharlton)
Date: Wed, 16 Oct 2013 16:03:12 -0700 (PDT)
Subject: [R] Error message after following Appendix A R-intro
Message-ID: <1381964592631-4678394.post@n4.nabble.com>

I am new to R and tried to go through the commands shown at App. A of
"R-intro" (p.78).  

I get the following error message.

> fm<-1m(y~x,data=dummy)
Error: unexpected symbol in "fm<-1m"

I suspect it might be related to the tilda.  All the commands in R-intro for
the tilda show it in a superscript postion. From my keyboard I only have the
option as shown above.  

Any help would be much appreciated.

Tim



--
View this message in context: http://r.789695.n4.nabble.com/Error-message-after-following-Appendix-A-R-intro-tp4678394.html
Sent from the R help mailing list archive at Nabble.com.


From jinskip at sfu.ca  Thu Oct 17 02:16:24 2013
From: jinskip at sfu.ca (Jess Inskip)
Date: Thu, 17 Oct 2013 00:16:24 +0000
Subject: [R] using ddply with segmented regression
References: <A780DAF149F5C24EBDFC048B071023B91B8C8423C5@useagan5503p.global.ecolab.corp>
	<1381560093.44823.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<A780DAF149F5C24EBDFC048B071023B91F927790EC@useagan5503p.global.ecolab.corp>
	<F42E84B0-61EA-40ED-8207-B6E20F272041@comcast.net>
	<A780DAF149F5C24EBDFC048B071023B91F9277914F@useagan5503p.global.ecolab.corp>
Message-ID: <loom.20131017T021124-668@post.gmane.org>

Hi Paul,

Thanks for starting this thread.  
I have been struggling with the same plyr problems. 

I have also had some trouble moving onto the next step -
integrating the segmented output with 
ggplot2 or lattice.  Have you had any luck in this? 
There is good documentation on adding lm into 
ggplot, but I am not sure how to go about adding in 
the segmented components.  I have looked into 
the plot.segmented documentation to try to recreate 
the plot call, but I have not had much success 
parsing through the code.  

Thanks a lot,
Jessica


From btupper at bigelow.org  Thu Oct 17 03:20:10 2013
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 16 Oct 2013 21:20:10 -0400
Subject: [R] Error message after following Appendix A R-intro
In-Reply-To: <1381964592631-4678394.post@n4.nabble.com>
References: <1381964592631-4678394.post@n4.nabble.com>
Message-ID: <0431097F-72D7-45D3-9B47-28DCE0B33A8F@bigelow.org>

Hi,

On Oct 16, 2013, at 7:03 PM, timscharlton <tcharlton at aquafirma.com.au> wrote:

> I am new to R and tried to go through the commands shown at App. A of
> "R-intro" (p.78).  
> 
> I get the following error message.
> 
>> fm<-1m(y~x,data=dummy)
> Error: unexpected symbol in "fm<-1m"


I think the example shows the function 'lm', which is an acronym for 'linear model', not '1m', which is an acronym 'one melon'. 
  
Cheers,
Ben

> 
> I suspect it might be related to the tilda.  All the commands in R-intro for
> the tilda show it in a superscript postion. From my keyboard I only have the
> option as shown above.  
> 
> Any help would be much appreciated.
> 
> Tim
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Error-message-after-following-Appendix-A-R-intro-tp4678394.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From dwinsemius at comcast.net  Thu Oct 17 03:22:07 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 16 Oct 2013 18:22:07 -0700
Subject: [R] Error message after following Appendix A R-intro
In-Reply-To: <1381964592631-4678394.post@n4.nabble.com>
References: <1381964592631-4678394.post@n4.nabble.com>
Message-ID: <752920E0-3287-4890-9ABB-1FDB18292179@comcast.net>


On Oct 16, 2013, at 4:03 PM, timscharlton wrote:

> I am new to R and tried to go through the commands shown at App. A of
> "R-intro" (p.78).  
> 
> I get the following error message.
> 
>> fm<-1m(y~x,data=dummy)
> Error: unexpected symbol in "fm<-1m"

In some screen fonts it's difficult to tell the difference between a "1" and an "l". You have type 1m thinking it was lm.


> 
> I suspect it might be related to the tilda.

No.

>  All the commands in R-intro for
> the tilda show it in a superscript postion. From my keyboard I only have the
> option as shown above.  
> 
> Any help would be much appreciated.
> 
> Tim
> 
> 
-- 
David Winsemius
Alameda, CA, USA


From kridox at ymail.com  Thu Oct 17 03:27:36 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 17 Oct 2013 10:27:36 +0900
Subject: [R] Error message after following Appendix A R-intro
In-Reply-To: <1381964592631-4678394.post@n4.nabble.com>
References: <1381964592631-4678394.post@n4.nabble.com>
Message-ID: <CAAcyNCyx9=Br0-rybUjuNoo1r-EnDQh254=htvJtSQN9SGi=Lg@mail.gmail.com>

Hello,

The command you have to use is "lm", not "1m".

Regards,
Pascal

On 17 October 2013 08:03, timscharlton <tcharlton at aquafirma.com.au> wrote:
> I am new to R and tried to go through the commands shown at App. A of
> "R-intro" (p.78).
>
> I get the following error message.
>
>> fm<-1m(y~x,data=dummy)
> Error: unexpected symbol in "fm<-1m"
>
> I suspect it might be related to the tilda.  All the commands in R-intro for
> the tilda show it in a superscript postion. From my keyboard I only have the
> option as shown above.
>
> Any help would be much appreciated.
>
> Tim
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Error-message-after-following-Appendix-A-R-intro-tp4678394.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From kmcreed32 at hotmail.com  Thu Oct 17 04:18:38 2013
From: kmcreed32 at hotmail.com (Kimberly Harris-McCoy)
Date: Wed, 16 Oct 2013 22:18:38 -0400
Subject: [R] Reshape
Message-ID: <BAY174-W43F68FA404527D8EE2C25CBD050@phx.gbl>

Hello,
 
I have data frame like the one created below,
 

 ##input data
Person <- c(1,1,1,1,1,1,2,2)
Amount <- c(100,10,100,10,100,10,50,150)
Date <- c("12/01/2012", "12/01/2012", "01/01/2013","01/01/2013","02/01/2013","02/01/2013","12/01/2012","12/01/2012")
df <- data.frame(Person,Amount,Date)
 
I would like to transpose the Amount data so that I can get the total amount paid by person and date.
So, it would look something like:
 
 
##Want it to look like:
 
Person Date              Amt1      Amt2
1          12/01/2012    100       10
1           01/01/2013   100       10
1           02/01/2013   100       10
2          12/01/2012     50        150
 
 
I have been working with reshape, but I am having trouble getting it to look exactly right.
Thank you,
K 		 	   		  

From ekbrown at k-state.edu  Thu Oct 17 05:45:11 2013
From: ekbrown at k-state.edu (Earl Brown)
Date: Wed, 16 Oct 2013 23:45:11 -0400 (EDT)
Subject: [R] saveXML() prefix argument
In-Reply-To: <1341943815.53903331.1381981177281.JavaMail.root@k-state.edu>
Message-ID: <720241366.53903648.1381981511046.JavaMail.root@k-state.edu>

I'm using the "XML" package and specifically the saveXML() function but I can't get the "prefix" argument of saveXML() to work:

library("XML")
concepts <- c("one", "two", "three")
info <- c("info one", "info two", "info three")
root <- newXMLNode("root")
for (i in 1:length(concepts)) {
	cur.concept <- concepts[i]
	cur.info <- info[i]
	cur.tip <- newXMLNode("tip", attrs = c(id = i), parent = root)
	newXMLNode("h1", cur.concept, parent = cur.tip)
	newXMLNode("p", cur.info, parent = cur.tip)
}

# None of the following output a prefix on the first line of the exported document
saveXML(root)
saveXML(root, file = "test.xml")
saveXML(root, file = "test.xml", prefix = '<?xml version="1.0"?>\n')

Am I missing something obvious? Any ideas?

Thanks in advance. Earl Brown

-----
Earl K. Brown, PhD
Assistant Professor of Spanish Linguistics
Advisor, TEFL MA Program
Department of Modern Languages
Kansas State University
www-personal.ksu.edu/~ekbrown


From caciquesamurai at gmail.com  Thu Oct 17 05:54:24 2013
From: caciquesamurai at gmail.com (Raoni Rodrigues)
Date: Thu, 17 Oct 2013 00:54:24 -0300
Subject: [R] Data handling
In-Reply-To: <1381850022.65086.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CAGtwFe0Baw3QzBd72+Gb2cyfymb4oEuV19o9quVd3eaUyN0KbA@mail.gmail.com>
	<1381850022.65086.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CAGtwFe3g4px5WJfSPOmv4o+JrgrKB09Jxb+CwEEFwNU4wZwW9A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/2efd7ae7/attachment.pl>

From smartpink111 at yahoo.com  Thu Oct 17 06:53:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 16 Oct 2013 21:53:22 -0700 (PDT)
Subject: [R] Reshape
In-Reply-To: <BAY174-W43F68FA404527D8EE2C25CBD050@phx.gbl>
References: <BAY174-W43F68FA404527D8EE2C25CBD050@phx.gbl>
Message-ID: <1381985602.62896.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
library(plyr)
?res <- reshape(ddply(df,.(Person),mutate,id=rep(1:2,length(Person)/2)),idvar=c("Person","Date"),timevar="id",direction="wide")
?colnames(res)[3:4] <- paste0("Amt",1:2)
rownames(res) <- 1:nrow(res)

? res
#? Person?????? Date Amt1 Amt2
#1????? 1 12/01/2012? 100?? 10
#2????? 1 01/01/2013? 100?? 10
#3????? 1 02/01/2013? 100?? 10
#4????? 2 12/01/2012?? 50? 150

A.K.


On Wednesday, October 16, 2013 11:54 PM, Kimberly Harris-McCoy <kmcreed32 at hotmail.com> wrote:
Hello,

I have data frame like the one created below,


##input data
Person <- c(1,1,1,1,1,1,2,2)
Amount <- c(100,10,100,10,100,10,50,150)
Date <- c("12/01/2012", "12/01/2012", "01/01/2013","01/01/2013","02/01/2013","02/01/2013","12/01/2012","12/01/2012")
df <- data.frame(Person,Amount,Date)

I would like to transpose the Amount data so that I can get the total amount paid by person and date.
So, it would look something like:


##Want it to look like:

Person Date? ? ? ? ? ? ? Amt1? ? ? Amt2
1? ? ? ? ? 12/01/2012? ? 100? ? ?  10
1? ? ? ? ?  01/01/2013?  100? ? ?  10
1? ? ? ? ?  02/01/2013?  100? ? ?  10
2? ? ? ? ? 12/01/2012? ?  50? ? ? ? 150


I have been working with reshape, but I am having trouble getting it to look exactly right.
Thank you,
K ??? ???  ??? ?  ??? ??? ? 
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Thu Oct 17 07:25:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 16 Oct 2013 22:25:58 -0700 (PDT)
Subject: [R] Reshape
In-Reply-To: <1381985602.62896.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <BAY174-W43F68FA404527D8EE2C25CBD050@phx.gbl>
	<1381985602.62896.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1381987558.81175.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
A minor change to make it a bit more generic.
?res <- reshape(ddply(df,.(Person), mutate,id=((seq_along(Person)-1)%%2+1)),idvar=c("Person","Date"),timevar="id",direction="wide")
? colnames(res)[3:4] <- paste0("Amt",1:2)
?rownames(res) <- 1:nrow(res)


In cases like:
df1 <- rbind(df,data.frame(Person=2,Amount=50,Date="12/02/2012"))

res1 <- reshape(ddply(df1,.(Person), mutate,id=((seq_along(Person)-1)%%2+1)),idvar=c("Person","Date"),timevar="id",direction="wide")
?colnames(res1)[3:4] <- colnames(res)[3:4]
?rownames(res1) <- 1:nrow(res1)
res1
#? Person?????? Date Amt1 Amt2
#1????? 1 12/01/2012? 100?? 10
#2????? 1 01/01/2013? 100?? 10
#3????? 1 02/01/2013? 100?? 10
#4????? 2 12/01/2012?? 50? 150
#5????? 2 12/02/2012?? 50?? NA


A.K.




On Thursday, October 17, 2013 12:53 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
library(plyr)
?res <- reshape(ddply(df,.(Person),mutate,id=rep(1:2,length(Person)/2)),idvar=c("Person","Date"),timevar="id",direction="wide")
?colnames(res)[3:4] <- paste0("Amt",1:2)
rownames(res) <- 1:nrow(res)

? res
#? Person?????? Date Amt1 Amt2
#1????? 1 12/01/2012? 100?? 10
#2????? 1 01/01/2013? 100?? 10
#3????? 1 02/01/2013? 100?? 10
#4????? 2 12/01/2012?? 50? 150

A.K.



On Wednesday, October 16, 2013 11:54 PM, Kimberly Harris-McCoy <kmcreed32 at hotmail.com> wrote:
Hello,

I have data frame like the one created below,


##input data
Person <- c(1,1,1,1,1,1,2,2)
Amount <- c(100,10,100,10,100,10,50,150)
Date <- c("12/01/2012", "12/01/2012", "01/01/2013","01/01/2013","02/01/2013","02/01/2013","12/01/2012","12/01/2012")
df <- data.frame(Person,Amount,Date)

I would like to transpose the Amount data so that I can get the total amount paid by person and date.
So, it would look something like:


##Want it to look like:

Person Date? ? ? ? ? ? ? Amt1? ? ? Amt2
1? ? ? ? ? 12/01/2012? ? 100? ? ?? 10
1? ? ? ? ?? 01/01/2013?? 100? ? ?? 10
1? ? ? ? ?? 02/01/2013?? 100? ? ?? 10
2? ? ? ? ? 12/01/2012? ?? 50? ? ? ? 150


I have been working with reshape, but I am having trouble getting it to look exactly right.
Thank you,
K ??? ???? ??? ?? ??? ??? ? 
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From catalinroibu at gmail.com  Thu Oct 17 09:17:24 2013
From: catalinroibu at gmail.com (catalin roibu)
Date: Thu, 17 Oct 2013 10:17:24 +0300
Subject: [R] extract column's from different dataframe
Message-ID: <CAEW+BDKZdodZuL6as_mtqDEyVLwRFrGbSS+s=n8uBqrquX72aw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/61d0f461/attachment.pl>

From charles.santana at gmail.com  Thu Oct 17 10:56:06 2013
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Thu, 17 Oct 2013 10:56:06 +0200
Subject: [R] Plot time series data irregularly hourly-spaced
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA0B89E@PA-MBX01.na.tibco.com>
References: <CAH-FEniLVhzw3s6m+0gOQL9-T1Gefw2ZCXWaMQXhCYJ4xRJX6Q@mail.gmail.com>
	<0EFBC7C31DB4F24F8CAC48136A1762D70184EE24A708@MAIL2.rose.portland.local>
	<E66794E69CFDE04D9A70842786030B933FA0B89E@PA-MBX01.na.tibco.com>
Message-ID: <CAH-FEng-zot83frdj+BmSk1HadJa4QgG1MCFvT2ipjs+v_WGmw@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/60342d73/attachment.pl>

From nalimilan at club.fr  Thu Oct 17 11:36:31 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Thu, 17 Oct 2013 11:36:31 +0200
Subject: [R] saveXML() prefix argument
In-Reply-To: <720241366.53903648.1381981511046.JavaMail.root@k-state.edu>
References: <720241366.53903648.1381981511046.JavaMail.root@k-state.edu>
Message-ID: <1382002591.13698.2.camel@milan>

Le mercredi 16 octobre 2013 ? 23:45 -0400, Earl Brown a ?crit :
> I'm using the "XML" package and specifically the saveXML() function but I can't get the "prefix" argument of saveXML() to work:
> 
> library("XML")
> concepts <- c("one", "two", "three")
> info <- c("info one", "info two", "info three")
> root <- newXMLNode("root")
> for (i in 1:length(concepts)) {
> 	cur.concept <- concepts[i]
> 	cur.info <- info[i]
> 	cur.tip <- newXMLNode("tip", attrs = c(id = i), parent = root)
> 	newXMLNode("h1", cur.concept, parent = cur.tip)
> 	newXMLNode("p", cur.info, parent = cur.tip)
> }
> 
> # None of the following output a prefix on the first line of the exported document
> saveXML(root)
> saveXML(root, file = "test.xml")
> saveXML(root, file = "test.xml", prefix = '<?xml version="1.0"?>\n')
> 
> Am I missing something obvious? Any ideas?
It looks like the function XML:::saveXML.XMLInternalNode() does not use
the 'prefix' parameter at all. So it won't be taken into account when
calling saveXML() on objects of class XMLInternalNode.

I think you should report this to Duncan Temple Lang, as this is
probably an oversight.


Regards


> Thanks in advance. Earl Brown
> 
> -----
> Earl K. Brown, PhD
> Assistant Professor of Spanish Linguistics
> Advisor, TEFL MA Program
> Department of Modern Languages
> Kansas State University
> www-personal.ksu.edu/~ekbrown
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tacsunday at yahoo.fr  Thu Oct 17 11:45:02 2013
From: tacsunday at yahoo.fr (Robert U)
Date: Thu, 17 Oct 2013 10:45:02 +0100 (BST)
Subject: [R] Constraint on regression parameters
Message-ID: <1382003102.27828.YahooMailNeo@web172401.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/ca778db2/attachment.pl>

From S.Ellison at LGCGroup.com  Thu Oct 17 12:22:30 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 17 Oct 2013 11:22:30 +0100
Subject: [R] Constraint on regression parameters
In-Reply-To: <1382003102.27828.YahooMailNeo@web172401.mail.ir2.yahoo.com>
References: <1382003102.27828.YahooMailNeo@web172401.mail.ir2.yahoo.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487EBFD45@GOLD.corp.lgc-group.com>



> -----Original Message-----
> I am doing a polynomial linear regression with 2 independent variables
> such as :
> 
> lm(A ~ B + I(B^2) + I(lB^3) + C, data=Dataset))
> 
> R return me a coefficient per independent variable, and I? would need
> the coefficient of the C parameter to equal 1.

Leaving aside the question of fitting simple polynomial coefficients instead of orthogonal polynomials - generally frowned upon, but not always serious - the problem you describe is one in which you are not fitting C at all; you're assuming C adds exactly. What you're really fitting is the difference between A and C. 

Try fitting 
A-C ~ B + I(B^2) + I(lB^3) 

to obtain the coefficients you're looking for. But be aware that you will still have a constant intercept, so the model you will have fitted is

A = b0 + b1.B +b2.B^2 +b3.B^3 + C + error

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From cjpauw at gmail.com  Thu Oct 17 12:56:03 2013
From: cjpauw at gmail.com (Christiaan Pauw)
Date: Thu, 17 Oct 2013 12:56:03 +0200
Subject: [R] Extract a predictors form constparty object (CHAID output)
	in R
In-Reply-To: <CAJESSmbdT5af79Z9rHgJ0NBiPJb2VnkGUZpar2Ghv80Ogriw9w@mail.gmail.com>
References: <CAJESSmbdT5af79Z9rHgJ0NBiPJb2VnkGUZpar2Ghv80Ogriw9w@mail.gmail.com>
Message-ID: <CAJESSmZ7LxLk4SKB1oZ6AWOp4y0ctnULaEpZ9UXk2d1ZhC=o7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/dd05218e/attachment.pl>

From jim at bitwrit.com.au  Thu Oct 17 12:55:19 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 17 Oct 2013 21:55:19 +1100
Subject: [R] extract column's from different dataframe
In-Reply-To: <CAEW+BDKZdodZuL6as_mtqDEyVLwRFrGbSS+s=n8uBqrquX72aw@mail.gmail.com>
References: <CAEW+BDKZdodZuL6as_mtqDEyVLwRFrGbSS+s=n8uBqrquX72aw@mail.gmail.com>
Message-ID: <525FC217.3070604@bitwrit.com.au>

On 10/17/2013 06:17 PM, catalin roibu wrote:
> Dear R users,
>
> I want to extract column's from different data frame with different row
> length.
> How can I do this in R?
>
Hi catalin,
If I understand your question, which I think is:

I want to extract columns from different data frames with differing 
numbers of rows and store them in a single object.

The answer is probably to use a list:

datalist<-list()
datalist[[1]]<-dataframe1[,"variable1"]
datalist[[2]]<-dataframe2[,"variable3"]
...

where each element of "datalist" may have different numbers of values.

Jim


From carl at witthoft.com  Thu Oct 17 13:34:41 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 17 Oct 2013 04:34:41 -0700 (PDT)
Subject: [R] How would i sum the number of NA's in multiple vectors
In-Reply-To: <1381988749051-4678411.post@n4.nabble.com>
References: <1381988749051-4678411.post@n4.nabble.com>
Message-ID: <1382009681066-4678432.post@n4.nabble.com>

mattbju2013 wrote
> Hi guys this is my first post, i need help summing the number of NA's in a
> few vectors
> 
> for example..
> 
> c1<-c(1,2,NA,3,4)
> c2<-c(NA,1,2,3,4)
> c3<-c(NA,1,2,3,4)
> 
> how would i get a result that only sums the number of NA's in the vector?
> the.result.i.want<-c(2,0,1,0,0)

See ?is.na .   
Now, if I can interpret your question correctly, you're actually looking for
the number of NA per *position* in the vectors, so let's make them into a
matrix first.

cmat<-rbind(c1,c2,c3)
then use apply over columns
apply(cmat,2,function(k)sum(is.na(k)))





--
View this message in context: http://r.789695.n4.nabble.com/How-would-i-sum-the-number-of-NA-s-in-multiple-vectors-tp4678411p4678432.html
Sent from the R help mailing list archive at Nabble.com.


From matthias.weber at fnt.de  Thu Oct 17 13:36:44 2013
From: matthias.weber at fnt.de (Mat)
Date: Thu, 17 Oct 2013 04:36:44 -0700 (PDT)
Subject: [R] match values in dependence of ID and Date
Message-ID: <1382009804637-4678433.post@n4.nabble.com>

hello togehter,

i have a little problem, maybe you can help me.

I have a data.frame like this one:

ID    Name
1     Andy
2     John
3     Amy

and a data.frame like this:

ID   Date            Value
1    2013-10-01    10
1    2013-10-02    15
2    2013-10-01    7
2    2013-10-03    10
2    2013-10-04    15
3    2013-10-01    10

the result should be this one:

ID    Name   First   Second    Third
1     Andy    10     15
2     John     7      10           15
3     Amy     10

maybe you can help me, to do this?

Thank you.

Mat



--
View this message in context: http://r.789695.n4.nabble.com/match-values-in-dependence-of-ID-and-Date-tp4678433.html
Sent from the R help mailing list archive at Nabble.com.


From jwiley.psych at gmail.com  Thu Oct 17 13:44:33 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 17 Oct 2013 04:44:33 -0700
Subject: [R] How would i sum the number of NA's in multiple vectors
In-Reply-To: <1382009681066-4678432.post@n4.nabble.com>
References: <1381988749051-4678411.post@n4.nabble.com>
	<1382009681066-4678432.post@n4.nabble.com>
Message-ID: <CANz9Z_JV_LQaEoLaNhjGCMF3HHokC34zXGA_UK6_eAcfxAgduw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/73e85e58/attachment.pl>

From chrisaa at med.umich.edu  Thu Oct 17 14:05:37 2013
From: chrisaa at med.umich.edu (Andrews, Chris)
Date: Thu, 17 Oct 2013 12:05:37 +0000
Subject: [R] How to obtain restricted estimates from coxph()?
In-Reply-To: <CAHJ49whqFq-pi64bH+Eq5F-v6mEy234ExTftEDykKUbYxK9aCQ@mail.gmail.com>
References: <mailman.21.1381917608.4459.r-help@r-project.org>
	<525E877E.2050500@mayo.edu> <525E9ABA.10200@umu.se>
	<CAHJ49whqFq-pi64bH+Eq5F-v6mEy234ExTftEDykKUbYxK9aCQ@mail.gmail.com>
Message-ID: <30411786F64EEF46856EFBA2CD9177992C21B04F@UHEXMBSPR03.umhs.med.umich.edu>

Consider the function f(x) = x on the open interval (0,1).  It does not have a maximum.
That is what your likelihood function will look like.  The MLE does not exist.
Chris

(Although if everything is continuous and you are okay with limits there is an extension that gets you to Terry's original answer.)

-----Original Message-----
From: Y [mailto:yuhanusa at gmail.com] 
Sent: Wednesday, October 16, 2013 7:08 PM
To: G?ran Brostr?m
Cc: r-help at r-project.org
Subject: Re: [R] How to obtain restricted estimates from coxph()?

Thanks very much for your help, Terry and G?ran!

As pointed out by G?ran, the difficult part is that it's an open set. How
to obtain a valid MLE in this case?


Thanks,
YH







On Wed, Oct 16, 2013 at 9:55 AM, G?ran Brostr?m <goran.brostrom at umu.se>wrote:

>
>
> On 2013-10-16 14:33, Terry Therneau wrote:
>
>>
>>
>> On 10/16/2013 05:00 AM, r-help-request at r-project.org wrote:
>>
>>> Hello,
>>>
>>> I'm trying to use coxph() function to fit a very simple Cox proportional
>>> hazards regression model (only one covariate) but the parameter space is
>>> restricted to an open set (0, 1). Can I still obtain a valid estimate by
>>> using coxph function in this scenario? If yes, how? Any suggestion would
>>> be
>>> greatly appreciated. Thanks!!!
>>>
>>
>> Easily:
>>      1.  Fit the unrestricted model.  If the solution is in 0-1 you are
>> done.
>>      2.  If it is outside, fix the coefficient.  Say that the solution is
>> 1.73, then the
>> optimal solution under contraint is 1.
>>
>
> OK, except for the small annoyance that 1 is not a member of the open set
> (interval) (0, 1). Maybe the answer is "No" in this case? Depends on what
> lies in the word 'valid'. If 'MLE', the answer is No.
>
>           Redo the fit adding the paramters  "init=1, iter=0".  This
>> forces the program to
>> give the loglik and etc for the fixed coefficient of 1.0.
>>
>> Terry Therneau
>>
>> ______________________________**________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/**
>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________**________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/**
> posting-guide.html <http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 


From spyqqqdia at yahoo.com  Thu Oct 17 14:43:55 2013
From: spyqqqdia at yahoo.com (Michael Meyer)
Date: Thu, 17 Oct 2013 20:43:55 +0800 (SGT)
Subject: [R] S4 base class
Message-ID: <1382013835.53113.YahooMailNeo@web193406.mail.sg3.yahoo.com>

Greetings,

Meanwhile I have figured out?how do do it only to find out that I have more serious problems.
Generally calling Base::f on the base class object is not what you want, instead you want to call
Base::f on the full object for the following reasons:

If the base class is virtual, then Base::f might use virtual functions 
(not defined in Base but defined in derived classes).

If you then call Base::f on an object of class "Base" the call will fail.

Is it possible in R to call Base::f from within Derived (when there is also Derived::f) on the full object this?

I suspect not, which would be a serious drawback to the R class mechanism.


Thanks,


Michael Meyer


From spyqqqdia at yahoo.com  Thu Oct 17 15:01:41 2013
From: spyqqqdia at yahoo.com (Michael Meyer)
Date: Thu, 17 Oct 2013 21:01:41 +0800 (SGT)
Subject: [R] S4 base class
Message-ID: <1382014901.11697.YahooMailNeo@web193402.mail.sg3.yahoo.com>

Sorry,

if the previous message seems without context.
Indeed, the first message was bounced by filtering rules (triggered by subject heading than which nothing could be more benign or less liable to suspician). It was:

Greetings,

I have an S4 class "B" (Base) which defines a function f=f(this="B",...) 
Dervided from?B we have a derived class D which also defines a function f=f(this="D",...)

In the definition of D::f we want to call the version B::f and could do this by simply?calling

f(baseClassObject(this),...)

The question is the following:

How do I refer to the base class?object from the derived class?



Many thanks?


Michael Meyer


From friendly at yorku.ca  Thu Oct 17 15:15:21 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 17 Oct 2013 09:15:21 -0400
Subject: [R] flatten a list of lists
Message-ID: <525FE2E9.3070705@yorku.ca>

I have functions that generate lists objects of class "foo" and lists of 
lists of these, of class
"foolist", similar to what is shown below.

How can I flatten something like this to remove the top-level list 
structure, i.e.,
return a single-level list of "foo" objects, of class "foolist"?

foo <- function(n) {
     result <- list(x=sample(1:10,n), y=sample(1:10,n))
     class(result) <- "foo"
     result
}

multifoo <- function(vec, label, ...) {
     result <- lapply(vec, foo, ...)
     names(result) <- paste0(label, vec)
     class(result) <- "foolist"
     result
}

foo1 <- multifoo(1:2, "A")
foo2 <- multifoo(1:2, "B")

mfoo <- list(A=foo1, B=foo2)

str(mfoo, 2)

 > str(mfoo, 2)
List of 2
  $ A:List of 2
   ..$ A1:List of 2
   .. ..- attr(*, "class")= chr "foo"
   ..$ A2:List of 2
   .. ..- attr(*, "class")= chr "foo"
   ..- attr(*, "class")= chr "foolist"
  $ B:List of 2
   ..$ B1:List of 2
   .. ..- attr(*, "class")= chr "foo"
   ..$ B2:List of 2
   .. ..- attr(*, "class")= chr "foo"
   ..- attr(*, "class")= chr "foolist"

In this case, what is wanted is a single-level list, of 4 foo objects, 
A1, A2, B1, B2,
all of class "foolist"

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From murdoch.duncan at gmail.com  Thu Oct 17 15:19:30 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 17 Oct 2013 09:19:30 -0400
Subject: [R] S4 base class
In-Reply-To: <1382014901.11697.YahooMailNeo@web193402.mail.sg3.yahoo.com>
References: <1382014901.11697.YahooMailNeo@web193402.mail.sg3.yahoo.com>
Message-ID: <525FE3E2.3010903@gmail.com>

On 17/10/2013 9:01 AM, Michael Meyer wrote:
> Sorry,
>
> if the previous message seems without context.
> Indeed, the first message was bounced by filtering rules (triggered by subject heading than which nothing could be more benign or less liable to suspician). It was:
>
> Greetings,
>
> I have an S4 class "B" (Base) which defines a function f=f(this="B",...)
> Dervided from B we have a derived class D which also defines a function f=f(this="D",...)
>
> In the definition of D::f we want to call the version B::f and could do this by simply calling
>
> f(baseClassObject(this),...)
>
> The question is the following:
>
> How do I refer to the base class object from the derived class?

You're asking the wrong question.  You should be asking how to call the 
method for the inherited class .  callNextMethod() is the answer to that 
question.

By the way, your use of the syntax D::f and B::f suggests that you're 
thinking from a C++ point of view.  That's very likely to lead to 
frustration:  the S4 object system is very different from C++.  Methods 
don't belong to classes, they belong to generics. There is no such thing 
as D::f or B::f, only f methods with different signatures.

Duncan Murdoch


From istazahn at gmail.com  Thu Oct 17 15:23:28 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 17 Oct 2013 09:23:28 -0400
Subject: [R] flatten a list of lists
In-Reply-To: <525FE2E9.3070705@yorku.ca>
References: <525FE2E9.3070705@yorku.ca>
Message-ID: <CA+vqiLH5u6mgWXxf4bdLkg6EqSkpJM8ZxK_KJwchEw7mFrJ8dw@mail.gmail.com>

unlist(mfoo, recursive = FALSE) gets you pretty close.

Best,
Ista

On Thu, Oct 17, 2013 at 9:15 AM, Michael Friendly <friendly at yorku.ca> wrote:
> I have functions that generate lists objects of class "foo" and lists of
> lists of these, of class
> "foolist", similar to what is shown below.
>
> How can I flatten something like this to remove the top-level list
> structure, i.e.,
> return a single-level list of "foo" objects, of class "foolist"?
>
> foo <- function(n) {
>     result <- list(x=sample(1:10,n), y=sample(1:10,n))
>     class(result) <- "foo"
>     result
> }
>
> multifoo <- function(vec, label, ...) {
>     result <- lapply(vec, foo, ...)
>     names(result) <- paste0(label, vec)
>     class(result) <- "foolist"
>     result
> }
>
> foo1 <- multifoo(1:2, "A")
> foo2 <- multifoo(1:2, "B")
>
> mfoo <- list(A=foo1, B=foo2)
>
> str(mfoo, 2)
>
>> str(mfoo, 2)
> List of 2
>  $ A:List of 2
>   ..$ A1:List of 2
>   .. ..- attr(*, "class")= chr "foo"
>   ..$ A2:List of 2
>   .. ..- attr(*, "class")= chr "foo"
>   ..- attr(*, "class")= chr "foolist"
>  $ B:List of 2
>   ..$ B1:List of 2
>   .. ..- attr(*, "class")= chr "foo"
>   ..$ B2:List of 2
>   .. ..- attr(*, "class")= chr "foo"
>   ..- attr(*, "class")= chr "foolist"
>
> In this case, what is wanted is a single-level list, of 4 foo objects, A1,
> A2, B1, B2,
> all of class "foolist"
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Oct 17 15:31:20 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 17 Oct 2013 09:31:20 -0400
Subject: [R] flatten a list of lists
In-Reply-To: <525FE2E9.3070705@yorku.ca>
References: <525FE2E9.3070705@yorku.ca>
Message-ID: <525FE6A8.5010902@gmail.com>

On 17/10/2013 9:15 AM, Michael Friendly wrote:
> I have functions that generate lists objects of class "foo" and lists of
> lists of these, of class
> "foolist", similar to what is shown below.

You can use c() to join lists.  So in the example below,

c(mfoo$A, mfoo$B)

will give you a list with the components you want, though the class 
won't be set.   More generally, do.call(c, unname(mfoo)) will join any 
number of components.  (Without unname(), the names at the top level 
will be combined with the component names;
maybe you'd actually want that, but your example didn't do it.)

This won't work if your list doesn't have the regular "list of lists" 
structure, e.g. if it mixes foo objects with foolist objects at the same 
level.  Then you probably need a more complicated recursive approach.  
You might be able to do it with rapply().

Duncan Murdoch

>
> How can I flatten something like this to remove the top-level list
> structure, i.e.,
> return a single-level list of "foo" objects, of class "foolist"?
>
> foo <- function(n) {
>       result <- list(x=sample(1:10,n), y=sample(1:10,n))
>       class(result) <- "foo"
>       result
> }
>
> multifoo <- function(vec, label, ...) {
>       result <- lapply(vec, foo, ...)
>       names(result) <- paste0(label, vec)
>       class(result) <- "foolist"
>       result
> }
>
> foo1 <- multifoo(1:2, "A")
> foo2 <- multifoo(1:2, "B")
>
> mfoo <- list(A=foo1, B=foo2)
>
> str(mfoo, 2)
>
>   > str(mfoo, 2)
> List of 2
>    $ A:List of 2
>     ..$ A1:List of 2
>     .. ..- attr(*, "class")= chr "foo"
>     ..$ A2:List of 2
>     .. ..- attr(*, "class")= chr "foo"
>     ..- attr(*, "class")= chr "foolist"
>    $ B:List of 2
>     ..$ B1:List of 2
>     .. ..- attr(*, "class")= chr "foo"
>     ..$ B2:List of 2
>     .. ..- attr(*, "class")= chr "foo"
>     ..- attr(*, "class")= chr "foolist"
>
> In this case, what is wanted is a single-level list, of 4 foo objects,
> A1, A2, B1, B2,
> all of class "foolist"
>


From dcarlson at tamu.edu  Thu Oct 17 15:39:50 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 17 Oct 2013 08:39:50 -0500
Subject: [R] flatten a list of lists
In-Reply-To: <CA+vqiLH5u6mgWXxf4bdLkg6EqSkpJM8ZxK_KJwchEw7mFrJ8dw@mail.gmail.com>
References: <525FE2E9.3070705@yorku.ca>
	<CA+vqiLH5u6mgWXxf4bdLkg6EqSkpJM8ZxK_KJwchEw7mFrJ8dw@mail.gmail.com>
Message-ID: <041a01cecb3e$5a98b050$0fca10f0$@tamu.edu>

Does this get you the rest of the way?

> mfoo2 <- unlist(mfoo, recursive = FALSE)
> names(mfoo2) <- unlist(lapply(mfoo, names))
> class(mfoo2) <- "foolist"
> str(mfoo2)
List of 4
 $ A1:List of 2
  ..$ x: int 3
  ..$ y: int 10
  ..- attr(*, "class")= chr "foo"
 $ A2:List of 2
  ..$ x: int [1:2] 6 4
  ..$ y: int [1:2] 8 9
  ..- attr(*, "class")= chr "foo"
 $ B1:List of 2
  ..$ x: int 2
  ..$ y: int 2
  ..- attr(*, "class")= chr "foo"
 $ B2:List of 2
  ..$ x: int [1:2] 3 6
  ..$ y: int [1:2] 4 2
  ..- attr(*, "class")= chr "foo"
 - attr(*, "class")= chr "foolist"

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Ista Zahn
Sent: Thursday, October 17, 2013 8:23 AM
To: Michael Friendly
Cc: R-help
Subject: Re: [R] flatten a list of lists

unlist(mfoo, recursive = FALSE) gets you pretty close.

Best,
Ista

On Thu, Oct 17, 2013 at 9:15 AM, Michael Friendly
<friendly at yorku.ca> wrote:
> I have functions that generate lists objects of class "foo"
and lists of
> lists of these, of class
> "foolist", similar to what is shown below.
>
> How can I flatten something like this to remove the top-level
list
> structure, i.e.,
> return a single-level list of "foo" objects, of class
"foolist"?
>
> foo <- function(n) {
>     result <- list(x=sample(1:10,n), y=sample(1:10,n))
>     class(result) <- "foo"
>     result
> }
>
> multifoo <- function(vec, label, ...) {
>     result <- lapply(vec, foo, ...)
>     names(result) <- paste0(label, vec)
>     class(result) <- "foolist"
>     result
> }
>
> foo1 <- multifoo(1:2, "A")
> foo2 <- multifoo(1:2, "B")
>
> mfoo <- list(A=foo1, B=foo2)
>
> str(mfoo, 2)
>
>> str(mfoo, 2)
> List of 2
>  $ A:List of 2
>   ..$ A1:List of 2
>   .. ..- attr(*, "class")= chr "foo"
>   ..$ A2:List of 2
>   .. ..- attr(*, "class")= chr "foo"
>   ..- attr(*, "class")= chr "foolist"
>  $ B:List of 2
>   ..$ B1:List of 2
>   .. ..- attr(*, "class")= chr "foo"
>   ..$ B2:List of 2
>   .. ..- attr(*, "class")= chr "foo"
>   ..- attr(*, "class")= chr "foolist"
>
> In this case, what is wanted is a single-level list, of 4 foo
objects, A1,
> A2, B1, B2,
> all of class "foolist"
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416
736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From friendly at yorku.ca  Thu Oct 17 16:42:06 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 17 Oct 2013 10:42:06 -0400
Subject: [R] flatten a list of lists
In-Reply-To: <041a01cecb3e$5a98b050$0fca10f0$@tamu.edu>
References: <525FE2E9.3070705@yorku.ca>
	<CA+vqiLH5u6mgWXxf4bdLkg6EqSkpJM8ZxK_KJwchEw7mFrJ8dw@mail.gmail.com>
	<041a01cecb3e$5a98b050$0fca10f0$@tamu.edu>
Message-ID: <525FF73E.708@yorku.ca>

Thanks to all who replied.

Here are two versions of a function (sans sanity checks) that do what I 
want:

foo1 <- multifoo(1:2, "A")
foo2 <- multifoo(1:2, "B")

mfoo <- list(A=foo1, B=foo2)
class(mfoo) <- c("foolist", "list")

#' flatten a list of lists

# from Duncan Murdoch
flatten <- function(list, unname=TRUE) {
     res <- do.call(c, if(unname) unname(list) else list)
     class(res) <- class(list)
     res
}

# from David Carlson
flatten2 <- function(list, unname=TRUE) {
     res <- unlist(list, recursive = FALSE)
     if(unname) names(res) <- unlist(lapply(list, names))
     class(res) <- class(list)
     res
}

mflat1 <- flatten(mfoo)
mflat2 <- flatten2(mfoo)
all.equal(mflat1,mflat2)

 > all.equal(mflat1,mflat2)
[1] TRUE

-Michael

On 10/17/2013 9:39 AM, David Carlson wrote:
> Does this get you the rest of the way?
>
>> mfoo2 <- unlist(mfoo, recursive = FALSE)
>> names(mfoo2) <- unlist(lapply(mfoo, names))
>> class(mfoo2) <- "foolist"
>> str(mfoo2)
> List of 4
>   $ A1:List of 2
>    ..$ x: int 3
>    ..$ y: int 10
>    ..- attr(*, "class")= chr "foo"
>   $ A2:List of 2
>    ..$ x: int [1:2] 6 4
>    ..$ y: int [1:2] 8 9
>    ..- attr(*, "class")= chr "foo"
>   $ B1:List of 2
>    ..$ x: int 2
>    ..$ y: int 2
>    ..- attr(*, "class")= chr "foo"
>   $ B2:List of 2
>    ..$ x: int [1:2] 3 6
>    ..$ y: int [1:2] 4 2
>    ..- attr(*, "class")= chr "foo"
>   - attr(*, "class")= chr "foolist"
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Ista Zahn
> Sent: Thursday, October 17, 2013 8:23 AM
> To: Michael Friendly
> Cc: R-help
> Subject: Re: [R] flatten a list of lists
>
> unlist(mfoo, recursive = FALSE) gets you pretty close.
>
> Best,
> Ista
>
> On Thu, Oct 17, 2013 at 9:15 AM, Michael Friendly
> <friendly at yorku.ca> wrote:
>> I have functions that generate lists objects of class "foo"
> and lists of
>> lists of these, of class
>> "foolist", similar to what is shown below.
>>
>> How can I flatten something like this to remove the top-level
> list
>> structure, i.e.,
>> return a single-level list of "foo" objects, of class
> "foolist"?
>> foo <- function(n) {
>>      result <- list(x=sample(1:10,n), y=sample(1:10,n))
>>      class(result) <- "foo"
>>      result
>> }
>>
>> multifoo <- function(vec, label, ...) {
>>      result <- lapply(vec, foo, ...)
>>      names(result) <- paste0(label, vec)
>>      class(result) <- "foolist"
>>      result
>> }
>>
>> foo1 <- multifoo(1:2, "A")
>> foo2 <- multifoo(1:2, "B")
>>
>> mfoo <- list(A=foo1, B=foo2)
>>
>> str(mfoo, 2)
>>
>>> str(mfoo, 2)
>> List of 2
>>   $ A:List of 2
>>    ..$ A1:List of 2
>>    .. ..- attr(*, "class")= chr "foo"
>>    ..$ A2:List of 2
>>    .. ..- attr(*, "class")= chr "foo"
>>    ..- attr(*, "class")= chr "foolist"
>>   $ B:List of 2
>>    ..$ B1:List of 2
>>    .. ..- attr(*, "class")= chr "foo"
>>    ..$ B2:List of 2
>>    .. ..- attr(*, "class")= chr "foo"
>>    ..- attr(*, "class")= chr "foolist"
>>
>> In this case, what is wanted is a single-level list, of 4 foo
> objects, A1,
>> A2, B1, B2,
>> all of class "foolist"
>>
>> --
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept. & Chair, Quantitative Methods
>> York University      Voice: 416 736-2100 x66249 Fax: 416
> 736-5814
>> 4700 Keele Street    Web:   http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible
> code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
> code.
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From rshepard at appl-ecosys.com  Thu Oct 17 17:17:15 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 17 Oct 2013 08:17:15 -0700 (PDT)
Subject: [R] Lattice xyplot: Fill Legend Points
Message-ID: <alpine.LNX.2.00.1310170813150.3144@salmo.appl-ecosys.com>

   When I specify pch = 19 for a scatter plot the points are filled circles.
Deapite reading ?points and trial-and-error experimentation I have not found
how to have the legend symbols (now open circles) filled.

   An example command is:

xyplot(pct.quant ~ sampdate, data = ffg.st, groups = func_feed_grp, type =
'p', pch = 19, key = simpleKey(text = levels(ffg.st$func_feed_grp), space =
'right', points = T, lines = F),par.settings = list(superpose.points =
list(col = rainbow(7)), superpose.lines = list(col = rainbow(7))), main =
'Functional Feeding Groups (Individuals)', xlab = 'Year', ylab = 'Proportion
of Individuals')

   Please pass me a pointer on how to fill the legend points.

TIA,

Rich


From rmh at temple.edu  Thu Oct 17 17:31:09 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 17 Oct 2013 11:31:09 -0400
Subject: [R] Lattice xyplot: Fill Legend Points
In-Reply-To: <alpine.LNX.2.00.1310170813150.3144@salmo.appl-ecosys.com>
References: <alpine.LNX.2.00.1310170813150.3144@salmo.appl-ecosys.com>
Message-ID: <CAGx1TMAW2oCb+yWO_dM_QHnd3366DU6ans-AttUp4o-4sH-png@mail.gmail.com>

put the pch into the par.settings

On Thu, Oct 17, 2013 at 11:17 AM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>   When I specify pch = 19 for a scatter plot the points are filled circles.
> Deapite reading ?points and trial-and-error experimentation I have not found
> how to have the legend symbols (now open circles) filled.
>
>   An example command is:
>
> xyplot(pct.quant ~ sampdate, data = ffg.st, groups = func_feed_grp, type =
> 'p', pch = 19, key = simpleKey(text = levels(ffg.st$func_feed_grp), space =
> 'right', points = T, lines = F),par.settings = list(superpose.points =
> list(col = rainbow(7)), superpose.lines = list(col = rainbow(7))), main =
> 'Functional Feeding Groups (Individuals)', xlab = 'Year', ylab = 'Proportion
> of Individuals')
>
>   Please pass me a pointer on how to fill the legend points.
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dtemplelang at ucdavis.edu  Thu Oct 17 17:30:00 2013
From: dtemplelang at ucdavis.edu (Duncan Temple Lang)
Date: Thu, 17 Oct 2013 08:30:00 -0700
Subject: [R] saveXML() prefix argument
In-Reply-To: <1382002591.13698.2.camel@milan>
References: <720241366.53903648.1381981511046.JavaMail.root@k-state.edu>
	<1382002591.13698.2.camel@milan>
Message-ID: <52600278.6020409@ucdavis.edu>

Milan is correct.
The prefix is used when saving the XML content that is represented in
a different format in R.

To get the prefix 
 <?xml version="1.0"?>
on the XML content that you save, use a document object

doc = newXMLDoc()
root = newXMLNode("foo", doc = doc)

saveXML(doc)


<?xml version="1.0"?>
<foo/>

Sorry for the confusion.
 D

On 10/17/13 2:36 AM, Milan Bouchet-Valat wrote:
> Le mercredi 16 octobre 2013 ? 23:45 -0400, Earl Brown a ?crit :
>> I'm using the "XML" package and specifically the saveXML() function but I can't get the "prefix" argument of saveXML() to work:
>>
>> library("XML")
>> concepts <- c("one", "two", "three")
>> info <- c("info one", "info two", "info three")
>> root <- newXMLNode("root")
>> for (i in 1:length(concepts)) {
>> 	cur.concept <- concepts[i]
>> 	cur.info <- info[i]
>> 	cur.tip <- newXMLNode("tip", attrs = c(id = i), parent = root)
>> 	newXMLNode("h1", cur.concept, parent = cur.tip)
>> 	newXMLNode("p", cur.info, parent = cur.tip)
>> }
>>
>> # None of the following output a prefix on the first line of the exported document
>> saveXML(root)
>> saveXML(root, file = "test.xml")
>> saveXML(root, file = "test.xml", prefix = '<?xml version="1.0"?>\n')
>>
>> Am I missing something obvious? Any ideas?
> It looks like the function XML:::saveXML.XMLInternalNode() does not use
> the 'prefix' parameter at all. So it won't be taken into account when
> calling saveXML() on objects of class XMLInternalNode.
> 
> I think you should report this to Duncan Temple Lang, as this is
> probably an oversight.
> 
> 
> Regards
> 
> 
>> Thanks in advance. Earl Brown
>>
>> -----
>> Earl K. Brown, PhD
>> Assistant Professor of Spanish Linguistics
>> Advisor, TEFL MA Program
>> Department of Modern Languages
>> Kansas State University
>> www-personal.ksu.edu/~ekbrown
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From carl at witthoft.com  Tue Oct 15 13:22:55 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Tue, 15 Oct 2013 04:22:55 -0700 (PDT)
Subject: [R] Help with combining functions
In-Reply-To: <71A9F37B694303439E0627F5D05323B56E2697@EXMBCT03.campus.ncl.ac.uk>
References: <71A9F37B694303439E0627F5D05323B56E2697@EXMBCT03.campus.ncl.ac.uk>
Message-ID: <1381836175134-4678272.post@n4.nabble.com>

This is the world-famous "fizzbuzz" problem.   You should be able to find
lots of implementations by Googling that word.  Here's a pointless
collection I wrote once:

# a really dumb fizzbuzz alg competition
#fbfun1 is 2.5x faster than fbfun2
# fbfun3 is 10x faster than fbfun1
# fbfun1 is 2x faster than fbfun4 
# fbfun5 is 20x faster than fbrun3
# Those are user times; in most cases the system time is very small indeed. 

fbfun1 <- function(xfoo) {
xfoo<-1:xfoo
fbfoo <- 1+(!as.logical(mod(xfoo,3)))*(as.logical(mod(xfoo,5))) +
2*(as.logical(mod(xfoo,3)))*(!as.logical(mod(xfoo,5)))+3*(!as.logical(mod(xfoo,3)))*(!as.logical(mod(xfoo,5)))

fbbar <- unlist(lapply(fbfoo, function(x)
switch(x,0,'fizz','buzz','fizzbuzz')))
return(fbbar)
}


fbfun3 <- function(xfoo) {
xfoo<-1:xfoo
fbfoo <- 1+(!as.logical(mod(xfoo,3)))*(as.logical(mod(xfoo,5))) +
2*(as.logical(mod(xfoo,3)))*(!as.logical(mod(xfoo,5)))+3*(!as.logical(mod(xfoo,3)))*(!as.logical(mod(xfoo,5)))
fbtab<-cbind(1:4,c('','fizz','buzz','fizzbuzz'))
fbbar <- fbtab[fbfoo,2]
return(fbbar)
}

# can I do it with recycled vectors, e.g. c('','','fizz') and
c('','','','','buzz') ?
fbfun4 <- function(xfoo) {
fiz<- rep(c('','','fizz'),length.out=xfoo)
buz<-rep(c('','','','','buzz'),length.out=xfoo)
fbbar <- unlist(lapply(1:xfoo, function(j)paste(fiz[j],buz[j]) ) )
return(fbbar)
}

# or completely sleazy:
fbfun5 <- function(xfoo) {
fiz<-
rep(c('','','fizz','','buzz','fizz','','','fizz','buzz','','fizz','','','fizzbuzz'),length.out=xfoo)
return(fiz)
}





--
View this message in context: http://r.789695.n4.nabble.com/Help-with-combining-functions-tp4678212p4678272.html
Sent from the R help mailing list archive at Nabble.com.


From andrej.g.miller at web.de  Tue Oct 15 14:01:28 2013
From: andrej.g.miller at web.de (Andrej)
Date: Tue, 15 Oct 2013 05:01:28 -0700 (PDT)
Subject: [R] Comparing two groups
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B96D50@SRVEXCHMBX.precheza.cz>
References: <1381736946485-4678190.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B96D50@SRVEXCHMBX.precheza.cz>
Message-ID: <1381838488519-4678277.post@n4.nabble.com>

>So why not start with some statistical textbook? There are plenty of them
available in CRAN. 

I wasn't implying, that I haven't read any textbook, or didn't do any
research. I read some textbooks/Papers/etc. during the research about what
to do and came across the wilcox test. I meant to imply that I could have
problems understanding some of the answers, and that maybe additional
explaining would be necessary.

My doubts stem from the fact, that the wilcox test is a - as far as I know -
ranking test, that states if two groups are different. My assumption is, due
to the fact that the second group has a much higher sample size, it is clear
that it differs from the first group. I performed a t-test (just to see; I
am aware that I am not allowed to perform it, because my samples aren't
normally distributed) and it gave me a p-value of 0.3.
Actually I am not even entirely sure, if wilcox is the right test. I just
want to know if the means of the two groups are significantly different.



--
View this message in context: http://r.789695.n4.nabble.com/Comparing-two-groups-tp4678190p4678277.html
Sent from the R help mailing list archive at Nabble.com.


From spyqqqdia at yahoo.com  Thu Oct 17 17:54:28 2013
From: spyqqqdia at yahoo.com (Michael Meyer)
Date: Thu, 17 Oct 2013 23:54:28 +0800 (SGT)
Subject: [R] S4 base class
Message-ID: <1382025268.48593.YahooMailNeo@web193404.mail.sg3.yahoo.com>

Quote

By the way, your use of the syntax D::f and B::f suggests that you&apos;re 
thinking from a C++ point of view.? That&apos;s very likely to lead to 
frustration:? the S4 object system is very different from C++.? Methods 
don&apos;t belong to classes, they belong to generics. There is no such thing 
as D::f or B::f, only f methods with different signatures.

Duncan Murdoch?


#-------------------------------------------------------------------------------------------#

I am aware of this.
We can probably agree that?we should use?S4 classes and generic functions to duplicate more usual object oriented architecture as far as possible while remaining conscious of the regrettable differences.

For example we can pretend we are defining a virtual function in class Base by writing:

setGeneric("F",
function(this) standardGeneric("F")
)

where the code for Base? is, even though it has nothing to do with the class Base. 
We can even use it in other functions "defined?in class Base" by writing 


setGeneric("G",
function(this) standardGeneric("G")
)
setMethod("G",
signature(this="Base"),
definition=function(this){

????F(this)
})

which will work on all derived classes which implement F in some fashion:

setMethod("F",
signature(this="Derived"),
definition=function(this){

????# do something appropriate for derived.
})

With this we can reproduce some semblance of object oriented programming
However, apparently we cannot solve in this manner a common problem of object 
oriented programming (from now on C++ parlance):

Suppose you have a base class "Base" which implements a function "Base::F" 
which works in most contexts but not in the context of "ComplicatedDerived" class
where some preparation has to happen before this very same function can be called.

You would then define

void ComplicatedDerived::F(...){

????preparation();
????Base::F();
}

You can nealry?duplicate this in R via 

setMethod("F",
signature(this="ComplicatedDerived"),
definition=function(this){

????preparation(this)
????F(as(this,"Base"))
})

but it will fail whenever F uses virtual functions (i.e. generics) which are only defined
for derived classes of Base, whereas this is not a problem at all in normal object oriented
languages.

This is not a contrived problem but is rather basic.
I wonder if you can do it in R in some other way.


Many thanks,

Michael


From rshepard at appl-ecosys.com  Thu Oct 17 17:48:29 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 17 Oct 2013 08:48:29 -0700 (PDT)
Subject: [R] Lattice xyplot: Fill Legend Points
In-Reply-To: <CAGx1TMAW2oCb+yWO_dM_QHnd3366DU6ans-AttUp4o-4sH-png@mail.gmail.com>
References: <alpine.LNX.2.00.1310170813150.3144@salmo.appl-ecosys.com>
	<CAGx1TMAW2oCb+yWO_dM_QHnd3366DU6ans-AttUp4o-4sH-png@mail.gmail.com>
Message-ID: <alpine.LNX.2.00.1310170844490.3144@salmo.appl-ecosys.com>

On Thu, 17 Oct 2013, Richard M. Heiberger wrote:

> put the pch into the par.settings

Richard,

   Tried this again, but I'm not finding the proper location within
par.settings.

par.settings = list(superpose.points = list(col = rainbow(7)),
superpose.lines = list(col = rainbow(7)), pch = 19)


If I put it prior to the (list ... group there's an error of an extra = ;
when I put it anywhere in the list (the above is one of my tries), it has no
effect on the legend symbols: they remain as outlines.

   What have I missed?

Thanks,

Rich

-- 
Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
Applied Ecosystem Services, Inc.   |
<http://www.appl-ecosys.com>     Voice: 503-667-4517      Fax: 503-667-8863


From hnorpois at gmail.com  Thu Oct 17 13:44:44 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Thu, 17 Oct 2013 13:44:44 +0200
Subject: [R] plot - how to vary the distances of the x axis?
Message-ID: <CAKyZeBuCHEFvotADYn7sn-N-D_k=DTFgTbXRZHMqjj9NofJy+Q@mail.gmail.com>

Hello,


my dots of 0 and 2 are quite close to the marging. So I would like to move
the 0 and the 2 both towards the 1. I wish to be my dots more centered.
And: I dont need so much space between 0,1 and 2.

How does it work?
I tried:

plot (data, axes=FALSE, main=i, ylab= expression (z^2))
              plot.window (xlim=c (0,2), ylim=c(0,80))
              box (lwd=2)
              axis (side=1, at = c (0,1,2))
              axis (side =2)

dput (data)
structure(list(Genotype = c(0, 0, 0, 1, 1, 1, 1, 1, 2), z =
c(0.66429502114682,
0.258444359570075, 0.0702937908415368, 0.694376498254858,
0.0967863570760579,
0.213966209301163, 0.671497050546114, 0.60318070802847, 75.6011068681301
)), .Names = c("Genotype", "z"), row.names = c(NA, 9L), class =
"data.frame")
>

Thanks
-------------- next part --------------
A non-text attachment was scrubbed...
Name: move.png
Type: image/png
Size: 5312 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/582b7e52/attachment.png>

From katherine_gobin at yahoo.com  Thu Oct 17 08:55:34 2013
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Thu, 17 Oct 2013 14:55:34 +0800 (SGT)
Subject: [R] Subseting a data.frame
Message-ID: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/76c3769a/attachment.pl>

From m.coulson at marlab.ac.uk  Thu Oct 17 11:47:11 2013
From: m.coulson at marlab.ac.uk (markw)
Date: Thu, 17 Oct 2013 02:47:11 -0700 (PDT)
Subject: [R] map with inset
In-Reply-To: <02d501ceca9b$44fa5080$ceeef180$@tamu.edu>
References: <1381920477182-4678341.post@n4.nabble.com>
	<D2DB6310-F31F-4A1C-BBB9-B22A7B14B66B@comcast.net>
	<CACk-te1wJPKY7_8T6UC6HpD66d0w4S3_eJDOqeptFr=CHQd9dg@mail.gmail.com>
	<02d501ceca9b$44fa5080$ceeef180$@tamu.edu>
Message-ID: <1382003231268-4678426.post@n4.nabble.com>

Hi David,

That worked brilliantly! Many thanks. I also had trouble getting subplot()
to work with either TeachingDemos or Hmisc.

Best,
Mark



--
View this message in context: http://r.789695.n4.nabble.com/map-with-inset-tp4678341p4678426.html
Sent from the R help mailing list archive at Nabble.com.


From deter088 at umn.edu  Thu Oct 17 18:01:03 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 17 Oct 2013 11:01:03 -0500
Subject: [R] Subseting a data.frame
In-Reply-To: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
Message-ID: <CAOLJphkSSKGY6bicVL6WJHtCF9Pi=kDLaEca+1+AKPLErbuiEA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/0b0915ff/attachment.pl>

From mike.sugarman at wayne.edu  Wed Oct 16 19:04:26 2013
From: mike.sugarman at wayne.edu (Msugarman)
Date: Wed, 16 Oct 2013 10:04:26 -0700 (PDT)
Subject: [R] Weighted regression markers on scatter plots
Message-ID: <1381943066063-4678370.post@n4.nabble.com>

Hi all,

I'm trying to graph the results of a weighted regression analysis. Is anyone
aware of a way to make my markers appear a different sizes to be consistent
with their respective weights?

Thanks,
-Mike Sugarman
Wayne State University



--
View this message in context: http://r.789695.n4.nabble.com/Weighted-regression-markers-on-scatter-plots-tp4678370.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Thu Oct 17 15:31:40 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 17 Oct 2013 06:31:40 -0700 (PDT)
Subject: [R] match values in dependence of ID and Date
In-Reply-To: <1382009804637-4678433.post@n4.nabble.com>
References: <1382009804637-4678433.post@n4.nabble.com>
Message-ID: <1382016700.89473.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
dat <- read.table(text="
ID??? Name
1??? Andy
2??? John
3??? Amy",sep="",header=TRUE,stringsAsFactors=FALSE)

dat2 <- read.table(text="
ID? Date??????????? Value
1??? 2013-10-01??? 10
1??? 2013-10-02??? 15
2??? 2013-10-01??? 7
2??? 2013-10-03??? 10
2??? 2013-10-04??? 15
3??? 2013-10-01??? 10",sep="",header=TRUE,colClasses=c("numeric","Date","numeric"))

library(plyr)

?res <- reshape(ddply(merge(dat,dat2,by="ID"),.(ID),mutate,id=((seq_along(ID)-1)%%3+1))[,-3],idvar=c("ID","Name"),timevar="id",direction="wide")
?rownames(res) <- 1:nrow(res)
?colnames(res)[3:5] <- c("First", "Second", "Third")

?res
#? ID Name First Second Third
#1? 1 Andy??? 10???? 15??? NA
#2? 2 John???? 7???? 10??? 15
#3? 3? Amy??? 10???? NA??? NA
A.K.






On Thursday, October 17, 2013 7:42 AM, Mat <matthias.weber at fnt.de> wrote:
hello togehter,

i have a little problem, maybe you can help me.

I have a data.frame like this one:

ID? ? Name
1? ?  Andy
2? ?  John
3? ?  Amy

and a data.frame like this:

ID?  Date? ? ? ? ? ? Value
1? ? 2013-10-01? ? 10
1? ? 2013-10-02? ? 15
2? ? 2013-10-01? ? 7
2? ? 2013-10-03? ? 10
2? ? 2013-10-04? ? 15
3? ? 2013-10-01? ? 10

the result should be this one:

ID? ? Name?  First?  Second? ? Third
1? ?  Andy? ? 10? ?  15
2? ?  John? ?  7? ? ? 10? ? ? ? ?  15
3? ?  Amy? ?  10

maybe you can help me, to do this?

Thank you.

Mat



--
View this message in context: http://r.789695.n4.nabble.com/match-values-in-dependence-of-ID-and-Date-tp4678433.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Thu Oct 17 16:08:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 17 Oct 2013 07:08:57 -0700 (PDT)
Subject: [R] match values in dependence of ID and Date
In-Reply-To: <1382016700.89473.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1382009804637-4678433.post@n4.nabble.com>
	<1382016700.89473.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1382018937.40523.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

I think based on your title, the output you provided is not clear. If it depends on Date, there should be four columns.
library(reshape2)

res1 <- dcast(merge(dat,dat2,by="ID"),ID+Name~Date,value.var="Value")
?colnames(res1)[3:6] <- c("First", "Second", "Third", "Fourth")
?rownames(res1) <- 1:nrow(res1)


#or
res2 <- reshape(merge(dat,dat2,by="ID"),idvar=c("ID","Name"),timevar="Date",direction="wide")
?dimnames(res2) <- dimnames(res1)

?res2
#? ID Name First Second Third Fourth
#1? 1 Andy??? 10???? 15??? NA???? NA
#2? 2 John???? 7???? NA??? 10???? 15
#3? 3? Amy??? 10???? NA??? NA???? NA


A.K.






On Thursday, October 17, 2013 9:31 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
dat <- read.table(text="
ID??? Name
1??? Andy
2??? John
3??? Amy",sep="",header=TRUE,stringsAsFactors=FALSE)

dat2 <- read.table(text="
ID? Date??????????? Value
1??? 2013-10-01??? 10
1??? 2013-10-02??? 15
2??? 2013-10-01??? 7
2??? 2013-10-03??? 10
2??? 2013-10-04??? 15
3??? 2013-10-01??? 10",sep="",header=TRUE,colClasses=c("numeric","Date","numeric"))

library(plyr)

?res <- reshape(ddply(merge(dat,dat2,by="ID"),.(ID),mutate,id=((seq_along(ID)-1)%%3+1))[,-3],idvar=c("ID","Name"),timevar="id",direction="wide")
?rownames(res) <- 1:nrow(res)
?colnames(res)[3:5] <- c("First", "Second", "Third")

?res
#? ID Name First Second Third
#1? 1 Andy??? 10???? 15??? NA
#2? 2 John???? 7???? 10??? 15
#3? 3? Amy??? 10???? NA??? NA
A.K.







On Thursday, October 17, 2013 7:42 AM, Mat <matthias.weber at fnt.de> wrote:
hello togehter,

i have a little problem, maybe you can help me.

I have a data.frame like this one:

ID? ? Name
1? ?? Andy
2? ?? John
3? ?? Amy

and a data.frame like this:

ID?? Date? ? ? ? ? ? Value
1? ? 2013-10-01? ? 10
1? ? 2013-10-02? ? 15
2? ? 2013-10-01? ? 7
2? ? 2013-10-03? ? 10
2? ? 2013-10-04? ? 15
3? ? 2013-10-01? ? 10

the result should be this one:

ID? ? Name?? First?? Second? ? Third
1? ?? Andy? ? 10? ?? 15
2? ?? John? ?? 7? ? ? 10? ? ? ? ?? 15
3? ?? Amy? ?? 10

maybe you can help me, to do this?

Thank you.

Mat



--
View this message in context: http://r.789695.n4.nabble.com/match-values-in-dependence-of-ID-and-Date-tp4678433.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From gunter.berton at gene.com  Thu Oct 17 18:03:06 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 17 Oct 2013 09:03:06 -0700
Subject: [R] Subseting a data.frame
In-Reply-To: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
Message-ID: <CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/d496b63b/attachment.pl>

From spyqqqdia at yahoo.com  Thu Oct 17 13:21:40 2013
From: spyqqqdia at yahoo.com (Michael Meyer)
Date: Thu, 17 Oct 2013 19:21:40 +0800 (SGT)
Subject: [R] S4 base class
Message-ID: <1382008900.89988.YahooMailNeo@web193405.mail.sg3.yahoo.com>

Greetings,

I have an S4 class "B" (Base) which defines a function f=f(this="B",...) 
Dervided from?B we have a derived class D which also defines a function f=f(this="D",...)

In the definition of D::f we want to call the version B::f and could do this by simply?calling

f(baseClassObject(this),...)

The question is the following:

How do I refer to the base class?object from the derived class?



Many thanks?

?
Michael Meyer


From teecheelip at gmail.com  Thu Oct 17 08:40:02 2013
From: teecheelip at gmail.com (CL Tee)
Date: Thu, 17 Oct 2013 14:40:02 +0800
Subject: [R] Singular Matrix 'a' in solve
Message-ID: <CAEedSfdUJY-3VZ=knYXiwgCxk_zWyOTeqo78L1Ukt1MzUT=Ptg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/71d22186/attachment.pl>

From timo_schmid at hotmail.com  Thu Oct 17 15:38:03 2013
From: timo_schmid at hotmail.com (Timo Schmid)
Date: Thu, 17 Oct 2013 15:38:03 +0200
Subject: [R] Incorporate Julia into R
Message-ID: <DUB115-W5920BFB0459EAB554DE0F797050@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/803b9df6/attachment.pl>

From umut.toprak at unige.ch  Thu Oct 17 14:59:31 2013
From: umut.toprak at unige.ch (Umut Toprak)
Date: Thu, 17 Oct 2013 14:59:31 +0200
Subject: [R] representing points in 3D space with trajectories over time
Message-ID: <CADyQWt3pdn2vTfY9guhBGTppnASNzFXmqLDyqGzfwosyXfg=bQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/ba4598b2/attachment.pl>

From rmh at temple.edu  Thu Oct 17 18:05:45 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 17 Oct 2013 12:05:45 -0400
Subject: [R] Lattice xyplot: Fill Legend Points
In-Reply-To: <alpine.LNX.2.00.1310170844490.3144@salmo.appl-ecosys.com>
References: <alpine.LNX.2.00.1310170813150.3144@salmo.appl-ecosys.com>
	<CAGx1TMAW2oCb+yWO_dM_QHnd3366DU6ans-AttUp4o-4sH-png@mail.gmail.com>
	<alpine.LNX.2.00.1310170844490.3144@salmo.appl-ecosys.com>
Message-ID: <CAGx1TMCKVXp_x=i6Nh=KTePeevzVtaVeHZNyjM2omciicrTaLA@mail.gmail.com>

par.settings = list(
   superpose.points = list(col = rainbow(7), pch = 19),
   superpose.lines = list(col = rainbow(7))
)

On Thu, Oct 17, 2013 at 11:48 AM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> On Thu, 17 Oct 2013, Richard M. Heiberger wrote:
>
>> put the pch into the par.settings
>
>
> Richard,
>
>   Tried this again, but I'm not finding the proper location within
> par.settings.
>
>
> par.settings = list(superpose.points = list(col = rainbow(7)),
> superpose.lines = list(col = rainbow(7)), pch = 19)
>
>
> If I put it prior to the (list ... group there's an error of an extra = ;
> when I put it anywhere in the list (the above is one of my tries), it has no
> effect on the legend symbols: they remain as outlines.
>
>   What have I missed?
>
>
> Thanks,
>
> Rich
>
> --
> Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
> Applied Ecosystem Services, Inc.   |
> <http://www.appl-ecosys.com>     Voice: 503-667-4517      Fax: 503-667-8863
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rshepard at appl-ecosys.com  Thu Oct 17 18:12:48 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 17 Oct 2013 09:12:48 -0700 (PDT)
Subject: [R] Lattice xyplot: Fill Legend Points
In-Reply-To: <CAGx1TMCKVXp_x=i6Nh=KTePeevzVtaVeHZNyjM2omciicrTaLA@mail.gmail.com>
References: <alpine.LNX.2.00.1310170813150.3144@salmo.appl-ecosys.com>
	<CAGx1TMAW2oCb+yWO_dM_QHnd3366DU6ans-AttUp4o-4sH-png@mail.gmail.com>
	<alpine.LNX.2.00.1310170844490.3144@salmo.appl-ecosys.com>
	<CAGx1TMCKVXp_x=i6Nh=KTePeevzVtaVeHZNyjM2omciicrTaLA@mail.gmail.com>
Message-ID: <alpine.LNX.2.00.1310170911400.3144@salmo.appl-ecosys.com>

On Thu, 17 Oct 2013, Richard M. Heiberger wrote:

> par.settings = list(
>   superpose.points = list(col = rainbow(7), pch = 19),
>   superpose.lines = list(col = rainbow(7))
> )

   I had tried that, too. Legend symbols stubbornly remain unfilled.

Thanks, Richard,

Rich


From bretschr at xs4all.nl  Thu Oct 17 18:14:55 2013
From: bretschr at xs4all.nl (Bretschneider (R))
Date: Thu, 17 Oct 2013 18:14:55 +0200
Subject: [R] plot - how to vary the distances of the x axis?
In-Reply-To: <CAKyZeBuCHEFvotADYn7sn-N-D_k=DTFgTbXRZHMqjj9NofJy+Q@mail.gmail.com>
References: <CAKyZeBuCHEFvotADYn7sn-N-D_k=DTFgTbXRZHMqjj9NofJy+Q@mail.gmail.com>
Message-ID: <B3C8801B-82F7-4931-89BB-594E4FDB248D@xs4all.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/0373ddcb/attachment.pl>

From rmh at temple.edu  Thu Oct 17 18:19:40 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 17 Oct 2013 12:19:40 -0400
Subject: [R] Lattice xyplot: Fill Legend Points
In-Reply-To: <alpine.LNX.2.00.1310170911400.3144@salmo.appl-ecosys.com>
References: <alpine.LNX.2.00.1310170813150.3144@salmo.appl-ecosys.com>
	<CAGx1TMAW2oCb+yWO_dM_QHnd3366DU6ans-AttUp4o-4sH-png@mail.gmail.com>
	<alpine.LNX.2.00.1310170844490.3144@salmo.appl-ecosys.com>
	<CAGx1TMCKVXp_x=i6Nh=KTePeevzVtaVeHZNyjM2omciicrTaLA@mail.gmail.com>
	<alpine.LNX.2.00.1310170911400.3144@salmo.appl-ecosys.com>
Message-ID: <CAGx1TMBA1nsaUmpoxTNarNRp2EnhjZrHETMLLrLFNrgfwwa+2Q@mail.gmail.com>

That should have worked.  I think something else is interfering.
Did you redefine either T or F?

Please send the output from dput(head(ffg.st))
so we can experiment in your setting.

Rich

On Thu, Oct 17, 2013 at 12:12 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> On Thu, 17 Oct 2013, Richard M. Heiberger wrote:
>
>> par.settings = list(
>>   superpose.points = list(col = rainbow(7), pch = 19),
>>   superpose.lines = list(col = rainbow(7))
>> )
>
>
>   I had tried that, too. Legend symbols stubbornly remain unfilled.
>
> Thanks, Richard,
>
> Rich
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Thu Oct 17 18:41:29 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 17 Oct 2013 10:41:29 -0600
Subject: [R] Constraint on regression parameters
In-Reply-To: <1382003102.27828.YahooMailNeo@web172401.mail.ir2.yahoo.com>
References: <1382003102.27828.YahooMailNeo@web172401.mail.ir2.yahoo.com>
Message-ID: <CAFEqCdyJQohwhczvbHZNFdru=Mp7NS=aVV2WvjpScY7KeOQxUw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/22e95519/attachment.pl>

From tim.umbach at hufw.de  Thu Oct 17 18:48:35 2013
From: tim.umbach at hufw.de (Tim Umbach)
Date: Thu, 17 Oct 2013 18:48:35 +0200
Subject: [R] Selecting maximums between different variables
Message-ID: <CA+iePbmtiuvV-AwL3SV_G+mQZOuXoc_kSV+jER3SGaHsQVWhMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/433e72e9/attachment.pl>

From rshepard at appl-ecosys.com  Thu Oct 17 18:57:44 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 17 Oct 2013 09:57:44 -0700 (PDT)
Subject: [R] Lattice xyplot: Fill Legend Points
In-Reply-To: <CAGx1TMBA1nsaUmpoxTNarNRp2EnhjZrHETMLLrLFNrgfwwa+2Q@mail.gmail.com>
References: <alpine.LNX.2.00.1310170813150.3144@salmo.appl-ecosys.com>
	<CAGx1TMAW2oCb+yWO_dM_QHnd3366DU6ans-AttUp4o-4sH-png@mail.gmail.com>
	<alpine.LNX.2.00.1310170844490.3144@salmo.appl-ecosys.com>
	<CAGx1TMCKVXp_x=i6Nh=KTePeevzVtaVeHZNyjM2omciicrTaLA@mail.gmail.com>
	<alpine.LNX.2.00.1310170911400.3144@salmo.appl-ecosys.com>
	<CAGx1TMBA1nsaUmpoxTNarNRp2EnhjZrHETMLLrLFNrgfwwa+2Q@mail.gmail.com>
Message-ID: <alpine.LNX.2.00.1310170956040.3144@salmo.appl-ecosys.com>

On Thu, 17 Oct 2013, Richard M. Heiberger wrote:

> That should have worked.

   That's what I thought when I first tried it.

> I think something else is interfering. Did you redefine either T or F?

   Not intentionally.

> Please send the output from dput(head(ffg.st)) so we can experiment in
> your setting.

structure(list(sampdate = structure(c(13326, 13326, 13326, 13326, 
13326, 13326), class = "Date"), func_feed_grp = structure(c(1L, 
2L, 3L, 4L, 6L, 7L), .Label = c("Filterer", "Gatherer", "Grazer", 
"Omnivore", "Parasite", "Predator", "Shredder"), class = "factor"),
     quant = c(812L, 1880L, 624L, 11L, 948L, 1540L), pct.quant = c(0.14,
     0.323, 0.107, 0.002, 0.163, 0.265), num.taxa = c(11L, 28L,
     4L, 1L, 12L, 3L), pct.num.taxa = c(0.186, 0.475, 0.068, 0.017,
     0.203, 0.051)), .Names = c("sampdate", "func_feed_grp", "quant", 
"pct.quant", "num.taxa", "pct.num.taxa"), row.names = 102:107, class =
"data.frame")

Rich

-- 
Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
Applied Ecosystem Services, Inc.   |
<http://www.appl-ecosys.com>     Voice: 503-667-4517      Fax: 503-667-8863


From 538280 at gmail.com  Thu Oct 17 19:14:50 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 17 Oct 2013 11:14:50 -0600
Subject: [R] Comparing two groups
In-Reply-To: <1381838488519-4678277.post@n4.nabble.com>
References: <1381736946485-4678190.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B96D50@SRVEXCHMBX.precheza.cz>
	<1381838488519-4678277.post@n4.nabble.com>
Message-ID: <CAFEqCdzoKwK-pXNFuZxk9cbSAsXt=HQbJfWVunBrs3GRjQqMCQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/8431c4d5/attachment.pl>

From lpfgarcia at gmail.com  Thu Oct 17 19:21:50 2013
From: lpfgarcia at gmail.com (=?ISO-8859-1?Q?Lu=EDs_Paulo_F=2E_Garcia?=)
Date: Thu, 17 Oct 2013 14:21:50 -0300
Subject: [R] RWeka and multicore package
Message-ID: <CAPK6mFru7FFPXLnivwzpDxi_GMqk_yVNpDvNTXz2nUTyWgLeMQ@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/9085e810/attachment.pl>

From mtmorgan at fhcrc.org  Thu Oct 17 19:27:06 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 17 Oct 2013 10:27:06 -0700
Subject: [R] S4 base class
In-Reply-To: <1382025268.48593.YahooMailNeo@web193404.mail.sg3.yahoo.com>
References: <1382025268.48593.YahooMailNeo@web193404.mail.sg3.yahoo.com>
Message-ID: <52601DEA.8040807@fhcrc.org>

On 10/17/2013 08:54 AM, Michael Meyer wrote:

> Suppose you have a base class "Base" which implements a function "Base::F"
> which works in most contexts but not in the context of "ComplicatedDerived" class
> where some preparation has to happen before this very same function can be called.
>
> You would then define
>
> void ComplicatedDerived::F(...){
>
>      preparation();
>      Base::F();
> }
>
> You can nealry duplicate this in R via
>
> setMethod("F",
> signature(this="ComplicatedDerived"),
> definition=function(this){
>
>      preparation(this)
>      F(as(this,"Base"))
> })
>
> but it will fail whenever F uses virtual functions (i.e. generics) which are only defined
> for derived classes of Base

With

   .A <- setClass("A", representation(a="numeric"))
   .B <- setClass("B", representation(b="numeric"), contains="A")

   setGeneric("f", function(x, ...) standardGeneric("f"))

   setMethod("f", "A", function(x, ...) {
       message("f,A-method")
       g(x, ...)   # generic with methods only for derived classes
   })

   setMethod("f", "B", function(x, ...) {
       message("f,B-method")
       callNextMethod(x, ...)  # earlier response from Duncan Murdoch
   })

   setGeneric("g", function(x, ...) standardGeneric("g"))

   setMethod("g", "B", function(x, ...) {
       message("g,B-method")
       x
   })

one has

 > f(.B())
f,B-method
f,A-method
g,B-method

An object of class "B"
Slot "b":
numeric(0)

Slot "a":
numeric(0)

?


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From ceoriley at gmail.com  Thu Oct 17 19:28:00 2013
From: ceoriley at gmail.com (CEO'Riley)
Date: Thu, 17 Oct 2013 12:28:00 -0500
Subject: [R] RWeka and multicore package
In-Reply-To: <CAPK6mFru7FFPXLnivwzpDxi_GMqk_yVNpDvNTXz2nUTyWgLeMQ@mail.gmail.com>
References: <CAPK6mFru7FFPXLnivwzpDxi_GMqk_yVNpDvNTXz2nUTyWgLeMQ@mail.gmail.com>
Message-ID: <01d401cecb5e$3ae0f9f0$b0a2edd0$@gmail.com>

I received the following error message with the multicore package:

install.packages("multicore")
Warning in install.packages :
  package ?multicore? is not available (for R version 3.0.2)
Warning in install.packages :
  package ?multicore? is not available (for R version 3.0.2)
Warning message:
package ?multicore? is not available (for R version 3.0.2)


With gratitude,
CEO'Riley Jr.
Charles Ellis O'Riley Jr.

Ambition is a state of permanent dissatisfaction with the present


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Lu?s Paulo F. Garcia
Sent: Thursday, October 17, 2013 12:22 PM
To: r-help at r-project.org
Subject: [R] RWeka and multicore package

I work very mutch with the packages RWeka and multicore. If you try to run
J48 or any tree of RWeka with multicore we hava some errors.

Example I:

library(RWeka);
library(multicore);

mclapply(1:100, function(i) {
    J48(Species ~., iris);
});


Output:  "Error in .jcall(o, \"Ljava/lang/Class;\", \"getClass\") : \n
java.lang.ClassFormatError: Incompatible magic value 1347093252 in class
file java/lang/ProcessEnvironment$StringEnvironment\n"


Example II:

library(multicore);

mclapply(1:100, function(i) {
    RWeka::J48(Species ~., iris);
});

Output: Erro em .jcall(x$classifier, "S", "toString") :
  RcallMethod: attempt to call a method of a NULL object.


Do you know some way to work with parallel processing and RWeka? I tried MPI
and SNOW without success.

R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Ubuntu 12.04 x64


--
Lums Paulo Faina Garcia
Engenheiro de Computagco - Universidade de Sco Paulo Sco Carlos - SP -
Brasil

	[[alternative HTML version deleted]]


From smartpink111 at yahoo.com  Thu Oct 17 19:33:04 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 17 Oct 2013 10:33:04 -0700 (PDT)
Subject: [R] Selecting maximums between different variables
In-Reply-To: <CA+iePbmtiuvV-AwL3SV_G+mQZOuXoc_kSV+jER3SGaHsQVWhMQ@mail.gmail.com>
References: <CA+iePbmtiuvV-AwL3SV_G+mQZOuXoc_kSV+jER3SGaHsQVWhMQ@mail.gmail.com>
Message-ID: <1382031184.19399.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
You may try:


unlist(lapply(seq_len(nrow(oil)),function(i) oil[i,-1][which.max(oil[i,-1])])) 
?#? CA??? ND 
#40000 60000?
#or
library(reshape2)

datM <- melt(oil,id.var="YEAR")


datM[as.logical(with(datM,ave(value,list(YEAR),FUN= function(x) x%in% max(x)))),]
#? YEAR variable value
#3 2011?????? CA 40000
#8 2012?????? ND 60000

A.K.




On Thursday, October 17, 2013 12:50 PM, Tim Umbach <tim.umbach at hufw.de> wrote:
Hi there,

another beginners question, I'm afraid. Basically i want to selct the
maximum of values, that correspond to different variables. I have a table
of oil production that looks somewhat like this:

oil <- data.frame( YEAR = c(2011, 2012),
? ? ? ? ? ? ? ? ?? TX = c(20000, 30000),
? ? ? ? ? ? ? ? ?? CA = c(40000, 25000),
? ? ? ? ? ? ? ? ?? AL = c(20000,
21000),

? ? ? ? ? ? ? ? ?? ND = c(21000,60000))

Now I want to find out, which state produced most oil in a given year. I
tried this:

attach(oil)
last_year = oil[ c(YEAR == 2012), ]
max(last_year)

Which works, but it doesnt't give me the corresponding values (i.e. it just
gives me the maximum output, not what state its from).
So I tried this:

oil[c(oil == max(last_year)),]
and this:
oil[c(last_year == max(last_year)),]
and this:
oil[which.max(last_year),]
and this:
last_year[max(last_year),]

None of them work, but they don't give error messages either, the output is
just "NA". The problem is, in my eyes, that I'm comparing the values of
different variables with each other. Because if i change the structure of
the dataframe (which I can't do with the real data, at least not with out
doing it by hand with a huge dataset), it looks like this and works
perfectly:

oil2 <- data.frame (
? names = c('YEAR', 'TX', 'CA', 'AL', 'ND'),
? oil_2011 = c(2011, 20000, 40000, 20000, 21000),
? oil_2012 = c(2012, 30000, 25000, 21000, 60000)
? )
attach(oil2)
oil2[c(oil_2012 == max(oil_2012)),]

Any help is much appreciated.

Thanks, Tim Umbach

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From 538280 at gmail.com  Thu Oct 17 19:34:58 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 17 Oct 2013 11:34:58 -0600
Subject: [R] Weighted regression markers on scatter plots
In-Reply-To: <1381943066063-4678370.post@n4.nabble.com>
References: <1381943066063-4678370.post@n4.nabble.com>
Message-ID: <CAFEqCdwStGjttki+zpCLmaGFjrdjQPqSx=4JLu8_e_6jnvpx5A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/f11c44ad/attachment.pl>

From bhh at xs4all.nl  Thu Oct 17 19:41:22 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 17 Oct 2013 19:41:22 +0200
Subject: [R] Selecting maximums between different variables
In-Reply-To: <CA+iePbmtiuvV-AwL3SV_G+mQZOuXoc_kSV+jER3SGaHsQVWhMQ@mail.gmail.com>
References: <CA+iePbmtiuvV-AwL3SV_G+mQZOuXoc_kSV+jER3SGaHsQVWhMQ@mail.gmail.com>
Message-ID: <3DAD0987-AF75-406A-9EEE-2F61DD3EC8F0@xs4all.nl>


On 17-10-2013, at 18:48, Tim Umbach <tim.umbach at hufw.de> wrote:

> Hi there,
> 
> another beginners question, I'm afraid. Basically i want to selct the
> maximum of values, that correspond to different variables. I have a table
> of oil production that looks somewhat like this:
> 
> oil <- data.frame( YEAR = c(2011, 2012),
>                   TX = c(20000, 30000),
>                   CA = c(40000, 25000),
>                   AL = c(20000,
> 21000),
> 
>                   ND = c(21000,60000))
> 
> Now I want to find out, which state produced most oil in a given year. I
> tried this:
> 
> attach(oil)
> last_year = oil[ c(YEAR == 2012), ]
> max(last_year)
> 

For a single year do

year <- which(oil[,"YEAR"]==2011)
oil[year,which.max(oil[year,]),drop=FALSE]

In the help look at base::[.data.frame	

Berend


> Which works, but it doesnt't give me the corresponding values (i.e. it just
> gives me the maximum output, not what state its from).
> So I tried this:
> 
> oil[c(oil == max(last_year)),]
> and this:
> oil[c(last_year == max(last_year)),]
> and this:
> oil[which.max(last_year),]
> and this:
> last_year[max(last_year),]
> 
> None of them work, but they don't give error messages either, the output is
> just "NA". The problem is, in my eyes, that I'm comparing the values of
> different variables with each other. Because if i change the structure of
> the dataframe (which I can't do with the real data, at least not with out
> doing it by hand with a huge dataset), it looks like this and works
> perfectly:
> 
> oil2 <- data.frame (
>  names = c('YEAR', 'TX', 'CA', 'AL', 'ND'),
>  oil_2011 = c(2011, 20000, 40000, 20000, 21000),
>  oil_2012 = c(2012, 30000, 25000, 21000, 60000)
>  )
> attach(oil2)
> oil2[c(oil_2012 == max(oil_2012)),]
> 
> Any help is much appreciated.
> 
> Thanks, Tim Umbach
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Thu Oct 17 19:46:28 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 17 Oct 2013 11:46:28 -0600
Subject: [R] representing points in 3D space with trajectories over time
In-Reply-To: <CADyQWt3pdn2vTfY9guhBGTppnASNzFXmqLDyqGzfwosyXfg=bQ@mail.gmail.com>
References: <CADyQWt3pdn2vTfY9guhBGTppnASNzFXmqLDyqGzfwosyXfg=bQ@mail.gmail.com>
Message-ID: <CAFEqCdx0FYUUaBXZGmPJiNhpS2=tg8Du6BOnLK=BYh8-cDdpPw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/fe395b6c/attachment.pl>

From katherine_gobin at yahoo.com  Thu Oct 17 19:59:44 2013
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Fri, 18 Oct 2013 01:59:44 +0800 (SGT)
Subject: [R] Subseting a data.frame
In-Reply-To: <CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>
Message-ID: <1382032784.1242.YahooMailNeo@web193201.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/8b27f35a/attachment.pl>

From katherine_gobin at yahoo.com  Thu Oct 17 20:04:37 2013
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Fri, 18 Oct 2013 02:04:37 +0800 (SGT)
Subject: [R] Subseting a data.frame
In-Reply-To: <1382032784.1242.YahooMailNeo@web193201.mail.sg3.yahoo.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>
	<1382032784.1242.YahooMailNeo@web193201.mail.sg3.yahoo.com>
Message-ID: <1382033077.8442.YahooMailNeo@web193206.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/d00e334f/attachment.pl>

From rmh at temple.edu  Thu Oct 17 20:15:07 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 17 Oct 2013 14:15:07 -0400
Subject: [R] Lattice xyplot: Fill Legend Points
In-Reply-To: <alpine.LNX.2.00.1310170956040.3144@salmo.appl-ecosys.com>
References: <alpine.LNX.2.00.1310170813150.3144@salmo.appl-ecosys.com>
	<CAGx1TMAW2oCb+yWO_dM_QHnd3366DU6ans-AttUp4o-4sH-png@mail.gmail.com>
	<alpine.LNX.2.00.1310170844490.3144@salmo.appl-ecosys.com>
	<CAGx1TMCKVXp_x=i6Nh=KTePeevzVtaVeHZNyjM2omciicrTaLA@mail.gmail.com>
	<alpine.LNX.2.00.1310170911400.3144@salmo.appl-ecosys.com>
	<CAGx1TMBA1nsaUmpoxTNarNRp2EnhjZrHETMLLrLFNrgfwwa+2Q@mail.gmail.com>
	<alpine.LNX.2.00.1310170956040.3144@salmo.appl-ecosys.com>
Message-ID: <CAGx1TMAUBuB3VVJthj-d8vXLp=OcG5j3UujOSPZQ3O7ZiBsm3w@mail.gmail.com>

I always get lost in simpleKey.  The approach of directly modifying
the trellis object usually works.

> tmp <- xyplot(pct.quant ~ sampdate, data = ffg.st, groups = func_feed_grp, type =
+ 'p', pch = 19, key = simpleKey(text = levels(ffg.st$func_feed_grp), space =
+ 'right', points = T, lines = F),par.settings = list(superpose.points =
+ list(col = rainbow(7)), superpose.lines = list(col = rainbow(7))), main =
+ 'Functional Feeding Groups (Individuals)', xlab = 'Year', ylab = 'Proportion
+ of Individuals')
> tmp
> str(tmp)
> tmp$legend$right$args$key$points$pch
[1] 1 1 1 1 1 1 1
> tmp$legend$right$args$key$points$pch[] <- 19
> tmp$legend$right$args$key$points$pch
[1] 19 19 19 19 19 19 19
> tmp
>

Rich

On Thu, Oct 17, 2013 at 12:57 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> On Thu, 17 Oct 2013, Richard M. Heiberger wrote:
>
>> That should have worked.
>
>
>   That's what I thought when I first tried it.
>
>
>> I think something else is interfering. Did you redefine either T or F?
>
>
>   Not intentionally.
>
>
>> Please send the output from dput(head(ffg.st)) so we can experiment in
>> your setting.
>
>
> structure(list(sampdate = structure(c(13326, 13326, 13326, 13326, 13326,
> 13326), class = "Date"), func_feed_grp = structure(c(1L, 2L, 3L, 4L, 6L,
> 7L), .Label = c("Filterer", "Gatherer", "Grazer", "Omnivore", "Parasite",
> "Predator", "Shredder"), class = "factor"),
>     quant = c(812L, 1880L, 624L, 11L, 948L, 1540L), pct.quant = c(0.14,
>     0.323, 0.107, 0.002, 0.163, 0.265), num.taxa = c(11L, 28L,
>     4L, 1L, 12L, 3L), pct.num.taxa = c(0.186, 0.475, 0.068, 0.017,
>     0.203, 0.051)), .Names = c("sampdate", "func_feed_grp", "quant",
> "pct.quant", "num.taxa", "pct.num.taxa"), row.names = 102:107, class =
> "data.frame")
>
>
> Rich
>
> --
> Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
> Applied Ecosystem Services, Inc.   |
> <http://www.appl-ecosys.com>     Voice: 503-667-4517      Fax: 503-667-8863
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From spyqqqdia at yahoo.com  Thu Oct 17 20:15:19 2013
From: spyqqqdia at yahoo.com (Michael Meyer)
Date: Fri, 18 Oct 2013 02:15:19 +0800 (SGT)
Subject: [R] S4 base class
Message-ID: <1382033719.43684.YahooMailNeo@web193403.mail.sg3.yahoo.com>

@Martin Morgan, Duncan Murdoch:

OK Thanks.
I did not understand the callNextMethod.
I will investigate this in detail.
This is great!

Thanks again,

?
Michael Meyer


From smartpink111 at yahoo.com  Thu Oct 17 20:33:46 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 17 Oct 2013 11:33:46 -0700 (PDT)
Subject: [R] Subseting a data.frame
In-Reply-To: <1382032784.1242.YahooMailNeo@web193201.mail.sg3.yahoo.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>
	<1382032784.1242.YahooMailNeo@web193201.mail.sg3.yahoo.com>
Message-ID: <1382034826.15146.YahooMailNeo@web142605.mail.bf1.yahoo.com>

You may try:
mydat[with(mydat,ave(seq_along(basel_asset_class),basel_asset_class,FUN=length)>2),]
#? basel_asset_class defa_frequency
#2???????????????? 8????????? 0.070
#3???????????????? 8????????? 0.030
#4???????????????? 8????????? 0.001


#or
library(plyr)
mydat[ddply(mydat,.(basel_asset_class),mutate,L=length(defa_frequency))[,3] >2,] #assuming it is sorted.

A.K.




On Thursday, October 17, 2013 1:59 PM, Katherine Gobin <katherine_gobin at yahoo.com> wrote:
?I am sorry perhaps ?was not able to put the question properly. I am not looking for the subset of the data.frame where the basel_asset_class is > 2. I do agree that would have been a basic requirement. Let me try to put the question again.?

I have a data frame as?

mydat = data.frame(basel_asset_class = c(4, 8, 8 ,8), defa_frequency = c(0.15, 0.07, 0.03, 0.001))

# Please note I have changed the basel_asset_class to 4 from 2, to avoid confusion.

> mydat
? basel_asset_class defa_frequency
1 ? ? ? ? ? ? ? ? 4 ? ? ? ? ?0.150
2 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.070
3 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.030
4 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.001



This is just an representative example. In reality, I may have no of basel asset classes. 4, 8 etc are the IDs can be anything thus I cant hard code it as subset(mydat, mydat$basel_asset_class > 2).


What I need is to select only those records for which there are more than two default frequencies (defa_frequency), Thus, there is only one default frequency = 0.150 w.r.t basel_asset_class = 4 whereas there are default frequencies w.r.t. basel aseet class 4, similarly there could be another basel asset class having say 5 default frequncies. Thus, I need to take subset of the data.frame s.t. the no of corresponding defa_frequencies is greater than 2.

The idea is we try to fit exponential curve Y = A exp( BX ) for each of the basel asset classes and to estimate values of A and B, mathematically one needs to have at least two values of X.

I hope I may be able to express my requirement. Its not that I need the subset of mydat s.t. basel asset class is > 2 (now 4 in revised example), but sbuset s.t. no of default frequencies is greater than or equal to 2. This 2 is not same as basel asset class 2.

Kindly guide

With warm regards

Katherine Gobin





On Thursday, 17 October 2013 9:33 PM, Bert Gunter <gunter.berton at gene.com> wrote:

"Kindly guide" ...

This is a very basic question, so the kindest guide I can give is to read an Introduction to R (ships with R) or a R web tutorial of your choice so that you can learn how R works instead of posting to this list.

Cheers,
Bert




On Wed, Oct 16, 2013 at 11:55 PM, Katherine Gobin <katherine_gobin at yahoo.com> wrote:

Dear Forum,
>
>I have a data frame as?
>
>mydat = data.frame(basel_asset_class = c(2, 8, 8 ,8), defa_frequency = c(0.15, 0.07, 0.03, 0.001))
>
>> mydat
>? basel_asset_class defa_frequency
>1 ? ? ? ? ? ? ? ? 2 ? ? ? ? ?0.150
>2 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.070
>3 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.030
>4 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.001
>
>
>I need to get the subset of this data.frame where no of records for the given basel_asset_class is > 2, i.e. I need to obtain subset of above data.frame as (since there is only 1 record, against basel_asset_class = 2, I want to filter it)
>
>> mydat_a
>? basel_asset_class defa_frequency
>1 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.070
>2 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.030
>3 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.001
>
>Kindly guide
>
>Katherine
>? ? ? ? [[alternative HTML version deleted]]
>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374
??? [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From rshepard at appl-ecosys.com  Thu Oct 17 20:37:56 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 17 Oct 2013 11:37:56 -0700 (PDT)
Subject: [R] Lattice xyplot: Fill Legend Points
In-Reply-To: <CAGx1TMAUBuB3VVJthj-d8vXLp=OcG5j3UujOSPZQ3O7ZiBsm3w@mail.gmail.com>
References: <alpine.LNX.2.00.1310170813150.3144@salmo.appl-ecosys.com>
	<CAGx1TMAW2oCb+yWO_dM_QHnd3366DU6ans-AttUp4o-4sH-png@mail.gmail.com>
	<alpine.LNX.2.00.1310170844490.3144@salmo.appl-ecosys.com>
	<CAGx1TMCKVXp_x=i6Nh=KTePeevzVtaVeHZNyjM2omciicrTaLA@mail.gmail.com>
	<alpine.LNX.2.00.1310170911400.3144@salmo.appl-ecosys.com>
	<CAGx1TMBA1nsaUmpoxTNarNRp2EnhjZrHETMLLrLFNrgfwwa+2Q@mail.gmail.com>
	<alpine.LNX.2.00.1310170956040.3144@salmo.appl-ecosys.com>
	<CAGx1TMAUBuB3VVJthj-d8vXLp=OcG5j3UujOSPZQ3O7ZiBsm3w@mail.gmail.com>
Message-ID: <alpine.LNX.2.00.1310171135490.3144@salmo.appl-ecosys.com>

On Thu, 17 Oct 2013, Richard M. Heiberger wrote:

> I always get lost in simpleKey.

   As this is my first use of it I take what's offered by those more
experienced than I.

> The approach of directly modifying the trellis object usually works.
> tmp <- xyplot(pct.quant ~ sampdate, data = ffg.st, groups = func_feed_grp, type =
> + 'p', pch = 19, key = simpleKey(text = levels(ffg.st$func_feed_grp), space =
> + 'right', points = T, lines = F),par.settings = list(superpose.points =
> + list(col = rainbow(7)), superpose.lines = list(col = rainbow(7))), main =
> + 'Functional Feeding Groups (Individuals)', xlab = 'Year', ylab = 'Proportion
> + of Individuals')
>> tmp
>> str(tmp)
>> tmp$legend$right$args$key$points$pch
> [1] 1 1 1 1 1 1 1
>> tmp$legend$right$args$key$points$pch[] <- 19
>> tmp$legend$right$args$key$points$pch
> [1] 19 19 19 19 19 19 19

   OK. More steps but it will get the plots where they need to be.

Many thanks,

Rich

-- 
Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
Applied Ecosystem Services, Inc.   |
<http://www.appl-ecosys.com>     Voice: 503-667-4517      Fax: 503-667-8863


From stockbeaver at ymail.com  Thu Oct 17 20:54:08 2013
From: stockbeaver at ymail.com (Stock Beaver)
Date: Thu, 17 Oct 2013 11:54:08 -0700 (PDT)
Subject: [R] Newb: How I find random vector index?
Message-ID: <1382036048.29787.YahooMailNeo@web140002.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/f1fe9083/attachment.pl>

From rflood02 at qub.ac.uk  Thu Oct 17 19:02:48 2013
From: rflood02 at qub.ac.uk (rflood13)
Date: Thu, 17 Oct 2013 10:02:48 -0700 (PDT)
Subject: [R] Goodness of fit for a Rietveld Refinement
Message-ID: <1382029368410-4678470.post@n4.nabble.com>

Hi folks,

Wondering if anyone might be able to help me on this one. I have just done
some geochemistry with X-ray Diffraction and Rietveld Refinement in order to
quantify the data. I have a observed spectra from my sample and a calculated
spectra from the Rietveld Refinement (in the attached image, along with the
background). I was wondering is there a package in R that I might be able to
use that would essentially show me how well (or how poorly) fitted the
Rietveld calculated spectra was with regard to my observed spectra? It's
essentially a goodness of fit or R-squared value but I've been having some
difficulty finding the right way to assess the model fit. I'd appreciate any
information or tips anyone might have.

Kind regards,

Rory Flood.

--
Rory Flood
Postgraduate Research Student
Room 02 044, Elmwood Building
School of Geography, Archaeology and Palaeoecology
Queen's University Belfast
Belfast BT7 1NN
Co. Antrim
Northern Ireland

Tel: +44 (0) 28 9097 3929
Email: rflood02 at qub.ac.uk
__________________________________

<http://r.789695.n4.nabble.com/file/n4678470/Spectra.jpg> 



--
View this message in context: http://r.789695.n4.nabble.com/Goodness-of-fit-for-a-Rietveld-Refinement-tp4678470.html
Sent from the R help mailing list archive at Nabble.com.


From sarah.goslee at gmail.com  Thu Oct 17 21:05:23 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 17 Oct 2013 15:05:23 -0400
Subject: [R] Newb: How I find random vector index?
In-Reply-To: <1382036048.29787.YahooMailNeo@web140002.mail.bf1.yahoo.com>
References: <1382036048.29787.YahooMailNeo@web140002.mail.bf1.yahoo.com>
Message-ID: <CAM_vjumvzeRy4Wogm7q5Nbj_ALqjr0JdBWDiHyjgkWJCCL4GhQ@mail.gmail.com>

Not only does it not require a loop, this is a one-liner:

> myvec <- c(1,0,3,0,77,9,0,1,2,0)
> sample(which(myvec == 0), 1)
[1] 4
> sample(which(myvec == 0), 1)
[1] 7
> sample(which(myvec == 0), 1)
[1] 2

If there's a possibility of not having zeros then you'll need to check
that separately, otherwise sample() will throw an error. For instance:

if(any(myvec == 0)) {
  sample(which(myvec == 0), 1)
}

which() will

Sarah


On Thu, Oct 17, 2013 at 2:54 PM, Stock Beaver <stockbeaver at ymail.com> wrote:
> # Suppose I have a vector:
>
> myvec = c(1,0,3,0,77,9,0,1,2,0)
>
> # I want to randomly pick an element from myvec
> # where element == 0
> # and print the value of the corresponding index.
>
> # So, for example I might randomly pick the 3rd 0
> # and I would print the corresponding index
> # which is 7,
>
> # My initial approach is to use a for-loop.
> # Also I take a short-cut which assumes myvec is short:
>
> elm = 1
> while (elm != 0) {
>   # Pick a random index, (it might be a 0):
>   rndidx = round(runif(1, min=1, max=length(myvec)))
>   elm = myvec[rndidx]
>   if(elm == 0)
>     print("I am done")
>   else
>     print("I am not done")
> }
> print(rndidx)
>
> # If myvec is large and/or contains no zeros,
> # The above loop is sub-optimal/faulty.
>
> # I suspect that skilled R-people would approach this task differently.
> # Perhaps they would use features baked into R rather than use a loop?
>         [[alternative HTML version deleted]]
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Thu Oct 17 21:10:49 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 17 Oct 2013 15:10:49 -0400
Subject: [R] Newb: How I find random vector index?
In-Reply-To: <CAM_vjumvzeRy4Wogm7q5Nbj_ALqjr0JdBWDiHyjgkWJCCL4GhQ@mail.gmail.com>
References: <1382036048.29787.YahooMailNeo@web140002.mail.bf1.yahoo.com>
	<CAM_vjumvzeRy4Wogm7q5Nbj_ALqjr0JdBWDiHyjgkWJCCL4GhQ@mail.gmail.com>
Message-ID: <CAM_vjukrCDmm1bkHvBB+6XX4J++UqyHvw6=Lbe51BP9dJ67h7Q@mail.gmail.com>

Typo fix below:

On Thu, Oct 17, 2013 at 3:05 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> Not only does it not require a loop, this is a one-liner:
>
>> myvec <- c(1,0,3,0,77,9,0,1,2,0)
>> sample(which(myvec == 0), 1)
> [1] 4
>> sample(which(myvec == 0), 1)
> [1] 7
>> sample(which(myvec == 0), 1)
> [1] 2
>
> If there's a possibility of not having zeros then you'll need to check
> that separately, otherwise sample() will throw an error. For instance:
>
> if(any(myvec == 0)) {
>   sample(which(myvec == 0), 1)
> }
>
> which() will
  ^^^^^^^^^^^^^  just delete this.

>
> Sarah
>
>
> On Thu, Oct 17, 2013 at 2:54 PM, Stock Beaver <stockbeaver at ymail.com> wrote:
>> # Suppose I have a vector:
>>
>> myvec = c(1,0,3,0,77,9,0,1,2,0)
>>
>> # I want to randomly pick an element from myvec
>> # where element == 0
>> # and print the value of the corresponding index.
>>
>> # So, for example I might randomly pick the 3rd 0
>> # and I would print the corresponding index
>> # which is 7,
>>
>> # My initial approach is to use a for-loop.
>> # Also I take a short-cut which assumes myvec is short:
>>
>> elm = 1
>> while (elm != 0) {
>>   # Pick a random index, (it might be a 0):
>>   rndidx = round(runif(1, min=1, max=length(myvec)))
>>   elm = myvec[rndidx]
>>   if(elm == 0)
>>     print("I am done")
>>   else
>>     print("I am not done")
>> }
>> print(rndidx)
>>
>> # If myvec is large and/or contains no zeros,
>> # The above loop is sub-optimal/faulty.
>>
>> # I suspect that skilled R-people would approach this task differently.
>> # Perhaps they would use features baked into R rather than use a loop?
>>         [[alternative HTML version deleted]]
>>
>

-- 
Sarah Goslee


From dwinsemius at comcast.net  Thu Oct 17 21:14:09 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 17 Oct 2013 12:14:09 -0700
Subject: [R] Weighted regression markers on scatter plots
In-Reply-To: <1381943066063-4678370.post@n4.nabble.com>
References: <1381943066063-4678370.post@n4.nabble.com>
Message-ID: <23713CFB-021B-4627-AFE1-680B4F7E2B09@comcast.net>


On Oct 16, 2013, at 10:04 AM, Msugarman wrote:

> Hi all,
> 
> I'm trying to graph the results of a weighted regression analysis. Is anyone
> aware of a way to make my markers appear a different sizes to be consistent
> with their respective weights?

You have not produced any data or code. If using base graphics then `plot.default` accepta vector for cex.


> 
> Thanks,
> -Mike Sugarman
> Wayne State University
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Weighted-regression-markers-on-scatter-plots-tp4678370.html
> Sent from the R help mailing list archive at Nabble.com.

David Winsemius
Alameda, CA, USA


From diggsb at ohsu.edu  Thu Oct 17 21:17:39 2013
From: diggsb at ohsu.edu (Brian Diggs)
Date: Thu, 17 Oct 2013 19:17:39 +0000
Subject: [R] Newb: How I find random vector index?
References: <1382036048.29787.YahooMailNeo@web140002.mail.bf1.yahoo.com>
Message-ID: <49F59CE1FDF43441BE9EE55EB76C4544018DD9@EXMB06.ohsu.edu>

On 10/17/2013 11:54 AM, Stock Beaver wrote:
> # Suppose I have a vector:
>
> myvec = c(1,0,3,0,77,9,0,1,2,0)
>
> # I want to randomly pick an element from myvec
> # where element == 0
> # and print the value of the corresponding index.
>
> # So, for example I might randomly pick the 3rd 0
> # and I would print the corresponding index
> # which is 7,
>
> # My initial approach is to use a for-loop.
> # Also I take a short-cut which assumes myvec is short:
>
> elm = 1
> while (elm != 0) {
>    # Pick a random index, (it might be a 0):
>    rndidx = round(runif(1, min=1, max=length(myvec)))
>    elm = myvec[rndidx]
>    if(elm == 0)
>      print("I am done")
>    else
>      print("I am not done")
> }
> print(rndidx)

It's a little easier if you re-arrange your problem statement. This is 
equivalent: return randomly one index of myvec for which the element of 
myvec equals 0. A direct implementation of this is

sample(which(myvec==0), 1)

which(myvec==0) returns a vector of indexes of myvec for which the value 
of the vector is 0. sample(..., 1) randomly selects one of those.

> # If myvec is large and/or contains no zeros,
> # The above loop is sub-optimal/faulty.

This approach also fails if there is no 0's in the vector. What do you 
want the result to be when that is the case? If we go with the simple 
answer of NA, then you can special case that (and wrap it up into a 
function)

OneZeroIndex <- function(myvec) {
   zeros <- which(myvec==0)
   if (length(zeros) > 0) {
     sample(zeros, 1)
   } else {
     NA
   }
}

> # I suspect that skilled R-people would approach this task differently.
> # Perhaps they would use features baked into R rather than use a loop?
> 	[[alternative HTML version deleted]]
Please post plain text only.

-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From smartpink111 at yahoo.com  Thu Oct 17 21:17:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 17 Oct 2013 12:17:43 -0700 (PDT)
Subject: [R] Selecting maximums between different variables
In-Reply-To: <1382031184.19399.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CA+iePbmtiuvV-AwL3SV_G+mQZOuXoc_kSV+jER3SGaHsQVWhMQ@mail.gmail.com>
	<1382031184.19399.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1382037463.15195.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

You could also check ?data.table() as it could be faster.

#Speed comparison


set.seed(498) 
oilT <- data.frame(YEAR=rep(rep(1800:2012,50),100),state=rep(rep(state.abb,each=213),100),value=sample(2000:80000,1065000,replace=TRUE),stringsAsFactors=FALSE)
system.time(res1 <- oilT[as.logical(with(oilT,ave(value,list(YEAR),FUN=function(x) x%in% max(x)))),])
# user? system elapsed 
#? 0.532?? 0.008?? 0.540 
?dim(res1) #as some years have duplicated maximums
#[1] 220?? 3

?res1[duplicated(res1[,1])|duplicated(res1[,1],fromLast=TRUE),]

library(data.table)
dt1 <- data.table(oilT,key='YEAR')
system.time( res2 <- dt1[dt1[,value %in% max(value),'YEAR']$V1])
#?? user? system elapsed 
#? 0.060?? 0.000?? 0.062 
?res1 <- res1[order(res1$YEAR),]
?row.names(res1) <- 1:nrow(res1)
?identical(res1,as.data.frame(res2))
#[1] TRUE


A.K.



On Thursday, October 17, 2013 1:35 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
You may try:


unlist(lapply(seq_len(nrow(oil)),function(i) oil[i,-1][which.max(oil[i,-1])])) 
?#? CA??? ND 
#40000 60000?
#or
library(reshape2)

datM <- melt(oil,id.var="YEAR")


datM[as.logical(with(datM,ave(value,list(YEAR),FUN= function(x) x%in% max(x)))),]
#? YEAR variable value
#3 2011?????? CA 40000
#8 2012?????? ND 60000

A.K.




On Thursday, October 17, 2013 12:50 PM, Tim Umbach <tim.umbach at hufw.de> wrote:
Hi there,

another beginners question, I'm afraid. Basically i want to selct the
maximum of values, that correspond to different variables. I have a table
of oil production that looks somewhat like this:

oil <- data.frame( YEAR = c(2011, 2012),
? ? ? ? ? ? ? ? ?? TX = c(20000, 30000),
? ? ? ? ? ? ? ? ?? CA = c(40000, 25000),
? ? ? ? ? ? ? ? ?? AL = c(20000,
21000),

? ? ? ? ? ? ? ? ?? ND = c(21000,60000))

Now I want to find out, which state produced most oil in a given year. I
tried this:

attach(oil)
last_year = oil[ c(YEAR == 2012), ]
max(last_year)

Which works, but it doesnt't give me the corresponding values (i.e. it just
gives me the maximum output, not what state its from).
So I tried this:

oil[c(oil == max(last_year)),]
and this:
oil[c(last_year == max(last_year)),]
and this:
oil[which.max(last_year),]
and this:
last_year[max(last_year),]

None of them work, but they don't give error messages either, the output is
just "NA". The problem is, in my eyes, that I'm comparing the values of
different variables with each other. Because if i change the structure of
the dataframe (which I can't do with the real data, at least not with out
doing it by hand with a huge dataset), it looks like this and works
perfectly:

oil2 <- data.frame (
? names = c('YEAR', 'TX', 'CA', 'AL', 'ND'),
? oil_2011 = c(2011, 20000, 40000, 20000, 21000),
? oil_2012 = c(2012, 30000, 25000, 21000, 60000)
? )
attach(oil2)
oil2[c(oil_2012 == max(oil_2012)),]

Any help is much appreciated.

Thanks, Tim Umbach

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Oct 17 21:36:40 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 17 Oct 2013 19:36:40 +0000
Subject: [R] Subseting a data.frame
In-Reply-To: <1382033077.8442.YahooMailNeo@web193206.mail.sg3.yahoo.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>
	<1382032784.1242.YahooMailNeo@web193201.mail.sg3.yahoo.com>
	<1382033077.8442.YahooMailNeo@web193206.mail.sg3.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0BC2C@PA-MBX01.na.tibco.com>

> What I need is to select only those records for which there are more than two default
> frequencies (defa_frequency),

Here is one way.  There are many others:
   > dat <- data.frame( # slightly less trivial example
        basel_asset_class=c(4,8,8,8,74,3,74),
        defa_frequency=(1:7)/8)
   > count_by_class <- with(dat, ave(numeric(length(basel_asset_class)), basel_asset_class, FUN=length))
   > cbind(dat, count_by_class) # see what we just computed
     basel_asset_class defa_frequency count_by_class
   1                 4          0.125              1
   2                 8          0.250              3
   3                 8          0.375              3
   4                 8          0.500              3
   5                74          0.625              2
   6                 3          0.750              1
   7                74          0.875              2
   > mydat[count_by_class>1, ] # I think this is what you are asking for
     basel_asset_class defa_frequency
   2                 8          0.250
   3                 8          0.375
   4                 8          0.500
   5                74          0.625
   7                74          0.875

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Katherine Gobin
> Sent: Thursday, October 17, 2013 11:05 AM
> To: Bert Gunter
> Cc: r-help at r-project.org
> Subject: Re: [R] Subseting a data.frame
> 
> Correction. (2nd para first three lines)
> 
> Pl read following line
> 
> What I need is to select only those records for which there are more than two default
> frequencies (defa_frequency), Thus, there is only one default frequency = 0.150 w.r.t
> basel_asset_class = 4 whereas there are default frequencies w.r.t. basel aseet class 4,
> 
> 
> as
> 
> What I need is to select only those records for which there are more than two default
> frequencies (defa_frequency), Thus, there is only one default frequency = 0.150 w.r.t
> basel_asset_class = 4 whereas there are THREE default frequencies w.r.t. basel aseet
> class 8,
> 
> 
> 
> I alpologize for the incovenience.
> 
> Regards
> 
> KAtherine
> 
> 
> 
> 
> 
> 
> 
> 
> On , Katherine Gobin <katherine_gobin at yahoo.com> wrote:
> 
> ?I am sorry perhaps ?was not able to put the question properly. I am not looking for the
> subset of the data.frame where the basel_asset_class is > 2. I do agree that would have
> been a basic requirement. Let me try to put the question again.
> 
> I have a data frame as
> 
> mydat = data.frame(basel_asset_class = c(4, 8, 8 ,8), defa_frequency = c(0.15, 0.07, 0.03,
> 0.001))
> 
> # Please note I have changed the basel_asset_class to 4 from 2, to avoid confusion.
> 
> > mydat
> ? basel_asset_class defa_frequency
> 1 ? ? ? ? ? ? ? ? 4 ? ? ? ? ?0.150
> 2 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.070
> 3 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.030
> 4 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.001
> 
> 
> 
> This is just an representative example. In reality, I may have no of basel asset classes. 4, 8
> etc are the IDs can be anything thus I cant hard code it as subset(mydat,
> mydat$basel_asset_class > 2).
> 
> 
> What I need is to select only those records for which there are more than two default
> frequencies (defa_frequency), Thus, there is only one default frequency = 0.150 w.r.t
> basel_asset_class = 4 whereas there are default frequencies w.r.t. basel aseet class 4,
> similarly there could be another basel asset class having say 5 default frequncies. Thus, I
> need to take subset of the data.frame s.t. the no of corresponding defa_frequencies is
> greater than 2.
> 
> The idea is we try to fit exponential curve Y = A exp( BX ) for each of the basel asset
> classes and to estimate values of A and B, mathematically one needs to have at least two
> values of X.
> 
> I hope I may be able to express my requirement. Its not that I need the subset of mydat
> s.t. basel asset class is > 2 (now 4 in revised example), but sbuset s.t. no of default
> frequencies is greater than or equal to 2. This 2 is not same as basel asset class 2.
> 
> Kindly guide
> 
> With warm regards
> 
> Katherine Gobin
> 
> 
> 
> 
> On Thursday, 17 October 2013 9:33 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> 
> "Kindly guide" ...
> 
> This is a very basic question, so the kindest guide I can give is to read an Introduction to R
> (ships with R) or a R web tutorial of your choice so that you can learn how R works
> instead of posting to this list.
> 
> Cheers,
> Bert
> 
> 
> 
> 
> On Wed, Oct 16, 2013 at 11:55 PM, Katherine Gobin <katherine_gobin at yahoo.com>
> wrote:
> 
> Dear Forum,
> >
> >I have a data frame as
> >
> >mydat = data.frame(basel_asset_class = c(2, 8, 8 ,8), defa_frequency = c(0.15, 0.07,
> 0.03, 0.001))
> >
> >> mydat
> >? basel_asset_class defa_frequency
> >1 ? ? ? ? ? ? ? ? 2 ? ? ? ? ?0.150
> >2 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.070
> >3 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.030
> >4 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.001
> >
> >
> >I need to get the subset of this data.frame where no of records for the given
> basel_asset_class is > 2, i.e. I need to obtain subset of above data.frame as (since there
> is only 1 record, against basel_asset_class = 2, I want to filter it)
> >
> >> mydat_a
> >? basel_asset_class defa_frequency
> >1 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.070
> >2 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.030
> >3 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.001
> >
> >Kindly guide
> >
> >Katherine
> >? ? ? ? [[alternative HTML version deleted]]
> >
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
> 
> --
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> (650) 467-7374
> 	[[alternative HTML version deleted]]


From jim at bitwrit.com.au  Thu Oct 17 21:46:46 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 18 Oct 2013 06:46:46 +1100
Subject: [R] Weighted regression markers on scatter plots
In-Reply-To: <1381943066063-4678370.post@n4.nabble.com>
References: <1381943066063-4678370.post@n4.nabble.com>
Message-ID: <52603EA6.1030708@bitwrit.com.au>

On 10/17/2013 04:04 AM, Msugarman wrote:
> Hi all,
>
> I'm trying to graph the results of a weighted regression analysis. Is anyone
> aware of a way to make my markers appear a different sizes to be consistent
> with their respective weights?
>
Hi Mike,
Have a look at the "size_n_color" function in the plotrix package.

Jim


From gunter.berton at gene.com  Thu Oct 17 22:05:34 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 17 Oct 2013 13:05:34 -0700
Subject: [R] Subseting a data.frame
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA0BC2C@PA-MBX01.na.tibco.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>
	<1382032784.1242.YahooMailNeo@web193201.mail.sg3.yahoo.com>
	<1382033077.8442.YahooMailNeo@web193206.mail.sg3.yahoo.com>
	<E66794E69CFDE04D9A70842786030B933FA0BC2C@PA-MBX01.na.tibco.com>
Message-ID: <CACk-te3qz8yuCPbFLf01ovvfvFmSU7jd6VRPa-ii4wVVpnSdMg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/1318d93a/attachment.pl>

From wdunlap at tibco.com  Thu Oct 17 22:34:09 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 17 Oct 2013 20:34:09 +0000
Subject: [R] Subseting a data.frame
In-Reply-To: <CACk-te3qz8yuCPbFLf01ovvfvFmSU7jd6VRPa-ii4wVVpnSdMg@mail.gmail.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>
	<1382032784.1242.YahooMailNeo@web193201.mail.sg3.yahoo.com>
	<1382033077.8442.YahooMailNeo@web193206.mail.sg3.yahoo.com>
	<E66794E69CFDE04D9A70842786030B933FA0BC2C@PA-MBX01.na.tibco.com>
	<CACk-te3qz8yuCPbFLf01ovvfvFmSU7jd6VRPa-ii4wVVpnSdMg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0BC9A@PA-MBX01.na.tibco.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/ec04e5a5/attachment.pl>

From gunter.berton at gene.com  Thu Oct 17 23:19:57 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 17 Oct 2013 14:19:57 -0700
Subject: [R] Subseting a data.frame
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA0BC9A@PA-MBX01.na.tibco.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>
	<1382032784.1242.YahooMailNeo@web193201.mail.sg3.yahoo.com>
	<1382033077.8442.YahooMailNeo@web193206.mail.sg3.yahoo.com>
	<E66794E69CFDE04D9A70842786030B933FA0BC2C@PA-MBX01.na.tibco.com>
	<CACk-te3qz8yuCPbFLf01ovvfvFmSU7jd6VRPa-ii4wVVpnSdMg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0BC9A@PA-MBX01.na.tibco.com>
Message-ID: <CACk-te2PfBO2Gjy92xBgcHUus1tEE7SO+Wyq9PtP7dbd5wSexQ@mail.gmail.com>

Thanks, Bill.

But ?ave specifically says:

ave(x, ..., FUN = mean)

Arguments:
x

A numeric.

So that it should not be expected to work properly if the argument is
not (coercible to) numeric. Nevertheless, defensive programming is
always wise.

Cheers,
Bert


On Thu, Oct 17, 2013 at 1:34 PM, William Dunlap <wdunlap at tibco.com> wrote:
>   May I ask why:
>     count_by_class <- with(dat, ave(numeric(length(basel_asset_class)),
> basel_asset_class, FUN=length))
>
>   should not be more simply done as:
>     count_by_class <- with(dat, ave(basel_asset_class, basel_asset_class,
> FUN=length))
>
> The way I did it would work if basel_asset_class were non-numeric.
>
> In ave(x, group, FUN=FUN), FUN's return value should be the same type as x
> (or
>
> you can get some odd type conversions).  E.g.,
>
>
>
>    > num <- c(2,3,2,2) ;  char <- c("Two","Three","Two","Two")
>
>    > ave(num, num, FUN=length) # good
>
>    [1] 3 1 3 3
>
>    > ave(char, char, FUN=length) # bad
>
>    [1] "3" "1" "3" "3"
>
>    > fac <- factor(char, levels=c("One","Two","Three"))
>
>    > ave(fac, fac, FUN=length)
>
>    [1] <NA> <NA> <NA> <NA>
>
>    Levels: One Two Three
>
>    Warning messages:
>
>    1: In `[<-.factor`(`*tmp*`, i, value = 0L) :
>
>      invalid factor level, NA generated
>
>    2: In `[<-.factor`(`*tmp*`, i, value = 3L) :
>
>      invalid factor level, NA generated
>
>    3: In `[<-.factor`(`*tmp*`, i, value = 1L) :
>
>      invalid factor level, NA generated
>
> but x=integer(length(group)) works in all cases:
>
>    > ave(integer(length(fac)), fac, FUN=length)
>
>    [1] 3 1 3 3
>
>    > ave(integer(length(char)), char, FUN=length)
>
>       [1] 3 1 3 3
>
>
>
> Bill Dunlap
>
> Spotfire, TIBCO Software
>
> wdunlap tibco.com
>
>
>
> From: Bert Gunter [mailto:gunter.berton at gene.com]
> Sent: Thursday, October 17, 2013 1:06 PM
> To: William Dunlap
> Cc: Katherine Gobin; r-help at r-project.org
> Subject: Re: [R] Subseting a data.frame
>
>
>
> May I ask why:
>
> count_by_class <- with(dat, ave(numeric(length(basel_
>
> asset_class)), basel_asset_class, FUN=length))
>
> should not be more simply done as:
>
> count_by_class <- with(dat, ave(basel_asset_class, basel_asset_class,
> FUN=length))
>
> ?
>
> -- Bert
>
>
>
> On Thu, Oct 17, 2013 at 12:36 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
>> What I need is to select only those records for which there are more than
>> two default
>> frequencies (defa_frequency),
>
> Here is one way.  There are many others:
>    > dat <- data.frame( # slightly less trivial example
>         basel_asset_class=c(4,8,8,8,74,3,74),
>         defa_frequency=(1:7)/8)
>    > count_by_class <- with(dat, ave(numeric(length(basel_asset_class)),
> basel_asset_class, FUN=length))
>    > cbind(dat, count_by_class) # see what we just computed
>      basel_asset_class defa_frequency count_by_class
>    1                 4          0.125              1
>    2                 8          0.250              3
>    3                 8          0.375              3
>    4                 8          0.500              3
>    5                74          0.625              2
>    6                 3          0.750              1
>    7                74          0.875              2
>    > mydat[count_by_class>1, ] # I think this is what you are asking for
>      basel_asset_class defa_frequency
>    2                 8          0.250
>    3                 8          0.375
>    4                 8          0.500
>    5                74          0.625
>    7                74          0.875
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf
>> Of Katherine Gobin
>> Sent: Thursday, October 17, 2013 11:05 AM
>> To: Bert Gunter
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Subseting a data.frame
>>
>> Correction. (2nd para first three lines)
>>
>> Pl read following line
>>
>> What I need is to select only those records for which there are more than
>> two default
>> frequencies (defa_frequency), Thus, there is only one default frequency =
>> 0.150 w.r.t
>> basel_asset_class = 4 whereas there are default frequencies w.r.t. basel
>> aseet class 4,
>>
>>
>> as
>>
>> What I need is to select only those records for which there are more than
>> two default
>> frequencies (defa_frequency), Thus, there is only one default frequency =
>> 0.150 w.r.t
>> basel_asset_class = 4 whereas there are THREE default frequencies w.r.t.
>> basel aseet
>> class 8,
>>
>>
>>
>> I alpologize for the incovenience.
>>
>> Regards
>>
>> KAtherine
>>
>>
>>
>>
>>
>>
>>
>>
>> On , Katherine Gobin <katherine_gobin at yahoo.com> wrote:
>>
>>  I am sorry perhaps  was not able to put the question properly. I am not
>> looking for the
>> subset of the data.frame where the basel_asset_class is > 2. I do agree
>> that would have
>> been a basic requirement. Let me try to put the question again.
>>
>> I have a data frame as
>>
>> mydat = data.frame(basel_asset_class = c(4, 8, 8 ,8), defa_frequency =
>> c(0.15, 0.07, 0.03,
>> 0.001))
>>
>> # Please note I have changed the basel_asset_class to 4 from 2, to avoid
>> confusion.
>>
>> > mydat
>>   basel_asset_class defa_frequency
>> 1                 4          0.150
>> 2                 8          0.070
>> 3                 8          0.030
>> 4                 8          0.001
>>
>>
>>
>> This is just an representative example. In reality, I may have no of basel
>> asset classes. 4, 8
>> etc are the IDs can be anything thus I cant hard code it as subset(mydat,
>> mydat$basel_asset_class > 2).
>>
>>
>> What I need is to select only those records for which there are more than
>> two default
>> frequencies (defa_frequency), Thus, there is only one default frequency =
>> 0.150 w.r.t
>> basel_asset_class = 4 whereas there are default frequencies w.r.t. basel
>> aseet class 4,
>> similarly there could be another basel asset class having say 5 default
>> frequncies. Thus, I
>> need to take subset of the data.frame s.t. the no of corresponding
>> defa_frequencies is
>> greater than 2.
>>
>> The idea is we try to fit exponential curve Y = A exp( BX ) for each of
>> the basel asset
>> classes and to estimate values of A and B, mathematically one needs to
>> have at least two
>> values of X.
>>
>> I hope I may be able to express my requirement. Its not that I need the
>> subset of mydat
>> s.t. basel asset class is > 2 (now 4 in revised example), but sbuset s.t.
>> no of default
>> frequencies is greater than or equal to 2. This 2 is not same as basel
>> asset class 2.
>>
>> Kindly guide
>>
>> With warm regards
>>
>> Katherine Gobin
>>
>>
>>
>>
>> On Thursday, 17 October 2013 9:33 PM, Bert Gunter <gunter.berton at gene.com>
>> wrote:
>>
>> "Kindly guide" ...
>>
>> This is a very basic question, so the kindest guide I can give is to read
>> an Introduction to R
>> (ships with R) or a R web tutorial of your choice so that you can learn
>> how R works
>> instead of posting to this list.
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> On Wed, Oct 16, 2013 at 11:55 PM, Katherine Gobin
>> <katherine_gobin at yahoo.com>
>> wrote:
>>
>> Dear Forum,
>> >
>> >I have a data frame as
>> >
>> >mydat = data.frame(basel_asset_class = c(2, 8, 8 ,8), defa_frequency =
>> > c(0.15, 0.07,
>> 0.03, 0.001))
>> >
>> >> mydat
>> >  basel_asset_class defa_frequency
>> >1                 2          0.150
>> >2                 8          0.070
>> >3                 8          0.030
>> >4                 8          0.001
>> >
>> >
>> >I need to get the subset of this data.frame where no of records for the
>> > given
>> basel_asset_class is > 2, i.e. I need to obtain subset of above data.frame
>> as (since there
>> is only 1 record, against basel_asset_class = 2, I want to filter it)
>> >
>> >> mydat_a
>> >  basel_asset_class defa_frequency
>> >1                 8          0.070
>> >2                 8          0.030
>> >3                 8          0.001
>> >
>> >Kindly guide
>> >
>> >Katherine
>> >        [[alternative HTML version deleted]]
>> >
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> (650) 467-7374
>>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374
>
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From smartpink111 at yahoo.com  Thu Oct 17 23:33:23 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 17 Oct 2013 14:33:23 -0700 (PDT)
Subject: [R] Subseting a data.frame
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA0BC9A@PA-MBX01.na.tibco.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>	<1382032784.1242.YahooMailNeo@web193201.mail.sg3.yahoo.com>	<1382033077.8442.YahooMailNeo@web193206.mail.sg3.yahoo.com>	<E66794E69CFDE04D9A70842786030B933FA0BC2C@PA-MBX01.na.tibco.com>	<CACk-te3qz8yuCPbFLf01ovvfvFmSU7jd6VRPa-ii4wVVpnSdMg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0BC9A@PA-MBX01.na.tibco.com>
Message-ID: <1382045603.87888.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi Bill,

#seq_along() worked in the cases you showed.

?ave(seq_along(fac),fac,FUN=length)
#[1] 3 1 3 3
? ave(seq_along(num), num, FUN=length) 
#[1] 3 1 3 3
? ave(seq_along(char), char, FUN=length) 
#[1] 3 1 3 3



I thought, there might be some advantages in speed, but they were similar in speed.
set.seed(195)
?num1 <- sample(1e3,1e7,replace=TRUE)
?system.time(res1 <- ave(integer(length(num1)),num1,FUN=length))
? # user? system elapsed 
? #4.148?? 0.228?? 4.382 
system.time(res2 <- ave(seq_along(num1),num1,FUN=length))
#?? user? system elapsed 
?# 3.944?? 0.228?? 4.181 
system.time(res3 <- ave(num1,num1,FUN=length))
#?? user? system elapsed 
?# 3.740?? 0.264?? 4.012 
identical(res1,res2)
#[1] TRUE
?identical(res2,res3)
#[1] TRUE


A.K. 




On Thursday, October 17, 2013 4:34 PM, William Dunlap <wdunlap at tibco.com> wrote:
? May I ask why:
? ? count_by_class <- with(dat, ave(numeric(length(basel_asset_class)), basel_asset_class, FUN=length))
? should not be more simply done as:
? ? count_by_class <- with(dat, ave(basel_asset_class, basel_asset_class, FUN=length))

The way I did it would work if basel_asset_class were non-numeric.
In ave(x, group, FUN=FUN), FUN's return value should be the same type as x (or
you can get some odd type conversions).? E.g.,

?  > num <- c(2,3,2,2) ;? char <- c("Two","Three","Two","Two")
?  > ave(num, num, FUN=length) # good
?  [1] 3 1 3 3
?  > ave(char, char, FUN=length) # bad
?  [1] "3" "1" "3" "3"
?  > fac <- factor(char, levels=c("One","Two","Three"))
?  > ave(fac, fac, FUN=length)
?  [1] <NA> <NA> <NA> <NA>
?  Levels: One Two Three
?  Warning messages:
?  1: In `[<-.factor`(`*tmp*`, i, value = 0L) :
? ?  invalid factor level, NA generated
?  2: In `[<-.factor`(`*tmp*`, i, value = 3L) :
? ?  invalid factor level, NA generated
?  3: In `[<-.factor`(`*tmp*`, i, value = 1L) :
? ?  invalid factor level, NA generated
but x=integer(length(group)) works in all cases:
?  > ave(integer(length(fac)), fac, FUN=length)
?  [1] 3 1 3 3
?  > ave(integer(length(char)), char, FUN=length)
? ? ? [1] 3 1 3 3

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

From: Bert Gunter [mailto:gunter.berton at gene.com]
Sent: Thursday, October 17, 2013 1:06 PM
To: William Dunlap
Cc: Katherine Gobin; r-help at r-project.org
Subject: Re: [R] Subseting a data.frame

May I ask why:

count_by_class <- with(dat, ave(numeric(length(basel_
asset_class)), basel_asset_class, FUN=length))
should not be more simply done as:

count_by_class <- with(dat, ave(basel_asset_class, basel_asset_class, FUN=length))

?
-- Bert

On Thu, Oct 17, 2013 at 12:36 PM, William Dunlap <wdunlap at tibco.com<mailto:wdunlap at tibco.com>> wrote:
> What I need is to select only those records for which there are more than two default
> frequencies (defa_frequency),

Here is one way.? There are many others:
?  > dat <- data.frame( # slightly less trivial example
? ? ? ? basel_asset_class=c(4,8,8,8,74,3,74),
? ? ? ? defa_frequency=(1:7)/8)
?  > count_by_class <- with(dat, ave(numeric(length(basel_asset_class)), basel_asset_class, FUN=length))
?  > cbind(dat, count_by_class) # see what we just computed
? ?  basel_asset_class defa_frequency count_by_class
?  1? ? ? ? ? ? ? ?  4? ? ? ? ? 0.125? ? ? ? ? ? ? 1
?  2? ? ? ? ? ? ? ?  8? ? ? ? ? 0.250? ? ? ? ? ? ? 3
?  3? ? ? ? ? ? ? ?  8? ? ? ? ? 0.375? ? ? ? ? ? ? 3
?  4? ? ? ? ? ? ? ?  8? ? ? ? ? 0.500? ? ? ? ? ? ? 3
?  5? ? ? ? ? ? ? ? 74? ? ? ? ? 0.625? ? ? ? ? ? ? 2
?  6? ? ? ? ? ? ? ?  3? ? ? ? ? 0.750? ? ? ? ? ? ? 1
?  7? ? ? ? ? ? ? ? 74? ? ? ? ? 0.875? ? ? ? ? ? ? 2
?  > mydat[count_by_class>1, ] # I think this is what you are asking for
? ?  basel_asset_class defa_frequency
?  2? ? ? ? ? ? ? ?  8? ? ? ? ? 0.250
?  3? ? ? ? ? ? ? ?  8? ? ? ? ? 0.375
?  4? ? ? ? ? ? ? ?  8? ? ? ? ? 0.500
?  5? ? ? ? ? ? ? ? 74? ? ? ? ? 0.625
?  7? ? ? ? ? ? ? ? 74? ? ? ? ? 0.875

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com<http://tibco.com>


> -----Original Message-----
> From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf
> Of Katherine Gobin
> Sent: Thursday, October 17, 2013 11:05 AM
> To: Bert Gunter
> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] Subseting a data.frame
>
> Correction. (2nd para first three lines)
>
> Pl read following line
>
> What I need is to select only those records for which there are more than two default
> frequencies (defa_frequency), Thus, there is only one default frequency = 0.150 w.r.t
> basel_asset_class = 4 whereas there are default frequencies w.r.t. basel aseet class 4,
>
>
> as
>
> What I need is to select only those records for which there are more than two default
> frequencies (defa_frequency), Thus, there is only one default frequency = 0.150 w.r.t
> basel_asset_class = 4 whereas there are THREE default frequencies w.r.t. basel aseet
> class 8,
>
>
>
> I alpologize for the incovenience.
>
> Regards
>
> KAtherine
>
>
>
>
>
>
>
>
> On , Katherine Gobin <katherine_gobin at yahoo.com<mailto:katherine_gobin at yahoo.com>> wrote:
>
>? I am sorry perhaps? was not able to put the question properly. I am not looking for the
> subset of the data.frame where the basel_asset_class is > 2. I do agree that would have
> been a basic requirement. Let me try to put the question again.
>
> I have a data frame as
>
> mydat = data.frame(basel_asset_class = c(4, 8, 8 ,8), defa_frequency = c(0.15, 0.07, 0.03,
> 0.001))
>
> # Please note I have changed the basel_asset_class to 4 from 2, to avoid confusion.
>
> > mydat
>?  basel_asset_class defa_frequency
> 1? ? ? ? ? ? ? ?  4? ? ? ? ? 0.150
> 2? ? ? ? ? ? ? ?  8? ? ? ? ? 0.070
> 3? ? ? ? ? ? ? ?  8? ? ? ? ? 0.030
> 4? ? ? ? ? ? ? ?  8? ? ? ? ? 0.001
>
>
>
> This is just an representative example. In reality, I may have no of basel asset classes. 4, 8
> etc are the IDs can be anything thus I cant hard code it as subset(mydat,
> mydat$basel_asset_class > 2).
>
>
> What I need is to select only those records for which there are more than two default
> frequencies (defa_frequency), Thus, there is only one default frequency = 0.150 w.r.t
> basel_asset_class = 4 whereas there are default frequencies w.r.t. basel aseet class 4,
> similarly there could be another basel asset class having say 5 default frequncies. Thus, I
> need to take subset of the data.frame s.t. the no of corresponding defa_frequencies is
> greater than 2.
>
> The idea is we try to fit exponential curve Y = A exp( BX ) for each of the basel asset
> classes and to estimate values of A and B, mathematically one needs to have at least two
> values of X.
>
> I hope I may be able to express my requirement. Its not that I need the subset of mydat
> s.t. basel asset class is > 2 (now 4 in revised example), but sbuset s.t. no of default
> frequencies is greater than or equal to 2. This 2 is not same as basel asset class 2.
>
> Kindly guide
>
> With warm regards
>
> Katherine Gobin
>
>
>
>
> On Thursday, 17 October 2013 9:33 PM, Bert Gunter <gunter.berton at gene.com<mailto:gunter.berton at gene.com>> wrote:
>
> "Kindly guide" ...
>
> This is a very basic question, so the kindest guide I can give is to read an Introduction to R
> (ships with R) or a R web tutorial of your choice so that you can learn how R works
> instead of posting to this list.
>
> Cheers,
> Bert
>
>
>
>
> On Wed, Oct 16, 2013 at 11:55 PM, Katherine Gobin <katherine_gobin at yahoo.com<mailto:katherine_gobin at yahoo.com>>
> wrote:
>
> Dear Forum,
> >
> >I have a data frame as
> >
> >mydat = data.frame(basel_asset_class = c(2, 8, 8 ,8), defa_frequency = c(0.15, 0.07,
> 0.03, 0.001))
> >
> >> mydat
> >? basel_asset_class defa_frequency
> >1? ? ? ? ? ? ? ?  2? ? ? ? ? 0.150
> >2? ? ? ? ? ? ? ?  8? ? ? ? ? 0.070
> >3? ? ? ? ? ? ? ?  8? ? ? ? ? 0.030
> >4? ? ? ? ? ? ? ?  8? ? ? ? ? 0.001
> >
> >
> >I need to get the subset of this data.frame where no of records for the given
> basel_asset_class is > 2, i.e. I need to obtain subset of above data.frame as (since there
> is only 1 record, against basel_asset_class = 2, I want to filter it)
> >
> >> mydat_a
> >? basel_asset_class defa_frequency
> >1? ? ? ? ? ? ? ?  8? ? ? ? ? 0.070
> >2? ? ? ? ? ? ? ?  8? ? ? ? ? 0.030
> >3? ? ? ? ? ? ? ?  8? ? ? ? ? 0.001
> >
> >Kindly guide
> >
> >Katherine
> >? ? ? ? [[alternative HTML version deleted]]
> >
> >
> >______________________________________________
> >R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374<tel:%28650%29%20467-7374>
>? ? ?  [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list

https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374



??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From wdunlap at tibco.com  Thu Oct 17 23:40:19 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 17 Oct 2013 21:40:19 +0000
Subject: [R] Subseting a data.frame
In-Reply-To: <1382045603.87888.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>
	<1382032784.1242.YahooMailNeo@web193201.mail.sg3.yahoo.com>
	<1382033077.8442.YahooMailNeo@web193206.mail.sg3.yahoo.com>
	<E66794E69CFDE04D9A70842786030B933FA0BC2C@PA-MBX01.na.tibco.com>
	<CACk-te3qz8yuCPbFLf01ovvfvFmSU7jd6VRPa-ii4wVVpnSdMg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0BC9A@PA-MBX01.na.tibco.com>
	<1382045603.87888.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0BCC8@PA-MBX01.na.tibco.com>

seq_along(x), integer(length(x)), is.na(x), or anything that produces an integer
(or numeric or logical) vector the length of x would work.  I use integer() or numeric()
to indicate I'm not using its value: it is just a vector in which to place the
return values of FUN().

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: arun [mailto:smartpink111 at yahoo.com]
> Sent: Thursday, October 17, 2013 2:33 PM
> To: R help
> Cc: William Dunlap; Bert Gunter
> Subject: Re: [R] Subseting a data.frame
> 
> Hi Bill,
> 
> #seq_along() worked in the cases you showed.
> 
> ?ave(seq_along(fac),fac,FUN=length)
> #[1] 3 1 3 3
> ? ave(seq_along(num), num, FUN=length)
> #[1] 3 1 3 3
> ? ave(seq_along(char), char, FUN=length)
> #[1] 3 1 3 3
> 
> 
> 
> I thought, there might be some advantages in speed, but they were similar in speed.
> set.seed(195)
> ?num1 <- sample(1e3,1e7,replace=TRUE)
> ?system.time(res1 <- ave(integer(length(num1)),num1,FUN=length))
> ? # user? system elapsed
> ? #4.148?? 0.228?? 4.382
> system.time(res2 <- ave(seq_along(num1),num1,FUN=length))
> #?? user? system elapsed
> ?# 3.944?? 0.228?? 4.181
> system.time(res3 <- ave(num1,num1,FUN=length))
> #?? user? system elapsed
> ?# 3.740?? 0.264?? 4.012
> identical(res1,res2)
> #[1] TRUE
> ?identical(res2,res3)
> #[1] TRUE
> 
> 
> A.K.
> 
> 
> 
> 
> On Thursday, October 17, 2013 4:34 PM, William Dunlap <wdunlap at tibco.com> wrote:
> ? May I ask why:
> ? ? count_by_class <- with(dat, ave(numeric(length(basel_asset_class)), basel_asset_class,
> FUN=length))
> ? should not be more simply done as:
> ? ? count_by_class <- with(dat, ave(basel_asset_class, basel_asset_class, FUN=length))
> 
> The way I did it would work if basel_asset_class were non-numeric.
> In ave(x, group, FUN=FUN), FUN's return value should be the same type as x (or
> you can get some odd type conversions).? E.g.,
> 
> ?  > num <- c(2,3,2,2) ;? char <- c("Two","Three","Two","Two")
> ?  > ave(num, num, FUN=length) # good
> ?  [1] 3 1 3 3
> ?  > ave(char, char, FUN=length) # bad
> ?  [1] "3" "1" "3" "3"
> ?  > fac <- factor(char, levels=c("One","Two","Three"))
> ?  > ave(fac, fac, FUN=length)
> ?  [1] <NA> <NA> <NA> <NA>
> ?  Levels: One Two Three
> ?  Warning messages:
> ?  1: In `[<-.factor`(`*tmp*`, i, value = 0L) :
> ? ?  invalid factor level, NA generated
> ?  2: In `[<-.factor`(`*tmp*`, i, value = 3L) :
> ? ?  invalid factor level, NA generated
> ?  3: In `[<-.factor`(`*tmp*`, i, value = 1L) :
> ? ?  invalid factor level, NA generated
> but x=integer(length(group)) works in all cases:
> ?  > ave(integer(length(fac)), fac, FUN=length)
> ?  [1] 3 1 3 3
> ?  > ave(integer(length(char)), char, FUN=length)
> ? ? ? [1] 3 1 3 3
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> From: Bert Gunter [mailto:gunter.berton at gene.com]
> Sent: Thursday, October 17, 2013 1:06 PM
> To: William Dunlap
> Cc: Katherine Gobin; r-help at r-project.org
> Subject: Re: [R] Subseting a data.frame
> 
> May I ask why:
> 
> count_by_class <- with(dat, ave(numeric(length(basel_
> asset_class)), basel_asset_class, FUN=length))
> should not be more simply done as:
> 
> count_by_class <- with(dat, ave(basel_asset_class, basel_asset_class, FUN=length))
> 
> ?
> -- Bert
> 
> On Thu, Oct 17, 2013 at 12:36 PM, William Dunlap
> <wdunlap at tibco.com<mailto:wdunlap at tibco.com>> wrote:
> > What I need is to select only those records for which there are more than two default
> > frequencies (defa_frequency),
> 
> Here is one way.? There are many others:
> ?  > dat <- data.frame( # slightly less trivial example
> ? ? ? ? basel_asset_class=c(4,8,8,8,74,3,74),
> ? ? ? ? defa_frequency=(1:7)/8)
> ?  > count_by_class <- with(dat, ave(numeric(length(basel_asset_class)),
> basel_asset_class, FUN=length))
> ?  > cbind(dat, count_by_class) # see what we just computed
> ? ?  basel_asset_class defa_frequency count_by_class
> ?  1? ? ? ? ? ? ? ?  4? ? ? ? ? 0.125? ? ? ? ? ? ? 1
> ?  2? ? ? ? ? ? ? ?  8? ? ? ? ? 0.250? ? ? ? ? ? ? 3
> ?  3? ? ? ? ? ? ? ?  8? ? ? ? ? 0.375? ? ? ? ? ? ? 3
> ?  4? ? ? ? ? ? ? ?  8? ? ? ? ? 0.500? ? ? ? ? ? ? 3
> ?  5? ? ? ? ? ? ? ? 74? ? ? ? ? 0.625? ? ? ? ? ? ? 2
> ?  6? ? ? ? ? ? ? ?  3? ? ? ? ? 0.750? ? ? ? ? ? ? 1
> ?  7? ? ? ? ? ? ? ? 74? ? ? ? ? 0.875? ? ? ? ? ? ? 2
> ?  > mydat[count_by_class>1, ] # I think this is what you are asking for
> ? ?  basel_asset_class defa_frequency
> ?  2? ? ? ? ? ? ? ?  8? ? ? ? ? 0.250
> ?  3? ? ? ? ? ? ? ?  8? ? ? ? ? 0.375
> ?  4? ? ? ? ? ? ? ?  8? ? ? ? ? 0.500
> ?  5? ? ? ? ? ? ? ? 74? ? ? ? ? 0.625
> ?  7? ? ? ? ? ? ? ? 74? ? ? ? ? 0.875
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com<http://tibco.com>
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> [mailto:r-
> help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf
> > Of Katherine Gobin
> > Sent: Thursday, October 17, 2013 11:05 AM
> > To: Bert Gunter
> > Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> > Subject: Re: [R] Subseting a data.frame
> >
> > Correction. (2nd para first three lines)
> >
> > Pl read following line
> >
> > What I need is to select only those records for which there are more than two default
> > frequencies (defa_frequency), Thus, there is only one default frequency = 0.150 w.r.t
> > basel_asset_class = 4 whereas there are default frequencies w.r.t. basel aseet class 4,
> >
> >
> > as
> >
> > What I need is to select only those records for which there are more than two default
> > frequencies (defa_frequency), Thus, there is only one default frequency = 0.150 w.r.t
> > basel_asset_class = 4 whereas there are THREE default frequencies w.r.t. basel aseet
> > class 8,
> >
> >
> >
> > I alpologize for the incovenience.
> >
> > Regards
> >
> > KAtherine
> >
> >
> >
> >
> >
> >
> >
> >
> > On , Katherine Gobin
> <katherine_gobin at yahoo.com<mailto:katherine_gobin at yahoo.com>> wrote:
> >
> >? I am sorry perhaps? was not able to put the question properly. I am not looking for the
> > subset of the data.frame where the basel_asset_class is > 2. I do agree that would have
> > been a basic requirement. Let me try to put the question again.
> >
> > I have a data frame as
> >
> > mydat = data.frame(basel_asset_class = c(4, 8, 8 ,8), defa_frequency = c(0.15, 0.07,
> 0.03,
> > 0.001))
> >
> > # Please note I have changed the basel_asset_class to 4 from 2, to avoid confusion.
> >
> > > mydat
> >?  basel_asset_class defa_frequency
> > 1? ? ? ? ? ? ? ?  4? ? ? ? ? 0.150
> > 2? ? ? ? ? ? ? ?  8? ? ? ? ? 0.070
> > 3? ? ? ? ? ? ? ?  8? ? ? ? ? 0.030
> > 4? ? ? ? ? ? ? ?  8? ? ? ? ? 0.001
> >
> >
> >
> > This is just an representative example. In reality, I may have no of basel asset classes. 4,
> 8
> > etc are the IDs can be anything thus I cant hard code it as subset(mydat,
> > mydat$basel_asset_class > 2).
> >
> >
> > What I need is to select only those records for which there are more than two default
> > frequencies (defa_frequency), Thus, there is only one default frequency = 0.150 w.r.t
> > basel_asset_class = 4 whereas there are default frequencies w.r.t. basel aseet class 4,
> > similarly there could be another basel asset class having say 5 default frequncies. Thus,
> I
> > need to take subset of the data.frame s.t. the no of corresponding defa_frequencies is
> > greater than 2.
> >
> > The idea is we try to fit exponential curve Y = A exp( BX ) for each of the basel asset
> > classes and to estimate values of A and B, mathematically one needs to have at least
> two
> > values of X.
> >
> > I hope I may be able to express my requirement. Its not that I need the subset of mydat
> > s.t. basel asset class is > 2 (now 4 in revised example), but sbuset s.t. no of default
> > frequencies is greater than or equal to 2. This 2 is not same as basel asset class 2.
> >
> > Kindly guide
> >
> > With warm regards
> >
> > Katherine Gobin
> >
> >
> >
> >
> > On Thursday, 17 October 2013 9:33 PM, Bert Gunter
> <gunter.berton at gene.com<mailto:gunter.berton at gene.com>> wrote:
> >
> > "Kindly guide" ...
> >
> > This is a very basic question, so the kindest guide I can give is to read an Introduction to
> R
> > (ships with R) or a R web tutorial of your choice so that you can learn how R works
> > instead of posting to this list.
> >
> > Cheers,
> > Bert
> >
> >
> >
> >
> > On Wed, Oct 16, 2013 at 11:55 PM, Katherine Gobin
> <katherine_gobin at yahoo.com<mailto:katherine_gobin at yahoo.com>>
> > wrote:
> >
> > Dear Forum,
> > >
> > >I have a data frame as
> > >
> > >mydat = data.frame(basel_asset_class = c(2, 8, 8 ,8), defa_frequency = c(0.15, 0.07,
> > 0.03, 0.001))
> > >
> > >> mydat
> > >? basel_asset_class defa_frequency
> > >1? ? ? ? ? ? ? ?  2? ? ? ? ? 0.150
> > >2? ? ? ? ? ? ? ?  8? ? ? ? ? 0.070
> > >3? ? ? ? ? ? ? ?  8? ? ? ? ? 0.030
> > >4? ? ? ? ? ? ? ?  8? ? ? ? ? 0.001
> > >
> > >
> > >I need to get the subset of this data.frame where no of records for the given
> > basel_asset_class is > 2, i.e. I need to obtain subset of above data.frame as (since there
> > is only 1 record, against basel_asset_class = 2, I want to filter it)
> > >
> > >> mydat_a
> > >? basel_asset_class defa_frequency
> > >1? ? ? ? ? ? ? ?  8? ? ? ? ? 0.070
> > >2? ? ? ? ? ? ? ?  8? ? ? ? ? 0.030
> > >3? ? ? ? ? ? ? ?  8? ? ? ? ? 0.001
> > >
> > >Kindly guide
> > >
> > >Katherine
> > >? ? ? ? [[alternative HTML version deleted]]
> > >
> > >
> > >______________________________________________
> > >R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> >
> >
> > --
> >
> > Bert Gunter
> > Genentech Nonclinical Biostatistics
> >
> > (650) 467-7374<tel:%28650%29%20467-7374>
> >? ? ?  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> (650) 467-7374
> 
> 
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From yelin at lbl.gov  Thu Oct 17 23:56:22 2013
From: yelin at lbl.gov (Ye Lin)
Date: Thu, 17 Oct 2013 14:56:22 -0700
Subject: [R] speeding up a loop
Message-ID: <CAAvu=b=0RXmoMJsbXvo8GRKANb=w2QMavRayiKPMJzQxsHf=ZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/6e76aaf1/attachment.pl>

From msuzen at gmail.com  Fri Oct 18 01:47:15 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Fri, 18 Oct 2013 01:47:15 +0200
Subject: [R] Incorporate Julia into R
In-Reply-To: <DUB115-W5920BFB0459EAB554DE0F797050@phx.gbl>
References: <DUB115-W5920BFB0459EAB554DE0F797050@phx.gbl>
Message-ID: <CAPtbhHyudQkDoxgCDfN7N1EG72LseZRkJH1oDm+_swuxa0N7RQ@mail.gmail.com>

On 17 October 2013 15:38, Timo Schmid <timo_schmid at hotmail.com> wrote:
> I have some code in R with a lot of matrix multiplication and inverting. R can be very slow for larger matrices like 5000x5000.
> I have seen the new programming language Julia (www.julialang.org) which is quite fast in doing matrix algebra.

Its not Julia, but LAPACK.


From Jason.Law at portlandoregon.gov  Thu Oct 17 22:21:05 2013
From: Jason.Law at portlandoregon.gov (Law, Jason)
Date: Thu, 17 Oct 2013 13:21:05 -0700
Subject: [R] Selecting maximums between different variables
In-Reply-To: <CA+iePbmtiuvV-AwL3SV_G+mQZOuXoc_kSV+jER3SGaHsQVWhMQ@mail.gmail.com>
References: <CA+iePbmtiuvV-AwL3SV_G+mQZOuXoc_kSV+jER3SGaHsQVWhMQ@mail.gmail.com>
Message-ID: <0EFBC7C31DB4F24F8CAC48136A1762D70184EE31ADD2@MAIL2.rose.portland.local>

See ?pmax for getting the max for each year.

do.call('pmax', oil[-1])

Or equivalently:

pmax(oil$TX, oil$CA, oil$AL, oil$ND)

apply and which.max will give you the index:

i <- apply(oil[-1], 1, which.max)

which you can use to extract the state:

names(oil[-1])[i]

Jason

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Tim Umbach
Sent: Thursday, October 17, 2013 9:49 AM
To: r-help at r-project.org
Subject: [R] Selecting maximums between different variables

Hi there,

another beginners question, I'm afraid. Basically i want to selct the maximum of values, that correspond to different variables. I have a table of oil production that looks somewhat like this:

oil <- data.frame( YEAR = c(2011, 2012),
                   TX = c(20000, 30000),
                   CA = c(40000, 25000),
                   AL = c(20000,
21000),

                   ND = c(21000,60000))

Now I want to find out, which state produced most oil in a given year. I tried this:

attach(oil)
last_year = oil[ c(YEAR == 2012), ]
max(last_year)

Which works, but it doesnt't give me the corresponding values (i.e. it just gives me the maximum output, not what state its from).
So I tried this:

oil[c(oil == max(last_year)),]
and this:
oil[c(last_year == max(last_year)),]
and this:
oil[which.max(last_year),]
and this:
last_year[max(last_year),]

None of them work, but they don't give error messages either, the output is just "NA". The problem is, in my eyes, that I'm comparing the values of different variables with each other. Because if i change the structure of the dataframe (which I can't do with the real data, at least not with out doing it by hand with a huge dataset), it looks like this and works
perfectly:

oil2 <- data.frame (
  names = c('YEAR', 'TX', 'CA', 'AL', 'ND'),
  oil_2011 = c(2011, 20000, 40000, 20000, 21000),
  oil_2012 = c(2012, 30000, 25000, 21000, 60000)
  )
attach(oil2)
oil2[c(oil_2012 == max(oil_2012)),]

Any help is much appreciated.

Thanks, Tim Umbach

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From elodie.gillain at gmail.com  Fri Oct 18 03:59:13 2013
From: elodie.gillain at gmail.com (Elan InP)
Date: Thu, 17 Oct 2013 21:59:13 -0400
Subject: [R] =?utf-8?q?crr_question=E2=80=8F_in_library=28cmprsk=29?=
Message-ID: <526095F1.7020605@aim.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131017/6e5146eb/attachment.pl>

From dwinsemius at comcast.net  Fri Oct 18 06:18:00 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 17 Oct 2013 21:18:00 -0700
Subject: [R] speeding up a loop
In-Reply-To: <CAAvu=b=0RXmoMJsbXvo8GRKANb=w2QMavRayiKPMJzQxsHf=ZQ@mail.gmail.com>
References: <CAAvu=b=0RXmoMJsbXvo8GRKANb=w2QMavRayiKPMJzQxsHf=ZQ@mail.gmail.com>
Message-ID: <E67BA69D-B92B-472B-A45E-A245A9351743@comcast.net>


On Oct 17, 2013, at 2:56 PM, Ye Lin wrote:

> Hey R professionals,
> 
> I have a large dataset and I want to run a loop on it basically creating a
> new column which gathers information from another reference table.
> 
> When I run the code, R just freezes and even does not response after 30min
> which is really unusual. I tried sapply as well but does not improve at
> all.
> 
> I am running R 3.0.2 on Windows 7.  I checked the system, when I run the
> code, my CPU usage is about 25%-30% that is taxing my desktop.

A guess: It's not your CPU use ... it's your RAM use. You've probably exhausted your RAM and your system has paged out to virutla memory
> 
> Here is my code:
> 
> #df1 is the data set I want to add a new column#
> #b is the reference tabel#
> 
> for (i in (1:nrow(df1))) {
>  begin=which(b$Time2==df1$start[i] & b$Date==df1$Date[i])
>  date=unlist(strsplit(as.character(dff$end[i])," "))[1]
>   end=ifelse(date=="2013-10-17",
>   which(b$Time2==df1$end[i] & b$Date==df1$Date[i]),
>   which(b$Time2==df1$end[i]-3600*24 & b$Date==as.Date(df1$Date[i])+1))
>    df1$new[i] <- sum(b[begin:end,]$Power)
> }
> 

I get: 
Error in strsplit(as.character(dff$end[i]), " ") : object 'dff' not found

If I change the dff to df1, I get: 
Error in begin:end : argument of length 0

-- 
David.
> And here is a mimic sample of df1 & b:
> 
> df1 <- structure(list(Date = structure(c(1369699200, 1369699200,
> 1369699200,
> 1369699200, 1369699200), tzone = "UTC", class = c("POSIXct",
> "POSIXt")), start = structure(c(1381991205, 1381990247, 1382010454,
> 1382007281, 1381992288), tzone = "UTC", class = c("POSIXct",
> "POSIXt")), end = structure(c(1381992405, 1381993727, 1382010694,
> 1382007461, 1381992468), tzone = "UTC", class = c("POSIXct",
> "POSIXt"))), .Names = c("Date", "start", "end"), row.names = c(NA,
> -5L), class = "data.frame")
> 
> 
> b <- structure(list(Date = structure(c(1369699200, 1369699200, 1369699200,
> 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
> 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
> 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
> 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
> 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
> 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
> 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
> 1369699200, 1369699200, 1369699200, 1369699200, 1369699200), tzone = "UTC",
> class = c("POSIXct",
> "POSIXt")), Time2 = structure(c(1381989634, 1381989694, 1381989754,
> 1381989814, 1381989874, 1381989934, 1381989994, 1381990054, 1381990114,
> 1381990174, 1381990234, 1381990294, 1381990354, 1381990414, 1381990474,
> 1381990534, 1381990594, 1381990654, 1381990714, 1381990774, 1381990834,
> 1381990894, 1381990954, 1381991014, 1381991074, 1381991134, 1381991194,
> 1381991254, 1381991314, 1381991374, 1381991434, 1381991494, 1381991554,
> 1381991614, 1381991674, 1381991734, 1381991794, 1381991854, 1381991914,
> 1381991974, 1381992034, 1381992094, 1381992154, 1381992214, 1381992274,
> 1381992334, 1381992394, 1381992454, 1381992514, 1381992574), tzone = "UTC",
> class = c("POSIXct",
> "POSIXt")), Power = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
> 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,
> 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,
> 45, 46, 47, 48, 49, 50)), .Names = c("Date", "Time2", "Power"
> ), row.names = c(NA, -50L), class = "data.frame")
> 
> Thanks for your help!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From oreslag at gmail.com  Fri Oct 18 06:11:02 2013
From: oreslag at gmail.com (Steven LeBlanc)
Date: Thu, 17 Oct 2013 21:11:02 -0700
Subject: [R] dmvnorm returns NaN
Message-ID: <8FB67D7C-F0CF-4A6A-B694-BE79BDEF2A95@gmail.com>

Greets,

I'm using nlminb() to estimate the parameters of a multivariate normal random sample with missing values and ran into an unexpected result from my call to dmvnorm() within the likelihood function. Particular details are provided below. It appears that dmvnorm() makes a call to log(eigen(sigma)). Whereas eigen(sigma) is returning a negative number, I understand log()'s complaint. However, it is a mystery to me why this data set should produce such a result.

Any suggestions?

Best Regards,
Steven

> complete
             [,1]      [,2]
 [1,]  0.84761637  3.994261
 [2,]  0.91487059  4.952595
 [3,]  0.84527267  4.521837
 [4,]  2.53821358  8.374880
 [5,]  1.16646209  6.255022
 [6,]  0.94706527  4.169510
 [7,]  0.48813564  3.349230
 [8,]  3.71828469  9.441518
 [9,]  0.08953357  1.651497
[10,]  0.68530515  5.498403
[11,]  1.52771645  8.484671
[12,]  1.55710697  5.231272
[13,]  1.89091603  4.152658
[14,]  1.08483541  5.401544
[15,]  0.58125385  5.340141
[16,]  0.24473250  2.965046
[17,]  1.59954401  8.095561
[18,]  1.57656436  5.335744
[19,]  2.73976992  8.572871
[20,]  0.87720252  6.067468
[21,]  1.18403087  3.526790
[22,] -1.03145244  1.776478
[23,]  2.88197343  7.720838
[24,]  0.60705218  4.406073
[25,]  0.58083464  3.374075
[26,]  0.87913427  5.247637
[27,]  1.10832692  3.534508
[28,]  2.92698371  8.682130
[29,]  4.04115277 11.827360
[30,] -0.57913297  1.476586
[31,]  0.84804365  7.009075
[32,]  0.79497940  3.671164
[33,]  1.58837762  5.535409
[34,]  0.63412821  3.932767
[35,]  3.14032433  9.271014
[36,] -0.18183869  1.666647
[37,]  0.57535770  6.881830
[38,]  3.21417723 10.901636
[39,]  0.29207932  4.120408
[40,]  0.65938218  5.209301
> u
[1] 1.267198 5.475045
> sigma
          [,1]     [,2]
[1,] 0.6461647 2.228951
[2,] 2.2289513 5.697834
> dmvnorm(x=complete,mean=u,sigma=sigma)
 [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
[30] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
Warning message:
In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  NaNs produced

From manujfb at gmail.com  Fri Oct 18 06:24:14 2013
From: manujfb at gmail.com (Manuel Figueroa)
Date: Fri, 18 Oct 2013 01:24:14 -0300
Subject: [R] (no subject)
Message-ID: <CAEchsticLj92jtKPABog0ZNvTH_czTmjf-b=r9ji55mjAHCYVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/3b1fb582/attachment.pl>

From dwinsemius at comcast.net  Fri Oct 18 08:37:26 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 17 Oct 2013 23:37:26 -0700
Subject: [R] dmvnorm returns NaN
In-Reply-To: <8FB67D7C-F0CF-4A6A-B694-BE79BDEF2A95@gmail.com>
References: <8FB67D7C-F0CF-4A6A-B694-BE79BDEF2A95@gmail.com>
Message-ID: <FACDBEA1-6B2C-4585-85C5-60C8B2806BC6@comcast.net>


On Oct 17, 2013, at 9:11 PM, Steven LeBlanc wrote:

> Greets,
> 
> I'm using nlminb() to estimate the parameters of a multivariate normal random sample with missing values and ran into an unexpected result from my call to dmvnorm()

There are at least 5 different version of dmvnorm. None of them are in the default packages.

> within the likelihood function. Particular details are provided below.

Complete? Except for the name of the package that has `dmvnorm`.

> It appears that dmvnorm() makes a call to log(eigen(sigma)). Whereas eigen(sigma) is returning a negative number, I understand log()'s complaint. However, it is a mystery to me why this data set should produce such a result.
> 
> Any suggestions?
> 
> Best Regards,
> Steven
> 
>> complete
>             [,1]      [,2]
> [1,]  0.84761637  3.994261
> [2,]  0.91487059  4.952595
> [3,]  0.84527267  4.521837
> [4,]  2.53821358  8.374880
> [5,]  1.16646209  6.255022
> [6,]  0.94706527  4.169510
> [7,]  0.48813564  3.349230
> [8,]  3.71828469  9.441518
> [9,]  0.08953357  1.651497
> [10,]  0.68530515  5.498403
> [11,]  1.52771645  8.484671
> [12,]  1.55710697  5.231272
> [13,]  1.89091603  4.152658
> [14,]  1.08483541  5.401544
> [15,]  0.58125385  5.340141
> [16,]  0.24473250  2.965046
> [17,]  1.59954401  8.095561
> [18,]  1.57656436  5.335744
> [19,]  2.73976992  8.572871
> [20,]  0.87720252  6.067468
> [21,]  1.18403087  3.526790
> [22,] -1.03145244  1.776478
> [23,]  2.88197343  7.720838
> [24,]  0.60705218  4.406073
> [25,]  0.58083464  3.374075
> [26,]  0.87913427  5.247637
> [27,]  1.10832692  3.534508
> [28,]  2.92698371  8.682130
> [29,]  4.04115277 11.827360
> [30,] -0.57913297  1.476586
> [31,]  0.84804365  7.009075
> [32,]  0.79497940  3.671164
> [33,]  1.58837762  5.535409
> [34,]  0.63412821  3.932767
> [35,]  3.14032433  9.271014
> [36,] -0.18183869  1.666647
> [37,]  0.57535770  6.881830
> [38,]  3.21417723 10.901636
> [39,]  0.29207932  4.120408
> [40,]  0.65938218  5.209301
>> u
> [1] 1.267198 5.475045
>> sigma
>          [,1]     [,2]
> [1,] 0.6461647 2.228951
> [2,] 2.2289513 5.697834
>> dmvnorm(x=complete,mean=u,sigma=sigma)

> [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> [30] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> Warning message:
> In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
>  NaNs produced
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From andrej.g.miller at web.de  Fri Oct 18 08:55:29 2013
From: andrej.g.miller at web.de (Andrej)
Date: Thu, 17 Oct 2013 23:55:29 -0700 (PDT)
Subject: [R] Comparing two groups
In-Reply-To: <CAFEqCdzoKwK-pXNFuZxk9cbSAsXt=HQbJfWVunBrs3GRjQqMCQ@mail.gmail.com>
References: <1381736946485-4678190.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B96D50@SRVEXCHMBX.precheza.cz>
	<1381838488519-4678277.post@n4.nabble.com>
	<CAFEqCdzoKwK-pXNFuZxk9cbSAsXt=HQbJfWVunBrs3GRjQqMCQ@mail.gmail.com>
Message-ID: <1382079328946-4678510.post@n4.nabble.com>

glsnow wrote
>>From your question it is not clear what your question/concerns really are,
> and from what we can see it could very well be that you do not understand
> the statistics that you are computing (not just the R implementation).  We
> ask for a reproducible example because that helps us to help you, just a
> couple of boxplots let us make some guesses, but we do not know the data
> values or even the means and standard deviations, even the actual sample
> sizes could help.
> 
>>From the graph it is not surprising that the wilcox test say that the 2
> groups are different and that the t test says that they are not (but
> knowing data values would help even more).  The 2 tests are testing very
> different hypotheses.  The wilcox test is testing that the 2 distributions
> are identical and the more specific way it tests that is by looking at all
> possible pairs between the 2 groups and seeing what proportion of them
> have
> each group higher, if the null were true then half the time the data point
> from mixed would be higher than the data point from monoculture and half
> the time the other way.  From the boxplot we can see that the median of
> monoculture is below the 1st quartile of mixed, so it is not surprising at
> all that the wilcox test rejects the null hypothesis.
> 
> The t-test (which version you used you do not say) is testing if the means
> are equal, since monculture is clearly skewed to the right with potential
> outliers, it would not be surprising if the sample means were close enough
> to each other that the t-test does not see a significant difference.  The
> 2
> tests give different answers because they are answering very different
> questions.
> 
> You state that "I am not allowed to perform it" referring to the t-test.
>  This indicates that you don't have a full understanding or appreciation
> of
> the Central Limit Theorem (an important enough theorem that I have a
> cross-stitch based on it hanging on my wall (along with 2 other
> cross-stitches of Bayes theorem and the mean value theorem of
> integration)).  The plot shows 18 outliers in the monoculture group which
> implies a sample size of at least 72, which means the other group has a
> sample size of at least 14 if I interpret "five times as big" correctly.
>  This is a large enough sample size for the CLT to tell us the t-test will
> give a reasonable approximation (provided the other assumptions hold
> reasonably well and you are interested in the question being answered).
> 
> So, I believe that the advice to read a textbook, or otherwise get some
> help in basic understanding of the statistical tools is reasonable.  Once
> you have that, then if you still need help then give us a reproducible
> example and make it clear what your question really is and you will be
> much
> more likely to receive an answer.

 
Thank you for your answer. It was actually really helpful. I apologize for
the inadequate information, but I can see that I do really need to gather
more statistical knowledge. 



--
View this message in context: http://r.789695.n4.nabble.com/Comparing-two-groups-tp4678190p4678510.html
Sent from the R help mailing list archive at Nabble.com.


From pdalgd at gmail.com  Fri Oct 18 10:12:28 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 18 Oct 2013 10:12:28 +0200
Subject: [R] dmvnorm returns NaN
In-Reply-To: <FACDBEA1-6B2C-4585-85C5-60C8B2806BC6@comcast.net>
References: <8FB67D7C-F0CF-4A6A-B694-BE79BDEF2A95@gmail.com>
	<FACDBEA1-6B2C-4585-85C5-60C8B2806BC6@comcast.net>
Message-ID: <303220E2-B1C2-408B-B81C-6E65E7435F82@gmail.com>


On Oct 18, 2013, at 08:37 , David Winsemius wrote:

> 
> On Oct 17, 2013, at 9:11 PM, Steven LeBlanc wrote:
> 
>> Greets,
>> 
>> I'm using nlminb() to estimate the parameters of a multivariate normal random sample with missing values and ran into an unexpected result from my call to dmvnorm()
> 
> There are at least 5 different version of dmvnorm. None of them are in the default packages.
> 
>> within the likelihood function. Particular details are provided below.
> 
> Complete? Except for the name of the package that has `dmvnorm`.
> 

More importantly, it gives no clue as to the connection between sigma and the data set. It is not the covariance matrix:

> s <- scan(what=list("",0,0))
1: [1,]  0.84761637  3.994261
2: [2,]  0.91487059  4.952595
3: [3,]  0.84527267  4.521837
....
40: [40,]  0.65938218  5.209301
41: 
Read 40 records
> cor(s[[2]],s[[3]])
[1] 0.8812403
> colMeans(cbind(s[[2]],s[[3]]))
[1] 1.252108 5.540686
> var(cbind(s[[2]],s[[3]]))
         [,1]     [,2]
[1,] 1.284475 2.536627
[2,] 2.536627 6.450582

These are not the u and sigma stated.

Furthermore the matrix given as sigma is not a covariance matrix. Try working out the correlation coefficient:

> 2.2289513/sqrt(0.6464647*5.697834)
[1] 1.161377

That should be enough to make any version of dmvnorm complain...


>> It appears that dmvnorm() makes a call to log(eigen(sigma)). Whereas eigen(sigma) is returning a negative number, I understand log()'s complaint. However, it is a mystery to me why this data set should produce such a result.
>> 
>> Any suggestions?
>> 
>> Best Regards,
>> Steven
>> 
>>> complete
>>            [,1]      [,2]
>> [1,]  0.84761637  3.994261
>> [2,]  0.91487059  4.952595
>> [3,]  0.84527267  4.521837
>> [4,]  2.53821358  8.374880
>> [5,]  1.16646209  6.255022
>> [6,]  0.94706527  4.169510
>> [7,]  0.48813564  3.349230
>> [8,]  3.71828469  9.441518
>> [9,]  0.08953357  1.651497
>> [10,]  0.68530515  5.498403
>> [11,]  1.52771645  8.484671
>> [12,]  1.55710697  5.231272
>> [13,]  1.89091603  4.152658
>> [14,]  1.08483541  5.401544
>> [15,]  0.58125385  5.340141
>> [16,]  0.24473250  2.965046
>> [17,]  1.59954401  8.095561
>> [18,]  1.57656436  5.335744
>> [19,]  2.73976992  8.572871
>> [20,]  0.87720252  6.067468
>> [21,]  1.18403087  3.526790
>> [22,] -1.03145244  1.776478
>> [23,]  2.88197343  7.720838
>> [24,]  0.60705218  4.406073
>> [25,]  0.58083464  3.374075
>> [26,]  0.87913427  5.247637
>> [27,]  1.10832692  3.534508
>> [28,]  2.92698371  8.682130
>> [29,]  4.04115277 11.827360
>> [30,] -0.57913297  1.476586
>> [31,]  0.84804365  7.009075
>> [32,]  0.79497940  3.671164
>> [33,]  1.58837762  5.535409
>> [34,]  0.63412821  3.932767
>> [35,]  3.14032433  9.271014
>> [36,] -0.18183869  1.666647
>> [37,]  0.57535770  6.881830
>> [38,]  3.21417723 10.901636
>> [39,]  0.29207932  4.120408
>> [40,]  0.65938218  5.209301
>>> u
>> [1] 1.267198 5.475045
>>> sigma
>>         [,1]     [,2]
>> [1,] 0.6461647 2.228951
>> [2,] 2.2289513 5.697834
>>> dmvnorm(x=complete,mean=u,sigma=sigma)
> 
>> [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
>> [30] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
>> Warning message:
>> In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
>> NaNs produced
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From petr.pikal at precheza.cz  Fri Oct 18 10:25:33 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 18 Oct 2013 08:25:33 +0000
Subject: [R] (no subject)
In-Reply-To: <CAEchsticLj92jtKPABog0ZNvTH_czTmjf-b=r9ji55mjAHCYVg@mail.gmail.com>
References: <CAEchsticLj92jtKPABog0ZNvTH_czTmjf-b=r9ji55mjAHCYVg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B98CCB@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Manuel Figueroa
> Sent: Friday, October 18, 2013 6:24 AM
> To: r-help at r-project.org
> Subject: [R] (no subject)
> 
> I have a simple table, 2 columns and 1994 rows. First row, "Crime" is
> how many crimes happen every month per 100000 inhabitants and second
> row is "Income" which contains the average income recorded in a city.
> 
> here's the head(dataset):
> 
>     Crime      Income
> 1 356.5152 4285.720
> 2 734.5625 4114.291
> 3 541.5171 3542.861
> 4 292.1667 4057.148
> 5 219.7747 4457.149
> 6 308.2538 6114.296
> 
> I want to stratify the crime based on income and then box plot each
> stratum to compare. Also I need to get the variance of each stratum in
> a table.

Homwork? There is no homework policy ot the list. Anyway, below are few hints.

> 
> this is the summary of the Income column:
> 
> Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> 2000    3257    3714    4001    4457    7714
> 
> 
> Closer I've been able to get is this:
> strata=table(cut(dataset$Income, breaks, right= FALSE))
> 
> where breaks is
> > breaks
>  [1] 2000 3500 5000 6500 8000
> 
> this gives me as result:
> > cbind(strata)
>                           strata
> [2e+03,3.5e+03)      805
> [3.5e+03,5e+03)      894
> [5e+03,6.5e+03)      206
> [6.5e+03,8e+03)       89
> 
> 
> I'm not even sure if that's the right way to get the strata.

It probably is unless you want breaks at other incomes. 

> 
> *The important thing here is I need to find a way to get a boxplot of
> the Crime values in each stratum and the variance too.
> *

Split crime by strata and make boxplot. See

?cut
?split
?boxplot

or use ggplot2.

For var table see

?aggregate
?sd
?var

Regards
Petr

> Thanks so much in advance.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From umut.toprak at unige.ch  Fri Oct 18 11:16:49 2013
From: umut.toprak at unige.ch (Umut Toprak)
Date: Fri, 18 Oct 2013 11:16:49 +0200
Subject: [R] representing points in 3D space with trajectories over time
In-Reply-To: <CAFEqCdx0FYUUaBXZGmPJiNhpS2=tg8Du6BOnLK=BYh8-cDdpPw@mail.gmail.com>
References: <CADyQWt3pdn2vTfY9guhBGTppnASNzFXmqLDyqGzfwosyXfg=bQ@mail.gmail.com>
	<CAFEqCdx0FYUUaBXZGmPJiNhpS2=tg8Du6BOnLK=BYh8-cDdpPw@mail.gmail.com>
Message-ID: <CADyQWt04WAC8iQMkqAQE9uH3V7-cCwJt_nRF2xEbMZJQLBjUUg@mail.gmail.com>

Thank you Greg

I will likely go with a list of data frames as each data frame will
represent independent entities and as the syntax will probably be
better that way.

I did find it puzzling that multidimensional data frame or the ability
to hold a vector in a cell of a data frame was not added in a 3rd
party package if not the core. I will find a way to work around this
though.

Best,
Umut

On Thu, Oct 17, 2013 at 7:46 PM, Greg Snow <538280 at gmail.com> wrote:
> If all your data is numeric then you can use an array instead of a data
> frame and arrays can easily be 3, 4, or higher dimensional.  Or you can use
> a data frame with a column each for x, y, z, and time; with possible other
> columns representing groups or other attributes, essentially a 3 dimensional
> data frame with the 3rd dimension being stacked rather than projecting out.
>
>
> On Thu, Oct 17, 2013 at 6:59 AM, Umut Toprak <umut.toprak at unige.ch> wrote:
>>
>> Dear all,
>>
>> I have a problem where I must represent points with XYZ coordinates
>> changing over time. I will do a number of operations on this data such as
>> calculating the YZ-projection distance of the points to the origin over
>> time, the frequency spectrum of the X-T data etc. I am trying to find a
>> good way of representing this data with an appropriate data structure.
>>
>> It appears like higher-dimensional data frames are not allowed and I do
>> not
>> know if I should use a list of data frames or if there is a better
>> solution, possibly as part of an external package.
>>
>> Thank you for your time
>> Umut Toprak
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com


From chrisaa at med.umich.edu  Fri Oct 18 13:32:45 2013
From: chrisaa at med.umich.edu (Andrews, Chris)
Date: Fri, 18 Oct 2013 11:32:45 +0000
Subject: [R] =?windows-1255?q?crr_question=FE_in_library=28cmprsk=29?=
In-Reply-To: <526095F1.7020605@aim.com>
References: <526095F1.7020605@aim.com>
Message-ID: <30411786F64EEF46856EFBA2CD9177992C21D25C@UHEXMBSPR03.umhs.med.umich.edu>

I don't get an error message.  However, I had to make up fstatus and all the rest because your example is not reproducible.  Please provide the list with more information and you'll likely get a more helpful answer from someone.

-----Original Message-----
From: Elan InP [mailto:elodie.gillain at gmail.com] 
Sent: Thursday, October 17, 2013 9:59 PM
To: r-help at r-project.org
Subject: [R] crr question? in library(cmprsk)

Hi all

I do not understand why I am getting the following error message. Can 
anybody help me with this? Thanks in advance.

install.packages("cmprsk")
library(cmprsk)
result1 <-crr(ftime, fstatus, cov1, failcode=1, cencode=0 )
one.pout1 = predict(result1,cov1,X=cbind(1,one.z1,one.z2))

predict.crr(result1,cov1,X=cbind(1,one.z1,one.z2))
Error: could not find function "predict.crr"



	[[alternative HTML version deleted]]


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 

From englishinparis at aim.com  Fri Oct 18 14:06:35 2013
From: englishinparis at aim.com (Elan InP)
Date: Fri, 18 Oct 2013 08:06:35 -0400
Subject: [R] =?windows-1255?q?crr_question=FE_in_library=28cmprsk=29?=
In-Reply-To: <30411786F64EEF46856EFBA2CD9177992C21D25C@UHEXMBSPR03.umhs.med.umich.edu>
References: <526095F1.7020605@aim.com>
	<30411786F64EEF46856EFBA2CD9177992C21D25C@UHEXMBSPR03.umhs.med.umich.edu>
Message-ID: <5261244B.9040904@aim.com>

Hi all

I do not understand why I am getting the following error message. I am showing all my code this time. Can
anybody help me with this? Thanks in advance.


install.packages("cmprsk")
library(cmprsk)


ndim = 5

# two covariates standard normal variates
z1 = rnorm(ndim)
z2 = rnorm(ndim)

beta11 = beta12=0.5

p = 0.15

# baseline is modeled by modified logistic model
b1 = 1
c1 = 2
b2 = 2
c2 = 4

U = runif(ndim)
V = runif(ndim)

tmp=(1-(1-U)^{exp(-z1*beta11-z2*beta12)})/p
T = ifelse(tmp<1, c1+1/b1*log((tmp+exp(-b1*c1))/(1-tmp)), 
c2+1/b2*log((V+exp(-b2*c2))/(1-V)))
epsilon = ifelse(tmp<1, 1, 2)
C = runif(ndim, 4,5)    # around 20% censored data
Y = ifelse(T<=C, T, C)
eta = ifelse(T<=C, epsilon, 0)

time = Y
event = eta

one.time = 3    # the time point that the predicted CIF is estimated
one.z1 = -1
one.z2 = 2        # the covariates values that the predicted CIF is 
estimated

ftime<-T
fstatus<-eta
cov1<-cbind(z1,z2)

result1 <-crr(ftime, fstatus, cov1, failcode=1, cencode=0 )
one.pout1 = predict(result1,cov1,X=cbind(1,one.z1,one.z2))

predict.crr(result1,cov1,X=cbind(1,one.z1,one.z2))
Error: could not find function "predict.crr"



On 10/18/2013 7:32 AM, Andrews, Chris wrote:
> I don't get an error message.  However, I had to make up fstatus and all the rest because your example is not reproducible.  Please provide the list with more information and you'll likely get a more helpful answer from someone.
>
> -----Original Message-----
> From: Elan InP [mailto:elodie.gillain at gmail.com]
> Sent: Thursday, October 17, 2013 9:59 PM
> To: r-help at r-project.org
> Subject: [R] crr question? in library(cmprsk)
>
> Hi all
>
> I do not understand why I am getting the following error message. Can
> anybody help me with this? Thanks in advance.
>
> install.packages("cmprsk")
> library(cmprsk)
> result1 <-crr(ftime, fstatus, cov1, failcode=1, cencode=0 )
> one.pout1 = predict(result1,cov1,X=cbind(1,one.z1,one.z2))
>
> predict.crr(result1,cov1,X=cbind(1,one.z1,one.z2))
> Error: could not find function "predict.crr"
>
>
>
> 	[[alternative HTML version deleted]]
>
>
> **********************************************************
> Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues


From S.Ellison at lgcgroup.com  Fri Oct 18 14:05:27 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Fri, 18 Oct 2013 13:05:27 +0100
Subject: [R] Lattice xyplot: Fill Legend Points
In-Reply-To: <alpine.LNX.2.00.1310170813150.3144@salmo.appl-ecosys.com>
References: <alpine.LNX.2.00.1310170813150.3144@salmo.appl-ecosys.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487F2135F@GOLD.corp.lgc-group.com>



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Rich Shepard
> Subject: [R] Lattice xyplot: Fill Legend Points
> 
>    When I specify pch = 19 for a scatter plot the points are filled
> circles.
> Deapite reading ?points and trial-and-error experimentation I have not
> found
> how to have the legend symbols (now open circles) filled.
> 

Using trellis.par.set seems more successful than specifying par.settings in the call, however much I'd prefer to avoid relying on globals. Example:

ss<-trellis.par.get("superpose.symbol")
ss$pch=rep(19,7)
ss$col=rainbow(7)
trellis.par.set(superpose.symbol=ss)

#Example from xyplot
dotplot(variety ~ yield | site, data = barley, groups = year,
         key = simpleKey(levels(barley$year), space = "right"),
         xlab = "Barley Yield (bushels/acre) ",
         aspect=0.5, layout = c(1,6), ylab=NULL)


S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From rshepard at appl-ecosys.com  Fri Oct 18 14:28:45 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 18 Oct 2013 05:28:45 -0700 (PDT)
Subject: [R] Lattice xyplot: Fill Legend Points
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5487F2135F@GOLD.corp.lgc-group.com>
References: <alpine.LNX.2.00.1310170813150.3144@salmo.appl-ecosys.com>
	<A4E5A0B016B8CB41A485FC629B633CED5487F2135F@GOLD.corp.lgc-group.com>
Message-ID: <alpine.LNX.2.00.1310180528190.22194@salmo.appl-ecosys.com>

On Fri, 18 Oct 2013, S Ellison wrote:

> Using trellis.par.set seems more successful than specifying par.settings
> in the call, however much I'd prefer to avoid relying on globals. Example:
>
> ss<-trellis.par.get("superpose.symbol")
> ss$pch=rep(19,7)
> ss$col=rainbow(7)
> trellis.par.set(superpose.symbol=ss)
>
> #Example from xyplot
> dotplot(variety ~ yield | site, data = barley, groups = year,
>         key = simpleKey(levels(barley$year), space = "right"),
>         xlab = "Barley Yield (bushels/acre) ",
>         aspect=0.5, layout = c(1,6), ylab=NULL)

   Thank you.

Rich

-- 
Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
Applied Ecosystem Services, Inc.   |
<http://www.appl-ecosys.com>     Voice: 503-667-4517      Fax: 503-667-8863


From c.rowat at bham.ac.uk  Fri Oct 18 14:50:31 2013
From: c.rowat at bham.ac.uk (Colin Rowat)
Date: Fri, 18 Oct 2013 12:50:31 +0000
Subject: [R] plotting a marginal distribution on the plane behind a
 persp() plot
In-Reply-To: <525D7482.4070903@gmail.com>
References: <BAE35083C4441B4E9975691D547496F9058913@EX3.adf.bham.ac.uk>
	<525D7482.4070903@gmail.com>
Message-ID: <BAE35083C4441B4E9975691D547496F9059DD5@EX3.adf.bham.ac.uk>

Dear Duncan,

Thank you for your quick reply.   I've got the basic version of what I'm looking for now (see below).  My next step will be your rgl::persp3d suggestion for the hidden lines control.

Best,

Colin 

library(MASS)

X <- mvrnorm(1000,mu=c(0,0),Sigma=matrix(c(1,0,0,1),2))

X.kde <- kde2d(X[,1],X[,2],n=25) # X.kde is list: $x 1*n, $y 1*n, $z n*n

persp(X.kde,phi=30,theta=60,xlab="x_b",ylab="x_a",zlab="f") ->res

c<-17
lines(trans3d(rep(X.kde$x[c],25), X.kde$y, X.kde$z[c,],pmat=res),col="red",lwd=2)

marg <- rowSums(X.kde$z)
mass <- sum(marg)
lines(trans3d(x=X.kde$x, y=rep(X.kde$y[25],25), z=marg/mass, pmat=res),col="green",lwd=2)

detach(package:MASS)

> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: 15 October 2013 18:00
> To: Colin Rowat
> Cc: r-help at R-project.org
> Subject: Re: [R] plotting a marginal distribution on the plane behind a persp()
> plot
> 
> On 15/10/2013 11:38 AM, Colin Rowat wrote:
> > R'istas:
> >
> > I am trying to plot a marginal distribution on the plane behind a persp()
> plot.  My existing code is:
> >
> > library(MASS)
> >
> > X <- mvrnorm(1000,mu=c(0,0),Sigma=matrix(c(1,0,0,1),2))
> >
> > X.kde <- kde2d(X[,1],X[,2],n=25) # X.kde is list: $x 1*n, $y 1*n, $z
> > n*n
> >
> > persp(X.kde,phi=30,theta=60,xlab="x_b",ylab="x_a",zlab="f") ->res
> >
> > Any suggestions are very appreciated.
> 
> I would suggest not using persp() (use rgl::persp3d instead), but you can do it
> in persp using the same technique as in the 2nd example in the
> ?persp help page.   The difficulty with doing this is that persp() uses
> the painter's algorithm for hiding things, so if you want something hidden,
> you need to draw it first.  That's not always easy....
> 
> rgl::persp3d maintains a depth buffer so the order in which you draw things
> usually doesn't matter.  (The exception is with semi-transparent
> objects.)
> 
> Duncan Murdoch
> 


From S.Ellison at lgcgroup.com  Fri Oct 18 14:52:46 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Fri, 18 Oct 2013 13:52:46 +0100
Subject: [R] Subseting a data.frame
In-Reply-To: <CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487F213BA@GOLD.corp.lgc-group.com>

> -----Original Message-----
> ... the kindest guide I can give is to
> read an Introduction to R (ships with R) or a R web tutorial of your choice

No quibble with the advice, but it prompted me to look again at the R Intro. Interestingly, the Intro doesn't mention subset() at all; the subsetting operations referred to there are all based on indexing (mostly because that section is intended to be about indexing, of course).

Subsetting using subset() is perhaps the most natural way of subsetting data frames; perhaps a line or two and an example could usefully be included in the 'Working with data frames' section of the R Intro?

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at LGCGroup.com  Fri Oct 18 14:58:34 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 18 Oct 2013 13:58:34 +0100
Subject: [R] Subseting a data.frame
In-Reply-To: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487F213CB@GOLD.corp.lgc-group.com>



> -----Original Message-----
> > mydat
> ? basel_asset_class defa_frequency
> 1 ? ? ? ? ? ? ? ? 2 ? ? ? ? ?0.150
> 2 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.070
> 3 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.030
> 4 ? ? ? ? ? ? ? ? 8 ? ? ? ? ?0.001
> 
> 
> I need to get the subset of this data.frame where no of records for the
> given basel_asset_class is > 2, 

Maybe something like

subset(mydat, ave(1:nrow(mydat), base_asset_class, FUN=length)>2)

?

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From bhh at xs4all.nl  Fri Oct 18 15:10:32 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 18 Oct 2013 15:10:32 +0200
Subject: [R] =?utf-8?q?crr_question=E2=80=8F_in_library=28cmprsk=29?=
In-Reply-To: <5261244B.9040904@aim.com>
References: <526095F1.7020605@aim.com>
	<30411786F64EEF46856EFBA2CD9177992C21D25C@UHEXMBSPR03.umhs.med.umich.edu>
	<5261244B.9040904@aim.com>
Message-ID: <C76D2717-957D-4F4D-9D9F-691BF60BF72D@xs4all.nl>


On 18-10-2013, at 14:06, Elan InP <englishinparis at aim.com> wrote:

> Hi all
> 
> I do not understand why I am getting the following error message. I am showing all my code this time. Can
> anybody help me with this? Thanks in advance.
> 
> 
> install.packages("cmprsk")
> library(cmprsk)
> 
> 
> ndim = 5
> 
> # two covariates standard normal variates
> z1 = rnorm(ndim)
> z2 = rnorm(ndim)
> 
> beta11 = beta12=0.5
> 
> p = 0.15
> 
> # baseline is modeled by modified logistic model
> b1 = 1
> c1 = 2
> b2 = 2
> c2 = 4
> 
> U = runif(ndim)
> V = runif(ndim)
> 
> tmp=(1-(1-U)^{exp(-z1*beta11-z2*beta12)})/p
> T = ifelse(tmp<1, c1+1/b1*log((tmp+exp(-b1*c1))/(1-tmp)), c2+1/b2*log((V+exp(-b2*c2))/(1-V)))
> epsilon = ifelse(tmp<1, 1, 2)
> C = runif(ndim, 4,5)    # around 20% censored data
> Y = ifelse(T<=C, T, C)
> eta = ifelse(T<=C, epsilon, 0)
> 
> time = Y
> event = eta
> 
> one.time = 3    # the time point that the predicted CIF is estimated
> one.z1 = -1
> one.z2 = 2        # the covariates values that the predicted CIF is estimated
> 
> ftime<-T
> fstatus<-eta
> cov1<-cbind(z1,z2)
> 
> result1 <-crr(ftime, fstatus, cov1, failcode=1, cencode=0 )
> one.pout1 = predict(result1,cov1,X=cbind(1,one.z1,one.z2))
> 
> predict.crr(result1,cov1,X=cbind(1,one.z1,one.z2))
> Error: could not find function "predict.crr"
> 

Your example is not reproducible since you didn't do a set.seed(..) before running your script.
With set.seed(11) the error can be reproduced.

preidct.crr is the predict method for a crr object.
Just use

predict(result1,?)

as given in the example for predict.crr.

Berend


From yelin at lbl.gov  Fri Oct 18 15:23:01 2013
From: yelin at lbl.gov (Ye Lin)
Date: Fri, 18 Oct 2013 06:23:01 -0700
Subject: [R] speeding up a loop
In-Reply-To: <E67BA69D-B92B-472B-A45E-A245A9351743@comcast.net>
References: <CAAvu=b=0RXmoMJsbXvo8GRKANb=w2QMavRayiKPMJzQxsHf=ZQ@mail.gmail.com>
	<E67BA69D-B92B-472B-A45E-A245A9351743@comcast.net>
Message-ID: <CAAvu=bmrissxskEUZ_0KayKiVrBd98wVv89GzQcu8o1h_4ShHQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/bc438cc1/attachment.pl>

From bill.q.hdp at gmail.com  Fri Oct 18 08:04:10 2013
From: bill.q.hdp at gmail.com (Bill Q)
Date: Fri, 18 Oct 2013 02:04:10 -0400
Subject: [R] Data frame to PostgreSQL without primary key
Message-ID: <CADrn=epQfC4yxc-E30=NiJ4JkKE9TZF1KwWstUm_A6G6nodATA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/ddb8cc75/attachment.pl>

From hnorpois at gmail.com  Fri Oct 18 11:10:35 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Fri, 18 Oct 2013 11:10:35 +0200
Subject: [R] plot - how to vary the distances of the x axis?
In-Reply-To: <B3C8801B-82F7-4931-89BB-594E4FDB248D@xs4all.nl>
References: <CAKyZeBuCHEFvotADYn7sn-N-D_k=DTFgTbXRZHMqjj9NofJy+Q@mail.gmail.com>
	<B3C8801B-82F7-4931-89BB-594E4FDB248D@xs4all.nl>
Message-ID: <CAKyZeBvvViXyvEMR+rNN0b-BrNimMa+wMh1FHzzUhWcxrJiOTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/a3949047/attachment.pl>

From katherine_gobin at yahoo.com  Fri Oct 18 11:21:47 2013
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Fri, 18 Oct 2013 17:21:47 +0800 (SGT)
Subject: [R] Subseting a data.frame
In-Reply-To: <CACk-te2PfBO2Gjy92xBgcHUus1tEE7SO+Wyq9PtP7dbd5wSexQ@mail.gmail.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>	<1382032784.1242.YahooMailNeo@web193201.mail.sg3.yahoo.com>	<1382033077.8442.YahooMailNeo@web193206.mail.sg3.yahoo.com>	<E66794E69CFDE04D9A70842786030B933FA0BC2C@PA-MBX01.na.tibco.com>	<CACk-te3qz8yuCPbFLf01ovvfvFmSU7jd6VRPa-ii4wVVpnSdMg@mail.gmail.com>	<E66794E69CFDE04D9A70842786030B933FA0BC9A@PA-MBX01.na.tibco.com>
	<CACk-te2PfBO2Gjy92xBgcHUus1tEE7SO+Wyq9PtP7dbd5wSexQ@mail.gmail.com>
Message-ID: <1382088107.21937.YahooMailNeo@web193204.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/e603e68d/attachment.pl>

From Sandeep.Sampara at ril.com  Fri Oct 18 13:37:48 2013
From: Sandeep.Sampara at ril.com (Sandeep.Sampara at ril.com)
Date: Fri, 18 Oct 2013 17:07:48 +0530
Subject: [R] Need to merge multiple data frames with time stamp
Message-ID: <67E5165A9DDC8E458AB7D5BE99D18F020E792E3B@SIDCMBX06.in.ril.com>

Hi,

 

I'm trying to combine 15 different data frames but all have time field as
common. But the thing is time intervals are different (like min's and
sec's).

So I have to check the common time from all the 15 data frames and merge it
to a single data frame and then export it to excel or csv. 

I tried with below query but it's not giving exact output. It's almost 5
year of data, but its giving output for 3months only. 

Please help with your query to get my output. 

 

a <- merge(MA2DHPA,MA2DHPB,by="IP_Trend_Time")

b <- merge(MA2UCPA,MA2UCPB,by="IP_Trend_Time")

c <- merge(MA2DCPA,MA2DCPB,by="IP_Trend_Time")

d <- merge(MA2DHTA,MA2DHTB,by="IP_Trend_Time")

e <- merge(MA2UCTA,MA2UCTB,by="IP_Trend_Time")

f <- merge(MA2DCTA,MA2DCTB,by="IP_Trend_Time")

g <- merge(MA2CP,MA2CPS,by="IP_Trend_Time")

h <- MA2AP

 

x <- merge(a,b,by="IP_Trend_Time")

y <- merge(c,d,by="IP_Trend_Time")

z <- merge(e,f,by="IP_Trend_Time")

w <- merge(g,h,by="IP_Trend_Time")

 

x1 <- merge(x,y,by="IP_Trend_Time")

y1 <- merge(z,w,by="IP_Trend_Time")

 

MA2 <- merge(x1,y1,by="IP_Trend_Time")

 

Regards,

Sandeep S|IT&C,
Reliance Industries Limited (E&P) | Onshore Terminal | Gadimoga
*  +91 884 2977066 / 9908130749

 

Please consider the environment before printing this email.

 

-------------- next part --------------
"Confidentiality Warning: This message and any attachments are intended only for the use of the intended recipient(s). 
are confidential and may be privileged. If you are not the intended recipient. you are hereby notified that any 
review. re-transmission. conversion to hard copy. copying. circulation or other use of this message and any attachments is 
strictly prohibited. If you are not the intended recipient. please notify the sender immediately by return email. 
and delete this message and any attachments from your system.

Virus Warning: Although the company has taken reasonable precautions to ensure no viruses are present in this email. 
The company cannot accept responsibility for any loss or damage arising from the use of this email or attachment."

From jholtman at gmail.com  Fri Oct 18 16:14:19 2013
From: jholtman at gmail.com (jim holtman)
Date: Fri, 18 Oct 2013 10:14:19 -0400
Subject: [R] speeding up a loop
In-Reply-To: <CAAvu=bmrissxskEUZ_0KayKiVrBd98wVv89GzQcu8o1h_4ShHQ@mail.gmail.com>
References: <CAAvu=b=0RXmoMJsbXvo8GRKANb=w2QMavRayiKPMJzQxsHf=ZQ@mail.gmail.com>
	<E67BA69D-B92B-472B-A45E-A245A9351743@comcast.net>
	<CAAvu=bmrissxskEUZ_0KayKiVrBd98wVv89GzQcu8o1h_4ShHQ@mail.gmail.com>
Message-ID: <CAAxdm-4oZnhYj38xUrCQCWMiEKyXj4KT8JH5-zgStApacBoHkA@mail.gmail.com>

You might want to use the profiler (Rprof) on a subset of your code to
see where time is being spent.  Find a subet that runs for a minute,
or so, and enable profiling for the test.  Take a look and see which
functions are taking the time. This will be a start.  You can also
watch the task monitor while the application is running to see how
fast it is using the CPU and memory.  If you are going around a loop a
number of times, you can put some monitoring 'cat' statements that
will periodically print out the memory and CPU used.  So these are
some of the techniques to start looking at things in your program.
Also data.frames are very costly to 'index' into.  You might want to
consider converting to a matrix (where possible since all columns have
to have the same mode).  This can provide significant improvement.
This is something that you will be able to see when you use the
profiling tool since it will probably show a lot of time in the
functions that handle dataframes.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Oct 18, 2013 at 9:23 AM, Ye Lin <yelin at lbl.gov> wrote:
> Thanks for your help David!
>
> I was running the same code the other day and it worked fine although it
> took a while as well. You are right that dff shud be df1 and maybe it's a
> portion of my data so it have an error of length =0.
>
> About CPU usage, I got it by clicking ctrl+alt+delete and it showed CPU
> usage is really high. Is there anyway to figure out why R is taxing my
> system?
>
> Thanks!
>
> Ye
>
> On Thursday, October 17, 2013, David Winsemius wrote:
>
>>
>> On Oct 17, 2013, at 2:56 PM, Ye Lin wrote:
>>
>> > Hey R professionals,
>> >
>> > I have a large dataset and I want to run a loop on it basically creating
>> a
>> > new column which gathers information from another reference table.
>> >
>> > When I run the code, R just freezes and even does not response after
>> 30min
>> > which is really unusual. I tried sapply as well but does not improve at
>> > all.
>> >
>> > I am running R 3.0.2 on Windows 7.  I checked the system, when I run the
>> > code, my CPU usage is about 25%-30% that is taxing my desktop.
>>
>> A guess: It's not your CPU use ... it's your RAM use. You've probably
>> exhausted your RAM and your system has paged out to virutla memory
>> >
>> > Here is my code:
>> >
>> > #df1 is the data set I want to add a new column#
>> > #b is the reference tabel#
>> >
>> > for (i in (1:nrow(df1))) {
>> >  begin=which(b$Time2==df1$start[i] & b$Date==df1$Date[i])
>> >  date=unlist(strsplit(as.character(dff$end[i])," "))[1]
>> >   end=ifelse(date=="2013-10-17",
>> >   which(b$Time2==df1$end[i] & b$Date==df1$Date[i]),
>> >   which(b$Time2==df1$end[i]-3600*24 & b$Date==as.Date(df1$Date[i])+1))
>> >    df1$new[i] <- sum(b[begin:end,]$Power)
>> > }
>> >
>>
>> I get:
>> Error in strsplit(as.character(dff$end[i]), " ") : object 'dff' not found
>>
>> If I change the dff to df1, I get:
>> Error in begin:end : argument of length 0
>>
>> --
>> David.
>> > And here is a mimic sample of df1 & b:
>> >
>> > df1 <- structure(list(Date = structure(c(1369699200, 1369699200,
>> > 1369699200,
>> > 1369699200, 1369699200), tzone = "UTC", class = c("POSIXct",
>> > "POSIXt")), start = structure(c(1381991205, 1381990247, 1382010454,
>> > 1382007281, 1381992288), tzone = "UTC", class = c("POSIXct",
>> > "POSIXt")), end = structure(c(1381992405, 1381993727, 1382010694,
>> > 1382007461, 1381992468), tzone = "UTC", class = c("POSIXct",
>> > "POSIXt"))), .Names = c("Date", "start", "end"), row.names = c(NA,
>> > -5L), class = "data.frame")
>> >
>> >
>> > b <- structure(list(Date = structure(c(1369699200, 1369699200,
>> 1369699200,
>> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200), tzone =
>> "UTC",
>> > class = c("POSIXct",
>> > "POSIXt")), Time2 = structure(c(1381989634, 1381989694, 1381989754,
>> > 1381989814, 1381989874, 1381989934, 1381989994, 1381990054, 1381990114,
>> > 1381990174, 1381990234, 1381990294, 1381990354, 1381990414, 1381990474,
>> > 1381990534, 1381990594, 1381990654, 1381990714, 1381990774, 1381990834,
>> > 1381990894, 1381990954, 1381991014, 1381991074, 1381991134, 1381991194,
>> > 1381991254, 1381991314, 1381991374, 1381991434, 1381991494, 1381991554,
>> > 1381991614, 1381991674, 1381991734, 1381991794, 1381991854, 1381991914,
>> > 1381991974, 1381992034, 1381992094, 1381992154, 1381992214, 1381992274,
>> > 1381992334, 1381992394, 1381992454, 1381992514, 1381992574), tzone =
>> "UTC",
>> > class = c("POSIXct",
>> > "POSIXt")), Power = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
>> > 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,
>> > 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,
>> > 45, 46, 47, 48, 49, 50)), .Names = c("Date", "Time2", "Power"
>> > ), row.names = c(NA, -50L), class = "data.frame")
>> >
>> > Thanks for your help!
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org <javascript:;> mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Fri Oct 18 16:19:42 2013
From: jholtman at gmail.com (jim holtman)
Date: Fri, 18 Oct 2013 10:19:42 -0400
Subject: [R] Need to merge multiple data frames with time stamp
In-Reply-To: <67E5165A9DDC8E458AB7D5BE99D18F020E792E3B@SIDCMBX06.in.ril.com>
References: <67E5165A9DDC8E458AB7D5BE99D18F020E792E3B@SIDCMBX06.in.ril.com>
Message-ID: <CAAxdm-5xysiAVQjB=vOGUaDvPZ1v+XCOd6HrVU9e2QC9V7NKEw@mail.gmail.com>

You at least need to provide a subset of what the data looks likes.
Since you are merging on 'time', if there are not the same times in
each set, then you will have missing values.  For example, in the
merges that you are doing, have you looked at the size of the
resulting object compared to the two that you are merging? That would
give you and idea as to how much you might be missing.

Also is your time as POSIXct? If so, are there fractional seconds in
the data?  If you had provided some data, some of these questions
would be answered.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Oct 18, 2013 at 7:37 AM,  <Sandeep.Sampara at ril.com> wrote:
> Hi,
>
>
>
> I'm trying to combine 15 different data frames but all have time field as
> common. But the thing is time intervals are different (like min's and
> sec's).
>
> So I have to check the common time from all the 15 data frames and merge it
> to a single data frame and then export it to excel or csv.
>
> I tried with below query but it's not giving exact output. It's almost 5
> year of data, but its giving output for 3months only.
>
> Please help with your query to get my output.
>
>
>
> a <- merge(MA2DHPA,MA2DHPB,by="IP_Trend_Time")
>
> b <- merge(MA2UCPA,MA2UCPB,by="IP_Trend_Time")
>
> c <- merge(MA2DCPA,MA2DCPB,by="IP_Trend_Time")
>
> d <- merge(MA2DHTA,MA2DHTB,by="IP_Trend_Time")
>
> e <- merge(MA2UCTA,MA2UCTB,by="IP_Trend_Time")
>
> f <- merge(MA2DCTA,MA2DCTB,by="IP_Trend_Time")
>
> g <- merge(MA2CP,MA2CPS,by="IP_Trend_Time")
>
> h <- MA2AP
>
>
>
> x <- merge(a,b,by="IP_Trend_Time")
>
> y <- merge(c,d,by="IP_Trend_Time")
>
> z <- merge(e,f,by="IP_Trend_Time")
>
> w <- merge(g,h,by="IP_Trend_Time")
>
>
>
> x1 <- merge(x,y,by="IP_Trend_Time")
>
> y1 <- merge(z,w,by="IP_Trend_Time")
>
>
>
> MA2 <- merge(x1,y1,by="IP_Trend_Time")
>
>
>
> Regards,
>
> Sandeep S|IT&C,
> Reliance Industries Limited (E&P) | Onshore Terminal | Gadimoga
> *  +91 884 2977066 / 9908130749
>
>
>
> Please consider the environment before printing this email.
>
>
>
>
> "Confidentiality Warning: This message and any attachments are intended only for the use of the intended recipient(s).
> are confidential and may be privileged. If you are not the intended recipient. you are hereby notified that any
> review. re-transmission. conversion to hard copy. copying. circulation or other use of this message and any attachments is
> strictly prohibited. If you are not the intended recipient. please notify the sender immediately by return email.
> and delete this message and any attachments from your system.
>
> Virus Warning: Although the company has taken reasonable precautions to ensure no viruses are present in this email.
> The company cannot accept responsibility for any loss or damage arising from the use of this email or attachment."
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Fri Oct 18 16:46:42 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 18 Oct 2013 07:46:42 -0700 (PDT)
Subject: [R] read table and import of a text file
Message-ID: <1382107602.94774.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,

Assuming that you provided the sample data from the file.
temp <- readLines(textConnection("#Hogd/met, Temp, 005[M], Value
#Hogd/met, Difftemp, 051[M], Value
BA0+
1 MTEMP005 1 [deg.C]
2 MDTMP051 1 [deg.C]
EOH
891231, 2400, -1.5, -0.21,
900101, 0100, -1.4, -0.25,
900101, 0200, -1.6, -0.28,
900101, 0300, -1.7, -0.25,
900101, 0400, -2.1, -0.0999999,
900101, 0500, -2.3, -0.0899999,
900101, 0600, -2.4, -0.21,
900101, 0700, -2.5, -0.28,
900101, 0800, -2.6, -0.3,
900101, 0900, -2.8, -0.3,
900101, 1000, -2.8, -0.3,
900101, 1100, -2.7, -0.3,
900101, 1200, -3, -0.3,
900101, 1300, -3.2, -0.3,
900101, 1400, -3.5, -0.0999999,
900101, 1500, -4, -0.2,
900101, 1600, -4.5, -0.19,
900101, 1700, -5.3, 0.27,
900101, 1800, -4, -0.27,
900101, 1900, -4, -0.28,
900101, 2000, -3.8, -0.28,
EOF")) 

temp1 <- read.table(text=gsub("#|,$","",temp[grepl(",",temp)][-1]),sep=",",header=TRUE,check.names=FALSE)
?head(temp1)
#? Hogd/met Difftemp 051[M]????? Value
#1?? 891231???? 2400?? -1.5 -0.2100000
#2?? 900101????? 100?? -1.4 -0.2500000
#3?? 900101????? 200?? -1.6 -0.2800000
#4?? 900101????? 300?? -1.7 -0.2500000
#5?? 900101????? 400?? -2.1 -0.0999999
#6?? 900101????? 500?? -2.3 -0.0899999


A.K.



I have a text file which was imported imperfectly. ?I used the following code: 
temp<-read.table("/New/temp.txt",skip=6,header = TRUE, sep="") 

However the result is not what I expected and looks like: 

> head(temp) 
? ? ? ?X891231..2400...1.5...0.21. 
1 ? ? ?900101, 0100, -1.4, -0.25, 
2 ? ? ?900101, 0200, -1.6, -0.28, 
3 ? ? ?900101, 0300, -1.7, -0.25, 
4 900101, 0400, -2.1, -0.0999999, 
5 900101, 0500, -2.3, -0.0899999, 
6 ? ? ?900101, 0600, -2.4, -0.21, 

Sample data with header and footer is found here: 

#Hogd/met, Temp, 005[M], Value 
#Hogd/met, Difftemp, 051[M], Value 
BA0+ 
1 MTEMP005 1 [deg.C] 
2 MDTMP051 1 [deg.C] 
EOH 
891231, 2400, -1.5, -0.21, 
900101, 0100, -1.4, -0.25, 
900101, 0200, -1.6, -0.28, 
900101, 0300, -1.7, -0.25, 
900101, 0400, -2.1, -0.0999999, 
900101, 0500, -2.3, -0.0899999, 
900101, 0600, -2.4, -0.21, 
900101, 0700, -2.5, -0.28, 
900101, 0800, -2.6, -0.3, 
900101, 0900, -2.8, -0.3, 
900101, 1000, -2.8, -0.3, 
900101, 1100, -2.7, -0.3, 
900101, 1200, -3, -0.3, 
900101, 1300, -3.2, -0.3, 
900101, 1400, -3.5, -0.0999999, 
900101, 1500, -4, -0.2, 
900101, 1600, -4.5, -0.19, 
900101, 1700, -5.3, 0.27, 
900101, 1800, -4, -0.27, 
900101, 1900, -4, -0.28, 
900101, 2000, -3.8, -0.28, 
EOF 

I have a number of similar files and would like to understand 
what I did wrong. I also wish to understand the anatomy of this text 
file. What does EOH mean? and EOF? I could not find this issues on web 
search. Thanks


From oreslag at gmail.com  Fri Oct 18 17:26:55 2013
From: oreslag at gmail.com (Steven LeBlanc)
Date: Fri, 18 Oct 2013 08:26:55 -0700
Subject: [R] dmvnorm returns NaN
In-Reply-To: <FACDBEA1-6B2C-4585-85C5-60C8B2806BC6@comcast.net>
References: <8FB67D7C-F0CF-4A6A-B694-BE79BDEF2A95@gmail.com>
	<FACDBEA1-6B2C-4585-85C5-60C8B2806BC6@comcast.net>
Message-ID: <6531FC68-0549-409F-899A-3907AF6A4669@gmail.com>

On Oct 17, 2013, at 11:37 PM, David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Oct 17, 2013, at 9:11 PM, Steven LeBlanc wrote:
> 
>> Greets,
>> 
>> I'm using nlminb() to estimate the parameters of a multivariate normal random sample with missing values and ran into an unexpected result from my call to dmvnorm()
> 
> There are at least 5 different version of dmvnorm. None of them are in the default packages.
> 
>> within the likelihood function. Particular details are provided below.
> 
> Complete? Except for the name of the package that has `dmvnorm`.
> 

Package: ?mvtnorm? version 0.9-9992
complete was the name of the data set.

Best Regards,
Steven

From alaios at yahoo.com  Fri Oct 18 17:47:14 2013
From: alaios at yahoo.com (Alaios)
Date: Fri, 18 Oct 2013 08:47:14 -0700 (PDT)
Subject: [R] Lists with numbers lists and strings
Message-ID: <1382111234.27961.YahooMailNeo@web125305.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/3f12f5e2/attachment.pl>

From oreslag at gmail.com  Fri Oct 18 18:02:45 2013
From: oreslag at gmail.com (Steven LeBlanc)
Date: Fri, 18 Oct 2013 09:02:45 -0700
Subject: [R] dmvnorm returns NaN
In-Reply-To: <303220E2-B1C2-408B-B81C-6E65E7435F82@gmail.com>
References: <8FB67D7C-F0CF-4A6A-B694-BE79BDEF2A95@gmail.com>
	<FACDBEA1-6B2C-4585-85C5-60C8B2806BC6@comcast.net>
	<303220E2-B1C2-408B-B81C-6E65E7435F82@gmail.com>
Message-ID: <CD81698D-4C8A-4155-991C-DFC1985FBBB7@gmail.com>


On Oct 18, 2013, at 1:12 AM, peter dalgaard <pdalgd at gmail.com> wrote:

> 
> On Oct 18, 2013, at 08:37 , David Winsemius wrote:
> 
>> 
>> On Oct 17, 2013, at 9:11 PM, Steven LeBlanc wrote:
>> 
>>> Greets,
>>> 
>>> I'm using nlminb() to estimate the parameters of a multivariate normal random sample with missing values and ran into an unexpected result from my call to dmvnorm()
>> 
>> There are at least 5 different version of dmvnorm. None of them are in the default packages.
>> 
>>> within the likelihood function. Particular details are provided below.
>> 
>> Complete? Except for the name of the package that has `dmvnorm`.
>> 
> 
> More importantly, it gives no clue as to the connection between sigma and the data set. It is not the covariance matrix:

u and sigma in my original post come from the parameter vector passed by nlminb(); which is why I mentioned nlminb() above and provided the u and sigma explicitly passed by nlminb(). Sorry for any confusion.

> 
>> s <- scan(what=list("",0,0))
> 1: [1,]  0.84761637  3.994261
> 2: [2,]  0.91487059  4.952595
> 3: [3,]  0.84527267  4.521837
> ....
> 40: [40,]  0.65938218  5.209301
> 41: 
> Read 40 records
>> cor(s[[2]],s[[3]])
> [1] 0.8812403
>> colMeans(cbind(s[[2]],s[[3]]))
> [1] 1.252108 5.540686
>> var(cbind(s[[2]],s[[3]]))
>         [,1]     [,2]
> [1,] 1.284475 2.536627
> [2,] 2.536627 6.450582
> 
> These are not the u and sigma stated.
> 
> Furthermore the matrix given as sigma is not a covariance matrix. Try working out the correlation coefficient:
> 
>> 2.2289513/sqrt(0.6464647*5.697834)
> [1] 1.161377
> 
> That should be enough to make any version of dmvnorm complain?

I hadn't thought to check the validity of the sigma constructed from nlminb(). Thank you for pointing this out. So it appears the problem lies in the parameters being estimated by nlminb() and has nothing to do with dmvnorm(). Perhaps it is something in the likelihood function I wrote or in nlminb() or my use of nlminb()? 

As I alluded to in my original post, there are two parts to the data set: 'complete' (bivariate normal with no missing data), and 'deleted' (bivariate normal with one of the two samples missing). I used mvrnorm() to generate a sample of size 50, then deleted 10 values. I then split the result into the 'complete' and 'deleted' you see below. The original undeleted data set can be generated with:

> mu<-c(1,5)
> sigma<-c(1,2,2,6)
> dim(sigma)<-c(2,2)
> set.seed(83165026)
> sample.full<-mvrnorm(50,mu,sigma)

Additional details are as follows. Pertinent facts about the output below: 'theta.hat.em' is the result of an EM algorithm I wrote and I was trying to use nlminb() to get a sense of whether or not my answer is reasonable. Thus, when nlminb() choked with a different starting value I used something I thought to be close to the result. exact() intends to be the complete likelihood function for the 'complete' and 'missing' data sets passed to it.

Perhaps also noteworthy, when I use the complete 'undeleted' data set (n=50 bivariate normal) and the missing data portion ('deleted' below), nlminb() returns what appears to be a reasonable result.

Best Regards,
Steven

> theta.hat.em
[1] 1.243821 5.536775 1.125628 5.823366 2.228952
> exact
function(theta,complete,deleted){
    one.only<-deleted[!(is.na(deleted[,1])),1]
    two.only<-deleted[!(is.na(deleted[,2])),2]
    u<-c(theta[1],theta[2])
    sigma<-c(theta[3],theta[5],theta[5],theta[4])
    dim(sigma)<-c(2,2)
    -sum(log(dmvnorm(x=complete,mean=u,sigma=sigma)))-
        sum(log(dnorm(one.only,u[1],sigma[1,1])))-
            sum(log(dnorm(two.only,u[2],sigma[2,2])))
}
> complete
             [,1]      [,2]
 [1,]  0.84761637  3.994261
 [2,]  0.91487059  4.952595
 [3,]  0.84527267  4.521837
 [4,]  2.53821358  8.374880
 [5,]  1.16646209  6.255022
 [6,]  0.94706527  4.169510
 [7,]  0.48813564  3.349230
 [8,]  3.71828469  9.441518
 [9,]  0.08953357  1.651497
[10,]  0.68530515  5.498403
[11,]  1.52771645  8.484671
[12,]  1.55710697  5.231272
[13,]  1.89091603  4.152658
[14,]  1.08483541  5.401544
[15,]  0.58125385  5.340141
[16,]  0.24473250  2.965046
[17,]  1.59954401  8.095561
[18,]  1.57656436  5.335744
[19,]  2.73976992  8.572871
[20,]  0.87720252  6.067468
[21,]  1.18403087  3.526790
[22,] -1.03145244  1.776478
[23,]  2.88197343  7.720838
[24,]  0.60705218  4.406073
[25,]  0.58083464  3.374075
[26,]  0.87913427  5.247637
[27,]  1.10832692  3.534508
[28,]  2.92698371  8.682130
[29,]  4.04115277 11.827360
[30,] -0.57913297  1.476586
[31,]  0.84804365  7.009075
[32,]  0.79497940  3.671164
[33,]  1.58837762  5.535409
[34,]  0.63412821  3.932767
[35,]  3.14032433  9.271014
[36,] -0.18183869  1.666647
[37,]  0.57535770  6.881830
[38,]  3.21417723 10.901636
[39,]  0.29207932  4.120408
[40,]  0.65938218  5.209301
> deleted
           [,1]     [,2]
 [1,]        NA 9.688308
 [2,]        NA 2.663027
 [3,]        NA 5.468419
 [4,]        NA 6.392642
 [5,] 0.9426628       NA
 [6,] 0.9009366       NA
 [7,] 0.2946175       NA
 [8,] 1.6123423       NA
 [9,] 1.3166623       NA
[10,] 1.2737043       NA
> nlminb(start=theta.hat.em,objective=exact,complete=complete,deleted=deleted,control=list(trace=1))
  0:     142.76785:  1.24382  5.53677  1.12563  5.82337  2.22895
  1:     142.76785:  1.26720  5.47504 0.646165  5.69783  2.22895
$par
[1] 1.2671979 5.4750445 0.6461647 5.6978339 2.2289513

$objective
[1] 142.7678

$convergence
[1] 1

$iterations
[1] 1

$evaluations
function gradient 
       3        5 

$message
[1] "false convergence (8)"

Warning messages:
1: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  NaNs produced
2: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  NaNs produced
3: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  NaNs produced

From dan.abner99 at gmail.com  Fri Oct 18 18:05:44 2013
From: dan.abner99 at gmail.com (Dan Abner)
Date: Fri, 18 Oct 2013 12:05:44 -0400
Subject: [R] Recovering object names when using the ... argument in a fn XXXX
Message-ID: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/f7b3c97e/attachment.pl>

From gunter.berton at gene.com  Fri Oct 18 18:26:42 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 18 Oct 2013 09:26:42 -0700
Subject: [R] Recovering object names when using the ... argument in a fn
	XXXX
In-Reply-To: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>
References: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>
Message-ID: <CACk-te0QA85YDJoYB6qboRP7+4uqp6OPF9o=eGwjSTWsOON8xg@mail.gmail.com>

I'm not exactly sure what you mean by "names." Does the following meet
your needs?

f <- function(...)names(list(...))

> f(a=2,b=3)
[1] "a" "b"
> f(a=2,3)
[1] "a" ""

If not, a reproducible example of what you want might be helpful.

Cheers,
Bert




On Fri, Oct 18, 2013 at 9:05 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> Hi all,
>
> I am using the ... argument to parmeterize a user define fn to accept
> multiple input objects. I subsquently save all these data as a list.
> Question: what is the best way to recover or extract the original object
> names that were fed to the fn?
>
> Thanks,
>
> Dan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From englishinparis at aim.com  Fri Oct 18 18:33:02 2013
From: englishinparis at aim.com (Elan InP)
Date: Fri, 18 Oct 2013 12:33:02 -0400
Subject: [R] =?utf-8?q?crr_question=E2=80=8F_in_library=28cmprsk=29?=
In-Reply-To: <C76D2717-957D-4F4D-9D9F-691BF60BF72D@xs4all.nl>
References: <526095F1.7020605@aim.com>
	<30411786F64EEF46856EFBA2CD9177992C21D25C@UHEXMBSPR03.umhs.med.umich.edu>
	<5261244B.9040904@aim.com>
	<C76D2717-957D-4F4D-9D9F-691BF60BF72D@xs4all.nl>
Message-ID: <526162BE.3020803@aim.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/7160528a/attachment.pl>

From smartpink111 at yahoo.com  Fri Oct 18 18:37:42 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 18 Oct 2013 09:37:42 -0700 (PDT)
Subject: [R] Lists with numbers lists and strings
In-Reply-To: <1382111234.27961.YahooMailNeo@web125305.mail.ne1.yahoo.com>
References: <1382111234.27961.YahooMailNeo@web125305.mail.ne1.yahoo.com>
Message-ID: <1382114262.91731.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Not sure this is what you wanted.
lstNew <- list(Spans, lapply(lapply(Spans,`[`,1),as.character) )
str(lstNew)
#List of 2
?$ :List of 3
? ..$ : num [1:2] 8.37e+08 8.42e+08
? ..$ : num [1:2] 8.32e+08 8.37e+08
? ..$ : num [1:2] 9.30e+08 9.35e+08
?$ :List of 3
? ..$ : chr "8.37e+08"
? ..$ : chr "8.32e+08"
? ..$ : chr "930100000"



A.K.




On Friday, October 18, 2013 11:48 AM, Alaios <alaios at yahoo.com> wrote:
Dear all,
I have a list that is created like that

Spans<-list( c(837e6,842e6), 
??? ????? c(832e6,837e6), 
??? ????? c(930.1e6,935.1e6)
??? ????? )



I would like to include a second list that will contain the string that would correspond to the numbers at the left side. 

I would like thus inside my list to have two sublists. The first onew would be the Spans and the second one the Caption list.

Could you please help me understand how I can do that?

Regards
Alex

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From enikok at gmail.com  Fri Oct 18 18:41:28 2013
From: enikok at gmail.com (=?ISO-8859-1?Q?Nicol=E1s_S=E1nchez?=)
Date: Fri, 18 Oct 2013 18:41:28 +0200
Subject: [R] Logistic regression over LOOCV
Message-ID: <CAMjf+Ejb7cO=+jsLE_BaTcZXaBBPYhvsx+TbDh-w-q-7d6Z_Tg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/90f023e8/attachment.pl>

From jthayn at ilstu.edu  Fri Oct 18 18:40:45 2013
From: jthayn at ilstu.edu (Jonathan Thayn)
Date: Fri, 18 Oct 2013 11:40:45 -0500
Subject: [R] Multimodal multidimensional optimization
Message-ID: <EC906BE8-84EA-42DC-8E6C-2BCC5E25EE04@ilstu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/f05cfa92/attachment.pl>

From vincent.guyader at allstat.fr  Fri Oct 18 16:01:14 2013
From: vincent.guyader at allstat.fr (Vincent Guyader)
Date: Fri, 18 Oct 2013 16:01:14 +0200
Subject: [R] No P.values in polr summary
Message-ID: <CANCN_HSuEbJvGNo-XaAFPmPN_2A=WPJbahjC-Ms0JQKXWU_rBQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/e327dddc/attachment.pl>

From valentina.lauria at nuigalway.ie  Fri Oct 18 18:42:19 2013
From: valentina.lauria at nuigalway.ie (Lauria, Valentina)
Date: Fri, 18 Oct 2013 16:42:19 +0000
Subject: [R] hurdle model error why does need integer values for the
 dependent variable?
Message-ID: <B11DE93D7F439D4BA1E942572BA750308BC65B56@UDSMBX01.uds.nuigalway.ie>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/e5a8359c/attachment.pl>

From gunter.berton at gene.com  Fri Oct 18 19:07:36 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 18 Oct 2013 10:07:36 -0700
Subject: [R] Recovering object names when using the ... argument in a fn
	XXXX
In-Reply-To: <CAPRGo-m_ZXnhr9yRKjoDnsegp+DYuSpjAa2mt7rcPvbLSaK-CQ@mail.gmail.com>
References: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>
	<CACk-te0QA85YDJoYB6qboRP7+4uqp6OPF9o=eGwjSTWsOON8xg@mail.gmail.com>
	<CAPRGo-m_ZXnhr9yRKjoDnsegp+DYuSpjAa2mt7rcPvbLSaK-CQ@mail.gmail.com>
Message-ID: <CACk-te273iH1OYH-2J2frLaB=uKFu+WoDUuLvx10YUdFUNYDmg@mail.gmail.com>

1. Always cc to the list unless it is truly a private offlist reply.
This is to get help from a wider audience, as may well be required
here. Translation: Take my "solution" with a grain of salt. It is
fragile at best.

2. I think ?match.call and ?deparse are what you're looking for:

f <- function(...){
  deparse(match.call())
}

> g(a,b,sqrt(c(1,2,5)))
[1] "a"                "b"                "sqrt(c(1, 2, 5))"

Cheers,
Bert




On Fri, Oct 18, 2013 at 9:36 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> Hi Bert,
>
> Thanks for your response. Please see example below:
>
>
> d1<-data.frame(x1=runif(100),x2=runif(100))
> d2<-data.frame(x3=runif(100),x4=runif(100))
> d3<-data.frame(x5=runif(100),x6=runif(100))
> set1 <- function(...,by){
>     df.name <<- list(...)
>     name1<<-names(list(...))
> }
>
> set1(d1,d2,d3)
>
> I need to be able to recover whatever input data frame names that the user
> passes to set1() (preferably in the character vector).
>
>> name1
> NULL
>
> Here is another possible call to the fn:
>
> set1(d1,d2)
>
>
>
>
>
>
> On Fri, Oct 18, 2013 at 12:26 PM, Bert Gunter <gunter.berton at gene.com>
> wrote:
>>
>> I'm not exactly sure what you mean by "names." Does the following meet
>> your needs?
>>
>> f <- function(...)names(list(...))
>>
>> > f(a=2,b=3)
>> [1] "a" "b"
>> > f(a=2,3)
>> [1] "a" ""
>>
>> If not, a reproducible example of what you want might be helpful.
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> On Fri, Oct 18, 2013 at 9:05 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
>> > Hi all,
>> >
>> > I am using the ... argument to parmeterize a user define fn to accept
>> > multiple input objects. I subsquently save all these data as a list.
>> > Question: what is the best way to recover or extract the original object
>> > names that were fed to the fn?
>> >
>> > Thanks,
>> >
>> > Dan
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> (650) 467-7374
>
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From yelin at lbl.gov  Fri Oct 18 19:07:31 2013
From: yelin at lbl.gov (Ye Lin)
Date: Fri, 18 Oct 2013 10:07:31 -0700
Subject: [R] speeding up a loop
In-Reply-To: <CAAxdm-4oZnhYj38xUrCQCWMiEKyXj4KT8JH5-zgStApacBoHkA@mail.gmail.com>
References: <CAAvu=b=0RXmoMJsbXvo8GRKANb=w2QMavRayiKPMJzQxsHf=ZQ@mail.gmail.com>
	<E67BA69D-B92B-472B-A45E-A245A9351743@comcast.net>
	<CAAvu=bmrissxskEUZ_0KayKiVrBd98wVv89GzQcu8o1h_4ShHQ@mail.gmail.com>
	<CAAxdm-4oZnhYj38xUrCQCWMiEKyXj4KT8JH5-zgStApacBoHkA@mail.gmail.com>
Message-ID: <CAAvu=b=rsVqCp64X3MP+eGSoOXrFcS8i2M1GriUyh5_KrWviVA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/574dd4cb/attachment.pl>

From gunter.berton at gene.com  Fri Oct 18 19:16:28 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 18 Oct 2013 10:16:28 -0700
Subject: [R] Multimodal multidimensional optimization
In-Reply-To: <EC906BE8-84EA-42DC-8E6C-2BCC5E25EE04@ilstu.edu>
References: <EC906BE8-84EA-42DC-8E6C-2BCC5E25EE04@ilstu.edu>
Message-ID: <CACk-te041EJkkS2TBggczSEc8u1F-1ntAH0FkNi7HtDnZhCyiA@mail.gmail.com>

1. This is not an R question. Post on a statistics or optimization list.

2. However, I would note that if what you mean by "multimodal"solution
is that there is more than one value that gives the "same" optimal
value (within numerical error?) then, probably no: An optimization
function by definition finds THE optimum (within numerical error)
value.

A standard approach is to use different starting values to seek
"better" (/"different") "optima."

If I have misunderstood, disregard. Also disregard if others with real
expertise (e.g. John Nash) respond.

Cheers,
Bert

On Fri, Oct 18, 2013 at 9:40 AM, Jonathan Thayn <jthayn at ilstu.edu> wrote:
> Hello all
>
> I've been performing a series of multidimensional optimizations (3 variables) using the optima() function. Recently, I noticed that the solution is rarely unimodal. Is there a package or function that handles multimodal multidimensional optimizations? I really appreciate any suggestions, I'm quite a bit beyond my expertise here. Thanks.
>
>
>
> Jonathan B. Thayn, Ph.D.
>
> Ridgely Fellow of Geography
> Department of Geography ? Geology
> Illinois State University
> Felmley Hall of Science, Rm 200A
> Normal, IL 61790
>
> jthayn at ilstu.edu
> my.ilstu.edu/~jthayn
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From dan.abner99 at gmail.com  Fri Oct 18 19:21:06 2013
From: dan.abner99 at gmail.com (Dan Abner)
Date: Fri, 18 Oct 2013 13:21:06 -0400
Subject: [R] Recovering object names when using the ... argument in a fn
	XXXX
In-Reply-To: <CACk-te273iH1OYH-2J2frLaB=uKFu+WoDUuLvx10YUdFUNYDmg@mail.gmail.com>
References: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>
	<CACk-te0QA85YDJoYB6qboRP7+4uqp6OPF9o=eGwjSTWsOON8xg@mail.gmail.com>
	<CAPRGo-m_ZXnhr9yRKjoDnsegp+DYuSpjAa2mt7rcPvbLSaK-CQ@mail.gmail.com>
	<CACk-te273iH1OYH-2J2frLaB=uKFu+WoDUuLvx10YUdFUNYDmg@mail.gmail.com>
Message-ID: <CAPRGo-k8GwzPxefDjHuK9RnkEQ+djr_YddzSy19S0p9LTz-XNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/86a2d4db/attachment.pl>

From gunter.berton at gene.com  Fri Oct 18 19:25:00 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 18 Oct 2013 10:25:00 -0700
Subject: [R] Recovering object names when using the ... argument in a fn
	XXXX
In-Reply-To: <CAPRGo-k8GwzPxefDjHuK9RnkEQ+djr_YddzSy19S0p9LTz-XNw@mail.gmail.com>
References: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>
	<CACk-te0QA85YDJoYB6qboRP7+4uqp6OPF9o=eGwjSTWsOON8xg@mail.gmail.com>
	<CAPRGo-m_ZXnhr9yRKjoDnsegp+DYuSpjAa2mt7rcPvbLSaK-CQ@mail.gmail.com>
	<CACk-te273iH1OYH-2J2frLaB=uKFu+WoDUuLvx10YUdFUNYDmg@mail.gmail.com>
	<CAPRGo-k8GwzPxefDjHuK9RnkEQ+djr_YddzSy19S0p9LTz-XNw@mail.gmail.com>
Message-ID: <CACk-te3SDS4k3M6GksjCywynSgGhRWT8DBY+-LY2bj8g8-X3SA@mail.gmail.com>

That's because I screwed up! I gave you the wrong function, "f" instead of "g" .

Here's g:

g <- function(...){
  sapply(as.list(match.call())[-1],deparse)
}

and the example should now work.

Sheepishly,

-Bert


On Fri, Oct 18, 2013 at 10:21 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> Hi Bert,
>
> Thank you for the code.
>
> However, I don't see what I am doing different, but my output is different.
> I would much rather have output similar to yours where only the input
> objects are returned (instead of the fn name, the encapsulating parentheses,
> etc.):
>
>
>> d1<-data.frame(x1=runif(100),x2=runif(100))
>> d2<-data.frame(x3=runif(100),x4=runif(100))
>> d3<-data.frame(x5=runif(100),x6=runif(100))
>>
>> set1 <- function(...,by){
> +     df.name <<- list(...)
> +     name1<<-deparse(match.call())
> + }
>>
>> set1(d1,d2,d3)
>>
>> name1
> [1] "set1(d1, d2, d3)"
>>
> Another application (with example data too large to email) gives:
>
>> name1
> [1] "matx.set(df1, df2, df3, df4, df5, df6, by = \"ID\")"
>
> Is there a simple way to just get:
>
> "df1" "df2" "df3" "df4" "df5" "df6"
>
> Thanks!
>
> Dan
>
>
>
> On Fri, Oct 18, 2013 at 1:07 PM, Bert Gunter <gunter.berton at gene.com> wrote:
>>
>> 1. Always cc to the list unless it is truly a private offlist reply.
>> This is to get help from a wider audience, as may well be required
>> here. Translation: Take my "solution" with a grain of salt. It is
>> fragile at best.
>>
>> 2. I think ?match.call and ?deparse are what you're looking for:
>>
>> f <- function(...){
>>   deparse(match.call())
>> }
>>
>> > g(a,b,sqrt(c(1,2,5)))
>> [1] "a"                "b"                "sqrt(c(1, 2, 5))"
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> On Fri, Oct 18, 2013 at 9:36 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
>> > Hi Bert,
>> >
>> > Thanks for your response. Please see example below:
>> >
>> >
>> > d1<-data.frame(x1=runif(100),x2=runif(100))
>> > d2<-data.frame(x3=runif(100),x4=runif(100))
>> > d3<-data.frame(x5=runif(100),x6=runif(100))
>> > set1 <- function(...,by){
>> >     df.name <<- list(...)
>> >     name1<<-names(list(...))
>> > }
>> >
>> > set1(d1,d2,d3)
>> >
>> > I need to be able to recover whatever input data frame names that the
>> > user
>> > passes to set1() (preferably in the character vector).
>> >
>> >> name1
>> > NULL
>> >
>> > Here is another possible call to the fn:
>> >
>> > set1(d1,d2)
>> >
>> >
>> >
>> >
>> >
>> >
>> > On Fri, Oct 18, 2013 at 12:26 PM, Bert Gunter <gunter.berton at gene.com>
>> > wrote:
>> >>
>> >> I'm not exactly sure what you mean by "names." Does the following meet
>> >> your needs?
>> >>
>> >> f <- function(...)names(list(...))
>> >>
>> >> > f(a=2,b=3)
>> >> [1] "a" "b"
>> >> > f(a=2,3)
>> >> [1] "a" ""
>> >>
>> >> If not, a reproducible example of what you want might be helpful.
>> >>
>> >> Cheers,
>> >> Bert
>> >>
>> >>
>> >>
>> >>
>> >> On Fri, Oct 18, 2013 at 9:05 AM, Dan Abner <dan.abner99 at gmail.com>
>> >> wrote:
>> >> > Hi all,
>> >> >
>> >> > I am using the ... argument to parmeterize a user define fn to accept
>> >> > multiple input objects. I subsquently save all these data as a list.
>> >> > Question: what is the best way to recover or extract the original
>> >> > object
>> >> > names that were fed to the fn?
>> >> >
>> >> > Thanks,
>> >> >
>> >> > Dan
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>> >>
>> >> --
>> >>
>> >> Bert Gunter
>> >> Genentech Nonclinical Biostatistics
>> >>
>> >> (650) 467-7374
>> >
>> >
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> (650) 467-7374
>
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From wdunlap at tibco.com  Fri Oct 18 19:27:48 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 18 Oct 2013 17:27:48 +0000
Subject: [R] Recovering object names when using the ... argument in a fn
 XXXX
In-Reply-To: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>
References: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0BEB1@PA-MBX01.na.tibco.com>

> I am using the ... argument to parmeterize a user define fn to accept
> multiple input objects. I subsquently save all these data as a list.
> Question: what is the best way to recover or extract the original object
> names that were fed to the fn?

The following function, ellipsisInfo, returns character strings representing the
actual arguments to the function.  If the function was called with tags on the
arguments, as in ellipsisInfo(tag=argument), it makes those tags the names
on the returned character  vector.  It does not evaluate the ... arguments, so
you don't run into problems with evaluating arguments too soon or evaluating
ones that should not be evaluated most of the time. 

ellipsisInfo <- function(...) {
    # get the unevaluated expressions given as arguments
    unevaluatedArgs <- substitute(...())
    # convert those expressions to text (truncate to single line)
    unevaluatedArgsAsText <- vapply(unevaluatedArgs, function(a)deparse(a)[1], "")
    unevaluatedArgsAsText
}

E.g.,

> i <- ellipsisInfo(x, log(10), e=exp(1), onProblem=stop("there was a problem"))
> i
                                
                            "x" 
                                
                      "log(10)" 
                              e 
                       "exp(1)" 
                      onProblem 
"stop(\"there was a problem\")" 
> ifelse(names(i)=="", i, names(i)) # use tag if supplied, otherwise argument itself
[1] "x"         "log(10)"   "e"        
[4] "onProblem"

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Dan Abner
> Sent: Friday, October 18, 2013 9:06 AM
> To: r-help at r-project.org
> Subject: [R] Recovering object names when using the ... argument in a fn XXXX
> 
> Hi all,
> 
> I am using the ... argument to parmeterize a user define fn to accept
> multiple input objects. I subsquently save all these data as a list.
> Question: what is the best way to recover or extract the original object
> names that were fed to the fn?
> 
> Thanks,
> 
> Dan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Oct 18 19:31:09 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 18 Oct 2013 10:31:09 -0700
Subject: [R] dmvnorm returns NaN
In-Reply-To: <303220E2-B1C2-408B-B81C-6E65E7435F82@gmail.com>
References: <8FB67D7C-F0CF-4A6A-B694-BE79BDEF2A95@gmail.com>
	<FACDBEA1-6B2C-4585-85C5-60C8B2806BC6@comcast.net>
	<303220E2-B1C2-408B-B81C-6E65E7435F82@gmail.com>
Message-ID: <43BF5A91-6265-4175-95AB-43388B2E468F@comcast.net>


On Oct 18, 2013, at 1:12 AM, peter dalgaard wrote:

> 
> On Oct 18, 2013, at 08:37 , David Winsemius wrote:
> 
>> 
>> On Oct 17, 2013, at 9:11 PM, Steven LeBlanc wrote:
>> 
>>> Greets,
>>> 
>>> I'm using nlminb() to estimate the parameters of a multivariate normal random sample with missing values and ran into an unexpected result from my call to dmvnorm()
>> 
>> There are at least 5 different version of dmvnorm. None of them are in the default packages.
>> 
>>> within the likelihood function. Particular details are provided below.
>> 
>> Complete? Except for the name of the package that has `dmvnorm`.
>> 
> 
> More importantly, it gives no clue as to the connection between sigma and the data set. It is not the covariance matrix:
> 
>> s <- scan(what=list("",0,0))
> 1: [1,]  0.84761637  3.994261
> 2: [2,]  0.91487059  4.952595
> 3: [3,]  0.84527267  4.521837
> ....
> 40: [40,]  0.65938218  5.209301
> 41: 
> Read 40 records
>> cor(s[[2]],s[[3]])
> [1] 0.8812403
>> colMeans(cbind(s[[2]],s[[3]]))
> [1] 1.252108 5.540686
>> var(cbind(s[[2]],s[[3]]))
>         [,1]     [,2]
> [1,] 1.284475 2.536627
> [2,] 2.536627 6.450582
> 
> These are not the u and sigma stated.
> 
> Furthermore the matrix given as sigma is not a covariance matrix. Try working out the correlation coefficient:
> 
>> 2.2289513/sqrt(0.6464647*5.697834)
> [1] 1.161377
> 
> That should be enough to make any version of dmvnorm complain...

I understood the question differently, but you are my superior in both R and statistics, so I beg some education if I'm totally confused. I thought that what was being requested was the passage of the "complete" matrix (a series of 40 points in 2-space) to some unspecified version of dmvnorm with the hope of getting 40 density estimates from a theoretical MVN distribution with mean = c(1.267198, 5.475045) and the variance-covariance matrix, sigma= matrix( c( 0.6461647, 2.2289513, 2.228951,  5.697834), 2)

library(mixtools)  # just a guess mind you

 dmvnorm( c(0.84761637 , 3.994261), mu=c(1.267198, 5.475045), 
                           sigma= matrix( c( 0.6461647, 2.2289513, 2.228951,  5.697834), 2) )
[1] 0.1224835

> complete <-matrix( scan(), ncol=2, byrow=TRUE)
1: 0.84761637  3.994261
3:  0.91487059  4.952595
5:  0.84527267  4.521837
7:  2.53821358  8.374880
9:  1.16646209  6.255022
11: 
Read 10 items
> dmvnorm( complete, mu=c(1.267198, 5.475045), sigma= matrix( c( 0.6461647, 2.2289513, 2.228951,  5.697834), 2) )
[1] 0.12248353 0.14380268 0.13025764 0.06991921 0.19158060

So I don't get the same error as the OP and I am unable to explain why he was getting NaNs.

-- 
David.

> 
>>> It appears that dmvnorm() makes a call to log(eigen(sigma)). Whereas eigen(sigma) is returning a negative number, I understand log()'s complaint. However, it is a mystery to me why this data set should produce such a result.
>>> 
>>> Any suggestions?
>>> 
>>> Best Regards,
>>> Steven
>>> 
>>>> complete
>>>           [,1]      [,2]
>>> [1,]  0.84761637  3.994261
>>> [2,]  0.91487059  4.952595
>>> [3,]  0.84527267  4.521837
>>> [4,]  2.53821358  8.374880
>>> [5,]  1.16646209  6.255022
>>> [6,]  0.94706527  4.169510
>>> [7,]  0.48813564  3.349230
>>> [8,]  3.71828469  9.441518
>>> [9,]  0.08953357  1.651497
>>> [10,]  0.68530515  5.498403
>>> [11,]  1.52771645  8.484671
>>> [12,]  1.55710697  5.231272
>>> [13,]  1.89091603  4.152658
>>> [14,]  1.08483541  5.401544
>>> [15,]  0.58125385  5.340141
>>> [16,]  0.24473250  2.965046
>>> [17,]  1.59954401  8.095561
>>> [18,]  1.57656436  5.335744
>>> [19,]  2.73976992  8.572871
>>> [20,]  0.87720252  6.067468
>>> [21,]  1.18403087  3.526790
>>> [22,] -1.03145244  1.776478
>>> [23,]  2.88197343  7.720838
>>> [24,]  0.60705218  4.406073
>>> [25,]  0.58083464  3.374075
>>> [26,]  0.87913427  5.247637
>>> [27,]  1.10832692  3.534508
>>> [28,]  2.92698371  8.682130
>>> [29,]  4.04115277 11.827360
>>> [30,] -0.57913297  1.476586
>>> [31,]  0.84804365  7.009075
>>> [32,]  0.79497940  3.671164
>>> [33,]  1.58837762  5.535409
>>> [34,]  0.63412821  3.932767
>>> [35,]  3.14032433  9.271014
>>> [36,] -0.18183869  1.666647
>>> [37,]  0.57535770  6.881830
>>> [38,]  3.21417723 10.901636
>>> [39,]  0.29207932  4.120408
>>> [40,]  0.65938218  5.209301
>>>> u
>>> [1] 1.267198 5.475045
>>>> sigma
>>>        [,1]     [,2]
>>> [1,] 0.6461647 2.228951
>>> [2,] 2.2289513 5.697834
>>>> dmvnorm(x=complete,mean=u,sigma=sigma)
>> 
>>> [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
>>> [30] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
>>> Warning message:
>>> In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
>>> NaNs produced
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 

David Winsemius
Alameda, CA, USA


From dan.abner99 at gmail.com  Fri Oct 18 19:32:14 2013
From: dan.abner99 at gmail.com (Dan Abner)
Date: Fri, 18 Oct 2013 13:32:14 -0400
Subject: [R] Recovering object names when using the ... argument in a fn
	XXXX
In-Reply-To: <CACk-te3SDS4k3M6GksjCywynSgGhRWT8DBY+-LY2bj8g8-X3SA@mail.gmail.com>
References: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>
	<CACk-te0QA85YDJoYB6qboRP7+4uqp6OPF9o=eGwjSTWsOON8xg@mail.gmail.com>
	<CAPRGo-m_ZXnhr9yRKjoDnsegp+DYuSpjAa2mt7rcPvbLSaK-CQ@mail.gmail.com>
	<CACk-te273iH1OYH-2J2frLaB=uKFu+WoDUuLvx10YUdFUNYDmg@mail.gmail.com>
	<CAPRGo-k8GwzPxefDjHuK9RnkEQ+djr_YddzSy19S0p9LTz-XNw@mail.gmail.com>
	<CACk-te3SDS4k3M6GksjCywynSgGhRWT8DBY+-LY2bj8g8-X3SA@mail.gmail.com>
Message-ID: <CAPRGo-nOb97yrgWRDBYvowXJ2VaZwxJ-DRFXmEtsXLnpUjx=GA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/ab4d1ea5/attachment.pl>

From gunter.berton at gene.com  Fri Oct 18 19:54:04 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 18 Oct 2013 10:54:04 -0700
Subject: [R] Recovering object names when using the ... argument in a fn
	XXXX
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA0BEB1@PA-MBX01.na.tibco.com>
References: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0BEB1@PA-MBX01.na.tibco.com>
Message-ID: <CACk-te11CuSEeVJZoVMa_2c2g2rFMwwumfvpWOzoUXQdq8uyRg@mail.gmail.com>

Yes, similar, but better, as match.call() will get unwanted named
arguments, too.

However, I do not understand the

substitute(...())

idiom. Would you care to explain it? (No is an acceptable  answer!).

I would have expressed it as:

as.list(substitute(list(...)))[-1]

to convert the parse tree to a list. (which is again better than using
match.call() ).

Best,
Bert

On Fri, Oct 18, 2013 at 10:27 AM, William Dunlap <wdunlap at tibco.com> wrote:
>> I am using the ... argument to parmeterize a user define fn to accept
>> multiple input objects. I subsquently save all these data as a list.
>> Question: what is the best way to recover or extract the original object
>> names that were fed to the fn?
>
> The following function, ellipsisInfo, returns character strings representing the
> actual arguments to the function.  If the function was called with tags on the
> arguments, as in ellipsisInfo(tag=argument), it makes those tags the names
> on the returned character  vector.  It does not evaluate the ... arguments, so
> you don't run into problems with evaluating arguments too soon or evaluating
> ones that should not be evaluated most of the time.
>
> ellipsisInfo <- function(...) {
>     # get the unevaluated expressions given as arguments
>     unevaluatedArgs <- substitute(...())
>     # convert those expressions to text (truncate to single line)
>     unevaluatedArgsAsText <- vapply(unevaluatedArgs, function(a)deparse(a)[1], "")
>     unevaluatedArgsAsText
> }
>
> E.g.,
>
>> i <- ellipsisInfo(x, log(10), e=exp(1), onProblem=stop("there was a problem"))
>> i
>
>                             "x"
>
>                       "log(10)"
>                               e
>                        "exp(1)"
>                       onProblem
> "stop(\"there was a problem\")"
>> ifelse(names(i)=="", i, names(i)) # use tag if supplied, otherwise argument itself
> [1] "x"         "log(10)"   "e"
> [4] "onProblem"
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Dan Abner
>> Sent: Friday, October 18, 2013 9:06 AM
>> To: r-help at r-project.org
>> Subject: [R] Recovering object names when using the ... argument in a fn XXXX
>>
>> Hi all,
>>
>> I am using the ... argument to parmeterize a user define fn to accept
>> multiple input objects. I subsquently save all these data as a list.
>> Question: what is the best way to recover or extract the original object
>> names that were fed to the fn?
>>
>> Thanks,
>>
>> Dan
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From dwinsemius at comcast.net  Fri Oct 18 19:59:08 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 18 Oct 2013 10:59:08 -0700
Subject: [R] dmvnorm returns NaN
In-Reply-To: <6531FC68-0549-409F-899A-3907AF6A4669@gmail.com>
References: <8FB67D7C-F0CF-4A6A-B694-BE79BDEF2A95@gmail.com>
	<FACDBEA1-6B2C-4585-85C5-60C8B2806BC6@comcast.net>
	<6531FC68-0549-409F-899A-3907AF6A4669@gmail.com>
Message-ID: <FDC7433F-D98E-4845-A7D1-18EDF445E786@comcast.net>


On Oct 18, 2013, at 8:26 AM, Steven LeBlanc wrote:

> On Oct 17, 2013, at 11:37 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Oct 17, 2013, at 9:11 PM, Steven LeBlanc wrote:
>> 
>>> Greets,
>>> 
>>> I'm using nlminb() to estimate the parameters of a multivariate normal random sample with missing values and ran into an unexpected result from my call to dmvnorm()
>> 
>> There are at least 5 different version of dmvnorm. None of them are in the default packages.
>> 
>>> within the likelihood function. Particular details are provided below.
>> 
>> Complete? Except for the name of the package that has `dmvnorm`.
>> 
> 
> Package: ?mvtnorm? version 0.9-9992
> complete was the name of the data set.

I was clear that "complete" was the name of the dataset:

library(mvtnorm)
# First five rows of your complete:

complete <-
structure(c(0.84761637, 0.91487059, 0.84527267, 2.53821358, 1.16646209, 
3.994261, 4.952595, 4.521837, 8.37488, 6.255022), .Dim = c(5L, 
2L))

dmvnorm( complete, mean=c(1.267198, 5.475045), 
                   sigma= matrix( c( 0.6461647, 2.2289513, 2.228951,  5.697834), 2) )
Error in dmvnorm(complete, mean = c(1.267198, 5.475045), sigma = matrix(c(0.6461647,  : 
  sigma must be a symmetric matrix

So trimming the covariance elements to be exactly equal:
> matrix( c( 0.6461647, 2.2289513, 2.228951,  5.697834), 2)
          [,1]     [,2]
[1,] 0.6461647 2.228951
[2,] 2.2289513 5.697834
> dmvnorm( complete, mean=c(1.267198, 5.475045), 
                     sigma= matrix( c( 0.6461647, 2.228951, 2.228951,  5.697834), 2) )
[1] NaN NaN NaN NaN NaN
Warning message:
In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  NaNs produced

> dmvnorm(x=c(0,0))
[1] 0.1591549
> dmvnorm( complete, mean=c(1.267198, 5.475045) )
[1] 0.048690952 0.130494869 0.092440480 0.001059309 0.116818598
> eigen(sigma, symmetric = TRUE, only.values = TRUE)$values
[1]  6.5406882 -0.1966895

So the specified variance covariance matrix is not invertible. This can happen if you use sample statistics:

http://stats.stackexchange.com/questions/49826/what-to-do-when-sample-covariance-matrix-is-not-invertible

I'm not sure what mixtools::dvnorm is doing that avoids the problem that mvtnorm::dvnorm is identifying. Perhaps a pseudo-inverse if being constructed and use as a substitute for sigma.


> 
> Best Regards,
> Steven

David Winsemius
Alameda, CA, USA


From Achim.Zeileis at uibk.ac.at  Fri Oct 18 19:57:13 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 18 Oct 2013 19:57:13 +0200 (CEST)
Subject: [R] hurdle model error why does need integer values for the
 dependent variable?
In-Reply-To: <B11DE93D7F439D4BA1E942572BA750308BC65B56@UDSMBX01.uds.nuigalway.ie>
References: <B11DE93D7F439D4BA1E942572BA750308BC65B56@UDSMBX01.uds.nuigalway.ie>
Message-ID: <alpine.DEB.2.10.1310181955260.18537@paninaro.uibk.ac.at>

On Fri, 18 Oct 2013, Lauria, Valentina wrote:

> Dear list,
>
> I am using the hurdle model for modelling the habitat of rare fish 
> species. However I do get an error message when I try to model my data:
>
>> test_new1<-hurdle(GALUMEL~ depth + sal + slope + vrm + lat:long + offset(log(haul_numb)), dist = "negbin", data = datafit_elasmo)
>
> Error in hurdle(GALUMEL ~ depth + sal + slope + vrm + lat:long + offset(log(haul_numb)),  :
>  invalid dependent variable, non-integer values
>
> When I do fit the same model with round(my dependent variable) the model 
> works. Sorry for the stupid question but could anyone explain me why? My 
> data are zero inflated (zeros occurring for 78%) and positively skewed.

hurdle() fits a count data distribution (poisson, negbin, geometric) by 
maximum likelihood. Hence, its response needs to be a count variable 
(i.e., integer). See vignette("countreg", package = "pscl") for the 
underlying likelihoods employed.

> Thank you very much in advance.
> Kind Regards,
> Valentina
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Fri Oct 18 20:05:12 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 18 Oct 2013 18:05:12 +0000
Subject: [R] Recovering object names when using the ... argument in a fn
 XXXX
In-Reply-To: <CACk-te11CuSEeVJZoVMa_2c2g2rFMwwumfvpWOzoUXQdq8uyRg@mail.gmail.com>
References: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0BEB1@PA-MBX01.na.tibco.com>
	<CACk-te11CuSEeVJZoVMa_2c2g2rFMwwumfvpWOzoUXQdq8uyRg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0BF75@PA-MBX01.na.tibco.com>

> However, I do not understand the
>    substitute(...())
> idiom. Would you care to explain it? (No is an acceptable  answer!).

I don't completely understand it either, I treat it as an idiom.  I saw it on this list once.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Bert Gunter [mailto:gunter.berton at gene.com]
> Sent: Friday, October 18, 2013 10:54 AM
> To: William Dunlap
> Cc: Dan Abner; r-help at r-project.org
> Subject: Re: [R] Recovering object names when using the ... argument in a fn XXXX
> 
> Yes, similar, but better, as match.call() will get unwanted named
> arguments, too.
> 
> However, I do not understand the
> 
> substitute(...())
> 
> idiom. Would you care to explain it? (No is an acceptable  answer!).
> 
> I would have expressed it as:
> 
> as.list(substitute(list(...)))[-1]
> 
> to convert the parse tree to a list. (which is again better than using
> match.call() ).
> 
> Best,
> Bert
> 
> On Fri, Oct 18, 2013 at 10:27 AM, William Dunlap <wdunlap at tibco.com> wrote:
> >> I am using the ... argument to parmeterize a user define fn to accept
> >> multiple input objects. I subsquently save all these data as a list.
> >> Question: what is the best way to recover or extract the original object
> >> names that were fed to the fn?
> >
> > The following function, ellipsisInfo, returns character strings representing the
> > actual arguments to the function.  If the function was called with tags on the
> > arguments, as in ellipsisInfo(tag=argument), it makes those tags the names
> > on the returned character  vector.  It does not evaluate the ... arguments, so
> > you don't run into problems with evaluating arguments too soon or evaluating
> > ones that should not be evaluated most of the time.
> >
> > ellipsisInfo <- function(...) {
> >     # get the unevaluated expressions given as arguments
> >     unevaluatedArgs <- substitute(...())
> >     # convert those expressions to text (truncate to single line)
> >     unevaluatedArgsAsText <- vapply(unevaluatedArgs, function(a)deparse(a)[1], "")
> >     unevaluatedArgsAsText
> > }
> >
> > E.g.,
> >
> >> i <- ellipsisInfo(x, log(10), e=exp(1), onProblem=stop("there was a problem"))
> >> i
> >
> >                             "x"
> >
> >                       "log(10)"
> >                               e
> >                        "exp(1)"
> >                       onProblem
> > "stop(\"there was a problem\")"
> >> ifelse(names(i)=="", i, names(i)) # use tag if supplied, otherwise argument itself
> > [1] "x"         "log(10)"   "e"
> > [4] "onProblem"
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf
> >> Of Dan Abner
> >> Sent: Friday, October 18, 2013 9:06 AM
> >> To: r-help at r-project.org
> >> Subject: [R] Recovering object names when using the ... argument in a fn XXXX
> >>
> >> Hi all,
> >>
> >> I am using the ... argument to parmeterize a user define fn to accept
> >> multiple input objects. I subsquently save all these data as a list.
> >> Question: what is the best way to recover or extract the original object
> >> names that were fed to the fn?
> >>
> >> Thanks,
> >>
> >> Dan
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> (650) 467-7374

From dwinsemius at comcast.net  Fri Oct 18 20:16:15 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 18 Oct 2013 11:16:15 -0700
Subject: [R] dmvnorm returns NaN
In-Reply-To: <43BF5A91-6265-4175-95AB-43388B2E468F@comcast.net>
References: <8FB67D7C-F0CF-4A6A-B694-BE79BDEF2A95@gmail.com>
	<FACDBEA1-6B2C-4585-85C5-60C8B2806BC6@comcast.net>
	<303220E2-B1C2-408B-B81C-6E65E7435F82@gmail.com>
	<43BF5A91-6265-4175-95AB-43388B2E468F@comcast.net>
Message-ID: <18B38586-2B9B-4681-B3B4-B5593272E8A1@comcast.net>


On Oct 18, 2013, at 10:31 AM, David Winsemius wrote:

> 
> On Oct 18, 2013, at 1:12 AM, peter dalgaard wrote:
> 
>> 
>> On Oct 18, 2013, at 08:37 , David Winsemius wrote:
>> 
>>> 
>>> On Oct 17, 2013, at 9:11 PM, Steven LeBlanc wrote:
>>> 
>>>> Greets,
>>>> 
>>>> I'm using nlminb() to estimate the parameters of a multivariate normal random sample with missing values and ran into an unexpected result from my call to dmvnorm()
>>> 
>>> There are at least 5 different version of dmvnorm. None of them are in the default packages.
>>> 
>>>> within the likelihood function. Particular details are provided below.
>>> 
>>> Complete? Except for the name of the package that has `dmvnorm`.
>>> 
>> 
>> More importantly, it gives no clue as to the connection between sigma and the data set. It is not the covariance matrix:
>> 
>>> s <- scan(what=list("",0,0))
>> 1: [1,]  0.84761637  3.994261
>> 2: [2,]  0.91487059  4.952595
>> 3: [3,]  0.84527267  4.521837
>> ....
>> 40: [40,]  0.65938218  5.209301
>> 41: 
>> Read 40 records
>>> cor(s[[2]],s[[3]])
>> [1] 0.8812403
>>> colMeans(cbind(s[[2]],s[[3]]))
>> [1] 1.252108 5.540686
>>> var(cbind(s[[2]],s[[3]]))
>>        [,1]     [,2]
>> [1,] 1.284475 2.536627
>> [2,] 2.536627 6.450582
>> 
>> These are not the u and sigma stated.
>> 
>> Furthermore the matrix given as sigma is not a covariance matrix. Try working out the correlation coefficient:
>> 
>>> 2.2289513/sqrt(0.6464647*5.697834)
>> [1] 1.161377
>> 

So the covariances need to be less than the sqrt of the product of the variances. I finally get it.

-- 
David.


>> That should be enough to make any version of dmvnorm complain...
> 
> I understood the question differently, but you are my superior in both R and statistics, so I beg some education if I'm totally confused. I thought that what was being requested was the passage of the "complete" matrix (a series of 40 points in 2-space) to some unspecified version of dmvnorm with the hope of getting 40 density estimates from a theoretical MVN distribution with mean = c(1.267198, 5.475045) and the variance-covariance matrix, sigma= matrix( c( 0.6461647, 2.2289513, 2.228951,  5.697834), 2)
> 
> 


David Winsemius
Alameda, CA, USA


From jholtman at gmail.com  Fri Oct 18 21:49:17 2013
From: jholtman at gmail.com (jim holtman)
Date: Fri, 18 Oct 2013 15:49:17 -0400
Subject: [R] speeding up a loop
In-Reply-To: <CAAvu=b=rsVqCp64X3MP+eGSoOXrFcS8i2M1GriUyh5_KrWviVA@mail.gmail.com>
References: <CAAvu=b=0RXmoMJsbXvo8GRKANb=w2QMavRayiKPMJzQxsHf=ZQ@mail.gmail.com>
	<E67BA69D-B92B-472B-A45E-A245A9351743@comcast.net>
	<CAAvu=bmrissxskEUZ_0KayKiVrBd98wVv89GzQcu8o1h_4ShHQ@mail.gmail.com>
	<CAAxdm-4oZnhYj38xUrCQCWMiEKyXj4KT8JH5-zgStApacBoHkA@mail.gmail.com>
	<CAAvu=b=rsVqCp64X3MP+eGSoOXrFcS8i2M1GriUyh5_KrWviVA@mail.gmail.com>
Message-ID: <CAAxdm-5VzBrFvu1TM0xttb1WusMsAwQ1nH6RMEpt-ws=AwCa4A@mail.gmail.com>

When the system locks up, what do  you see in the Task Manager?  Is it
consuming CPU and memory?  On the example data you sent, you won't get
a match on the time since there is not match for the first entry in
df1 in the 'b' dataframe.  This leads to an error that you are not
checking for.  Have you tried it with a small subset to see if it
locks up in the same way.  Put a counter in the look that every 'n'
iteration the value of 'i' is printed out.  May sure you have
'flush.console()' after the print statement to ensure it gets to the
GUI even if you have the writes buffered.  You should be able to debug
with some of these pointers.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Oct 18, 2013 at 1:07 PM, Ye Lin <yelin at lbl.gov> wrote:
> Thanks for your advice Jim!
>
> I tried Rprof but since the code just freezes the system, I am not able to
> get results so far as I had to close R after waiting for a long time. I am
> confused that the same code would work differently on the same system.
>
> I tried out foreach package as well but didnt notice significant
> improvement. Is it that my code is not efficient or there is sth wrong or
> sth has changed with my system?
>
> Thanks!
>
>
>
> On Fri, Oct 18, 2013 at 7:14 AM, jim holtman <jholtman at gmail.com> wrote:
>>
>> You might want to use the profiler (Rprof) on a subset of your code to
>> see where time is being spent.  Find a subet that runs for a minute,
>> or so, and enable profiling for the test.  Take a look and see which
>> functions are taking the time. This will be a start.  You can also
>> watch the task monitor while the application is running to see how
>> fast it is using the CPU and memory.  If you are going around a loop a
>> number of times, you can put some monitoring 'cat' statements that
>> will periodically print out the memory and CPU used.  So these are
>> some of the techniques to start looking at things in your program.
>> Also data.frames are very costly to 'index' into.  You might want to
>> consider converting to a matrix (where possible since all columns have
>> to have the same mode).  This can provide significant improvement.
>> This is something that you will be able to see when you use the
>> profiling tool since it will probably show a lot of time in the
>> functions that handle dataframes.
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>>
>> On Fri, Oct 18, 2013 at 9:23 AM, Ye Lin <yelin at lbl.gov> wrote:
>> > Thanks for your help David!
>> >
>> > I was running the same code the other day and it worked fine although it
>> > took a while as well. You are right that dff shud be df1 and maybe it's
>> > a
>> > portion of my data so it have an error of length =0.
>> >
>> > About CPU usage, I got it by clicking ctrl+alt+delete and it showed CPU
>> > usage is really high. Is there anyway to figure out why R is taxing my
>> > system?
>> >
>> > Thanks!
>> >
>> > Ye
>> >
>> > On Thursday, October 17, 2013, David Winsemius wrote:
>> >
>> >>
>> >> On Oct 17, 2013, at 2:56 PM, Ye Lin wrote:
>> >>
>> >> > Hey R professionals,
>> >> >
>> >> > I have a large dataset and I want to run a loop on it basically
>> >> > creating
>> >> a
>> >> > new column which gathers information from another reference table.
>> >> >
>> >> > When I run the code, R just freezes and even does not response after
>> >> 30min
>> >> > which is really unusual. I tried sapply as well but does not improve
>> >> > at
>> >> > all.
>> >> >
>> >> > I am running R 3.0.2 on Windows 7.  I checked the system, when I run
>> >> > the
>> >> > code, my CPU usage is about 25%-30% that is taxing my desktop.
>> >>
>> >> A guess: It's not your CPU use ... it's your RAM use. You've probably
>> >> exhausted your RAM and your system has paged out to virutla memory
>> >> >
>> >> > Here is my code:
>> >> >
>> >> > #df1 is the data set I want to add a new column#
>> >> > #b is the reference tabel#
>> >> >
>> >> > for (i in (1:nrow(df1))) {
>> >> >  begin=which(b$Time2==df1$start[i] & b$Date==df1$Date[i])
>> >> >  date=unlist(strsplit(as.character(dff$end[i])," "))[1]
>> >> >   end=ifelse(date=="2013-10-17",
>> >> >   which(b$Time2==df1$end[i] & b$Date==df1$Date[i]),
>> >> >   which(b$Time2==df1$end[i]-3600*24 &
>> >> > b$Date==as.Date(df1$Date[i])+1))
>> >> >    df1$new[i] <- sum(b[begin:end,]$Power)
>> >> > }
>> >> >
>> >>
>> >> I get:
>> >> Error in strsplit(as.character(dff$end[i]), " ") : object 'dff' not
>> >> found
>> >>
>> >> If I change the dff to df1, I get:
>> >> Error in begin:end : argument of length 0
>> >>
>> >> --
>> >> David.
>> >> > And here is a mimic sample of df1 & b:
>> >> >
>> >> > df1 <- structure(list(Date = structure(c(1369699200, 1369699200,
>> >> > 1369699200,
>> >> > 1369699200, 1369699200), tzone = "UTC", class = c("POSIXct",
>> >> > "POSIXt")), start = structure(c(1381991205, 1381990247, 1382010454,
>> >> > 1382007281, 1381992288), tzone = "UTC", class = c("POSIXct",
>> >> > "POSIXt")), end = structure(c(1381992405, 1381993727, 1382010694,
>> >> > 1382007461, 1381992468), tzone = "UTC", class = c("POSIXct",
>> >> > "POSIXt"))), .Names = c("Date", "start", "end"), row.names = c(NA,
>> >> > -5L), class = "data.frame")
>> >> >
>> >> >
>> >> > b <- structure(list(Date = structure(c(1369699200, 1369699200,
>> >> 1369699200,
>> >> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> >> > 1369699200,
>> >> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> >> > 1369699200,
>> >> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> >> > 1369699200,
>> >> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> >> > 1369699200,
>> >> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> >> > 1369699200,
>> >> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> >> > 1369699200,
>> >> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200,
>> >> > 1369699200,
>> >> > 1369699200, 1369699200, 1369699200, 1369699200, 1369699200), tzone =
>> >> "UTC",
>> >> > class = c("POSIXct",
>> >> > "POSIXt")), Time2 = structure(c(1381989634, 1381989694, 1381989754,
>> >> > 1381989814, 1381989874, 1381989934, 1381989994, 1381990054,
>> >> > 1381990114,
>> >> > 1381990174, 1381990234, 1381990294, 1381990354, 1381990414,
>> >> > 1381990474,
>> >> > 1381990534, 1381990594, 1381990654, 1381990714, 1381990774,
>> >> > 1381990834,
>> >> > 1381990894, 1381990954, 1381991014, 1381991074, 1381991134,
>> >> > 1381991194,
>> >> > 1381991254, 1381991314, 1381991374, 1381991434, 1381991494,
>> >> > 1381991554,
>> >> > 1381991614, 1381991674, 1381991734, 1381991794, 1381991854,
>> >> > 1381991914,
>> >> > 1381991974, 1381992034, 1381992094, 1381992154, 1381992214,
>> >> > 1381992274,
>> >> > 1381992334, 1381992394, 1381992454, 1381992514, 1381992574), tzone =
>> >> "UTC",
>> >> > class = c("POSIXct",
>> >> > "POSIXt")), Power = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
>> >> > 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,
>> >> > 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,
>> >> > 45, 46, 47, 48, 49, 50)), .Names = c("Date", "Time2", "Power"
>> >> > ), row.names = c(NA, -50L), class = "data.frame")
>> >> >
>> >> > Thanks for your help!
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org <javascript:;> mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >> David Winsemius
>> >> Alameda, CA, USA
>> >>
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From yelin at lbl.gov  Fri Oct 18 21:56:52 2013
From: yelin at lbl.gov (Ye Lin)
Date: Fri, 18 Oct 2013 12:56:52 -0700
Subject: [R] speeding up a loop
In-Reply-To: <CAAxdm-5VzBrFvu1TM0xttb1WusMsAwQ1nH6RMEpt-ws=AwCa4A@mail.gmail.com>
References: <CAAvu=b=0RXmoMJsbXvo8GRKANb=w2QMavRayiKPMJzQxsHf=ZQ@mail.gmail.com>
	<E67BA69D-B92B-472B-A45E-A245A9351743@comcast.net>
	<CAAvu=bmrissxskEUZ_0KayKiVrBd98wVv89GzQcu8o1h_4ShHQ@mail.gmail.com>
	<CAAxdm-4oZnhYj38xUrCQCWMiEKyXj4KT8JH5-zgStApacBoHkA@mail.gmail.com>
	<CAAvu=b=rsVqCp64X3MP+eGSoOXrFcS8i2M1GriUyh5_KrWviVA@mail.gmail.com>
	<CAAxdm-5VzBrFvu1TM0xttb1WusMsAwQ1nH6RMEpt-ws=AwCa4A@mail.gmail.com>
Message-ID: <CAAvu=bnEKYLUBeW8=wReavsRPUEN6Ekv0LdU-BG9wE_uUAa+9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131018/882b7849/attachment.pl>

From smartpink111 at yahoo.com  Fri Oct 18 22:19:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 18 Oct 2013 13:19:24 -0700 (PDT)
Subject: [R] Loop for taking sum of rows based on proximity to other
	non-NA rows
Message-ID: <1382127564.35830.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,

May be this helps:

dat1 <- structure(list(Position = c(15L, 22L, 38L, 49L, 55L, 61L, 62L, 
14L, 29L, 63L, 46L, 22L, 18L, 24L, 22L, 49L, 42L, 38L, 29L, 22L, 
29L, 23L, 42L), Count = c(15L, NA, NA, 5L, NA, 17L, 18L, NA, 
NA, NA, 8L, NA, 20L, NA, NA, 16L, 19L, NA, NA, NA, 13L, NA, 33L
)), .Names = c("Position", "Count"), class = "data.frame", row.names = c(NA, 
-23L))


#There might be simple solutions.

fun1 <- function(dat,n) {
?rl <- rle(is.na(dat[,"Count"]))
indx <- which(is.na(dat[,"Count"]))[rep(rl$lengths[rl$values],rl$lengths[rl$values])==n]
?lst1 <- lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) {
??? ??? ??? ??? ???????? x1 <- dat[c(min(x)-1L,x,max(x)+1L),]
??? ??? ??? ??? ??? ?x2 <- x1[!is.na(x1$Count),]
??? ??? ??? ??? ??? ?datN <- data.frame(Position=max(x2$Position),Count=sum(x2$Count))
??? ??? ??? ??? ??? ?rowN <- row.names(x2)[x2$Position %in% max(x2$Position)]??? 
??? ??? ??? ??? ??? ?row.names(datN) <- if(length(rowN)>1) rowN[1] else rowN
??? ??? ??? ??? ??? ?datN
??? ??? ??? ??? ??? })
names(lst1) <- NULL
dat2 <- do.call(rbind,lst1)
indx2 <-? sort(unlist(lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) c(min(x)-1L,x,c(max(x)+1L))),use.names=FALSE))

dat1New <- dat[-indx2[!indx2 %in% row.names(dat2)],]
dat1New[match(row.names(dat2),row.names(dat1New)),] <- dat2
row.names(dat1New) <- 1:nrow(dat1New)
dat1New
}

dat1N <- fun1(dat1,1)
dat1N
?? Position Count
1??????? 15??? 15
2??????? 22??? NA
3??????? 38??? NA
4??????? 61??? 22
5??????? 62??? 18
6??????? 14??? NA
7??????? 29??? NA
8??????? 63??? NA
9??????? 46??? 28
10?????? 24??? NA
11?????? 22??? NA
12?????? 49??? 16
13?????? 42??? 19
14?????? 38??? NA
15?????? 29??? NA
16?????? 22??? NA
17?????? 42??? 46

dat2N <- fun1(dat1N,2)
dat2N
?? Position Count
1??????? 61??? 37
2??????? 62??? 18
3??????? 14??? NA
4??????? 29??? NA
5??????? 63??? NA
6??????? 49??? 44
7??????? 42??? 19
8??????? 38??? NA
9??????? 29??? NA
10?????? 22??? NA
11?????? 42??? 46
dat3N <- fun1(dat2N,3)
dat3N
? Position Count
1?????? 61??? 37
2?????? 62??? 62
3?????? 42??? 65

A.K.









Hi all, I have a dataset with 2 important columns, "Position" and 
"Count". There are a total of 34,532 rows, but only 457 non-NA values in the "Count" column (every cell in "Position" column has a value). I 
need to write a loop to march down the rows, and if there are 2 rows in 
"Count" where there is only 1 NA row between them, sum the two values up and print only one row with the summed Count value and the Position 
value that corresponds to the larger Count value, thus making the three 
rows into one. For example: 

Position Count 
15 15 
22 NA 
38 NA 
49 5 
55 NA 
61 17 

would become 

Position Count 
15 15 
22 NA 
38 NA 
61 22 

After this step, I also need to write another script to march 
down the rows and look for rows with only two NA's between non-NA rows 
in Count. This would make the previous data become 

Position Count 
61 37 

Ideally I would like a loop that can be flexibly adjusted to the
 number of NA's in between adjacent non-NA values that can be freely 
changed. I would greatly appreciate any insight for this.


From jgrn at illinois.edu  Sat Oct 19 00:46:01 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Fri, 18 Oct 2013 17:46:01 -0500
Subject: [R] Official way to set/retrieve options in packages?
In-Reply-To: <9ac4a7ea5b424580ba3c71d96dee61b7@CITESHT1.ad.uillinois.edu>
References: <CABG0rfskpFF8T+i9OKCBNRGyCS_rn7L1PVO4RO0NivWo0a7jGQ@mail.gmail.com>
	<CAOwvMDz0kzspV8se-gB+7u2WAUghNi99fONcvEofPiVjfEjQng@mail.gmail.com>
	<9ac4a7ea5b424580ba3c71d96dee61b7@CITESHT1.ad.uillinois.edu>
Message-ID: <CABG0rftDuXF9S_nthC_2UdsTbJrnSFcuS+7VSfkSXpfwBg_6bQ@mail.gmail.com>

Wanted to re-start this thread a bit, since I'm still not exactly sure
the best approach to my problem -- basically, the parameters I'm try
to make persistent are installation locations of a particular command
line program that is not installed along with an R package I'm working
on (GDAL, for those of you who are interested in the specifics).  The
function tries to dummy-proof this process by doing a (mostly)
brute-force search of the user's drive for the program location the
first time it executes, and then stores this information (the path to
a given executable) in an option for use with other functions.   This
search process can take some time, so I'd prefer to have this option
set in a semi-permanent way (so it persists between sessions).

Now, Brian Ripley suggested modifying the .Rprofile, but Bert Guntner
suggested this might not be a welcome behavior.  Given that, on an
operating system level, there are often per-program directories for
preferences, would it follow that it might make sense to store
package-options in some standardized location?  If so, where might
this be?  Would it make sense to drop then in the package directory?

Is this a discussion that should move over to r-developers?

--j

On Sat, Jun 1, 2013 at 4:57 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On 01/06/2013 22:44, Anthony Damico wrote:
>> hope this helps..  :)
>>
>>      # define an object `x`
>>      x <- list( "any value here" , 10 )
>>
>>      # set `myoption` to that object
>>      options( "myoption" = x )
>>
>>      # retrieve it later (perhaps within a function elsewhere in the package)
>>      ( y <- getOption( myoption ) )
>>
>>
>> it's nice to name your options `mypackage.myoption` so users know what
>> package the option is associated with in case they type `options()`
>>
>>
>> here's the `.onLoad` function in the R survey package.  notice how the
>> options are only set *if* they don't already exist--
>
> But a nicer convention is that used by most packages in R itself: if the
> option is not set, the function using it assumes a suitable default.
> That would make sense for all the FALSE defaults below.
>
> Note though that this is not 'persistent': users have to set options in
> their startup files (see ?Startup).   There is no official location to
> store package configurations.  Users generally dislike software saving
> settings in their own file space so it seems very much preferable to use
> the standard R mechanisms (.Rprofile etc).
>
>>
>>> survey:::.onLoad
>>
>> function (...)
>> {
>>      if (is.null(getOption("survey.lonely.psu")))
>> options(survey.lonely.psu = "fail")
>>      if (is.null(getOption("survey.ultimate.cluster")))
>> options(survey.ultimate.cluster = FALSE)
>>      if (is.null(getOption("survey.want.obsolete")))
>> options(survey.want.obsolete = FALSE)
>>      if (is.null(getOption("survey.adjust.domain.lonely")))
>> options(survey.adjust.domain.lonely = FALSE)
>>      if (is.null(getOption("survey.drop.replicates")))
>> options(survey.drop.replicates = TRUE)
>>      if (is.null(getOption("survey.multicore")))
>> options(survey.multicore = FALSE)
>>      if (is.null(getOption("survey.replicates.mse")))
>> options(survey.replicates.mse = FALSE)
>> }
>> <environment: namespace:survey>
>>
>>
>>
>>
>> On Sat, Jun 1, 2013 at 4:01 PM, Jonathan Greenberg <jgrn at illinois.edu>wrote:
>>
>>> R-helpers:
>>>
>>> Say I'm developing a package that has a set of user-definable options that
>>> I would like to be persistent across R-invocations (they are saved
>>> someplace).  Of course, I can create a little text file to be written/read,
>>> but I was wondering if there is an "officially sanctioned" way to do this?
>>>   I see there is an options() and getOptions() function, but I'm unclear how
>>> I would use this in my own package to create/save new options for my
>>> particular package.  Cheers!
>>>
>>> --j
>>>
>>> --
>>> Jonathan A. Greenberg, PhD
>>> Assistant Professor
>>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>>> Department of Geography and Geographic Information Science
>>> University of Illinois at Urbana-Champaign
>>> 607 South Mathews Avenue, MC 150
>>> Urbana, IL 61801
>>> Phone: 217-300-1924
>>> http://www.geog.illinois.edu/~jgrn/
>>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From gunter.berton at gene.com  Sat Oct 19 01:53:33 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 18 Oct 2013 16:53:33 -0700
Subject: [R] Official way to set/retrieve options in packages?
In-Reply-To: <CABG0rftDuXF9S_nthC_2UdsTbJrnSFcuS+7VSfkSXpfwBg_6bQ@mail.gmail.com>
References: <CABG0rfskpFF8T+i9OKCBNRGyCS_rn7L1PVO4RO0NivWo0a7jGQ@mail.gmail.com>
	<CAOwvMDz0kzspV8se-gB+7u2WAUghNi99fONcvEofPiVjfEjQng@mail.gmail.com>
	<9ac4a7ea5b424580ba3c71d96dee61b7@CITESHT1.ad.uillinois.edu>
	<CABG0rftDuXF9S_nthC_2UdsTbJrnSFcuS+7VSfkSXpfwBg_6bQ@mail.gmail.com>
Message-ID: <CACk-te0BJ7j6AxRZubZytfCT0E=r1FKK3gNc3ObOF0a=eHCMmw@mail.gmail.com>

1. I do not recall saying any such thing.

2. HOWEVER, no matter. There is no choice. Follow Brian's advice.

-- Bert

On Fri, Oct 18, 2013 at 3:46 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
> Wanted to re-start this thread a bit, since I'm still not exactly sure
> the best approach to my problem -- basically, the parameters I'm try
> to make persistent are installation locations of a particular command
> line program that is not installed along with an R package I'm working
> on (GDAL, for those of you who are interested in the specifics).  The
> function tries to dummy-proof this process by doing a (mostly)
> brute-force search of the user's drive for the program location the
> first time it executes, and then stores this information (the path to
> a given executable) in an option for use with other functions.   This
> search process can take some time, so I'd prefer to have this option
> set in a semi-permanent way (so it persists between sessions).
>
> Now, Brian Ripley suggested modifying the .Rprofile, but Bert Guntner
> suggested this might not be a welcome behavior.  Given that, on an
> operating system level, there are often per-program directories for
> preferences, would it follow that it might make sense to store
> package-options in some standardized location?  If so, where might
> this be?  Would it make sense to drop then in the package directory?
>
> Is this a discussion that should move over to r-developers?
>
> --j
>
> On Sat, Jun 1, 2013 at 4:57 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> On 01/06/2013 22:44, Anthony Damico wrote:
>>> hope this helps..  :)
>>>
>>>      # define an object `x`
>>>      x <- list( "any value here" , 10 )
>>>
>>>      # set `myoption` to that object
>>>      options( "myoption" = x )
>>>
>>>      # retrieve it later (perhaps within a function elsewhere in the package)
>>>      ( y <- getOption( myoption ) )
>>>
>>>
>>> it's nice to name your options `mypackage.myoption` so users know what
>>> package the option is associated with in case they type `options()`
>>>
>>>
>>> here's the `.onLoad` function in the R survey package.  notice how the
>>> options are only set *if* they don't already exist--
>>
>> But a nicer convention is that used by most packages in R itself: if the
>> option is not set, the function using it assumes a suitable default.
>> That would make sense for all the FALSE defaults below.
>>
>> Note though that this is not 'persistent': users have to set options in
>> their startup files (see ?Startup).   There is no official location to
>> store package configurations.  Users generally dislike software saving
>> settings in their own file space so it seems very much preferable to use
>> the standard R mechanisms (.Rprofile etc).
>>
>>>
>>>> survey:::.onLoad
>>>
>>> function (...)
>>> {
>>>      if (is.null(getOption("survey.lonely.psu")))
>>> options(survey.lonely.psu = "fail")
>>>      if (is.null(getOption("survey.ultimate.cluster")))
>>> options(survey.ultimate.cluster = FALSE)
>>>      if (is.null(getOption("survey.want.obsolete")))
>>> options(survey.want.obsolete = FALSE)
>>>      if (is.null(getOption("survey.adjust.domain.lonely")))
>>> options(survey.adjust.domain.lonely = FALSE)
>>>      if (is.null(getOption("survey.drop.replicates")))
>>> options(survey.drop.replicates = TRUE)
>>>      if (is.null(getOption("survey.multicore")))
>>> options(survey.multicore = FALSE)
>>>      if (is.null(getOption("survey.replicates.mse")))
>>> options(survey.replicates.mse = FALSE)
>>> }
>>> <environment: namespace:survey>
>>>
>>>
>>>
>>>
>>> On Sat, Jun 1, 2013 at 4:01 PM, Jonathan Greenberg <jgrn at illinois.edu>wrote:
>>>
>>>> R-helpers:
>>>>
>>>> Say I'm developing a package that has a set of user-definable options that
>>>> I would like to be persistent across R-invocations (they are saved
>>>> someplace).  Of course, I can create a little text file to be written/read,
>>>> but I was wondering if there is an "officially sanctioned" way to do this?
>>>>   I see there is an options() and getOptions() function, but I'm unclear how
>>>> I would use this in my own package to create/save new options for my
>>>> particular package.  Cheers!
>>>>
>>>> --j
>>>>
>>>> --
>>>> Jonathan A. Greenberg, PhD
>>>> Assistant Professor
>>>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>>>> Department of Geography and Geographic Information Science
>>>> University of Illinois at Urbana-Champaign
>>>> 607 South Mathews Avenue, MC 150
>>>> Urbana, IL 61801
>>>> Phone: 217-300-1924
>>>> http://www.geog.illinois.edu/~jgrn/
>>>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
>
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 259 Computing Applications Building, MC-150
> 605 East Springfield Avenue
> Champaign, IL  61820-6371
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From murdoch.duncan at gmail.com  Sat Oct 19 01:55:50 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 18 Oct 2013 19:55:50 -0400
Subject: [R] Official way to set/retrieve options in packages?
In-Reply-To: <CABG0rftDuXF9S_nthC_2UdsTbJrnSFcuS+7VSfkSXpfwBg_6bQ@mail.gmail.com>
References: <CABG0rfskpFF8T+i9OKCBNRGyCS_rn7L1PVO4RO0NivWo0a7jGQ@mail.gmail.com>	<CAOwvMDz0kzspV8se-gB+7u2WAUghNi99fONcvEofPiVjfEjQng@mail.gmail.com>	<9ac4a7ea5b424580ba3c71d96dee61b7@CITESHT1.ad.uillinois.edu>
	<CABG0rftDuXF9S_nthC_2UdsTbJrnSFcuS+7VSfkSXpfwBg_6bQ@mail.gmail.com>
Message-ID: <5261CA86.4000009@gmail.com>

On 13-10-18 6:46 PM, Jonathan Greenberg wrote:
> Wanted to re-start this thread a bit, since I'm still not exactly sure
> the best approach to my problem -- basically, the parameters I'm try
> to make persistent are installation locations of a particular command
> line program that is not installed along with an R package I'm working
> on (GDAL, for those of you who are interested in the specifics).  The
> function tries to dummy-proof this process by doing a (mostly)
> brute-force search of the user's drive for the program location the
> first time it executes, and then stores this information (the path to
> a given executable) in an option for use with other functions.   This
> search process can take some time, so I'd prefer to have this option
> set in a semi-permanent way (so it persists between sessions).
>
> Now, Brian Ripley suggested modifying the .Rprofile, but Bert Guntner
> suggested this might not be a welcome behavior.  Given that, on an
> operating system level, there are often per-program directories for
> preferences, would it follow that it might make sense to store
> package-options in some standardized location?  If so, where might
> this be?  Would it make sense to drop then in the package directory?

No.

>
> Is this a discussion that should move over to r-developers?

Yes.

Duncan Murdoch

>
> --j
>
> On Sat, Jun 1, 2013 at 4:57 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> On 01/06/2013 22:44, Anthony Damico wrote:
>>> hope this helps..  :)
>>>
>>>       # define an object `x`
>>>       x <- list( "any value here" , 10 )
>>>
>>>       # set `myoption` to that object
>>>       options( "myoption" = x )
>>>
>>>       # retrieve it later (perhaps within a function elsewhere in the package)
>>>       ( y <- getOption( myoption ) )
>>>
>>>
>>> it's nice to name your options `mypackage.myoption` so users know what
>>> package the option is associated with in case they type `options()`
>>>
>>>
>>> here's the `.onLoad` function in the R survey package.  notice how the
>>> options are only set *if* they don't already exist--
>>
>> But a nicer convention is that used by most packages in R itself: if the
>> option is not set, the function using it assumes a suitable default.
>> That would make sense for all the FALSE defaults below.
>>
>> Note though that this is not 'persistent': users have to set options in
>> their startup files (see ?Startup).   There is no official location to
>> store package configurations.  Users generally dislike software saving
>> settings in their own file space so it seems very much preferable to use
>> the standard R mechanisms (.Rprofile etc).
>>
>>>
>>>> survey:::.onLoad
>>>
>>> function (...)
>>> {
>>>       if (is.null(getOption("survey.lonely.psu")))
>>> options(survey.lonely.psu = "fail")
>>>       if (is.null(getOption("survey.ultimate.cluster")))
>>> options(survey.ultimate.cluster = FALSE)
>>>       if (is.null(getOption("survey.want.obsolete")))
>>> options(survey.want.obsolete = FALSE)
>>>       if (is.null(getOption("survey.adjust.domain.lonely")))
>>> options(survey.adjust.domain.lonely = FALSE)
>>>       if (is.null(getOption("survey.drop.replicates")))
>>> options(survey.drop.replicates = TRUE)
>>>       if (is.null(getOption("survey.multicore")))
>>> options(survey.multicore = FALSE)
>>>       if (is.null(getOption("survey.replicates.mse")))
>>> options(survey.replicates.mse = FALSE)
>>> }
>>> <environment: namespace:survey>
>>>
>>>
>>>
>>>
>>> On Sat, Jun 1, 2013 at 4:01 PM, Jonathan Greenberg <jgrn at illinois.edu>wrote:
>>>
>>>> R-helpers:
>>>>
>>>> Say I'm developing a package that has a set of user-definable options that
>>>> I would like to be persistent across R-invocations (they are saved
>>>> someplace).  Of course, I can create a little text file to be written/read,
>>>> but I was wondering if there is an "officially sanctioned" way to do this?
>>>>    I see there is an options() and getOptions() function, but I'm unclear how
>>>> I would use this in my own package to create/save new options for my
>>>> particular package.  Cheers!
>>>>
>>>> --j
>>>>
>>>> --
>>>> Jonathan A. Greenberg, PhD
>>>> Assistant Professor
>>>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>>>> Department of Geography and Geographic Information Science
>>>> University of Illinois at Urbana-Champaign
>>>> 607 South Mathews Avenue, MC 150
>>>> Urbana, IL 61801
>>>> Phone: 217-300-1924
>>>> http://www.geog.illinois.edu/~jgrn/
>>>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>>>
>>>>           [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
>


From hpaul.benton08 at imperial.ac.uk  Sat Oct 19 02:17:54 2013
From: hpaul.benton08 at imperial.ac.uk (Benton, Paul)
Date: Sat, 19 Oct 2013 00:17:54 +0000
Subject: [R] find jumps in vector of repeats
Message-ID: <2733EDCF-EFD9-4ED1-AF11-F04DB7DD51F6@imperial.ac.uk>

Hello all,

I'm not really sure how to search for this in google/Rseek so there is probably a command to do it. I also know I could write an apply loop to find it but thought I would ask all you lovely R gurus. 

I have a very long vector (length=1855190) it looks something like this

1111...2222...3333....etc so it would be something equivalent of doing:
rep(c(1,2,3,4,5), c(10,30,24,65,3))

How can I find the index of where the step/jump is? For example using the above I would get an index of 0, 10, 40, 64, 129

Any help would be greatly appreciated.

Cheers,

Paul

From dtemplelang at ucdavis.edu  Sat Oct 19 02:22:56 2013
From: dtemplelang at ucdavis.edu (Duncan Temple Lang)
Date: Fri, 18 Oct 2013 17:22:56 -0700
Subject: [R] saveXML() prefix argument
In-Reply-To: <1889419292.977405.1382117263258.JavaMail.root@k-state.edu>
References: <1889419292.977405.1382117263258.JavaMail.root@k-state.edu>
Message-ID: <5261D0E0.1010408@ucdavis.edu>

Hi Earl

Unfortunately, the code works for me, i.e. indents _and_ displays the accented vowels correctly.

Can you send me the output of the function call

 libxmlVersion()

and also sessionInfo(), please?

 D.

On 10/18/13 10:27 AM, Earl Brown wrote:
> Thanks Duncan. However, now I can't get the Spanish and Portuguese accented vowels to come out correctly and still keep the indents in the saved document, even when I set encoding = "UTF-8":
> 
> library("XML")
> concepts <- c("espa?ol", "portugu?s")
> info <- c("info about espa?ol", "info about portugu?s")
> 
> doc <- newXMLDoc()
> root <- newXMLNode("tips", doc = doc)
> for (i in 1:length(concepts)) {
> 	cur.concept <- concepts[i]
> 	cur.info <- info[i]
> 	cur.tip <- newXMLNode("tip", attrs = c(id = i), parent = root)
> 	newXMLNode("h1", cur.concept, parent = cur.tip)
> 	newXMLNode("p", cur.info, parent = cur.tip)
> }
> 
> # accented vowels don't come through correctly, but the indents are correct:
> saveXML(doc, file = "test1.xml", indent = T)
> 
> Resulting file looks like this:
> <?xml version="1.0"?>
> <tips>
>   <tip id="1">
>     <h1>espa&#xF1;ol</h1>
>     <p>info about espa&#xF1;ol</p>
>   </tip>
>   <tip id="2">
>     <h1>portugu&#xEA;s</h1>
>     <p>info about portugu&#xEA;s</p>
>   </tip>
> </tips>
> 
> # accented vowels are correct, but the indents are no longer correct:
> saveXML(doc, file = "test2.xml", indent = T, encoding = "UTF-8")
> 
> Resulting file:
> <?xml version="1.0" encoding="UTF-8"?>
> <tips><tip id="1"><h1>espa?ol</h1><p>info about espa?ol</p></tip><tip id="2"><h1>portugu?s</h1><p>info about portugu?s</p></tip></tips>
> 
> I tried to workaround the problem by simply loading in that resulting file and saving it again:
> doc2 <- xmlInternalTreeParse(file = "test2.xml", asTree = T)
> saveXML(doc2, file = "test_word_around.xml", indent = T)
> 
> but still don't get the indents.
> 
> Does setting encoding = "UTF-8" override indents = TRUE in saveXML()?
> 
> Thanks. Earl
> 
> 
>


From wdunlap at tibco.com  Sat Oct 19 02:29:11 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 19 Oct 2013 00:29:11 +0000
Subject: [R] find jumps in vector of repeats
In-Reply-To: <2733EDCF-EFD9-4ED1-AF11-F04DB7DD51F6@imperial.ac.uk>
References: <2733EDCF-EFD9-4ED1-AF11-F04DB7DD51F6@imperial.ac.uk>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0C093@PA-MBX01.na.tibco.com>

> I have a very long vector (length=1855190) it looks something like this
> 
> 1111...2222...3333....etc so it would be something equivalent of doing:
> rep(c(1,2,3,4,5), c(10,30,24,65,3))
> 
> How can I find the index of where the step/jump is? For example using the above I would
> get an index of 0, 10, 40, 64, 129

Define 2 functions:
     isFirstInRun <- function(x) c(TRUE, x[-1]!=x[-length(x)])
     isLastInRun <- function(x) c(x[-1]!=x[-length(x)], TRUE)
and use them as
     > z <- rep(c(1,2,3,4,5), c(10,30,24,65,3))
     > which(isLastInRun(z))
     [1]  10  40  64 129 132
     > which(isFirstInRun(z))
     [1]   1  11  41  65 130
(0 is not a valid R index into a vector, so I prefer one of
the above results, but you can fiddle with the endpoints
as you wish.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Benton, Paul
> Sent: Friday, October 18, 2013 5:18 PM
> To: r-help at r-project.org
> Subject: [R] find jumps in vector of repeats
> 
> Hello all,
> 
> I'm not really sure how to search for this in google/Rseek so there is probably a
> command to do it. I also know I could write an apply loop to find it but thought I would
> ask all you lovely R gurus.
> 
> I have a very long vector (length=1855190) it looks something like this
> 
> 1111...2222...3333....etc so it would be something equivalent of doing:
> rep(c(1,2,3,4,5), c(10,30,24,65,3))
> 
> How can I find the index of where the step/jump is? For example using the above I would
> get an index of 0, 10, 40, 64, 129
> 
> Any help would be greatly appreciated.
> 
> Cheers,
> 
> Paul
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sat Oct 19 02:32:05 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 18 Oct 2013 17:32:05 -0700
Subject: [R] find jumps in vector of repeats
In-Reply-To: <2733EDCF-EFD9-4ED1-AF11-F04DB7DD51F6@imperial.ac.uk>
References: <2733EDCF-EFD9-4ED1-AF11-F04DB7DD51F6@imperial.ac.uk>
Message-ID: <CACk-te26ghh5-4qpPO4LCKux8SRU3pTAg5RPYcB=AFnjxa4mjA@mail.gmail.com>

Hint: ?diff

-- Bert

On Fri, Oct 18, 2013 at 5:17 PM, Benton, Paul
<hpaul.benton08 at imperial.ac.uk> wrote:
> Hello all,
>
> I'm not really sure how to search for this in google/Rseek so there is probably a command to do it. I also know I could write an apply loop to find it but thought I would ask all you lovely R gurus.
>
> I have a very long vector (length=1855190) it looks something like this
>
> 1111...2222...3333....etc so it would be something equivalent of doing:
> rep(c(1,2,3,4,5), c(10,30,24,65,3))
>
> How can I find the index of where the step/jump is? For example using the above I would get an index of 0, 10, 40, 64, 129
>
> Any help would be greatly appreciated.
>
> Cheers,
>
> Paul
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From ekbrown at k-state.edu  Fri Oct 18 19:27:43 2013
From: ekbrown at k-state.edu (Earl Brown)
Date: Fri, 18 Oct 2013 13:27:43 -0400 (EDT)
Subject: [R] saveXML() prefix argument
In-Reply-To: <mailman.29.1382090408.489.r-help@r-project.org>
Message-ID: <1889419292.977405.1382117263258.JavaMail.root@k-state.edu>

Thanks Duncan. However, now I can't get the Spanish and Portuguese accented vowels to come out correctly and still keep the indents in the saved document, even when I set encoding = "UTF-8":

library("XML")
concepts <- c("espa?ol", "portugu?s")
info <- c("info about espa?ol", "info about portugu?s")

doc <- newXMLDoc()
root <- newXMLNode("tips", doc = doc)
for (i in 1:length(concepts)) {
	cur.concept <- concepts[i]
	cur.info <- info[i]
	cur.tip <- newXMLNode("tip", attrs = c(id = i), parent = root)
	newXMLNode("h1", cur.concept, parent = cur.tip)
	newXMLNode("p", cur.info, parent = cur.tip)
}

# accented vowels don't come through correctly, but the indents are correct:
saveXML(doc, file = "test1.xml", indent = T)

Resulting file looks like this:
<?xml version="1.0"?>
<tips>
  <tip id="1">
    <h1>espa&#xF1;ol</h1>
    <p>info about espa&#xF1;ol</p>
  </tip>
  <tip id="2">
    <h1>portugu&#xEA;s</h1>
    <p>info about portugu&#xEA;s</p>
  </tip>
</tips>

# accented vowels are correct, but the indents are no longer correct:
saveXML(doc, file = "test2.xml", indent = T, encoding = "UTF-8")

Resulting file:
<?xml version="1.0" encoding="UTF-8"?>
<tips><tip id="1"><h1>espa?ol</h1><p>info about espa?ol</p></tip><tip id="2"><h1>portugu?s</h1><p>info about portugu?s</p></tip></tips>

I tried to workaround the problem by simply loading in that resulting file and saving it again:
doc2 <- xmlInternalTreeParse(file = "test2.xml", asTree = T)
saveXML(doc2, file = "test_word_around.xml", indent = T)

but still don't get the indents.

Does setting encoding = "UTF-8" override indents = TRUE in saveXML()?

Thanks. Earl


From kevin.schiesser at xoom.com  Fri Oct 18 19:52:08 2013
From: kevin.schiesser at xoom.com (Kevin Schiesser)
Date: Fri, 18 Oct 2013 17:52:08 +0000
Subject: [R] Need to merge multiple data frames with time stamp
In-Reply-To: <67E5165A9DDC8E458AB7D5BE99D18F020E792E3B@SIDCMBX06.in.ril.com>
Message-ID: <CE86C290.DB22%kevin.schiesser@xoom.com>

Merge has an option 'all', when set to 'TRUE' merge will return a
data.frame of every row in both data.frames. You can also specify all.x,
and all.y.

I do not suggest taking this path. Rather, standardize time columns for
all 15 data.frames with as.POSIXct()/as.POSIXlt() depending on the input
time format.

-Kevin

On 10/18/13 04:37 , "Sandeep.Sampara at ril.com" <Sandeep.Sampara at ril.com>
wrote:

Hi,

 

I'm trying to combine 15 different data frames but all have time field as
common. But the thing is time intervals are different (like min's and
sec's).

So I have to check the common time from all the 15 data frames and merge it
to a single data frame and then export it to excel or csv.

I tried with below query but it's not giving exact output. It's almost 5
year of data, but its giving output for 3months only.

Please help with your query to get my output.

 

a <- merge(MA2DHPA,MA2DHPB,by="IP_Trend_Time")

b <- merge(MA2UCPA,MA2UCPB,by="IP_Trend_Time")

c <- merge(MA2DCPA,MA2DCPB,by="IP_Trend_Time")

d <- merge(MA2DHTA,MA2DHTB,by="IP_Trend_Time")

e <- merge(MA2UCTA,MA2UCTB,by="IP_Trend_Time")

f <- merge(MA2DCTA,MA2DCTB,by="IP_Trend_Time")

g <- merge(MA2CP,MA2CPS,by="IP_Trend_Time")

h <- MA2AP

 

x <- merge(a,b,by="IP_Trend_Time")

y <- merge(c,d,by="IP_Trend_Time")

z <- merge(e,f,by="IP_Trend_Time")

w <- merge(g,h,by="IP_Trend_Time")

 

x1 <- merge(x,y,by="IP_Trend_Time")

y1 <- merge(z,w,by="IP_Trend_Time")

 

MA2 <- merge(x1,y1,by="IP_Trend_Time")

 

Regards,

Sandeep S|IT&C,
Reliance Industries Limited (E&P) | Onshore Terminal | Gadimoga
*  +91 884 2977066 / 9908130749

 

Please consider the environment before printing this email.

 


---------------------------------------------------------------------------------
The information transmitted in this email is intended on...{{dropped:9}}


From smartpink111 at yahoo.com  Sat Oct 19 06:31:51 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 18 Oct 2013 21:31:51 -0700 (PDT)
Subject: [R] Loop for taking sum of rows based on proximity to other
	non-NA rows
In-Reply-To: <1382127564.35830.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1382127564.35830.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1382157111.46359.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,

Found a bug in the function when tested.? So, try this (added one more line):

#Modified function
fun1 <- function(dat,n) {
?rl <- rle(is.na(dat[,"Count"]))
indx <- which(is.na(dat[,"Count"]))[rep(rl$lengths[rl$values],rl$lengths[rl$values])==n]
?lst1 <- lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) {
???????????????????????? x1 <- dat[c(min(x)-1L,x,max(x)+1L),]
???????????????????? x2 <- x1[!is.na(x1$Count),]
???????????????????? datN <- data.frame(Position=max(x2$Position),Count=sum(x2$Count))
???????????????????? rowN <- row.names(x2)[x2$Position %in% max(x2$Position)]?? 
???????????????????? row.names(datN) <- if(length(rowN)>1) rowN[1] else rowN
???????????????????? datN
??????????????????? })
names(lst1) <- NULL
lst1 <- lst1[!duplicated(sapply(lst1,row.names))] ######added
dat2 <- do.call(rbind,lst1)
indx2 <-? sort(unlist(lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) c(min(x)-1L,x,c(max(x)+1L))),use.names=FALSE))

dat1New <- dat[-indx2[!indx2 %in% row.names(dat2)],]
dat1New[match(row.names(dat2),row.names(dat1New)),] <- dat2
row.names(dat1New) <- 1:nrow(dat1New)
dat1New
}



#Another function
fun2 <- function(dat,n){
?indx <- cumsum(c(1,abs(diff(is.na(dat[,"Count"])))))
?indx1 <- indx[is.na(dat[,"Count"])]
?names(indx1) <- which(is.na(dat[,"Count"]))
indx2 <- indx1[indx1 %in% names(table(indx1))[table(indx1)==n]]
lst1 <- tapply(seq_along(indx2),list(indx2),FUN=function(i) {
??? ??? ??? ??? ??? ??? ??? x1 <- indx2[i]
??? ??? ??? ??? ??? ??? ??? ?x2 <- as.numeric(names(x1))
??? ??? ??? ??? ??? ??? ??? ?x3 <- dat[c(min(x2)-1L,x2,max(x2)+1L),]
??? ??? ??? ??? ??? ??? ??? ?x4 <- subset(x3, !is.na(Count))
??? ??? ??? ??? ??? ??? ??? ?x5 <- data.frame(Position=max(x4$Position),Count=sum(x4$Count))
??? ??? ??? ??? ??? ??? ??? ind <- x4$Position %in% max(x4$Position)
??? ??? ??? ??? ??? ??? ??? ?row.names(x5) <- if(sum(ind)>1) row.names(x4)[ind][1] else row.names(x4)[ind]
??? ??? ??? ??? ??? ??? ??? x5
??? ??? ??? ??? ??? ??? })
attr(lst1,"dimnames") <- NULL
?dat2 <- do.call(rbind,lst1)
indx3 <- sort(unlist(tapply(seq_along(indx2),list(indx2),FUN=function(i) {x1 <- indx2[i]
??? ??? ??? ??? ??? ??? ??? ??? ??? ?x2 <- as.numeric(names(x1))
??? ??? ??? ??? ??? ??? ??? ??? ??? ?c(min(x2)-1L, x2, max(x2)+1L)}),use.names=FALSE))

dat$id <- 1:nrow(dat)
dat2$id <- as.numeric(row.names(dat2))
library(plyr)
res <- join(dat,dat2[,-1],by="id",type="left")
res1 <- res[!((row.names(res) %in% indx3) & is.na(res[,4])),]
res1[,2][!is.na(res1[,4])] <- res1[,4][!is.na(res1[,4])]
res2 <- res1[,1:2]
row.names(res2) <- 1:nrow(res2)
res2
}


identical(fun1(dat1,1),fun2(dat1,1))
#[1] TRUE
identical(fun1(fun1(dat1,1),2),fun2(fun2(dat1,1),2))
#[1] TRUE

identical(fun1(fun1(fun1(dat1,1),2),3),fun2(fun2(fun2(dat1,1),2),3))
#[1] TRUE


#Speed
set.seed(185)
datT <- data.frame(Position = sample(10:80,1e5,replace=TRUE),Count= sample(c(NA, 10:100),1e5, replace=TRUE))
?system.time(res <- fun1(datT,1))
?#? user? system elapsed 
?# 0.676?? 0.000?? 0.676 
?system.time(res2 <- fun2(datT,1))
#?? user? system elapsed 
#? 1.240?? 0.000?? 1.237 
?identical(res,res2)
#[1] TRUE

A.K.









On Friday, October 18, 2013 4:19 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,

May be this helps:

dat1 <- structure(list(Position = c(15L, 22L, 38L, 49L, 55L, 61L, 62L, 
14L, 29L, 63L, 46L, 22L, 18L, 24L, 22L, 49L, 42L, 38L, 29L, 22L, 
29L, 23L, 42L), Count = c(15L, NA, NA, 5L, NA, 17L, 18L, NA, 
NA, NA, 8L, NA, 20L, NA, NA, 16L, 19L, NA, NA, NA, 13L, NA, 33L
)), .Names = c("Position", "Count"), class = "data.frame", row.names = c(NA, 
-23L))


#There might be simple solutions.

fun1 <- function(dat,n) {
?rl <- rle(is.na(dat[,"Count"]))
indx <- which(is.na(dat[,"Count"]))[rep(rl$lengths[rl$values],rl$lengths[rl$values])==n]
?lst1 <- lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) {
??? ??? ??? ??? ???????? x1 <- dat[c(min(x)-1L,x,max(x)+1L),]
??? ??? ??? ??? ??? ?x2 <- x1[!is.na(x1$Count),]
??? ??? ??? ??? ??? ?datN <- data.frame(Position=max(x2$Position),Count=sum(x2$Count))
??? ??? ??? ??? ??? ?rowN <- row.names(x2)[x2$Position %in% max(x2$Position)]??? 
??? ??? ??? ??? ??? ?row.names(datN) <- if(length(rowN)>1) rowN[1] else rowN
??? ??? ??? ??? ??? ?datN
??? ??? ??? ??? ??? })
names(lst1) <- NULL
dat2 <- do.call(rbind,lst1)
indx2 <-? sort(unlist(lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) c(min(x)-1L,x,c(max(x)+1L))),use.names=FALSE))

dat1New <- dat[-indx2[!indx2 %in% row.names(dat2)],]
dat1New[match(row.names(dat2),row.names(dat1New)),] <- dat2
row.names(dat1New) <- 1:nrow(dat1New)
dat1New
}

dat1N <- fun1(dat1,1)
dat1N
?? Position Count
1??????? 15??? 15
2??????? 22??? NA
3??????? 38??? NA
4??????? 61??? 22
5??????? 62??? 18
6??????? 14??? NA
7??????? 29??? NA
8??????? 63??? NA
9??????? 46??? 28
10?????? 24??? NA
11?????? 22??? NA
12?????? 49??? 16
13?????? 42??? 19
14?????? 38??? NA
15?????? 29??? NA
16?????? 22??? NA
17?????? 42??? 46

dat2N <- fun1(dat1N,2)
dat2N
?? Position Count
1??????? 61??? 37
2??????? 62??? 18
3??????? 14??? NA
4??????? 29??? NA
5??????? 63??? NA
6??????? 49??? 44
7??????? 42??? 19
8??????? 38??? NA
9??????? 29??? NA
10?????? 22??? NA
11?????? 42??? 46
dat3N <- fun1(dat2N,3)
dat3N
? Position Count
1?????? 61??? 37
2?????? 62??? 62
3?????? 42??? 65

A.K.









Hi all, I have a dataset with 2 important columns, "Position" and 
"Count". There are a total of 34,532 rows, but only 457 non-NA values in the "Count" column (every cell in "Position" column has a value). I 
need to write a loop to march down the rows, and if there are 2 rows in 
"Count" where there is only 1 NA row between them, sum the two values up and print only one row with the summed Count value and the Position 
value that corresponds to the larger Count value, thus making the three 
rows into one. For example: 

Position Count 
15 15 
22 NA 
38 NA 
49 5 
55 NA 
61 17 

would become 

Position Count 
15 15 
22 NA 
38 NA 
61 22 

After this step, I also need to write another script to march 
down the rows and look for rows with only two NA's between non-NA rows 
in Count. This would make the previous data become 

Position Count 
61 37 

Ideally I would like a loop that can be flexibly adjusted to the
number of NA's in between adjacent non-NA values that can be freely 
changed. I would greatly appreciate any insight for this.


From smartpink111 at yahoo.com  Sat Oct 19 06:47:06 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 18 Oct 2013 21:47:06 -0700 (PDT)
Subject: [R] How would i set every column in a data frame to a scale of
	1-100
Message-ID: <1382158026.69530.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try

dat <- read.table(text="
a?? b???? c
0?? 89?? 4
1?? 93?? 3
0?? 88?? 5",sep="",header=TRUE) 

datNew <- within(dat,{a<-a*(100/1);c <- c*(100/5)})

#or
vec1 <- c(1,100,5)
as.data.frame(t(t(dat*(100))/vec1))


#or
sweep(dat*100,2,vec1,`/`)


A.K.



Hi, i am trying to get all the colums of my data frame to be in the same scale.. 

right now i have something like this... where a is on a 0-1 scale ?b is on a 100 scale and c is on a 1-5 scale 
a ? b ? ? c 
0 ? 89 ? 4 
1 ? 93 ? 3 
0 ? 88 ? 5 

How would i get it to a 100scale like this... 
a ? ? b ? ? ?c 
0 ? ? 89 ? ? 80 
100 ?93 ? ? 60 
0 ? ? 88 ? ? 100 

i hope that is somewhat clear..


From bhh at xs4all.nl  Sat Oct 19 06:51:08 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 19 Oct 2013 06:51:08 +0200
Subject: [R] find jumps in vector of repeats
In-Reply-To: <2733EDCF-EFD9-4ED1-AF11-F04DB7DD51F6@imperial.ac.uk>
References: <2733EDCF-EFD9-4ED1-AF11-F04DB7DD51F6@imperial.ac.uk>
Message-ID: <0F09C092-19F0-49DB-8978-136F1D1CCD0A@xs4all.nl>


On 19-10-2013, at 02:17, "Benton, Paul" <hpaul.benton08 at imperial.ac.uk> wrote:

> Hello all,
> 
> I'm not really sure how to search for this in google/Rseek so there is probably a command to do it. I also know I could write an apply loop to find it but thought I would ask all you lovely R gurus. 
> 
> I have a very long vector (length=1855190) it looks something like this
> 
> 1111...2222...3333....etc so it would be something equivalent of doing:
> rep(c(1,2,3,4,5), c(10,30,24,65,3))
> 
> How can I find the index of where the step/jump is? For example using the above I would get an index of 0, 10, 40, 64, 129
> 
> Any help would be greatly appreciated.


z <- rep(c(1,2,3,4,5), c(10,30,24,65,3))
cumsum(rle(z)$lengths) 

Berend


From smartpink111 at yahoo.com  Sat Oct 19 06:54:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 18 Oct 2013 21:54:57 -0700 (PDT)
Subject: [R] find jumps in vector of repeats
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA0C093@PA-MBX01.na.tibco.com>
References: <2733EDCF-EFD9-4ED1-AF11-F04DB7DD51F6@imperial.ac.uk>
	<E66794E69CFDE04D9A70842786030B933FA0C093@PA-MBX01.na.tibco.com>
Message-ID: <1382158497.37782.YahooMailNeo@web142602.mail.bf1.yahoo.com>

In addition to Bill's method, you may also use:

vec1 <- rep(c(1,2,3,4,5), c(10,30,24,65,3))
?c(0,which(diff(vec2)!=0))
#or
?indx <- cumsum(rle(vec2)$lengths)
?c(0,indx[-length(indx)])


#Bill's method was found to be the fastest


vec3 <- rep(vec1,1e4)
system.time( res <- c(0,which(diff(vec3)!=0)))
#?? user? system elapsed 
# 0.124?? 0.000?? 0.125 
?system.time({ indx <- cumsum(rle(vec3)$lengths)
?res2 <- c(0,indx[-length(indx)])})
#?? user? system elapsed 
#?? 0.112?? 0.000?? 0.112 

?system.time({ indx <- which(isLastInRun(vec3))
?res3 <- c(0,indx[-length(indx)]) })
#?? user? system elapsed 
#? 0.088?? 0.000?? 0.086 
system.time({indx <- cumsum(c(0,abs(diff(vec3))))
?indx2 <- tapply(seq_along(indx),list(indx),FUN=max)
?res4 <- c(0,indx2[-length(indx2)]) })
#?? user? system elapsed 
#? 2.456?? 0.000?? 2.457 
?names(res4)<-NULL
?identical(res,res4)
#[1] TRUE
identical(res,res2)
#[1] TRUE
?identical(res,res3)
#[1] TRUE

A.K.



On Friday, October 18, 2013 8:31 PM, William Dunlap <wdunlap at tibco.com> wrote:
> I have a very long vector (length=1855190) it looks something like this
> 
> 1111...2222...3333....etc so it would be something equivalent of doing:
> rep(c(1,2,3,4,5), c(10,30,24,65,3))
> 
> How can I find the index of where the step/jump is? For example using the above I would
> get an index of 0, 10, 40, 64, 129

Define 2 functions:
? ?  isFirstInRun <- function(x) c(TRUE, x[-1]!=x[-length(x)])
? ?  isLastInRun <- function(x) c(x[-1]!=x[-length(x)], TRUE)
and use them as
? ?  > z <- rep(c(1,2,3,4,5), c(10,30,24,65,3))
? ?  > which(isLastInRun(z))
? ?  [1]? 10? 40? 64 129 132
? ?  > which(isFirstInRun(z))
? ?  [1]?  1? 11? 41? 65 130
(0 is not a valid R index into a vector, so I prefer one of
the above results, but you can fiddle with the endpoints
as you wish.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Benton, Paul
> Sent: Friday, October 18, 2013 5:18 PM
> To: r-help at r-project.org
> Subject: [R] find jumps in vector of repeats
> 
> Hello all,
> 
> I'm not really sure how to search for this in google/Rseek so there is probably a
> command to do it. I also know I could write an apply loop to find it but thought I would
> ask all you lovely R gurus.
> 
> I have a very long vector (length=1855190) it looks something like this
> 
> 1111...2222...3333....etc so it would be something equivalent of doing:
> rep(c(1,2,3,4,5), c(10,30,24,65,3))
> 
> How can I find the index of where the step/jump is? For example using the above I would
> get an index of 0, 10, 40, 64, 129
> 
> Any help would be greatly appreciated.
> 
> Cheers,
> 
> Paul
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sat Oct 19 07:14:04 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 18 Oct 2013 22:14:04 -0700 (PDT)
Subject: [R] read table and import of a text file
In-Reply-To: <1382107602.94774.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1382107602.94774.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1382159644.87379.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,

The code is based on what you pasted on the page. In the original post, you used sep="", while the pasted data shows "," as delimiter.
dat1 <- subset(head(read.table(text="#Hogd/met, Temp, 005[M], Value
#Hogd/met, Difftemp, 051[M], Value
BA0+
1 MTEMP005 1 [deg.C]
2 MDTMP051 1 [deg.C]
EOH
891231, 2400, -1.5, -0.21,
900101, 0100, -1.4, -0.25,
900101, 0200, -1.6, -0.28,
900101, 0300, -1.7, -0.25,
900101, 0400, -2.1, -0.0999999,
900101, 0500, -2.3, -0.0899999,
900101, 0600, -2.4, -0.21,
900101, 0700, -2.5, -0.28,
900101, 0800, -2.6, -0.3,
900101, 0900, -2.8, -0.3,
900101, 1000, -2.8, -0.3,
900101, 1100, -2.7, -0.3,
900101, 1200, -3, -0.3,
900101, 1300, -3.2, -0.3,
900101, 1400, -3.5, -0.0999999,
900101, 1500, -4, -0.2,
900101, 1600, -4.5, -0.19,
900101, 1700, -5.3, 0.27,
900101, 1800, -4, -0.27,
900101, 1900, -4, -0.28,
900101, 2000, -3.8, -0.28,
EOF",skip=6,sep=",",header=FALSE,fill=TRUE,stringsAsFactors=FALSE),-1),select=1:4)
?str(dat1)
#'data.frame':??? 21 obs. of? 4 variables:
# $ V1: num? 891231 900101 900101 900101 900101 ...
# $ V2: int? 2400 100 200 300 400 500 600 700 800 900 ...
# $ V3: num? -1.5 -1.4 -1.6 -1.7 -2.1 -2.3 -2.4 -2.5 -2.6 -2.8 ...
# $ V4: num? -0.21 -0.25 -0.28 -0.25 -0.1 ...
dat1
?????? V1?? V2?? V3???????? V4
1? 891231 2400 -1.5 -0.2100000
2? 900101? 100 -1.4 -0.2500000
3? 900101? 200 -1.6 -0.2800000
4? 900101? 300 -1.7 -0.2500000
5? 900101? 400 -2.1 -0.0999999
6? 900101? 500 -2.3 -0.0899999
7? 900101? 600 -2.4 -0.2100000
8? 900101? 700 -2.5 -0.2800000
9? 900101? 800 -2.6 -0.3000000
10 900101? 900 -2.8 -0.3000000
11 900101 1000 -2.8 -0.3000000
12 900101 1100 -2.7 -0.3000000
13 900101 1200 -3.0 -0.3000000
14 900101 1300 -3.2 -0.3000000
15 900101 1400 -3.5 -0.0999999
16 900101 1500 -4.0 -0.2000000
17 900101 1600 -4.5 -0.1900000
18 900101 1700 -5.3? 0.2700000
19 900101 1800 -4.0 -0.2700000
20 900101 1900 -4.0 -0.2800000
21 900101 2000 -3.8 -0.2800000


A.K.








Thanks, but the code does not work. ?I received an error like this one " Error in read.table(text = gsub("#|,$", "", temp[grepl(",", 
temp)][-1]), ?: 
? duplicate 'row.names' are not allowed". 

In the sample data that I have pasted on this page the data has 
four columns and it starts at the following line "891231, 2400, -1.5, 
-0.21, ". ?Anything before that is uninteresting for me. ? 


On Friday, October 18, 2013 10:46 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,

Assuming that you provided the sample data from the file.
temp <- readLines(textConnection("#Hogd/met, Temp, 005[M], Value
#Hogd/met, Difftemp, 051[M], Value
BA0+
1 MTEMP005 1 [deg.C]
2 MDTMP051 1 [deg.C]
EOH
891231, 2400, -1.5, -0.21,
900101, 0100, -1.4, -0.25,
900101, 0200, -1.6, -0.28,
900101, 0300, -1.7, -0.25,
900101, 0400, -2.1, -0.0999999,
900101, 0500, -2.3, -0.0899999,
900101, 0600, -2.4, -0.21,
900101, 0700, -2.5, -0.28,
900101, 0800, -2.6, -0.3,
900101, 0900, -2.8, -0.3,
900101, 1000, -2.8, -0.3,
900101, 1100, -2.7, -0.3,
900101, 1200, -3, -0.3,
900101, 1300, -3.2, -0.3,
900101, 1400, -3.5, -0.0999999,
900101, 1500, -4, -0.2,
900101, 1600, -4.5, -0.19,
900101, 1700, -5.3, 0.27,
900101, 1800, -4, -0.27,
900101, 1900, -4, -0.28,
900101, 2000, -3.8, -0.28,
EOF")) 

temp1 <- read.table(text=gsub("#|,$","",temp[grepl(",",temp)][-1]),sep=",",header=TRUE,check.names=FALSE)
?head(temp1)
#? Hogd/met Difftemp 051[M]????? Value
#1?? 891231???? 2400?? -1.5 -0.2100000
#2?? 900101????? 100?? -1.4 -0.2500000
#3?? 900101????? 200?? -1.6 -0.2800000
#4?? 900101????? 300?? -1.7 -0.2500000
#5?? 900101????? 400?? -2.1 -0.0999999
#6?? 900101????? 500?? -2.3 -0.0899999


A.K.



I have a text file which was imported imperfectly. ?I used the following code: 
temp<-read.table("/New/temp.txt",skip=6,header = TRUE, sep="") 

However the result is not what I expected and looks like: 

> head(temp) 
? ? ? ?X891231..2400...1.5...0.21. 
1 ? ? ?900101, 0100, -1.4, -0.25, 
2 ? ? ?900101, 0200, -1.6, -0.28, 
3 ? ? ?900101, 0300, -1.7, -0.25, 
4 900101, 0400, -2.1, -0.0999999, 
5 900101, 0500, -2.3, -0.0899999, 
6 ? ? ?900101, 0600, -2.4, -0.21, 

Sample data with header and footer is found here: 

#Hogd/met, Temp, 005[M], Value 
#Hogd/met, Difftemp, 051[M], Value 
BA0+ 
1 MTEMP005 1 [deg.C] 
2 MDTMP051 1 [deg.C] 
EOH 
891231, 2400, -1.5, -0.21, 
900101, 0100, -1.4, -0.25, 
900101, 0200, -1.6, -0.28, 
900101, 0300, -1.7, -0.25, 
900101, 0400, -2.1, -0.0999999, 
900101, 0500, -2.3, -0.0899999, 
900101, 0600, -2.4, -0.21, 
900101, 0700, -2.5, -0.28, 
900101, 0800, -2.6, -0.3, 
900101, 0900, -2.8, -0.3, 
900101, 1000, -2.8, -0.3, 
900101, 1100, -2.7, -0.3, 
900101, 1200, -3, -0.3, 
900101, 1300, -3.2, -0.3, 
900101, 1400, -3.5, -0.0999999, 
900101, 1500, -4, -0.2, 
900101, 1600, -4.5, -0.19, 
900101, 1700, -5.3, 0.27, 
900101, 1800, -4, -0.27, 
900101, 1900, -4, -0.28, 
900101, 2000, -3.8, -0.28, 
EOF 

I have a number of similar files and would like to understand 
what I did wrong. I also wish to understand the anatomy of this text 
file. What does EOH mean? and EOF? I could not find this issues on web 
search. Thanks


From ripley at stats.ox.ac.uk  Sat Oct 19 08:35:03 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 19 Oct 2013 07:35:03 +0100
Subject: [R] No P.values in polr summary
In-Reply-To: <CANCN_HSuEbJvGNo-XaAFPmPN_2A=WPJbahjC-Ms0JQKXWU_rBQ@mail.gmail.com>
References: <CANCN_HSuEbJvGNo-XaAFPmPN_2A=WPJbahjC-Ms0JQKXWU_rBQ@mail.gmail.com>
Message-ID: <52622817.5020805@stats.ox.ac.uk>

On 18/10/2013 15:01, Vincent Guyader wrote:
> Hi everyone,
>
> If I compute a "Ordered Logistic or Probit Regression" with the polr
> function from MASS package. the summary give me : coefficients, Standard
> error and Tvalue.. but  not directly the p.value.
>
>
> I can compute "manualy" the Pvalue, but Is there a way to directly obtain
> the pa.value, and I wonder why the p.valeu is not directly calculated, is
> there a reason?

How are you going to calculate the P values?  Have you read the book for 
which this is support software?: it explains why such Wald tests are 
inappropriate and that the asymptotic theory can be wildly misleading.

>
> exemple :
>
> house.plr <- polr(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
> house.plr
> summary(house.plr, digits = 3)
>
>
>
>
> Regards
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
PLEASE do.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tcmuigai at gmail.com  Sat Oct 19 11:26:46 2013
From: tcmuigai at gmail.com (Charles Thuo)
Date: Sat, 19 Oct 2013 12:26:46 +0300
Subject: [R] fitting a random gamma sample into the weibull distribution
Message-ID: <CAAJc=rNn-JyR0fov_U=dAHBH-oAzqbPz8aQHCJwUvmPC3kQNCw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131019/1c017615/attachment.pl>

From ignacio82 at gmail.com  Sat Oct 19 12:22:02 2013
From: ignacio82 at gmail.com (Ignacio Martinez)
Date: Sat, 19 Oct 2013 06:22:02 -0400
Subject: [R] ivreg with fixed effect in R?
Message-ID: <CAJA1VFzVFL=i4bOfDJt1YrJp4tVH6W1kGT+v8ESvKqEeOeDk4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131019/edf7606f/attachment.pl>

From Achim.Zeileis at uibk.ac.at  Sat Oct 19 13:29:23 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sat, 19 Oct 2013 13:29:23 +0200 (CEST)
Subject: [R] ivreg with fixed effect in R?
In-Reply-To: <CAJA1VFzVFL=i4bOfDJt1YrJp4tVH6W1kGT+v8ESvKqEeOeDk4Q@mail.gmail.com>
References: <CAJA1VFzVFL=i4bOfDJt1YrJp4tVH6W1kGT+v8ESvKqEeOeDk4Q@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1310191326001.26017@paninaro.uibk.ac.at>

On Sat, 19 Oct 2013, Ignacio Martinez wrote:

> I want to estimate the following fixed effect model:
> y_i,t = alpha_i + beta_1 x1_t + beta_2 x2_i,tx2_i,t = gamma_i + gamma_1
> x1_t + gamma_2 Z1_i + gamma_3 Z2_i
> I can use ivreg from AER to do the iv regression.
> fm <- ivreg(y_i,t ~  x1_t + x2_i,t |                x1_t + Z1_i + Z2_i,
>        data = DataSet)
> But, I'm not sure how can I add the fixed effects.

You can simply add a factor coding the variable with respect to which you 
want to compute fixed effects. In help("Fatalities", package = "AER") 
there is an example (starting with "pp. 360") that shows how to do this 
for OLS. In principle, the same approach can be used for IV.

> Thanks!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From nalimilan at club.fr  Sat Oct 19 13:36:14 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sat, 19 Oct 2013 13:36:14 +0200
Subject: [R] saveXML() prefix argument
In-Reply-To: <1889419292.977405.1382117263258.JavaMail.root@k-state.edu>
References: <1889419292.977405.1382117263258.JavaMail.root@k-state.edu>
Message-ID: <1382182574.13698.41.camel@milan>

Le vendredi 18 octobre 2013 ? 13:27 -0400, Earl Brown a ?crit :
> Thanks Duncan. However, now I can't get the Spanish and Portuguese accented vowels to come out correctly and still keep the indents in the saved document, even when I set encoding = "UTF-8":
> 
> library("XML")
> concepts <- c("espa?ol", "portugu?s")
> info <- c("info about espa?ol", "info about portugu?s")
> 
> doc <- newXMLDoc()
> root <- newXMLNode("tips", doc = doc)
> for (i in 1:length(concepts)) {
> 	cur.concept <- concepts[i]
> 	cur.info <- info[i]
> 	cur.tip <- newXMLNode("tip", attrs = c(id = i), parent = root)
> 	newXMLNode("h1", cur.concept, parent = cur.tip)
> 	newXMLNode("p", cur.info, parent = cur.tip)
> }
> 
> # accented vowels don't come through correctly, but the indents are correct:
> saveXML(doc, file = "test1.xml", indent = T)
> 
> Resulting file looks like this:
> <?xml version="1.0"?>
> <tips>
>   <tip id="1">
>     <h1>espa&#xF1;ol</h1>
>     <p>info about espa&#xF1;ol</p>
>   </tip>
>   <tip id="2">
>     <h1>portugu&#xEA;s</h1>
>     <p>info about portugu&#xEA;s</p>
>   </tip>
> </tips>
> 
> # accented vowels are correct, but the indents are no longer correct:
> saveXML(doc, file = "test2.xml", indent = T, encoding = "UTF-8")
> 
> Resulting file:
> <?xml version="1.0" encoding="UTF-8"?>
> <tips><tip id="1"><h1>espa?ol</h1><p>info about espa?ol</p></tip><tip
> id="2"><h1>portugu?s</h1><p>info about portugu?s</p></tip></tips>
> 
> I tried to workaround the problem by simply loading in that resulting
> file and saving it again:
> doc2 <- xmlInternalTreeParse(file = "test2.xml", asTree = T)
> saveXML(doc2, file = "test_word_around.xml", indent = T)
> 
> but still don't get the indents.
> 
> Does setting encoding = "UTF-8" override indents = TRUE in saveXML()?
I can confirm the same issue happens here. What is interesting is that
without the 'file' argument, the returned string includes the expected
line breaks and spacing. These do not appear when redirecting the output
to a file.

> saveXML(doc, encoding="UTF-8", indent=T)
[1] "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<tips>\n  <tip id=\"1
\">\n    <h1>espa?ol</h1>\n    <p>info about espa?ol</p>\n  </tip>\n
<tip id=\"2\">\n    <h1>portugu?s</h1>\n    <p>info about
portugu?s</p>\n  </tip>\n</tips>\n"

> saveXML(doc, encoding="UTF-8", indent=T, file="test.xml")

Contents of test.xml:
<?xml version="1.0" encoding="UTF-8"?>
<tips><tip id="1"><h1>espa?ol</h1><p>info about espa?ol</p></tip><tip id="2"><h1>portugu?s</h1><p>info about portugu?s</p></tip></tips>


> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-redhat-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=fr_FR.utf8       LC_NUMERIC=C             
 [3] LC_TIME=fr_FR.utf8        LC_COLLATE=fr_FR.utf8    
 [5] LC_MONETARY=fr_FR.utf8    LC_MESSAGES=fr_FR.utf8   
 [7] LC_PAPER=C                LC_NAME=C                
 [9] LC_ADDRESS=C              LC_TELEPHONE=C           
[11] LC_MEASUREMENT=fr_FR.utf8 LC_IDENTIFICATION=C      

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
base     

other attached packages:
[1] XML_3.96-1.1


Regards


From ignacio82 at gmail.com  Sat Oct 19 13:39:45 2013
From: ignacio82 at gmail.com (Ignacio Martinez)
Date: Sat, 19 Oct 2013 07:39:45 -0400
Subject: [R] ivreg with fixed effect in R?
In-Reply-To: <alpine.DEB.2.10.1310191326001.26017@paninaro.uibk.ac.at>
References: <CAJA1VFzVFL=i4bOfDJt1YrJp4tVH6W1kGT+v8ESvKqEeOeDk4Q@mail.gmail.com>
	<alpine.DEB.2.10.1310191326001.26017@paninaro.uibk.ac.at>
Message-ID: <CAJA1VFyvzw22cBPbu3S2_2bek7DL_M-OamydVfTDac-4zdYpBA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131019/576a53ac/attachment.pl>

From Achim.Zeileis at uibk.ac.at  Sat Oct 19 14:03:32 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sat, 19 Oct 2013 14:03:32 +0200
Subject: [R] ivreg with fixed effect in R?
Message-ID: <59fs94wuc0w8gc5e39srn83s.1382184212414@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131019/ba1d9344/attachment.pl>

From info at aghmed.fsnet.co.uk  Sat Oct 19 15:12:25 2013
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sat, 19 Oct 2013 14:12:25 +0100
Subject: [R] Fortune?,
 was Re: Recovering object names when using the ... argument in a fn
 XXXX
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA0BF75@PA-MBX01.na.tibco .com>
References: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0BEB1@PA-MBX01.na.tibco.com>
	<CACk-te11CuSEeVJZoVMa_2c2g2rFMwwumfvpWOzoUXQdq8uyRg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0BF75@PA-MBX01.na.tibco.com>
Message-ID: <Zen-1VXWKW-000FMS-Vd@smarthost01d.mail.zen.net.uk>

At 19:05 18/10/2013, William Dunlap wrote:
> > However, I do not understand the
> >    substitute(...())
> > idiom. Would you care to explain it? (No is an acceptable  answer!).
>
>I don't completely understand it either, I treat it as an idiom.  I 
>saw it on this list once.
>
>Bill Dunlap
>Spotfire, TIBCO Software
>wdunlap tibco.com

Well it brightened up my day. Not sure whether that is sufficient or 
necessary for it to be a fortune.



> > -----Original Message-----
> > From: Bert Gunter [mailto:gunter.berton at gene.com]
> > Sent: Friday, October 18, 2013 10:54 AM
> > To: William Dunlap
> > Cc: Dan Abner; r-help at r-project.org
> > Subject: Re: [R] Recovering object names when using the ... 
> argument in a fn XXXX
> >
> > Yes, similar, but better, as match.call() will get unwanted named
> > arguments, too.
> >
> > However, I do not understand the
> >
> > substitute(...())
> >
> > idiom. Would you care to explain it? (No is an acceptable  answer!).
> >
> > I would have expressed it as:
> >
> > as.list(substitute(list(...)))[-1]
> >
> > to convert the parse tree to a list. (which is again better than using
> > match.call() ).
> >
> > Best,
> > Bert
> >
> > On Fri, Oct 18, 2013 at 10:27 AM, William Dunlap <wdunlap at tibco.com> wrote:
> > >> I am using the ... argument to parmeterize a user define fn to accept
> > >> multiple input objects. I subsquently save all these data as a list.
> > >> Question: what is the best way to recover or extract the original object
> > >> names that were fed to the fn?
> > >
> > > The following function, ellipsisInfo, returns character strings 
> representing the
> > > actual arguments to the function.  If the function was called 
> with tags on the
> > > arguments, as in ellipsisInfo(tag=argument), it makes those 
> tags the names
> > > on the returned character  vector.  It does not evaluate the 
> ... arguments, so
> > > you don't run into problems with evaluating arguments too soon 
> or evaluating
> > > ones that should not be evaluated most of the time.
> > >
> > > ellipsisInfo <- function(...) {
> > >     # get the unevaluated expressions given as arguments
> > >     unevaluatedArgs <- substitute(...())
> > >     # convert those expressions to text (truncate to single line)
> > >     unevaluatedArgsAsText <- vapply(unevaluatedArgs, 
> function(a)deparse(a)[1], "")
> > >     unevaluatedArgsAsText
> > > }
> > >
> > > E.g.,
> > >
> > >> i <- ellipsisInfo(x, log(10), e=exp(1), onProblem=stop("there 
> was a problem"))
> > >> i
> > >
> > >                             "x"
> > >
> > >                       "log(10)"
> > >                               e
> > >                        "exp(1)"
> > >                       onProblem
> > > "stop(\"there was a problem\")"
> > >> ifelse(names(i)=="", i, names(i)) # use tag if supplied, 
> otherwise argument itself
> > > [1] "x"         "log(10)"   "e"
> > > [4] "onProblem"
> > >
> > > Bill Dunlap
> > > Spotfire, TIBCO Software
> > > wdunlap tibco.com
> > >
> > >
> > >> -----Original Message-----
> > >> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On
> > Behalf
> > >> Of Dan Abner
> > >> Sent: Friday, October 18, 2013 9:06 AM
> > >> To: r-help at r-project.org
> > >> Subject: [R] Recovering object names when using the ... 
> argument in a fn XXXX
> > >>
> > >> Hi all,
> > >>
> > >> I am using the ... argument to parmeterize a user define fn to accept
> > >> multiple input objects. I subsquently save all these data as a list.
> > >> Question: what is the best way to recover or extract the original object
> > >> names that were fed to the fn?
> > >>
> > >> Thanks,
> > >>
> > >> Dan
> > >>
> > >>       [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> >
> > Bert Gunter
> > Genentech Nonclinical Biostatistics
> >
> > (650) 467-7374

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From dwinsemius at comcast.net  Sat Oct 19 15:20:35 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 19 Oct 2013 06:20:35 -0700
Subject: [R] fitting a random gamma sample into the weibull distribution
In-Reply-To: <CAAJc=rNn-JyR0fov_U=dAHBH-oAzqbPz8aQHCJwUvmPC3kQNCw@mail.gmail.com>
References: <CAAJc=rNn-JyR0fov_U=dAHBH-oAzqbPz8aQHCJwUvmPC3kQNCw@mail.gmail.com>
Message-ID: <82123576-08F4-4B48-9C95-8E8A3F38EFD4@comcast.net>


On Oct 19, 2013, at 2:26 AM, Charles Thuo wrote:

>> require(MASS)
>> n<- 100000
>> n
> [1] 1e+05
>> w<- rgamma(n,rate=0.5,shape=5);head(w)
> [1] 14.135679 18.839336  6.623502 17.165505  2.847572  7.511726
>> fit.w<- fitdistr(w,"weibull")
> Warning messages:
> 1: In densfun(x, parm[1], parm[2], ...) : NaNs produced
> 2: In densfun(x, parm[1], parm[2], ...) : NaNs produced
> 3: In densfun(x, parm[1], parm[2], ...) : NaNs produced
> 4: In densfun(x, parm[1], parm[2], ...) : NaNs produced
> 5: In densfun(x, parm[1], parm[2], ...) : NaNs produced
> 6: In densfun(x, parm[1], parm[2], ...) : NaNs produced
> 7: In densfun(x, parm[1], parm[2], ...) : NaNs produced
> 8: In densfun(x, parm[1], parm[2], ...) : NaNs produced
>
>> summary(fit.w)
>         Length Class  Mode
> estimate 2      -none- numeric
> sd       2      -none- numeric
> vcov     4      -none- numeric
> loglik   1      -none- numeric
> n        1      -none- numeric
>>
>
> I do not understand why the summary does not have the fitted  
> parameters.

methods(summary)

There is no summary.fitdistr function so you are just seeing  
summary.default's method of summarizing a list.

-- 

David Winsemius, MD
Alameda, CA, USA


From vincent.guyader at gmail.com  Sat Oct 19 15:22:09 2013
From: vincent.guyader at gmail.com (vincent guyader)
Date: Sat, 19 Oct 2013 15:22:09 +0200
Subject: [R] No P.values in polr summary
In-Reply-To: <52622817.5020805@stats.ox.ac.uk>
References: <CANCN_HSuEbJvGNo-XaAFPmPN_2A=WPJbahjC-Ms0JQKXWU_rBQ@mail.gmail.com>
	<52622817.5020805@stats.ox.ac.uk>
Message-ID: <CANCN_HRznj8b3M-HytOZFgmeJ9f8Tr2+ccuwH=J3voh16ioE5A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131019/962abe75/attachment.pl>

From Achim.Zeileis at uibk.ac.at  Sat Oct 19 15:39:50 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sat, 19 Oct 2013 15:39:50 +0200 (CEST)
Subject: [R] Fortune?,
 was Re: Recovering object names when using the ... argument in a fn
 XXXX
In-Reply-To: <Zen-1VXWKW-000FMS-Vd@smarthost01d.mail.zen.net.uk>
References: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0BEB1@PA-MBX01.na.tibco.com>
	<CACk-te11CuSEeVJZoVMa_2c2g2rFMwwumfvpWOzoUXQdq8uyRg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0BF75@PA-MBX01.na.tibco.com>
	<Zen-1VXWKW-000FMS-Vd@smarthost01d.mail.zen.net.uk>
Message-ID: <alpine.DEB.2.10.1310191539240.30421@paninaro.uibk.ac.at>

On Sat, 19 Oct 2013, Michael Dewey wrote:

> At 19:05 18/10/2013, William Dunlap wrote:
>> > However, I do not understand the
>> >    substitute(...())
>> > idiom. Would you care to explain it? (No is an acceptable  answer!).
>> 
>> I don't completely understand it either, I treat it as an idiom.  I saw it 
>> on this list once.
>> 
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>
> Well it brightened up my day. Not sure whether that is sufficient or 
> necessary for it to be a fortune.

It made me smile as well so I've added it to the package on R-Forge now 
:-)

Best,
Z

>
>
>> > -----Original Message-----
>> > From: Bert Gunter [mailto:gunter.berton at gene.com]
>> > Sent: Friday, October 18, 2013 10:54 AM
>> > To: William Dunlap
>> > Cc: Dan Abner; r-help at r-project.org
>> > Subject: Re: [R] Recovering object names when using the ... argument in a 
>> fn XXXX
>> >
>> > Yes, similar, but better, as match.call() will get unwanted named
>> > arguments, too.
>> >
>> > However, I do not understand the
>> >
>> > substitute(...())
>> >
>> > idiom. Would you care to explain it? (No is an acceptable  answer!).
>> >
>> > I would have expressed it as:
>> >
>> > as.list(substitute(list(...)))[-1]
>> >
>> > to convert the parse tree to a list. (which is again better than using
>> > match.call() ).
>> >
>> > Best,
>> > Bert
>> >
>> > On Fri, Oct 18, 2013 at 10:27 AM, William Dunlap <wdunlap at tibco.com> 
>> wrote:
>> > >> I am using the ... argument to parmeterize a user define fn to accept
>> > >> multiple input objects. I subsquently save all these data as a list.
>> > >> Question: what is the best way to recover or extract the original 
>> object
>> > >> names that were fed to the fn?
>> > >
>> > > The following function, ellipsisInfo, returns character strings 
>> representing the
>> > > actual arguments to the function.  If the function was called with tags 
>> on the
>> > > arguments, as in ellipsisInfo(tag=argument), it makes those tags the 
>> names
>> > > on the returned character  vector.  It does not evaluate the ... 
>> arguments, so
>> > > you don't run into problems with evaluating arguments too soon or 
>> evaluating
>> > > ones that should not be evaluated most of the time.
>> > >
>> > > ellipsisInfo <- function(...) {
>> > >     # get the unevaluated expressions given as arguments
>> > >     unevaluatedArgs <- substitute(...())
>> > >     # convert those expressions to text (truncate to single line)
>> > >     unevaluatedArgsAsText <- vapply(unevaluatedArgs, 
>> function(a)deparse(a)[1], "")
>> > >     unevaluatedArgsAsText
>> > > }
>> > >
>> > > E.g.,
>> > >
>> > >> i <- ellipsisInfo(x, log(10), e=exp(1), onProblem=stop("there was a 
>> problem"))
>> > >> i
>> > >
>> > >                             "x"
>> > >
>> > >                       "log(10)"
>> > >                               e
>> > >                        "exp(1)"
>> > >                       onProblem
>> > > "stop(\"there was a problem\")"
>> > >> ifelse(names(i)=="", i, names(i)) # use tag if supplied, otherwise 
>> argument itself
>> > > [1] "x"         "log(10)"   "e"
>> > > [4] "onProblem"
>> > >
>> > > Bill Dunlap
>> > > Spotfire, TIBCO Software
>> > > wdunlap tibco.com
>> > >
>> > >
>> > >> -----Original Message-----
>> > >> From: r-help-bounces at r-project.org 
>> [mailto:r-help-bounces at r-project.org] On
>> > Behalf
>> > >> Of Dan Abner
>> > >> Sent: Friday, October 18, 2013 9:06 AM
>> > >> To: r-help at r-project.org
>> > >> Subject: [R] Recovering object names when using the ... argument in a 
>> fn XXXX
>> > >>
>> > >> Hi all,
>> > >>
>> > >> I am using the ... argument to parmeterize a user define fn to accept
>> > >> multiple input objects. I subsquently save all these data as a list.
>> > >> Question: what is the best way to recover or extract the original 
>> object
>> > >> names that were fed to the fn?
>> > >>
>> > >> Thanks,
>> > >>
>> > >> Dan
>> > >>
>> > >>       [[alternative HTML version deleted]]
>> > >>
>> > >> ______________________________________________
>> > >> R-help at r-project.org mailing list
>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> > >> and provide commented, minimal, self-contained, reproducible code.
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>> > --
>> >
>> > Bert Gunter
>> > Genentech Nonclinical Biostatistics
>> >
>> > (650) 467-7374
>
> Michael Dewey
> info at aghmed.fsnet.co.uk
> http://www.aghmed.fsnet.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chrisege at stud.ntnu.no  Sat Oct 19 12:44:26 2013
From: chrisege at stud.ntnu.no (Chris89)
Date: Sat, 19 Oct 2013 03:44:26 -0700 (PDT)
Subject: [R] Extracting AICc and BIC from an ARIMA model.
Message-ID: <1382179466932-4678593.post@n4.nabble.com>

Hi everyone!

I am making some time series models, and as i want to compare a lot of
models I thought it would be smart to compare the AIC, AICc and BIC values
from the models. My question is, how can I extract the BIC and AICc from the
model?

As an example:

kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
mod = arima(kings, order = c(1,0,0), include.mean=T)

obviously summary(mod) would suffice, but I don't want to have to look
through all the models (as there are alot... )

Sincerly 
Chris



--
View this message in context: http://r.789695.n4.nabble.com/Extracting-AICc-and-BIC-from-an-ARIMA-model-tp4678593.html
Sent from the R help mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Sat Oct 19 19:03:25 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 19 Oct 2013 13:03:25 -0400
Subject: [R] Recovering object names when using the ... argument in a fn
 XXXX
In-Reply-To: <CACk-te11CuSEeVJZoVMa_2c2g2rFMwwumfvpWOzoUXQdq8uyRg@mail.gmail.com>
References: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>	<E66794E69CFDE04D9A70842786030B933FA0BEB1@PA-MBX01.na.tibco.com>
	<CACk-te11CuSEeVJZoVMa_2c2g2rFMwwumfvpWOzoUXQdq8uyRg@mail.gmail.com>
Message-ID: <5262BB5D.1090802@gmail.com>

On 13-10-18 1:54 PM, Bert Gunter wrote:
> Yes, similar, but better, as match.call() will get unwanted named
> arguments, too.
>
> However, I do not understand the
>
> substitute(...())
>
> idiom. Would you care to explain it? (No is an acceptable  answer!).

I suspect it's a bug, though I can't see it's one that's likely to need 
fixing.  The general idea is that a function call like ...() is parsed 
into a pairlist containing just the name "...", then substitute replaces 
it with the content of that variable, which is a pairlist containing the 
unevaluated argument list.  So by that analysis, you might expect to get 
the same result using

pairlist(...)

However, you don't, because the latter expression evaluates all the 
arguments to the function, while Bill's idiom leaves them unevaluated. 
I can't think of any documented reason why that should be, but on the 
other hand, I can't think of any reason it would cause problems.  So I'd 
say it's unlikely to be deliberately changed, but it might change as a 
result of some internal change to R.

Duncan Murdoch


>
> I would have expressed it as:
>
> as.list(substitute(list(...)))[-1]
>
> to convert the parse tree to a list. (which is again better than using
> match.call() ).
>
> Best,
> Bert
>
> On Fri, Oct 18, 2013 at 10:27 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>> I am using the ... argument to parmeterize a user define fn to accept
>>> multiple input objects. I subsquently save all these data as a list.
>>> Question: what is the best way to recover or extract the original object
>>> names that were fed to the fn?
>>
>> The following function, ellipsisInfo, returns character strings representing the
>> actual arguments to the function.  If the function was called with tags on the
>> arguments, as in ellipsisInfo(tag=argument), it makes those tags the names
>> on the returned character  vector.  It does not evaluate the ... arguments, so
>> you don't run into problems with evaluating arguments too soon or evaluating
>> ones that should not be evaluated most of the time.
>>
>> ellipsisInfo <- function(...) {
>>      # get the unevaluated expressions given as arguments
>>      unevaluatedArgs <- substitute(...())
>>      # convert those expressions to text (truncate to single line)
>>      unevaluatedArgsAsText <- vapply(unevaluatedArgs, function(a)deparse(a)[1], "")
>>      unevaluatedArgsAsText
>> }
>>
>> E.g.,
>>
>>> i <- ellipsisInfo(x, log(10), e=exp(1), onProblem=stop("there was a problem"))
>>> i
>>
>>                              "x"
>>
>>                        "log(10)"
>>                                e
>>                         "exp(1)"
>>                        onProblem
>> "stop(\"there was a problem\")"
>>> ifelse(names(i)=="", i, names(i)) # use tag if supplied, otherwise argument itself
>> [1] "x"         "log(10)"   "e"
>> [4] "onProblem"
>>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>>
>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>>> Of Dan Abner
>>> Sent: Friday, October 18, 2013 9:06 AM
>>> To: r-help at r-project.org
>>> Subject: [R] Recovering object names when using the ... argument in a fn XXXX
>>>
>>> Hi all,
>>>
>>> I am using the ... argument to parmeterize a user define fn to accept
>>> multiple input objects. I subsquently save all these data as a list.
>>> Question: what is the best way to recover or extract the original object
>>> names that were fed to the fn?
>>>
>>> Thanks,
>>>
>>> Dan
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From dwinsemius at comcast.net  Sat Oct 19 19:32:40 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 19 Oct 2013 10:32:40 -0700
Subject: [R] Extracting AICc and BIC from an ARIMA model.
In-Reply-To: <1382179466932-4678593.post@n4.nabble.com>
References: <1382179466932-4678593.post@n4.nabble.com>
Message-ID: <0D6507BF-C776-459A-A6D6-8EBFFFC2C7D9@comcast.net>


On Oct 19, 2013, at 3:44 AM, Chris89 wrote:

> Hi everyone!
> 
> I am making some time series models, and as i want to compare a lot of
> models I thought it would be smart to compare the AIC, AICc and BIC values
> from the models. My question is, how can I extract the BIC and AICc from the
> model?
> 
> As an example:
> 
> kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
> mod = arima(kings, order = c(1,0,0), include.mean=T)
> 
> obviously summary(mod) would suffice,

How would that "obviously" suffice? There is no summary.Arima function, at least that I see. (Maybe you have loaded an additonal package that you were asked to tell us about?)


> but I don't want to have to look
> through all the models (as there are alot... )

The models already have an "aic" element:

> modList <-list(mod,mod2);  sapply(modList, "[", "aic")
$aic
[1] 352.8227

$aic
[1] 352.8227

(Please read the Fine Posting Guide.)

-- 

David Winsemius
Alameda, CA, USA


From lmramba at ufl.edu  Sat Oct 19 19:41:00 2013
From: lmramba at ufl.edu (laz)
Date: Sat, 19 Oct 2013 13:41:00 -0400
Subject: [R] loop not working my way
Message-ID: <5262C42C.4080706@ufl.edu>

Dear R users,

Suppose I want to randomly generate some data, in matrix form, randomly 
swap some of the elements and calculate trace of the matrix for each of 
these stages. If the value of trace obtained in the later is bigger than 
the former, drop the latter matrix and go back to the former matrix, 
swap some elements of the matrix again and calculate the trace. If the 
recent trace is smaller than the previous one, accept the matrix as the 
current .  Use the current matrix  and swap elements again. repeat the 
whole process for a number of times, say, 10. The output from the 
function should display only the original matrix and its value of trace, 
trace values of successful swaps and their iteration counts and the 
final best matrix that had the smallest value of trace, together with 
its trace value.

For example
## original
 > matd<-matrix(sample(1:30,30,replace=FALSE),ncol=5,nrow=6,byrow=FALSE)
 > matd
      [,1] [,2] [,3] [,4] [,5]
[1,]   12   27   29   16   19
[2,]   25   10    7   22   13
[3,]   14   23    3   11   21
[4,]   28    6    5    2   18
[5,]   24   20    1   17   26
[6,]    9    4   30    8   15
 > trace<-sum(diag(matd))
 > trace
[1] 53

#  1st iteration

      [,1] [,2] [,3] [,4] [,5]
[1,]   24   29   20   25   17
[2,]   16    1   30    9    5
[3,]   18   22    2   10   26
[4,]   23   27   19   21   28
[5,]   15    6    8    3   13
[6,]   12   14    7   11    4
 > trace<-sum(diag(matd))
 > trace
[1] 61

## drop this matrix because 61 >  53

#  2nd iteration
 > matd<-matrix(sample(1:30,30,replace=FALSE),ncol=5,nrow=6,byrow=FALSE)
 > matd
      [,1] [,2] [,3] [,4] [,5]
[1,]    2   28   23   15   14
[2,]   27    9   10   29    7
[3,]    5   18   12    1   11
[4,]    8    4   30   16   24
[5,]   25   19   26    6   13
[6,]   17   22    3   20   21
 > trace<-sum(diag(matd))
 > trace
[1] 52

## accept this matrix because 52 < 53

### 3rd iteration
 > matd<-matrix(sample(1:30,30,replace=FALSE),ncol=5,nrow=6,byrow=FALSE)
 > matd
      [,1] [,2] [,3] [,4] [,5]
[1,]    1   29   17    8    6
[2,]   21   23   10    7   14
[3,]   22    4   12   26    9
[4,]    3   13   11   30   15
[5,]    5   24   18   16    2
[6,]   20   25   19   27   28
 > trace<-sum(diag(matd))
 > trace
[1] 68

## drop this matrix because 68 > 52

##  4th  iteration
 > matd<-matrix(sample(1:30,30,replace=FALSE),ncol=5,nrow=6,byrow=FALSE)
 > matd
      [,1] [,2] [,3] [,4] [,5]
[1,]    2    6    5   28   15
[2,]    9   12   13   19   24
[3,]    3   22   14   11   29
[4,]   30   20   17    7   23
[5,]   18   27   21    1   10
[6,]   25   16    4    8   26
 > trace<-sum(diag(matd))
 > trace
[1] 45

## accept this matrix because 45 < 52

The final results will be:
$mat
         trace    iterations
[1,]       53        0
[2,]       52        2
[3,]       45        4

$ Design_best

   [,1] [,2] [,3] [,4] [,5]
[1,]    2    6    5   28   15
[2,]    9   12   13   19   24
[3,]    3   22   14   11   29
[4,]   30   20   17    7   23
[5,]   18   27   21    1   10
[6,]   25   16    4    8   26

$ Original_design

   [,1] [,2] [,3] [,4] [,5]
[1,]   12   27   29   16   19
[2,]   25   10    7   22   13
[3,]   14   23    3   11   21
[4,]   28    6    5    2   18
[5,]   24   20    1   17   26
[6,]    9    4   30    8   15

Regards,
Laz


From dwinsemius at comcast.net  Sat Oct 19 20:07:09 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 19 Oct 2013 11:07:09 -0700
Subject: [R] Extracting AICc and BIC from an ARIMA model.
In-Reply-To: <0D6507BF-C776-459A-A6D6-8EBFFFC2C7D9@comcast.net>
References: <1382179466932-4678593.post@n4.nabble.com>
	<0D6507BF-C776-459A-A6D6-8EBFFFC2C7D9@comcast.net>
Message-ID: <A4953848-02DB-44C2-B138-C2B9DCB080B2@comcast.net>


On Oct 19, 2013, at 10:32 AM, David Winsemius wrote:

> 
> On Oct 19, 2013, at 3:44 AM, Chris89 wrote:
> 
>> Hi everyone!
>> 
>> I am making some time series models, and as i want to compare a lot of
>> models I thought it would be smart to compare the AIC, AICc and BIC values
>> from the models. My question is, how can I extract the BIC and AICc from the
>> model?
>> 
>> As an example:
>> 
>> kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
>> mod = arima(kings, order = c(1,0,0), include.mean=T)
>> 
>> obviously summary(mod) would suffice,
> 
> How would that "obviously" suffice? There is no summary.Arima function, at least that I see. (Maybe you have loaded an additonal package that you were asked to tell us about?)
> 
> 
>> but I don't want to have to look
>> through all the models (as there are alot... )
> 
> The models already have an "aic" element:
> 
>> modList <-list(mod,mod2);  sapply(modList, "[", "aic")
> $aic
> [1] 352.8227
> 
> $aic
> [1] 352.8227
> 
> (Please read the Fine Posting Guide.)

I evemtually did find an hidden and undocumented `summary.Arima` function in the 'forecast' package, but most (all?) of its output was via side-effects. It also appeared that it initially called another hidden function `print.Arima` also using side-effects rather than retruning an object.

library(forecast)
forecast:::print.Arima

The code may be useful if you want to make a parred-down version that spits out AIC, BIC, AICc.


> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Sat Oct 19 22:44:05 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 19 Oct 2013 21:44:05 +0100
Subject: [R] Extracting AICc and BIC from an ARIMA model.
In-Reply-To: <A4953848-02DB-44C2-B138-C2B9DCB080B2@comcast.net>
References: <1382179466932-4678593.post@n4.nabble.com>	<0D6507BF-C776-459A-A6D6-8EBFFFC2C7D9@comcast.net>
	<A4953848-02DB-44C2-B138-C2B9DCB080B2@comcast.net>
Message-ID: <5262EF15.7050002@sapo.pt>

Hello,



Em 19-10-2013 19:07, David Winsemius escreveu:
>
> On Oct 19, 2013, at 10:32 AM, David Winsemius wrote:
>
>>
>> On Oct 19, 2013, at 3:44 AM, Chris89 wrote:
>>
>>> Hi everyone!
>>>
>>> I am making some time series models, and as i want to compare a lot of
>>> models I thought it would be smart to compare the AIC, AICc and BIC values
>>> from the models. My question is, how can I extract the BIC and AICc from the
>>> model?
>>>
>>> As an example:
>>>
>>> kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
>>> mod = arima(kings, order = c(1,0,0), include.mean=T)
>>>
>>> obviously summary(mod) would suffice,
>>
>> How would that "obviously" suffice? There is no summary.Arima function, at least that I see. (Maybe you have loaded an additonal package that you were asked to tell us about?)
>>
>>
>>> but I don't want to have to look
>>> through all the models (as there are alot... )
>>
>> The models already have an "aic" element:
>>
>>> modList <-list(mod,mod2);  sapply(modList, "[", "aic")
>> $aic
>> [1] 352.8227
>>
>> $aic
>> [1] 352.8227
>>
>> (Please read the Fine Posting Guide.)
>
> I evemtually did find an hidden and undocumented `summary.Arima` function in the 'forecast' package, but most (all?) of its output was via side-effects. It also appeared that it initially called another hidden function `print.Arima` also using side-effects rather than retruning an object.
>
> library(forecast)
> forecast:::print.Arima
>
> The code may be useful if you want to make a parred-down version that spits out AIC, BIC, AICc.

As for AIC, there's an AIC method for objects of class Arima. Using the 
example data and model given by the op,

AIC(mod)
[1] 352.8227

or maybe

lapply(modList, AIC)


Hope this helps,

Rui Barradas
>
>
>>
>> --
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Sat Oct 19 23:03:08 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 19 Oct 2013 22:03:08 +0100
Subject: [R] loop not working my way
In-Reply-To: <5262C42C.4080706@ufl.edu>
References: <5262C42C.4080706@ufl.edu>
Message-ID: <5262F38C.1000002@sapo.pt>

Hello,

Seems simple.


fun <- function(n = 10){
	matd <- matrix(sample(1:30,30, replace=FALSE), ncol=5, nrow=6)
	res <- list(mat = NULL, Design_best = matd, Original_design = matd)
	trace <- sum(diag(matd))
	res$mat <- rbind(res$mat, c(trace = trace, iterations = 0))
	for(i in seq_len(n)){
		matd <- matrix(sample(1:30,30, replace=FALSE), ncol=5, nrow=6)
		if(sum(diag(matd)) < trace){
			trace <- sum(diag(matd))
			res$mat <- rbind(res$mat, c(trace = trace, iterations = i))
			res$Design_best <- matd
		}
	}
	res
}

fun()
fun(20)


Hope this helps,

Rui Barradas

Em 19-10-2013 18:41, laz escreveu:
> Dear R users,
>
> Suppose I want to randomly generate some data, in matrix form, randomly
> swap some of the elements and calculate trace of the matrix for each of
> these stages. If the value of trace obtained in the later is bigger than
> the former, drop the latter matrix and go back to the former matrix,
> swap some elements of the matrix again and calculate the trace. If the
> recent trace is smaller than the previous one, accept the matrix as the
> current .  Use the current matrix  and swap elements again. repeat the
> whole process for a number of times, say, 10. The output from the
> function should display only the original matrix and its value of trace,
> trace values of successful swaps and their iteration counts and the
> final best matrix that had the smallest value of trace, together with
> its trace value.
>
> For example
> ## original
>  > matd<-matrix(sample(1:30,30,replace=FALSE),ncol=5,nrow=6,byrow=FALSE)
>  > matd
>       [,1] [,2] [,3] [,4] [,5]
> [1,]   12   27   29   16   19
> [2,]   25   10    7   22   13
> [3,]   14   23    3   11   21
> [4,]   28    6    5    2   18
> [5,]   24   20    1   17   26
> [6,]    9    4   30    8   15
>  > trace<-sum(diag(matd))
>  > trace
> [1] 53
>
> #  1st iteration
>
>       [,1] [,2] [,3] [,4] [,5]
> [1,]   24   29   20   25   17
> [2,]   16    1   30    9    5
> [3,]   18   22    2   10   26
> [4,]   23   27   19   21   28
> [5,]   15    6    8    3   13
> [6,]   12   14    7   11    4
>  > trace<-sum(diag(matd))
>  > trace
> [1] 61
>
> ## drop this matrix because 61 >  53
>
> #  2nd iteration
>  > matd<-matrix(sample(1:30,30,replace=FALSE),ncol=5,nrow=6,byrow=FALSE)
>  > matd
>       [,1] [,2] [,3] [,4] [,5]
> [1,]    2   28   23   15   14
> [2,]   27    9   10   29    7
> [3,]    5   18   12    1   11
> [4,]    8    4   30   16   24
> [5,]   25   19   26    6   13
> [6,]   17   22    3   20   21
>  > trace<-sum(diag(matd))
>  > trace
> [1] 52
>
> ## accept this matrix because 52 < 53
>
> ### 3rd iteration
>  > matd<-matrix(sample(1:30,30,replace=FALSE),ncol=5,nrow=6,byrow=FALSE)
>  > matd
>       [,1] [,2] [,3] [,4] [,5]
> [1,]    1   29   17    8    6
> [2,]   21   23   10    7   14
> [3,]   22    4   12   26    9
> [4,]    3   13   11   30   15
> [5,]    5   24   18   16    2
> [6,]   20   25   19   27   28
>  > trace<-sum(diag(matd))
>  > trace
> [1] 68
>
> ## drop this matrix because 68 > 52
>
> ##  4th  iteration
>  > matd<-matrix(sample(1:30,30,replace=FALSE),ncol=5,nrow=6,byrow=FALSE)
>  > matd
>       [,1] [,2] [,3] [,4] [,5]
> [1,]    2    6    5   28   15
> [2,]    9   12   13   19   24
> [3,]    3   22   14   11   29
> [4,]   30   20   17    7   23
> [5,]   18   27   21    1   10
> [6,]   25   16    4    8   26
>  > trace<-sum(diag(matd))
>  > trace
> [1] 45
>
> ## accept this matrix because 45 < 52
>
> The final results will be:
> $mat
>          trace    iterations
> [1,]       53        0
> [2,]       52        2
> [3,]       45        4
>
> $ Design_best
>
>    [,1] [,2] [,3] [,4] [,5]
> [1,]    2    6    5   28   15
> [2,]    9   12   13   19   24
> [3,]    3   22   14   11   29
> [4,]   30   20   17    7   23
> [5,]   18   27   21    1   10
> [6,]   25   16    4    8   26
>
> $ Original_design
>
>    [,1] [,2] [,3] [,4] [,5]
> [1,]   12   27   29   16   19
> [2,]   25   10    7   22   13
> [3,]   14   23    3   11   21
> [4,]   28    6    5    2   18
> [5,]   24   20    1   17   26
> [6,]    9    4   30    8   15
>
> Regards,
> Laz
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tal.galili at gmail.com  Sat Oct 19 23:04:20 2013
From: tal.galili at gmail.com (Tal Galili)
Date: Sat, 19 Oct 2013 23:04:20 +0200
Subject: [R] No P.values in polr summary
In-Reply-To: <CANCN_HRznj8b3M-HytOZFgmeJ9f8Tr2+ccuwH=J3voh16ioE5A@mail.gmail.com>
References: <CANCN_HSuEbJvGNo-XaAFPmPN_2A=WPJbahjC-Ms0JQKXWU_rBQ@mail.gmail.com>
	<52622817.5020805@stats.ox.ac.uk>
	<CANCN_HRznj8b3M-HytOZFgmeJ9f8Tr2+ccuwH=J3voh16ioE5A@mail.gmail.com>
Message-ID: <CANdJ3dX1ZkrRFSJA7_5r1F7R++tQsd1wzy=pdnmMAMq-Fubhwg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131019/6ded1b6d/attachment.pl>

From lmramba at ufl.edu  Sat Oct 19 23:09:39 2013
From: lmramba at ufl.edu (Laz)
Date: Sat, 19 Oct 2013 17:09:39 -0400
Subject: [R] loop not working my way
In-Reply-To: <5262F38C.1000002@sapo.pt>
References: <5262C42C.4080706@ufl.edu> <5262F38C.1000002@sapo.pt>
Message-ID: <5262F513.1070307@ufl.edu>

Thank you so very much!
It works like a charm !!!

Regards,
Laz

On 10/19/2013 5:03 PM, Rui Barradas wrote:
> fun <- function(n = 10){
>     matd <- matrix(sample(1:30,30, replace=FALSE), ncol=5, nrow=6)
>     res <- list(mat = NULL, Design_best = matd, Original_design = matd)
>     trace <- sum(diag(matd))
>     res$mat <- rbind(res$mat, c(trace = trace, iterations = 0))
>     for(i in seq_len(n)){
>         matd <- matrix(sample(1:30,30, replace=FALSE), ncol=5, nrow=6)
>         if(sum(diag(matd)) < trace){
>             trace <- sum(diag(matd))
>             res$mat <- rbind(res$mat, c(trace = trace, iterations = i))
>             res$Design_best <- matd
>         }
>     }
>     res
> }
>
> fun()
> fun(20)


From eliza_botto at hotmail.com  Sat Oct 19 23:27:04 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Sat, 19 Oct 2013 21:27:04 +0000
Subject: [R] blod dot size and name in plot
Message-ID: <BLU170-W1143E1828B49B724A0A73C089070@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131019/4b554d9e/attachment.pl>

From eliza_botto at hotmail.com  Sat Oct 19 23:29:19 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Sat, 19 Oct 2013 21:29:19 +0000
Subject: [R] bold dot size and name in plot
Message-ID: <BLU170-W1003E188F13E7E734C92E3089070@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131019/33156be7/attachment.pl>

From gunter.berton at gene.com  Sun Oct 20 00:14:48 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 19 Oct 2013 15:14:48 -0700
Subject: [R] bold dot size and name in plot
In-Reply-To: <BLU170-W1003E188F13E7E734C92E3089070@phx.gbl>
References: <BLU170-W1003E188F13E7E734C92E3089070@phx.gbl>
Message-ID: <CACk-te1-JjdjQxv=Ud7c6mYJ_NpdU8Fa5VPFvFQs5wTR7aK4UQ@mail.gmail.com>

Follow the posting guide!  Code code code.

(What you call a "dotplot" I think is what most of us call a
scatterplot. And there are many ways of doing this in R and packages,
and we have no idea what you used.)

Cheers,

Bert

On Sat, Oct 19, 2013 at 2:29 PM, eliza botto <eliza_botto at hotmail.com> wrote:
> Dear useRs,
>
> I have the following data "z" of two variables "x"(z[,1]) and "y"(z[,2]).
>
>> dput(z)
>
> structure(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 4.36222673881464, 3.69969030080286, 4.2171385106796, 3.13216766340978, 4.48272959444564, 5.15902588302327, 5.48017158746089, 4.27937198622481, 6.87798628712867, 10.6244257045475, 4.28697206373731, 2.36185506591713, 3.8999910824793, 3.53659639173799, 3.55002661079475, 1.69933515030185, 3.05902585757021, 7.36381894775327, 7.40245656365444, 3.6848569064997, 6.08996204878611, 6.28326065486612, 3.94011667392145, 4.32959623927668, 4.53659549630782, 10.5471767576564, !
>  3.25988629354992, 4.09457312472741, 3.80883550148271, 3.31050022622877, 4.97298874506525, 4.44111508385058, 8.07706784555988, 4.82859189180109, 4.28049047919568, 4.02054752142086, 4.45446182299703, 2.88902557744596, 4.17698124193575, 6.31474248231764, 2.68657606391183, 3.75708892669439, 4.70294050809375, 6.35750639997654, 5.66591712203293, 5.1676226656419, 6.36111068522507, 5.0746871785069, 3.74549388607439, 10.0499160660981, 2.73392821921647, 7.5468698295455, 3.63310870671515, 4.73756281172226, 3.12831980852897, 5.92478381773712, 3.97278768529811, 4.43603447353224, 3.22165005512334, 2.64048226457915, 4.82170867550029, 3.88802663642624, 6.28071352879497, 7.1898792291212, 3.45069580057411, 2.11874855961612, 6.83308998981622, 4.88594913751698, 7.2043715042717, 5.92944522632847, 5.28125713924232, 2.92406012836832, 5.51193983406794, 3.92034936881849, 4.02863562948636, 2.63086007943162, 2.29816871384959, 5.43277606496536, 2.748057506715, 2.98832890910102, 3.86750736412989, 10.02!
>  51585616053, 2.4508507570229, 5.15539283003769, 4.92251312085952, 3.75
> 60826804466, 3.55555381750724, 3.80501827417895, 6.9500408077286, 5.63753820219307, 4.34417512875296, 2.38134080759689, 6.02021367624557, 7.61923679606813, 4.2639565075926, 5.19690782449524, 2.77914619706371, 2.80469912067042, 2.5030368187632, 3.66180330645551, 4.73586073723542, 4.03431276216711, 2.65910091882713, 2.83278553692168, 7.41646908081112, 1.87620181096256, 1.51781201506458, 1.92751580314289, 2.43506169436137, 1.88641686599088, 4.49013870147502, 2.15361460668737, 3.46482799242971, 2.69942251292495, 5.49300237653247, 3.34643344573202, 4.094064955793, 8.96571331963092, 2.22907411871184, 4.38143383339268, 6.52622723104758, 3.96979373172918, 5.52311167411852, 7.12115478587954), .Dim = c(124L, 2L), .Dimnames = list(c("1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2"!
>  , "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2"), NULL))
>
> I made a dot plot between them. what i want to do is to bold the size of dots,compared to that of others, for the following ranges
> -------80<x<100 and 2<y<4
>
> -------40<x<60 and 8<y<10
>
> -------100<x<120 and 6<y<8
>
> Then, i also want to draw square around those dots falling in these ranges and finally naming the areas with alphabets A, B and C.
>
> Is there a way of doing it?
>
> Thanks in advance
>
> Eliza
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From lmramba at ufl.edu  Sun Oct 20 00:25:59 2013
From: lmramba at ufl.edu (Laz)
Date: Sat, 19 Oct 2013 18:25:59 -0400
Subject: [R] loop not working my way
In-Reply-To: <5262F513.1070307@ufl.edu>
References: <5262C42C.4080706@ufl.edu> <5262F38C.1000002@sapo.pt>
	<5262F513.1070307@ufl.edu>
Message-ID: <526306F7.5020906@ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131019/a9df0567/attachment.pl>

From lmramba at ufl.edu  Sun Oct 20 00:38:40 2013
From: lmramba at ufl.edu (Laz)
Date: Sat, 19 Oct 2013 18:38:40 -0400
Subject: [R] loop not working my way
In-Reply-To: <5262F38C.1000002@sapo.pt>
References: <5262C42C.4080706@ufl.edu> <5262F38C.1000002@sapo.pt>
Message-ID: <526309F0.9020106@ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131019/5fd2d730/attachment.pl>

From smartpink111 at yahoo.com  Sat Oct 19 17:27:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 19 Oct 2013 08:27:24 -0700 (PDT)
Subject: [R] read table and import of a text file
In-Reply-To: <CAAC1QdDbgZapbeaexUyyREJkAmvT+QrQfaVN2jiZ_pPj-yixKA@mail.gmail.com>
References: <13058161.79387.1382149825353.JavaMail.nabble@joe.nabble.com>
	<CAAC1QdDbgZapbeaexUyyREJkAmvT+QrQfaVN2jiZ_pPj-yixKA@mail.gmail.com>
Message-ID: <1382196444.96678.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
No problem.



dat1 <- subset(head(read.table("temp1.txt",skip=6,sep=",",header=FALSE,fill=TRUE,stringsAsFactors=FALSE),-1),select=1:4)
?dat1$V1 <- as.numeric(dat1$V1)
?str(dat1)
#'data.frame':??? 96409 obs. of? 4 variables:
# $ V1: num? 891231 900101 900101 900101 900101 ...
# $ V2: int? 2400 100 200 300 400 500 600 700 800 900 ...
# $ V3: num? -1.5 -1.4 -1.6 -1.7 -2.1 -2.3 -2.4 -2.5 -2.6 -2.8 ...
# $ V4: num? -0.21 -0.25 -0.28 -0.25 -0.1 ...
?head(dat1)
#????? V1?? V2?? V3???????? V4
#1 891231 2400 -1.5 -0.2100000
#2 900101? 100 -1.4 -0.2500000
#3 900101? 200 -1.6 -0.2800000
#4 900101? 300 -1.7 -0.2500000
#5 900101? 400 -2.1 -0.0999999
#6 900101? 500 -2.3 -0.0899999
?tail(dat1,2)
#??????? V1?? V2???? V3??? V4
#96408 1230 2300 -1.215 1.308
#96409 1230 2400 -1.485 0.377
A.K.




On Saturday, October 19, 2013 7:17 AM, Kumar Raj <pollaroid at gmail.com> wrote:

Hi ,

Thanks for your effort. Now your new code works for the sample data. The earlier one did not work for sample and whole data set. I have attached part of the real data as it is publicly available . As you could see in the data EOF and all other information in the header is downloaded as part of the data.

Thanks



On 19 October 2013 04:30, <smartpink111 at yahoo.com> wrote:

Hi,
>If the data starts on the lines as you described, I am not sure why you have EOF and all the other things. ?It is confusing. ?Anyway, it is not clear what you meant by it doesn't work. ?Is it on the full dataset or on the sample set I showed? ?It worked for me. ?I can check your dataset or a sample of the data in its original .txt format if you can email me.
>
>Regards.
>
>
><quote author='Anuma'>
>Thanks, but the code does not work. ?I received an error like this one "
>Error in read.table(text = gsub("#|,$", "", temp[grepl(",", temp)][-1]), ?:
>? duplicate 'row.names' are not allowed".
>
>In the sample data that I have pasted on this page the data has four columns
>and it starts at the following line "891231, 2400, -1.5, -0.21, ". ?Anything
>before that is uninteresting for me.
></quote>
>Quoted from:
>http://r.789695.n4.nabble.com/read-table-and-import-of-a-text-file-tp4678525p4678571.html
>
>
>_____________________________________
>Sent from http://r.789695.n4.nabble.com
>
>


From ekbrown at k-state.edu  Sat Oct 19 19:51:59 2013
From: ekbrown at k-state.edu (Earl Brown)
Date: Sat, 19 Oct 2013 13:51:59 -0400 (EDT)
Subject: [R] saveXML() prefix argument
In-Reply-To: <5261D0E0.1010408@ucdavis.edu>
Message-ID: <805795809.1223716.1382205119546.JavaMail.root@k-state.edu>

Duncan, like what happens with Milan, when I print to the console both the accents and the indents come through correctly. However, when I save to a file, the indents disappear:

# when saved to a file the indents disappear
> saveXML(doc, file = "test.xml", encoding = "UTF-8")

# contents of text.xml
<?xml version="1.0" encoding="UTF-8"?>
<tips><tip id="1"><h1>espa?ol</h1><p>info about espa?ol</p></tip><tip id="2"><h1>portugu?s</h1><p>info about portugu?s</p></tip></tips>

# correctly prints to console
> saveXML(doc, encoding = "UTF-8")
[1] "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<tips>\n  <tip id=\"1\">\n    <h1>espa?ol</h1>\n    <p>info about espa?ol</p>\n  </tip>\n  <tip id=\"2\">\n    <h1>portugu?s</h1>\n    <p>info about portugu?s</p>\n  </tip>\n</tips>\n"

Here's the info you requested:

> libxmlVersion()
$major
[1] "2"

$minor
[1] "07"

$patch
[1] "03"

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] XML_3.95-0.2

loaded via a namespace (and not attached):
[1] tools_3.0.2

Thanks for the help. Earl Brown


----- Mensaje original -----
De: "Duncan Temple Lang" <dtemplelang at ucdavis.edu>
Para: "Earl Brown" <ekbrown at k-state.edu>
CC: r-help at r-project.org
Enviados: Viernes, 18 de Octubre 2013 19:22:56
Asunto: Re: saveXML() prefix argument

Hi Earl

Unfortunately, the code works for me, i.e. indents _and_ displays the accented vowels correctly.

Can you send me the output of the function call

 libxmlVersion()

and also sessionInfo(), please?

 D.

On 10/18/13 10:27 AM, Earl Brown wrote:
> Thanks Duncan. However, now I can't get the Spanish and Portuguese accented vowels to come out correctly and still keep the indents in the saved document, even when I set encoding = "UTF-8":
> 
> library("XML")
> concepts <- c("espa?ol", "portugu?s")
> info <- c("info about espa?ol", "info about portugu?s")
> 
> doc <- newXMLDoc()
> root <- newXMLNode("tips", doc = doc)
> for (i in 1:length(concepts)) {
> 	cur.concept <- concepts[i]
> 	cur.info <- info[i]
> 	cur.tip <- newXMLNode("tip", attrs = c(id = i), parent = root)
> 	newXMLNode("h1", cur.concept, parent = cur.tip)
> 	newXMLNode("p", cur.info, parent = cur.tip)
> }
> 
> # accented vowels don't come through correctly, but the indents are correct:
> saveXML(doc, file = "test1.xml", indent = T)
> 
> Resulting file looks like this:
> <?xml version="1.0"?>
> <tips>
>   <tip id="1">
>     <h1>espa&#xF1;ol</h1>
>     <p>info about espa&#xF1;ol</p>
>   </tip>
>   <tip id="2">
>     <h1>portugu&#xEA;s</h1>
>     <p>info about portugu&#xEA;s</p>
>   </tip>
> </tips>
> 
> # accented vowels are correct, but the indents are no longer correct:
> saveXML(doc, file = "test2.xml", indent = T, encoding = "UTF-8")
> 
> Resulting file:
> <?xml version="1.0" encoding="UTF-8"?>
> <tips><tip id="1"><h1>espa?ol</h1><p>info about espa?ol</p></tip><tip id="2"><h1>portugu?s</h1><p>info about portugu?s</p></tip></tips>
> 
> I tried to workaround the problem by simply loading in that resulting file and saving it again:
> doc2 <- xmlInternalTreeParse(file = "test2.xml", asTree = T)
> saveXML(doc2, file = "test_word_around.xml", indent = T)
> 
> but still don't get the indents.
> 
> Does setting encoding = "UTF-8" override indents = TRUE in saveXML()?
> 
> Thanks. Earl
> 
> 
> 


From randolph_steven_d at lilly.com  Sat Oct 19 21:47:03 2013
From: randolph_steven_d at lilly.com (Steven Dwayne Randolph)
Date: Sat, 19 Oct 2013 19:47:03 +0000
Subject: [R] XML package not working
Message-ID: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131019/04c00664/attachment.pl>

From randolph_steven_d at lilly.com  Sat Oct 19 21:51:42 2013
From: randolph_steven_d at lilly.com (Steven Dwayne Randolph)
Date: Sat, 19 Oct 2013 19:51:42 +0000
Subject: [R] 'XML' package cannot be un-zipped or un-tar'd"
In-Reply-To: <524B2F20.70600@xtra.co.nz>
References: <66C71547284587479F8009E05C07DA9704F6FF71@USTLMLLYC107.RF.lilly.com>
	<524B2F20.70600@xtra.co.nz>
Message-ID: <66C71547284587479F8009E05C07DA9704F8A095@USTLMLLYC107.RF.lilly.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131019/201202ce/attachment.pl>

From jim at bitwrit.com.au  Sun Oct 20 01:55:05 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 20 Oct 2013 10:55:05 +1100
Subject: [R] bold dot size and name in plot
In-Reply-To: <BLU170-W1003E188F13E7E734C92E3089070@phx.gbl>
References: <BLU170-W1003E188F13E7E734C92E3089070@phx.gbl>
Message-ID: <52631BD9.4030204@bitwrit.com.au>

On 10/20/2013 08:29 AM, eliza botto wrote:
> Dear useRs,
> ...
>
> I made a dot plot between them. what i want to do is to bold the size of dots,compared to that of others, for the following ranges
> -------80<x<100 and 2<y<4
>
> -------40<x<60 and 8<y<10
>
> -------100<x<120 and 6<y<8
>
> Then, i also want to draw square around those dots falling in these ranges and finally naming the areas with alphabets A, B and C.
>
> Is there a way of doing it?
>
Hi Eliza,
Your data was a bit corrupted, but try this:

z1<-cbind(z,rep(1,124))
z1[z1[,1]>80 & z1[,1]<100 & z1[,2]>2 & z1[,2]<4,3]<-2
z1[z1[,1]>40 & z1[,1]<60 & z1[,2]>8 & z1[,2]<10,3]<-2
z1[z1[,1]>100 & z1[,1]<120 & z1[,2]>6 & z1[,2]<8,3]<-2
plot(z1[,1],z1[,2],cex=z1[,3])
rect(80,2,100,4)
rect(40,8,60,10)
rect(100,6,120,8)
text(c(90,50,110),c(3,9,7),LETTERS[1:3])

Jim


From eliza_botto at hotmail.com  Sun Oct 20 02:00:10 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Sun, 20 Oct 2013 00:00:10 +0000
Subject: [R] bold dot size and name in plot
In-Reply-To: <52631BD9.4030204@bitwrit.com.au>
References: <BLU170-W1003E188F13E7E734C92E3089070@phx.gbl>,
	<52631BD9.4030204@bitwrit.com.au>
Message-ID: <BLU170-W626F9426583A12AF290E6489000@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131020/09b2c878/attachment.pl>

From murdoch.duncan at gmail.com  Sun Oct 20 02:23:07 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 19 Oct 2013 20:23:07 -0400
Subject: [R] XML package not working
In-Reply-To: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>
References: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>
Message-ID: <5263226B.7070103@gmail.com>

On 13-10-19 3:47 PM, Steven Dwayne Randolph wrote:
> I know I  cannot be the only one who is not able to install the XML package from CRAN (zip or tar file)  Many packages depend on this XML package.  Can someone help me either access the source for a good binary?  I have received no assistance from the author/developer of the package.

It installs fine for me.

Duncan Murdoch


From istazahn at gmail.com  Sun Oct 20 03:29:40 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 19 Oct 2013 21:29:40 -0400
Subject: [R] XML package not working
In-Reply-To: <5263226B.7070103@gmail.com>
References: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>
	<5263226B.7070103@gmail.com>
Message-ID: <CA+vqiLGLfSC5mE6j=bEiPTV2Z_ub4gG0QexmERMtNwJfvdKZYA@mail.gmail.com>

On Sat, Oct 19, 2013 at 8:23 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13-10-19 3:47 PM, Steven Dwayne Randolph wrote:
>>
>> I know I  cannot be the only one who is not able to install the XML
>> package from CRAN (zip or tar file)  Many packages depend on this XML
>> package.  Can someone help me either access the source for a good binary?  I
>> have received no assistance from the author/developer of the package.
>
>
> It installs fine for me.

Me too. Steven, please back up, follow the posting guide, describe
your system, what you did, and what happened.

install.packages("XM", dep=TRUE)

works for me on both Windows and Linux with R version 3.0.2

Best,
Ista

>
> Duncan Murdoch
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kannan at iitb.ac.in  Sun Oct 20 02:54:39 2013
From: kannan at iitb.ac.in (kannan at iitb.ac.in)
Date: Sun, 20 Oct 2013 00:54:39 +0000
Subject: [R] Want to create a histogram
Message-ID: <7xa9Awqb.1382230479.2051420.kannan@iitb.ac.in>

Dear All,

For a report that I am writing, I need to create a histogram plot with
x-axis fixed as very bad, bad, fair, good and very good - i.e. the order
not changed.  Can someone give me an example?  For sample purposes, I am
giving the following data: 159, 374, 3765, 11388, 6708.  Thanks,

Kannan


From jim at bitwrit.com.au  Sun Oct 20 05:29:43 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 20 Oct 2013 14:29:43 +1100
Subject: [R] Want to create a histogram
In-Reply-To: <7xa9Awqb.1382230479.2051420.kannan@iitb.ac.in>
References: <7xa9Awqb.1382230479.2051420.kannan@iitb.ac.in>
Message-ID: <52634E27.8060206@bitwrit.com.au>

On 10/20/2013 11:54 AM, kannan at iitb.ac.in wrote:
> Dear All,
>
> For a report that I am writing, I need to create a histogram plot with
> x-axis fixed as very bad, bad, fair, good and very good - i.e. the order
> not changed.  Can someone give me an example?  For sample purposes, I am
> giving the following data: 159, 374, 3765, 11388, 6708.  Thanks,
>
Hi Kannan,
You can get something that looks like what you want with these totals. 
Try this:

barplot(c(159,374,3765,11388,6708),
  names.arg=c("very bad","bad","fair","good","very good"))

Histograms are usually created from the raw data.

Jim


From smartpink111 at yahoo.com  Sun Oct 20 06:31:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 19 Oct 2013 21:31:09 -0700 (PDT)
Subject: [R] bold dot size and name in plot
In-Reply-To: <BLU170-W1003E188F13E7E734C92E3089070@phx.gbl>
References: <BLU170-W1003E188F13E7E734C92E3089070@phx.gbl>
Message-ID: <1382243469.80741.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this also helps.? Using ?ggplot()
indx <- 1 + 2*((z[,1]>80 & z[,1] < 100) & (z[,2]>2 & z[,2] < 4)) + 4*((z[,1]>40 & z[,1] < 60) & (z[,2]>8 & z[,2] < 10)) + 8*((z[,1]>100 & z[,1] < 120) & (z[,2]> 6 & z[,2] < 8))
?indx[indx>1] <- 2
z1<-cbind(z,indx)
z2 <- as.data.frame(z1)
colnames(z2)[1:2] <- c("x","y")
rect1 <- data.frame(xmin=c(80,40,100),xmax=c(100,60,120),ymin=c(2,8,6),ymax=c(4,10,8))
library(ggplot2)
p <- ggplot(x=x, y=y,data=z2)+scale_size(range=c(2,4))+
?geom_rect(data=rect1, aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax),fill='gray80', alpha=0.8) + geom_point(data=z2,aes(x=x,y=y,size=indx,colour=factor(indx)))+scale_colour_manual(values=c("black","red"))+theme_bw() +theme(legend.position = "none") 
p+ annotate("text", label = "A", x = 90, y = 3) +
?annotate("text", label = "B", x = 50, y = 9) +
?annotate("text", label = "C", x = 110, y = 7)


#or
p+ geom_text(aes(90, 3, label="A")) +
geom_text(aes(50, 9, label="B")) +
?geom_text(aes(110, 7, label="C"))

A.K.




On Saturday, October 19, 2013 5:30 PM, eliza botto <eliza_botto at hotmail.com> wrote:
Dear useRs,

I have the following data "z" of two variables "x"(z[,1]) and "y"(z[,2]).

> dput(z)

structure(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 4.36222673881464, 3.69969030080286, 4.2171385106796, 3.13216766340978, 4.48272959444564, 5.15902588302327, 5.48017158746089, 4.27937198622481, 6.87798628712867, 10.6244257045475, 4.28697206373731, 2.36185506591713, 3.8999910824793, 3.53659639173799, 3.55002661079475, 1.69933515030185, 3.05902585757021, 7.36381894775327, 7.40245656365444, 3.6848569064997, 6.08996204878611, 6.28326065486612, 3.94011667392145, 4.32959623927668,
 4.53659549630782, 10.5471767576564, !
3.25988629354992, 4.09457312472741, 3.80883550148271, 3.31050022622877, 4.97298874506525, 4.44111508385058, 8.07706784555988, 4.82859189180109, 4.28049047919568, 4.02054752142086, 4.45446182299703, 2.88902557744596, 4.17698124193575, 6.31474248231764, 2.68657606391183, 3.75708892669439, 4.70294050809375, 6.35750639997654, 5.66591712203293, 5.1676226656419, 6.36111068522507, 5.0746871785069, 3.74549388607439, 10.0499160660981, 2.73392821921647, 7.5468698295455, 3.63310870671515, 4.73756281172226, 3.12831980852897, 5.92478381773712, 3.97278768529811, 4.43603447353224, 3.22165005512334, 2.64048226457915, 4.82170867550029, 3.88802663642624, 6.28071352879497, 7.1898792291212, 3.45069580057411, 2.11874855961612, 6.83308998981622, 4.88594913751698, 7.2043715042717, 5.92944522632847, 5.28125713924232, 2.92406012836832, 5.51193983406794, 3.92034936881849, 4.02863562948636, 2.63086007943162, 2.29816871384959, 5.43277606496536, 2.748057506715, 2.98832890910102,
 3.86750736412989, 10.02!
51585616053, 2.4508507570229, 5.15539283003769, 4.92251312085952, 3.75
60826804466, 3.55555381750724, 3.80501827417895, 6.9500408077286, 5.63753820219307, 4.34417512875296, 2.38134080759689, 6.02021367624557, 7.61923679606813, 4.2639565075926, 5.19690782449524, 2.77914619706371, 2.80469912067042, 2.5030368187632, 3.66180330645551, 4.73586073723542, 4.03431276216711, 2.65910091882713, 2.83278553692168, 7.41646908081112, 1.87620181096256, 1.51781201506458, 1.92751580314289, 2.43506169436137, 1.88641686599088, 4.49013870147502, 2.15361460668737, 3.46482799242971, 2.69942251292495, 5.49300237653247, 3.34643344573202, 4.094064955793, 8.96571331963092, 2.22907411871184, 4.38143383339268, 6.52622723104758, 3.96979373172918, 5.52311167411852, 7.12115478587954), .Dim = c(124L, 2L), .Dimnames = list(c("1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2",
 "1_2", "1_2", "1_2", "1_2"!
, "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2", "1_2"), NULL))

I made a dot plot between them. what i want to do is to bold the size of dots,compared to that of others, for the following ranges
-------80<x<100 and 2<y<4

-------40<x<60 and 8<y<10

-------100<x<120 and 6<y<8

Then, i also want to draw square around those dots falling in these ranges and finally naming the areas with alphabets A, B and C.

Is there a way of doing it?

Thanks in advance

Eliza
??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From weitaiyun at gmail.com  Sun Oct 20 06:28:54 2013
From: weitaiyun at gmail.com (Taiyun Wei)
Date: Sun, 20 Oct 2013 12:28:54 +0800
Subject: [R] list and <<-
Message-ID: <CAM4FiqHQN-AFjsw+Fn1uOaAtDsgLqxp=ap=hepyThk=aPa0cjQ@mail.gmail.com>

Dear All,

> opt = list()
> opt$aa <<- TRUE
Error in opt$aa <<- TRUE : object 'opt' not found

Why?

-- 
Regards,
Taiyun
--
Taiyun Wei <weitaiyun at gmail.com>
Homepage: http://blog.cos.name/taiyun/
Phone: +86-15201142716
Renmin University of China


From dwinsemius at comcast.net  Sun Oct 20 08:48:45 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 19 Oct 2013 23:48:45 -0700
Subject: [R] list and <<-
In-Reply-To: <CAM4FiqHQN-AFjsw+Fn1uOaAtDsgLqxp=ap=hepyThk=aPa0cjQ@mail.gmail.com>
References: <CAM4FiqHQN-AFjsw+Fn1uOaAtDsgLqxp=ap=hepyThk=aPa0cjQ@mail.gmail.com>
Message-ID: <42B4567A-8C09-4ED9-B48A-D510D193D41B@comcast.net>


On Oct 19, 2013, at 9:28 PM, Taiyun Wei wrote:

> Dear All,
> 
>> opt = list()
>> opt$aa <<- TRUE
> Error in opt$aa <<- TRUE : object 'opt' not found

Try _not_ using `<<-`

> Why?

There wasn't an object by htat name in the enclosing environment.

-- 
David Winsemius
Alameda, CA, USA


From Achim.Zeileis at uibk.ac.at  Sun Oct 20 09:57:18 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sun, 20 Oct 2013 09:57:18 +0200 (CEST)
Subject: [R] No P.values in polr summary
In-Reply-To: <CANdJ3dX1ZkrRFSJA7_5r1F7R++tQsd1wzy=pdnmMAMq-Fubhwg@mail.gmail.com>
References: <CANCN_HSuEbJvGNo-XaAFPmPN_2A=WPJbahjC-Ms0JQKXWU_rBQ@mail.gmail.com>
	<52622817.5020805@stats.ox.ac.uk>
	<CANCN_HRznj8b3M-HytOZFgmeJ9f8Tr2+ccuwH=J3voh16ioE5A@mail.gmail.com>
	<CANdJ3dX1ZkrRFSJA7_5r1F7R++tQsd1wzy=pdnmMAMq-Fubhwg@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1310200953010.4177@paninaro.uibk.ac.at>

On Sat, 19 Oct 2013, Tal Galili wrote:

> Vincent,
> I believe Prof. Ripley is referring to this:
> http://www.stats.ox.ac.uk/pub/MASS4/
>
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com |
> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> www.r-statistics.com (English)
> ----------------------------------------------------------------------------------------------
>
>
>
> On Sat, Oct 19, 2013 at 3:22 PM, vincent guyader
> <vincent.guyader at gmail.com>wrote:
>
>> 2013/10/19 Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>
>>> On 18/10/2013 15:01, Vincent Guyader wrote:
>>>
>>>> Hi everyone,
>>>>
>>>> If I compute a "Ordered Logistic or Probit Regression" with the polr
>>>> function from MASS package. the summary give me : coefficients, Standard
>>>> error and Tvalue.. but  not directly the p.value.
>>>>
>>>>
>>>> I can compute "manualy" the Pvalue, but Is there a way to directly
>> obtain
>>>> the pa.value, and I wonder why the p.valeu is not directly calculated,
>> is
>>>> there a reason?
>>>>
>>>
>>> How are you going to calculate the P values?  Have you read the book for
>>> which this is support software?: it explains why such Wald tests are
>>> inappropriate and that the asymptotic theory can be wildly misleading.
>>>
>>
>> Hi,
>>
>> thanks for your answer.
>> to have the P.value I use this code :
>> http://www.ats.ucla.edu/stat/r/dae/ologit.htm
>>
>> pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2

A convenience option for computing this is the coeftest() method provided 
in the "AER" package:

## data
library("foreign")
dat <- read.dta("http://www.ats.ucla.edu/stat/data/ologit.dta")

## model
library("MASS")
m <- polr(apply ~ pared + public + gpa, data = dat, Hess = TRUE)

## coefficient test
library("AER")
coeftest(m)

Checking out the discussion in MASS (the book) on the usefulness of these 
p-values is nevertheless a good idea, of course.

>> It give the same result as Stata, but you are right i'm not sure that it's
>> good. Could you please tell me which book you are talking about.
>>
>> Regards
>>
>>
>>
>>
>>>
>>>> exemple :
>>>>
>>>> house.plr <- polr(Sat ~ Infl + Type + Cont, weights = Freq, data =
>>>> housing)
>>>> house.plr
>>>> summary(house.plr, digits = 3)
>>>>
>>>>
>>>>
>>>>
>>>> Regards
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________**________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/**listinfo/r-help<
>> https://stat.ethz.ch/mailman/listinfo/r-help>
>>>> PLEASE do read the posting guide http://www.R-project.org/**
>>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>  PLEASE do.
>>>
>>> --
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~**ripley/<
>> http://www.stats.ox.ac.uk/~ripley/>
>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>
>>> ______________________________**________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-help<
>> https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/**
>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From luana.paponi at libero.it  Sun Oct 20 08:49:16 2013
From: luana.paponi at libero.it (luana)
Date: Sat, 19 Oct 2013 23:49:16 -0700 (PDT)
Subject: [R] Combining two models into one
Message-ID: <1382251756004-4678635.post@n4.nabble.com>

Hi guys,
I'm trying to combining 2 models into 1 but maybe I'm not doing this in the
right way.
my dataset is about the level of the vitamin A in the blood measured at
different times with two different treatments (ie. I have 6 coloums, vit A1
, time1, treat1, vit A2, time2, treat2, n=28). It wants to determinate if
the variable treatment is really appropriate.
E(y) = ?0 + ?1 x +  ?2 x^2 (treatment1)
      =  ?0 +  ?1 x +  ?2 x^2 (treatment2)
(level of vit a against time)

satisfy the hypothesis H0 :  ?1 = ?1 and ?2 =  ?2 .

The question is how can I combine the two models into one E(y) = X ? with
appropriate design matrix X and coefficient vector ?? In this question ?  is
6x1.

I did it but I think it is not good at all:

vita<-cbind(dt$Vita..y., dt$Time..x.,
dt$Treatment,dt$Vita..y..1,dt$Time..x..1,dt$Treatment.1)


x1 <- cbind(rep(1,28), matrix(0,28,2), vita[,1], matrix(0,28,2))
x11 <- cbind(rep(1,28), matrix(0,28,2), vita[,4], matrix(0,28,2))
x2 <- cbind(rep(0,28), rep(1,28), matrix(0,28,2), vita[,2], rep(0,28))
x22 <- cbind(rep(0,28), rep(1,28), matrix(0,28,2), vita[,5], rep(0,28))
x3 <- cbind(matrix(0,28,2), rep(1,28), matrix(0,28,2), vita[,3])
x33 <- cbind(matrix(0,28,2), rep(1,28), matrix(0,28,2), vita[,6])

x <- rbind(x1, x2, x3,x11, x22, x33) #create the design matrix

ma <-c(vita[,1],vita[,4])  #response values

mma <- data.frame(ma,x) #create the data frame for regression

attach(mma) #attach the data frame to make it available to lm()

ma.lm <- lm(ma ~ -1 + X1 + X2 + X3 + X4 + X5 + X6) #regr model without
#intercept (note the -1 term)

I am sure that is not good, because I should have x^2  and there isn't.
Moreover it gives me an error:
Error in model.frame.default(formula = ma ~ -1 + X1 + X2 + X3 + X4 + X5 +  : 
  variable lengths differ (found for 'X1')

How can I do it?

Tnx



--
View this message in context: http://r.789695.n4.nabble.com/Combining-two-models-into-one-tp4678635.html
Sent from the R help mailing list archive at Nabble.com.


From allan.clark at uct.ac.za  Sun Oct 20 12:12:07 2013
From: allan.clark at uct.ac.za (Allan Clark)
Date: Sun, 20 Oct 2013 10:12:07 +0000
Subject: [R] R2admb compile problem
Message-ID: <771C135EE0374A4E8499038BC9906246204B4A30@SRVWINEXC004.wf.uct.ac.za>

Good morning all

I am trying to use R2admb and have the following very simple example. The *.tpl is included below. I am a Windows 7 user, using R3.01.

//Function1.tpl
//*********************************
PARAMETER_SECTION
 init_number x;
 objective_function_value C;

PROCEDURE_SECTION
 C=  pow(x-5,2);
//*********************************

I am running the example using three different methods
1. from DOS
2. From Emacs
3. From within R


1. from DOS
admb Function1
Function1

This runs correctly and works

2. From Emacs

I "Translate", "Build" and "Run" the file and it works correctly

3. From R

#Using the following code

require(R2admb)

fn="Function1"
setup_admb()  #outputs the following [1] "c:\\ADMB\\admb101-gcc452-win64"
compile_admb(fn, verbose=T)
#I set 'verbose =T' to see whats happening
#last error line = 'collect2: ld returned 1 exit status'

#cant run this part of the code
run_admb(fn)

#Error in run_admb(fn) :
#executable Function1.exe not found: did you forget to compile it?


Note that if I first compile the tpl file using DOS and then run the following from R, that everything works.

run_admb(fn) #to run the executable
results <- read_admb(fn)
results
clean_admb(fn)


DOES ANYONE KNOW WHY compile_admb(fn, verbose=T) DOES NOT WORK CORRECTLY?


//Function1.tpl
DATA_SECTION

PARAMETER_SECTION
 init_number x;
 objective_function_value C;


PRELIMINARY_CALCS_SECTION

PROCEDURE_SECTION

 C=  pow(x-5,2);
________________________________
 UNIVERSITY OF CAPE TOWN

This e-mail is subject to the UCT ICT policies and e-mai...{{dropped:9}}


From valentina81c at hotmail.it  Sun Oct 20 13:08:08 2013
From: valentina81c at hotmail.it (valentina colombo)
Date: Sun, 20 Oct 2013 11:08:08 +0000
Subject: [R] Errore  : requires numeric/complex matrix/vector arguments
Message-ID: <DUB110-W137625DBF468113AE66E3A1BB000@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131020/069fc642/attachment.pl>

From jrkrideau at inbox.com  Sun Oct 20 13:20:31 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 20 Oct 2013 03:20:31 -0800
Subject: [R] Errore : requires numeric/complex matrix/vector arguments
In-Reply-To: <DUB110-W137625DBF468113AE66E3A1BB000@phx.gbl>
Message-ID: <B5A77780A63.00000085jrkrideau@inbox.com>

It looks like you have posted in HTML and your code is basically unreadable.  

Please repost in text format.  Also I'd suggest reading one or both of the following lists for some hints on how to create a good question.

I think a key point here is to supply sample data using the dput() function as described in the links:
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Welcome to the R-help list
John Kane
Kingston ON Canada


> -----Original Message-----
> From: valentina81c at hotmail.it
> Sent: Sun, 20 Oct 2013 11:08:08 +0000
> To: r-help at r-project.org
> Subject: [R] Errore : requires numeric/complex matrix/vector arguments
> 
> Dear R users,I'm a new user of R. I'm trying to do a LM test an there is
> this type of error: Error in t(mX) %*% mX : requires numeric/complex
> matrix/vector arguments.
> To be clear I write down the code in which mY ( 126,1 )   mX (126,1)
> mZ(126,1) are matrix.
> 
> LMTEST <- function(mY, mX, mZ)#mY, mX, mZ must be matrices!#returns the
> LM test statistic and the degree of freedom{iT = dim(mY)[1]ip =
> dim(mY)[2]iDF = dim(mZ)[2]*ipmE = mY -
> mX%*%solve(t(mX)%*%mX)%*%t(mX)%*%mY
> the error starts from the above step     (t(mX)%*%mX)%*%t(mX)%*%mY
> RSS0 = t(mE)%*%mEmXX = cbind(mX, mZ)mK = mE -
> mXX%*%solve(t(mXX)%*%mXX)%*%t(mXX)%*%mERSS1 = t(mK)%*%mKdTR =
> sum(diag(solve(RSS0)%*%RSS1))LM = iT*(ip-dTR)pval =
> 1-pchisq(LM,df=iDF)return( c(pval, LM, iDF) )}
> Any suggestion? Where is the problem? I am getting craxy!
> Valentina
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From bhh at xs4all.nl  Sun Oct 20 13:29:37 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 20 Oct 2013 13:29:37 +0200
Subject: [R] Errore  : requires numeric/complex matrix/vector arguments
In-Reply-To: <DUB110-W137625DBF468113AE66E3A1BB000@phx.gbl>
References: <DUB110-W137625DBF468113AE66E3A1BB000@phx.gbl>
Message-ID: <EFF1A9F4-B9B2-49AF-96FF-16CA2932D936@xs4all.nl>


On 20-10-2013, at 13:08, valentina colombo <valentina81c at hotmail.it> wrote:

> Dear R users,I'm a new user of R. I'm trying to do a LM test an there is this type of error: Error in t(mX) %*% mX : requires numeric/complex matrix/vector arguments.
> To be clear I write down the code in which mY ( 126,1 )   mX (126,1)   mZ(126,1) are matrix.
> 
> LMTEST <- function(mY, mX, mZ)#mY, mX, mZ must be matrices!#returns the LM test statistic and the degree of freedom{iT = dim(mY)[1]ip = dim(mY)[2]iDF = dim(mZ)[2]*ipmE = mY - mX%*%solve(t(mX)%*%mX)%*%t(mX)%*%mY
> the error starts from the above step     (t(mX)%*%mX)%*%t(mX)%*%mY
> RSS0 = t(mE)%*%mEmXX = cbind(mX, mZ)mK = mE - mXX%*%solve(t(mXX)%*%mXX)%*%t(mXX)%*%mERSS1 = t(mK)%*%mKdTR = sum(diag(solve(RSS0)%*%RSS1))LM = iT*(ip-dTR)pval = 1-pchisq(LM,df=iDF)return( c(pval, LM, iDF) )}
> Any suggestion? Where is the problem? I am getting craxy!

Your code is a complete mess and thus unreadable because you posted in HTML.
Cleaning up and doing this

LMTEST <- function(mY, mX, mZ)#mY, mX, mZ must be matrices!
#returns the LM test statistic and the degree of freedom
{iT = dim(mY)[1]
    ip = dim(mY)[2]
    iDF = dim(mZ)[2]*ip
    mE = mY - mX%*%solve(t(mX)%*%mX)%*%t(mX)%*%mY
# the error starts from the above step   
 (t(mX)%*%mX)%*%t(mX)%*%mY
RSS0 = t(mE)%*%mE
mXX = cbind(mX, mZ)
mK = mE - mXX%*%solve(t(mXX)%*%mXX)%*%t(mXX)%*%mE
RSS1 = t(mK)%*%mK
dTR = sum(diag(solve(RSS0)%*%RSS1))
LM = iT*(ip-dTR)
pval = 1-pchisq(LM,df=iDF)
return( c(pval, LM, iDF) )
}

set.seed(1)

N <- 20
mX <- matrix(runif(N),ncol=1)
mY <- matrix(runif(N),ncol=1)
mZ <- matrix(runif(N),ncol=1)

LMTEST(mY,mX,mZ)   

the answer I got was:

[1] 0.004965514 7.891955826 1.000000000


So it must be your data.
Are you sure they are numeric? Have you checked  with str(mX) etc?

Berend

> Valentina 		 	   		  
> 	[[alternative HTML version deleted]]


Please don't post in html but in plain text.


> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sun Oct 20 13:35:57 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 20 Oct 2013 03:35:57 -0800
Subject: [R] Want to create a histogram
In-Reply-To: <7xa9Awqb.1382230479.2051420.kannan@iitb.ac.in>
Message-ID: <B5C9F7E75D3.000000A0jrkrideau@inbox.com>

I  don't think you do. I think that you are confusing a histogram and a bar chart.  With only five data points and five categories you have data for a barplot.

I see Jim has provided one approach 

Another, using the ggplot2 package (which you will probably have to install is :


# to install ggplot2 package
install.packages("ggplot2")

library(ggplot2)
dat1  <- data.frame(  aa  =  c("very bad", "bad", "fair", "good", "very good"),
bb = c(159, 374, 3765, 11388, 6708))

ggplot(dat1, aes(aa, bb)) + geom_bar(stat="identity")






John Kane
Kingston ON Canada


> -----Original Message-----
> From: kannan at iitb.ac.in
> Sent: Sun, 20 Oct 2013 00:54:39 +0000
> To: r-help at r-project.org
> Subject: [R] Want to create a histogram
> 
> Dear All,
> 
> For a report that I am writing, I need to create a histogram plot with
> x-axis fixed as very bad, bad, fair, good and very good - i.e. the order
> not changed.  Can someone give me an example?  For sample purposes, I am
> giving the following data: 159, 374, 3765, 11388, 6708.  Thanks,
> 
> Kannan
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From bhh at xs4all.nl  Sun Oct 20 16:31:00 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 20 Oct 2013 16:31:00 +0200
Subject: [R] Errore  : requires numeric/complex matrix/vector arguments
In-Reply-To: <DUB110-W78FD6351CA54ED4A233CB5BB000@phx.gbl>
References: <DUB110-W137625DBF468113AE66E3A1BB000@phx.gbl>,
	<EFF1A9F4-B9B2-49AF-96FF-16CA2932D936@xs4all.nl>
	<DUB110-W78FD6351CA54ED4A233CB5BB000@phx.gbl>
Message-ID: <235A9DCB-0308-4764-B1FB-1526FB35C9A9@xs4all.nl>


On 20-10-2013, at 16:16, valentina colombo <valentina81c at hotmail.it> wrote:

> Dear Mr. Hasselman,
> I have attached my code to solve (hopefully) my problem in Error-require numeric/complex matrix/vector
> Any suggestions?
> Thanks
> 
Please answer to the list and NOT only privately. I'm forwarding this message to R-help.

You are not showing how you constructed mX and others.
In the attachment you show how you read X.

I do not get your error when I generate your matrices with these commands:

set.seed(1)

N <- 126
mX <- matrix(runif(N*4),ncol=4)
mY <- matrix(runif(N*4),ncol=4)
mZ <- matrix(runif(N*4),ncol=4)

If you want to include data in a text-only mail use dput.

Berend

> 
> 
> > Subject: Re: [R] Errore : requires numeric/complex matrix/vector arguments
> > From: bhh at xs4all.nl
> > Date: Sun, 20 Oct 2013 13:29:37 +0200
> > CC: r-help at r-project.org
> > To: valentina81c at hotmail.it
> > 
> > 
> > On 20-10-2013, at 13:08, valentina colombo <valentina81c at hotmail.it> wrote:
> > 
> > > Dear R users,I'm a new user of R. I'm trying to do a LM test an there is this type of error: Error in t(mX) %*% mX : requires numeric/complex matrix/vector arguments.
> > > To be clear I write down the code in which mY ( 126,1 ) mX (126,1) mZ(126,1) are matrix.
> > > 
> > > LMTEST <- function(mY, mX, mZ)#mY, mX, mZ must be matrices!#returns the LM test statistic and the degree of freedom{iT = dim(mY)[1]ip = dim(mY)[2]iDF = dim(mZ)[2]*ipmE = mY - mX%*%solve(t(mX)%*%mX)%*%t(mX)%*%mY
> > > the error starts from the above step (t(mX)%*%mX)%*%t(mX)%*%mY
> > > RSS0 = t(mE)%*%mEmXX = cbind(mX, mZ)mK = mE - mXX%*%solve(t(mXX)%*%mXX)%*%t(mXX)%*%mERSS1 = t(mK)%*%mKdTR = sum(diag(solve(RSS0)%*%RSS1))LM = iT*(ip-dTR)pval = 1-pchisq(LM,df=iDF)return( c(pval, LM, iDF) )}
> > > Any suggestion? Where is the problem? I am getting craxy!
> > 
> > Your code is a complete mess and thus unreadable because you posted in HTML.
> > Cleaning up and doing this
> > 
> > LMTEST <- function(mY, mX, mZ)#mY, mX, mZ must be matrices!
> > #returns the LM test statistic and the degree of freedom
> > {iT = dim(mY)[1]
> > ip = dim(mY)[2]
> > iDF = dim(mZ)[2]*ip
> > mE = mY - mX%*%solve(t(mX)%*%mX)%*%t(mX)%*%mY
> > # the error starts from the above step 
> > (t(mX)%*%mX)%*%t(mX)%*%mY
> > RSS0 = t(mE)%*%mE
> > mXX = cbind(mX, mZ)
> > mK = mE - mXX%*%solve(t(mXX)%*%mXX)%*%t(mXX)%*%mE
> > RSS1 = t(mK)%*%mK
> > dTR = sum(diag(solve(RSS0)%*%RSS1))
> > LM = iT*(ip-dTR)
> > pval = 1-pchisq(LM,df=iDF)
> > return( c(pval, LM, iDF) )
> > }
> > 
> > set.seed(1)
> > 
> > N <- 20
> > mX <- matrix(runif(N),ncol=1)
> > mY <- matrix(runif(N),ncol=1)
> > mZ <- matrix(runif(N),ncol=1)
> > 
> > LMTEST(mY,mX,mZ) 
> > 
> > the answer I got was:
> > 
> > [1] 0.004965514 7.891955826 1.000000000
> > 
> > 
> > So it must be your data.
> > Are you sure they are numeric? Have you checked with str(mX) etc?
> > 
> > Berend
> > 
> > > Valentina 
> > > [[alternative HTML version deleted]]
> > 
> > 
> > Please don't post in html but in plain text.
> > 
> > 
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > 
> <R error.txt>


From ahmedatia80 at gmail.com  Sun Oct 20 17:29:26 2013
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Sun, 20 Oct 2013 10:29:26 -0500
Subject: [R] Nash-Sutcliffe coefficient
Message-ID: <CAG6S0O=q6_zXwChOP923Tueyx7Fe6Wqip8fZEgc=bS7Mz8Xmpw@mail.gmail.com>

Hi

Could you please inform how can I get the Nash-Sutcliffe coefficient in r?

Comparing observed vs. simulated values.

Appreciated

-- 
Ahmed M. Attia


Research Assistant
Dept. Of Soil&Crop Sciences
Texas A&M University
ahmed.attia at ag.tamu.edu
Cell phone: 001-979-248-5215


From bhh at xs4all.nl  Sun Oct 20 17:40:16 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 20 Oct 2013 17:40:16 +0200
Subject: [R] Nash-Sutcliffe coefficient
In-Reply-To: <CAG6S0O=q6_zXwChOP923Tueyx7Fe6Wqip8fZEgc=bS7Mz8Xmpw@mail.gmail.com>
References: <CAG6S0O=q6_zXwChOP923Tueyx7Fe6Wqip8fZEgc=bS7Mz8Xmpw@mail.gmail.com>
Message-ID: <27CF8E65-4A3D-425D-82B9-27D27D7F877C@xs4all.nl>


On 20-10-2013, at 17:29, Ahmed Attia <ahmedatia80 at gmail.com> wrote:

> Hi
> 
> Could you please inform how can I get the Nash-Sutcliffe coefficient in r?
> 
> Comparing observed vs. simulated values.
> 
> Appreciated
> 

Install package sos.
Then

findFn("Nash") should lead you to package hydroGOF which seems to have several flavours.


Berend

> -- 
> Ahmed M. Attia
> 
> 
> Research Assistant
> Dept. Of Soil&Crop Sciences
> Texas A&M University
> ahmed.attia at ag.tamu.edu
> Cell phone: 001-979-248-5215
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dtemplelang at ucdavis.edu  Sun Oct 20 17:49:07 2013
From: dtemplelang at ucdavis.edu (Duncan Temple Lang)
Date: Sun, 20 Oct 2013 08:49:07 -0700
Subject: [R] saveXML() prefix argument
In-Reply-To: <1382182574.13698.41.camel@milan>
References: <1889419292.977405.1382117263258.JavaMail.root@k-state.edu>
	<1382182574.13698.41.camel@milan>
Message-ID: <5263FB73.7070704@ucdavis.edu>


Thanks Earl and Milan.
Yes, the C code to serialize does branch and do things
differently for the different combinations of file, encoding and indent.
I have updated the code to use a different routine in libxml2 for this case
and that honors the indentation in this case. That will be in the next release
of XML.

In the meantime, you can use

   cat( saveXML( doc, encoding = "UTF-8", indent = TRUE),  file = "bob.xml")

rather than 
    saveXML(doc, file = "bob.xml", encoding = "UTF-8", indent = TRUE)
i.e. move the file argument to cat().

 Thanks,
     D.

On 10/19/13 4:36 AM, Milan Bouchet-Valat wrote:
> Le vendredi 18 octobre 2013 ? 13:27 -0400, Earl Brown a ?crit :
>> Thanks Duncan. However, now I can't get the Spanish and Portuguese accented vowels to come out correctly and still keep the indents in the saved document, even when I set encoding = "UTF-8":
>>
>> library("XML")
>> concepts <- c("espa?ol", "portugu?s")
>> info <- c("info about espa?ol", "info about portugu?s")
>>
>> doc <- newXMLDoc()
>> root <- newXMLNode("tips", doc = doc)
>> for (i in 1:length(concepts)) {
>> 	cur.concept <- concepts[i]
>> 	cur.info <- info[i]
>> 	cur.tip <- newXMLNode("tip", attrs = c(id = i), parent = root)
>> 	newXMLNode("h1", cur.concept, parent = cur.tip)
>> 	newXMLNode("p", cur.info, parent = cur.tip)
>> }
>>
>> # accented vowels don't come through correctly, but the indents are correct:
>> saveXML(doc, file = "test1.xml", indent = T)
>>
>> Resulting file looks like this:
>> <?xml version="1.0"?>
>> <tips>
>>   <tip id="1">
>>     <h1>espa&#xF1;ol</h1>
>>     <p>info about espa&#xF1;ol</p>
>>   </tip>
>>   <tip id="2">
>>     <h1>portugu&#xEA;s</h1>
>>     <p>info about portugu&#xEA;s</p>
>>   </tip>
>> </tips>
>>
>> # accented vowels are correct, but the indents are no longer correct:
>> saveXML(doc, file = "test2.xml", indent = T, encoding = "UTF-8")
>>
>> Resulting file:
>> <?xml version="1.0" encoding="UTF-8"?>
>> <tips><tip id="1"><h1>espa?ol</h1><p>info about espa?ol</p></tip><tip
>> id="2"><h1>portugu?s</h1><p>info about portugu?s</p></tip></tips>
>>
>> I tried to workaround the problem by simply loading in that resulting
>> file and saving it again:
>> doc2 <- xmlInternalTreeParse(file = "test2.xml", asTree = T)
>> saveXML(doc2, file = "test_word_around.xml", indent = T)
>>
>> but still don't get the indents.
>>
>> Does setting encoding = "UTF-8" override indents = TRUE in saveXML()?
> I can confirm the same issue happens here. What is interesting is that
> without the 'file' argument, the returned string includes the expected
> line breaks and spacing. These do not appear when redirecting the output
> to a file.
> 
>> saveXML(doc, encoding="UTF-8", indent=T)
> [1] "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<tips>\n  <tip id=\"1
> \">\n    <h1>espa?ol</h1>\n    <p>info about espa?ol</p>\n  </tip>\n
> <tip id=\"2\">\n    <h1>portugu?s</h1>\n    <p>info about
> portugu?s</p>\n  </tip>\n</tips>\n"
> 
>> saveXML(doc, encoding="UTF-8", indent=T, file="test.xml")
> 
> Contents of test.xml:
> <?xml version="1.0" encoding="UTF-8"?>
> <tips><tip id="1"><h1>espa?ol</h1><p>info about espa?ol</p></tip><tip id="2"><h1>portugu?s</h1><p>info about portugu?s</p></tip></tips>
> 
> 
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-redhat-linux-gnu (64-bit)
> 
> locale:
>  [1] LC_CTYPE=fr_FR.utf8       LC_NUMERIC=C             
>  [3] LC_TIME=fr_FR.utf8        LC_COLLATE=fr_FR.utf8    
>  [5] LC_MONETARY=fr_FR.utf8    LC_MESSAGES=fr_FR.utf8   
>  [7] LC_PAPER=C                LC_NAME=C                
>  [9] LC_ADDRESS=C              LC_TELEPHONE=C           
> [11] LC_MEASUREMENT=fr_FR.utf8 LC_IDENTIFICATION=C      
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> base     
> 
> other attached packages:
> [1] XML_3.96-1.1
> 
> 
> Regards
> 
>


From murdoch.duncan at gmail.com  Sun Oct 20 18:13:11 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 20 Oct 2013 12:13:11 -0400
Subject: [R] XML package not working
In-Reply-To: <66C71547284587479F8009E05C07DA9704F8E5D2@USTLMLLYC107.RF.lilly.com>
References: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>
	<5263226B.7070103@gmail.com>
	<66C71547284587479F8009E05C07DA9704F8E5D2@USTLMLLYC107.RF.lilly.com>
Message-ID: <52640117.2010908@gmail.com>

On 13-10-20 9:23 AM, Steven Dwayne Randolph wrote:
> My apologies for not conforming to the posting guideline.
>
>
> Sys.info()
>                       sysname                      release                      version
>                     "Windows"                      "7 x64" "build 7601, Service Pack 1"
>                      nodename                      machine                        login
>             "xxxxxxNU247BZ1S"                     "x86-64"                    "XXXXXX"
>                          user               effective_user
>                     "xxxxxxx"                    "xxxxxxx"
>
> When I attempt to install a local copy of the xml.zip file:
>
> in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>    cannot open the connection
> In addition: Warning messages:
> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>    cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'

I think it is pretty clear that the problem is at your end:  you aren't 
downloading the file properly, even though everyone else is.  Perhaps 
you are behind a firewall, or something else is interfering with your 
downloads?

Duncan Murdoch

>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Saturday, October 19, 2013 8:23 PM
> To: Steven Dwayne Randolph; r-help at r-project.org
> Cc: stevendrandolph at aol.com
> Subject: Re: [R] XML package not working
>
> On 13-10-19 3:47 PM, Steven Dwayne Randolph wrote:
>> I know I  cannot be the only one who is not able to install the XML package from CRAN (zip or tar file)  Many packages depend on this XML package.  Can someone help me either access the source for a good binary?  I have received no assistance from the author/developer of the package.
>
> It installs fine for me.
>
> Duncan Murdoch
>


From carl at witthoft.com  Sun Oct 20 18:21:23 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Sun, 20 Oct 2013 09:21:23 -0700 (PDT)
Subject: [R] Combining two models into one
In-Reply-To: <1382251756004-4678635.post@n4.nabble.com>
References: <1382251756004-4678635.post@n4.nabble.com>
Message-ID: <1382286083492-4678648.post@n4.nabble.com>

You created a bunch of 'x' items but call for "X" in your formula.   That's
part of it.  Next, you don't provide a "data=x" argument in your lm() call,
so it goes off and looks for various capital-X items (I suspect).


Hint:  start with a small, simple dataset and work with it until you know
how to use lm() and R's formula syntax.  Only then go on to your full-on
model.




--
View this message in context: http://r.789695.n4.nabble.com/Combining-two-models-into-one-tp4678635p4678648.html
Sent from the R help mailing list archive at Nabble.com.


From ruipbarradas at sapo.pt  Sun Oct 20 18:54:01 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 20 Oct 2013 17:54:01 +0100
Subject: [R] loop not working my way
In-Reply-To: <526309F0.9020106@ufl.edu>
References: <5262C42C.4080706@ufl.edu> <5262F38C.1000002@sapo.pt>
	<526309F0.9020106@ufl.edu>
Message-ID: <52640AA9.4070400@sapo.pt>

Hello,

Make a _simple_ example, I don't see what packages like knitr or ggplot2 
have anything to do with your problem.
Like this is, I think you're asking too much from r-help.

Rui Barradas

Em 19-10-2013 23:38, Laz escreveu:
> Dear R users,
> Dear R users,
>   (I had not included two more functions in the previous mail. This
> version is complete)
>
> There is a small problem which I don't know how to sort it out, based on
> the former example I had explained earlier  own.
> I am calling my own  functions which are based on simulations as below:
>
> library(gmp)
> library(knitr) # load this packages for publishing results
> library(matlab)
> library(Matrix)
> library(psych)
> library(foreach)
> library(epicalc)
> library(ggplot2)
> library(xtable)
> library(gdata)
> library(gplots)
>
> ####################################
> # function to calculate heritability
> herit<-function(varG,varR=1)
> {
>    h<-4*varG/(varG+varR)
>    h
> }
> h<-herit(0.081,1);h
>
> ###################################
> # function to calculate random error
> varR<-function(varG,h2)
> {
>    varR<- varG*(4-h2)/h2
>    varR
> }
> #system.time(h<-varR(0.081,0.3));h
> ##########################################
> # function to calculate treatment variance
> varG<-function(varR=1,h2)
> {
>    varG<-varR*h2/(4-h2)
>    varG
> }
> # system.time(h<-varG(1,0.3));h
> ###############################
>
> # calculating R inverse from spatial data
> rspat<-function(rhox=0.6,rhoy=0.6)
> {
>    s2e<-1
>    R<-s2e*eye(N)
>    for(i in 1:N) {
>      for (j in i:N){
>        y1<-y[i]
>        y2<-y[j]
>        x1<-x[i]
>        x2<-x[j]
>        R[i,j]<-s2e*(rhox^abs(x2-x1))*(rhoy^abs(y2-y1)) # Core AR(1)*AR(1)
>        R[j,i]<-R[i,j]
>      }
>    }
>    IR<-solve(R)
>    IR
> }
>
> ### a function to generate A sparse matrix from a pedigree
> ZGped<-function(ped)
> {
>    ped2<-data.frame(ped)
>    lenp2<-length(unique(ped2$V1));lenp2 # how many Genotypes in total in
> the pedigree =40
>    ln2<-length(g);ln2#ln2=nrow(matdf)=30
>    # calculate the new Z
>    Zped<-model.matrix(~ matdf$genotypes -1)# has order N*t = 180 by 30
>    dif<-(lenp2-ln2);dif # 40-30=10
>    #print(c(lenp2,ln2,dif))
>    zeromatrix<-zeros(nrow(matdf),dif);zeromatrix # 180 by 10
>    Z<-cbind(zeromatrix,Zped) # Design Matrix for random effect
> (Genotypes): 180 by 40
>    # calculate the new G
>    M<-matrix(0,lenp2,lenp2) # 40 by 40
>    for (i in 1:nrow(ped2)) { M[ped2[i, 1], ped2[i, 2]] <- ped2[i, 3]  }
>    G<-s2g*M # Genetic Variance covariance matrix for pedigree 2: 40 by 40
>    IG<-solve(G)
>    results<-c(IG, Z)
>    results
> }
>
> ####  Three main functions  here  #####
>
> ### function 1: generate a design (dataframe)
> setup<-function(b,g,rb,cb,r,c,h2,rhox=0.6,rhoy=0.6,ped="F")
> {
>    # where
>    # b   = number of blocks
>    # t   = number of treatments per block
>    # rb  = number of rows per block
>    # cb  = number of columns per block
>    # s2g = variance within genotypes
>    # h2  = heritability
>    # r   = total number of rows for the layout
>    # c   = total number of columns for the layout
>      ### Check points
>    if(b==" ")
>      stop(paste(sQuote("block")," cannot be missing"))
>    if(!is.vector(g) | length(g)<3)
>      stop(paste(sQuote("treatments")," should be a vector and more than
> 2"))
>    if(!is.numeric(b))
>      stop(paste(sQuote("block"),"is not of class", sQuote("numeric")))
>    if(length(b)>1)
>      stop(paste(sQuote("block"),"has to be only 1 numeric value"))
>    if(!is.whole(b))
>      stop(paste(sQuote("block"),"has to be an", sQuote("integer")))
>      ## Compatibility checks
>    if(rb*cb !=length(g))
>      stop(paste(sQuote("rb x cb")," should be equal to number of
> treatment", sQuote("g")))
>    if(length(g) != rb*cb)
>      stop(paste(sQuote("the number of treatments"), "is not equal to",
> sQuote("rb*cb")))
>      ## Generate the design
>    g<<-g
>    genotypes<-times(b) %do% sample(g,length(g))
>    #genotypes<-rep(g,b)
>    block<-rep(1:b,each=length(g))
>    genotypes<-factor(genotypes)
>    block<-factor(block)
>      ### generate the base design
>    k<-c/cb # number of blocks on the x-axis
>    x<<-rep(rep(1:r,each=cb),k)  # X-coordinate
>     #w<-rb
>    l<-cb
>    p<-r/rb
>    m<-l+1
>    d<-l*b/p
>    y<<-c(rep(1:l,r),rep(m:d,r)) # Y-coordinate
>      ## compact
>    matdf<<-data.frame(x,y,block,genotypes)
>    N<<-nrow(matdf)
>    mm<-summ(matdf)
>    ss<-des(matdf)
>      ## Identity matrices
>    X<<-model.matrix(~block-1)
>    h2<<-h2;rhox<<-rhox;rhoy<<-rhoy
>    s2g<<-varG(varR=1,h2)
>    ## calculate G and Z
>    ifelse(ped == "F",
> c(IG<<-(1/s2g)*eye(length(g)),Z<<-model.matrix(~matdf$genotypes-1)),
> c(IG<<- ZGped(ped)[[1]],Z<<-ZGped(ped)[[2]]))
>    ## calculate R and IR
>    s2e<-1
>    ifelse(rhox==0 | rhoy==0, IR<<-(1/s2e)*eye(N),
> IR<<-rspat(rhox=rhox,rhoy=rhoy))
>    C11<-t(X)%*%IR%*%X
>    C11inv<-solve(C11)
>    K<<-IR%*%X%*%C11inv%*%t(X)%*%IR
>    return(list( matdf= matdf,summary=mm,description=ss))
>    }
> matrix0<-setup(b=4,g=seq(1,4,1),rb=2,cb=2,r=4,c=4,h2=0.3,rhox=0.6,rhoy=0.6,ped="F")[1]$matdf;
> matrix0
>
>     x y block genotypes
> 1  1 1     1         1
> 2  1 2     1         3
> 3  2 1     1         2
> 4  2 2     1         4
> 5  3 1     2         1
> 6  3 2     2         3
> 7  4 1     2         4
> 8  4 2     2         2
> 9  1 3     3         1
> 10 1 4     3         2
> 11 2 3     3         4
> 12 2 4     3         3
> 13 3 3     4         1
> 14 3 4     4         2
> 15 4 3     4         3
> 16 4 4     4         4
>
>
> ### function 2
> mainF<-function(criteria=c("A","D"))
> {
>    ### Variance covariance matrices
>    temp<-t(Z)%*%IR%*%Z+IG - t(Z)%*%K%*%Z
>    C22<-solve(temp)
>      ##   calculate trace or determinant
>     traceI<<-sum(diag(C22)) ## A-Optimality
>    doptimI<<-log(det(C22)) # D-Optimality
>     if(criteria=="A") return(traceI)
>    if(criteria=="D") return(doptimI)
>    else{return(c(traceI,doptimI))}
> }
>
> start0<-mainF(criteria="A");start0
> [1] 0.1863854
>
>
> ###  function 3 : A function that swaps pairs of treatments randomly
> swapsimple<-function(matdf,ped="F")
> {
>     matdf<-as.data.frame(matdf)
>    attach(matdf,warn.conflict=FALSE)
>    b1<-sample(matdf$block,1,replace=TRUE);b1
>    gg1<-matdf$genotypes[block==b1];gg1
>    g1<-sample(gg1,2);g1
>    samp<-Matrix(c(g1=g1,block=b1),nrow=1,ncol=3,
>                 dimnames=list(NULL,c("gen1","gen2","block")));samp
>    newGen<-matdf$genotypes
>    newG<-ifelse(matdf$genotypes==samp[,1] &
> block==samp[,3],samp[,2],matdf$genotypes)
>    NewG<-ifelse(matdf$genotypes==samp[,2] & block==samp[,3],samp[,1],newG)
>    NewG<-factor(NewG)
>     ## now, new design after swapping is
>    newmatdf<-cbind(matdf,NewG)
>    newmatdf<-as.data.frame(newmatdf)
>    mm<-summ(newmatdf)
>    ss<-des(newmatdf)
>     ## Identity matrices
>    #X<<-model.matrix(~block-1)
>    #s2g<<-varG(varR=1,h2)
>    ## calculate G and Z
>    ifelse(ped == "F",
> c(IG<<-(1/s2g)*eye(length(g)),Z<<-model.matrix(~newmatdf$NewG-1)),
> c(IG<<- ZGped(ped)[[1]],Z<<-ZGped(ped)[[2]]))
>    ## calculate R and IR
>    C11<-t(X)%*%IR%*%X
>    C11inv<-solve(C11)
>    K<<-IR%*%X%*%C11inv%*%t(X)%*%IR
>    #Nmatdf<-newmatdf[,c(1,2,3,5)]
>    names(newmatdf)[names(newmatdf)=="genotypes"] <- "old_G"
>    names(newmatdf)[names(newmatdf)=="NewG"] <- "genotypes"
>    #newmatdf <- remove.vars(newmatdf, "old_G")
>    newmatdf$old_G <- newmatdf$old_G <- NULL
>    #matdf<-newmatdf
>    newmatdf
> }
>
> matdf<-swapsimple(matdf,ped="F")
>> matdf
>     x y block genotypes
> 1  1 1     1         1
> 2  1 2     1         3
> 3  2 1     1         2
> 4  2 2     1         4
> 5  3 1     2         4
> 6  3 2     2         3
> 7  4 1     2         1
> 8  4 2     2         2
> 9  1 3     3         1
> 10 1 4     3         2
> 11 2 3     3         4
> 12 2 4     3         3
> 13 3 3     4         1
> 14 3 4     4         2
> 15 4 3     4         3
> 16 4 4     4         4
>
>
>> which(matrix0$genotypes  != matdf$genotypes)
> [1] 5 7
>
> # This is fine because I expected a maximum of 1 pair to change, so I
> have a maximum of 2 positions swapped on the first iteration.
> # If  I swap 10 times (iterations=10), I expect a maximum of 20
> positions to change
>
> ### The final function (where I need your help more )
> fun <- function(n = 10){
> matrix0<-setup(b=4,g=seq(1,4,1),rb=2,cb=2,r=4,c=4,h2=0.3,rhox=0.6,rhoy=0.6,ped="F")[1]$matdf
>
> # matrix0 is the original design before swapping any pairs of treatments
>    res <- list(mat = NULL, Design_best = matrix0, Original_design =
> matrix0)
>    start0<-mainF(criteria="A")
> # start0 is the original trace
>    res$mat <- rbind(res$mat, c(trace = start0, iterations = 0))
>    for(i in seq_len(n)){
> # now swap the pairs of treatments from the original design, n times
>      matdf<-swapsimple(matdf,ped="F")
>           if(mainF(criteria="A") < start0){
>            start0<- mainF(criteria="A")
>        res$mat <- rbind(res$mat, c(trace = start0, iterations = i))
>        res$Design_best <- matdf
>      }
>    }
>    res
> }
>
> res<-fun(50)
>
> res
> $mat
>           trace iterations
> [1,] 0.1938285          0
> [2,] 0.1881868          1
> [3,] 0.1871099         17
> [4,] 0.1837258         18
> [5,] 0.1812291         19
>
>
> ### here is the problem
>
>> which(res$Design_best$genotypes != res$Original_design$genotypes) #
>> always get a pair of difference
>   [1]  2  3  4  5  6  7 10 11 13 14 15 16
>
> ## I expect a maximum of 8 changes but I get 12 changes which means that
> function only dropped the traces when trace_j > trace_i but did not drop
> the design !!
> How do I fix this ?????
>
> Kind regards,
> lazarus
> On 10/19/2013 5:03 PM, Rui Barradas wrote:
>> Hello,
>>
>> Seems simple.
>>
>>
>> fun <- function(n = 10){
>>     matd <- matrix(sample(1:30,30, replace=FALSE), ncol=5, nrow=6)
>>     res <- list(mat = NULL, Design_best = matd, Original_design = matd)
>>     trace <- sum(diag(matd))
>>     res$mat <- rbind(res$mat, c(trace = trace, iterations = 0))
>>     for(i in seq_len(n)){
>>         matd <- matrix(sample(1:30,30, replace=FALSE), ncol=5, nrow=6)
>>         if(sum(diag(matd)) < trace){
>>             trace <- sum(diag(matd))
>>             res$mat <- rbind(res$mat, c(trace = trace, iterations = i))
>>             res$Design_best <- matd
>>         }
>>     }
>>     res
>> }
>>
>> fun()
>> fun(20)
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 19-10-2013 18:41, laz escreveu:
>>> Dear R users,
>>>
>>> Suppose I want to randomly generate some data, in matrix form, randomly
>>> swap some of the elements and calculate trace of the matrix for each of
>>> these stages. If the value of trace obtained in the later is bigger than
>>> the former, drop the latter matrix and go back to the former matrix,
>>> swap some elements of the matrix again and calculate the trace. If the
>>> recent trace is smaller than the previous one, accept the matrix as the
>>> current .  Use the current matrix  and swap elements again. repeat the
>>> whole process for a number of times, say, 10. The output from the
>>> function should display only the original matrix and its value of trace,
>>> trace values of successful swaps and their iteration counts and the
>>> final best matrix that had the smallest value of trace, together with
>>> its trace value.
>>>
>>> For example
>>> ## original
>>>  > matd<-matrix(sample(1:30,30,replace=FALSE),ncol=5,nrow=6,byrow=FALSE)
>>>  > matd
>>>       [,1] [,2] [,3] [,4] [,5]
>>> [1,]   12   27   29   16   19
>>> [2,]   25   10    7   22   13
>>> [3,]   14   23    3   11   21
>>> [4,]   28    6    5    2   18
>>> [5,]   24   20    1   17   26
>>> [6,]    9    4   30    8   15
>>>  > trace<-sum(diag(matd))
>>>  > trace
>>> [1] 53
>>>
>>> #  1st iteration
>>>
>>>       [,1] [,2] [,3] [,4] [,5]
>>> [1,]   24   29   20   25   17
>>> [2,]   16    1   30    9    5
>>> [3,]   18   22    2   10   26
>>> [4,]   23   27   19   21   28
>>> [5,]   15    6    8    3   13
>>> [6,]   12   14    7   11    4
>>>  > trace<-sum(diag(matd))
>>>  > trace
>>> [1] 61
>>>
>>> ## drop this matrix because 61 >  53
>>>
>>> #  2nd iteration
>>>  > matd<-matrix(sample(1:30,30,replace=FALSE),ncol=5,nrow=6,byrow=FALSE)
>>>  > matd
>>>       [,1] [,2] [,3] [,4] [,5]
>>> [1,]    2   28   23   15   14
>>> [2,]   27    9   10   29    7
>>> [3,]    5   18   12    1   11
>>> [4,]    8    4   30   16   24
>>> [5,]   25   19   26    6   13
>>> [6,]   17   22    3   20   21
>>>  > trace<-sum(diag(matd))
>>>  > trace
>>> [1] 52
>>>
>>> ## accept this matrix because 52 < 53
>>>
>>> ### 3rd iteration
>>>  > matd<-matrix(sample(1:30,30,replace=FALSE),ncol=5,nrow=6,byrow=FALSE)
>>>  > matd
>>>       [,1] [,2] [,3] [,4] [,5]
>>> [1,]    1   29   17    8    6
>>> [2,]   21   23   10    7   14
>>> [3,]   22    4   12   26    9
>>> [4,]    3   13   11   30   15
>>> [5,]    5   24   18   16    2
>>> [6,]   20   25   19   27   28
>>>  > trace<-sum(diag(matd))
>>>  > trace
>>> [1] 68
>>>
>>> ## drop this matrix because 68 > 52
>>>
>>> ##  4th  iteration
>>>  > matd<-matrix(sample(1:30,30,replace=FALSE),ncol=5,nrow=6,byrow=FALSE)
>>>  > matd
>>>       [,1] [,2] [,3] [,4] [,5]
>>> [1,]    2    6    5   28   15
>>> [2,]    9   12   13   19   24
>>> [3,]    3   22   14   11   29
>>> [4,]   30   20   17    7   23
>>> [5,]   18   27   21    1   10
>>> [6,]   25   16    4    8   26
>>>  > trace<-sum(diag(matd))
>>>  > trace
>>> [1] 45
>>>
>>> ## accept this matrix because 45 < 52
>>>
>>> The final results will be:
>>> $mat
>>>          trace    iterations
>>> [1,]       53        0
>>> [2,]       52        2
>>> [3,]       45        4
>>>
>>> $ Design_best
>>>
>>>    [,1] [,2] [,3] [,4] [,5]
>>> [1,]    2    6    5   28   15
>>> [2,]    9   12   13   19   24
>>> [3,]    3   22   14   11   29
>>> [4,]   30   20   17    7   23
>>> [5,]   18   27   21    1   10
>>> [6,]   25   16    4    8   26
>>>
>>> $ Original_design
>>>
>>>    [,1] [,2] [,3] [,4] [,5]
>>> [1,]   12   27   29   16   19
>>> [2,]   25   10    7   22   13
>>> [3,]   14   23    3   11   21
>>> [4,]   28    6    5    2   18
>>> [5,]   24   20    1   17   26
>>> [6,]    9    4   30    8   15
>>>
>>> Regards,
>>> Laz
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From arne.henningsen at gmail.com  Sun Oct 20 23:00:32 2013
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Sun, 20 Oct 2013 23:00:32 +0200
Subject: [R] MaxLik estimation issues
In-Reply-To: <BLU0-SMTP390D710EFF7793A71ED8204DE1A0@phx.gbl>
References: <BLU0-SMTP6815963BC2241F40F0D22BDE2F0@phx.gbl>
	<CAMTWbJiVL1yP2A7Mt+dykC+Bm8-6=C9n4cbEDwJ5mdA=YebBXQ@mail.gmail.com>
	<BLU0-SMTP390D710EFF7793A71ED8204DE1A0@phx.gbl>
Message-ID: <CAMTWbJiyvpKms=y+UEzuYjS5JbFZSh2nvarS0xKQvnsP4w5anw@mail.gmail.com>

Dear Filipe

On 14 October 2013 17:42, Filipe Ribeiro <flipjribeiro at hotmail.com> wrote:
> Dear Arne,
>
> First of all, thank you very much for your reply. Secondly, please accept my
> apologies for only give you an answer now, but I was moving from one country
> to another and only today I was able to get back to work.
> I did not write the model specification because it was just a trial, but my
> main idea was to apply the "Nelder-Mead" model.
> Since the beginning my guess was that something is wrong with the
> log-likelihood function, however, I don't find any problem with the same
> exact function applying the "optim" function:
>
> loglike.GGompi <- function(theta,age,deaths,exposures) {
>   alpha <- exp(theta[1])
>   beta <- exp(theta[2])
>   gamma <- exp(theta[3])
>   first <- alpha*exp(beta*age)
>   second <- 1+(((alpha*gamma)/beta)*(exp(beta*age)-1))
>   mu <- first/second
>   llk <- -sum((deaths * log(mu)) + (- mu*exposures))
>   return(llk)
> }
>
>
> fit1 <- optim(par=c(-4.1402817, -0.6375773, -1.6945914),
>               loglike.GGompi,
>               age=0:6,
>               deaths=c(15545, 21278, 32444, 36201, 30360, 14201, 5198),
>               exposures=c(935023.67, 819392.00, 724568.17, 470947.00,
>                           231951.64, 69502.65, 15798.72))
>
> exp(fit1$par)
>
>> exp(fit1$par)
> [1] 0.01585683 0.53471945 0.25368426
>
> Due to this results I can't understand why...

Please note that optim() is (by default) *minimizing* the provided
function, while maxLik() is *maximizing* the provided log-likelihood
function.

Cheers,
Arne



> A 26/09/2013, ?s 05:28, Arne Henningsen escreveu:
>
> Dear Filipe
>
> On 25 September 2013 14:23, Filipe Ribeiro <flipjribeiro at hotmail.com> wrote:
>
> Hello everybody!
>
>
> I'm having some trouble to compute maximum likelihood
>
> estimations using maxLik package and I hope that you
>
> could give me a hint.
>
> The main problem is that I'm not able to get a result not
>
> even close to the ones given by glm() directly, and the
>
> second one is: "Error in maxNRCompute(fn = logLikAttr,
>
> fnOrig = fn, gradOrig = grad, hessOrig = hess, : NA in
>
> gradient".
>
>
> The codes:
>
> loglike.GGompiMaxLik <- function(theta,age,deaths,exposures) {
>
> alpha <- exp(theta[1])
>
> beta <- exp(theta[2])
>
> gamma <- exp(theta[3])
>
> first <- alpha*exp(beta*age)
>
> second <- 1+(((alpha*gamma)/beta)*(exp(beta*age)-1))
>
> mu <- first/second
>
> llk <- -sum((deaths * log(mu)) + (- mu*exposures))
>
> return(llk)
>
> }
>
>
>
> fit1 <- maxLik(loglike.GGompiMaxLik,
>
>              age=0:6,
>
>              deaths=c(15545, 21278, 32444, 36201, 30360, 14201, 5198),
>
>              exposures=c(935023.67, 819392.00, 724568.17, 470947.00,
>
> 231951.64, 69502.65, 15798.72),
>
>              start=c(-4.1402817, -0.6375773, -1.6945914))
>
>
> Do you know how I can solve this problem?
>
>
> You did not write which model specification you want to estimate but I
> am pretty sure that something in your log-likelihood function is
> incorrect. The log-likelihood value at the starting values of the
> parameters is so large that R even cannot calculate the likelihood
> value:
>
> a <- loglike.GGompiMaxLik(c(-4.1402817, -0.6375773, -1.6945914), age=0:6,
>
> +     deaths=c(15545, 21278, 32444, 36201, 30360, 14201, 5198),
> +     exposures=c(935023.67, 819392.00, 724568.17, 470947.00,
> +      231951.64, 69502.65, 15798.72))
>
> a
>
> [1] 580365.2
>
> exp(a)
>
> [1] Inf
>
> In the second iteration, the first parameter gets so small (large in
> absolute terms, -5e+10) that the log-likelihood value become extremely
> (numerically infinitely) large and the gradients cannot be computed
> (by the finite-difference method):
>
> fit1 <- maxLik(loglike.GGompiMaxLik,
>
> +     age=0:6,
> +     deaths=c(15545, 21278, 32444, 36201, 30360, 14201, 5198),
> +     exposures=c(935023.67, 819392.00, 724568.17, 470947.00,
> +         231951.64, 69502.65, 15798.72),
> +     start=c(-4.1402817, -0.6375773, -1.6945914))
> Iteration 2
> Parameter:
> [1] -5.174233e+10 -3.839076e+02  5.988668e+00
> Gradient:
>     [,1] [,2] [,3]
> [1,]  NaN  NaN  NaN
> Error in maxNRCompute(fn = logLikAttr, fnOrig = fn, gradOrig = grad,
> hessOrig = hess,  :
>  NA in gradient
>
> b <- loglike.GGompiMaxLik(c(-5.174233e+10, -3.839076e+02, 5.988668e+00),
> age=0:6,
>
> +     deaths=c(15545, 21278, 32444, 36201, 30360, 14201, 5198),
> +     exposures=c(935023.67, 819392.00, 724568.17, 470947.00,
> +         231951.64, 69502.65, 15798.72))
>
> b
>
> [1] Inf
>
> Please note that you can also find hints and ask questions about the
> maxLik package in the forums at maxLik's R-Forge site:
>
> https://r-forge.r-project.org/projects/maxlik/
>
> ...and please do not forget to cite the maxLik package in your publications:
>
> http://cran.r-project.org/web/packages/maxLik/citation.html
>
> Best wishes,
> Arne



-- 
Arne Henningsen
http://www.arne-henningsen.name


From jdnewmil at dcn.davis.ca.us  Sun Oct 20 23:11:25 2013
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 20 Oct 2013 14:11:25 -0700 (PDT)
Subject: [R] Loop for taking sum of rows based on proximity to other
 non-NA rows
In-Reply-To: <1382157111.46359.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1382127564.35830.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1382157111.46359.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <alpine.BSF.2.00.1310201358390.8581@pedal.dcn.davis.ca.us>

I thought this question looked interesting enough to make my own stab at 
it, but in hindsight I think this business of combining the counts seems 
quite unlikely to be necessary... it would be simpler and less damaging to 
the original data pattern to just remove groups of rows having fewer than 
"N" NAs.

removeNNAs <- function( dat, N, lessOrEqual=FALSE ) {
   N1 <- N+1
   rx <- rle( !is.na( dat$Count ) )
   # indexes of the ends of each run of NAs or non-NAs
   cs <- cumsum( rx$lengths )
   # indexes of the ends of runs of NAs or non-NAs
   cs2 <- cs[ !rx$values ]
   # If the first Count is NA, then drop first run of NAs
   if ( !rx$values[1] ) {
     cs2 <- cs2[ -1 ]
   }
   # If the last Count is NA, then drop last run of NAs
   if ( !rx$values[ length( rx$values ) ] ) {
     cs2 <- cs2[ -length( cs2 ) ]
   }
   # cs2 is indexes of rows to potentially receive deleted Counts
   # after collapse
   cs2 <- cs2 + 1
   # cs1 is indexes of non-NA Counts to be deleted
   cs1 <- cs[ rx$values ][ seq.int( length( cs2 ) ) ]
   # identify the indexes of the Count values before the strings
   # of NAs that meet the criteria
   if ( lessOrEqual ) {
     idx0 <- N1 >= ( cs2 - cs1 )
   } else {
     idx0 <- N1 == ( cs2 - cs1 )
   }
   idx1 <- cs1[ idx0 ]
   # identify the indexes of the Count values after the strings of
   # NAs that meet the criteria
   idx2 <- cs2[ idx0 ]
   # Identify which indexes are both sources and destinations
   idx1c <-c( idx2[ -length( idx2 ) ] == idx1[ -1 ], FALSE )
   # identify groups of indexes that need to be merged
   idx1g <- rev( cumsum( rev( !idx1c ) ) )
   # find which elements of idx1 represent the beginning of a
   # sequence of indexes to be replaced (meta-indexes)
   srcmidxs <- which( -1 == diff( c( idx1g[ 1 ] + 1, idx1g ) ) )
   # find which elements of idx2 represent the end of a sequence
   # to be  replaced (meta-indexes)
   destmidxs <- which( 1 == rev( diff( rev( c( idx1g, 0 ) ) ) ) )
   # add counts from before NAs to destination rows
   result <- dat
   srcidxList <- vector( mode="list", length=length( destmidxs ) )
   for ( i in seq.int( length( destmidxs ) ) ) {
     # row to which data will be copied
     destidx <- idx2[ destmidxs[ i ] ]
     # sequence of indexes of source rows
     srcidxss <- seq.int( from=idx1[ srcmidxs[ i ] ], to=destidx - 1 )
     result[ destidx, "Count" ] <- ( dat[ destidx, "Count" ]
                        + sum( dat[ srcidxss, "Count" ], na.rm=TRUE )
     # keep a list of indexes to be removed
     srcidxList[ i ] <- list( srcidxss )
   }
   # remove source rows
   result <- result[ -unlist( srcidxList ), ]
   result
}


On Fri, 18 Oct 2013, arun wrote:

>
>
> Hi,
>
> Found a bug in the function when tested.? So, try this (added one more line):
>
> #Modified function
> fun1 <- function(dat,n) {
> ?rl <- rle(is.na(dat[,"Count"]))
> indx <- which(is.na(dat[,"Count"]))[rep(rl$lengths[rl$values],rl$lengths[rl$values])==n]
> ?lst1 <- lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) {
> ???????????????????????? x1 <- dat[c(min(x)-1L,x,max(x)+1L),]
> ???????????????????? x2 <- x1[!is.na(x1$Count),]
> ???????????????????? datN <- data.frame(Position=max(x2$Position),Count=sum(x2$Count))
> ???????????????????? rowN <- row.names(x2)[x2$Position %in% max(x2$Position)]??
> ???????????????????? row.names(datN) <- if(length(rowN)>1) rowN[1] else rowN
> ???????????????????? datN
> ??????????????????? })
> names(lst1) <- NULL
> lst1 <- lst1[!duplicated(sapply(lst1,row.names))] ######added
> dat2 <- do.call(rbind,lst1)
> indx2 <-? sort(unlist(lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) c(min(x)-1L,x,c(max(x)+1L))),use.names=FALSE))
>
> dat1New <- dat[-indx2[!indx2 %in% row.names(dat2)],]
> dat1New[match(row.names(dat2),row.names(dat1New)),] <- dat2
> row.names(dat1New) <- 1:nrow(dat1New)
> dat1New
> }
>
>
>
> #Another function
> fun2 <- function(dat,n){
> ?indx <- cumsum(c(1,abs(diff(is.na(dat[,"Count"])))))
> ?indx1 <- indx[is.na(dat[,"Count"])]
> ?names(indx1) <- which(is.na(dat[,"Count"]))
> indx2 <- indx1[indx1 %in% names(table(indx1))[table(indx1)==n]]
> lst1 <- tapply(seq_along(indx2),list(indx2),FUN=function(i) {
> ??? ??? ??? ??? ??? ??? ??? x1 <- indx2[i]
> ??? ??? ??? ??? ??? ??? ??? ?x2 <- as.numeric(names(x1))
> ??? ??? ??? ??? ??? ??? ??? ?x3 <- dat[c(min(x2)-1L,x2,max(x2)+1L),]
> ??? ??? ??? ??? ??? ??? ??? ?x4 <- subset(x3, !is.na(Count))
> ??? ??? ??? ??? ??? ??? ??? ?x5 <- data.frame(Position=max(x4$Position),Count=sum(x4$Count))
> ??? ??? ??? ??? ??? ??? ??? ind <- x4$Position %in% max(x4$Position)
> ??? ??? ??? ??? ??? ??? ??? ?row.names(x5) <- if(sum(ind)>1) row.names(x4)[ind][1] else row.names(x4)[ind]
> ??? ??? ??? ??? ??? ??? ??? x5
> ??? ??? ??? ??? ??? ??? })
> attr(lst1,"dimnames") <- NULL
> ?dat2 <- do.call(rbind,lst1)
> indx3 <- sort(unlist(tapply(seq_along(indx2),list(indx2),FUN=function(i) {x1 <- indx2[i]
> ??? ??? ??? ??? ??? ??? ??? ??? ??? ?x2 <- as.numeric(names(x1))
> ??? ??? ??? ??? ??? ??? ??? ??? ??? ?c(min(x2)-1L, x2, max(x2)+1L)}),use.names=FALSE))
>
> dat$id <- 1:nrow(dat)
> dat2$id <- as.numeric(row.names(dat2))
> library(plyr)
> res <- join(dat,dat2[,-1],by="id",type="left")
> res1 <- res[!((row.names(res) %in% indx3) & is.na(res[,4])),]
> res1[,2][!is.na(res1[,4])] <- res1[,4][!is.na(res1[,4])]
> res2 <- res1[,1:2]
> row.names(res2) <- 1:nrow(res2)
> res2
> }
>
>
> identical(fun1(dat1,1),fun2(dat1,1))
> #[1] TRUE
> identical(fun1(fun1(dat1,1),2),fun2(fun2(dat1,1),2))
> #[1] TRUE
>
> identical(fun1(fun1(fun1(dat1,1),2),3),fun2(fun2(fun2(dat1,1),2),3))
> #[1] TRUE
>
>
> #Speed
> set.seed(185)
> datT <- data.frame(Position = sample(10:80,1e5,replace=TRUE),Count= sample(c(NA, 10:100),1e5, replace=TRUE))
> ?system.time(res <- fun1(datT,1))
> ?#? user? system elapsed
> ?# 0.676?? 0.000?? 0.676
> ?system.time(res2 <- fun2(datT,1))
> #?? user? system elapsed
> #? 1.240?? 0.000?? 1.237
> ?identical(res,res2)
> #[1] TRUE
>
> A.K.
>
>
>
>
>
>
>
>
>
> On Friday, October 18, 2013 4:19 PM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
>
> May be this helps:
>
> dat1 <- structure(list(Position = c(15L, 22L, 38L, 49L, 55L, 61L, 62L,
> 14L, 29L, 63L, 46L, 22L, 18L, 24L, 22L, 49L, 42L, 38L, 29L, 22L,
> 29L, 23L, 42L), Count = c(15L, NA, NA, 5L, NA, 17L, 18L, NA,
> NA, NA, 8L, NA, 20L, NA, NA, 16L, 19L, NA, NA, NA, 13L, NA, 33L
> )), .Names = c("Position", "Count"), class = "data.frame", row.names = c(NA,
> -23L))
>
>
> #There might be simple solutions.
>
> fun1 <- function(dat,n) {
> ?rl <- rle(is.na(dat[,"Count"]))
> indx <- which(is.na(dat[,"Count"]))[rep(rl$lengths[rl$values],rl$lengths[rl$values])==n]
> ?lst1 <- lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) {
> ??? ??? ??? ??? ???????? x1 <- dat[c(min(x)-1L,x,max(x)+1L),]
> ??? ??? ??? ??? ??? ?x2 <- x1[!is.na(x1$Count),]
> ??? ??? ??? ??? ??? ?datN <- data.frame(Position=max(x2$Position),Count=sum(x2$Count))
> ??? ??? ??? ??? ??? ?rowN <- row.names(x2)[x2$Position %in% max(x2$Position)]???
> ??? ??? ??? ??? ??? ?row.names(datN) <- if(length(rowN)>1) rowN[1] else rowN
> ??? ??? ??? ??? ??? ?datN
> ??? ??? ??? ??? ??? })
> names(lst1) <- NULL
> dat2 <- do.call(rbind,lst1)
> indx2 <-? sort(unlist(lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) c(min(x)-1L,x,c(max(x)+1L))),use.names=FALSE))
>
> dat1New <- dat[-indx2[!indx2 %in% row.names(dat2)],]
> dat1New[match(row.names(dat2),row.names(dat1New)),] <- dat2
> row.names(dat1New) <- 1:nrow(dat1New)
> dat1New
> }
>
> dat1N <- fun1(dat1,1)
> dat1N
> ?? Position Count
> 1??????? 15??? 15
> 2??????? 22??? NA
> 3??????? 38??? NA
> 4??????? 61??? 22
> 5??????? 62??? 18
> 6??????? 14??? NA
> 7??????? 29??? NA
> 8??????? 63??? NA
> 9??????? 46??? 28
> 10?????? 24??? NA
> 11?????? 22??? NA
> 12?????? 49??? 16
> 13?????? 42??? 19
> 14?????? 38??? NA
> 15?????? 29??? NA
> 16?????? 22??? NA
> 17?????? 42??? 46
>
> dat2N <- fun1(dat1N,2)
> dat2N
> ?? Position Count
> 1??????? 61??? 37
> 2??????? 62??? 18
> 3??????? 14??? NA
> 4??????? 29??? NA
> 5??????? 63??? NA
> 6??????? 49??? 44
> 7??????? 42??? 19
> 8??????? 38??? NA
> 9??????? 29??? NA
> 10?????? 22??? NA
> 11?????? 42??? 46
> dat3N <- fun1(dat2N,3)
> dat3N
> ? Position Count
> 1?????? 61??? 37
> 2?????? 62??? 62
> 3?????? 42??? 65
>
> A.K.
>
>
>
>
>
>
>
>
>
> Hi all, I have a dataset with 2 important columns, "Position" and
> "Count". There are a total of 34,532 rows, but only 457 non-NA values in the "Count" column (every cell in "Position" column has a value). I
> need to write a loop to march down the rows, and if there are 2 rows in
> "Count" where there is only 1 NA row between them, sum the two values up and print only one row with the summed Count value and the Position
> value that corresponds to the larger Count value, thus making the three
> rows into one. For example:
>
> Position Count
> 15 15
> 22 NA
> 38 NA
> 49 5
> 55 NA
> 61 17
>
> would become
>
> Position Count
> 15 15
> 22 NA
> 38 NA
> 61 22
>
> After this step, I also need to write another script to march
> down the rows and look for rows with only two NA's between non-NA rows
> in Count. This would make the previous data become
>
> Position Count
> 61 37
>
> Ideally I would like a loop that can be flexibly adjusted to the
> number of NA's in between adjacent non-NA values that can be freely
> changed. I would greatly appreciate any insight for this.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From eliza_botto at hotmail.com  Sun Oct 20 23:26:38 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Sun, 20 Oct 2013 21:26:38 +0000
Subject: [R] bold dot size and name in plot
In-Reply-To: <1382243469.80741.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <BLU170-W1003E188F13E7E734C92E3089070@phx.gbl>,
	<1382243469.80741.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <BLU170-W121071F4882A270E4AB6A0089000@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131020/e51d2d22/attachment.pl>

From oreslag at gmail.com  Mon Oct 21 00:01:44 2013
From: oreslag at gmail.com (Steven LeBlanc)
Date: Sun, 20 Oct 2013 15:01:44 -0700
Subject: [R] nlminb() - how do I constrain the parameter vector properly?
Message-ID: <2F4EF2C2-6C30-41C7-908C-FFCAE8A0C02E@gmail.com>

Greets,

I'm trying to use nlminb() to estimate the parameters of a bivariate normal sample and during one of the iterations it passes a parameter vector to the likelihood function resulting in an invalid covariance matrix that causes dmvnorm() to throw an error. Thus, it seems I need to somehow communicate to nlminb() that the final three parameters in my parameter vector are used to construct a positive semi-definite matrix, but I can't see how to achieve this using the constraint mechanism provided. Additional details are provided in the code below.

Suggestions?

Best Regards,
Steven

Generate the data set I'm using:

mu<-c(1,5)
sigma<-c(1,2,2,6)
dim(sigma)<-c(2,2)
set.seed(83165026)
sample.full<-sample.deleted<-mvrnorm(50,mu,sigma)
delete.one<-c(1,5,13,20)
delete.two<-c(3,11,17,31,40,41)
sample.deleted[delete.one,1]<-NA
sample.deleted[delete.two,2]<-NA
missing<-c(delete.one,delete.two)
complete<-sample.deleted[!(is.na(sample.deleted[,1]) | is.na(sample.deleted[,2])),]
deleted<-sample.deleted[missing,]

Try to estimate the parameters of the data set less the deleted values:

exact<-function(theta,complete,deleted){
    one.only<-deleted[!(is.na(deleted[,1])),1]
    two.only<-deleted[!(is.na(deleted[,2])),2]
    u<-c(theta[1],theta[2])
    sigma<-c(theta[3],theta[5],theta[5],theta[4])
    dim(sigma)<-c(2,2)
    -sum(log(dmvnorm(x=complete,mean=u,sigma=sigma)))-
        sum(log(dnorm(one.only,u[1],sigma[1,1])))-
            sum(log(dnorm(two.only,u[2],sigma[2,2])))
}
nlminb(start=c(0,0,1,1,0),objective=exact,complete=complete,deleted=deleted,control=list(trace=1))

Escape and it stops at Iteration 9 on my machine.

From jdnewmil at dcn.davis.ca.us  Mon Oct 21 01:49:32 2013
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 20 Oct 2013 16:49:32 -0700 (PDT)
Subject: [R] Loop for taking sum of rows based on proximity to other
 non-NA rows
In-Reply-To: <alpine.BSF.2.00.1310201358390.8581@pedal.dcn.davis.ca.us>
References: <1382127564.35830.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1382157111.46359.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<alpine.BSF.2.00.1310201358390.8581@pedal.dcn.davis.ca.us>
Message-ID: <alpine.BSF.2.00.1310201648260.45901@pedal.dcn.davis.ca.us>

Looks like a right parenthesis was dropped. Corrected:

removeNNAs <- function( dat, N, lessOrEqual=FALSE ) {
   N1 <- N+1
   rx <- rle( !is.na( dat$Count ) )
   # indexes of the ends of each run of NAs or non-NAs
   cs <- cumsum( rx$lengths )
   # indexes of the ends of runs of NAs or non-NAs
   cs2 <- cs[ !rx$values ]
   # If the first Count is NA, then drop first run of NAs
   if ( !rx$values[1] ) {
     cs2 <- cs2[ -1 ]
   }
   # If the last Count is NA, then drop last run of NAs
   if ( !rx$values[ length( rx$values ) ] ) {
     cs2 <- cs2[ -length( cs2 ) ]
   }
   # cs2 is indexes of rows to potentially receive deleted Counts
   # after collapse
   cs2 <- cs2 + 1
   # cs1 is indexes of non-NA Counts to be deleted
   cs1 <- cs[ rx$values ][ seq.int( length( cs2 ) ) ]
   # identify the indexes of the Count values before the strings
   # of NAs that meet the criteria
   if ( lessOrEqual ) {
     idx0 <- N1 >= ( cs2 - cs1 )
   } else {
     idx0 <- N1 == ( cs2 - cs1 )
   }
   idx1 <- cs1[ idx0 ]
   # identify the indexes of the Count values after the strings of
   # NAs that meet the criteria
   idx2 <- cs2[ idx0 ]
   # Identify which indexes are both sources and destinations
   idx1c <-c( idx2[ -length( idx2 ) ] == idx1[ -1 ], FALSE )
   # identify groups of indexes that need to be merged
   idx1g <- rev( cumsum( rev( !idx1c ) ) )
   # find which elements of idx1 represent the beginning of a
   # sequence of indexes to be replaced (meta-indexes)
   srcmidxs <- which( -1 == diff( c( idx1g[ 1 ] + 1, idx1g ) ) )
   # find which elements of idx2 represent the end of a sequence
   # to be  replaced (meta-indexes)
   destmidxs <- which( 1 == rev( diff( rev( c( idx1g, 0 ) ) ) ) )
   # add counts from before NAs to destination rows
   result <- dat
   srcidxList <- vector( mode="list", length=length( destmidxs ) )
   for ( i in seq.int( length( destmidxs ) ) ) {
     # row to which data will be copied
     destidx <- idx2[ destmidxs[ i ] ]
     # sequence of indexes of source rows
     srcidxss <- seq.int( from=idx1[ srcmidxs[ i ] ], to=destidx - 1 )
     result[ destidx, "Count" ] <- ( dat[ destidx, "Count" ]
                     + sum( dat[ srcidxss, "Count" ], na.rm=TRUE ) )
     # keep a list of indexes to be removed
     srcidxList[ i ] <- list( srcidxss )
   }
   # remove source rows
   result <- result[ -unlist( srcidxList ), ]
   result
}


On Sun, 20 Oct 2013, Jeff Newmiller wrote:

> I thought this question looked interesting enough to make my own stab at it, 
> but in hindsight I think this business of combining the counts seems quite 
> unlikely to be necessary... it would be simpler and less damaging to the 
> original data pattern to just remove groups of rows having fewer than "N" 
> NAs.
>
> removeNNAs <- function( dat, N, lessOrEqual=FALSE ) {
>  N1 <- N+1
>  rx <- rle( !is.na( dat$Count ) )
>  # indexes of the ends of each run of NAs or non-NAs
>  cs <- cumsum( rx$lengths )
>  # indexes of the ends of runs of NAs or non-NAs
>  cs2 <- cs[ !rx$values ]
>  # If the first Count is NA, then drop first run of NAs
>  if ( !rx$values[1] ) {
>    cs2 <- cs2[ -1 ]
>  }
>  # If the last Count is NA, then drop last run of NAs
>  if ( !rx$values[ length( rx$values ) ] ) {
>    cs2 <- cs2[ -length( cs2 ) ]
>  }
>  # cs2 is indexes of rows to potentially receive deleted Counts
>  # after collapse
>  cs2 <- cs2 + 1
>  # cs1 is indexes of non-NA Counts to be deleted
>  cs1 <- cs[ rx$values ][ seq.int( length( cs2 ) ) ]
>  # identify the indexes of the Count values before the strings
>  # of NAs that meet the criteria
>  if ( lessOrEqual ) {
>    idx0 <- N1 >= ( cs2 - cs1 )
>  } else {
>    idx0 <- N1 == ( cs2 - cs1 )
>  }
>  idx1 <- cs1[ idx0 ]
>  # identify the indexes of the Count values after the strings of
>  # NAs that meet the criteria
>  idx2 <- cs2[ idx0 ]
>  # Identify which indexes are both sources and destinations
>  idx1c <-c( idx2[ -length( idx2 ) ] == idx1[ -1 ], FALSE )
>  # identify groups of indexes that need to be merged
>  idx1g <- rev( cumsum( rev( !idx1c ) ) )
>  # find which elements of idx1 represent the beginning of a
>  # sequence of indexes to be replaced (meta-indexes)
>  srcmidxs <- which( -1 == diff( c( idx1g[ 1 ] + 1, idx1g ) ) )
>  # find which elements of idx2 represent the end of a sequence
>  # to be  replaced (meta-indexes)
>  destmidxs <- which( 1 == rev( diff( rev( c( idx1g, 0 ) ) ) ) )
>  # add counts from before NAs to destination rows
>  result <- dat
>  srcidxList <- vector( mode="list", length=length( destmidxs ) )
>  for ( i in seq.int( length( destmidxs ) ) ) {
>    # row to which data will be copied
>    destidx <- idx2[ destmidxs[ i ] ]
>    # sequence of indexes of source rows
>    srcidxss <- seq.int( from=idx1[ srcmidxs[ i ] ], to=destidx - 1 )
>    result[ destidx, "Count" ] <- ( dat[ destidx, "Count" ]
>                       + sum( dat[ srcidxss, "Count" ], na.rm=TRUE )
>    # keep a list of indexes to be removed
>    srcidxList[ i ] <- list( srcidxss )
>  }
>  # remove source rows
>  result <- result[ -unlist( srcidxList ), ]
>  result
> }
>
>
> On Fri, 18 Oct 2013, arun wrote:
>
>> 
>> 
>> Hi,
>> 
>> Found a bug in the function when tested.? So, try this (added one more 
>> line):
>> 
>> #Modified function
>> fun1 <- function(dat,n) {
>> ?rl <- rle(is.na(dat[,"Count"]))
>> indx <- 
>> which(is.na(dat[,"Count"]))[rep(rl$lengths[rl$values],rl$lengths[rl$values])==n]
>> ?lst1 <- lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) {
>> ???????????????????????? x1 <- dat[c(min(x)-1L,x,max(x)+1L),]
>> ???????????????????? x2 <- x1[!is.na(x1$Count),]
>> ???????????????????? datN <- 
>> data.frame(Position=max(x2$Position),Count=sum(x2$Count))
>> ???????????????????? rowN <- row.names(x2)[x2$Position %in% 
>> max(x2$Position)]??
>> ???????????????????? row.names(datN) <- if(length(rowN)>1) rowN[1] else 
>> rowN
>> ???????????????????? datN
>> ??????????????????? })
>> names(lst1) <- NULL
>> lst1 <- lst1[!duplicated(sapply(lst1,row.names))] ######added
>> dat2 <- do.call(rbind,lst1)
>> indx2 <-? 
>> sort(unlist(lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) 
>> c(min(x)-1L,x,c(max(x)+1L))),use.names=FALSE))
>> 
>> dat1New <- dat[-indx2[!indx2 %in% row.names(dat2)],]
>> dat1New[match(row.names(dat2),row.names(dat1New)),] <- dat2
>> row.names(dat1New) <- 1:nrow(dat1New)
>> dat1New
>> }
>> 
>> 
>> 
>> #Another function
>> fun2 <- function(dat,n){
>> ?indx <- cumsum(c(1,abs(diff(is.na(dat[,"Count"])))))
>> ?indx1 <- indx[is.na(dat[,"Count"])]
>> ?names(indx1) <- which(is.na(dat[,"Count"]))
>> indx2 <- indx1[indx1 %in% names(table(indx1))[table(indx1)==n]]
>> lst1 <- tapply(seq_along(indx2),list(indx2),FUN=function(i) {
>> ??? ??? ??? ??? ??? ??? ??? x1 <- indx2[i]
>> ??? ??? ??? ??? ??? ??? ??? ?x2 <- as.numeric(names(x1))
>> ??? ??? ??? ??? ??? ??? ??? ?x3 <- dat[c(min(x2)-1L,x2,max(x2)+1L),]
>> ??? ??? ??? ??? ??? ??? ??? ?x4 <- subset(x3, !is.na(Count))
>> ??? ??? ??? ??? ??? ??? ??? ?x5 <- 
>> data.frame(Position=max(x4$Position),Count=sum(x4$Count))
>> ??? ??? ??? ??? ??? ??? ??? ind <- x4$Position %in% max(x4$Position)
>> ??? ??? ??? ??? ??? ??? ??? ?row.names(x5) <- if(sum(ind)>1) 
>> row.names(x4)[ind][1] else row.names(x4)[ind]
>> ??? ??? ??? ??? ??? ??? ??? x5
>> ??? ??? ??? ??? ??? ??? })
>> attr(lst1,"dimnames") <- NULL
>> ?dat2 <- do.call(rbind,lst1)
>> indx3 <- sort(unlist(tapply(seq_along(indx2),list(indx2),FUN=function(i) 
>> {x1 <- indx2[i]
>> ??? ??? ??? ??? ??? ??? ??? ??? ??? ?x2 <- as.numeric(names(x1))
>> ??? ??? ??? ??? ??? ??? ??? ??? ??? ?c(min(x2)-1L, x2, 
>> max(x2)+1L)}),use.names=FALSE))
>> 
>> dat$id <- 1:nrow(dat)
>> dat2$id <- as.numeric(row.names(dat2))
>> library(plyr)
>> res <- join(dat,dat2[,-1],by="id",type="left")
>> res1 <- res[!((row.names(res) %in% indx3) & is.na(res[,4])),]
>> res1[,2][!is.na(res1[,4])] <- res1[,4][!is.na(res1[,4])]
>> res2 <- res1[,1:2]
>> row.names(res2) <- 1:nrow(res2)
>> res2
>> }
>> 
>> 
>> identical(fun1(dat1,1),fun2(dat1,1))
>> #[1] TRUE
>> identical(fun1(fun1(dat1,1),2),fun2(fun2(dat1,1),2))
>> #[1] TRUE
>> 
>> identical(fun1(fun1(fun1(dat1,1),2),3),fun2(fun2(fun2(dat1,1),2),3))
>> #[1] TRUE
>> 
>> 
>> #Speed
>> set.seed(185)
>> datT <- data.frame(Position = sample(10:80,1e5,replace=TRUE),Count= 
>> sample(c(NA, 10:100),1e5, replace=TRUE))
>> ?system.time(res <- fun1(datT,1))
>> ?#? user? system elapsed
>> ?# 0.676?? 0.000?? 0.676
>> ?system.time(res2 <- fun2(datT,1))
>> #?? user? system elapsed
>> #? 1.240?? 0.000?? 1.237
>> ?identical(res,res2)
>> #[1] TRUE
>> 
>> A.K.
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> On Friday, October 18, 2013 4:19 PM, arun <smartpink111 at yahoo.com> wrote:
>> Hi,
>> 
>> May be this helps:
>> 
>> dat1 <- structure(list(Position = c(15L, 22L, 38L, 49L, 55L, 61L, 62L,
>> 14L, 29L, 63L, 46L, 22L, 18L, 24L, 22L, 49L, 42L, 38L, 29L, 22L,
>> 29L, 23L, 42L), Count = c(15L, NA, NA, 5L, NA, 17L, 18L, NA,
>> NA, NA, 8L, NA, 20L, NA, NA, 16L, 19L, NA, NA, NA, 13L, NA, 33L
>> )), .Names = c("Position", "Count"), class = "data.frame", row.names = 
>> c(NA,
>> -23L))
>> 
>> 
>> #There might be simple solutions.
>> 
>> fun1 <- function(dat,n) {
>> ?rl <- rle(is.na(dat[,"Count"]))
>> indx <- 
>> which(is.na(dat[,"Count"]))[rep(rl$lengths[rl$values],rl$lengths[rl$values])==n]
>> ?lst1 <- lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) {
>> ??? ??? ??? ??? ???????? x1 <- dat[c(min(x)-1L,x,max(x)+1L),]
>> ??? ??? ??? ??? ??? ?x2 <- x1[!is.na(x1$Count),]
>> ??? ??? ??? ??? ??? ?datN <- 
>> data.frame(Position=max(x2$Position),Count=sum(x2$Count))
>> ??? ??? ??? ??? ??? ?rowN <- row.names(x2)[x2$Position %in% 
>> max(x2$Position)]???
>> ??? ??? ??? ??? ??? ?row.names(datN) <- if(length(rowN)>1) rowN[1] else 
>> rowN
>> ??? ??? ??? ??? ??? ?datN
>> ??? ??? ??? ??? ??? })
>> names(lst1) <- NULL
>> dat2 <- do.call(rbind,lst1)
>> indx2 <-? 
>> sort(unlist(lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) 
>> c(min(x)-1L,x,c(max(x)+1L))),use.names=FALSE))
>> 
>> dat1New <- dat[-indx2[!indx2 %in% row.names(dat2)],]
>> dat1New[match(row.names(dat2),row.names(dat1New)),] <- dat2
>> row.names(dat1New) <- 1:nrow(dat1New)
>> dat1New
>> }
>> 
>> dat1N <- fun1(dat1,1)
>> dat1N
>> ?? Position Count
>> 1??????? 15??? 15
>> 2??????? 22??? NA
>> 3??????? 38??? NA
>> 4??????? 61??? 22
>> 5??????? 62??? 18
>> 6??????? 14??? NA
>> 7??????? 29??? NA
>> 8??????? 63??? NA
>> 9??????? 46??? 28
>> 10?????? 24??? NA
>> 11?????? 22??? NA
>> 12?????? 49??? 16
>> 13?????? 42??? 19
>> 14?????? 38??? NA
>> 15?????? 29??? NA
>> 16?????? 22??? NA
>> 17?????? 42??? 46
>> 
>> dat2N <- fun1(dat1N,2)
>> dat2N
>> ?? Position Count
>> 1??????? 61??? 37
>> 2??????? 62??? 18
>> 3??????? 14??? NA
>> 4??????? 29??? NA
>> 5??????? 63??? NA
>> 6??????? 49??? 44
>> 7??????? 42??? 19
>> 8??????? 38??? NA
>> 9??????? 29??? NA
>> 10?????? 22??? NA
>> 11?????? 42??? 46
>> dat3N <- fun1(dat2N,3)
>> dat3N
>> ? Position Count
>> 1?????? 61??? 37
>> 2?????? 62??? 62
>> 3?????? 42??? 65
>> 
>> A.K.
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> Hi all, I have a dataset with 2 important columns, "Position" and
>> "Count". There are a total of 34,532 rows, but only 457 non-NA values in 
>> the "Count" column (every cell in "Position" column has a value). I
>> need to write a loop to march down the rows, and if there are 2 rows in
>> "Count" where there is only 1 NA row between them, sum the two values up 
>> and print only one row with the summed Count value and the Position
>> value that corresponds to the larger Count value, thus making the three
>> rows into one. For example:
>> 
>> Position Count
>> 15 15
>> 22 NA
>> 38 NA
>> 49 5
>> 55 NA
>> 61 17
>> 
>> would become
>> 
>> Position Count
>> 15 15
>> 22 NA
>> 38 NA
>> 61 22
>> 
>> After this step, I also need to write another script to march
>> down the rows and look for rows with only two NA's between non-NA rows
>> in Count. This would make the previous data become
>> 
>> Position Count
>> 61 37
>> 
>> Ideally I would like a loop that can be flexibly adjusted to the
>> number of NA's in between adjacent non-NA values that can be freely
>> changed. I would greatly appreciate any insight for this.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From dwinsemius at comcast.net  Mon Oct 21 02:19:07 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 20 Oct 2013 17:19:07 -0700
Subject: [R] nlminb() - how do I constrain the parameter vector properly?
In-Reply-To: <2F4EF2C2-6C30-41C7-908C-FFCAE8A0C02E@gmail.com>
References: <2F4EF2C2-6C30-41C7-908C-FFCAE8A0C02E@gmail.com>
Message-ID: <C304DA7C-7B8B-4A97-94DF-41A24395796F@comcast.net>


On Oct 20, 2013, at 3:01 PM, Steven LeBlanc wrote:

> Greets,
> 
> I'm trying to use nlminb() to estimate the parameters of a bivariate normal sample and during one of the iterations it passes a parameter vector to the likelihood function resulting in an invalid covariance matrix that causes dmvnorm() to throw an error. Thus, it seems I need to somehow communicate to nlminb() that the final three parameters in my parameter vector are used to construct a positive semi-definite matrix, but I can't see how to achieve this using the constraint mechanism provided. Additional details are provided in the code below.
> 

I recently noticed that teh dmvnorn function in package mixtools doe not throw an error when given a non-positive definite varaince-covariance matrix. Whether it should be doing so might be up for debate. Peter Dalgaard seemed to think that any self respecting such function _should_ be throwing NaN's back at you.

The code it was using is rather compact:

> mixtools::dmvnorm
function (y, mu = NULL, sigma = NULL) 
{
    exp(logdmvnorm(y, mu = mu, sigma = sigma))
}
<environment: namespace:mixtools>

> mixtools::logdmvnorm
function (y, mu = NULL, sigma = NULL) 
{
    if (is.vector(y)) 
        y <- matrix(y, nrow = 1)
    d <- ncol(y)
    if (!is.null(mu)) 
        y <- sweep(y, 2, mu, "-")
    if (is.null(sigma)) 
        sigma <- diag(d)
    k <- d * 1.83787706640935
    a <- qr(sigma)
    logdet <- sum(log(abs(diag(a$qr))))
    if (nrow(y) == 1) 
        mahaldist <- as.vector(y %*% qr.solve(a, t(y)))
    else mahaldist <- rowSums((y %*% qr.solve(a)) * y)
    -0.5 * (mahaldist + logdet + k)
}

I noticed that you were logging the dmvnorm values and so I wondered also if going directly to that function might save some time. (Note that I am way out of my mathematical dept here. Caveat emptor, maxima caveat emptor).

-- 
David.

> Suggestions?
> 
> Best Regards,
> Steven
> 
> Generate the data set I'm using:
> 
> mu<-c(1,5)
> sigma<-c(1,2,2,6)
> dim(sigma)<-c(2,2)
> set.seed(83165026)
> sample.full<-sample.deleted<-mvrnorm(50,mu,sigma)
> delete.one<-c(1,5,13,20)
> delete.two<-c(3,11,17,31,40,41)
> sample.deleted[delete.one,1]<-NA
> sample.deleted[delete.two,2]<-NA
> missing<-c(delete.one,delete.two)
> complete<-sample.deleted[!(is.na(sample.deleted[,1]) | is.na(sample.deleted[,2])),]
> deleted<-sample.deleted[missing,]
> 
> Try to estimate the parameters of the data set less the deleted values:
> 
> exact<-function(theta,complete,deleted){
>    one.only<-deleted[!(is.na(deleted[,1])),1]
>    two.only<-deleted[!(is.na(deleted[,2])),2]
>    u<-c(theta[1],theta[2])
>    sigma<-c(theta[3],theta[5],theta[5],theta[4])
>    dim(sigma)<-c(2,2)
>    -sum(log(dmvnorm(x=complete,mean=u,sigma=sigma)))-
>        sum(log(dnorm(one.only,u[1],sigma[1,1])))-
>            sum(log(dnorm(two.only,u[2],sigma[2,2])))
> }
> nlminb(start=c(0,0,1,1,0),objective=exact,complete=complete,deleted=deleted,control=list(trace=1))
> 
> Escape and it stops at Iteration 9 on my machine.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From valentina81c at hotmail.it  Sun Oct 20 17:30:35 2013
From: valentina81c at hotmail.it (valentina colombo)
Date: Sun, 20 Oct 2013 15:30:35 +0000
Subject: [R] =?windows-1256?q?=22Error_=3A_requires_numeric/complex_matrix?=
 =?windows-1256?q?/vector_arguments=FE=22?=
Message-ID: <DUB110-W275914A7EE740EDCC3A1B8BB000@phx.gbl>

Can you post my message?ThanksValentina 		 	   		  
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R error.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131020/4a629ed4/attachment.txt>

From randolph_steven_d at lilly.com  Sun Oct 20 15:23:44 2013
From: randolph_steven_d at lilly.com (Steven Dwayne Randolph)
Date: Sun, 20 Oct 2013 13:23:44 +0000
Subject: [R] XML package not working
In-Reply-To: <5263226B.7070103@gmail.com>
References: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>
	<5263226B.7070103@gmail.com>
Message-ID: <66C71547284587479F8009E05C07DA9704F8E5D2@USTLMLLYC107.RF.lilly.com>

My apologies for not conforming to the posting guideline.


Sys.info()
                     sysname                      release                      version 
                   "Windows"                      "7 x64" "build 7601, Service Pack 1" 
                    nodename                      machine                        login 
           "xxxxxxNU247BZ1S"                     "x86-64"                    "XXXXXX" 
                        user               effective_user 
                   "xxxxxxx"                    "xxxxxxx"

When I attempt to install a local copy of the xml.zip file:

in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) : 
  cannot open the connection
In addition: Warning messages:
1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
  cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Saturday, October 19, 2013 8:23 PM
To: Steven Dwayne Randolph; r-help at r-project.org
Cc: stevendrandolph at aol.com
Subject: Re: [R] XML package not working

On 13-10-19 3:47 PM, Steven Dwayne Randolph wrote:
> I know I  cannot be the only one who is not able to install the XML package from CRAN (zip or tar file)  Many packages depend on this XML package.  Can someone help me either access the source for a good binary?  I have received no assistance from the author/developer of the package.

It installs fine for me.

Duncan Murdoch


From smartpink111 at yahoo.com  Mon Oct 21 03:36:14 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 20 Oct 2013 18:36:14 -0700 (PDT)
Subject: [R] Loop for taking sum of rows based on proximity to other
	non-NA rows
In-Reply-To: <alpine.BSF.2.00.1310201648260.45901@pedal.dcn.davis.ca.us>
References: <1382127564.35830.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1382157111.46359.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<alpine.BSF.2.00.1310201358390.8581@pedal.dcn.davis.ca.us>
	<alpine.BSF.2.00.1310201648260.45901@pedal.dcn.davis.ca.us>
Message-ID: <1382319374.55579.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi Jeff,

I found some difference in results between your function and mine.? It also point out a mistake in my code. In the original post, it says:
""""""""""" 

I need to write a loop to march down the rows, and if there are 2 rows in 
"Count"
 where there is only 1 NA row between them, sum the two values up and 
print only one row with the summed Count value and the Position value that corresponds to the larger Count value, thus making the three 
rows into one.
"""""""""

Sorry, I read it incorrectly the last time and selected the maximum? "Position" value instead of that corresponds to the larger Count value.? 


After correcting the function, there is still some difference between the results. 




##fun1() and fun2() corrected
fun1 <- function(dat,n) {
?rl <- rle(is.na(dat[,"Count"]))
indx <- which(is.na(dat[,"Count"]))[rep(rl$lengths[rl$values],rl$lengths[rl$values])==n]
?lst1 <- lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) {
???????????????????????? x1 <- dat[c(min(x)-1L,x,max(x)+1L),]
???????????????????? x2 <- x1[!is.na(x1$Count),]
???????????????????? datN <- data.frame(Position=x2$Position[x2$Count %in% max(x2$Count)],Count=sum(x2$Count))
???????????????????? rowN <- row.names(x2)[x2$Count %in% max(x2$Count)]?? 
???????????????????? row.names(datN) <- if(length(rowN)>1) rowN[1] else rowN
???????????????????? datN
??????????????????? })
names(lst1) <- NULL
lst1 <- lst1[!duplicated(sapply(lst1,row.names))] ######added
dat2 <- do.call(rbind,lst1)
indx2 <-? sort(unlist(lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) c(min(x)-1L,x,c(max(x)+1L))),use.names=FALSE))

dat1New <- dat[-indx2[!indx2 %in% row.names(dat2)],]
dat1New[match(row.names(dat2),row.names(dat1New)),] <- dat2
row.names(dat1New) <- 1:nrow(dat1New)
dat1New
}


##################################

fun2 <- function(dat,n){
?indx <- cumsum(c(1,abs(diff(is.na(dat[,"Count"])))))
?indx1 <- indx[is.na(dat[,"Count"])]
?names(indx1) <- which(is.na(dat[,"Count"]))
indx2 <- indx1[indx1 %in% names(table(indx1))[table(indx1)==n]]
lst1 <- tapply(seq_along(indx2),list(indx2),FUN=function(i) {
??? ??? ??? ??? ??? ??? ??? x1 <- indx2[i]
??? ??? ??? ??? ??? ??? ??? ?x2 <- as.numeric(names(x1))
??? ??? ??? ??? ??? ??? ??? ?x3 <- dat[c(min(x2)-1L,x2,max(x2)+1L),]
??? ??? ??? ??? ??? ??? ??? ?x4 <- subset(x3, !is.na(Count))
??? ??? ??? ??? ??? ??? ??? ?x5 <- data.frame(Position=x4$Position[x4$Count %in% max(x4$Count)],Count=sum(x4$Count))
??? ??? ??? ??? ??? ??? ??? ind <- x4$Count %in% max(x4$Count)
??? ??? ??? ??? ??? ??? ??? ?row.names(x5) <- if(sum(ind)>1) row.names(x4)[ind][1] else row.names(x4)[ind]
??? ??? ??? ??? ??? ??? ??? x5
??? ??? ??? ??? ??? ??? })
attr(lst1,"dimnames") <- NULL
?dat2 <- do.call(rbind,lst1)
indx3 <- sort(unlist(tapply(seq_along(indx2),list(indx2),FUN=function(i) {x1 <- indx2[i]
??? ??? ??? ??? ??? ??? ??? ??? ??? ?x2 <- as.numeric(names(x1))
??? ??? ??? ??? ??? ??? ??? ??? ??? ?c(min(x2)-1L, x2, max(x2)+1L)}),use.names=FALSE))

dat$id <- 1:nrow(dat)
dat2$id <- as.numeric(row.names(dat2))
library(plyr)
res <- join(dat,dat2[,-1],by="id",type="left")
res1 <- res[!((row.names(res) %in% indx3) & is.na(res[,4])),]
res1[,2][!is.na(res1[,4])] <- res1[,4][!is.na(res1[,4])]
res2 <- res1[,1:2]
row.names(res2) <- 1:nrow(res2)
res2
}


dat1 <- structure(list(Position = c(15L, 22L, 38L, 49L, 55L, 61L, 62L,
14L, 29L, 63L, 46L, 22L, 18L, 24L, 22L, 49L, 42L, 38L, 29L, 22L,
29L, 23L, 42L), Count = c(15L, NA, NA, 5L, NA, 17L, 18L, NA,
NA, NA, 8L, NA, 20L, NA, NA, 16L, 19L, NA, NA, NA, 13L, NA, 33L
)), .Names = c("Position", "Count"), class = "data.frame", row.names = c(NA,
-23L))

fun1(dat1,1)
?? Position Count
1??????? 15??? 15
2??????? 22??? NA
3??????? 38??? NA
4??????? 61??? 22
5??????? 62??? 18
6??????? 14??? NA
7??????? 29??? NA
8??????? 63??? NA
9??????? 18??? 28? ###
10?????? 24??? NA
11?????? 22??? NA
12?????? 49??? 16 ####
13?????? 42??? 19
14?????? 38??? NA
15?????? 29??? NA
16?????? 22??? NA
17?????? 42??? 46
removeNNAs(dat1,1) #gets similar results

#but,

?fun1(fun1(dat1,1),2)
?? Position Count
1??????? 61??? 37
2??????? 62??? 18
3??????? 14??? NA
4??????? 29??? NA
5??????? 63??? NA
6??????? 18??? 44 #######different
7??????? 42??? 19
8??????? 38??? NA
9??????? 29??? NA
10?????? 22??? NA
11?????? 42??? 46
?
?removeNNAs(dat1,2,lessOrEqual=TRUE)
?? Position Count
6??????? 61??? 37
7??????? 62??? 18
8??????? 14??? NA
9??????? 29??? NA
10?????? 63??? NA
16?????? 49??? 44 ###### different
17?????? 42??? 19
18?????? 38??? NA
19?????? 29??? NA
20?????? 22??? NA
23?????? 42??? 46
> 




removeNNAs(dat1,3,lessOrEqual=TRUE)
?? Position Count
6??????? 61??? 37
16?????? 49??? 62
23?????? 42??? 65
?fun1(fun1(fun1(dat1,1),2),3)
? Position Count
1?????? 61??? 37
2?????? 18??? 62
3?????? 42??? 65





A.K.


On Sunday, October 20, 2013 7:49 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
Looks like a right parenthesis was dropped. Corrected:

removeNNAs <- function( dat, N, lessOrEqual=FALSE ) {
?  N1 <- N+1
?  rx <- rle( !is.na( dat$Count ) )
?  # indexes of the ends of each run of NAs or non-NAs
?  cs <- cumsum( rx$lengths )
?  # indexes of the ends of runs of NAs or non-NAs
?  cs2 <- cs[ !rx$values ]
?  # If the first Count is NA, then drop first run of NAs
?  if ( !rx$values[1] ) {
? ?  cs2 <- cs2[ -1 ]
?  }
?  # If the last Count is NA, then drop last run of NAs
?  if ( !rx$values[ length( rx$values ) ] ) {
? ?  cs2 <- cs2[ -length( cs2 ) ]
?  }
?  # cs2 is indexes of rows to potentially receive deleted Counts
?  # after collapse
?  cs2 <- cs2 + 1
?  # cs1 is indexes of non-NA Counts to be deleted
?  cs1 <- cs[ rx$values ][ seq.int( length( cs2 ) ) ]
?  # identify the indexes of the Count values before the strings
?  # of NAs that meet the criteria
?  if ( lessOrEqual ) {
? ?  idx0 <- N1 >= ( cs2 - cs1 )
?  } else {
? ?  idx0 <- N1 == ( cs2 - cs1 )
?  }
?  idx1 <- cs1[ idx0 ]
?  # identify the indexes of the Count values after the strings of
?  # NAs that meet the criteria
?  idx2 <- cs2[ idx0 ]
?  # Identify which indexes are both sources and destinations
?  idx1c <-c( idx2[ -length( idx2 ) ] == idx1[ -1 ], FALSE )
?  # identify groups of indexes that need to be merged
?  idx1g <- rev( cumsum( rev( !idx1c ) ) )
?  # find which elements of idx1 represent the beginning of a
?  # sequence of indexes to be replaced (meta-indexes)
?  srcmidxs <- which( -1 == diff( c( idx1g[ 1 ] + 1, idx1g ) ) )
?  # find which elements of idx2 represent the end of a sequence
?  # to be? replaced (meta-indexes)
?  destmidxs <- which( 1 == rev( diff( rev( c( idx1g, 0 ) ) ) ) )
?  # add counts from before NAs to destination rows
?  result <- dat
?  srcidxList <- vector( mode="list", length=length( destmidxs ) )
?  for ( i in seq.int( length( destmidxs ) ) ) {
? ?  # row to which data will be copied
? ?  destidx <- idx2[ destmidxs[ i ] ]
? ?  # sequence of indexes of source rows
? ?  srcidxss <- seq.int( from=idx1[ srcmidxs[ i ] ], to=destidx - 1 )
? ?  result[ destidx, "Count" ] <- ( dat[ destidx, "Count" ]
? ? ? ? ? ? ? ? ? ?  + sum( dat[ srcidxss, "Count" ], na.rm=TRUE ) )
? ?  # keep a list of indexes to be removed
? ?  srcidxList[ i ] <- list( srcidxss )
?  }
?  # remove source rows
?  result <- result[ -unlist( srcidxList ), ]
?  result
}


From wdunlap at tibco.com  Mon Oct 21 03:41:44 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 21 Oct 2013 01:41:44 +0000
Subject: [R] nlminb() - how do I constrain the parameter vector properly?
In-Reply-To: <2F4EF2C2-6C30-41C7-908C-FFCAE8A0C02E@gmail.com>
References: <2F4EF2C2-6C30-41C7-908C-FFCAE8A0C02E@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0D424@PA-MBX01.na.tibco.com>

Do you mean that your objective function (given to nlminb) parameterized
a positive definite matrix, P, as the elements in its upper (or lower) triangle?
If so, you could reparameterize it by the non-zero (upper triangular) elements
of the Choleski decomposition, C, of P.  Compute P as crossprod(C), compute
the initial estimate of C as chol(P).

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Steven LeBlanc
> Sent: Sunday, October 20, 2013 3:02 PM
> To: r-help at R-project.org
> Subject: [R] nlminb() - how do I constrain the parameter vector properly?
> 
> Greets,
> 
> I'm trying to use nlminb() to estimate the parameters of a bivariate normal sample and
> during one of the iterations it passes a parameter vector to the likelihood function
> resulting in an invalid covariance matrix that causes dmvnorm() to throw an error. Thus,
> it seems I need to somehow communicate to nlminb() that the final three parameters in
> my parameter vector are used to construct a positive semi-definite matrix, but I can't see
> how to achieve this using the constraint mechanism provided. Additional details are
> provided in the code below.
> 
> Suggestions?
> 
> Best Regards,
> Steven
> 
> Generate the data set I'm using:
> 
> mu<-c(1,5)
> sigma<-c(1,2,2,6)
> dim(sigma)<-c(2,2)
> set.seed(83165026)
> sample.full<-sample.deleted<-mvrnorm(50,mu,sigma)
> delete.one<-c(1,5,13,20)
> delete.two<-c(3,11,17,31,40,41)
> sample.deleted[delete.one,1]<-NA
> sample.deleted[delete.two,2]<-NA
> missing<-c(delete.one,delete.two)
> complete<-sample.deleted[!(is.na(sample.deleted[,1]) | is.na(sample.deleted[,2])),]
> deleted<-sample.deleted[missing,]
> 
> Try to estimate the parameters of the data set less the deleted values:
> 
> exact<-function(theta,complete,deleted){
>     one.only<-deleted[!(is.na(deleted[,1])),1]
>     two.only<-deleted[!(is.na(deleted[,2])),2]
>     u<-c(theta[1],theta[2])
>     sigma<-c(theta[3],theta[5],theta[5],theta[4])
>     dim(sigma)<-c(2,2)
>     -sum(log(dmvnorm(x=complete,mean=u,sigma=sigma)))-
>         sum(log(dnorm(one.only,u[1],sigma[1,1])))-
>             sum(log(dnorm(two.only,u[2],sigma[2,2])))
> }
> nlminb(start=c(0,0,1,1,0),objective=exact,complete=complete,deleted=deleted,control=l
> ist(trace=1))
> 
> Escape and it stops at Iteration 9 on my machine.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ceoriley at gmail.com  Mon Oct 21 04:11:38 2013
From: ceoriley at gmail.com (CEO'Riley)
Date: Sun, 20 Oct 2013 21:11:38 -0500
Subject: [R] XML package not working
In-Reply-To: <66C71547284587479F8009E05C07DA9704F8E5D2@USTLMLLYC107.RF.lilly.com>
References: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>
	<5263226B.7070103@gmail.com>
	<66C71547284587479F8009E05C07DA9704F8E5D2@USTLMLLYC107.RF.lilly.com>
Message-ID: <014c01cece02$e1028be0$a307a3a0$@gmail.com>

I'm running the same os system and same r version.  Only difference I see in
Sys.info() is that login, user, and effective_user  on my machine is all are
of the same case.  Your display shows login as upper case.  I'm not even
sure if that would make a difference.


With gratitude,
CEO'Riley Jr.
Charles Ellis O'Riley Jr.

Ambition is a state of permanent dissatisfaction with the present

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Steven Dwayne Randolph
Sent: Sunday, October 20, 2013 8:24 AM
To: Duncan Murdoch; r-help at r-project.org; Ista Zahn; Duncan Murdoch
Cc: Steven Dwayne Randolph; stevendrandolph at aol.com
Subject: Re: [R] XML package not working

My apologies for not conforming to the posting guideline.


Sys.info()
                     sysname                      release
version 
                   "Windows"                      "7 x64" "build 7601,
Service Pack 1" 
                    nodename                      machine
login 
           "xxxxxxNU247BZ1S"                     "x86-64"
"XXXXXX" 
                        user               effective_user 
                   "xxxxxxx"                    "xxxxxxx"

When I attempt to install a local copy of the xml.zip file:

in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) : 
  cannot open the connection
In addition: Warning messages:
1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
  cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such
file or directory'


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Saturday, October 19, 2013 8:23 PM
To: Steven Dwayne Randolph; r-help at r-project.org
Cc: stevendrandolph at aol.com
Subject: Re: [R] XML package not working

On 13-10-19 3:47 PM, Steven Dwayne Randolph wrote:
> I know I  cannot be the only one who is not able to install the XML
package from CRAN (zip or tar file)  Many packages depend on this XML
package.  Can someone help me either access the source for a good binary?  I
have received no assistance from the author/developer of the package.

It installs fine for me.

Duncan Murdoch

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Mon Oct 21 05:21:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 20 Oct 2013 20:21:45 -0700 (PDT)
Subject: [R] Loop for taking sum of rows based on proximity to other
	non-NA rows
In-Reply-To: <1382319374.55579.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1382127564.35830.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1382157111.46359.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<alpine.BSF.2.00.1310201358390.8581@pedal.dcn.davis.ca.us>
	<alpine.BSF.2.00.1310201648260.45901@pedal.dcn.davis.ca.us>
	<1382319374.55579.YahooMailNeo@web142605.mail.bf1.yahoo.com> 
Message-ID: <1382325705.31247.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Sorry, I noticed that when two "Count" values are the same and NA in between, my function fails.

#Modified
fun1 <- function(dat,n) {
?rl <- rle(is.na(dat[,"Count"]))
indx <- which(is.na(dat[,"Count"]))[rep(rl$lengths[rl$values],rl$lengths[rl$values])==n]
?lst1 <- lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) {
???????????????????????? x1 <- dat[c(min(x)-1L,x,max(x)+1L),]
???????????????????? x2 <- x1[!is.na(x1$Count),]
???????????????????? datN <- data.frame(Position=x2$Position[x2$Count %in% max(x2$Count)],Count=sum(x2$Count))
???????????????????? rowN <- row.names(x2)[x2$Count %in% max(x2$Count)]?? 
???????????????????? datN<- if(length(rowN)>1) datN[1,] else datN
??? ??? ???? row.names(datN) <- if(length(rowN) >1) rowN[1] else rowN??? 
???????????????????? datN
??????????????????? })
names(lst1) <- NULL
lst1 <- lst1[!duplicated(sapply(lst1,row.names))] 
dat2 <- do.call(rbind,lst1)
indx2 <-? sort(unlist(lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) c(min(x)-1L,x,c(max(x)+1L))),use.names=FALSE))

dat1New <- dat[-indx2[!indx2 %in% row.names(dat2)],]
dat1New[match(row.names(dat2),row.names(dat1New)),] <- dat2
row.names(dat1New) <- 1:nrow(dat1New)
dat1New
}


#########################
fun2 <- function(dat,n){
?indx <- cumsum(c(1,abs(diff(is.na(dat[,"Count"])))))
?indx1 <- indx[is.na(dat[,"Count"])]
?names(indx1) <- which(is.na(dat[,"Count"]))
indx2 <- indx1[indx1 %in% names(table(indx1))[table(indx1)==n]]
lst1 <- tapply(seq_along(indx2),list(indx2),FUN=function(i) {
??? ??? ??? ??? ??? ??? ??? x1 <- indx2[i]
??? ??? ??? ??? ??? ??? ??? ?x2 <- as.numeric(names(x1))
??? ??? ??? ??? ??? ??? ??? ?x3 <- dat[c(min(x2)-1L,x2,max(x2)+1L),]
??? ??? ??? ??? ??? ??? ??? ?x4 <- subset(x3, !is.na(Count))
??? ??? ??? ??? ??? ??? ??? ?x5 <- data.frame(Position=x4$Position[x4$Count %in% max(x4$Count)],Count=sum(x4$Count))
??? ??? ??? ??? ??? ??? ??? ind <- x4$Count %in% max(x4$Count)
??? ??? ??? ??? ??? ??? ??? ?row.names(x5) <- row.names(x4)[ind] 
??? ??? ??? ??? ??? ??? ??? x5 <- if(sum(ind)>1) x5[1,] else x5
??? ??? ??? ??? ??? ??? ??? x5
??? ??? ??? ??? ??? ??? })
attr(lst1,"dimnames") <- NULL
?dat2 <- do.call(rbind,lst1)
indx3 <- sort(unlist(tapply(seq_along(indx2),list(indx2),FUN=function(i) {x1 <- indx2[i]
??? ??? ??? ??? ??? ??? ??? ??? ??? ?x2 <- as.numeric(names(x1))
??? ??? ??? ??? ??? ??? ??? ??? ??? ?c(min(x2)-1L, x2, max(x2)+1L)}),use.names=FALSE))

dat$id <- 1:nrow(dat)
dat2$id <- as.numeric(row.names(dat2))
library(plyr)
res <- join(dat,dat2[,-1],by="id",type="left")
res1 <- res[!((row.names(res) %in% indx3) & is.na(res[,4])),]
res1[,2][!is.na(res1[,4])] <- res1[,4][!is.na(res1[,4])]
res2 <- res1[,1:2]
row.names(res2) <- 1:nrow(res2)
res2
}


identical(fun1(dat1,1),fun2(dat1,1))
#[1] TRUE
identical(fun1(fun1(dat1,1),2),fun2(fun2(dat1,1),2))
#[1] TRUE

identical(fun1(fun1(fun1(dat1,1),2),3),fun2(fun2(fun2(dat1,1),2),3))
#[1] TRUE
fun1(fun1(fun1(dat1,1),2),3)
?# Position Count
#1?????? 61??? 37
#2?????? 18??? 62
#3?????? 42??? 65


##When I tried the function on a bigger dataset:
set.seed(185)
datT <- data.frame(Position = sample(10:80,1e5,replace=TRUE),Count= sample(c(NA, 10:100),1e5, replace=TRUE))
?dim(datT)
#[1] 100000????? 2

?system.time(res <- fun1(datT,1))
#?? user? system elapsed 
?# 0.708?? 0.000?? 0.709 
system.time(res2 <- fun2(datT,1))
#?? user? system elapsed 
?# 1.400?? 0.016?? 1.421 

system.time(res3 <- removeNNAs(datT,1))
#?? user? system elapsed 
?# 1.068?? 0.000?? 1.071 

all.equal(res,res2)
#[1] TRUE
?all.equal(res,res3)
#[1] "Attributes: < Component 2: Numeric: lengths (97786, 97778) differ >"
#[2] "Component 1: Numeric: lengths (97786, 97778) differ"??????????????? 
#[3] "Component 2: Numeric: lengths (97786, 97778) differ"? 
dim(res)
#[1] 97786???? 2
dim(res3)
#[1] 97778???? 2


##Here your function seems to give the correct number of rows as:
rl <- rle(is.na(datT[,"Count"]))
indx <- which(is.na(datT[,"Count"]))[rep(rl$lengths[rl$values],rl$lengths[rl$values])==1]
?dim(datT)[1]- 2*length(indx)
#[1] 97778

#Here is where I think the difference occur (in addition to the one with the values)
datS <- datT[16000:20000,]
row.names(datS) <- 1:nrow(datS)

resT <- fun1(datS,1)
?resT3 <- removeNNAs(datS,1)


?datS[3402:3408,]
???? Position Count
3402?????? 72??? 70
3403?????? 38??? 51
3404?????? 80??? NA
3405?????? 26??? 44
3406?????? 42??? NA
3407?????? 78??? 77
3408?????? 70??? 89


resT3[3311:3318,]
???? Position Count
3401?????? 54??? 65
3402?????? 72??? 70
3407?????? 78?? 172######
3408?????? 70??? 89
3409?????? 27??? 40
3410?????? 44??? 44
3411?????? 73??? 75
3412?????? 73??? 76


?resT[3311:3318,]
???? Position Count
3311?????? 29??? 98
3312?????? 54??? 65
3313?????? 72??? 70
3314?????? 38??? 95####
3315?????? 78?? 121 ###
3316?????? 70??? 89
3317?????? 27??? 40
3318?????? 44??? 44


In these conditions, the post is not very clear about dealing it.



A.K.

















On Sunday, October 20, 2013 9:36 PM, arun <smartpink111 at yahoo.com> wrote:
Hi Jeff,

I found some difference in results between your function and mine.? It also point out a mistake in my code. In the original post, it says:
""""""""""" 

I need to write a loop to march down the rows, and if there are 2 rows in 
"Count"
where there is only 1 NA row between them, sum the two values up and 
print only one row with the summed Count value and the Position value that corresponds to the larger Count value, thus making the three 
rows into one.
"""""""""

Sorry, I read it incorrectly the last time and selected the maximum? "Position" value instead of that corresponds to the larger Count value.? 


After correcting the function, there is still some difference between the results. 




##fun1() and fun2() corrected
fun1 <- function(dat,n) {
?rl <- rle(is.na(dat[,"Count"]))
indx <- which(is.na(dat[,"Count"]))[rep(rl$lengths[rl$values],rl$lengths[rl$values])==n]
?lst1 <- lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) {
???????????????????????? x1 <- dat[c(min(x)-1L,x,max(x)+1L),]
???????????????????? x2 <- x1[!is.na(x1$Count),]
???????????????????? datN <- data.frame(Position=x2$Position[x2$Count %in% max(x2$Count)],Count=sum(x2$Count))
???????????????????? rowN <- row.names(x2)[x2$Count %in% max(x2$Count)]?? 
???????????????????? row.names(datN) <- if(length(rowN)>1) rowN[1] else rowN
???????????????????? datN
??????????????????? })
names(lst1) <- NULL
lst1 <- lst1[!duplicated(sapply(lst1,row.names))] ######added
dat2 <- do.call(rbind,lst1)
indx2 <-? sort(unlist(lapply(split(indx,((seq_along(indx)-1)%/%n)+1),function(x) c(min(x)-1L,x,c(max(x)+1L))),use.names=FALSE))

dat1New <- dat[-indx2[!indx2 %in% row.names(dat2)],]
dat1New[match(row.names(dat2),row.names(dat1New)),] <- dat2
row.names(dat1New) <- 1:nrow(dat1New)
dat1New
}


##################################

fun2 <- function(dat,n){
?indx <- cumsum(c(1,abs(diff(is.na(dat[,"Count"])))))
?indx1 <- indx[is.na(dat[,"Count"])]
?names(indx1) <- which(is.na(dat[,"Count"]))
indx2 <- indx1[indx1 %in% names(table(indx1))[table(indx1)==n]]
lst1 <- tapply(seq_along(indx2),list(indx2),FUN=function(i) {
??? ??? ??? ??? ??? ??? ??? x1 <- indx2[i]
??? ??? ??? ??? ??? ??? ??? ?x2 <- as.numeric(names(x1))
??? ??? ??? ??? ??? ??? ??? ?x3 <- dat[c(min(x2)-1L,x2,max(x2)+1L),]
??? ??? ??? ??? ??? ??? ??? ?x4 <- subset(x3, !is.na(Count))
??? ??? ??? ??? ??? ??? ??? ?x5 <- data.frame(Position=x4$Position[x4$Count %in% max(x4$Count)],Count=sum(x4$Count))
??? ??? ??? ??? ??? ??? ??? ind <- x4$Count %in% max(x4$Count)
??? ??? ??? ??? ??? ??? ??? ?row.names(x5) <- if(sum(ind)>1) row.names(x4)[ind][1] else row.names(x4)[ind]
??? ??? ??? ??? ??? ??? ??? x5
??? ??? ??? ??? ??? ??? })
attr(lst1,"dimnames") <- NULL
?dat2 <- do.call(rbind,lst1)
indx3 <- sort(unlist(tapply(seq_along(indx2),list(indx2),FUN=function(i) {x1 <- indx2[i]
??? ??? ??? ??? ??? ??? ??? ??? ??? ?x2 <- as.numeric(names(x1))
??? ??? ??? ??? ??? ??? ??? ??? ??? ?c(min(x2)-1L, x2, max(x2)+1L)}),use.names=FALSE))

dat$id <- 1:nrow(dat)
dat2$id <- as.numeric(row.names(dat2))
library(plyr)
res <- join(dat,dat2[,-1],by="id",type="left")
res1 <- res[!((row.names(res) %in% indx3) & is.na(res[,4])),]
res1[,2][!is.na(res1[,4])] <- res1[,4][!is.na(res1[,4])]
res2 <- res1[,1:2]
row.names(res2) <- 1:nrow(res2)
res2
}


dat1 <- structure(list(Position = c(15L, 22L, 38L, 49L, 55L, 61L, 62L,
14L, 29L, 63L, 46L, 22L, 18L, 24L, 22L, 49L, 42L, 38L, 29L, 22L,
29L, 23L, 42L), Count = c(15L, NA, NA, 5L, NA, 17L, 18L, NA,
NA, NA, 8L, NA, 20L, NA, NA, 16L, 19L, NA, NA, NA, 13L, NA, 33L
)), .Names = c("Position", "Count"), class = "data.frame", row.names = c(NA,
-23L))

fun1(dat1,1)
?? Position Count
1??????? 15??? 15
2??????? 22??? NA
3??????? 38??? NA
4??????? 61??? 22
5??????? 62??? 18
6??????? 14??? NA
7??????? 29??? NA
8??????? 63??? NA
9??????? 18??? 28? ###
10?????? 24??? NA
11?????? 22??? NA
12?????? 49??? 16 ####
13?????? 42??? 19
14?????? 38??? NA
15?????? 29??? NA
16?????? 22??? NA
17?????? 42??? 46
removeNNAs(dat1,1) #gets similar results

#but,

?fun1(fun1(dat1,1),2)
?? Position Count
1??????? 61??? 37
2??????? 62??? 18
3??????? 14??? NA
4??????? 29??? NA
5??????? 63??? NA
6??????? 18??? 44 #######different
7??????? 42??? 19
8??????? 38??? NA
9??????? 29??? NA
10?????? 22??? NA
11?????? 42??? 46
?
?removeNNAs(dat1,2,lessOrEqual=TRUE)
?? Position Count
6??????? 61??? 37
7??????? 62??? 18
8??????? 14??? NA
9??????? 29??? NA
10?????? 63??? NA
16?????? 49??? 44 ###### different
17?????? 42??? 19
18?????? 38??? NA
19?????? 29??? NA
20?????? 22??? NA
23?????? 42??? 46
> 




removeNNAs(dat1,3,lessOrEqual=TRUE)
?? Position Count
6??????? 61??? 37
16?????? 49??? 62
23?????? 42??? 65
?fun1(fun1(fun1(dat1,1),2),3)
? Position Count
1?????? 61??? 37
2?????? 18??? 62
3?????? 42??? 65





A.K.



On Sunday, October 20, 2013 7:49 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
Looks like a right parenthesis was dropped. Corrected:

removeNNAs <- function( dat, N, lessOrEqual=FALSE ) {
?? N1 <- N+1
?? rx <- rle( !is.na( dat$Count ) )
?? # indexes of the ends of each run of NAs or non-NAs
?? cs <- cumsum( rx$lengths )
?? # indexes of the ends of runs of NAs or non-NAs
?? cs2 <- cs[ !rx$values ]
?? # If the first Count is NA, then drop first run of NAs
?? if ( !rx$values[1] ) {
? ?? cs2 <- cs2[ -1 ]
?? }
?? # If the last Count is NA, then drop last run of NAs
?? if ( !rx$values[ length( rx$values ) ] ) {
? ?? cs2 <- cs2[ -length( cs2 ) ]
?? }
?? # cs2 is indexes of rows to potentially receive deleted Counts
?? # after collapse
?? cs2 <- cs2 + 1
?? # cs1 is indexes of non-NA Counts to be deleted
?? cs1 <- cs[ rx$values ][ seq.int( length( cs2 ) ) ]
?? # identify the indexes of the Count values before the strings
?? # of NAs that meet the criteria
?? if ( lessOrEqual ) {
? ?? idx0 <- N1 >= ( cs2 - cs1 )
?? } else {
? ?? idx0 <- N1 == ( cs2 - cs1 )
?? }
?? idx1 <- cs1[ idx0 ]
?? # identify the indexes of the Count values after the strings of
?? # NAs that meet the criteria
?? idx2 <- cs2[ idx0 ]
?? # Identify which indexes are both sources and destinations
?? idx1c <-c( idx2[ -length( idx2 ) ] == idx1[ -1 ], FALSE )
?? # identify groups of indexes that need to be merged
?? idx1g <- rev( cumsum( rev( !idx1c ) ) )
?? # find which elements of idx1 represent the beginning of a
?? # sequence of indexes to be replaced (meta-indexes)
?? srcmidxs <- which( -1 == diff( c( idx1g[ 1 ] + 1, idx1g ) ) )
?? # find which elements of idx2 represent the end of a sequence
?? # to be? replaced (meta-indexes)
?? destmidxs <- which( 1 == rev( diff( rev( c( idx1g, 0 ) ) ) ) )
?? # add counts from before NAs to destination rows
?? result <- dat
?? srcidxList <- vector( mode="list", length=length( destmidxs ) )
?? for ( i in seq.int( length( destmidxs ) ) ) {
? ?? # row to which data will be copied
? ?? destidx <- idx2[ destmidxs[ i ] ]
? ?? # sequence of indexes of source rows
? ?? srcidxss <- seq.int( from=idx1[ srcmidxs[ i ] ], to=destidx - 1 )
? ?? result[ destidx, "Count" ] <- ( dat[ destidx, "Count" ]
? ? ? ? ? ? ? ? ? ?? + sum( dat[ srcidxss, "Count" ], na.rm=TRUE ) )
? ?? # keep a list of indexes to be removed
? ?? srcidxList[ i ] <- list( srcidxss )
?? }
?? # remove source rows
?? result <- result[ -unlist( srcidxList ), ]
?? result
}


From canamika at gmail.com  Mon Oct 21 06:22:36 2013
From: canamika at gmail.com (Anamika Chaudhuri)
Date: Mon, 21 Oct 2013 00:22:36 -0400
Subject: [R] Data Manipulation in R
Message-ID: <CALv--dYT7G4zZ_4VDAWjSJimWQ6JHaMn8bHmoi0oj3zP1XYiqQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/dfd64194/attachment.pl>

From markleeds2 at gmail.com  Mon Oct 21 06:54:22 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Mon, 21 Oct 2013 00:54:22 -0400
Subject: [R] nlminb() - how do I constrain the parameter vector properly?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA0D424@PA-MBX01.na.tibco.com>
References: <2F4EF2C2-6C30-41C7-908C-FFCAE8A0C02E@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0D424@PA-MBX01.na.tibco.com>
Message-ID: <CAHz+bWbmo=fDEMvkSEjRRAoDEWF=NpiRoZAmFQ_MbhURShAnWQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/ad77cb7b/attachment.pl>

From smartpink111 at yahoo.com  Mon Oct 21 07:11:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 20 Oct 2013 22:11:58 -0700 (PDT)
Subject: [R] Data Manipulation in R
In-Reply-To: <CALv--dYT7G4zZ_4VDAWjSJimWQ6JHaMn8bHmoi0oj3zP1XYiqQ@mail.gmail.com>
References: <CALv--dYT7G4zZ_4VDAWjSJimWQ6JHaMn8bHmoi0oj3zP1XYiqQ@mail.gmail.com>
Message-ID: <1382332318.35234.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this helps:
Y1 <- read.table(text="V1 V2 V3 V4
1 4 0 20 17
2 4 0 15 17
3 2 0 13 21",sep="",header=TRUE)

Y2 <- read.table(text="V1 V2 V3 V4
1 20 52 15 18
2 18 54 14 21
3 18 51 13 21",sep="",header=TRUE)
?res <- lapply(seq_len(nrow(Y1)),function(i) {dat <- data.frame(X=i,Y1=unlist(Y1[i,]),Y2=unlist(Y2[i,])); row.names(dat) <- 1:nrow(dat); write.csv(dat,paste0("file",i,".csv"),row.names=FALSE,quote=FALSE)})


A.K.





A.K.




On Monday, October 21, 2013 12:24 AM, Anamika Chaudhuri <canamika at gmail.com> wrote:
Hi:

I am looking for some help to manipulate data in R. I have two csv files.

datasetY1
V1 "V2" "V3" "V4"
1 4 0 20 17
2 4 0 15 17
3 2 0 13 21

datasetY2
V1 "V2" "V3" "V4"
1 20 52 15 18
2 18 54 14 21
3 18 51 13 21

I want to be able to create separate csv files by taking the corresponding
rows of dataset1 and dataset2, convert them into columns. So from the above
example I would be creating 3 datasets (csvs), of which the first one would
be
? ? ? ? ? ? ?  X? ? ? ? ? ?  Y1? ? ? ? ? ? Y2? 1 4 20? 1 0
52? 1 20 15? 1 17
18
? Appreciate any help.

Thanks
Anamika

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ddegrasv at depaul.edu  Mon Oct 21 05:18:09 2013
From: ddegrasv at depaul.edu (David Degras)
Date: Sun, 20 Oct 2013 20:18:09 -0700 (PDT)
Subject: [R] Conflict between Accelerate BLAS and package 'stats'
Message-ID: <1382325489515-4678674.post@n4.nabble.com>

Hi All, 

After successfully setting up the Accelerate BLAS library via 
 
/cd /Library/Frameworks/R.framework/Resources/lib
ln -sf
/System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/Versions/Current/libBLAS.dylib
libRblas.dylib
/

I restarted R (version 3.0.1) and got the following error message: 

/Error in dyn.load(file, DLLpath = DLLpath, ...) : 
  unable to load shared object
'/Library/Frameworks/R.framework/Versions/3.0/Resources/library/stats/libs/stats.so':
 
dlopen(/Library/Frameworks/R.framework/Versions/3.0/Resources/library/stats/libs/stats.so,
6): Symbol not found: _lsame_
  Referenced from:
/Library/Frameworks/R.framework/Versions/3.0/Resources/lib/libRlapack.dylib
  Expected in:
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
 in
/Library/Frameworks/R.framework/Versions/3.0/Resources/lib/libRlapack.dylib
During startup - Warning message:
package 'stats' in options("defaultPackages") was not found /

Can anybody help? 

Below is the system info for my iMac:
 
/sysname   "Darwin" 
release     "10.8.0" 
version 
"Darwin Kernel Version 10.8.0: Tue Jun  7 16:33:36 PDT 2011;
root:xnu-1504.15.3~1/RELEASE_I386" 
machine    "i386"
/

Thanks,
David


David Degras
Department of Mathematical Sciences 
DePaul University




--
View this message in context: http://r.789695.n4.nabble.com/Conflict-between-Accelerate-BLAS-and-package-stats-tp4678674.html
Sent from the R help mailing list archive at Nabble.com.


From oreslag at gmail.com  Mon Oct 21 09:01:34 2013
From: oreslag at gmail.com (Steven LeBlanc)
Date: Mon, 21 Oct 2013 00:01:34 -0700
Subject: [R] nlminb() - how do I constrain the parameter vector properly?
In-Reply-To: <CAHz+bWbmo=fDEMvkSEjRRAoDEWF=NpiRoZAmFQ_MbhURShAnWQ@mail.gmail.com>
References: <2F4EF2C2-6C30-41C7-908C-FFCAE8A0C02E@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0D424@PA-MBX01.na.tibco.com>
	<CAHz+bWbmo=fDEMvkSEjRRAoDEWF=NpiRoZAmFQ_MbhURShAnWQ@mail.gmail.com>
Message-ID: <C4074918-8B78-47F6-872A-174EA5150E0C@gmail.com>


On Oct 20, 2013, at 9:54 PM, Mark Leeds <markleeds2 at gmail.com> wrote:

> Bill: I didn't look at the code but I think the OP means that during the nlminb algorithm,
> the variance covariance parameters hit values such that the covariance matrix estimate becomes negative definite.

Yes, that is what I meant.

> 
> Again, I didn't look at the details but one way to deal with this is to have the likelihood
> function return -Inf whenever the covariance matrix becomes not positive definite. so, the
> likelihood should check for  positive definiteness first before it actually calculates anything.
> If PD is not true, the -Inf value should push nlminb towards values that obtain a positive definite matrix. But there could be something more subtle going on that I'm not understanding. I don't know even what algorithm nlminb is using ( probably quasi-newton ) but this is one thing the OP could try.

I tried this at your suggestion. nlminb() seems to hang at -Inf, but Inf works splendidly. Thanks much!


From davidmarino838 at gmail.com  Mon Oct 21 09:51:46 2013
From: davidmarino838 at gmail.com (Marino David)
Date: Mon, 21 Oct 2013 15:51:46 +0800
Subject: [R] Gaussian Quadrature for arbitrary PDF
In-Reply-To: <525DE7E1.6030902@structuremonitoring.com>
References: <CABmD0bFpFHUCqsr-Sg2jhtNULCGQa3n_86a4HwA+WB0yBBvRZA@mail.gmail.com>
	<525B8DE1.1080100@structuremonitoring.com>
	<CABmD0bEeygBwMEPOvX+FbJqjV6SnQ2E414cnRg1mMjr0KFNa1Q@mail.gmail.com>
	<525DE7E1.6030902@structuremonitoring.com>
Message-ID: <CABmD0bHnm5SB_CBsY9g=gLc+iNnuDHT_Uxej=kPKjLXQTfHePQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/daacc333/attachment.pl>

From petr.pikal at precheza.cz  Mon Oct 21 09:52:18 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 21 Oct 2013 07:52:18 +0000
Subject: [R] Errore  : requires numeric/complex matrix/vector arguments
In-Reply-To: <235A9DCB-0308-4764-B1FB-1526FB35C9A9@xs4all.nl>
References: <DUB110-W137625DBF468113AE66E3A1BB000@phx.gbl>,
	<EFF1A9F4-B9B2-49AF-96FF-16CA2932D936@xs4all.nl>
	<DUB110-W78FD6351CA54ED4A233CB5BB000@phx.gbl>
	<235A9DCB-0308-4764-B1FB-1526FB35C9A9@xs4all.nl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9925D@SRVEXCHMBX.precheza.cz>

Hi

>From your first post if any of variables is not numeric this command

mY<-cbind(G, T, Y, news)

makes mY also nonumeric.

so look at structure of 

"D" data.frame which results from reading your csv file by

str(D)

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Berend Hasselman
> Sent: Sunday, October 20, 2013 4:31 PM
> To: valentina colombo
> Cc: r-help at r-project.org help
> Subject: Re: [R] Errore : requires numeric/complex matrix/vector
> arguments
> 
> 
> On 20-10-2013, at 16:16, valentina colombo <valentina81c at hotmail.it>
> wrote:
> 
> > Dear Mr. Hasselman,
> > I have attached my code to solve (hopefully) my problem in
> > Error-require numeric/complex matrix/vector Any suggestions?
> > Thanks
> >
> Please answer to the list and NOT only privately. I'm forwarding this
> message to R-help.
> 
> You are not showing how you constructed mX and others.
> In the attachment you show how you read X.
> 
> I do not get your error when I generate your matrices with these
> commands:
> 
> set.seed(1)
> 
> N <- 126
> mX <- matrix(runif(N*4),ncol=4)
> mY <- matrix(runif(N*4),ncol=4)
> mZ <- matrix(runif(N*4),ncol=4)
> 
> If you want to include data in a text-only mail use dput.
> 
> Berend
> 
> >
> >
> > > Subject: Re: [R] Errore : requires numeric/complex matrix/vector
> > > arguments
> > > From: bhh at xs4all.nl
> > > Date: Sun, 20 Oct 2013 13:29:37 +0200
> > > CC: r-help at r-project.org
> > > To: valentina81c at hotmail.it
> > >
> > >
> > > On 20-10-2013, at 13:08, valentina colombo
> <valentina81c at hotmail.it> wrote:
> > >
> > > > Dear R users,I'm a new user of R. I'm trying to do a LM test an
> there is this type of error: Error in t(mX) %*% mX : requires
> numeric/complex matrix/vector arguments.
> > > > To be clear I write down the code in which mY ( 126,1 ) mX
> (126,1) mZ(126,1) are matrix.
> > > >
> > > > LMTEST <- function(mY, mX, mZ)#mY, mX, mZ must be
> > > > matrices!#returns the LM test statistic and the degree of
> > > > freedom{iT = dim(mY)[1]ip = dim(mY)[2]iDF = dim(mZ)[2]*ipmE = mY
> -
> > > > mX%*%solve(t(mX)%*%mX)%*%t(mX)%*%mY
> > > > the error starts from the above step (t(mX)%*%mX)%*%t(mX)%*%mY
> > > > RSS0 = t(mE)%*%mEmXX = cbind(mX, mZ)mK = mE -
> > > > mXX%*%solve(t(mXX)%*%mXX)%*%t(mXX)%*%mERSS1 = t(mK)%*%mKdTR =
> sum(diag(solve(RSS0)%*%RSS1))LM = iT*(ip-dTR)pval = 1-
> pchisq(LM,df=iDF)return( c(pval, LM, iDF) )} Any suggestion? Where is
> the problem? I am getting craxy!
> > >
> > > Your code is a complete mess and thus unreadable because you posted
> in HTML.
> > > Cleaning up and doing this
> > >
> > > LMTEST <- function(mY, mX, mZ)#mY, mX, mZ must be matrices!
> > > #returns the LM test statistic and the degree of freedom {iT =
> > > dim(mY)[1] ip = dim(mY)[2] iDF = dim(mZ)[2]*ip mE = mY -
> > > mX%*%solve(t(mX)%*%mX)%*%t(mX)%*%mY
> > > # the error starts from the above step (t(mX)%*%mX)%*%t(mX)%*%mY
> > > RSS0 = t(mE)%*%mE mXX = cbind(mX, mZ) mK = mE -
> > > mXX%*%solve(t(mXX)%*%mXX)%*%t(mXX)%*%mE
> > > RSS1 = t(mK)%*%mK
> > > dTR = sum(diag(solve(RSS0)%*%RSS1))
> > > LM = iT*(ip-dTR)
> > > pval = 1-pchisq(LM,df=iDF)
> > > return( c(pval, LM, iDF) )
> > > }
> > >
> > > set.seed(1)
> > >
> > > N <- 20
> > > mX <- matrix(runif(N),ncol=1)
> > > mY <- matrix(runif(N),ncol=1)
> > > mZ <- matrix(runif(N),ncol=1)
> > >
> > > LMTEST(mY,mX,mZ)
> > >
> > > the answer I got was:
> > >
> > > [1] 0.004965514 7.891955826 1.000000000
> > >
> > >
> > > So it must be your data.
> > > Are you sure they are numeric? Have you checked with str(mX) etc?
> > >
> > > Berend
> > >
> > > > Valentina
> > > > [[alternative HTML version deleted]]
> > >
> > >
> > > Please don't post in html but in plain text.
> > >
> > >
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible
> code.
> > >
> > <R error.txt>
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Mon Oct 21 09:54:57 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 21 Oct 2013 08:54:57 +0100
Subject: [R] Conflict between Accelerate BLAS and package 'stats'
In-Reply-To: <1382325489515-4678674.post@n4.nabble.com>
References: <1382325489515-4678674.post@n4.nabble.com>
Message-ID: <5264DDD1.5030607@stats.ox.ac.uk>

On 21/10/2013 04:18, David Degras wrote:
> Hi All,
>
> After successfully setting up the Accelerate BLAS library via

'UNsucessfully' ...

This is a question for R-sig-MAC: see the posting guide, and you need to 
ask how to achieve whatever you are trying to do, rather than tell us 
how you broke your R.  (My guess is that the advice you need is in the 
'R Installation and Administration Manual'.)

>
> /cd /Library/Frameworks/R.framework/Resources/lib
> ln -sf
> /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/Versions/Current/libBLAS.dylib
> libRblas.dylib
> /
>
> I restarted R (version 3.0.1) and got the following error message:
>
> /Error in dyn.load(file, DLLpath = DLLpath, ...) :
>    unable to load shared object
> '/Library/Frameworks/R.framework/Versions/3.0/Resources/library/stats/libs/stats.so':
>
> dlopen(/Library/Frameworks/R.framework/Versions/3.0/Resources/library/stats/libs/stats.so,
> 6): Symbol not found: _lsame_
>    Referenced from:
> /Library/Frameworks/R.framework/Versions/3.0/Resources/lib/libRlapack.dylib
>    Expected in:
> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
>   in
> /Library/Frameworks/R.framework/Versions/3.0/Resources/lib/libRlapack.dylib
> During startup - Warning message:
> package 'stats' in options("defaultPackages") was not found /
>
> Can anybody help?
>
> Below is the system info for my iMac:
>
> /sysname   "Darwin"
> release     "10.8.0"
> version
> "Darwin Kernel Version 10.8.0: Tue Jun  7 16:33:36 PDT 2011;
> root:xnu-1504.15.3~1/RELEASE_I386"
> machine    "i386"
> /
>
> Thanks,
> David
>
>
> David Degras
> Department of Mathematical Sciences
> DePaul University
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Conflict-between-Accelerate-BLAS-and-package-stats-tp4678674.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tal.galili at gmail.com  Mon Oct 21 11:19:53 2013
From: tal.galili at gmail.com (Tal Galili)
Date: Mon, 21 Oct 2013 11:19:53 +0200
Subject: [R] Reproducing density(..., kernel='rectangular',
 width=1) using convolve? (for educational purposes)
Message-ID: <CANdJ3dV_pUxbRsyfkZDOauRaqz5nQsGoXC+UyJqynP=DwTLvJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/05a58551/attachment.pl>

From markleeds2 at gmail.com  Mon Oct 21 11:56:45 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Mon, 21 Oct 2013 05:56:45 -0400
Subject: [R] nlminb() - how do I constrain the parameter vector properly?
In-Reply-To: <C4074918-8B78-47F6-872A-174EA5150E0C@gmail.com>
References: <2F4EF2C2-6C30-41C7-908C-FFCAE8A0C02E@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0D424@PA-MBX01.na.tibco.com>
	<CAHz+bWbmo=fDEMvkSEjRRAoDEWF=NpiRoZAmFQ_MbhURShAnWQ@mail.gmail.com>
	<C4074918-8B78-47F6-872A-174EA5150E0C@gmail.com>
Message-ID: <CAHz+bWYEtvZjiCCauGVxstGcqmF6ENw0N3MMb7jfa3OkYkBTKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/1f1d42c0/attachment.pl>

From S.Ellison at lgcgroup.com  Mon Oct 21 12:51:57 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Mon, 21 Oct 2013 11:51:57 +0100
Subject: [R] blod dot size and name in plot
In-Reply-To: <BLU170-W1143E1828B49B724A0A73C089070@phx.gbl>
References: <BLU170-W1143E1828B49B724A0A73C089070@phx.gbl>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554B39D79@GOLD.corp.lgc-group.com>



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of eliza botto
> Sent: 19 October 2013 22:27
> To: r-help at r-project.org
> Subject: [R] blod dot size and name in plot
> 
> Dear useRs,I have the following data "z" of two variables "x"(z[,1])
> and "y"(z[,2]).
> ...
> I made a dot plot between them. what i want to do is to bold the size
> of dots,compared to that of others, for the following ranges
> -------80<x<100 and 2<y<4-------40<x<60 and 8<y<10-------100<x<120 and
> 6<y<8
> Then, i also want to draw square around those dots falling in these
> ranges and finally naming the areas with alphabets A, B and C.
> Is there a way of doing it?

Yes, depending what you mean by 'bold'.
If 'bold' means 'bigger' you can use cex to change sizes. 
If it means 'coloured' or a filled symbol (eg pch=19) you can use pch.
if it means 'the same size with thicker lines', you can't have 'bold' symbols, though you could plot circles with lwd=2 or go looking for a symbol font on your machine that has thicker lines.

The trick is to use a cex, col or pch as long as the data. For example

bold.A <- bold.B <- bold.C <- rep_len(FALSE,length.out=length(x)) # A bit crude, but it'll work
bold.A[ 80<x & x<100 & 2<y & y<4 ] <- TRUE 
bold.B[ 40<x & x<60 & 8<y & y<10 ] <- TRUE
bold.C[ 100<x & x<120 & 6<y & y<8 ] <- TRUE
bold <- bold.A | bold.B | bold.C

plot(x, y, cex=ifelse(bold, 1.4, 0.7)) #specifying pch or col follows the same pattern

#You can add squares with another symbol:
points(x[bold], y[bold], pch=22, cex=2, bg=NA)

#and you can add text labels with text:
text(x[bold.A], y[bold.A], "A", pos=3) #pos=3 means 'above'; see ?text

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From nashjc at uottawa.ca  Mon Oct 21 14:47:53 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Mon, 21 Oct 2013 08:47:53 -0400
Subject: [R] nlminb() - how do I constrain the parameter vector properly?
In-Reply-To: <5265217F.10307@uottawa.ca>
References: <5265217F.10307@uottawa.ca>
Message-ID: <52652279.7020105@uottawa.ca>

This is one area where more internal communication between the objective 
function (inadmissible inputs) and optimizer (e.g., Quasi-Newton) is 
needed. This is NOT done at the moment in R, nor in most software. An 
area for R&D. In Nash and Walker-Smith (1987) we did some of this in 
BASIC back in mid-80s. Still trying to redo that for R, but it won't be 
done quickly due to the much bigger infrastructure of R.

The "trick" with using a large value or Inf (which sometimes causes
other errors) usually slows the optimization, whereas communicating that 
the objective is inadmissible in a line search can often be simply a 
shortening of the step size.

JN

On 13-10-21 06:00 AM, r-help-request at r-project.org wrote:
> Message: 34
> Date: Mon, 21 Oct 2013 05:56:45 -0400
> From: Mark Leeds<markleeds2 at gmail.com>
> To: Steven LeBlanc<oreslag at gmail.com>
> Cc:"r-help at R-project.org"  <r-help at r-project.org>
> Subject: Re: [R] nlminb() - how do I constrain the parameter vector
> 	properly?
> Message-ID:
> 	<CAHz+bWYEtvZjiCCauGVxstGcqmF6ENw0N3MMb7jfa3OkYkBTKA at mail.gmail.com>
> Content-Type: text/plain
>
> my mistake. since nlminb is minimizing, it should be +Inf  ( so that the
> likelihood
> is large ) as you pointed out. Note  that this approach is a heuristic and
> may  not work all the time.


From smartpink111 at yahoo.com  Mon Oct 21 16:09:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 21 Oct 2013 07:09:35 -0700 (PDT)
Subject: [R] Removing duplicates dates matched on another column
Message-ID: <1382364575.39279.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
May be this helps:

dat1 <- structure(....
res <- dat1[!(duplicated(dat1$date) & dat1$admit==0),]

A.K.


I want to remove duplicate dates if the value of admit is 0. How could I realize this in R? ?Reproducible sample data is here: 

structure(list(date = structure(c(13879, 13879, 13880, 13880, 
13881, 13881, 13882, 13882, 13883, 13883, 13884, 13885, 13886, 
13886, 13887, 13887, 13888, 13888, 13889, 13889, 13890, 13891, 
13891, 13892, 13893, 13893, 13894, 13894, 13895, 13895, 13896, 
13896, 13897, 13897, 13898, 13898, 13899, 13899, 13900, 13900, 
13901, 13901, 13902, 13902, 13903, 13903, 13904, 13904, 13905, 
13905, 13906, 13906, 13907, 13907, 13908, 13908, 13909, 13909 
), class = "Date"), admit = c(1, 0, 1, 0, 2, 0, 1, 0, 3, 0, 0, 
0, 4, 0, 2, 0, 1, 0, 3, 0, 0, 2, 0, 0, 2, 0, 1, 0, 5, 0, 2, 0, 
2, 0, 1, 0, 4, 0, 3, 0, 1, 0, 4, 0, 6, 0, 8, 0, 3, 0, 3, 0, 3, 
0, 2, 0, 4, 0)), .Names = c("date", "admit"), row.names = 10152:10209, class = "data.frame")


From mohammad.godarzi at gmail.com  Mon Oct 21 12:18:17 2013
From: mohammad.godarzi at gmail.com (Mohammad Goodarzi)
Date: Mon, 21 Oct 2013 12:18:17 +0200
Subject: [R] merging matrices
Message-ID: <CAO4=jh7PL3YvpLtb-QK0+_s8wX0Ap42xc5f0QFRJ1=3NmK=qmg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/6bbc29bc/attachment.pl>

From zzgt2006 at gmail.com  Mon Oct 21 16:04:18 2013
From: zzgt2006 at gmail.com (zhe zhao)
Date: Mon, 21 Oct 2013 10:04:18 -0400
Subject: [R] Problem to understand calculation of loglikelihood in the ramps
	package
Message-ID: <CABX7Z=9JKku_DqcitcDauH4E5qhRun78w-+q-WWwGu2Oc-KSqw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/9ac99c83/attachment.pl>

From gunter.berton at gene.com  Mon Oct 21 16:28:42 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 21 Oct 2013 07:28:42 -0700
Subject: [R] merging matrices
In-Reply-To: <CAO4=jh7PL3YvpLtb-QK0+_s8wX0Ap42xc5f0QFRJ1=3NmK=qmg@mail.gmail.com>
References: <CAO4=jh7PL3YvpLtb-QK0+_s8wX0Ap42xc5f0QFRJ1=3NmK=qmg@mail.gmail.com>
Message-ID: <CACk-te2gZimwS9UBDOaugyb0FEGco8pzZ75OJOkuNx58f4K7PA@mail.gmail.com>

Have you read "An Introduction to R" (ships with R) or any R web
tutorials to learn how R works? If not, don't you think you should
before posting here? Your question appears to be rather basic.

Cheers,
Bert

On Mon, Oct 21, 2013 at 3:18 AM, Mohammad Goodarzi
<mohammad.godarzi at gmail.com> wrote:
> Dear all,
>
> I have to load more than 1000 matrices from desktop which all of them have
> the same size.
> If I do it manually, it would be very hard, can you please guide me how to
> load them and merge them together ?
>
> for example I want to put them one after another
> X1 X2 X3 etc
>
> Many thanks,
> Mohammad
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From gunter.berton at gene.com  Mon Oct 21 16:30:06 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 21 Oct 2013 07:30:06 -0700
Subject: [R] Problem to understand calculation of loglikelihood in the
 ramps package
In-Reply-To: <CABX7Z=9JKku_DqcitcDauH4E5qhRun78w-+q-WWwGu2Oc-KSqw@mail.gmail.com>
References: <CABX7Z=9JKku_DqcitcDauH4E5qhRun78w-+q-WWwGu2Oc-KSqw@mail.gmail.com>
Message-ID: <CACk-te1NT3-yT_7d+tkVU3va0jLUrjTNm2MnPL3W1b8JaNkqXw@mail.gmail.com>

You may get an answer here, but this appears to be something that you
should address to the package maintainer or package author.

Cheers,
Bert

On Mon, Oct 21, 2013 at 7:04 AM, zhe zhao <zzgt2006 at gmail.com> wrote:
> Dear R,
>
> We are trying to understand the calculation of loglikelihood in the ramps
> package. Our calculations do not agree with the package's. Can anyone
> explain why not?
>
> Here's an example using a small data set.
>
> # create small dataset
> library(ramps)
>
> data(NURE)  ## NURE is included in ramps package
> attach(NURE)
> data <- NURE[lat>41.9 & lon > -72.5 & !is.na(lat),]
> dim(data)  # 20 data points
>
> # ramps analysis
> set.seed(22)
>
> NURE.ctrl1 <- ramps.control(
>   iter = 10,
>   beta = param(0, "flat"),
>   sigma2.e = param(1, "invgamma", shape = 2.0, scale = 0.1, tuning = 0.75),
>   phi = param(10, "uniform", min = 0, max = 35, tuning = 0.50),
>   sigma2.z = param(1, "invgamma", shape = 2.0, scale = 0.1)
> )
>
> NURE.fit2 <- georamps(log(ppm) ~ 1,
>   correlation = corRExp(form = ~ easting + northing),
>
>   data = data,
>   control = NURE.ctrl1
> )
> rampsll <- NURE.fit2$loglik[1:4] # ramps loglikelihood for iterations 1:4
>
>
> # our calculation
> # We should be able to use the parameter values from a single MCMC iteration
> # to calculate the loglikelihood using dmvnorm
>
> library(mvtnorm)
> cor.exp <- function(x, range = 1, p = 1) # copied from corStruct.R in the
> ramps package
>
> {
>    if (range <= 0 || p <= 0)
>       stop("Exponential correlation parameter must be > 0")
>
>    if (p == 1) exp(x / (-1 * range))
>    else exp(-1 * (x / range)^p)
> }
>
> # Compute the covariance matrix
>
> sig.fn <- function(itno,data){
>   dist <- as.matrix ( dist ( data[,c("easting","northing")] ) )
>   npts <- nrow(data)
>   sig1 <- diag(npts)
>   for ( i in 1:(npts-1) )
>     for ( j in (i+1):npts )
>       sig1[j,i] <- sig1[i,j] <- cor.exp ( dist[i,j], range =
> NURE.fit2$params[itno,"phi"] )
>
>   Sigma <- sig1 * NURE.fit2$params[itno, "sigma2.z"] +
>     diag(npts) * NURE.fit2$params[itno, "sigma2.e"]
>   return(Sigma)
> }
>
> # Calculate the loglikelihood for a single MCMC iteration
> loglik.fn <- function(itno,data){
>
>   loglik <- dmvnorm ( x = log(data[,"ppm"]),
>     mean = rep ( NURE.fit2$params[itno,"(Intercept)"], nrow(data) ),
>     sigma = sig.fn(itno,data),
>     log = TRUE
>   )
>   return(loglik)
> }
>
> # Collect the loglikelihood from iterations 1:4
> myll <- c ( loglik.fn(1,data), loglik.fn(2,data), loglik.fn(3,data),
> loglik.fn(4,data) )
>
>
> But myll does not agree with rampsll.
> Can anyone tell us why not?
>
> Thanks very much for your help.
> Zhe
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From alaios at yahoo.com  Mon Oct 21 16:45:34 2013
From: alaios at yahoo.com (Alaios)
Date: Mon, 21 Oct 2013 07:45:34 -0700 (PDT)
Subject: [R] plot correlation matrix
Message-ID: <1382366734.8245.YahooMailNeo@web125303.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/832b1f9a/attachment.pl>

From wdunlap at tibco.com  Mon Oct 21 16:52:11 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 21 Oct 2013 14:52:11 +0000
Subject: [R] nlminb() - how do I constrain the parameter vector properly?
In-Reply-To: <0ADAF72C-B591-4222-9AD5-24858F650784@gmail.com>
References: <2F4EF2C2-6C30-41C7-908C-FFCAE8A0C02E@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0D424@PA-MBX01.na.tibco.com>
	<0ADAF72C-B591-4222-9AD5-24858F650784@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0D4F9@PA-MBX01.na.tibco.com>

Try defining the function
    theta345toSigma <- function(theta) {
       cholSigma <- cbind(c(theta[3], 0), c(theta[4], theta[5]))
       crossprod(cholSigma) # t(cholSigma) %*% cholSigma)
    }
This creates a positive definite matrix for any theta (and
any positive definite matrix has such a representation, generally
more than one).  It is like using the square root of a quantity
in the optimizer when you know the quantity must be non-negative.

Then change your
    sigma <- c(theta[3],theta[5],theta[5],theta[4])
    dim(sigma) <- c(2, 2)
to
    sigma <- theta345toSigma(theta)

If one of your variances is near 0 the optimizer may run into
trouble at saddlepoints.  Others may be able to help better
with that issue.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Steven LeBlanc [mailto:oreslag at gmail.com]
> Sent: Sunday, October 20, 2013 9:35 PM
> To: William Dunlap
> Subject: Re: [R] nlminb() - how do I constrain the parameter vector properly?
> 
> 
> On Oct 20, 2013, at 6:41 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> > Do you mean that your objective function (given to nlminb) parameterized
> > a positive definite matrix, P, as the elements in its upper (or lower) triangle?
> > If so, you could reparameterize it by the non-zero (upper triangular) elements
> > of the Choleski decomposition, C, of P.  Compute P as crossprod(C), compute
> > the initial estimate of C as chol(P).
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> 
> Hi Bill,
> 
> I've clipped out the superfluous code to leave the objective function and call to nlminb()
> below.
> 
> I'm using the first two parameters to construct the vector of means 'u' for a bivariate
> normal, and the final three parameters to construct the corresponding covariance matrix
> 'sigma'. Both are required by dmvnorm(). In summary, nlminb() required a vector of
> parameters, so I supplied the number of parameters I needed nlminb() to optimize and
> simply built the required formats within the function.
> 
> It didn't occur to me until I saw the error that nlminb() would have no way of knowing the
> proper boundaries of the parameter space unless there is some way to communicate the
> constraints. nlminb() implements simple box constraints, but I don't see a way to
> communicate "parameters 3, 4, and 5 must satisfy 3*4 - 5^2 > 0.
> 
> Regarding your suggestion, I don't think I understand. Might you elaborate?
> 
> Thanks & Best Regards,
> Steven
> 
> > exact<-function(theta,complete,deleted){
> >>
> >>    u<-c(theta[1],theta[2])
> >>    sigma<-c(theta[3],theta[5],theta[5],theta[4])
> >>    dim(sigma)<-c(2,2)
> >>    -sum(log(dmvnorm(x=complete,mean=u,sigma=sigma)))-
> >>        sum(log(dnorm(one.only,u[1],sigma[1,1])))-
> >>            sum(log(dnorm(two.only,u[2],sigma[2,2])))
> >> }
> >>
> nlminb(start=c(0,0,1,1,0),objective=exact,complete=complete,deleted=deleted,control=l
> >> ist(trace=1))


From markleeds2 at gmail.com  Mon Oct 21 17:16:18 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Mon, 21 Oct 2013 11:16:18 -0400
Subject: [R] nlminb() - how do I constrain the parameter vector properly?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA0D4F9@PA-MBX01.na.tibco.com>
References: <2F4EF2C2-6C30-41C7-908C-FFCAE8A0C02E@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0D424@PA-MBX01.na.tibco.com>
	<0ADAF72C-B591-4222-9AD5-24858F650784@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0D4F9@PA-MBX01.na.tibco.com>
Message-ID: <CAHz+bWa3p_iKXmmVFZrnena4W-2scyw-3h7m=S=HfahURfpnTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/c33bf0bc/attachment.pl>

From jholtman at gmail.com  Mon Oct 21 17:21:29 2013
From: jholtman at gmail.com (jim holtman)
Date: Mon, 21 Oct 2013 11:21:29 -0400
Subject: [R] merging matrices
In-Reply-To: <CAO4=jh7PL3YvpLtb-QK0+_s8wX0Ap42xc5f0QFRJ1=3NmK=qmg@mail.gmail.com>
References: <CAO4=jh7PL3YvpLtb-QK0+_s8wX0Ap42xc5f0QFRJ1=3NmK=qmg@mail.gmail.com>
Message-ID: <CAAxdm-7oKmBHdDHh5gNSUJet39Fdxfbbn6w5eNPa8vrqNcGcuQ@mail.gmail.com>

?list.files
?read.table
?rbind

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Mon, Oct 21, 2013 at 6:18 AM, Mohammad Goodarzi
<mohammad.godarzi at gmail.com> wrote:
> Dear all,
>
> I have to load more than 1000 matrices from desktop which all of them have
> the same size.
> If I do it manually, it would be very hard, can you please guide me how to
> load them and merge them together ?
>
> for example I want to put them one after another
> X1 X2 X3 etc
>
> Many thanks,
> Mohammad
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Mon Oct 21 17:38:03 2013
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 21 Oct 2013 09:38:03 -0600
Subject: [R] list and <<-
In-Reply-To: <CAM4FiqHQN-AFjsw+Fn1uOaAtDsgLqxp=ap=hepyThk=aPa0cjQ@mail.gmail.com>
References: <CAM4FiqHQN-AFjsw+Fn1uOaAtDsgLqxp=ap=hepyThk=aPa0cjQ@mail.gmail.com>
Message-ID: <CAFEqCdwUaB-xaoqSpXg7SEn5-dANuu+v7feHoaT_trB7j4fkJw@mail.gmail.com>

See fortune(174).

It is best to avoid using '<<-', if you tell us what you are trying to
accomplish then we may be able to provide a better means to accomplish
it.

On Sat, Oct 19, 2013 at 10:28 PM, Taiyun Wei <weitaiyun at gmail.com> wrote:
> Dear All,
>
>> opt = list()
>> opt$aa <<- TRUE
> Error in opt$aa <<- TRUE : object 'opt' not found
>
> Why?
>
> --
> Regards,
> Taiyun
> --
> Taiyun Wei <weitaiyun at gmail.com>
> Homepage: http://blog.cos.name/taiyun/
> Phone: +86-15201142716
> Renmin University of China
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From zhangweiwu at realss.com  Mon Oct 21 17:40:00 2013
From: zhangweiwu at realss.com (Weiwu Zhang)
Date: Mon, 21 Oct 2013 23:40:00 +0800
Subject: [R] Am I working with regularly spaced time series?
Message-ID: <CAEvpD63R3Goc-0wb-aV44JMWAJoV+hBcDqMw2=A_XPxqunP_sw@mail.gmail.com>

My data is sampled once per minute. There are invalid samples, leaving
a lot of holes in the samples, successful sample is around 80% of all
minutes in a day. and during the last 4 months sampling, one month's
data was stored on a harddisk that failed, leaving a month's gap in
between.

So am I working with regularly spaced time series or not? Should I
padd all missing data with NAs, and start with ts(), and followed by
forecast package (which seems to have all the functions I need in the
begining) or should I start with a library with irregular time series
in mind?

Also, ts() manual didn't say how to create time-series with one minute
as daltat. Its seems to assume time-series is about dates. So the data
I have with me, is it really time series at all?

Newbie question indeed. Thanks.


From wdunlap at tibco.com  Mon Oct 21 18:28:38 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 21 Oct 2013 16:28:38 +0000
Subject: [R] nlminb() - how do I constrain the parameter vector properly?
In-Reply-To: <F2024EB6-EF65-4378-BD00-1F1670416A29@gmail.com>
References: <2F4EF2C2-6C30-41C7-908C-FFCAE8A0C02E@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0D424@PA-MBX01.na.tibco.com>
	<0ADAF72C-B591-4222-9AD5-24858F650784@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0D4F9@PA-MBX01.na.tibco.com>
	<F2024EB6-EF65-4378-BD00-1F1670416A29@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0D5BD@PA-MBX01.na.tibco.com>

[I added r-help to the cc again.  Please keep the replies on the list as
there are others who can contribute to or learn from them.]

> I also learned you have to be very careful with the starting value, as the simple identity
> matrix becomes singular under the transformation.

That is why I suggested using the non-zero entries in chol(sigmaStart), where
sigmaStart is your initial estimate of the variance matrix, as the initial
values of theta[3:5].

I should have said that crossProd(x) gives you a positive semidefinite matrix,
not positive definite.  When I said that variances near 0 would cause problems
I meant that a singular covariance matrix would cause problems.


Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Steven LeBlanc [mailto:oreslag at gmail.com]
> Sent: Monday, October 21, 2013 9:21 AM
> To: William Dunlap
> Subject: Re: [R] nlminb() - how do I constrain the parameter vector properly?
> 
> 
> On Oct 21, 2013, at 7:52 AM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> > Try defining the function
> >    theta345toSigma <- function(theta) {
> >       cholSigma <- cbind(c(theta[3], 0), c(theta[4], theta[5]))
> >       crossprod(cholSigma) # t(cholSigma) %*% cholSigma)
> >    }
> > This creates a positive definite matrix for any theta (and
> > any positive definite matrix has such a representation, generally
> > more than one).  It is like using the square root of a quantity
> > in the optimizer when you know the quantity must be non-negative.
> >
> > Then change your
> >    sigma <- c(theta[3],theta[5],theta[5],theta[4])
> >    dim(sigma) <- c(2, 2)
> > to
> >    sigma <- theta345toSigma(theta)
> >
> > If one of your variances is near 0 the optimizer may run into
> > trouble at saddlepoints.  Others may be able to help better
> > with that issue.
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> 
> Hi Bill,
> 
> I tried your suggestion and the optimizer produces a result, but it seems substantially far
> from the anticipated result and from the result obtained when I use Inf as a return value
> for an invalid covariance matrix. Perhaps it would work if I made other adjustments to
> account for the 'bias' (using this term very loosely) induced by changing an invalid
> parameter vector into something valid but incorrect?
> 
> I also learned you have to be very careful with the starting value, as the simple identity
> matrix becomes singular under the transformation.
> 
> > theta<-c(0,0,1,1,0)
> > cholSigma<-cbind(c(theta[3], 0), c(theta[4], theta[5]))
> > sigma<-crossprod(cholSigma)
> > sigma
>      [,1] [,2]
> [1,]    1    1
> [2,]    1    1
> 
> In any case, the Inf trick works for now. I was asking about 'adjustments' strictly out of
> curiosity. Code and results are below.
> 
> Best Regards,
> Steven
> 
> > exact<-function(theta,complete,deleted){
> +     one.only<-deleted[!(is.na(deleted[,1])),1]
> +     two.only<-deleted[!(is.na(deleted[,2])),2]
> +     u<-c(theta[1],theta[2])
> +     sigma<-c(theta[3],theta[5],theta[5],theta[4])
> +     dim(sigma)<-c(2,2)
> +     if(!(is.positive.semi.definite(sigma))){return(Inf)}
> +     -sum(log(dmvnorm(x=complete,mean=u,sigma=sigma)))-
> +         sum(log(dnorm(one.only,u[1],sigma[1,1])))-
> +             sum(log(dnorm(two.only,u[2],sigma[2,2])))
> + }
> > exact2<-function(theta,complete,deleted){
> +     one.only<-deleted[!(is.na(deleted[,1])),1]
> +     two.only<-deleted[!(is.na(deleted[,2])),2]
> +     u<-c(theta[1],theta[2])
> +     cholSigma<-cbind(c(theta[3], 0), c(theta[4], theta[5]))
> +     sigma<-crossprod(cholSigma)
> +     -sum(log(dmvnorm(x=complete,mean=u,sigma=sigma)))-
> +         sum(log(dnorm(one.only,u[1],sigma[1,1])))-
> +             sum(log(dnorm(two.only,u[2],sigma[2,2])))
> + }
> > nlminb(start=theta.hat.em,objective=exact,complete=complete,deleted=deleted)$par
> [1] 1.2289422 5.4995271 0.9395155 4.8069068 1.8009213
> > nlminb(start=theta.hat.em,objective=exact2,complete=complete,deleted=deleted)$par
> [1] 1.2289421 5.4995265 0.9692861 1.8579876 1.1639544


From kw.stat at gmail.com  Mon Oct 21 18:58:31 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 21 Oct 2013 11:58:31 -0500
Subject: [R] plot correlation matrix
In-Reply-To: <1382366734.8245.YahooMailNeo@web125303.mail.ne1.yahoo.com>
References: <1382366734.8245.YahooMailNeo@web125303.mail.ne1.yahoo.com>
Message-ID: <CAKFxdiSGGPXZqYzkQxds1V+XGWf-NAsJLagRq7fGXYqu-hLZ_w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/1d33e607/attachment.pl>

From markleeds2 at gmail.com  Mon Oct 21 14:48:47 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Mon, 21 Oct 2013 08:48:47 -0400
Subject: [R] R-help Digest, Vol 128, Issue 22
In-Reply-To: <5265217F.10307@uottawa.ca>
References: <mailman.25.1382349611.25802.r-help@r-project.org>
	<5265217F.10307@uottawa.ca>
Message-ID: <CAHz+bWYEOJDNP66uTaZXG6yogOBpxxZPuDPRioTU9qhH4KJE2g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/d1e1c6bf/attachment.pl>

From farewelld at cf.ac.uk  Mon Oct 21 13:06:59 2013
From: farewelld at cf.ac.uk (Daniel Farewell)
Date: Mon, 21 Oct 2013 12:06:59 +0100
Subject: [R] Statistical software interoperability meeting
Message-ID: <20131021110659.GE337@Menken.local>

The British and Irish Region of the International Biometric Society
would like to bring your attention to a half-day meeting on Statistical
Software Interoperability on Thursday 14th November 2013 at the
headquarters of the Royal Statistical Society, Errol Street, London, UK. 

Please see 

http://bir.biometricsociety.org/events/interop

for registration, and more details.

Closing date for online registration: Friday 8th November 2013

This is an afternoon meeting featuring four presentations from leading
figures in computational statistics, giving talks on new developments
that involve interoperability between statistical software packages.
Some of the speakers will discuss interoperability with R.

This is a joint meeting of the Statistical Computing Section of the
Royal Statistical Society and the British and Irish Region of the
International Biometric Society.

Cost:
Member of Biometric/Royal Statistical Society: ?20
Student/Retired Member: ?10
Non-Member: ?35


From rickturner at btconnect.com  Mon Oct 21 15:57:34 2013
From: rickturner at btconnect.com (Rick Turner)
Date: Mon, 21 Oct 2013 14:57:34 +0100
Subject: [R] Problem with coordinates when trying to draw lines into a
 raster (image) file
Message-ID: <526532CE.6020404@btconnect.com>


   Hi All,

   I am struggling with something, and could use some help

   I have a scenario where I need to draw lines onto a base image using R ???
   briefly, the image has what amounts to an outline ???map??? of locations, and
   the lines will correspond to ???routes??? between two locations.

   The locations are known in terms of image pixel coordinates ??? let???s call
   them (px1, py1) and (px2, py2), but when I try and plot a line into the
   image using these coordinates, the visual positions are incorrect ??? the
   start and end points of the line are offset from the desired position, and
   the amount of offset changes as I resize the window. I've tried such things
   as normalising them into the [0,1] range used by the viewport but this does
   not correct the problem.

   So,  I  figured  that I must have made some mistake with my scaling of
   coordinates from image to viewport, but I cannot find where or what. I???ve
   fiddled around a bit (well, a lot!) but cannot get the desired result. So,
   it is time to ask for help, hence this message???.

   Any  suggestions  gratefully  received???   I???ve done a fair amount of R
   programming, but have not used these extended graphics capabilities much at
   all, so I really am getting frustrated....

   Regards and thanks in advance,
   Rick

   ----------------------------------------------------------------------------
   --------------------------------------------------

   The code segment in question is:

   # load packages

   library(jpeg)

   library(grid)


   # read the image file

   baseimg <- readJPEG("loc_map.jpg", native=FALSE)

   xsize <- ncol(baseimg)                   # Get image size ??? this one is 1344
   px wide

   ysize <- nrow(baseimg)                 # and 1008 px high


   # create a viewport

   xrange <- c(0, xsize)                        # set up the viewport range to
   match the image size

   yrange <- c(0, ysize)

   vp  <-  viewport(x=0.5,  y=0.5,  width=0.9, height=0.9, xscale=xrange,
   yscale=yrange)

   pushViewport(vp)

   grid.rect(gp=gpar(lty="dashed"))        # draw a dashed line around it.


   # display the base image

   grid.raster(baseimg)


   # First location ??? image pixel coordinates (748, 177). Normalise these to
   [0,1] to

   # match the viewpoint coordinate scheme. Note that we need to invert the

   # y coordinate as R coords run from bottom up, but image ones are top down

   px1 <- (748/xsize)                                            # 748/1344 ~=
   0.556, so in range [0,1]

   py1 <- (1.0 - (177/ysize))                               # 1-(177/1008) ~=
   0.824, so also in range [0,1]


   # position of the St Johns Hill enterance (image coords

   # [769, 892]) normalised to the viewport

     x2 <- (769/xsize)

     y2 <- (1.0 - (892/ysize))


     # draw a line from pixel (px1,py1) to pixel (px2,py2) in blue

     xx <- c(px1, px2)

     yy <- c(py1, py2)

     grid.lines(xx, yy, gp=gpar(col="blue"))

From sartene at voila.fr  Mon Oct 21 16:29:55 2013
From: sartene at voila.fr (sartene at voila.fr)
Date: Mon, 21 Oct 2013 16:29:55 +0200 (CEST)
Subject: [R] Aggregate values in one dataframe into a list of vectors of
 different sieze
Message-ID: <362508921.88181382365795672.JavaMail.www@wwinf7128>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/407e5b49/attachment.pl>

From sartene at voila.fr  Mon Oct 21 17:41:53 2013
From: sartene at voila.fr (sartene at voila.fr)
Date: Mon, 21 Oct 2013 17:41:53 +0200 (CEST)
Subject: [R] tr: Aggregate values in one dataframe into a list of vectors of
 different sieze
Message-ID: <387514723.105571382370113385.JavaMail.www@wwinf7139>


I just found out what I was looking for, aggregate did the trick:
AggregatedList <- aggregate(data = Sample, Value ~ Name, list)

Hope this will help someone else!


Sartene Bel

> Message du 21/10/13 ? 16h29
> De : sartene at voila.fr
> A : r-help at r-project.org
> Copie ? : 
> Objet : Aggregate values in one dataframe into a list of vectors of different sieze
> 
> Hi everyone,
> 
> I have a data frame that is quite huge (dozens of millions of lines).
> 
> It looks like this :
> 
> Name????? Value
> Name1??? 156
> Name2??? 458963
> Name3??? 758
> ...
> Name143 89325
> Name1???? 4678
> Name42?? 766
> Name144 777
> ...
> Name2???? 46767
> ...
> 
> Each name and and value has no predefined length and may be repeated any number of times.
> 
> My goal is to have a list (aggregating the numbers relative to each name, so to obtain a data frame which looks like this:
> Name???? Values
> Name1?? 156, 4678,...
> Name2?? 458963, 46767...
> ...
> 
> Creating the unique names in the first column is easy via the unique function, but I did not find any way to regroup in matching vectors the different values 
aggregated for each name, of to directly create a data frame like I want.
> 
> The ultimate goal is to use the values in the vectors to do some statistics (means, etc.), but that is another matter for later!
> 
> Thanks for your help.
> 
> 
> Sartene Bel
> ___________________________________________________________
> Les pr?visions m?t?o pour aujourd'hui, demain et jusqu'? 8 jours ! Voila.fr http://meteo.voila.fr/
___________________________________________________________
Les pr?visions m?t?o pour aujourd'hui, demain et jusqu'? 8 jours ! Voila.fr http://meteo.voila.fr/


From valentina.lauria at nuigalway.ie  Mon Oct 21 18:28:47 2013
From: valentina.lauria at nuigalway.ie (Lauria, Valentina)
Date: Mon, 21 Oct 2013 16:28:47 +0000
Subject: [R] Predicting hurdle model results on spatial scale
Message-ID: <B11DE93D7F439D4BA1E942572BA750308BC65EED@UDSMBX01.uds.nuigalway.ie>

Dear List,

I apologise in advance for all my questions. 

I am interested to predict the habitat selection of fish species using the hurdle model. I know that I can perform this in R with the function predict.hurdle() on newdata, however how this work  is not entirely clear.

Usually with a two-step approach a binary and a poisson models are created to deal with zero-inflated and over-dispersed data, then the binary model is multiplied by the poisson model in order weight the predictions.  Is this already included in the predict.hurdle function? 

Also I am using the function dredge (from the MuMin package) to select my best model based on AIC, still in this case the best model selected seems to be a combination between the truncated poisson and the binary model (hurdle model). Is there any way that I could dredge the two model components separately? I did some research and in the NEWS section I found that a package pscf was created for this but when I did more digging around I did not have much luck.

I would be grateful if someone could help me. 
Thank you very much once again,
Valentina




-----Original Message-----
From: Achim Zeileis [mailto:Achim.Zeileis at uibk.ac.at] 
Sent: 18 October 2013 18:57
To: Lauria, Valentina
Cc: r-help at r-project.org
Subject: Re: [R] hurdle model error why does need integer values for the dependent variable?

On Fri, 18 Oct 2013, Lauria, Valentina wrote:

> Dear list,
>
> I am using the hurdle model for modelling the habitat of rare fish 
> species. However I do get an error message when I try to model my data:
>
>> test_new1<-hurdle(GALUMEL~ depth + sal + slope + vrm + lat:long + 
>> offset(log(haul_numb)), dist = "negbin", data = datafit_elasmo)
>
> Error in hurdle(GALUMEL ~ depth + sal + slope + vrm + lat:long + offset(log(haul_numb)),  :
>  invalid dependent variable, non-integer values
>
> When I do fit the same model with round(my dependent variable) the 
> model works. Sorry for the stupid question but could anyone explain me 
> why? My data are zero inflated (zeros occurring for 78%) and positively skewed.

hurdle() fits a count data distribution (poisson, negbin, geometric) by maximum likelihood. Hence, its response needs to be a count variable (i.e., integer). See vignette("countreg", package = "pscl") for the underlying likelihoods employed.

> Thank you very much in advance.
> Kind Regards,
> Valentina
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From william.tambellini at galaxysemi.com  Mon Oct 21 19:09:26 2013
From: william.tambellini at galaxysemi.com (Tambellini William)
Date: Mon, 21 Oct 2013 10:09:26 -0700
Subject: [R] About integrating R inside a C++ software
Message-ID: <52655FC6.7030700@galaxysemi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/425e9bdf/attachment.pl>

From markleeds2 at gmail.com  Mon Oct 21 19:33:05 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Mon, 21 Oct 2013 13:33:05 -0400
Subject: [R] nlminb() - how do I constrain the parameter vector properly?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA0D5BD@PA-MBX01.na.tibco.com>
References: <2F4EF2C2-6C30-41C7-908C-FFCAE8A0C02E@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0D424@PA-MBX01.na.tibco.com>
	<0ADAF72C-B591-4222-9AD5-24858F650784@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0D4F9@PA-MBX01.na.tibco.com>
	<F2024EB6-EF65-4378-BD00-1F1670416A29@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0D5BD@PA-MBX01.na.tibco.com>
Message-ID: <CAHz+bWYQ2yJ2nF6e744D-FE-KZe2XFK0L_ePXL428QpwpuSB2Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/22952996/attachment.pl>

From canamika at gmail.com  Mon Oct 21 19:55:00 2013
From: canamika at gmail.com (Anamika Chaudhuri)
Date: Mon, 21 Oct 2013 13:55:00 -0400
Subject: [R] Data Manipulation in R
In-Reply-To: <1382332318.35234.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <CALv--dYT7G4zZ_4VDAWjSJimWQ6JHaMn8bHmoi0oj3zP1XYiqQ@mail.gmail.com>
	<1382332318.35234.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CALv--dZEDuDHO+PFcnaATEY8vDWjbjtD4OA4z7FyzGm5xnF3UQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/c30a6ea7/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Mon Oct 21 20:08:49 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 21 Oct 2013 11:08:49 -0700
Subject: [R] About integrating R inside a C++ software
In-Reply-To: <52655FC6.7030700@galaxysemi.com>
References: <52655FC6.7030700@galaxysemi.com>
Message-ID: <226d9285-d6a2-4ecd-8407-bcc3fb81d625@email.android.com>

Don't cross-post. If discussed further, this should probably be in r-devel, but I am not on that list.

Also, what is your question? I don't really see a question here. It might be along the lines of what technical solutions others like, but your research seems thorough enough for you to apply your own opinions. If it is legal (this is not a legal advice forum), keep in mind that many of the valuable algorithms in R are really in packages, and they may have similar but different licensing restrictions than R. However, as long as your software conforms to GPL2 (used in house only or released with source code) you are probably most of the way there. If not, you may need to keep the system calls in there or start discussions with the individual package authors to avoid stepping on licensing mines.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Tambellini William <william.tambellini at galaxysemi.com> wrote:
>Hi,
>  We are a company developing a software mainly in C++.
> We want to integrate R inside our software in order to use mainly the 
>engine (usual stats as mean, sigma, Pearson, outlier detection, CPA, 
>multivariate, ...) and probably later the chart solution.
> Of course we don't want to temporary write the data to some csv files 
>and then do an ugly system() call : system("RScript.exe myscript.R")
>for 
>many legitimate reasons.
>  We are also using Qt so a Qt to/from R wrapper could be interesting.
>  For the moment, we have found these solutions :
>- using directly the standard R C API : R.h, Rmath.h, R_ext, ....
>- Rcpp : www.rcpp.org
>- QtInterfaces : http://r-forge.r-project.org/projects/qtinterfaces/
>- RInside http://dirk.eddelbuettel.com/code/rinside.html
>
>  Any advices ?
>Kind regards
>William.


From carl at witthoft.com  Mon Oct 21 20:10:29 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Mon, 21 Oct 2013 11:10:29 -0700 (PDT)
Subject: [R] merging matrices
In-Reply-To: <CAO4=jh7PL3YvpLtb-QK0+_s8wX0Ap42xc5f0QFRJ1=3NmK=qmg@mail.gmail.com>
References: <CAO4=jh7PL3YvpLtb-QK0+_s8wX0Ap42xc5f0QFRJ1=3NmK=qmg@mail.gmail.com>
Message-ID: <1382379029454-4678721.post@n4.nabble.com>

If you have over a thousand files on your desktop, you have bigger problems
than just how to load them into R.   
Where do these files come from, and why do you want to "merge" them into a
single entity?




--
View this message in context: http://r.789695.n4.nabble.com/merging-matrices-tp4678702p4678721.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Mon Oct 21 20:11:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 21 Oct 2013 11:11:10 -0700 (PDT)
Subject: [R] Data Manipulation in R
In-Reply-To: <CALv--dZEDuDHO+PFcnaATEY8vDWjbjtD4OA4z7FyzGm5xnF3UQ@mail.gmail.com>
References: <CALv--dYT7G4zZ_4VDAWjSJimWQ6JHaMn8bHmoi0oj3zP1XYiqQ@mail.gmail.com>	<1382332318.35234.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CALv--dZEDuDHO+PFcnaATEY8vDWjbjtD4OA4z7FyzGm5xnF3UQ@mail.gmail.com>
Message-ID: <1382379070.79527.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

I am getting this.


?res <- lapply(seq_len(nrow(Y1)),function(i) {dat <- data.frame(X=i,Y1=unlist(Y1[i,]),Y2=unlist(Y2[i,])); row.names(dat) <- 1:nrow(dat); write.csv(dat,paste0("Anam",i,".csv"),row.names=FALSE,quote=FALSE)})


dat1 <- read.csv("Anam1.csv",header=TRUE)

?dat1
? X Y1 Y2
1 1? 4 20
2 1? 0 52
3 1 20 15
4 1 17 18


Attaching one of the files generated.


A.K.




On Monday, October 21, 2013 1:55 PM, Anamika Chaudhuri <canamika at gmail.com> wrote:

Hi Arun:

Thanks for your help. Seperate files are being created by concatenating the rows from the two files but I was looking to have them as columns rather than text. This is the way it appears in Excel with row # at the beginning.
X?Y1?Y2
1?1 4 0 20 17 1 20 52 15 18

Ideally I would like it to look like
X?Y1?Y2
1?4?20
1?0?52
1?20?15
1?17?18

Thanks again!
Anamika


On Mon, Oct 21, 2013 at 1:11 AM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>May be this helps:
>Y1 <- read.table(text="V1 V2 V3 V4
>
>1 4 0 20 17
>2 4 0 15 17
>3 2 0 13 21",sep="",header=TRUE)
>
>Y2 <- read.table(text="V1 V2 V3 V4
>
>1 20 52 15 18
>2 18 54 14 21
>3 18 51 13 21",sep="",header=TRUE)
>?res <- lapply(seq_len(nrow(Y1)),function(i) {dat <- data.frame(X=i,Y1=unlist(Y1[i,]),Y2=unlist(Y2[i,])); row.names(dat) <- 1:nrow(dat); write.csv(dat,paste0("file",i,".csv"),row.names=FALSE,quote=FALSE)})
>
>
>A.K.
>
>
>
>
>
>A.K.
>
>
>
>
>
>On Monday, October 21, 2013 12:24 AM, Anamika Chaudhuri <canamika at gmail.com> wrote:
>Hi:
>
>I am looking for some help to manipulate data in R. I have two csv files.
>
>datasetY1
>V1 "V2" "V3" "V4"
>1 4 0 20 17
>2 4 0 15 17
>3 2 0 13 21
>
>datasetY2
>V1 "V2" "V3" "V4"
>1 20 52 15 18
>2 18 54 14 21
>3 18 51 13 21
>
>I want to be able to create separate csv files by taking the corresponding
>rows of dataset1 and dataset2, convert them into columns. So from the above
>example I would be creating 3 datasets (csvs), of which the first one would
>be
>? ? ? ? ? ? ? ?X? ? ? ? ? ? ?Y1? ? ? ? ? ? Y2? 1 4 20? 1 0
>52? 1 20 15? 1 17
>18
>? Appreciate any help.
>
>Thanks
>Anamika
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>

From carl at witthoft.com  Mon Oct 21 20:45:36 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Mon, 21 Oct 2013 11:45:36 -0700 (PDT)
Subject: [R] help creating a simple function to rename columns
In-Reply-To: <1382378400643-4678719.post@n4.nabble.com>
References: <1382378400643-4678719.post@n4.nabble.com>
Message-ID: <1382381136191-4678726.post@n4.nabble.com>

Steve E. wrote
> Hi R users,
> 
> I am having some trouble with a very simple function that I hope that you
> might be able to help me with (and, really, to shed some light on how
> functions work generally). I have a series of very small 2-column data
> frames of which I need to change the column names. A simple command such
> as this one below works just fine on any given data frame:
> 
> colnames(DF) <- c("newname1","newname2")
> 
> However, I have to do this for numerous files and would like to address it
> with a function for easier processing but when I put the above in a
> function like this: 
> 
> cnames <- function(DF) {colnames(DF) <- c("newname1","newname2")}
> 
> the function returns a list of the column names instead of the modified
> data frame (e.g., DF <- cnames(DF) returns the list
> c("newname1","newname2") instead of a data frame with the desired column
> names).

1) You've confused what a function *returns* with what goes on inside.  Your
function quite correctly returns the result of the last command, which in
this case is  c('newname1','newname2') .
2) Anything you do *inside* a function persists only in that environment. 
What that means is that your "DF" inside the function is not your "DF" in
your working environment, so nothing you do (with exceptions not to be gone
into here) will change the actual matrix.

An easier way: 
alldf<-list(df1,df2,df3) # for however many little dfs you have
for(j in 1:length(alldf) )  colnames(alldf[[j]])<- c("newname1","newname2")  

I suspect there are cleaner tools in the *apply function  set (or the
data.frame package).




--
View this message in context: http://r.789695.n4.nabble.com/help-creating-a-simple-function-to-rename-columns-tp4678719p4678726.html
Sent from the R help mailing list archive at Nabble.com.


From pdalgd at gmail.com  Mon Oct 21 20:55:52 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 21 Oct 2013 20:55:52 +0200
Subject: [R] Recovering object names when using the ... argument in a fn
	XXXX
In-Reply-To: <5262BB5D.1090802@gmail.com>
References: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>	<E66794E69CFDE04D9A70842786030B933FA0BEB1@PA-MBX01.na.tibco.com>
	<CACk-te11CuSEeVJZoVMa_2c2g2rFMwwumfvpWOzoUXQdq8uyRg@mail.gmail.com>
	<5262BB5D.1090802@gmail.com>
Message-ID: <B98E3C80-772D-4B0E-99F6-189F65800465@gmail.com>


On Oct 19, 2013, at 19:03 , Duncan Murdoch wrote:

> On 13-10-18 1:54 PM, Bert Gunter wrote:
>> Yes, similar, but better, as match.call() will get unwanted named
>> arguments, too.
>> 
>> However, I do not understand the
>> 
>> substitute(...())
>> 
>> idiom. Would you care to explain it? (No is an acceptable  answer!).
> 
> I suspect it's a bug, though I can't see it's one that's likely to need fixing.  The general idea is that a function call like ...() is parsed into a pairlist containing just the name "...", then substitute replaces it with the content of that variable, which is a pairlist containing the unevaluated argument list.  So by that analysis, you might expect to get the same result using
> 
> pairlist(...)
> 
> However, you don't, because the latter expression evaluates all the arguments to the function, while Bill's idiom leaves them unevaluated. I can't think of any documented reason why that should be, but on the other hand, I can't think of any reason it would cause problems.  So I'd say it's unlikely to be deliberately changed, but it might change as a result of some internal change to R.
> 
> Duncan Murdoch
> 

Just curious, does substitute(...()) buy you anything that you don't get from the straightforward

match.call(expand.dots=FALSE)$...

???
-pd


> 
>> 
>> I would have expressed it as:
>> 
>> as.list(substitute(list(...)))[-1]
>> 
>> to convert the parse tree to a list. (which is again better than using
>> match.call() ).
>> 
>> Best,
>> Bert
>> 
>> On Fri, Oct 18, 2013 at 10:27 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>>> I am using the ... argument to parmeterize a user define fn to accept
>>>> multiple input objects. I subsquently save all these data as a list.
>>>> Question: what is the best way to recover or extract the original object
>>>> names that were fed to the fn?
>>> 
>>> The following function, ellipsisInfo, returns character strings representing the
>>> actual arguments to the function.  If the function was called with tags on the
>>> arguments, as in ellipsisInfo(tag=argument), it makes those tags the names
>>> on the returned character  vector.  It does not evaluate the ... arguments, so
>>> you don't run into problems with evaluating arguments too soon or evaluating
>>> ones that should not be evaluated most of the time.
>>> 
>>> ellipsisInfo <- function(...) {
>>>     # get the unevaluated expressions given as arguments
>>>     unevaluatedArgs <- substitute(...())
>>>     # convert those expressions to text (truncate to single line)
>>>     unevaluatedArgsAsText <- vapply(unevaluatedArgs, function(a)deparse(a)[1], "")
>>>     unevaluatedArgsAsText
>>> }
>>> 
>>> E.g.,
>>> 
>>>> i <- ellipsisInfo(x, log(10), e=exp(1), onProblem=stop("there was a problem"))
>>>> i
>>> 
>>>                             "x"
>>> 
>>>                       "log(10)"
>>>                               e
>>>                        "exp(1)"
>>>                       onProblem
>>> "stop(\"there was a problem\")"
>>>> ifelse(names(i)=="", i, names(i)) # use tag if supplied, otherwise argument itself
>>> [1] "x"         "log(10)"   "e"
>>> [4] "onProblem"
>>> 
>>> Bill Dunlap
>>> Spotfire, TIBCO Software
>>> wdunlap tibco.com
>>> 
>>> 
>>>> -----Original Message-----
>>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>>>> Of Dan Abner
>>>> Sent: Friday, October 18, 2013 9:06 AM
>>>> To: r-help at r-project.org
>>>> Subject: [R] Recovering object names when using the ... argument in a fn XXXX
>>>> 
>>>> Hi all,
>>>> 
>>>> I am using the ... argument to parmeterize a user define fn to accept
>>>> multiple input objects. I subsquently save all these data as a list.
>>>> Question: what is the best way to recover or extract the original object
>>>> names that were fed to the fn?
>>>> 
>>>> Thanks,
>>>> 
>>>> Dan
>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dromero at mda.cinvestav.mx  Mon Oct 21 20:04:42 2013
From: dromero at mda.cinvestav.mx (David Romero)
Date: Mon, 21 Oct 2013 13:04:42 -0500
Subject: [R]  Error in heatmap
Message-ID: <000f01cece88$0442bdc0$0cc83940$@cinvestav.mx>

Hi,

 

Could you please help?

 

Heatmap  doesn't work with:

 

> heatmap(as.matrix(SPIV2),na.rm = T)

Error in hclustfun(distfun(x)) : 

  NA/NaN/Inf in foreign function call (arg 11)

 

There are no 0 data rows or column

 

Thanks a lot

 

Regards

---------------------------------------

David

 


From wdunlap at tibco.com  Mon Oct 21 21:13:41 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 21 Oct 2013 19:13:41 +0000
Subject: [R] Recovering object names when using the ... argument in a fn
 XXXX
In-Reply-To: <B98E3C80-772D-4B0E-99F6-189F65800465@gmail.com>
References: <CAPRGo-kJaCcnTa0WTAo1VDg_K3mgU=1FMeZdnfT1yA=cA+uttg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0BEB1@PA-MBX01.na.tibco.com>
	<CACk-te11CuSEeVJZoVMa_2c2g2rFMwwumfvpWOzoUXQdq8uyRg@mail.gmail.com>
	<5262BB5D.1090802@gmail.com>
	<B98E3C80-772D-4B0E-99F6-189F65800465@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0D75B@PA-MBX01.na.tibco.com>

> Just curious, does substitute(...()) buy you anything that you don't get from the
> straightforward
> 
> match.call(expand.dots=FALSE)$...

substitute() makes is easier to bury the idiom in a function so you don't have to
remember the weird syntax.
   > dotdotdot1 <- function(...)substitute(...())
   > dotdotdot2 <- function(...)match.call(expand.dots=FALSE)$...
   > (function(..., FUN)dotdotdot1(...))(1:10, onProblem=stop("oops"), FUN=objects)
   [[1]]
   1:10
   
   $onProblem
   stop("oops")

   > (function(..., FUN)dotdotdot2(...))(1:10, onProblem=stop("oops"), FUN=objects)
   [[1]]
   ..1
   
   $onProblem
   ..2

I suppose one could figure out appropriate values for match.call's 'definition'
and 'call' arguments to make this work.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: peter dalgaard [mailto:pdalgd at gmail.com]
> Sent: Monday, October 21, 2013 11:56 AM
> To: Duncan Murdoch
> Cc: Bert Gunter; William Dunlap; r-help at r-project.org
> Subject: Re: [R] Recovering object names when using the ... argument in a fn XXXX
> 
> 
> On Oct 19, 2013, at 19:03 , Duncan Murdoch wrote:
> 
> > On 13-10-18 1:54 PM, Bert Gunter wrote:
> >> Yes, similar, but better, as match.call() will get unwanted named
> >> arguments, too.
> >>
> >> However, I do not understand the
> >>
> >> substitute(...())
> >>
> >> idiom. Would you care to explain it? (No is an acceptable  answer!).
> >
> > I suspect it's a bug, though I can't see it's one that's likely to need fixing.  The general
> idea is that a function call like ...() is parsed into a pairlist containing just the name "...",
> then substitute replaces it with the content of that variable, which is a pairlist containing
> the unevaluated argument list.  So by that analysis, you might expect to get the same
> result using
> >
> > pairlist(...)
> >
> > However, you don't, because the latter expression evaluates all the arguments to the
> function, while Bill's idiom leaves them unevaluated. I can't think of any documented
> reason why that should be, but on the other hand, I can't think of any reason it would
> cause problems.  So I'd say it's unlikely to be deliberately changed, but it might change as
> a result of some internal change to R.
> >
> > Duncan Murdoch
> >
> 
> Just curious, does substitute(...()) buy you anything that you don't get from the
> straightforward
> 
> match.call(expand.dots=FALSE)$...
> 
> ???
> -pd
> 
> 
> >
> >>
> >> I would have expressed it as:
> >>
> >> as.list(substitute(list(...)))[-1]
> >>
> >> to convert the parse tree to a list. (which is again better than using
> >> match.call() ).
> >>
> >> Best,
> >> Bert
> >>
> >> On Fri, Oct 18, 2013 at 10:27 AM, William Dunlap <wdunlap at tibco.com> wrote:
> >>>> I am using the ... argument to parmeterize a user define fn to accept
> >>>> multiple input objects. I subsquently save all these data as a list.
> >>>> Question: what is the best way to recover or extract the original object
> >>>> names that were fed to the fn?
> >>>
> >>> The following function, ellipsisInfo, returns character strings representing the
> >>> actual arguments to the function.  If the function was called with tags on the
> >>> arguments, as in ellipsisInfo(tag=argument), it makes those tags the names
> >>> on the returned character  vector.  It does not evaluate the ... arguments, so
> >>> you don't run into problems with evaluating arguments too soon or evaluating
> >>> ones that should not be evaluated most of the time.
> >>>
> >>> ellipsisInfo <- function(...) {
> >>>     # get the unevaluated expressions given as arguments
> >>>     unevaluatedArgs <- substitute(...())
> >>>     # convert those expressions to text (truncate to single line)
> >>>     unevaluatedArgsAsText <- vapply(unevaluatedArgs, function(a)deparse(a)[1], "")
> >>>     unevaluatedArgsAsText
> >>> }
> >>>
> >>> E.g.,
> >>>
> >>>> i <- ellipsisInfo(x, log(10), e=exp(1), onProblem=stop("there was a problem"))
> >>>> i
> >>>
> >>>                             "x"
> >>>
> >>>                       "log(10)"
> >>>                               e
> >>>                        "exp(1)"
> >>>                       onProblem
> >>> "stop(\"there was a problem\")"
> >>>> ifelse(names(i)=="", i, names(i)) # use tag if supplied, otherwise argument itself
> >>> [1] "x"         "log(10)"   "e"
> >>> [4] "onProblem"
> >>>
> >>> Bill Dunlap
> >>> Spotfire, TIBCO Software
> >>> wdunlap tibco.com
> >>>
> >>>
> >>>> -----Original Message-----
> >>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf
> >>>> Of Dan Abner
> >>>> Sent: Friday, October 18, 2013 9:06 AM
> >>>> To: r-help at r-project.org
> >>>> Subject: [R] Recovering object names when using the ... argument in a fn XXXX
> >>>>
> >>>> Hi all,
> >>>>
> >>>> I am using the ... argument to parmeterize a user define fn to accept
> >>>> multiple input objects. I subsquently save all these data as a list.
> >>>> Question: what is the best way to recover or extract the original object
> >>>> names that were fed to the fn?
> >>>>
> >>>> Thanks,
> >>>>
> >>>> Dan
> >>>>
> >>>>       [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 


From dwinsemius at comcast.net  Mon Oct 21 21:23:25 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 21 Oct 2013 12:23:25 -0700
Subject: [R] help creating a simple function to rename columns
In-Reply-To: <1382381136191-4678726.post@n4.nabble.com>
References: <1382378400643-4678719.post@n4.nabble.com>
	<1382381136191-4678726.post@n4.nabble.com>
Message-ID: <E2C68C6C-BFBB-4FDB-995F-861DFFD5B00C@comcast.net>


On Oct 21, 2013, at 11:45 AM, Carl Witthoft wrote:

> Steve E. wrote
>> Hi R users,
>> 
>> I am having some trouble with a very simple function that I hope that you
>> might be able to help me with (and, really, to shed some light on how
>> functions work generally). I have a series of very small 2-column data
>> frames of which I need to change the column names. A simple command such
>> as this one below works just fine on any given data frame:
>> 
>> colnames(DF) <- c("newname1","newname2")
>> 
>> However, I have to do this for numerous files and would like to address it
>> with a function for easier processing but when I put the above in a
>> function like this: 
>> 
>> cnames <- function(DF) {colnames(DF) <- c("newname1","newname2")}
>> 
>> the function returns a list of the column names instead of the modified
>> data frame (e.g., DF <- cnames(DF) returns the list
>> c("newname1","newname2") instead of a data frame with the desired column
>> names).
> 
> 1) You've confused what a function *returns* with what goes on inside.  Your
> function quite correctly returns the result of the last command, which in
> this case is  c('newname1','newname2') .
> 2) Anything you do *inside* a function persists only in that environment. 
> What that means is that your "DF" inside the function is not your "DF" in
> your working environment, so nothing you do (with exceptions not to be gone
> into here) will change the actual matrix.
> 
> An easier way: 
> alldf<-list(df1,df2,df3) # for however many little dfs you have
> for(j in 1:length(alldf) )  colnames(alldf[[j]])<- c("newname1","newname2")  
> 
> I suspect there are cleaner tools in the *apply function  set (or the
> data.frame package).

Carl;

In such an instance , you might try using either `names<-` or `colnames<-` with `lapply`.

alldf <- lapply(alldf, `names<-`, c("newname1","newname2")  )

-- 

David Winsemius
Alameda, CA, USA


From roger.bos at rothschild.com  Mon Oct 21 22:30:08 2013
From: roger.bos at rothschild.com (Bos, Roger)
Date: Mon, 21 Oct 2013 20:30:08 +0000
Subject: [R] speeding up "sum of squared differences" calculation
Message-ID: <0765308CD028654885F30322557308D80E1DF378@NYCSM0208.rth.ad.rothschild.com>

All,

I am using a sum of squared differences in the objective function of an optimization problem I am doing and I have managed to speed it up using the outer function versus the nested for loops, but my suspicion is that the calculation could be done even quicker.  Please see the code below for a simple example.  If anyone can point out a faster way I would appreciate it greatly.

Thanks,

Roger

X <- runif(1000)

now <- proc.time()
ans <- 0
for (i in 1:length(X)) {
  for (j in 1:length(X)) {
    ans <- ans + (X[i]-X[j])*(X[i]-X[j])
  }
}
ans
speed <- proc.time() - now; cat(" That took ", round(speed[3],1), " secs.\n", sep="")

now <- proc.time()
gg <- outer(X, X, FUN="-")
sum(gg*gg)
speed <- proc.time() - now; cat(" That took ", round(speed[3],1), " secs.\n", sep="")


From ken.knoblauch at inserm.fr  Mon Oct 21 22:49:45 2013
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Mon, 21 Oct 2013 20:49:45 +0000
Subject: [R] speeding up
References: <0765308CD028654885F30322557308D80E1DF378@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <loom.20131021T224510-119@post.gmane.org>

Bos, Roger <roger.bos <at> rothschild.com> writes:
> I am using a sum of squared differences in the 
objective function of an optimization problem I am 
doing and I
> have managed to speed it up using the
 outer function versus the nested for loops, but my 
suspicion is that
> the calculation could be done even quicker.  
Please see the code below for a simple example.  If 
anyone can

> point out a faster way I would appreciate it greatly.
> 
> Thanks,
> 
> Roger
> 
> X <- runif(1000)
> 
> now <- proc.time()
> ans <- 0
> for (i in 1:length(X)) {
>   for (j in 1:length(X)) {
>     ans <- ans + (X[i]-X[j])*(X[i]-X[j])
>   }
> }
> ans
> speed <- proc.time() - now; cat(" That took ", 
round(speed[3],1), " secs.\n", sep="")
> 
> now <- proc.time()
> gg <- outer(X, X, FUN="-")
> sum(gg*gg)
> speed <- proc.time() - now; cat(" That took ", 
round(speed[3],1), " secs.\n", sep="")
> 
> 

system.time(
for (i in 1:length(X)) {
  for (j in 1:length(X)) {
    ans <- ans + (X[i]-X[j])*(X[i]-X[j])
  }
})
   user  system elapsed 
  2.241   0.009   2.293 

system.time(2 * sum(c(dist(X))^2))

   user  system elapsed 
  0.038   0.002   0.040 

and then there is Rcpp if you want to add
some extra grease.

-- 
Kenneth Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From ken.knoblauch at inserm.fr  Mon Oct 21 23:04:21 2013
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Mon, 21 Oct 2013 21:04:21 +0000
Subject: [R] speeding up
References: <0765308CD028654885F30322557308D80E1DF378@NYCSM0208.rth.ad.rothschild.com>
	<loom.20131021T224510-119@post.gmane.org>
Message-ID: <loom.20131021T230344-212@post.gmane.org>

Ken Knoblauch <ken.knoblauch <at> inserm.fr> writes:

> 
> Bos, Roger <roger.bos <at> rothschild.com> writes:
> > I am using a sum of squared differences in the 
> objective function of an optimization problem I am 
> doing and I
> > have managed to speed it up using the
>  outer function versus the nested for loops, but my 
> suspicion is that
> > the calculation could be done even quicker.  
> Please see the code below for a simple example.  If 
> anyone can
> 
> > point out a faster way I would appreciate it greatly.
> > 
> > Thanks,
> > 
> > Roger
> > 
> > X <- runif(1000)
> > 
> > now <- proc.time()
> > ans <- 0
> > for (i in 1:length(X)) {
> >   for (j in 1:length(X)) {
> >     ans <- ans + (X[i]-X[j])*(X[i]-X[j])
> >   }
> > }
> > ans
> > speed <- proc.time() - now; cat(" That took ", 
> round(speed[3],1), " secs.\n", sep="")
> > 
> > now <- proc.time()
> > gg <- outer(X, X, FUN="-")
> > sum(gg*gg)
> > speed <- proc.time() - now; cat(" That took ", 
> round(speed[3],1), " secs.\n", sep="")
> > 
> > 
> 
> system.time(
> for (i in 1:length(X)) {
>   for (j in 1:length(X)) {
>     ans <- ans + (X[i]-X[j])*(X[i]-X[j])
>   }
> })
>    user  system elapsed 
>   2.241   0.009   2.293 
> 
> system.time(2 * sum(c(dist(X))^2))
> 
>    user  system elapsed 
>   0.038   0.002   0.040 
> 
> and then there is Rcpp if you want to add
> some extra grease.
> 

and just to follow-up on my own suggestion

library(Rcpp)

cppFunction('
	double ss(NumericVector X){
		int n = X.size();
		double total = 0;
		for(int i = 0; i < n; i++)
	   		for(int j = 0; j < n; j++)
	     total += (X[i] - X[j]) * (X[i] - X[j]);
		return total;
	}'
)

system.time(ss(X))
   user  system elapsed 
  0.002   0.000   0.002 

-- 
Kenneth Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From berkr at wharton.upenn.edu  Mon Oct 21 21:39:07 2013
From: berkr at wharton.upenn.edu (Berk, Richard)
Date: Mon, 21 Oct 2013 19:39:07 +0000
Subject: [R] Installation of 3.0.2
Message-ID: <92C05AE1-A337-4757-BBB6-BF50A155F4AE@wharton.upenn.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/79a30243/attachment.pl>

From g.acjunior at gmail.com  Mon Oct 21 22:11:44 2013
From: g.acjunior at gmail.com (Geraldo Carvalho Jr)
Date: Mon, 21 Oct 2013 15:11:44 -0500
Subject: [R] Calculating Blups Using R (lem4 packages)
Message-ID: <000001cece99$c46f7500$4d4e5f00$@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/5813e70f/attachment.pl>

From hill0093 at umn.edu  Mon Oct 21 23:15:18 2013
From: hill0093 at umn.edu (Hurr)
Date: Mon, 21 Oct 2013 14:15:18 -0700 (PDT)
Subject: [R] May I send a zip attachment to a post?
Message-ID: <1382390117896-4678742.post@n4.nabble.com>

May I send a .zip file attached to a post?




--
View this message in context: http://r.789695.n4.nabble.com/May-I-send-a-zip-attachment-to-a-post-tp4678742.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Mon Oct 21 23:51:04 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 21 Oct 2013 14:51:04 -0700
Subject: [R] May I send a zip attachment to a post?
In-Reply-To: <1382390117896-4678742.post@n4.nabble.com>
References: <1382390117896-4678742.post@n4.nabble.com>
Message-ID: <D409BF0E-6355-4FE3-A631-F592AF0ED568@comcast.net>


On Oct 21, 2013, at 2:15 PM, Hurr wrote:

> May I send a .zip file attached to a post?

No.

-- 
David Winsemius
Alameda, CA, USA


From gunter.berton at gene.com  Tue Oct 22 00:02:19 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 21 Oct 2013 15:02:19 -0700
Subject: [R] Calculating Blups Using R (lem4 packages)
In-Reply-To: <000001cece99$c46f7500$4d4e5f00$@gmail.com>
References: <000001cece99$c46f7500$4d4e5f00$@gmail.com>
Message-ID: <CACk-te2cVLRoCPce5DmiAtsm-SY+-FP43f26Cxz-WFRMPgyALQ@mail.gmail.com>

I suggest you post to the R-sig-Mixed-models list rather than here. It
is specifically devoted to mixed models and you are more likely to get
an (reliable!) answer there.

Cheers,
Bert

On Mon, Oct 21, 2013 at 1:11 PM, Geraldo Carvalho Jr
<g.acjunior at gmail.com> wrote:
> Hi,
>
>
>
> I have some field data from a randomized complete block design trial in two
> locations and I would like to calculate BLUPs and BLUEs from this data. I?ve
> run some analysis using the lem4 package but I am not too sure about the
> results I got.
>
>
>
> When I calculate the BLUPs considering environments separate the output
> lists genotypes and intercept values. Are these intercept values BLUPs?
>
>
>
> Many thanks! I am new in R but I really want learn how to use it for this
> purpose.
>
>
>
> I aprreciate your time!
>
>
>
> --
>
> Geraldo Afonso de Carvalho Junior
>
> PhD student, Plant Breeding
>
> Soil and Crop Sciences Dept
>
> Texas A&M University
>
> 979-220-9923
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From marongiu.luigi at gmail.com  Tue Oct 22 01:08:23 2013
From: marongiu.luigi at gmail.com (luigi marongiu)
Date: Tue, 22 Oct 2013 00:08:23 +0100
Subject: [R] post hoc test to a significant Kruskal-Wallis test package
 asbio function pairw.kw()
Message-ID: <CAMk+s2TK0a+03nefawGVjnwR+M0JxBP2Vdd1behNRQKweKiQhw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131022/ff3275e4/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Tue Oct 22 02:02:53 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 21 Oct 2013 17:02:53 -0700
Subject: [R] Installation of 3.0.2
In-Reply-To: <92C05AE1-A337-4757-BBB6-BF50A155F4AE@wharton.upenn.edu>
References: <92C05AE1-A337-4757-BBB6-BF50A155F4AE@wharton.upenn.edu>
Message-ID: <04e6605b-e387-43c9-ba75-3f03e91f75f6@email.android.com>

Perhaps ask on r-sig-mac?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"Berk, Richard" <berkr at wharton.upenn.edu> wrote:
>I am trying to update R  from 3.0.1 to 3.0.2. The installer quits
>saying I need a Mac OS of
>at least 10.6. I have 10.8.5. I have tried several times over a period
>of 2 weeks hoping the
>problem would be fixed. Suggestions?
>
>
>Richard A. Berk
>berkr at wharton.upenn.edu<mailto:berkr at wharton.upenn.edu>
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From hill0093 at umn.edu  Tue Oct 22 02:31:47 2013
From: hill0093 at umn.edu (Hurr)
Date: Mon, 21 Oct 2013 17:31:47 -0700 (PDT)
Subject: [R] How do I use simple calls to java methods?
Message-ID: <1382401907888-4678753.post@n4.nabble.com>

I need to learn how to set up two methods (java functions) so I can call them
from R.
Currently I just copy and paste R code into the R console. 
A little piece of the R code inside a loop is:
      linTm <- linTimOfCalStg(dta[i,timCol],tlev) 
      calCk <- calStgOfLinTim(linTm,tlev) 
      if(calCk!=dta[i,timCol]) { 
        print(c(i,dta[i,timCol],linTm,calCk),digits=20) 
        stop("incorrect time conversion") 
      } 
The two functions called have these first lines:
linTimOfCalStg <- function(calStg,tlev) and 
calStgOfLinTim <- function(linTm, tlev) 
which in java substitutes are: 
public final static double linTimOfCalqsStg(String calStg,int tlev)  and  
public final static String calqsStgOfLinTim(double linTm,int tlev) 
both in a java class called "CalqsLin.class" compiled from "CalqsLin.java".
The R code works.
The purpose of all this is to eliminate duplicate subroutines and 
their duplicate checking ln both languages.
There will be several other subroutines that I will also use in both
languages.
I can start by putting everything into a single directory in Windows seven
to learn.
How do I make this substitution?




--
View this message in context: http://r.789695.n4.nabble.com/How-do-I-use-simple-calls-to-java-methods-tp4678753.html
Sent from the R help mailing list archive at Nabble.com.


From stian at mail.rockefeller.edu  Tue Oct 22 03:18:10 2013
From: stian at mail.rockefeller.edu (Suyan Tian)
Date: Tue, 22 Oct 2013 01:18:10 +0000
Subject: [R] cor matrix in multivariate regression
Message-ID: <E244C6B8-685A-4EBC-B776-E05E76B1C154@rockefeller.edu>

Sorry to bother, I want to construct a correlation matrix in multivariate regression  (several dependent variables and they are correlated in some ways) like the followings, 

1   0.8   0  0 ?     0 0 
0.8 1     0  0  ?    0 0 
0    0     1  0.8 ?  0 0 
0   0      0.8 1  ? 0 0 
.     .       .     .         ?.

.     .        .   .          

0  0                      1  0.8 
0  0                       0.8 1 

Does anyone know how to do it? 

Thanks,

Suyan Tian 
Associate Professor 
The Jilin University 




From vokey at uleth.ca  Tue Oct 22 03:52:53 2013
From: vokey at uleth.ca (Vokey, John)
Date: Tue, 22 Oct 2013 01:52:53 +0000
Subject: [R] left transpose
Message-ID: <CF037782-6DE8-466D-9611-FD8D89FE5784@uleth.ca>

useRs,
  I frequently require the following transform of a matrix that I call a leftTranspose:

  -- transposes x such that the last items of each row become
  -- the first items in each column.  E.g.,
  --      a b c d
  --      e f g h
  -- becomes:
  -- d h
  -- c g
  -- b f
  -- a e

because it is a leftward rotation.  I have written my own function, but I was wondering whether I was reinventing the wheel here.  Does such a transpose already exist in R (or matlab/octave/FreeMat, for that matter)?


--
Please avoid sending me Word or PowerPoint attachments.
See <http://www.gnu.org/philosophy/no-word-attachments.html>

-Dr. John R. Vokey


From jorgeivanvelez at gmail.com  Tue Oct 22 04:05:25 2013
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Tue, 22 Oct 2013 13:05:25 +1100
Subject: [R] left transpose
In-Reply-To: <CF037782-6DE8-466D-9611-FD8D89FE5784@uleth.ca>
References: <CF037782-6DE8-466D-9611-FD8D89FE5784@uleth.ca>
Message-ID: <CAKL8G3Fdh77WDWJvZhN51nkxTcAVKX=m3bsANx255OsAo_z25g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131022/d608b3a2/attachment.pl>

From smartpink111 at yahoo.com  Tue Oct 22 05:12:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 21 Oct 2013 20:12:26 -0700 (PDT)
Subject: [R] post hoc test to a significant Kruskal-Wallis test package
	asbio function pairw.kw()
In-Reply-To: <CAMk+s2TK0a+03nefawGVjnwR+M0JxBP2Vdd1behNRQKweKiQhw@mail.gmail.com>
References: <CAMk+s2TK0a+03nefawGVjnwR+M0JxBP2Vdd1behNRQKweKiQhw@mail.gmail.com>
Message-ID: <1382411546.59966.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
pairw.kw(y,factor(x),conf=.95)


A.K.




On Monday, October 21, 2013 7:10 PM, luigi marongiu <marongiu.luigi at gmail.com> wrote:
Dear all,
I am trying to apply a post hoc test to a significant Kruskal-Wallis test.
I eventually found the function ?pairw.kw()? of the package ?asbio?. This
function has the following syntax:
pairw.kw(y, x, conf)
Arguments
y? ?  The response variable. A vector of quantitative responses.
x? ?  An explanatory variable. A vector of factor levels.
conf? ?  The level of desired con?dence, 1 - P(type I error).

The example reported indicated 2 vectors of length 12 arranged in a data
frame:
rye.data <- data.frame(rye = c(50, 49.8, 52.3, 44.5, 62.3, 74.8, 72.5, 80.2,
47.6, 39.5, 47.7,50.7), nutrient = factor(c(rep(1, 4), rep(2, 4), rep(3,
4))))
with(rye.data, pairw.kw(y = rye, x = nutrient, conf = .95))

I tried to arrange the data in this way, as well as using my own dataframe
obtained from the read.table() function and directly with two vectors, but
I always obtained an error. Essentially the two vectors are not of the same
length; this is incorrect since there are both 64 elements.

Is there somebody who could tell me how to use this function?

Many thanks,
Luigi

EXAMPLE GIVEN
Here I am using the vector example.

### define vectors
x<-c(? ? 0,? ? 0,? ? 0,? ? 0,? ? 0,? ? 0,? ? 0,? ? 0,? ? 0,? ? 0,? ? 0,
0,? ? 1,? ? 1,? ? 1,? ? 1,? ? 1,? ? 1,? ? 1,? ? 1,? ? 1,? ? 1,? ? 1,
1,? ? 2,? ? 2,? ? 2,? ? 2,? ? 2,? ? 2,? ? 2,? ? 2,? ? 2,? ? 2,? ? 2,
2,? ? 2,? ? 2,? ? 2,? ? 2,? ? 3,? ? 3,? ? 3,? ? 3,? ? 3,? ? 3,? ? 3,
3,? ? 3,? ? 3,? ? 3,? ? 3,? ? 3,? ? 3,? ? 3,? ? 4,? ? 4,? ? 4,? ? 4,
4,? ? 4,? ? 4,? ? 4,? ? 4)

y<-c(? ? 0.002515324,? ? 0.005128344,? ? 0.008474943,? ? 0.009992525,
0.01460982,? ? 0.020567249,? ? 0.069597233,? ? 0.192428254,
0.636910481,? ? 0.673830995,? ? 4.354055891,? ? 4.847755691,
0.403135211,? ? 0.539626363,? ? 0.892722111,? ? 0.993636963,
1.289747804,? ? 3.766986726,? ? 5.623002684,? ? 8.52186547,
17.24684431,? ? 19.84624792,? ? 25.9529251,? ? 35.64632645,
0.437492775,? ? 0.594863773,? ? 0.64377689,? ? 0.88033664,
3.199906591,? ? 5.745723357,? ? 6.339129057,? ? 6.583851172,
11.27921212,? ? 13.01230334,? ? 14.61151433,? ? 26.68041064,
52.42360789,? ? 71.88062442,? ? 91.34132781,? ? 115.1038548,
0.059333604,? ? 0.068746428,? ? 0.1473799,? ? 0.220983138,
0.959677864,? ? 1.21197612,? ? 2.860983172,? ? 4.402992963,
5.122748306,? ? 8.711530662,? ? 25.6245157,? ? 44.0798333,
45.24736747,? ? 66.4490478,? ? 86.60427738,? ? 0.10348061,
0.390758249,? ? 0.634667258,? ? 1.122594755,? ? 2.726868877,
4.15194739,? ? 5.361175006,? ? 8.825635885,? ? 45.75640999)

### confirm length:
? ? length(x)? ? # 64
? ? length(y)? ? # 64

### KRUSKAL-WALLIS to test inter-group differences
? ? kruskal.test(y, x)? ?  # p-value = 0.0008701

### Multiple pairwise comparison procedure to accompany a Kruskal-Wallis
test
? ? pairw.kw(y, x, conf = .95)

# Error in outer(levels(x), levels(x), function(x1, x2) { :
# dims [product 0] do not match the length of object [1]

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From arborkoeser at yahoo.com  Tue Oct 22 05:22:58 2013
From: arborkoeser at yahoo.com (Andrew Koeser)
Date: Mon, 21 Oct 2013 23:22:58 -0400
Subject: [R] post hoc test to a significant Kruskal-Wallis test package
 asbio function pairw.kw()
In-Reply-To: <1382411546.59966.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <CAMk+s2TK0a+03nefawGVjnwR+M0JxBP2Vdd1behNRQKweKiQhw@mail.gmail.com>
	<1382411546.59966.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <5265EF92.2080809@yahoo.com>

Luigi,

agricolae has a nice function for this with the post hoc test as part of 
the output.

AKK

On 10/21/2013 11:12 PM, arun wrote:
> Hi,
> Try:
> pairw.kw(y,factor(x),conf=.95)
>
>
> A.K.
>
>
>
>
> On Monday, October 21, 2013 7:10 PM, luigi marongiu <marongiu.luigi at gmail.com> wrote:
> Dear all,
> I am trying to apply a post hoc test to a significant Kruskal-Wallis test.
> I eventually found the function ?pairw.kw()? of the package ?asbio?. This
> function has the following syntax:
> pairw.kw(y, x, conf)
> Arguments
> y     The response variable. A vector of quantitative responses.
> x     An explanatory variable. A vector of factor levels.
> conf     The level of desired con?dence, 1 - P(type I error).
>
> The example reported indicated 2 vectors of length 12 arranged in a data
> frame:
> rye.data <- data.frame(rye = c(50, 49.8, 52.3, 44.5, 62.3, 74.8, 72.5, 80.2,
> 47.6, 39.5, 47.7,50.7), nutrient = factor(c(rep(1, 4), rep(2, 4), rep(3,
> 4))))
> with(rye.data, pairw.kw(y = rye, x = nutrient, conf = .95))
>
> I tried to arrange the data in this way, as well as using my own dataframe
> obtained from the read.table() function and directly with two vectors, but
> I always obtained an error. Essentially the two vectors are not of the same
> length; this is incorrect since there are both 64 elements.
>
> Is there somebody who could tell me how to use this function?
>
> Many thanks,
> Luigi
>
> EXAMPLE GIVEN
> Here I am using the vector example.
>
> ### define vectors
> x<-c(    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
> 0,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
> 1,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,
> 2,    2,    2,    2,    2,    3,    3,    3,    3,    3,    3,    3,
> 3,    3,    3,    3,    3,    3,    3,    3,    4,    4,    4,    4,
> 4,    4,    4,    4,    4)
>
> y<-c(    0.002515324,    0.005128344,    0.008474943,    0.009992525,
> 0.01460982,    0.020567249,    0.069597233,    0.192428254,
> 0.636910481,    0.673830995,    4.354055891,    4.847755691,
> 0.403135211,    0.539626363,    0.892722111,    0.993636963,
> 1.289747804,    3.766986726,    5.623002684,    8.52186547,
> 17.24684431,    19.84624792,    25.9529251,    35.64632645,
> 0.437492775,    0.594863773,    0.64377689,    0.88033664,
> 3.199906591,    5.745723357,    6.339129057,    6.583851172,
> 11.27921212,    13.01230334,    14.61151433,    26.68041064,
> 52.42360789,    71.88062442,    91.34132781,    115.1038548,
> 0.059333604,    0.068746428,    0.1473799,    0.220983138,
> 0.959677864,    1.21197612,    2.860983172,    4.402992963,
> 5.122748306,    8.711530662,    25.6245157,    44.0798333,
> 45.24736747,    66.4490478,    86.60427738,    0.10348061,
> 0.390758249,    0.634667258,    1.122594755,    2.726868877,
> 4.15194739,    5.361175006,    8.825635885,    45.75640999)
>
> ### confirm length:
>      length(x)    # 64
>      length(y)    # 64
>
> ### KRUSKAL-WALLIS to test inter-group differences
>      kruskal.test(y, x)     # p-value = 0.0008701
>
> ### Multiple pairwise comparison procedure to accompany a Kruskal-Wallis
> test
>      pairw.kw(y, x, conf = .95)
>
> # Error in outer(levels(x), levels(x), function(x1, x2) { :
> # dims [product 0] do not match the length of object [1]
>
>      [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Tue Oct 22 05:34:18 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 22 Oct 2013 14:34:18 +1100
Subject: [R] plot correlation matrix
In-Reply-To: <1382366734.8245.YahooMailNeo@web125303.mail.ne1.yahoo.com>
References: <1382366734.8245.YahooMailNeo@web125303.mail.ne1.yahoo.com>
Message-ID: <5265F23A.90801@bitwrit.com.au>

On 10/22/2013 01:45 AM, Alaios wrote:
> Hi all,
> I am having 4 vectors like
>
> Data: num [1:4, 1:32] -82.8 -81.8 -75.5 -107.6 -87.6 ...
>
> and I want to calculate the correlation between those.
>
> Is there a graphical way in R to plot the correlations or not?
>
> I would like to thank you in advance for your help
>
Hi Alex,
Have a look at color2D.matplot in plotrix, particularly the show.values 
argument and the first example.

Jim


From akhelifa at logitech.com  Tue Oct 22 01:12:28 2013
From: akhelifa at logitech.com (Alexandre Khelifa)
Date: Mon, 21 Oct 2013 16:12:28 -0700
Subject: [R] R - How to "physically" Increase Speed
Message-ID: <CADd4zuUw-WgknkbNCakX220auMCopzZDCCx7hfcBSEpF7AvQuw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131021/62b6f858/attachment.pl>

From walt at dataanalyticscorp.com  Tue Oct 22 01:32:17 2013
From: walt at dataanalyticscorp.com (Data Analytics Corp.)
Date: Mon, 21 Oct 2013 19:32:17 -0400
Subject: [R] Quick advice on loading packages
Message-ID: <5265B981.50306@dataanalyticscorp.com>

Hi,

I need some quick advice/help on loading packages.  I want to write a 
simple function to load a number of packages I intend to use at a 
conference presentation.  I'm thinking of something like:

             fn.install <- function(){install.packages(c("ggplot2", 
"scales"),  repos = "c:\\temp")}

There will be many more than just the two I listed.  All the zip files 
are in a Windows directory c:\temp.  Will this work?

Thanks,

Walt

________________________

Walter R. Paczkowski, Ph.D.
Data Analytics Corp.
44 Hamilton Lane
Plainsboro, NJ 08536
________________________
(V) 609-936-8999
(F) 609-936-3733
walt at dataanalyticscorp.com
www.dataanalyticscorp.com


From hb at biostat.ucsf.edu  Tue Oct 22 07:36:51 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 21 Oct 2013 22:36:51 -0700
Subject: [R] R - How to "physically" Increase Speed
In-Reply-To: <CADd4zuUw-WgknkbNCakX220auMCopzZDCCx7hfcBSEpF7AvQuw@mail.gmail.com>
References: <CADd4zuUw-WgknkbNCakX220auMCopzZDCCx7hfcBSEpF7AvQuw@mail.gmail.com>
Message-ID: <CAFDcVCSkTOK-8xHC-bUu7fddkXTVHcNGMU=wrb+Pv_n+o4MaXw@mail.gmail.com>

On Mon, Oct 21, 2013 at 4:12 PM, Alexandre Khelifa
<akhelifa at logitech.com> wrote:
> Hi,
>
> My name is Alexandre Khelifa and I have been using R at my work for about 2
> years. I have been working on a project when we do Monte Carlo Simulation
> and it involves a lot of calculations.
>
> I am currently using R x64.3.0.1 and used to work on a 4GB machine.
> However, the calculation time was very long (about 2 weeks), and the IT
> team and I decided to add more memory and to make it a 8GB virtual machine.
>  I also added the following line in my code:
> *
> *
>
>    - *options(java.parameters = "-Xmx8192m") *
>
>
> I re-did the same calculations (4GB vs. 8GB) but did not see a significant
> increase in the calculation time, so I was wondering if I did anything
> wrong and/or what would be the best solution to increase this time.

If you and your team travel Earth-to-Space round trip at 87% the speed
of light, your computations would *physically* become roughly twice as
fast (you must leave computer behind).  Alternatively, look at
help(package="parallel").  But what really makes a difference is to
find and replace bottle necks in your code by profiling it, cf.
help("Rprof").  I'd go with the latter if you haven't already done so.

/Henrik

>
> Thanks a lot for your help and more generally for building such an amazing
> (and free) tool.
> Let me know if you have any questions.
>
> Regards,
>
> Alexandre Khelifa
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Tue Oct 22 08:51:55 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 22 Oct 2013 06:51:55 +0000
Subject: [R] merging matrices
In-Reply-To: <CAAxdm-7oKmBHdDHh5gNSUJet39Fdxfbbn6w5eNPa8vrqNcGcuQ@mail.gmail.com>
References: <CAO4=jh7PL3YvpLtb-QK0+_s8wX0Ap42xc5f0QFRJ1=3NmK=qmg@mail.gmail.com>
	<CAAxdm-7oKmBHdDHh5gNSUJet39Fdxfbbn6w5eNPa8vrqNcGcuQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B998B5@SRVEXCHMBX.precheza.cz>

Hi

?merge

and if you are in reading help pages

?matrix
?data.frame

and of course R-intro.pdf especially chapters about data objects and their differences.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of jim holtman
> Sent: Monday, October 21, 2013 5:21 PM
> To: Mohammad Goodarzi
> Cc: R mailing list
> Subject: Re: [R] merging matrices
> 
> ?list.files
> ?read.table
> ?rbind
> 
> Jim Holtman
> Data Munger Guru
> 
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
> 
> On Mon, Oct 21, 2013 at 6:18 AM, Mohammad Goodarzi
> <mohammad.godarzi at gmail.com> wrote:
> > Dear all,
> >
> > I have to load more than 1000 matrices from desktop which all of them
> > have the same size.
> > If I do it manually, it would be very hard, can you please guide me
> > how to load them and merge them together ?
> >
> > for example I want to put them one after another
> > X1 X2 X3 etc
> >
> > Many thanks,
> > Mohammad
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jutesoro at yahoo.com  Tue Oct 22 09:35:28 2013
From: jutesoro at yahoo.com (Julius Tesoro)
Date: Tue, 22 Oct 2013 00:35:28 -0700 (PDT)
Subject: [R] Merging data.frames with overlapping intervals
Message-ID: <1382427328.73699.YahooMailNeo@web162806.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131022/0665f3bf/attachment.pl>

From petr.pikal at precheza.cz  Tue Oct 22 10:25:42 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 22 Oct 2013 08:25:42 +0000
Subject: [R] Merging data.frames with overlapping intervals
In-Reply-To: <1382427328.73699.YahooMailNeo@web162806.mail.bf1.yahoo.com>
References: <1382427328.73699.YahooMailNeo@web162806.mail.bf1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B99983@SRVEXCHMBX.precheza.cz>

Hi

Your HTML formated message was scrammbled so it is impossible to say what result you expected.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Julius Tesoro
> Sent: Tuesday, October 22, 2013 9:35 AM
> To: r-help at r-project.org
> Subject: [R] Merging data.frames with overlapping intervals
> 
> How do I merge two data.frames with overlapping intervals?
> Data Frame 1
> read.table(textConnection("   from to Lith Form
> 1   0   1.2 GRN   BCM
> 2   1.2 5.0 GDI   BDI
> "),header=TRUE)
> Data Frame 2
> read.table(textConnection("   from to Weath Str
> 1   0  1.1  HW ES
> 2   1.1 2.9 SW VS
> 3   2.9 5.0 HW ST
> "),header=TRUE)
> Resulting Data Frame
> fromto WeathStrLithForm10.01.1HW ES GRN  BCM 21.11.2SW VS GRN  BCM
> 31.22.9SW VS GDI  BDI 42.95.0HW ST GDI  BDI
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jwd at surewest.net  Tue Oct 22 09:27:53 2013
From: jwd at surewest.net (jwd)
Date: Tue, 22 Oct 2013 00:27:53 -0700
Subject: [R] Quick advice on loading packages
In-Reply-To: <5265B981.50306@dataanalyticscorp.com>
References: <5265B981.50306@dataanalyticscorp.com>
Message-ID: <20131022002753.75293d08@draco.site>

On Mon, 21 Oct 2013 19:32:17 -0400
"Data Analytics Corp." <walt at dataanalyticscorp.com> wrote:

> Hi,
> 
> I need some quick advice/help on loading packages.  I want to write a 
> simple function to load a number of packages I intend to use at a 
> conference presentation.  I'm thinking of something like:
> 
>              fn.install <- function(){install.packages(c("ggplot2", 
> "scales"),  repos = "c:\\temp")}
> 
> There will be many more than just the two I listed.  All the zip
> files are in a Windows directory c:\temp.  Will this work?
> 
> Thanks,
> 
> Walt
> 
Just use a short script.  Install R, install the packages.  To load
them, write a short script, e.g.

#Sets working directory and loads essential libraries.
setwd([working directory here])
library(MASS, aplpack, cclust, ggplot, ...)

Call that from R and provided you have everything where you've R it
was, you're set.

JWDougherty


From p_connolly at slingshot.co.nz  Tue Oct 22 11:11:20 2013
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Tue, 22 Oct 2013 22:11:20 +1300
Subject: [R] RWeka and multicore package
In-Reply-To: <CAPK6mFru7FFPXLnivwzpDxi_GMqk_yVNpDvNTXz2nUTyWgLeMQ@mail.gmail.com>
References: <CAPK6mFru7FFPXLnivwzpDxi_GMqk_yVNpDvNTXz2nUTyWgLeMQ@mail.gmail.com>
Message-ID: <20131022091119.GB4253@slingshot.co.nz>

On Thu, 17-Oct-2013 at 02:21PM -0300, Lu?s Paulo F. Garcia wrote:

|> I work very mutch with the packages RWeka and multicore. If you try to run
|> J48 or any tree of RWeka with multicore we hava some errors.
|> 
|> Example I:
|> 
|> library(RWeka);
|> library(multicore);
|> 
|> mclapply(1:100, function(i) {
|>     J48(Species ~., iris);
|> });
|> 
|> 
|> Output:  "Error in .jcall(o, \"Ljava/lang/Class;\", \"getClass\") : \n
|> java.lang.ClassFormatError: Incompatible magic value 1347093252 in class
|> file java/lang/ProcessEnvironment$StringEnvironment\n"
|> 
|> 
|> Example II:
|> 
|> library(multicore);
|> 
|> mclapply(1:100, function(i) {
|>     RWeka::J48(Species ~., iris);
|> });
|> 
|> Output: Erro em .jcall(x$classifier, "S", "toString") :
|>   RcallMethod: attempt to call a method of a NULL object.
|> 
|> 
|> Do you know some way to work with parallel processing and RWeka? I tried
|> MPI and SNOW without success.

Not much help, but I too have not been able to get parallelling RWeka
to work.  OTOH, what RWeka can do is very fast compared with, say, gbm
(which does work well with mclapply).  

I suspect that it has something to do with how Java is set up, but I
know nothing about setting up Java.




|> 
|> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
|> Ubuntu 12.04 x64
|> 
|> 
|> -- 
|> Lu?s Paulo Faina Garcia
|> Engenheiro de Computa??o - Universidade de S?o Paulo
|> S?o Carlos - SP - Brasil
|> 
|> 	[[alternative HTML version deleted]]
|> 

|> ______________________________________________
|> R-help at r-project.org mailing list
|> https://stat.ethz.ch/mailman/listinfo/r-help
|> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> and provide commented, minimal, self-contained, reproducible code.


-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From jholtman at gmail.com  Tue Oct 22 11:47:15 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Tue, 22 Oct 2013 05:47:15 -0400
Subject: [R] R - How to "physically" Increase Speed
In-Reply-To: <CADd4zuUw-WgknkbNCakX220auMCopzZDCCx7hfcBSEpF7AvQuw@mail.gmail.com>
References: <CADd4zuUw-WgknkbNCakX220auMCopzZDCCx7hfcBSEpF7AvQuw@mail.gmail.com>
Message-ID: <73D989DA-B6B3-421D-838C-903DA34350F2@gmail.com>

I would start with taking a subset of the data (definitely some that would run in less than 10 minutes) and use the profiler "Rprof" to see where time is being spent.  you can use the the task monitor (if on windows) to see how much memory you are using; it sounds like you did not need the extra memory.

You might see if you can partition your data so you can run multiple versions of R and then merge the results.

Anything that takes more than a half hour, for me, is looked into to see where the problems are.  For example dataframes arevexpensive to access and conversion to matrices is one way to speed it up.  the is where the profiler helps.

Sent from my iPad

On Oct 21, 2013, at 19:12, Alexandre Khelifa <akhelifa at logitech.com> wrote:

> Hi,
> 
> My name is Alexandre Khelifa and I have been using R at my work for about 2
> years. I have been working on a project when we do Monte Carlo Simulation
> and it involves a lot of calculations.
> 
> I am currently using R x64.3.0.1 and used to work on a 4GB machine.
> However, the calculation time was very long (about 2 weeks), and the IT
> team and I decided to add more memory and to make it a 8GB virtual machine.
> I also added the following line in my code:
> *
> *
> 
>   - *options(java.parameters = "-Xmx8192m") *
> 
> 
> I re-did the same calculations (4GB vs. 8GB) but did not see a significant
> increase in the calculation time, so I was wondering if I did anything
> wrong and/or what would be the best solution to increase this time.
> 
> Thanks a lot for your help and more generally for building such an amazing
> (and free) tool.
> Let me know if you have any questions.
> 
> Regards,
> 
> Alexandre Khelifa
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From b.rowlingson at lancaster.ac.uk  Tue Oct 22 12:10:04 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 22 Oct 2013 11:10:04 +0100
Subject: [R] May I send a zip attachment to a post?
In-Reply-To: <70d37f6f28ee4e97adfdaf3f09772ff3@EX-0-HT0.lancs.local>
References: <1382390117896-4678742.post@n4.nabble.com>
	<70d37f6f28ee4e97adfdaf3f09772ff3@EX-0-HT0.lancs.local>
Message-ID: <CANVKczMUE-z1XGZKvQQBD=QnfPwy+WA6ZgbYmLCuPSEEKprTuA@mail.gmail.com>

On Mon, Oct 21, 2013 at 10:51 PM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
> On Oct 21, 2013, at 2:15 PM, Hurr wrote:
>
>> May I send a .zip file attached to a post?
>
> No.

 That's not explicit from the posting guide:

"No binary attachments except for PS, PDF, and some image and archive formats "

 you have to click through to the General Instructions to see:

"Furthermore, most binary e-mail attachments are not accepted, i.e.,
they are removed from the posting completely. As an exception, we
allow application/pdf, application/postscript, and image/png (and
x-tar and gzip on R-devel)."

Maybe the posting guide should be more explicit - not that anyone reads it...

Barry


From alaios at yahoo.com  Tue Oct 22 13:21:11 2013
From: alaios at yahoo.com (Alaios)
Date: Tue, 22 Oct 2013 04:21:11 -0700 (PDT)
Subject: [R] Where is element 30?
Message-ID: <1382440871.43333.YahooMailNeo@web125301.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131022/40cc9ed8/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Tue Oct 22 13:33:12 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 22 Oct 2013 13:33:12 +0200 (MEST)
Subject: [R] Where is element 30?
In-Reply-To: <1382440871.43333.YahooMailNeo@web125301.mail.ne1.yahoo.com>
References: <1382440871.43333.YahooMailNeo@web125301.mail.ne1.yahoo.com>
Message-ID: <Pine.SOC.4.64.1310221332440.17063@solcom.hrz.uni-giessen.de>

Hi, Alaios,

check out

?which

and in particular its "Examples" and "See Also" section.

  Hth -- Gerrit

On Tue, 22 Oct 2013, Alaios wrote:

> Hi I have a vector like that
>
> readCsvFile$V1
> ?[1]? 30? 31? 32? 33? 34? 35? 36? 37? 38? 39 310 311 312 313 314 315 316 317 318
> [20] 319 320 321? 20? 21? 22? 23? 24? 25? 26? 27? 28? 29 210 211 212 213 214 215
> [39] 216 217 218 219 220 221 222 223? 40? 41? 42? 43? 44? 45? 46? 47? 48? 49 410
> [58] 411 412 413 414 415 416 417 418 419 420 421
>
>
> and I am looking to find where the number 31 is located. So I need one function to return me the index of where the number 31 is.
> Is there a function for that in R?
>
> Regards
> Alex

From carl at witthoft.com  Tue Oct 22 13:32:58 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Tue, 22 Oct 2013 04:32:58 -0700 (PDT)
Subject: [R] May I send a zip attachment to a post?
In-Reply-To: <CANVKczMUE-z1XGZKvQQBD=QnfPwy+WA6ZgbYmLCuPSEEKprTuA@mail.gmail.com>
References: <1382390117896-4678742.post@n4.nabble.com>
	<CANVKczMUE-z1XGZKvQQBD=QnfPwy+WA6ZgbYmLCuPSEEKprTuA@mail.gmail.com>
Message-ID: <1382441578738-4678782.post@n4.nabble.com>

Barry Rowlingson wrote
> On Mon, Oct 21, 2013 at 10:51 PM, David Winsemius
> &lt;

> dwinsemius@

> &gt; wrote:
>>
>> On Oct 21, 2013, at 2:15 PM, Hurr wrote:
>>
>>> May I send a .zip file attached to a post?
>>
>> No.
> 
>  That's not explicit from the posting guide:
> 
> "No binary attachments except for PS, PDF, and some image and archive
> formats "
> 
>  you have to click through to the General Instructions to see:
> 
> "Furthermore, most binary e-mail attachments are not accepted, i.e.,
> they are removed from the posting completely. As an exception, we
> allow application/pdf, application/postscript, and image/png (and
> x-tar and gzip on R-devel)."
> 
> Maybe the posting guide should be more explicit - not that anyone reads
> it...
> 
> Barry
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

There's really no justification for attaching *any* file to a post.  Posts
should be clear and concise.  If there's really some value to providing an
image, a hyperlink should be provided.   I'd argue against any attempt to
work around the intent of the posting guide, regardless of the alleged
format of the attachment (remember, folks, if posting a "file.pdf" is
allowed, you could rename your "junk.zip" to "junk.pdf")





--
View this message in context: http://r.789695.n4.nabble.com/May-I-send-a-zip-attachment-to-a-post-tp4678742p4678782.html
Sent from the R help mailing list archive at Nabble.com.


From jvadams at usgs.gov  Tue Oct 22 14:02:53 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 22 Oct 2013 07:02:53 -0500
Subject: [R] Error in heatmap
In-Reply-To: <000f01cece88$0442bdc0$0cc83940$@cinvestav.mx>
References: <000f01cece88$0442bdc0$0cc83940$@cinvestav.mx>
Message-ID: <CAN5YmCEtBSgEKS6JgmqqqX2mBKRoiKxfYKmvrWRiewqyFK7szQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131022/9bf56530/attachment.pl>

From istazahn at gmail.com  Tue Oct 22 14:09:12 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 22 Oct 2013 08:09:12 -0400
Subject: [R] XML package not working
In-Reply-To: <66C71547284587479F8009E05C07DA9704F96EC4@USTLMLLYC107.RF.lilly.com>
References: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>
	<5263226B.7070103@gmail.com>
	<66C71547284587479F8009E05C07DA9704F8E5D2@USTLMLLYC107.RF.lilly.com>
	<52640117.2010908@gmail.com>
	<66C71547284587479F8009E05C07DA9704F96EC4@USTLMLLYC107.RF.lilly.com>
Message-ID: <CA+vqiLH9HP_T599Cbru+v=OZ126x1KBz==mweCuY-DXXtXD02g@mail.gmail.com>

Hi Steven,

I still don't understand why you are downloading it manually. What
happens when you

install.packages("XML")

?

Best,
Ista

On Tue, Oct 22, 2013 at 8:03 AM, Steven Dwayne Randolph
<randolph_steven_d at lilly.com> wrote:
> Duncan... Thank you.
>
>         1.   I am able to download the XML file via my corporate network, other packages without this same issue, even rcurl and bitops which are pre-requisites on the same page as XML.
>         2.   I  have attempted to download this from my own wifi at home using xfinity/Comcast to my personal pc and still get the same error on this package alone.
>                 3.   I am genuinely baffled by this package download and install experience.
>                  4.  I would gladly build this from source, If indeed I could find the source and then use RTools to compile it.  That has been unsuccessful as well.   Nightmare? Slightly.
>
> Thanks for your response.....
> Steven
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Sunday, October 20, 2013 12:13 PM
> To: Steven Dwayne Randolph; r-help at r-project.org; Ista Zahn
> Cc: stevendrandolph at aol.com
> Subject: Re: [R] XML package not working
>
> On 13-10-20 9:23 AM, Steven Dwayne Randolph wrote:
>> My apologies for not conforming to the posting guideline.
>>
>>
>> Sys.info()
>>                       sysname                      release                      version
>>                     "Windows"                      "7 x64" "build 7601, Service Pack 1"
>>                      nodename                      machine                        login
>>             "xxxxxxNU247BZ1S"                     "x86-64"                    "XXXXXX"
>>                          user               effective_user
>>                     "xxxxxxx"                    "xxxxxxx"
>>
>> When I attempt to install a local copy of the xml.zip file:
>>
>> in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>    cannot open the connection
>> In addition: Warning messages:
>> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
>> file
>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>    cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'
>
> I think it is pretty clear that the problem is at your end:  you aren't downloading the file properly, even though everyone else is.  Perhaps you are behind a firewall, or something else is interfering with your downloads?
>
> Duncan Murdoch
>
>>
>>
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: Saturday, October 19, 2013 8:23 PM
>> To: Steven Dwayne Randolph; r-help at r-project.org
>> Cc: stevendrandolph at aol.com
>> Subject: Re: [R] XML package not working
>>
>> On 13-10-19 3:47 PM, Steven Dwayne Randolph wrote:
>>> I know I  cannot be the only one who is not able to install the XML package from CRAN (zip or tar file)  Many packages depend on this XML package.  Can someone help me either access the source for a good binary?  I have received no assistance from the author/developer of the package.
>>
>> It installs fine for me.
>>
>> Duncan Murdoch
>>
>


From S.Ellison at lgcgroup.com  Tue Oct 22 15:00:42 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Tue, 22 Oct 2013 14:00:42 +0100
Subject: [R] speeding up "sum of squared differences" calculation
In-Reply-To: <0765308CD028654885F30322557308D80E1DF378@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D80E1DF378@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554B3A409@GOLD.corp.lgc-group.com>

> I am using a sum of squared differences in the objective function of an
> optimization problem I am doing and I have managed to speed it up using
> the outer function versus the nested for loops, but my suspicion is
> that the calculation could be done even quicker.  Please see the code
> below for a simple example.  If anyone can point out a faster way I
> would appreciate it greatly.

First, look at ?system.time ; it's intended for finding out how much compute time a command takes. You're also calculating elapsed time which is dependent on (among other things) other processes running so maybe not the most reliable thing for benchmarking. 

Second, outer() is fast because it avoids loops and uses the fastest vector routines R can (essentially, replicating the vector and then relying on simple subtraction of vectors). In principle calling outer() loses a little time in internal checks on what object types and function you've provided etc.; in practice that doesn't add up to much. You can check by using just the core code from outer with an added multiplication instead of the dimensioning statement:

ssqdif <- function(X, Y=X) {
      #From 'outer' without modification
	Y <- rep(Y, rep.int(length(X), length(Y)))
	X <- rep(X, times = ceiling(length(Y)/length(X)))
   	#For this case:
	sum((X-Y)^2) #SLIGHTLY quicker than d<-X-Y; sum(d*d)
}

system.time(ssqdif(X))

#Comparing outer() method:
system.time({gg <- outer(X, X, FUN="-"); sum(gg*gg)})

There's little practical difference; both hover from 0.00 to 0.03 s system time. I could barely tell the difference even averaged over 100 runs; I was getting an average around 0.007 (system time) and 2.5s user time for both methods.

Conclusion: hard to beat outer() for this purpose in R

S Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at LGCGroup.com  Tue Oct 22 15:08:00 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 22 Oct 2013 14:08:00 +0100
Subject: [R] speeding up "sum of squared differences" calculation
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5554B3A409@GOLD.corp.lgc-group.com>
References: <0765308CD028654885F30322557308D80E1DF378@NYCSM0208.rth.ad.rothschild.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A409@GOLD.corp.lgc-group.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554B3A420@GOLD.corp.lgc-group.com>

> Conclusion: hard to beat outer() for this purpose in R
... unless you use Ken Knoblauch's suggestion of dist() or Rccp.

Nice indeed.

 
S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ken.knoblauch at inserm.fr  Tue Oct 22 15:12:50 2013
From: ken.knoblauch at inserm.fr (Kenneth Knoblauch)
Date: Tue, 22 Oct 2013 15:12:50 +0200
Subject: [R] speeding up "sum of squared differences" calculation
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5554B3A420@GOLD.corp.lgc-group.com>
References: <0765308CD028654885F30322557308D80E1DF378@NYCSM0208.rth.ad.rothschild.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A409@GOLD.corp.lgc-group.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A420@GOLD.corp.lgc-group.com>
Message-ID: <ed2c5a6cb2df03f1e53bbca77be90fa1@inserm.fr>

Actually, you don't need to use c() in the dist example, either, which 
should shave off a few microseconds for a function call.  It was late 
last night ...

Ken

On 22-10-2013 15:08, S Ellison wrote:
>> Conclusion: hard to beat outer() for this purpose in R
> ... unless you use Ken Knoblauch's suggestion of dist() or Rccp.
> 
> Nice indeed.
> 
> 
> S Ellison
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any use, copying or
> disclosure other than by the intended recipient is unauthorised. If
> you have received this message in error, please notify the sender
> immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com
> and delete this message and any copies from your computer and network.
> LGC Limited. Registered in England 2991879.
> Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

-- 
Kenneth Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From hill0093 at umn.edu  Tue Oct 22 15:13:34 2013
From: hill0093 at umn.edu (Hurr)
Date: Tue, 22 Oct 2013 06:13:34 -0700 (PDT)
Subject: [R] How do I use simple calls to java methods?
In-Reply-To: <1382401907888-4678753.post@n4.nabble.com>
References: <1382401907888-4678753.post@n4.nabble.com>
Message-ID: <1382447614947-4678786.post@n4.nabble.com>

I am surprised to not get a reply. 
I suppose this means that extremely few, if any, use rJava.

rJava.pdf says this, but I am too stupid to interpret it:
Description
.jcall calls a Java method with the supplied arguments.
Usage
.jcall(obj, returnSig = "V", method, ..., evalArray = TRUE,
evalString = TRUE, check = TRUE, interface = "RcallMethod",
simplify = FALSE, use.true.class = FALSE)

Perhaps it means that to replace:
      calCk <- calStgOfLinTim(linTm,tlev) 
and use something like:
      calCk <- .jcall(CalqsLin.class,returnSig = "S",
      calStgOfLinTim(linTm,tlev),evalArray=FALSE, 
      evalString = TRUE, check = TRUE, interface = "RcallMethod",
      simplify = FALSE, use.true.class = TRUE)

I suppose there are other setup things to do, 
like start the JVM (java Virtual machine)
and I don't know what obj means.

Anyway, if I am able to do these simple java method calls, 
it will be a big plus to our data analysis lab to use R conveniently.

Please help




--
View this message in context: http://r.789695.n4.nabble.com/How-do-I-use-simple-calls-to-java-methods-tp4678753p4678786.html
Sent from the R help mailing list archive at Nabble.com.


From carl at witthoft.com  Tue Oct 22 15:15:10 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Tue, 22 Oct 2013 06:15:10 -0700 (PDT)
Subject: [R] More Columns than column names Error
In-Reply-To: <1382422519242-4678770.post@n4.nabble.com>
References: <1382422519242-4678770.post@n4.nabble.com>
Message-ID: <1382447710424-4678787.post@n4.nabble.com>

What is the exact code you are using to try to load this file?
I strongly suspect the problem is a mixture of spaces and multiple tabs in
your text file.



--
View this message in context: http://r.789695.n4.nabble.com/More-Columns-than-column-names-Error-tp4678770p4678787.html
Sent from the R help mailing list archive at Nabble.com.


From roger.bos at rothschild.com  Tue Oct 22 15:18:00 2013
From: roger.bos at rothschild.com (Bos, Roger)
Date: Tue, 22 Oct 2013 13:18:00 +0000
Subject: [R] speeding up "sum of squared differences" calculation
In-Reply-To: <ed2c5a6cb2df03f1e53bbca77be90fa1@inserm.fr>
References: <0765308CD028654885F30322557308D80E1DF378@NYCSM0208.rth.ad.rothschild.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A409@GOLD.corp.lgc-group.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A420@GOLD.corp.lgc-group.com>
	<ed2c5a6cb2df03f1e53bbca77be90fa1@inserm.fr>
Message-ID: <0765308CD028654885F30322557308D80E1DFBA0@NYCSM0208.rth.ad.rothschild.com>

Thanks for the Rccp example Ken!  I vaguely knew about Rccp, but I didn't realize how easy it was to use it.

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Kenneth Knoblauch
Sent: Tuesday, October 22, 2013 9:13 AM
To: S Ellison
Cc: r-help at r-project.org
Subject: Re: [R] speeding up "sum of squared differences" calculation

Actually, you don't need to use c() in the dist example, either, which should shave off a few microseconds for a function call.  It was late last night ...

Ken

On 22-10-2013 15:08, S Ellison wrote:
>> Conclusion: hard to beat outer() for this purpose in R
> ... unless you use Ken Knoblauch's suggestion of dist() or Rccp.
> 
> Nice indeed.
> 
> 
> S Ellison
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any use, copying or 
> disclosure other than by the intended recipient is unauthorised. If 
> you have received this message in error, please notify the sender 
> immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
> and delete this message and any copies from your computer and network.
> LGC Limited. Registered in England 2991879.
> Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

--
Kenneth Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From murdoch.duncan at gmail.com  Tue Oct 22 15:27:36 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 22 Oct 2013 09:27:36 -0400
Subject: [R] XML package not working
In-Reply-To: <66C71547284587479F8009E05C07DA9704F96FB5@USTLMLLYC107.RF.lilly.com>
References: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>
	<5263226B.7070103@gmail.com>
	<66C71547284587479F8009E05C07DA9704F8E5D2@USTLMLLYC107.RF.lilly.com>
	<52640117.2010908@gmail.com>
	<66C71547284587479F8009E05C07DA9704F96EC4@USTLMLLYC107.RF.lilly.com>
	<CA+vqiLH9HP_T599Cbru+v=OZ126x1KBz==mweCuY-DXXtXD02g@mail.gmail.com>
	<66C71547284587479F8009E05C07DA9704F96FB5@USTLMLLYC107.RF.lilly.com>
Message-ID: <52667D48.6040203@gmail.com>

On 13-10-22 9:19 AM, Steven Dwayne Randolph wrote:
> Ista,... Thank you for your response.   Here is what is occurring when I attempt to command-line install.
>   ----------------------------------------------------------------------------------------------------------------------------------
>> install.packages('XML')
> Installing package into ?C:/Users/xxxxxxx/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> trying URL 'http://cran.rstudio.com/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> Content type 'application/zip' length 4287270 bytes (4.1 Mb)
> opened URL
> downloaded 4.1 Mb
>
> Warning in install.packages :
>    downloaded length 4276224 != reported length 4287270
> Warning in install.packages :
>    error 1 in extracting from zip file
> Warning in install.packages :
>    cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'
> Error in install.packages : cannot open the connection

Read the message:  your download is failing.  The file is being mangled 
during the download.

I just tried from the same mirror, and it was fine.

As I said before, there is something wrong on your system that is 
messing up file transfers.

You could try downloading the file some other way, and confirming that 
the length comes out to 4287270.

Duncan Murdoch

>
> ------------------------------------------------------------------------------------------------------------------------------------------
>
> STeven
> -----Original Message-----
> From: Ista Zahn [mailto:istazahn at gmail.com]
> Sent: Tuesday, October 22, 2013 8:09 AM
> To: Steven Dwayne Randolph
> Cc: Duncan Murdoch; r-help at r-project.org; stevendrandolph at aol.com; Piyush Singh - Network
> Subject: Re: [R] XML package not working
>
> Hi Steven,
>
> I still don't understand why you are downloading it manually. What happens when you
>
> install.packages("XML")
>
> ?
>
> Best,
> Ista
>
> On Tue, Oct 22, 2013 at 8:03 AM, Steven Dwayne Randolph <randolph_steven_d at lilly.com> wrote:
>> Duncan... Thank you.
>>
>>          1.   I am able to download the XML file via my corporate network, other packages without this same issue, even rcurl and bitops which are pre-requisites on the same page as XML.
>>          2.   I  have attempted to download this from my own wifi at home using xfinity/Comcast to my personal pc and still get the same error on this package alone.
>>                  3.   I am genuinely baffled by this package download and install experience.
>>                   4.  I would gladly build this from source, If indeed I could find the source and then use RTools to compile it.  That has been unsuccessful as well.   Nightmare? Slightly.
>>
>> Thanks for your response.....
>> Steven
>>
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: Sunday, October 20, 2013 12:13 PM
>> To: Steven Dwayne Randolph; r-help at r-project.org; Ista Zahn
>> Cc: stevendrandolph at aol.com
>> Subject: Re: [R] XML package not working
>>
>> On 13-10-20 9:23 AM, Steven Dwayne Randolph wrote:
>>> My apologies for not conforming to the posting guideline.
>>>
>>>
>>> Sys.info()
>>>                        sysname                      release                      version
>>>                      "Windows"                      "7 x64" "build 7601, Service Pack 1"
>>>                       nodename                      machine                        login
>>>              "xxxxxxNU247BZ1S"                     "x86-64"                    "XXXXXX"
>>>                           user               effective_user
>>>                      "xxxxxxx"                    "xxxxxxx"
>>>
>>> When I attempt to install a local copy of the xml.zip file:
>>>
>>> in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>>     cannot open the connection
>>> In addition: Warning messages:
>>> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
>>> file
>>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>>     cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'
>>
>> I think it is pretty clear that the problem is at your end:  you aren't downloading the file properly, even though everyone else is.  Perhaps you are behind a firewall, or something else is interfering with your downloads?
>>
>> Duncan Murdoch
>>
>>>
>>>
>>> -----Original Message-----
>>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>>> Sent: Saturday, October 19, 2013 8:23 PM
>>> To: Steven Dwayne Randolph; r-help at r-project.org
>>> Cc: stevendrandolph at aol.com
>>> Subject: Re: [R] XML package not working
>>>
>>> On 13-10-19 3:47 PM, Steven Dwayne Randolph wrote:
>>>> I know I  cannot be the only one who is not able to install the XML package from CRAN (zip or tar file)  Many packages depend on this XML package.  Can someone help me either access the source for a good binary?  I have received no assistance from the author/developer of the package.
>>>
>>> It installs fine for me.
>>>
>>> Duncan Murdoch
>>>
>>


From keith.jewell at campdenbri.co.uk  Tue Oct 22 15:35:43 2013
From: keith.jewell at campdenbri.co.uk (Keith Jewell)
Date: Tue, 22 Oct 2013 14:35:43 +0100
Subject: [R] More Columns than column names Error
In-Reply-To: <1382447710424-4678787.post@n4.nabble.com>
References: <1382422519242-4678770.post@n4.nabble.com>
	<1382447710424-4678787.post@n4.nabble.com>
Message-ID: <l45uv6$k1r$1@ger.gmane.org>

Carl is right.

Going to the nabble post and looking in the source data file 
<http://r.789695.n4.nabble.com/file/n4678770/Garbage.txt> I see the 
headings row has 'Material' tab 'Weight...' tab 'Percent'.
Each of the data rows has 1 tab character between the 'Material' and 
'Weight' columns and 3 tab characters between the 'Weight...' and 
'Percent' columns.

On 22/10/2013 14:15, Carl Witthoft wrote:
> What is the exact code you are using to try to load this file?
> I strongly suspect the problem is a mixture of spaces and multiple tabs in
> your text file.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/More-Columns-than-column-names-Error-tp4678770p4678787.html
> Sent from the R help mailing list archive at Nabble.com.
>


From smartpink111 at yahoo.com  Tue Oct 22 15:41:21 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 22 Oct 2013 06:41:21 -0700 (PDT)
Subject: [R] More Columns than column names Error
Message-ID: <1382449281.37719.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:
?lines1 <- readLines("Garbage.txt",warn=FALSE)
dat1 <- read.table(text=gsub("\t+","\t",lines1),stringsAsFactors=FALSE,sep="\t",check.names=FALSE,header=TRUE)
?str(dat1)
#'data.frame':??? 10 obs. of? 3 variables:
# $ Material??????????? : chr? "Food Scraps" "Glass" "Metals" "Paper" ...
# $ Weight(Million Tons): num? 25.9 12.8 18 86.7 24.7 ...
# $ Percent???????????? : num? 11.2 5.5 7.8 37.4 10.7 6.8 5.5 11.9 3.2 100
jpeg("garbageweight.jpg",width=800)
?barplot(dat1[-10,2],names.arg=dat1[-10,1],ylab=colnames(dat1)[2],col=rainbow(9),main="American garbage")
?dev.off()


A.K.


Hello guys, I'm having this weird problem with my assignment. I can't seem to import the data that I have created. 

I keep getting an error that says "Error: More Columns than Column names" 

This is my data file. 
Garbage.txt

Was also wondering if you guys could send me into the right direction on how to do this. 

1. Create a data frame with the data given above. 
2. Create the bar plot for weight variable with appropriate labels. Resize the graphics 
panel/ window so that all labels are visible. 
3. Add colors. Suppose n is the number of bars. 
> barplot(..., col = rainbow(n)) 
4. Save the plot to garbageweight.jpg 

This is how it's supposed to look like at the end.


From h.wickham at gmail.com  Tue Oct 22 15:43:24 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 22 Oct 2013 06:43:24 -0700
Subject: [R] speeding up "sum of squared differences" calculation
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5554B3A409@GOLD.corp.lgc-group.com>
References: <0765308CD028654885F30322557308D80E1DF378@NYCSM0208.rth.ad.rothschild.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A409@GOLD.corp.lgc-group.com>
Message-ID: <CABdHhvFOYv-0A5W5M+-f3EyB_yvKiEeKTWnjf-7N75znn90+YA@mail.gmail.com>

> There's little practical difference; both hover from 0.00 to 0.03 s system time. I could barely tell the difference even averaged over 100 runs; I was getting an average around 0.007 (system time) and 2.5s user time for both methods.

It's almost always better to use a high precision timer, as
implemented in the microbenchmark package:

library(microbenchmark)

ssqdif <- function(X, Y=X) {
  #From 'outer' without modification
  Y <- rep(Y, rep.int(length(X), length(Y)))
  X <- rep(X, times = ceiling(length(Y)/length(X)))
  #For this case:
  sum((X-Y)^2) #SLIGHTLY quicker than d<-X-Y; sum(d*d)
}

outerdif <- function(X, Y = X) {
  gg <- outer(X, Y, FUN="-")
  sum(gg*gg)
}

X <- runif(1000)

microbenchmark(
  ssqdif(X),
  outerdif(X)
)

Unit: milliseconds
        expr      min       lq   median       uq      max neval
   ssqdif(X) 9.035473 9.912253 14.65940 16.34044 68.30620   100
 outerdif(X) 8.962955 9.647820 14.85338 17.00048 66.89351   100

Looking at the range of values you can see indeed that the performance
is indeed almost identical.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From nashjc at uottawa.ca  Tue Oct 22 16:05:22 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Tue, 22 Oct 2013 10:05:22 -0400
Subject: [R] R - How to "physically" Increase Speed
In-Reply-To: <mailman.23.1382436009.26591.r-help@r-project.org>
References: <mailman.23.1382436009.26591.r-help@r-project.org>
Message-ID: <52668622.7050809@uottawa.ca>

The advice given is sensible. For a timing study see

http://rwiki.sciviews.org/doku.php?id=tips:rqcasestudy

We found that for optimization calculations, putting the objective
function calculation or parts thereof in Fortran was helpful. But we
kept those routines pretty small -- less than a page -- and we just
called them to evaluate things, avoiding passing around information back
and forth to R.

JN




On 13-10-22 06:00 AM, r-help-request at r-project.org wrote:
> Message: 58
> Date: Tue, 22 Oct 2013 05:47:15 -0400
> From: Jim Holtman <jholtman at gmail.com>
> To: Alexandre Khelifa <akhelifa at logitech.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Subject: Re: [R] R - How to "physically" Increase Speed
> Message-ID: <73D989DA-B6B3-421D-838C-903DA34350F2 at gmail.com>
> Content-Type: text/plain;	charset=us-ascii
> 
> I would start with taking a subset of the data (definitely some that would run in less than 10 minutes) and use the profiler "Rprof" to see where time is being spent.  you can use the the task monitor (if on windows) to see how much memory you are using; it sounds like you did not need the extra memory.
> 
> You might see if you can partition your data so you can run multiple versions of R and then merge the results.
> 
> Anything that takes more than a half hour, for me, is looked into to see where the problems are.  For example dataframes arevexpensive to access and conversion to matrices is one way to speed it up.  the is where the profiler helps.
>


From jdnewmil at dcn.davis.CA.us  Tue Oct 22 16:38:31 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 22 Oct 2013 07:38:31 -0700
Subject: [R] How do I use simple calls to java methods?
In-Reply-To: <1382447614947-4678786.post@n4.nabble.com>
References: <1382401907888-4678753.post@n4.nabble.com>
	<1382447614947-4678786.post@n4.nabble.com>
Message-ID: <22fca3b0-d454-4377-a482-d53039feab2f@email.android.com>

I don't use rJava, but numerous examples came up when I Googled for "rjava examples". The fact that you have not referenced any of that material may be leaving a bad taste in the mouths of those few people who do use both R and Java. Or, they may just not spend time wading through emails on this list.

Also, note that Nabble has a poor reputation on this list, because it encourages you to look at Nabble for message history rather than including it in the email. Please re-read the Posting Guide for this list.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Hurr <hill0093 at umn.edu> wrote:
>I am surprised to not get a reply. 
>I suppose this means that extremely few, if any, use rJava.
>
>rJava.pdf says this, but I am too stupid to interpret it:
>Description
>.jcall calls a Java method with the supplied arguments.
>Usage
>.jcall(obj, returnSig = "V", method, ..., evalArray = TRUE,
>evalString = TRUE, check = TRUE, interface = "RcallMethod",
>simplify = FALSE, use.true.class = FALSE)
>
>Perhaps it means that to replace:
>      calCk <- calStgOfLinTim(linTm,tlev) 
>and use something like:
>      calCk <- .jcall(CalqsLin.class,returnSig = "S",
>      calStgOfLinTim(linTm,tlev),evalArray=FALSE, 
>      evalString = TRUE, check = TRUE, interface = "RcallMethod",
>      simplify = FALSE, use.true.class = TRUE)
>
>I suppose there are other setup things to do, 
>like start the JVM (java Virtual machine)
>and I don't know what obj means.
>
>Anyway, if I am able to do these simple java method calls, 
>it will be a big plus to our data analysis lab to use R conveniently.
>
>Please help
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/How-do-I-use-simple-calls-to-java-methods-tp4678753p4678786.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From batholdy at googlemail.com  Tue Oct 22 16:43:18 2013
From: batholdy at googlemail.com (Martin Batholdy)
Date: Tue, 22 Oct 2013 16:43:18 +0200
Subject: [R] colour code areas of a plot
Message-ID: <19E1EA3A-3C58-4BFB-A2F8-9ED4A2D96C03@googlemail.com>

Hi,

I would like to colour different areas of a plot.
But I don't know how to do this efficiently.

As an example;

lets say three stimuli were presented in an experiment, alternating, one at a time.
Now I want to plot time on the x-axis and the plot-area should colour code the stimulus that was presented at that time interval
(green for stimulus 1, yellow for stimulus 2 etc.)


here an example:
(t = time)


t <- 1:100
bg_colors <- c(rep('green',20), rep('yellow',10), rep('green',20), rep('red',5), rep('yellow',45)) 

color_scheme <- data.frame(t, bg_colors)

plot(c(), c(), xlim = c(1,100), ylim=c(-1,1))


rect(xleft = 1, ybottom = -1, xright = 20, ytop = 1, col = 'green', lwd=0) 
rect(xleft = 20, ybottom = -1, xright = 30, ytop = 1, col = 'yellow', lwd=0) 
?


now how can I do this efficiently based on the color_scheme data-frame and without having to manually draw all the rectangles as in the example above?



thanks for any suggestions!

From ken.knoblauch at inserm.fr  Tue Oct 22 17:08:49 2013
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Tue, 22 Oct 2013 15:08:49 +0000
Subject: [R] colour code areas of a plot
References: <19E1EA3A-3C58-4BFB-A2F8-9ED4A2D96C03@googlemail.com>
Message-ID: <loom.20131022T170557-323@post.gmane.org>

Martin Batholdy <batholdy <at> googlemail.com> writes:
> I would like to colour different areas of a plot.
> But I don't know how to do this efficiently.
> 
> here an example:
> (t = time)
> 
> t <- 1:100
> bg_colors <- c(rep('green',20), rep('yellow',10), 
rep('green',20), rep('red',5),
> rep('yellow',45)) 
> 
> color_scheme <- data.frame(t, bg_colors)
> 
> plot(c(), c(), xlim = c(1,100), ylim=c(-1,1))
> 
> rect(xleft = 1, ybottom = -1, xright = 20, ytop = 1, 
col = 'green', lwd=0) 
> rect(xleft = 20, ybottom = -1, xright = 30, ytop = 1, 
col = 'yellow', lwd=0) 
> ?
> 
> now how can I do this efficiently based on the c
olor_scheme data-frame
 and without having to manually draw
> all the rectangles as in the example above?

The first 4 arguments of rect can be vectors 
as can be the col argument.  So you might be able to
draw all of the regions with a single call to rect.
I've done this to create alternating light and dark
regions to highlight condition changes.
See ?rect, of course.

> 
> thanks for any suggestions!
> 

-- 
Kenneth Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From randolph_steven_d at lilly.com  Tue Oct 22 14:03:37 2013
From: randolph_steven_d at lilly.com (Steven Dwayne Randolph)
Date: Tue, 22 Oct 2013 12:03:37 +0000
Subject: [R] XML package not working
In-Reply-To: <52640117.2010908@gmail.com>
References: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>
	<5263226B.7070103@gmail.com>
	<66C71547284587479F8009E05C07DA9704F8E5D2@USTLMLLYC107.RF.lilly.com>
	<52640117.2010908@gmail.com>
Message-ID: <66C71547284587479F8009E05C07DA9704F96EC4@USTLMLLYC107.RF.lilly.com>

Duncan... Thank you.  
 
	1.   I am able to download the XML file via my corporate network, other packages without this same issue, even rcurl and bitops which are pre-requisites on the same page as XML.
	2.   I  have attempted to download this from my own wifi at home using xfinity/Comcast to my personal pc and still get the same error on this package alone.  
                3.   I am genuinely baffled by this package download and install experience.
                 4.  I would gladly build this from source, If indeed I could find the source and then use RTools to compile it.  That has been unsuccessful as well.   Nightmare? Slightly. 

Thanks for your response.....
Steven

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Sunday, October 20, 2013 12:13 PM
To: Steven Dwayne Randolph; r-help at r-project.org; Ista Zahn
Cc: stevendrandolph at aol.com
Subject: Re: [R] XML package not working

On 13-10-20 9:23 AM, Steven Dwayne Randolph wrote:
> My apologies for not conforming to the posting guideline.
>
>
> Sys.info()
>                       sysname                      release                      version
>                     "Windows"                      "7 x64" "build 7601, Service Pack 1"
>                      nodename                      machine                        login
>             "xxxxxxNU247BZ1S"                     "x86-64"                    "XXXXXX"
>                          user               effective_user
>                     "xxxxxxx"                    "xxxxxxx"
>
> When I attempt to install a local copy of the xml.zip file:
>
> in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>    cannot open the connection
> In addition: Warning messages:
> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip 
> file
> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>    cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'

I think it is pretty clear that the problem is at your end:  you aren't downloading the file properly, even though everyone else is.  Perhaps you are behind a firewall, or something else is interfering with your downloads?

Duncan Murdoch

>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Saturday, October 19, 2013 8:23 PM
> To: Steven Dwayne Randolph; r-help at r-project.org
> Cc: stevendrandolph at aol.com
> Subject: Re: [R] XML package not working
>
> On 13-10-19 3:47 PM, Steven Dwayne Randolph wrote:
>> I know I  cannot be the only one who is not able to install the XML package from CRAN (zip or tar file)  Many packages depend on this XML package.  Can someone help me either access the source for a good binary?  I have received no assistance from the author/developer of the package.
>
> It installs fine for me.
>
> Duncan Murdoch
>


From allan.northpine at gmail.com  Tue Oct 22 09:17:16 2013
From: allan.northpine at gmail.com (Allan Clark)
Date: Tue, 22 Oct 2013 09:17:16 +0200
Subject: [R] [ADMB Users] R2admb compile problem
In-Reply-To: <5265328B.5080506@gmail.com>
References: <CAKJ=C4jg8A3HcsKc0eYt8kzf7r4CnukwmyPdg-MEwOJhh+wLAw@mail.gmail.com>
	<52652F7B.8080100@gmail.com>
	<alpine.LFD.2.03.1310211348320.43400@hafro.is>
	<5265328B.5080506@gmail.com>
Message-ID: <CAHpUJXC0xKcOUZD35=QYOg=zRnbqTw8=XR2eJEZ18GzOEqkpMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131022/01c3361a/attachment.pl>

From weitaiyun at gmail.com  Tue Oct 22 10:04:04 2013
From: weitaiyun at gmail.com (Taiyun Wei)
Date: Tue, 22 Oct 2013 16:04:04 +0800
Subject: [R] list and <<-
In-Reply-To: <CAFEqCdwUaB-xaoqSpXg7SEn5-dANuu+v7feHoaT_trB7j4fkJw@mail.gmail.com>
References: <CAM4FiqHQN-AFjsw+Fn1uOaAtDsgLqxp=ap=hepyThk=aPa0cjQ@mail.gmail.com>
	<CAFEqCdwUaB-xaoqSpXg7SEn5-dANuu+v7feHoaT_trB7j4fkJw@mail.gmail.com>
Message-ID: <CAM4FiqG+ZdmbkofVK_TUOTaYi5B7asm42EcQ5d_nSd0L5L8UwA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131022/4808bda8/attachment.pl>

From luana.paponi at libero.it  Tue Oct 22 11:50:57 2013
From: luana.paponi at libero.it (luana)
Date: Tue, 22 Oct 2013 02:50:57 -0700 (PDT)
Subject: [R] integer -> factor
Message-ID: <1382435457481-4678778.post@n4.nabble.com>

Hi!
I have a dataset composed by bmi, sex, age, and race.
I have to convert bmi, sex and race in factor and they have still to be in
the same dataset with their names.
That's because I need to do an Ordered Logistic Regression.
Can you help me?
really tnx!



--
View this message in context: http://r.789695.n4.nabble.com/integer-factor-tp4678778.html
Sent from the R help mailing list archive at Nabble.com.


From randolph_steven_d at lilly.com  Tue Oct 22 15:19:28 2013
From: randolph_steven_d at lilly.com (Steven Dwayne Randolph)
Date: Tue, 22 Oct 2013 13:19:28 +0000
Subject: [R] XML package not working
In-Reply-To: <CA+vqiLH9HP_T599Cbru+v=OZ126x1KBz==mweCuY-DXXtXD02g@mail.gmail.com>
References: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>
	<5263226B.7070103@gmail.com>
	<66C71547284587479F8009E05C07DA9704F8E5D2@USTLMLLYC107.RF.lilly.com>
	<52640117.2010908@gmail.com>
	<66C71547284587479F8009E05C07DA9704F96EC4@USTLMLLYC107.RF.lilly.com>
	<CA+vqiLH9HP_T599Cbru+v=OZ126x1KBz==mweCuY-DXXtXD02g@mail.gmail.com>
Message-ID: <66C71547284587479F8009E05C07DA9704F96FB5@USTLMLLYC107.RF.lilly.com>

Ista,... Thank you for your response.   Here is what is occurring when I attempt to command-line install.
 ----------------------------------------------------------------------------------------------------------------------------------
> install.packages('XML')
Installing package into ?C:/Users/xxxxxxx/Documents/R/win-library/3.0?
(as ?lib? is unspecified)
trying URL 'http://cran.rstudio.com/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
Content type 'application/zip' length 4287270 bytes (4.1 Mb)
opened URL
downloaded 4.1 Mb

Warning in install.packages :
  downloaded length 4276224 != reported length 4287270
Warning in install.packages :
  error 1 in extracting from zip file
Warning in install.packages :
  cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'
Error in install.packages : cannot open the connection

------------------------------------------------------------------------------------------------------------------------------------------

STeven
-----Original Message-----
From: Ista Zahn [mailto:istazahn at gmail.com] 
Sent: Tuesday, October 22, 2013 8:09 AM
To: Steven Dwayne Randolph
Cc: Duncan Murdoch; r-help at r-project.org; stevendrandolph at aol.com; Piyush Singh - Network
Subject: Re: [R] XML package not working

Hi Steven,

I still don't understand why you are downloading it manually. What happens when you

install.packages("XML")

?

Best,
Ista

On Tue, Oct 22, 2013 at 8:03 AM, Steven Dwayne Randolph <randolph_steven_d at lilly.com> wrote:
> Duncan... Thank you.
>
>         1.   I am able to download the XML file via my corporate network, other packages without this same issue, even rcurl and bitops which are pre-requisites on the same page as XML.
>         2.   I  have attempted to download this from my own wifi at home using xfinity/Comcast to my personal pc and still get the same error on this package alone.
>                 3.   I am genuinely baffled by this package download and install experience.
>                  4.  I would gladly build this from source, If indeed I could find the source and then use RTools to compile it.  That has been unsuccessful as well.   Nightmare? Slightly.
>
> Thanks for your response.....
> Steven
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Sunday, October 20, 2013 12:13 PM
> To: Steven Dwayne Randolph; r-help at r-project.org; Ista Zahn
> Cc: stevendrandolph at aol.com
> Subject: Re: [R] XML package not working
>
> On 13-10-20 9:23 AM, Steven Dwayne Randolph wrote:
>> My apologies for not conforming to the posting guideline.
>>
>>
>> Sys.info()
>>                       sysname                      release                      version
>>                     "Windows"                      "7 x64" "build 7601, Service Pack 1"
>>                      nodename                      machine                        login
>>             "xxxxxxNU247BZ1S"                     "x86-64"                    "XXXXXX"
>>                          user               effective_user
>>                     "xxxxxxx"                    "xxxxxxx"
>>
>> When I attempt to install a local copy of the xml.zip file:
>>
>> in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>    cannot open the connection
>> In addition: Warning messages:
>> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip 
>> file
>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>    cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'
>
> I think it is pretty clear that the problem is at your end:  you aren't downloading the file properly, even though everyone else is.  Perhaps you are behind a firewall, or something else is interfering with your downloads?
>
> Duncan Murdoch
>
>>
>>
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: Saturday, October 19, 2013 8:23 PM
>> To: Steven Dwayne Randolph; r-help at r-project.org
>> Cc: stevendrandolph at aol.com
>> Subject: Re: [R] XML package not working
>>
>> On 13-10-19 3:47 PM, Steven Dwayne Randolph wrote:
>>> I know I  cannot be the only one who is not able to install the XML package from CRAN (zip or tar file)  Many packages depend on this XML package.  Can someone help me either access the source for a good binary?  I have received no assistance from the author/developer of the package.
>>
>> It installs fine for me.
>>
>> Duncan Murdoch
>>
>

From maechler at stat.math.ethz.ch  Tue Oct 22 17:12:43 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 22 Oct 2013 17:12:43 +0200
Subject: [R] cor matrix in multivariate regression
In-Reply-To: <E244C6B8-685A-4EBC-B776-E05E76B1C154@rockefeller.edu>
References: <E244C6B8-685A-4EBC-B776-E05E76B1C154@rockefeller.edu>
Message-ID: <21094.38379.252495.77819@stat.math.ethz.ch>

>>>>> Suyan Tian <stian at mail.rockefeller.edu>
>>>>>     on Tue, 22 Oct 2013 01:18:10 +0000 writes:

    > Sorry to bother, I want to construct a correlation matrix
    > in multivariate regression (several dependent variables
    > and they are correlated in some ways) like the followings,

    > 1   0.8   0  0 ?     0 0 
    > 0.8 1     0  0  ?    0 0 
    > 0    0     1  0.8 ?  0 0 
    > 0   0      0.8 1  ? 0 0 
    > .     .       .     .         ?.

    > .     .        .   .          

    > 0  0                      1  0.8 
    > 0  0                       0.8 1 

    > Does anyone know how to do it? 

Of course, with many such problems in R, there are *many* ways.

I believe one of the nicest ways here is to use  toeplitz() :

  n <- 12  ## or whatever your  n is
  toeplitz(c(1,0.8, rep(0, n-2)))

Note that for larger n, under some circumstances it may be
beneficial to use the Matrix package and its *sparse* matrices,
e.g.,

> require(Matrix)
> n <- 12; toeplitz(as(c(1,0.8, rep(0, n-2)), "sparseVector"))
12 x 12 sparse Matrix of class "dsCMatrix"
                                                     
 [1,] 1.0 0.8 .   .   .   .   .   .   .   .   .   .  
 [2,] 0.8 1.0 0.8 .   .   .   .   .   .   .   .   .  
 [3,] .   0.8 1.0 0.8 .   .   .   .   .   .   .   .  
 [4,] .   .   0.8 1.0 0.8 .   .   .   .   .   .   .  
 [5,] .   .   .   0.8 1.0 0.8 .   .   .   .   .   .  
 [6,] .   .   .   .   0.8 1.0 0.8 .   .   .   .   .  
 [7,] .   .   .   .   .   0.8 1.0 0.8 .   .   .   .  
 [8,] .   .   .   .   .   .   0.8 1.0 0.8 .   .   .  
 [9,] .   .   .   .   .   .   .   0.8 1.0 0.8 .   .  
[10,] .   .   .   .   .   .   .   .   0.8 1.0 0.8 .  
[11,] .   .   .   .   .   .   .   .   .   0.8 1.0 0.8
[12,] .   .   .   .   .   .   .   .   .   .   0.8 1.0
> 

Best regards,
Martin Maechler, ETH Zurich


From olivier.crouzet at univ-nantes.fr  Tue Oct 22 17:14:12 2013
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Tue, 22 Oct 2013 17:14:12 +0200
Subject: [R] colour code areas of a plot
In-Reply-To: <19E1EA3A-3C58-4BFB-A2F8-9ED4A2D96C03@googlemail.com>
References: <19E1EA3A-3C58-4BFB-A2F8-9ED4A2D96C03@googlemail.com>
Message-ID: <20131022171412.9a0354652390e33d873edc1b@univ-nantes.fr>

On Tue, 22 Oct 2013 16:43:18 +0200
Martin Batholdy <batholdy at googlemail.com> wrote:

Hi,

you should replace your "color names" by calls to the rgb() function in
order to generate the adequate colors, something like:

bg_colors <- c(rep (rgb (0,1,0),20), rep (rgb (0,1,1),10), rep (rgb
(0,1,0),20), rep(rgb (1,0,0),5), rep(rgb (1,1,0),45)) 

(though it should obviously be automatically extracted from your data I
suppose).

Then it is possible to use the color vector as an option to
any plotting command e.g.:

plot(color_scheme$t, color_scheme$t,col=bg_colors)

or (something like):

rect(xleft = color_scheme$t[1:99], ybottom = -1, xright = color_scheme$t
[2:100], ytop = 1, col=bg_colors, lwd=0) 

Olivier.


> Hi,
> 
> I would like to colour different areas of a plot.
> But I don't know how to do this efficiently.
> 
> As an example;
> 
> lets say three stimuli were presented in an experiment, alternating,
> one at a time. Now I want to plot time on the x-axis and the
> plot-area should colour code the stimulus that was presented at that
> time interval (green for stimulus 1, yellow for stimulus 2 etc.)
> 
> 
> here an example:
> (t = time)
> 
> 
> t <- 1:100
> bg_colors <- c(rep('green',20), rep('yellow',10), rep('green',20), rep
> ('red',5), rep('yellow',45)) 
> 
> color_scheme <- data.frame(t, bg_colors)
> 
> plot(c(), c(), xlim = c(1,100), ylim=c(-1,1))
> 
> 
> rect(xleft = 1, ybottom = -1, xright = 20, ytop = 1, col = 'green',
> lwd=0) rect(xleft = 20, ybottom = -1, xright = 30, ytop = 1, col =
> 'yellow', lwd=0) ?
> 
> 
> now how can I do this efficiently based on the color_scheme
> data-frame and without having to manually draw all the rectangles as
> in the example above?
> 
> 
> 
> thanks for any suggestions!
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.


-- 
  Olivier Crouzet, PhD
  Laboratoire de Linguistique -- EA3827
  Universit? de Nantes
  Chemin de la Censive du Tertre - BP 81227
  44312 Nantes cedex 3
  France

     phone:        (+33) 02 40 14 14 05 (lab.)
                   (+33) 02 40 14 14 36 (office)
     fax:          (+33) 02 40 14 13 27
     e-mail:       olivier.crouzet at univ-nantes.fr
 		
  http://www.lling.univ-nantes.fr/


From sarah.goslee at gmail.com  Tue Oct 22 17:21:56 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 22 Oct 2013 11:21:56 -0400
Subject: [R] integer -> factor
In-Reply-To: <1382435457481-4678778.post@n4.nabble.com>
References: <1382435457481-4678778.post@n4.nabble.com>
Message-ID: <CAM_vjukqqKGhrNJAA0yg15Gz-VhhzROoNeg2VAq8LoyOTvPySg@mail.gmail.com>

Hi,

You should probably start by reading

?factor

Sarah

On Tue, Oct 22, 2013 at 5:50 AM, luana <luana.paponi at libero.it> wrote:
> Hi!
> I have a dataset composed by bmi, sex, age, and race.
> I have to convert bmi, sex and race in factor and they have still to be in
> the same dataset with their names.
> That's because I need to do an Ordered Logistic Regression.
> Can you help me?
> really tnx!
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From gunter.berton at gene.com  Tue Oct 22 17:25:24 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 22 Oct 2013 08:25:24 -0700
Subject: [R] integer -> factor
In-Reply-To: <CAM_vjukqqKGhrNJAA0yg15Gz-VhhzROoNeg2VAq8LoyOTvPySg@mail.gmail.com>
References: <1382435457481-4678778.post@n4.nabble.com>
	<CAM_vjukqqKGhrNJAA0yg15Gz-VhhzROoNeg2VAq8LoyOTvPySg@mail.gmail.com>
Message-ID: <CACk-te1ayJck2OtBA6873pSURb60502syVOSpPkeY74yDoVsCA@mail.gmail.com>

... and ?ordered for bmi.

And if the OP has not already done so, read An Introduction to R or
other web tutorial and stop posting such basic questions here.

Cheers,
Bert

On Tue, Oct 22, 2013 at 8:21 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> Hi,
>
> You should probably start by reading
>
> ?factor
>
> Sarah
>
> On Tue, Oct 22, 2013 at 5:50 AM, luana <luana.paponi at libero.it> wrote:
>> Hi!
>> I have a dataset composed by bmi, sex, age, and race.
>> I have to convert bmi, sex and race in factor and they have still to be in
>> the same dataset with their names.
>> That's because I need to do an Ordered Logistic Regression.
>> Can you help me?
>> really tnx!
>>
>>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From pgilbert902 at gmail.com  Tue Oct 22 17:37:34 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Tue, 22 Oct 2013 11:37:34 -0400
Subject: [R] Am I working with regularly spaced time series?
In-Reply-To: <mailman.23.1382436009.26591.r-help@r-project.org>
References: <mailman.23.1382436009.26591.r-help@r-project.org>
Message-ID: <52669BBE.3050601@gmail.com>



On 13-10-22 06:00 AM, Weiwu Zhang <zhangweiwu at realss.com> wrote:
> My data is sampled once per minute.

At the same second each minute or not? Regularly spaced would mean 
exactly one minute between observations.

There are invalid samples, leaving
> a lot of holes in the samples, successful sample is around 80% of all
> minutes in a day. and during the last 4 months sampling, one month's
> data was stored on a harddisk that failed, leaving a month's gap in
> between.

This is called "missing observations". With regular spacing you need to 
fill in the holes with NA. With irregular spacing you can either drop 
the missing observations or, if you know the time at which they were 
missed, you could fill in with NA.

>
> So am I working with regularly spaced time series or not? Should I
> padd all missing data with NAs, and start with ts(), and followed by
> forecast package (which seems to have all the functions I need in the
> begining) or should I start with a library with irregular time series
> in mind?
>
> Also, ts() manual didn't say how to create time-series with one minute
> as daltat. Its seems to assume time-series is about dates. So the data
> I have with me, is it really time series at all?

ts() representations works best with regularly spaced monthly, 
quarterly, or annual data. You can use it for other things if they fit 
nicely into the regular spaced observations with a frequency of 
observation, such as 12 times per year or 60 times per hour. This 
usually only makes sense if the frequency has something to do with your 
problem, like seasonality questions. You can also use frequency 1 for 
one observation per period, like annual data, which in your case would 
be once per minute. I'm inclined to think that a zoo (see package zoo) 
represenation would fit your problem better.

HTH,
Paul
>
> Newbie question indeed. Thanks.
>


From ggrothendieck at gmail.com  Tue Oct 22 17:47:23 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 22 Oct 2013 11:47:23 -0400
Subject: [R] Am I working with regularly spaced time series?
In-Reply-To: <52669BBE.3050601@gmail.com>
References: <mailman.23.1382436009.26591.r-help@r-project.org>
	<52669BBE.3050601@gmail.com>
Message-ID: <CAP01uRnP-SViqMv4zOMKu4xU3owTjTL-RH=AkHU9Eps4gSUgXQ@mail.gmail.com>

On Tue, Oct 22, 2013 at 11:37 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>
>
> On 13-10-22 06:00 AM, Weiwu Zhang <zhangweiwu at realss.com> wrote:
>>
>> My data is sampled once per minute.
>
>
> At the same second each minute or not? Regularly spaced would mean exactly
> one minute between observations.
>
>
> There are invalid samples, leaving
>>
>> a lot of holes in the samples, successful sample is around 80% of all
>> minutes in a day. and during the last 4 months sampling, one month's
>> data was stored on a harddisk that failed, leaving a month's gap in
>> between.
>
>
> This is called "missing observations". With regular spacing you need to fill
> in the holes with NA. With irregular spacing you can either drop the missing
> observations or, if you know the time at which they were missed, you could
> fill in with NA.
>
>
>>
>> So am I working with regularly spaced time series or not? Should I
>> padd all missing data with NAs, and start with ts(), and followed by
>> forecast package (which seems to have all the functions I need in the
>> begining) or should I start with a library with irregular time series
>> in mind?
>>
>> Also, ts() manual didn't say how to create time-series with one minute
>> as daltat. Its seems to assume time-series is about dates. So the data
>> I have with me, is it really time series at all?
>
>
> ts() representations works best with regularly spaced monthly, quarterly, or
> annual data. You can use it for other things if they fit nicely into the
> regular spaced observations with a frequency of observation, such as 12
> times per year or 60 times per hour. This usually only makes sense if the
> frequency has something to do with your problem, like seasonality questions.
> You can also use frequency 1 for one observation per period, like annual
> data, which in your case would be once per minute. I'm inclined to think
> that a zoo (see package zoo) represenation would fit your problem better.
>

Also note that the zoo package has two classes:

1. zoo for irregularly spaced series
2. zooreg for series with an underlying regularity but for which some
of the points are missing (which seems to be the situation under
discussion)

The two classes are nearly the same but zooreg series have a frequency
and some methods act differently -- most notably lag and diff.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From 538280 at gmail.com  Tue Oct 22 18:16:27 2013
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 22 Oct 2013 10:16:27 -0600
Subject: [R] list and <<-
In-Reply-To: <CAM4FiqG+ZdmbkofVK_TUOTaYi5B7asm42EcQ5d_nSd0L5L8UwA@mail.gmail.com>
References: <CAM4FiqHQN-AFjsw+Fn1uOaAtDsgLqxp=ap=hepyThk=aPa0cjQ@mail.gmail.com>
	<CAFEqCdwUaB-xaoqSpXg7SEn5-dANuu+v7feHoaT_trB7j4fkJw@mail.gmail.com>
	<CAM4FiqG+ZdmbkofVK_TUOTaYi5B7asm42EcQ5d_nSd0L5L8UwA@mail.gmail.com>
Message-ID: <CAFEqCdxpRBN8mX1eaPnabr=DJFYE0Vp3MGxD+PriPVb4hsGiDA@mail.gmail.com>

Look carefully at your output (and I don't think that you are showing
us the output of what you actually ran in the order that you ran it).
After running `x %=% 1` you should see that x has the value `1`, but
your output shows `2`, this is the result of the next command `y$a %=%
2`, see the `<<-` assignment will always assign to `x`, not to the
variable named in the local variable x.

An operator like %=% should be used to somehow combine its 2 arguments
and return the result, not ever change a variable value.  The job of
assigning the result should go to the user/caller.  You could possibly
create a new class and an assignment method for that class that would
work like the assignment.

If you can give us more of an idea of what your ultimate goal is then
we may be able to help you find a better approach.

On Tue, Oct 22, 2013 at 2:04 AM, Taiyun Wei <weitaiyun at gmail.com> wrote:
> Many thanks:)
>
> I have a list(), eg. named opt, I want to check and assign values to it:
>
> if(is.null(opt$a)) opt$a = 'x'
> if(is.null(opt$b)) opt$a = 'y'
> ...
>
> I need to do a lot of these jobs, so I write a function to simplify it:
>
> '%=%' = function(x, y){
>     if(is.null(x)) {
>         x <<- y
>     }
> }
>
> x=NULL
> y=list()
>
>> is.null(x)
> [1] TRUE
>> is.null(y$a)
> [1] TRUE
>
>> x %=% 1;
>> x
> [1] 2
>> y$a %=% 2; ## Can't assign 2 to y$a, still NULL
>> y$a
> NULL
>
>
>
>
>
>
> On Mon, Oct 21, 2013 at 11:38 PM, Greg Snow <538280 at gmail.com> wrote:
>>
>> See fortune(174).
>>
>> It is best to avoid using '<<-', if you tell us what you are trying to
>> accomplish then we may be able to provide a better means to accomplish
>> it.
>>
>> On Sat, Oct 19, 2013 at 10:28 PM, Taiyun Wei <weitaiyun at gmail.com> wrote:
>> > Dear All,
>> >
>> >> opt = list()
>> >> opt$aa <<- TRUE
>> > Error in opt$aa <<- TRUE : object 'opt' not found
>> >
>> > Why?
>> >
>> > --
>> > Regards,
>> > Taiyun
>> > --
>> > Taiyun Wei <weitaiyun at gmail.com>
>> > Homepage: http://blog.cos.name/taiyun/
>> > Phone: +86-15201142716
>> > Renmin University of China
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>
>
>
>
> --
> Regards,
> Taiyun
> --
> Taiyun Wei <weitaiyun at gmail.com>
> Homepage: http://blog.cos.name/taiyun/
> Phone: +86-15201142716
> Renmin University of China



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From wdunlap at tibco.com  Tue Oct 22 18:37:51 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 22 Oct 2013 16:37:51 +0000
Subject: [R] speeding up "sum of squared differences" calculation
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5554B3A420@GOLD.corp.lgc-group.com>
References: <0765308CD028654885F30322557308D80E1DF378@NYCSM0208.rth.ad.rothschild.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A409@GOLD.corp.lgc-group.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A420@GOLD.corp.lgc-group.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0EB9A@PA-MBX01.na.tibco.com>

outer() and dist() are good for speed on smaller problems but they
require O(length(X)^2) memory.  This can slow things down or even
stop the calculations for large problems.  You can gain a lot of speed
without the memory problem by summing things up in chunks.
E.g., On a Linux box I compared
    fChunk <- function(x) {
        ans <- 0
        for(i in seq_along(x)[-1]) {
            ans <- ans + sum( (x[i] - x[seq_len(i-1)])^2)
        }
        2*ans
    }
with the original algorithm (slightly cleaned up)
    fOrig <-function (x) {
        ans <- 0
        for (i in seq_along(x)[-1]) {
            for (j in seq_len(i)) {
                ans <- ans + (x[i] - x[j])^2
            }
        }
        2 * ans
    }
and the ones based on outer() and dist().
   fOuter <- function(x) sum(outer(x, x, FUN=`-`)^2)
   fDist <- function(x) 2 * sum(dist(x)^2)
for a vector of length 10000.

   > z <- rnorm(10^4)
   > t(sapply(list(fOrig=fOrig, fChunk=fChunk, fDist=fDist, fOuter=fOuter),
            function(f)tryCatch(system.time(f(z)), error=function(e)NA)[1:3]))
          user.self sys.self elapsed
   fOrig     90.262    0.000  90.378
   fChunk     0.776    0.004   0.779
   fDist      1.092    0.276   1.370
   fOuter     0.740    1.068   1.855

They all give slightly different answers because the round-off error depends on
the order in which sums and squares are done.

Of course, the Rcpp version has no memory penalty and is faster than any of them.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of S Ellison
> Sent: Tuesday, October 22, 2013 6:08 AM
> To: r-help at r-project.org
> Cc: Ken Knoblauch
> Subject: Re: [R] speeding up "sum of squared differences" calculation
> 
> > Conclusion: hard to beat outer() for this purpose in R
> ... unless you use Ken Knoblauch's suggestion of dist() or Rccp.
> 
> Nice indeed.
> 
> 
> S Ellison
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Tue Oct 22 18:38:47 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 22 Oct 2013 18:38:47 +0200
Subject: [R] XML package not working
In-Reply-To: <66C71547284587479F8009E05C07DA9704F96FB5@USTLMLLYC107.RF.lilly.com>
References: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>
	<5263226B.7070103@gmail.com>
	<66C71547284587479F8009E05C07DA9704F8E5D2@USTLMLLYC107.RF.lilly.com>
	<52640117.2010908@gmail.com>
	<66C71547284587479F8009E05C07DA9704F96EC4@USTLMLLYC107.RF.lilly.com>
	<CA+vqiLH9HP_T599Cbru+v=OZ126x1KBz==mweCuY-DXXtXD02g@mail.gmail.com>
	<66C71547284587479F8009E05C07DA9704F96FB5@USTLMLLYC107.RF.lilly.com>
Message-ID: <3A91AE42-2C39-484B-B331-5E1E4EFFCDF0@xs4all.nl>


On 22-10-2013, at 15:19, Steven Dwayne Randolph <randolph_steven_d at lilly.com> wrote:

> Ista,... Thank you for your response.   Here is what is occurring when I attempt to command-line install.
> ----------------------------------------------------------------------------------------------------------------------------------
>> install.packages('XML')
> Installing package into ?C:/Users/xxxxxxx/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> trying URL 'http://cran.rstudio.com/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> Content type 'application/zip' length 4287270 bytes (4.1 Mb)
> opened URL
> downloaded 4.1 Mb
> 
> Warning in install.packages :
>  downloaded length 4276224 != reported length 4287270


Look at what is reported here. The downloaded length is not equal to the reported (i.e. actual) length of  the zip.
What is the length if you download the .zip file manually?
So something has gone wrong with the download.
Can you open a .zip file in another program? If so see what happens if you open it in that program.
You have to do detective work.

Berend


> Warning in install.packages :
>  error 1 in extracting from zip file
> Warning in install.packages :
>  cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'
> Error in install.packages : cannot open the connection
> 
> ------------------------------------------------------------------------------------------------------------------------------------------
> 
> STeven
> -----Original Message-----
> From: Ista Zahn [mailto:istazahn at gmail.com] 
> Sent: Tuesday, October 22, 2013 8:09 AM
> To: Steven Dwayne Randolph
> Cc: Duncan Murdoch; r-help at r-project.org; stevendrandolph at aol.com; Piyush Singh - Network
> Subject: Re: [R] XML package not working
> 
> Hi Steven,
> 
> I still don't understand why you are downloading it manually. What happens when you
> 
> install.packages("XML")
> 
> ?
> 
> Best,
> Ista
> 
> On Tue, Oct 22, 2013 at 8:03 AM, Steven Dwayne Randolph <randolph_steven_d at lilly.com> wrote:
>> Duncan... Thank you.
>> 
>>        1.   I am able to download the XML file via my corporate network, other packages without this same issue, even rcurl and bitops which are pre-requisites on the same page as XML.
>>        2.   I  have attempted to download this from my own wifi at home using xfinity/Comcast to my personal pc and still get the same error on this package alone.
>>                3.   I am genuinely baffled by this package download and install experience.
>>                 4.  I would gladly build this from source, If indeed I could find the source and then use RTools to compile it.  That has been unsuccessful as well.   Nightmare? Slightly.
>> 
>> Thanks for your response.....
>> Steven
>> 
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: Sunday, October 20, 2013 12:13 PM
>> To: Steven Dwayne Randolph; r-help at r-project.org; Ista Zahn
>> Cc: stevendrandolph at aol.com
>> Subject: Re: [R] XML package not working
>> 
>> On 13-10-20 9:23 AM, Steven Dwayne Randolph wrote:
>>> My apologies for not conforming to the posting guideline.
>>> 
>>> 
>>> Sys.info()
>>>                      sysname                      release                      version
>>>                    "Windows"                      "7 x64" "build 7601, Service Pack 1"
>>>                     nodename                      machine                        login
>>>            "xxxxxxNU247BZ1S"                     "x86-64"                    "XXXXXX"
>>>                         user               effective_user
>>>                    "xxxxxxx"                    "xxxxxxx"
>>> 
>>> When I attempt to install a local copy of the xml.zip file:
>>> 
>>> in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>>   cannot open the connection
>>> In addition: Warning messages:
>>> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip 
>>> file
>>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>>   cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'
>> 
>> I think it is pretty clear that the problem is at your end:  you aren't downloading the file properly, even though everyone else is.  Perhaps you are behind a firewall, or something else is interfering with your downloads?
>> 
>> Duncan Murdoch
>> 
>>> 
>>> 
>>> -----Original Message-----
>>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>>> Sent: Saturday, October 19, 2013 8:23 PM
>>> To: Steven Dwayne Randolph; r-help at r-project.org
>>> Cc: stevendrandolph at aol.com
>>> Subject: Re: [R] XML package not working
>>> 
>>> On 13-10-19 3:47 PM, Steven Dwayne Randolph wrote:
>>>> I know I  cannot be the only one who is not able to install the XML package from CRAN (zip or tar file)  Many packages depend on this XML package.  Can someone help me either access the source for a good binary?  I have received no assistance from the author/developer of the package.
>>> 
>>> It installs fine for me.
>>> 
>>> Duncan Murdoch
>>> 
>> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j.keirstead at imperial.ac.uk  Tue Oct 22 16:14:31 2013
From: j.keirstead at imperial.ac.uk (James Keirstead)
Date: Tue, 22 Oct 2013 15:14:31 +0100
Subject: [R] [R-pkgs] scholar 0.1.0 on CRAN
Message-ID: <52668847.1000201@imperial.ac.uk>

Dear R users,

A new package 'scholar' (version 0.1.0) is now available on CRAN: 
http://cran.r-project.org/web/packages/scholar/index.html.

The scholar package provides functions to extract citation data from 
Google Scholar.  In addition to retrieving basic information about a 
single scholar, the package also allows you to compare multiple scholars 
and predict future h-index values based on the method of Acuna et al.  
For example, we can compare the careers of Richard Feynman and Stephen 
Hawking as follows:

    ids <- c('B7vSqZsAAAAJ', 'qj74uXkAAAAJ')
    df <- compare_scholar_careers(ids)
    ggplot(df, aes(x=career_year, y=cites)) + geom_line(aes(linetype=name))

For more information and examples of how to use the package, please see 
https://github.com/jkeirstead/scholar.

Your comments and suggestions would be appreciated.

Best wishes,
James

-- 
Dr James Keirstead
Lecturer
Dept of Civil and Environmental Engineering
Imperial College
South Kensington, London
SW7 2AZ

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From terka424 at gmail.com  Tue Oct 22 18:40:07 2013
From: terka424 at gmail.com (Tereza Smejkalova)
Date: Tue, 22 Oct 2013 17:40:07 +0100
Subject: [R] Hdf files Download
Message-ID: <001001cecf45$5f39a730$1dacf590$@gmail.com>

I am triing one more time since my first message was rejected by the filter:

 

Dear all, 
I need to download and process large amounts of MODIS surface reflectance
imagery. I have adapted a script written by T. Hengl (
<http://www.spatial-analyst.net/wiki/?title=Download_and_resampling_of_MODIS
_images>
http://www.spatial-analyst.net/wiki/?title=Download_and_resampling_of_MODIS_
images) for download from the new HTTP (since FTP is no longer available).
The downloaded .HDF files however have no headers and it is impossible to
work with them. If I download directly from the webpage everything is fine.
Does anyone know what the problem might be, please? 

I am attaching my code

 

Please it is urgent. 

Thanks a lot.

 

 


From halim10-fes at sust.edu  Tue Oct 22 17:08:16 2013
From: halim10-fes at sust.edu (halim10-fes)
Date: Tue, 22 Oct 2013 22:08:16 +0700
Subject: [R] How to draw figures in a graph?
In-Reply-To: <CABdHhvFOYv-0A5W5M+-f3EyB_yvKiEeKTWnjf-7N75znn90+YA@mail.gmail.com>
References: <0765308CD028654885F30322557308D80E1DF378@NYCSM0208.rth.ad.rothschild.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A409@GOLD.corp.lgc-group.com>
	<CABdHhvFOYv-0A5W5M+-f3EyB_yvKiEeKTWnjf-7N75znn90+YA@mail.gmail.com>
Message-ID: <20131022144358.M19935@sust.edu>

Hi All,

Hope you guys are doing well. I am thinking of drawing some figures within a 
graph to make it more interesting. To make a graph more storytelling, like the 
attached one.

I am looking for a couple of days but couldn't come up with any solution on how 
to do it with R. Any ideas will be greatly appreciated.

Thanks,

---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com

-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Sample graph.png
Type: image/png
Size: 10728 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131022/ea50d6d7/attachment.png>

From john at jvp247.com  Tue Oct 22 19:07:34 2013
From: john at jvp247.com (John Van Praag)
Date: Tue, 22 Oct 2013 18:07:34 +0100
Subject: [R] Graphing complex functions
Message-ID: <CAEorq2N5Td92mU=8D+73mkmg_Jp5HCD+0dXkfNSwtjC8CNGx0Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131022/584a259f/attachment.pl>

From Wayne.W.Jones at shell.com  Tue Oct 22 19:52:28 2013
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Tue, 22 Oct 2013 17:52:28 +0000
Subject: [R]  nls model definition help
Message-ID: <823FB8AD8FD2F44A92284630A4AADF7E2F1B5B2D@seacmw-s-53401.europe.shell.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131022/119716b5/attachment.pl>

From ingfimo at gmail.com  Tue Oct 22 20:21:38 2013
From: ingfimo at gmail.com (Filippo Monari)
Date: Tue, 22 Oct 2013 19:21:38 +0100
Subject: [R] reference class error
Message-ID: <5266C232.304@gmail.com>

hi,
I'm new to reference classes but as I have experience with python I 
decided to port some of my code in this frame work.
I have the following two reference classes in separate files:

#1#
uvRndVar = setRefClass(
     Class = 'uvRndVar',
     fields = list(
         desc = 'character',
         type = 'character',
         pars = 'list',
         MAP = c('numeric'),
         post = c('numeric')
     ),
     methods = list(
         initialize = function (desc, type, pars) {
             types = c('norm', 'lnorm', 'beta', 'gamma')
             parameters = list(norm = c('mean', 'sd'), lnorm = c('mean', 
'sd'),
                 beta = c('shape1', 'shape2'), gamma = c('shape', 'rate'))
             if (!any(types == type)) {
                 stop('not correct type provided')
             } else {
                 if (length(names(pars)) == length(parameters[[type]])) {
                     for (i in 1:length(names(pars))) {
                         a = which(parameters[[type]] == names(pars)[i])
                         if (length(a)) {
                             parameters[[type]] = parameters[[type]][-a]
                         } else {
                             stop(paste('parameter', names(pars)[i], 
'not compatible with provided type'))
                         }
                     }
                     .self$desc = desc
                     .self$type = type
                     .self$pars = pars
                     .self$MAP = NaN
                     .self$post = NaN
                 } else {
                     stop('parameter list provided has wrong length')
                 }
             }
         }
     )
)


#2#
NG = setRefClass(
     Class = 'NG',
     fields = list(
         Y = 'matrix',
         X = 'matrix',
         CvFun = 'Cf',
         CfHp = 'list',
         lam = 'uvRndVar',
         lam.upd = 'logical',
         A = 'array',
         basis = 'matrix',
         Y.star = 'matrix',
         X.star = 'matrix',
         lam.star = 'numeric',
         lam.star.upd = 'logical',
         A.star = 'matrix'
     ),
     methods = list(
         initialize = function (Y, X, Cf, CfHp, lam, A, basis) {
             if (nrow(Y) != nrow(X)) {
                 stop('X and Y have different numbers of rows')
             } else if (dim(A)[1] != dim(A)[2]) {
                 stop('A is not a square matrix')
             } else if (dim(A)[1] != nrow(basis)) {
                 stop('basis matrix and precision matrix A have 
different number of rows')
             } else if (dim(A)[3] != nrow(X)) {
                 stop('dim(A)[3] != nrow(X)')
             } else if (ncol(basis) != ncol(Y)) {
                 stop('basis matrix and Y have different number of columns')
             } else {
                 CvFun$checkModel(Y, X, CfHp)
             }
             .self$q = ncol(Y)
             .self$m = nrow(X)
             .self$p = ncol(X)
             .self$n = nrow(basis)
             .self$Y = Y
             .self$X = X
             .self$CvFun = CvFun
             .self$CfHp = CfHp
             .self$lam = lam
             .self$A = A
             .self$basis = basis
         }
     )
)


the second takes an object of the first class in two of its fields. I 
load the first class and then the second with the 'source' command, but 
then I got this error which i don't understand:

Error in match(x, table, nomatch = 0L) :
   argument "type" is missing, with no default

I'm working with Ubuntu 12.04 and R 3.0.2.
Any suggestions about what is going wrong?
Thanks in advance,
Filippo


From roy.mendelssohn at noaa.gov  Tue Oct 22 20:34:44 2013
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 22 Oct 2013 11:34:44 -0700
Subject: [R] Hdf files Download
In-Reply-To: <001001cecf45$5f39a730$1dacf590$@gmail.com>
References: <001001cecf45$5f39a730$1dacf590$@gmail.com>
Message-ID: <D73E4CE5-B471-4D8D-BE52-A994D532A4E0@noaa.gov>

Your script didn't make it.  There are restrictions on the mail list for attached files.  You might try putting the script directly into the email.

-Roy

On Oct 22, 2013, at 9:40 AM, "Tereza Smejkalova" <terka424 at gmail.com> wrote:

> I am triing one more time since my first message was rejected by the filter:
> 
> 
> 
> Dear all, 
> I need to download and process large amounts of MODIS surface reflectance
> imagery. I have adapted a script written by T. Hengl (
> <http://www.spatial-analyst.net/wiki/?title=Download_and_resampling_of_MODIS
> _images>
> http://www.spatial-analyst.net/wiki/?title=Download_and_resampling_of_MODIS_
> images) for download from the new HTTP (since FTP is no longer available).
> The downloaded .HDF files however have no headers and it is impossible to
> work with them. If I download directly from the webpage everything is fine.
> Does anyone know what the problem might be, please? 
> 
> I am attaching my code
> 
> 
> 
> Please it is urgent. 
> 
> Thanks a lot.
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
1352 Lighthouse Avenue
Pacific Grove, CA 93950-2097

e-mail: Roy.Mendelssohn at noaa.gov (Note new e-mail address)
voice: (831)-648-9029
fax: (831)-648-8440
www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From smartpink111 at yahoo.com  Tue Oct 22 20:58:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 22 Oct 2013 11:58:58 -0700 (PDT)
Subject: [R] Replace NA values with previous valid value in array
Message-ID: <1382468338.46861.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,

c1 = (1,2,3,4,5,6,NA,7,8,NA,9,10,NA)
library(zoo)

na.locf(c1)
# [1]? 1? 2? 3? 4? 5? 6? 6? 7? 8? 8? 9 10 10

A.K.

Hi, I want to "fix" an array that contains several NA elements. And I 
would like to replace them with the previous valid element. 

So my array c = (1,2,3,4,5,6,NA,7,8,NA,9,10,NA) become cfixed= (1,2,3,4,5,6,6,7,8,8,9,10,10) 

(that's an example the actual array has thousands of elements) 

Thanks!


From smartpink111 at yahoo.com  Tue Oct 22 21:07:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 22 Oct 2013 12:07:25 -0700 (PDT)
Subject: [R] More Columns than column names Error
In-Reply-To: <1382449281.37719.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1382449281.37719.YahooMailNeo@web142605.mail.bf1.yahoo.com> 
Message-ID: <1382468845.78284.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

The "Garbage.txt" file you showed in the original post is slighly different (in spacing) from the one you are showing now.

lines1 <- readLines("Garbage.txt",warn=FALSE)

lines2 <- readLines("GarbageNew.txt",warn=FALSE) #saved the new as "GarbageNew.txt"

lines1
?[1] "Material\tWeight(Million Tons)\tPercent"
?[2] "Food Scraps\t25.9\t\t\t11.2"??????????? 
?[3] "Glass\t\t12.8\t\t\t5.5"???????????????? 
?[4] "Metals\t\t18.0\t\t\t7.8"??????????????? 
?[5] "Paper\t\t86.7\t\t\t37.4"??????????????? 
?[6] "Plastics\t24.7\t\t\t10.7"?????????????? 
?[7] "Textiles\t15.8\t\t\t6.8"??????????????? 
?[8] "Wood\t\t12.7\t\t\t5.5"????????????????? 
?[9] "Yard trimmings\t27.7\t\t\t11.9"???????? 
[10] "Other\t\t7.5\t\t\t3.2"????????????????? 
[11] "Total\t\t231.9\t\t\t100.0"????????????? 
?lines2
?[1] "Material\tWeight(Million Tons)\tPercent"
?[2] "Food Scraps\t25.9\t11.2"??????????????? 
?[3] "Glass\t12.8\t5.5"?????????????????????? 
?[4] "Metals\t18.0\t7.8"????????????????????? 
?[5] "Paper\t86.7\t37.4"????????????????????? 
?[6] "Plastics\t24.7\t10.7"?????????????????? 
?[7] "Textiles\t15.8\t6.8"??????????????????? 
?[8] "Wood\t12.7\t5.5"??????????????????????? 
?[9] "Yard trimmings\t27.7 11.9"?? #####here there are two delimiters "\t" and "space" ?????????? 
[10] "Other\t7.5\t3.2"??????????????????????? 
[11] "Total\t231.9\t100.0"????? 


Looks like you changed the tab spaces.
dat1 <- read.table(text=gsub("\t+","\t",lines1),stringsAsFactors=FALSE,sep="\t",check.names=FALSE,header=TRUE) #no errors

#able to reproduce the error mentioned

dat2 <- read.table(text=gsub("\t+","\t",lines2),stringsAsFactors=FALSE,sep="\t",check.names=FALSE,header=TRUE)
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,? : 
? line 8 did not have 3 elements

#Try this
?dat2 <- read.table(text=gsub("(.*\\d+) (\\d+)","\\1\t\\2",lines2),stringsAsFactors=FALSE,sep="\t",check.names=FALSE,header=TRUE)
?identical(dat1,dat2)
#[1] TRUE

jpeg("garbageweight.jpg",width=800)
?barplot(dat2[-10,2],names.arg=dat2[-10,1],ylab=colnames(dat2)[2],col=rainbow(9),main="American garbage")
?dev.off()


Attached is the pdf of the figure
A.K.



Garbage.txt

The error I get now is "Line 8 did not have 3 elements" 





On Tuesday, October 22, 2013 9:41 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
?lines1 <- readLines("Garbage.txt",warn=FALSE)
dat1 <- read.table(text=gsub("\t+","\t",lines1),stringsAsFactors=FALSE,sep="\t",check.names=FALSE,header=TRUE)
?str(dat1)
#'data.frame':??? 10 obs. of? 3 variables:
# $ Material??????????? : chr? "Food Scraps" "Glass" "Metals" "Paper" ...
# $ Weight(Million Tons): num? 25.9 12.8 18 86.7 24.7 ...
# $ Percent???????????? : num? 11.2 5.5 7.8 37.4 10.7 6.8 5.5 11.9 3.2 100
jpeg("garbageweight.jpg",width=800)
?barplot(dat1[-10,2],names.arg=dat1[-10,1],ylab=colnames(dat1)[2],col=rainbow(9),main="American garbage")
?dev.off()


A.K.


Hello guys, I'm having this weird problem with my assignment. I can't seem to import the data that I have created. 

I keep getting an error that says "Error: More Columns than Column names" 

This is my data file. 
Garbage.txt

Was also wondering if you guys could send me into the right direction on how to do this. 

1. Create a data frame with the data given above. 
2. Create the bar plot for weight variable with appropriate labels. Resize the graphics 
panel/ window so that all labels are visible. 
3. Add colors. Suppose n is the number of bars. 
> barplot(..., col = rainbow(n)) 
4. Save the plot to garbageweight.jpg 

This is how it's supposed to look like at the end.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: garbage.weight.pdf
Type: application/pdf
Size: 4688 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131022/67898a6f/attachment.pdf>

From dwinsemius at comcast.net  Tue Oct 22 21:43:00 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 22 Oct 2013 12:43:00 -0700
Subject: [R] Hdf files Download
In-Reply-To: <D73E4CE5-B471-4D8D-BE52-A994D532A4E0@noaa.gov>
References: <001001cecf45$5f39a730$1dacf590$@gmail.com>
	<D73E4CE5-B471-4D8D-BE52-A994D532A4E0@noaa.gov>
Message-ID: <634FFCBF-F132-4BEC-9013-943ADF3EAFBC@comcast.net>


On Oct 22, 2013, at 11:34 AM, Roy Mendelssohn - NOAA Federal wrote:

> Your script didn't make it.  There are restrictions on the mail list for attached files.  You might try putting the script directly into the email.

Thinking that the rejection might have be due to a Nabble posting I located it there and here include it. I'm hoping to use the method as well.

#----------------

# title         : MODIS_download_HTTP.R
# purpose       : Download of MODIS EVI images for the British Colombia;
# reference     : http://spatial-analyst.net/wiki/index.php?title=Download_and_resampling_of_MODIS_images
# producer      : Prepared by T. Hengl (addapted by T. Smejkalova)
# last update   : Southampton, UK, 18 October 2013.
# inputs        : Coordinates of the area of interest; proj4 parameters; ftp addresses etc.;
# outputs       : a series of EVI images (geoTIFF) projected in the local coordinate system;
# remarks 1     : To run this script, you need to obtain and install the MODIS resampling tool from [https://lpdaac.usgs.gov/lpdaac/tools/modis_reprojection_tool];
# remarks 2     : You should also obtain the WGET from [http://users.ugent.be/~bpuype/wget/]  --- simply copy the wget exe to windows system folder;
# remarks 3     : make sure you disable your antivirus tools such as Norton or McAfee otherwise it might block wget from running!

library(rgdal)
library(RCurl)
setInternet2(use = TRUE)
# Obtain the MODIS tool from: http://lpdaac.usgs.gov/landdaac/tools/modis/index.asp
# setwd("E:/PineBeetleBC/MODIS")
# location of the MODIS 1 km monthly blocks:
MOD09GQ <- "http://e4ftl01.cr.usgs.gov/MOLT/MOD09GQ.005/"
MOD09GQa <- "http://anonymous:test at e4ftl01.cr.usgs.gov/MOLT/MOD09GQ.005/"
product = "MOD09GQ"
year = 2000
# location of the mosaicing tool:
MRT <- 'D:\\MRT\\MRT_Win\\bin\\'
workd <- 'D:\\R_Modis\\'
setwd('D:\\R_Modis\\')
options(download.file.method="auto")

# get the list of directories (thanks to Barry Rowlingson):
items1 <- strsplit(getURL(MOD09GQ), "\n")[[1]]

# get the directory names and create a new data frame:
dates=data.frame(dirname=substr(items1[20:length(items1)],52,62))

# get the list of *.hdf files:
dates$BLOCK1 <- rep(NA, length(dates))
dates$BLOCK2 <- rep(NA, length(dates))
#dates$BLOCK3 <- rep(NA, length(dates))
#dates$BLOCK4 <- rep(NA, length(dates))

for (i in 1:1)#length(dates))# for each date per year
{
  getlist <- strsplit(getURL(paste(MOD09GQ, dates$dirname[i], sep="")), ">")[[1]]
  getlist=getlist[grep(product,getlist)]
  getlist=getlist[grep(".hdf<",getlist)]
  filenames=substr(getlist,1,nchar(getlist[1])-3)
  BLOCK1 <- filenames[grep(filenames,pattern="MOD09GQ.*.h18v02.*.hdf")[1]]
  BLOCK2 <- filenames[grep(filenames,pattern="MOD09GQ.*.h19v02.*.hdf")[1]]
  
  # write up the file names back to the dates.txt:
  for(j in 2:3){
    dates[i,j] <- get(paste("BLOCK", j-1, sep=""))
  }
  
  # Download all blocks from the list to a local drive:
  # while(!is.na(dates[i,2])&!is.na(dates[i,3])&!is.na(dates[i,4])&!is.na(dates[i,5])&!is.na(dates[i,6])&!is.na(dates[i,7])&!is.na(dates[i,8])&!is.na(dates[i,9])&!is.na(dates[i,10])){
  download.file(paste(MOD09GQa,  dates$dirname[i], dates$BLOCK1[i],sep=""),destfile=paste(getwd(), "/", BLOCK1, sep=""))
  download.file(paste(MOD09GQ,  dates$dirname[i], dates$BLOCK2[i],sep=""),destfile=paste(getwd(), "/", BLOCK2, sep=""), cacheOK=FALSE, )
  
  # remove "." from the file name:
  dirname1 <- sub(sub(pattern="\\.", replacement="_", dates$dirname[[i]]), pattern="\\.", replacement="_", dates$dirname[[i]])
  # mosaic the blocks:
  mosaicname = file(paste(MRT, "TmpMosaic.prm", sep=""), open="wt")
  write(paste(workd, BLOCK1, sep=""), mosaicname)
  write(paste(workd, BLOCK2, sep=""), mosaicname, append=T)
  #write(paste(workd, BLOCK3, sep=""), mosaicname, append=T)
  #write(paste(workd, BLOCK4, sep=""), mosaicname, append=T)
  close(mosaicname)

  # generate temporary mosaic:
  shell(cmd=paste(MRT, 'mrtmosaic -i ', MRT, 'TmpMosaic.prm -s "0 1 0 0 0 0 0 0 0 0 0" -o ', workd, 'TmpMosaic.hdf', sep=""))
  
  # resample to epsg=3005:
  filename = file(paste(MRT, "mrt", dirname1, ".prm", sep=""), open="wt")
  write(paste('INPUT_FILENAME = ', workd, 'TmpMosaic.hdf', sep=""), filename) 
  # write(paste('INPUT_FILENAMES = ( ', workd, BLOCK1, ' ', workd, BLOCK2, ' ', workd, BLOCK3, ' ', workd, BLOCK4, ' ', workd, BLOCK5, ' ', workd, BLOCK6, ' ', workd, BLOCK7, ' ', workd, BLOCK8, ' ', workd, BLOCK9, ' )', sep=""), filename)  # unfortunatelly does not work via command line  :(
  write('  ', filename, append=TRUE) 
  # write('SPECTRAL_SUBSET = ( 0 1 0 0 0 0 0 0 0 0 0 )', filename, append=TRUE)
  write('SPECTRAL_SUBSET = ( 1 )', filename, append=TRUE)
  write('  ', filename, append=TRUE)
  write('SPATIAL_SUBSET_TYPE = OUTPUT_PROJ_COORDS', filename, append=TRUE)
  write('  ', filename, append=TRUE)
  write('SPATIAL_SUBSET_UL_CORNER = ( 500000.0 -1800000.0 )', filename, append=TRUE)
  write('SPATIAL_SUBSET_LR_CORNER = ( 1600000.0 -2700000.0 )', filename, append=TRUE)
  write('  ', filename, append=TRUE)
  write(paste('OUTPUT_FILENAME = ', workd, 'tmp', dirname1, '.tif', sep=""), filename, append=TRUE)
  write('  ', filename, append=TRUE)
  write('RESAMPLING_TYPE = NEAREST_NEIGHBOR', filename, append=TRUE)
  write('  ', filename, append=TRUE)
  write('OUTPUT_PROJECTION_TYPE = PS', filename, append=TRUE)
  write('  ', filename, append=TRUE)
  write('OUTPUT_PROJECTION_PARAMETERS = ( ', filename, append=TRUE)
  write(' 6378137.0 6356752.314245179 0.0', filename, append=TRUE)
  write(' 0.0 0.0 71.0', filename, append=TRUE)
  write(' 0.0 0.0 0.0', filename, append=TRUE)
  write(' 0.0 0.0 0.0', filename, append=TRUE)
  write(' 0.0 0.0 0.0 )', filename, append=TRUE)
  write('  ', filename, append=TRUE)
  write('DATUM = WGS84', filename, append=TRUE)
  write('  ', filename, append=TRUE)
  write('OUTPUT_PIXEL_SIZE = 250', filename, append=TRUE)
  write('  ', filename, append=TRUE)
  close(filename)
  
  # Mosaic the images to get the whole area:
  shell(cmd=paste(MRT, 'resample -p ', MRT, 'mrt', dirname1, '.prm', sep=""))
  # delete all hdf files!
  unlink(paste(getwd(), '/', BLOCK1, sep=""))
  unlink(paste(getwd(), '/', BLOCK2, sep=""))
  #unlink(paste(getwd(), '/', BLOCK3, sep=""))
  #unlink(paste(getwd(), '/', BLOCK4, sep=""))
}
# end of script!

-- 
David.

> -Roy
> 
> On Oct 22, 2013, at 9:40 AM, "Tereza Smejkalova" <terka424 at gmail.com> wrote:
> 
>> I am triing one more time since my first message was rejected by the filter:
>> 
>> 
>> 
>> Dear all, 
>> I need to download and process large amounts of MODIS surface reflectance
>> imagery. I have adapted a script written by T. Hengl (
>> <http://www.spatial-analyst.net/wiki/?title=Download_and_resampling_of_MODIS
>> _images>
>> http://www.spatial-analyst.net/wiki/?title=Download_and_resampling_of_MODIS_
>> images) for download from the new HTTP (since FTP is no longer available).
>> The downloaded .HDF files however have no headers and it is impossible to
>> work with them. If I download directly from the webpage everything is fine.
>> Does anyone know what the problem might be, please? 
>> 
>> I am attaching my code
>> 
>> 
>> Please it is urgent. 

It only delays response if you don't "read the directions" for your toys that "may require assembly".

-- 
David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Tue Oct 22 21:49:03 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 22 Oct 2013 15:49:03 -0400
Subject: [R] Graphing complex functions
In-Reply-To: <CAEorq2N5Td92mU=8D+73mkmg_Jp5HCD+0dXkfNSwtjC8CNGx0Q@mail.gmail.com>
References: <CAEorq2N5Td92mU=8D+73mkmg_Jp5HCD+0dXkfNSwtjC8CNGx0Q@mail.gmail.com>
Message-ID: <5266D6AF.7030502@gmail.com>

On 22/10/2013 1:07 PM, John Van Praag wrote:
> Does R have any facilities, or packages, for graphing complex functions?

I don't think base R does, but if you have a complex-valued function of 
a real variable, it wouldn't be hard to write one.
For your example:

library(rgl)
xvals <- seq(0, 2*pi, len=256)
f <- function(x) cos(x) + 1i * sin(x)
zvals <- f(xvals)
plot3d(xvals, Re(zvals), Im(zvals), type="l")

For the case of a real-valued function of a complex variable, you could 
use persp() or persp3d().  For both argument and value being complex, 
you'll need 4 dimensions, and that's hard to do nicely, though I suppose 
you could overlay contour or perspective plots of the real and imaginary 
parts of the value.  For example:

x <- y <- seq(0, 2*pi, len=50)
z <- outer(x, y, function(x,y) x + 1i*y)
zvals <- f(z)
persp3d(x, y, Re(zvals), col="red", alpha=0.5, xlab="Re(z)", 
ylab="Im(z)", zlab="f(z)")
surface3d(x, y, Im(zvals), col="blue", alpha=0.5)

Duncan Murdoch

>
> I find that 'curve' does not do the trick. Example:
>
> > f = function(x) cos(x) + 1i * sin(x)
> > curve(f, -pi, pi)
> Error in xy.coords(x, y, xlabel, ylabel, log) :
>    (converted from warning) imaginary parts discarded in coercion
>
> Enter a frame number, or 0 to exit
>
> 1: curve(f, -pi, pi)
> 2: plot(x = x, y = y, type = type, xlab = xlab, ylab = ylab, xlim = xlim,
> log = lg, ...)
> 3: plot.default(x = x, y = y, type = type, xlab = xlab, ylab = ylab, xlim =
> xlim, log = lg, ...)
> 4: xy.coords(x, y, xlabel, ylabel, log)
> 5: .signalSimpleWarning("imaginary parts discarded in coercion",
> quote(xy.coords(x, y, xlabel, ylabel, log)))
> 6: withRestarts({
>      .Internal(.signalCondition(simpleWarning(msg, call), msg, call))
>      .Internal(.dfltWarn(msg, call))
> }, muffleWarning = function() NULL)
> 7: withOneRestart(expr, restarts[[1]])
> 8: doWithOneRestart(return(expr), restart)
> 9: (function ()
> {
>      error()
>      utils::recover()
> })()
>
> Selection:
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Tue Oct 22 21:49:30 2013
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 22 Oct 2013 13:49:30 -0600
Subject: [R] How to draw figures in a graph?
In-Reply-To: <20131022144358.M19935@sust.edu>
References: <0765308CD028654885F30322557308D80E1DF378@NYCSM0208.rth.ad.rothschild.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A409@GOLD.corp.lgc-group.com>
	<CABdHhvFOYv-0A5W5M+-f3EyB_yvKiEeKTWnjf-7N75znn90+YA@mail.gmail.com>
	<20131022144358.M19935@sust.edu>
Message-ID: <CAFEqCdwL1CsNVLEKb6eOf4CJh5xw+E9STSJS8b+B150iEmdEPQ@mail.gmail.com>

You will want to be very careful in adding things to a plot that are
not conveying information.  One term for these things is "chartjunk"
which should give you a feel for the general opinion about doing this.

If you still feel the need to add to a graph (and promise to think
hard about it and be careful in the implementation that the added
figures do not distort the data) then you can start by looking at the
rasterImage function (and grid.raster for grid based graphics).  The
grImport package could also be useful if your images are in a vector
format, see the import vignette from that package.  Possibly also the
my.symbols function in the TeachingDemos package.

On Tue, Oct 22, 2013 at 9:08 AM, halim10-fes <halim10-fes at sust.edu> wrote:
> Hi All,
>
> Hope you guys are doing well. I am thinking of drawing some figures within a
> graph to make it more interesting. To make a graph more storytelling, like the
> attached one.
>
> I am looking for a couple of days but couldn't come up with any solution on how
> to do it with R. Any ideas will be greatly appreciated.
>
> Thanks,
>
> ---------------
> Md. Abdul Halim
> Assistant Professor
> Department of Forestry and Environmental Science
> Shahjalal University of Science and Technology,Sylhet-3114,
> Bangladesh.
> Cell: +8801714078386.
> alt. e-mail: xou03 at yahoo.com
>
> --
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From hwborchers at googlemail.com  Tue Oct 22 23:03:29 2013
From: hwborchers at googlemail.com (Hans W Borchers)
Date: Tue, 22 Oct 2013 21:03:29 +0000
Subject: [R] Graphing complex functions
References: <CAEorq2N5Td92mU=8D+73mkmg_Jp5HCD+0dXkfNSwtjC8CNGx0Q@mail.gmail.com>
Message-ID: <loom.20131022T230051-222@post.gmane.org>

John Van Praag <john <at> jvp247.com> writes:
> 
> Does R have any facilities, or packages, for graphing complex functions?

Package 'elliptic' has function view() for

    "Visualization of complex functions using colourmaps and contours"

Hans Werner


From smartpink111 at yahoo.com  Wed Oct 23 00:57:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 22 Oct 2013 15:57:43 -0700 (PDT)
Subject: [R] Help with loop ;(
Message-ID: <1382482663.19581.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi, 

The conditions are not very clear. For example, it is not mentioned whether vectors are of same length or not.? Assuming the former case:
fun1 <- function(x,y){
?if(length(x)==length(y) & length(x)%%2==0){
?res <- x+y
?}
?else if(length(x)==length(y) & length(x)%%2==1){
?res <- abs(x-y)
}
else print("Lengths are not same")
res
}
?vec1 <- 1:10
?vec2 <- 11:20
?vec3 <- 1:9
?vec4 <- 10:18
?fun1(vec3,vec4)
?fun1(vec1,vec2)
fun1(vec1,vec3)

A.K.





Hi, I'm new on this forum, and I need some help with for loop. I have to write loop that will add two vectors, if they are even. Even if they 
are odd, it must subtract the two vectors.


From paul.bivand at gmail.com  Wed Oct 23 01:02:48 2013
From: paul.bivand at gmail.com (Paul Bivand)
Date: Wed, 23 Oct 2013 00:02:48 +0100
Subject: [R] 'XML' package cannot be un-zipped or un-tar'd"
In-Reply-To: <66C71547284587479F8009E05C07DA9704F8A095@USTLMLLYC107.RF.lilly.com>
References: <66C71547284587479F8009E05C07DA9704F6FF71@USTLMLLYC107.RF.lilly.com>
	<524B2F20.70600@xtra.co.nz>
	<66C71547284587479F8009E05C07DA9704F8A095@USTLMLLYC107.RF.lilly.com>
Message-ID: <CAC=KSNjQT=_Go6XUxTfvnArhQ_mzjXwZq=jchtOsKXMCaRm-Og@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/b771c714/attachment.pl>

From aljehani-k at hotmail.com  Wed Oct 23 00:55:39 2013
From: aljehani-k at hotmail.com (Ms khulood aljehani)
Date: Wed, 23 Oct 2013 01:55:39 +0300
Subject: [R] warning messages
Message-ID: <DUB122-W4710B84C16178FC44445B585020@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/1d7217b2/attachment.pl>

From hill0093 at umn.edu  Tue Oct 22 23:50:35 2013
From: hill0093 at umn.edu (Hurr)
Date: Tue, 22 Oct 2013 14:50:35 -0700 (PDT)
Subject: [R] How do I use simple calls to java methods?
In-Reply-To: <1382401907888-4678753.post@n4.nabble.com>
References: <1382401907888-4678753.post@n4.nabble.com>
Message-ID: <1382478635689-4678834.post@n4.nabble.com>

Thanks so much for the reply.
I did the search for "rJava examples" and found the Scott 
Hoover instructions which seemed like exactly what I needed.
I compiled the java code and copied myExchange.java and 
myExchange.class to the directory where I started R where 
I did and the calls suggested inside worked.
But there are no parameters passed in the examples.
I need to do something like this:
dateStg <- "201310221439591234"
dateStg
doubleLin <- .jcall(CalqsLin, "D", "linTimOfCalqsStgIsLev",dateStg,-4)
or
doubleLin <- .jcall(CalqsLin, "D",
"linTimOfCalqsStgIsLev","201310221439591234",-4)
where the latter two parameters are passed to linTimOfCalqsStgIsLev.
Neither way works and I cannot understand the .jcall() instructions in
rJava.pdf well enough.
I'll keep trying, but would like help.




--
View this message in context: http://r.789695.n4.nabble.com/How-do-I-use-simple-calls-to-java-methods-tp4678753p4678834.html
Sent from the R help mailing list archive at Nabble.com.


From marc_grt at yahoo.fr  Wed Oct 23 05:03:57 2013
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 23 Oct 2013 05:03:57 +0200
Subject: [R] Depends and Imports in DESCRIPTION file
Message-ID: <52673C9D.3000201@yahoo.fr>

Dear list members:

I try to check my updated package to include a new version in CRAN 
(phenology) but a new error is indicated and I don't find the logic.
First my system:
* using R version 3.0.2 Patched (2013-09-27 r64011)
* using platform: x86_64-apple-darwin10.8.0 (64-bit)

Here is the message:

* checking dependencies in R code ... NOTE
Packages in Depends field not imported from:
?fields? ?zoo?
These packages needs to imported from for the case when
this namespace is loaded but not attached.
See the information on DESCRIPTION files in the chapter ?Creating R
packages? of the ?Writing R Extensions? manual.

It is based on this line in DESCRIPTION file:
Depends: fields, zoo, coda, R (>= 2.14.0)

I use indeed functions from fields and zoo packages.

If I create a new line:
Imports: fields, zoo
and remove these two packages from depends, I have still a problem in 
Imports and errors because functions from fields and zoo are not available.
* checking dependencies in R code ... NOTE
Namespaces in Imports field not imported from:
?fields? ?zoo?
All declared Imports should be used.
See the information on DESCRIPTION files in the chapter ?Creating R
packages? of the ?Writing R Extensions? manual.
* checking R code for possible problems ... NOTE
.read_phenology: no visible global function definition for ?na.locf?
plot.phenologymap: no visible global function definition for
?image.plot?


If I add the packages fields, zoo packages in both Depends and Imports, 
I have also error because packages fields, zoo are indicated twice and I 
have the same errors as previously indicated.
* checking DESCRIPTION meta-information ... NOTE
Packages listed in more than one of Depends, Imports, Suggests, Enhances:
?fields? ?zoo?
A package should be listed in only one of these fields.

Of course I read ?Creating R packages? of the ?Writing R Extensions? 
manual, but I can't find solution to this problem.

Thanks a lot,

Marc Girondot

-- 
__________________________________________________________
Marc Girondot, Pr

Laboratoire Ecologie, Syst?matique et Evolution
Equipe de Conservation des Populations et des Communaut?s
CNRS, AgroParisTech et Universit? Paris-Sud 11 , UMR 8079
B?timent 362
91405 Orsay Cedex, France

Tel:  33 1 (0)1.69.15.72.30   Fax: 33 1 (0)1.69.15.73.53
e-mail: marc.girondot at u-psud.fr
Web: http://www.ese.u-psud.fr/epc/conservation/Marc.html
Skype: girondot


From vksingh.iiitb at gmail.com  Wed Oct 23 05:35:11 2013
From: vksingh.iiitb at gmail.com (Vivek Singh)
Date: Wed, 23 Oct 2013 11:35:11 +0800
Subject: [R] cbind() function : Not able to display columns
Message-ID: <CAFgDSD4kLipsMns7Z5Si0TDXfG0SjcE7Wz4x4fU59i=hj8LGNg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/db0d0dfc/attachment.pl>

From hill0093 at umn.edu  Wed Oct 23 05:28:20 2013
From: hill0093 at umn.edu (Hurr)
Date: Tue, 22 Oct 2013 20:28:20 -0700 (PDT)
Subject: [R] How do I use simple calls to java methods?
In-Reply-To: <1382478635689-4678834.post@n4.nabble.com>
References: <1382401907888-4678753.post@n4.nabble.com>
	<1382478635689-4678834.post@n4.nabble.com>
Message-ID: <1382498900429-4678844.post@n4.nabble.com>

What I was missing was that I had to put as.integer(-4) to make it an
integer.




--
View this message in context: http://r.789695.n4.nabble.com/How-do-I-use-simple-calls-to-java-methods-tp4678753p4678844.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Wed Oct 23 05:57:50 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 22 Oct 2013 20:57:50 -0700 (PDT)
Subject: [R] cbind() function : Not able to display columns
In-Reply-To: <CAFgDSD4kLipsMns7Z5Si0TDXfG0SjcE7Wz4x4fU59i=hj8LGNg@mail.gmail.com>
References: <CAFgDSD4kLipsMns7Z5Si0TDXfG0SjcE7Wz4x4fU59i=hj8LGNg@mail.gmail.com>
Message-ID: <1382500670.83690.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

Try:

? k[,"a"]
#[1] "1" "2" "3"
?k[,"b"]
#[1] "a" "b" "c"
?k[,"c"]
#[1] "ee" "tt" "rr"
A.K.






On Tuesday, October 22, 2013 11:37 PM, Vivek Singh <vksingh.iiitb at gmail.com> wrote:
Hi All,


I have create a matrix using cbind() function as follows:


> a=c(1,2,3)

> b=c('a','b','c')

> c=c("ee","tt","rr")


> k=cbind(a,b,c)


Problem: when we print the matrix k,

> k

? ? a?? b?? c

[1,] "1" "a" "ee"

[2,] "2" "b" "tt"

[3,] "3" "c" "rr"

we can see that rows are represented by [1,] , [2,] and [3,]. Similarly,
the columns are denoted by [a], [b] and [c]. When we try to print the
corresponding columns, we are able to print for k[a], i.e., the first
column but not able to correctly print the second and third columns.

> k[a]

[1] "1" "2" "3"

> k[b]

[1] NA NA NA

> k[c]

[1] NA NA NA

Please let me know what am I doing wrong.

-- 
Thanks and Regards,

Vivek Kumar Singh

Research Assistant,
School of Computing,
National University of Singapore
Mobile:(0065) 82721535

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jdnewmil at dcn.davis.CA.us  Wed Oct 23 06:01:50 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 22 Oct 2013 21:01:50 -0700
Subject: [R] cbind() function : Not able to display columns
In-Reply-To: <CAFgDSD4kLipsMns7Z5Si0TDXfG0SjcE7Wz4x4fU59i=hj8LGNg@mail.gmail.com>
References: <CAFgDSD4kLipsMns7Z5Si0TDXfG0SjcE7Wz4x4fU59i=hj8LGNg@mail.gmail.com>
Message-ID: <516d08fa-ef43-4a88-ac6a-58d32aa99df9@email.android.com>

Hard to say, not sure what you want to do. But the columns are not denoted by [a], [b] or [c]. You should learn to use the str function to understand what various expressions really are, and return to the "Introduction to R" document that comes with the software. There is a distinct difference between a and "a" in R, and square brackets are not at all like quotes. See help("[") and the ItoR section on indexing.

You might get what you want by k[,"b"] for example.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Vivek Singh <vksingh.iiitb at gmail.com> wrote:
>Hi All,
>
>
>I have create a matrix using cbind() function as follows:
>
>
>> a=c(1,2,3)
>
>> b=c('a','b','c')
>
>> c=c("ee","tt","rr")
>
>
>> k=cbind(a,b,c)
>
>
>Problem: when we print the matrix k,
>
>> k
>
>    a   b   c
>
>[1,] "1" "a" "ee"
>
>[2,] "2" "b" "tt"
>
>[3,] "3" "c" "rr"
>
>we can see that rows are represented by [1,] , [2,] and [3,].
>Similarly,
>the columns are denoted by [a], [b] and [c]. When we try to print the
>corresponding columns, we are able to print for k[a], i.e., the first
>column but not able to correctly print the second and third columns.
>
>> k[a]
>
>[1] "1" "2" "3"
>
>> k[b]
>
>[1] NA NA NA
>
>> k[c]
>
>[1] NA NA NA
>
>Please let me know what am I doing wrong.


From jdnewmil at dcn.davis.CA.us  Wed Oct 23 06:23:26 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 22 Oct 2013 21:23:26 -0700
Subject: [R] How do I use simple calls to java methods?
In-Reply-To: <1382498900429-4678844.post@n4.nabble.com>
References: <1382401907888-4678753.post@n4.nabble.com>
	<1382478635689-4678834.post@n4.nabble.com>
	<1382498900429-4678844.post@n4.nabble.com>
Message-ID: <75039ef4-1aee-4474-a14d-80b078fc47e4@email.android.com>

Or use the literal form 4L.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Hurr <hill0093 at umn.edu> wrote:
>What I was missing was that I had to put as.integer(-4) to make it an
>integer.
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/How-do-I-use-simple-calls-to-java-methods-tp4678753p4678844.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Wed Oct 23 06:23:54 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 23 Oct 2013 00:23:54 -0400
Subject: [R] cbind() function : Not able to display columns
In-Reply-To: <516d08fa-ef43-4a88-ac6a-58d32aa99df9@email.android.com>
References: <CAFgDSD4kLipsMns7Z5Si0TDXfG0SjcE7Wz4x4fU59i=hj8LGNg@mail.gmail.com>
	<516d08fa-ef43-4a88-ac6a-58d32aa99df9@email.android.com>
Message-ID: <CAGx1TMDy4JxPucM4ouRWVRcAuhDq+FCQjUukMFJ=SyLAoDozGA@mail.gmail.com>

In addition to what the others have told you, it looks like you might
be confusing
matrices with data.frames.  Please see
?data.frame

I think what you are looking for is

> b <- c('a','b','c')
> c <- c("ee","tt","rr")
> k <- cbind(a,b,c)
> K <- data.frame(a, b, c)
> K
  a b  c
1 1 a ee
2 2 b tt
3 3 c rr

I recommend using " <- " for assignment (not the spaces on both sides), not "=".

On Wed, Oct 23, 2013 at 12:01 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Hard to say, not sure what you want to do. But the columns are not denoted by [a], [b] or [c]. You should learn to use the str function to understand what various expressions really are, and return to the "Introduction to R" document that comes with the software. There is a distinct difference between a and "a" in R, and square brackets are not at all like quotes. See help("[") and the ItoR section on indexing.
>
> You might get what you want by k[,"b"] for example.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> Vivek Singh <vksingh.iiitb at gmail.com> wrote:
>>Hi All,
>>
>>
>>I have create a matrix using cbind() function as follows:
>>
>>
>>> a=c(1,2,3)
>>
>>> b=c('a','b','c')
>>
>>> c=c("ee","tt","rr")
>>
>>
>>> k=cbind(a,b,c)
>>
>>
>>Problem: when we print the matrix k,
>>
>>> k
>>
>>    a   b   c
>>
>>[1,] "1" "a" "ee"
>>
>>[2,] "2" "b" "tt"
>>
>>[3,] "3" "c" "rr"
>>
>>we can see that rows are represented by [1,] , [2,] and [3,].
>>Similarly,
>>the columns are denoted by [a], [b] and [c]. When we try to print the
>>corresponding columns, we are able to print for k[a], i.e., the first
>>column but not able to correctly print the second and third columns.
>>
>>> k[a]
>>
>>[1] "1" "2" "3"
>>
>>> k[b]
>>
>>[1] NA NA NA
>>
>>> k[c]
>>
>>[1] NA NA NA
>>
>>Please let me know what am I doing wrong.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_grt at yahoo.fr  Wed Oct 23 06:34:21 2013
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 23 Oct 2013 06:34:21 +0200
Subject: [R] Depends and Imports in DESCRIPTION file
In-Reply-To: <52673C9D.3000201@yahoo.fr>
References: <52673C9D.3000201@yahoo.fr>
Message-ID: <526751CD.2090900@yahoo.fr>

Le 23/10/13 05:03, Marc Girondot a ?crit :
> Dear list members:
>
> I try to check my updated package to include a new version in CRAN 
> (phenology) but a new error is indicated and I don't find the logic.
> First my system:
> * using R version 3.0.2 Patched (2013-09-27 r64011)
> * using platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> Here is the message:
>
> * checking dependencies in R code ... NOTE
> Packages in Depends field not imported from:
> ?fields? ?zoo?
> These packages needs to imported from for the case when
> this namespace is loaded but not attached.
> See the information on DESCRIPTION files in the chapter ?Creating R
> packages? of the ?Writing R Extensions? manual.
>
I begin to find the origin of the problem... but not still the solution.
When the NAMESPACE file is created by package.skeleton(), it includes:
import(coda)
but not
import(fields)
import(zoo)

If I add these manually, the check is ok.

Now the question becomes: why package.skeleton() does not add them and 
how to force package.skeleton() to add them ?

Sincerely,

Marc Girondot



-- 
__________________________________________________________
Marc Girondot, Pr

Laboratoire Ecologie, Syst?matique et Evolution
Equipe de Conservation des Populations et des Communaut?s
CNRS, AgroParisTech et Universit? Paris-Sud 11 , UMR 8079
B?timent 362
91405 Orsay Cedex, France

Tel:  33 1 (0)1.69.15.72.30   Fax: 33 1 (0)1.69.15.73.53
e-mail: marc.girondot at u-psud.fr
Web: http://www.ese.u-psud.fr/epc/conservation/Marc.html
Skype: girondot


From hb at biostat.ucsf.edu  Wed Oct 23 07:48:57 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 22 Oct 2013 22:48:57 -0700
Subject: [R] Depends and Imports in DESCRIPTION file
In-Reply-To: <52673C9D.3000201@yahoo.fr>
References: <52673C9D.3000201@yahoo.fr>
Message-ID: <CAFDcVCQhMQ66=N65m9Yr8BQEvLk9P33fA-Hcd8XcwraJmzrcFA@mail.gmail.com>

On Tue, Oct 22, 2013 at 8:03 PM, Marc Girondot <marc_grt at yahoo.fr> wrote:
> Dear list members:
>
> I try to check my updated package to include a new version in CRAN
> (phenology) but a new error is indicated and I don't find the logic.
> First my system:
> * using R version 3.0.2 Patched (2013-09-27 r64011)
> * using platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> Here is the message:
>
> * checking dependencies in R code ... NOTE
> Packages in Depends field not imported from:
> ?fields? ?zoo?
> These packages needs to imported from for the case when
> this namespace is loaded but not attached.
> See the information on DESCRIPTION files in the chapter ?Creating R
> packages? of the ?Writing R Extensions? manual.

Just as packages under 'Imports:' in your DESCRIPTION file need to
have corresponding import()/importFrom() statements in the NAMESPACE
file, so do packages under 'Depends:'.  That is what this 'R CMD
check' NOTE is trying to say.  If you don't do this, those package's
functions/variables will only be available if you *attach* your
package, but not if you only *load* it.  That's also what the NOTE
tries to say.

When you do library()/require(), you *attach* a package and it appear
in the search() path and all functions/variables in the search() path
will be found by the user and from all packages attached/loaded.

When a package is *loaded* - explicitly via
loadNamespace()/requireNamespace(), but more commonly via Imports:
statements in DESCRIPTION, it is *not* attached to the search() path
and therefore none of its functions/variables are found.  Such
functions/variables are only found if they are explicitly imported via
import()/importFrom() in the NAMESPACE file.

Most people will *attach* your package, i.e. library("YourPackage"),
and currently the functions/variables of the packages under "Depends:"
will be on the search() and therefore found by the functions of your
package.  To see what packages are attached (=on the search() path)
and which are only loaded, look as sessionInfo().

So far so, good.  However, if someone else decides to use one of your
package's functions in their package and put it under 'Imports:", e.g.

Package: AnotherPackage
Depends: SomePackage
Imports: YourPackage  <= your package

you will be in trouble.  Because, library("AnotherPackage") will
*attach* AnotherPackage and SomePackage to the search() path and
*load* YourPackage.  In turn, you have specified in your DESCRIPTION
will *load* all packages under its "Imports:" as well as "Depends:".
However, since your NAMESPACE file does not import()/importFrom() any
of the packages under "Depends:", none of those functions will be
found.  Your functions will give errors like 'could not find function
"foo".

Basically, "Depends:" could be though of as "AttachOrLoad:" and
"Imports:" as "LoadOnly:".

To learn more about how all this works and why/why not, I strongly
recommend Suraj Gupta's nice write up 'How R Searches and Finds Stuff'
(Mar 2012):  http://obeautifulcode.com/R/How-R-Searches-And-Finds-Stuff/

/Henrik

>
> It is based on this line in DESCRIPTION file:
> Depends: fields, zoo, coda, R (>= 2.14.0)
>
> I use indeed functions from fields and zoo packages.
>
> If I create a new line:
> Imports: fields, zoo
> and remove these two packages from depends, I have still a problem in
> Imports and errors because functions from fields and zoo are not available.
> * checking dependencies in R code ... NOTE
> Namespaces in Imports field not imported from:
> ?fields? ?zoo?
> All declared Imports should be used.
> See the information on DESCRIPTION files in the chapter ?Creating R
> packages? of the ?Writing R Extensions? manual.
> * checking R code for possible problems ... NOTE
> .read_phenology: no visible global function definition for ?na.locf?
> plot.phenologymap: no visible global function definition for
> ?image.plot?
>
>
> If I add the packages fields, zoo packages in both Depends and Imports, I
> have also error because packages fields, zoo are indicated twice and I have
> the same errors as previously indicated.
> * checking DESCRIPTION meta-information ... NOTE
> Packages listed in more than one of Depends, Imports, Suggests, Enhances:
> ?fields? ?zoo?
> A package should be listed in only one of these fields.
>
> Of course I read ?Creating R packages? of the ?Writing R Extensions? manual,
> but I can't find solution to this problem.
>
> Thanks a lot,
>
> Marc Girondot
>
> --
> __________________________________________________________
> Marc Girondot, Pr
>
> Laboratoire Ecologie, Syst?matique et Evolution
> Equipe de Conservation des Populations et des Communaut?s
> CNRS, AgroParisTech et Universit? Paris-Sud 11 , UMR 8079
> B?timent 362
> 91405 Orsay Cedex, France
>
> Tel:  33 1 (0)1.69.15.72.30   Fax: 33 1 (0)1.69.15.73.53
> e-mail: marc.girondot at u-psud.fr
> Web: http://www.ese.u-psud.fr/epc/conservation/Marc.html
> Skype: girondot
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pmaclean2011 at yahoo.com  Wed Oct 23 11:05:10 2013
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Wed, 23 Oct 2013 02:05:10 -0700 (PDT)
Subject: [R] Geocode Conversion
Message-ID: <1382519110.7159.YahooMailNeo@web121706.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/a7dae44a/attachment.pl>

From jim at bitwrit.com.au  Wed Oct 23 11:27:16 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 23 Oct 2013 20:27:16 +1100
Subject: [R] Geocode Conversion
In-Reply-To: <1382519110.7159.YahooMailNeo@web121706.mail.ne1.yahoo.com>
References: <1382519110.7159.YahooMailNeo@web121706.mail.ne1.yahoo.com>
Message-ID: <52679674.6030109@bitwrit.com.au>

On 10/23/2013 08:05 PM, Peter Maclean wrote:
> I have this kind od?  data
> x<- read.table(text="
> ?  Log? ? ? ?  lat
> 3025.264 901.331
> 3039.237 810.811
> 3137.760 806.040
> 3141.190 806.557
> 3141.229 806.622
> 3138.891 806.281",
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  header=TRUE,
> stringsAsFactors=FALSE)
> I what to insert ???:??? after every first
> two numbers in Lon variable and after
> every first number in lat variable.
> The variables should end with ???E????  for
> Lon and ???S??? for the Lon variable. ? The
> results should look like:
> Lon? ? ?  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Lat
> 30:25:264E? ? ? ? ?  ?  9:01:331S
> 30:39:237E? ? ? ? ?  ?  8:10:811S
> 31:37:760E? ? ? ? ? ?  ? 8:06:040S
> 31:41:190E? ? ? ? ?  ?  8:06:557S
> 31:41:229E? ? ? ? ?  ?  8:06:622S
> 31:38:891E? ? ?  ? ? ?  8:06:281S
> I am using gmt package for
> geocodes conversion.

Hi Peter,
Kind of messy, but:

insert.colons.lon<-function(x) {
  newx<-paste(x[1],x[2],":",x[3],x[4],":",x[6],sep="")
  if(length(x) > 6) newx<-paste(newx,x[7],sep="")
  if(length(x) > 7) newx<-paste(newx,x[8],sep="")
  newx<-paste(newx,"E",sep="")
  return(newx)
}

insert.colons.lat<-function(x) {
  newx<-paste(x[1],":",x[2],x[3],":",x[5],sep="")
  if(length(x) > 5) newx<-paste(newx,x[6],sep="")
  if(length(x) > 6) newx<-paste(newx,x[7],sep="")
  newx<-paste(newx,"S",sep="")
  return(newx)
}

x$lon<-unlist(sapply(strsplit(as.character(x$lon),insert.colons.lon)))
x$lat<-unlist(sapply(strsplit(as.character(x$lat),insert.colons.lat)))

Jim


From murdoch.duncan at gmail.com  Wed Oct 23 11:48:00 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 23 Oct 2013 05:48:00 -0400
Subject: [R] Depends and Imports in DESCRIPTION file
In-Reply-To: <526751CD.2090900@yahoo.fr>
References: <52673C9D.3000201@yahoo.fr> <526751CD.2090900@yahoo.fr>
Message-ID: <52679B50.8030007@gmail.com>

On 13-10-23 12:34 AM, Marc Girondot wrote:
> Le 23/10/13 05:03, Marc Girondot a ?crit :
>> Dear list members:
>>
>> I try to check my updated package to include a new version in CRAN
>> (phenology) but a new error is indicated and I don't find the logic.
>> First my system:
>> * using R version 3.0.2 Patched (2013-09-27 r64011)
>> * using platform: x86_64-apple-darwin10.8.0 (64-bit)
>>
>> Here is the message:
>>
>> * checking dependencies in R code ... NOTE
>> Packages in Depends field not imported from:
>> ?fields? ?zoo?
>> These packages needs to imported from for the case when
>> this namespace is loaded but not attached.
>> See the information on DESCRIPTION files in the chapter ?Creating R
>> packages? of the ?Writing R Extensions? manual.
>>
> I begin to find the origin of the problem... but not still the solution.
> When the NAMESPACE file is created by package.skeleton(), it includes:
> import(coda)
> but not
> import(fields)
> import(zoo)
>
> If I add these manually, the check is ok.
>
> Now the question becomes: why package.skeleton() does not add them and
> how to force package.skeleton() to add them ?

You should only use package.skeleton once, when you first decide to turn 
your code into a package.  After that, the assumption is that you will 
manually edit the files.

If you call it later, it will not make use of all the work you did on 
the previous attempt.

However, looking at the source, I don't see it ever writing import() 
lines to the namespace.  I think you must be mistaken about what it is 
doing.

Duncan Murdoch


From smartpink111 at yahoo.com  Wed Oct 23 14:32:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 23 Oct 2013 05:32:52 -0700 (PDT)
Subject: [R] Geocode Conversion
In-Reply-To: <1382519110.7159.YahooMailNeo@web121706.mail.ne1.yahoo.com>
References: <1382519110.7159.YahooMailNeo@web121706.mail.ne1.yahoo.com>
Message-ID: <1382531572.4807.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:

x$Log <-? gsub("^(\\d{2})(\\d{2})\\.(\\d{3})","\\1:\\2:\\3E",sprintf("%.3f",x$Log))
x$lat <- gsub("^(\\d{1})(\\d{2})\\.(\\d{3})","\\1:\\2:\\3S",sprintf("%.3f",x$lat))
?x
#???????? Log?????? lat
#1 30:25:264E 9:01:331S
#2 30:39:237E 8:10:811S
#3 31:37:760E 8:06:040S
#4 31:41:190E 8:06:557S
#5 31:41:229E 8:06:622S
#6 31:38:891E 8:06:281S

A.K.


On Wednesday, October 23, 2013 5:07 AM, Peter Maclean <pmaclean2011 at yahoo.com> wrote:
I have this kind od? data
x <- read.table(text="
? Log???? lat
3025.264 901.331
3039.237 810.811
3137.760 806.040
3141.190 806.557
3141.229 806.622
3138.891 806.281",
??????????????? header=TRUE,
stringsAsFactors=FALSE)
I what to insert ?:? after every first
two numbers in Lon variable and after 
every first number in lat variable.
The variables should end with ?E?? for
Lon and ?S? for the Lon variable. ?The
results should look like:
Lon??? ??????????????????Lat
30:25:264E????? ? 9:01:331S
30:39:237E????? ? 8:10:811S
31:37:760E?????? ?8:06:040S
31:41:190E????? ? 8:06:557S
31:41:229E????? ? 8:06:622S
31:38:891E??? ??? 8:06:281S 
I am using gmt package for
geocodes conversion.
I will appreciate any help.

Peter Maclean
Department of Economics
UDSM
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Wed Oct 23 14:36:44 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 23 Oct 2013 05:36:44 -0700 (PDT)
Subject: [R] Help parsing from .txt
In-Reply-To: <1382503847.4061.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1382503847.4061.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1382531804.22289.YahooMailNeo@web142601.mail.bf1.yahoo.com>





Hi,
You may try:
?list.files()
nm1 <- list.files(pattern=".txt")

res <- lapply(nm1,function(x) {
??? ??? ??? ??? ??? ??? ??? ??? ln1 <- readLines(x)
???????????????????????????????? indx1 <- grep("DATE PROCESSED",ln1)
???????????????????????????????? indx2 <- grep("[A-Z]",ln1)
???????????????????????????????? ln2 <- if(max(indx2)==indx1) ln1[1:length(ln1)] else ln1[1:(indx2[match(indx1,indx2)+1]-1)]
???????????????????????????????? ln2 <- ln2[ln2!=""]
???????????????????????????????? indx3 <- grepl("[A-Z]",ln2)
???????????????????????????????? indx4 <- cumsum(c(TRUE,diff(which(!indx3))>1))
??? ??? ??? ??? ??? ??? ??? ??? mat1 <- do.call(cbind, split(ln2[!indx3],indx4))
???????????????????????????????? colnames(mat1) <-? ln2[indx3][-1]
???????????????????????????????? write.table(mat1,paste0(ln2[indx3][1],".txt"),row.names=FALSE,quote=FALSE,sep="\t")})



A.K.


I have a number of .txt files (1,200) from which I need to parse a 
number of pieces of information. ?The files are read into R as such: 

TITLE 
EXAMPLE 
example 1 
example 2 
RELATED TITLE 
related title 1 
DATE PROCESSED 
06/12/2011 

Some of the files have examples 1-4, others 1-12 and beyond. ? 

How can I create a script that will grab the information from 
the different .txt files, put it in a matrix, and spit it out in a .csv 
file with appropriately named columns (the column titles are in CAPS 
above, where the information that will in the column is lower case). 

Thanks in advance.


From nashjc at uottawa.ca  Wed Oct 23 14:38:13 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Wed, 23 Oct 2013 08:38:13 -0400
Subject: [R] nls model definition help
In-Reply-To: <mailman.31.1382522410.23053.r-help@r-project.org>
References: <mailman.31.1382522410.23053.r-help@r-project.org>
Message-ID: <5267C335.6090706@uottawa.ca>

Because you have y on both sides, and at different times, I think you
are going to have to bite the bullet and write down a residual function.

Suggestion: write it as

res[t+1] = (th1*x1 + R1*x2) * exp(a1*x3) + (1-th1*x1 + R1*x2)*y(t) - y[t+1]

(cleaning up the indices -- they are surely needed for the x's too).
This way you can compute derivatives without sign issue if you decide to
do so rather than relying on numeric Jacobian.

nlmrt or minpack.lm will give more stable computations that nls(). Both
have either formula or functional versions of the NLLS minimizer. nlfb()
from nlmrt does bounds constraints and also fixed parameters (masks).

JN



On 13-10-23 06:00 AM, r-help-request at r-project.org wrote:
> Message: 37
> Date: Tue, 22 Oct 2013 17:52:28 +0000
> From: <Wayne.W.Jones at shell.com>
> To: <R-help at r-project.org>
> Subject: [R]  nls model definition help
> Message-ID:
> 	<823FB8AD8FD2F44A92284630A4AADF7E2F1B5B2D at seacmw-s-53401.europe.shell.com>
> 	
> Content-Type: text/plain
> 
> Hi fellow R users,
> 
> I'm trying to fit a model using nls with the following model definition:
> 
> y(t+1)=(th1*x1 + R1*x2) * exp(a1*x3) + (1-th1*x1 + R1*x2)*y(t)
> 
> y is the dependent variable (note on both sides of eq) and the x's represent the regressors.
> th1, R1 and a1 are parameters to be estimated. The problem is non- linear and hence why I'm trying to fit using the well used "nls" function.
> 
> To fit the model I would like to be able to use the formula interface rather than build my own ugly function definition.
> Any ideas if this is achievable and if not any ideas on how to fit this model?
> 
> 
> Many thanks,
> 
> Wayne


From rafa_moral2004 at yahoo.com.br  Wed Oct 23 15:00:15 2013
From: rafa_moral2004 at yahoo.com.br (Rafael Moral)
Date: Wed, 23 Oct 2013 06:00:15 -0700 (PDT)
Subject: [R] changing model matrix restriction in lm()
Message-ID: <1382533215.16028.YahooMailBasic@web164501.mail.gq1.yahoo.com>

Dear useRs,
I was wondering if there was a way of changing the model matrix restriction automatically in the formula statement when fitting a model using, for example, lm().
When we do

set.seed(100)
y <- rnorm(12)
A <- gl(3, 4)
summary(lm(y ~ A))

we obtain A1=0 as a baseline and A2 and A3 as effects.
However, if I want to use A2=0 as a baseline, I can do

X <- cbind(1, model.matrix(lm(y ~ A - 1)))[,-3]
summary(lm(y ~ X))

I wonder if there is a way of specifying the restriction in the parameters directly in the formula argument instead of building the desired model matrix.

Best wishes,
Rafael.


From smartpink111 at yahoo.com  Wed Oct 23 14:58:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 23 Oct 2013 05:58:10 -0700 (PDT)
Subject: [R] matrix of mean values
In-Reply-To: <CAMMD=S5BxPZVoCdb_HAP0k_Qqz=4vD8xNV79MqSAOL57F965-A@mail.gmail.com>
References: <CAMMD=S5_druNFxzGtK5bnqKB15HD04CskeCEpYKqQmRhE3u0Lw@mail.gmail.com>	<1381244075.53183.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<1381244163.66311.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAMMD=S6eHJQoVSZ5ZRJvp5LEE2=6TY4JVH8RxHUbbjCMURnOZQ@mail.gmail.com>	<1381251208.3018.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAMMD=S6y2buBsJc+Q8GxXrEXT=ZhtuVzUaCBENv8sbp_yabb_A@mail.gmail.com>	<1381253473.39852.YahooMailNeo@web142605.mail.bf1.yahoo.com>	<1381327756.50387.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAMMD=S54FC5NAhE8YjgrCy4vbMJWEw5dGM6FdBEwrndw0tN6KA@mail.gmail.com>	<1381411093.93070.YahooMailNeo@web142605.mail.bf1.yahoo.com>	<CAMMD=S4p4Hee4W6SFPa34yJwo7PS120_Ly5Yh1YGSOPArLRjUg@mail.gmail.com>	<1381847935.99647.YahooMailNeo@web142605.mail.bf1.yahoo.com>	<CAMMD=S5jcM8xtiSN38f8=Ls1R=utpNH7mS6eRZ=LnmDAVpP7yA@mail.gmail.com>	<1381928000.98432.YahooMailNeo@web142605.mail.bf1.yahoo.com>	<CAMMD=S5rJQnyDQ3uO1h7+zPEU4xXaBpDOiumk-54b87rW2AZ+g@mail.gmail.com>	<1381934660.30750.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<CAMMD=S5V1Rkfx8z=GkJd4iB_rbVs+bq4kr8QBh+dA+Udi7GKwQ@mail.gmail.com>	<1381938854.43273.YahooMailNeo@web142602.mail.bf1.yahoo.com>	<CAMMD=S6kNsEJ0bNvMt-+HKRBZFYgNxfUJCEY6Pn2DbHagKFFNQ@mail.gmail.com>	<1382452218.80360.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAMMD=S5BxPZVoCdb_HAP0k_Qqz=4vD8xNV79MqSAOL57F965-A@mail.gmail.com>
Message-ID: <1382533090.92288.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi Nico,

Try:
dat<-read.table("pollShed.txt", header = T, sep = "\t",dec=",") 
?as.vector(sapply(split(dat,dat$name1),nrow))
?#[1]? 86? 10? 43?? 3? 20?? 7? 25? 12? 18?? 3?? 7? 12? 12? 14?? 3? 14? 25 175? 59
#[20]? 49? 16?? 3? 16? 14? 25? 14? 19?? 3? 18?? 7?? 4?? 3? 45? 14? 16?? 3? 12 238
#[39]? 12?? 3? 25?? 9? 20? 12? 12? 15? 20?? 7 170? 16? 12? 45? 14? 25?? 3? 12? 14
#[58] 397?? 1?? 3? 10 542? 14? 14? 12? 24? 12?? 3? 14? 20?? 3?? 4?? 3? 40? #### list element 59 produce the error 
lst1 <- split(dat,dat$name1)

t.test(lst1[[59]][,2],dat[,2])
#Error in t.test.default(lst1[[59]][, 2], dat[, 2]) : 
#? not enough 'x' observations

?res <- sapply(lst1[sapply(lst1,nrow)>1],function(x) t.test(x[,2],dat[,2])$p.value)
?head(res)
#????? -99999?????? 108946?????? 111364?????? 140400?????? 149067?????? 206262 
#4.508590e-01 9.142790e-05 4.911925e-09 7.124666e-01 1.376976e-03 3.161232e-02 



A.K.









On Wednesday, October 23, 2013 8:27 AM, Nico Met <nicomet80 at gmail.com> wrote:

Many thanks Arun for the suggestion.?

However, I tried following and do not know why it shows error. Data attached.



?dat<-read.table("pollShed.txt", header = T, sep = "\t",dec=",") # works fine?

?mean1<-sapply(split(dat,dat$name1),function(x) t.test(x[,2],dat[,2])$statistic)?

# Error in t.test.default(x[, 2], dat[, 2]) : not enough 'x' observations


?pval<-sapply(split(dat,dat$name1),function(x) t.test(x[,2],dat[,2])$p.value)

# Error in t.test.default(x[, 2], dat[, 2]) : not enough 'x' observations

Thanks in advance


From gunter.berton at gene.com  Wed Oct 23 15:29:28 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 23 Oct 2013 06:29:28 -0700
Subject: [R] changing model matrix restriction in lm()
In-Reply-To: <1382533215.16028.YahooMailBasic@web164501.mail.gq1.yahoo.com>
References: <1382533215.16028.YahooMailBasic@web164501.mail.gq1.yahoo.com>
Message-ID: <CACk-te2RNsxsMoBX79cxtdd+msAztj0mwLa36Z5qafx08fAxcw@mail.gmail.com>

?contrasts
?C

Cheers,
Bert

On Wed, Oct 23, 2013 at 6:00 AM, Rafael Moral
<rafa_moral2004 at yahoo.com.br> wrote:
> Dear useRs,
> I was wondering if there was a way of changing the model matrix restriction automatically in the formula statement when fitting a model using, for example, lm().
> When we do
>
> set.seed(100)
> y <- rnorm(12)
> A <- gl(3, 4)
> summary(lm(y ~ A))
>
> we obtain A1=0 as a baseline and A2 and A3 as effects.
> However, if I want to use A2=0 as a baseline, I can do
>
> X <- cbind(1, model.matrix(lm(y ~ A - 1)))[,-3]
> summary(lm(y ~ X))
>
> I wonder if there is a way of specifying the restriction in the parameters directly in the formula argument instead of building the desired model matrix.
>
> Best wishes,
> Rafael.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From rafa_moral2004 at yahoo.com.br  Wed Oct 23 15:45:41 2013
From: rafa_moral2004 at yahoo.com.br (Rafael Moral)
Date: Wed, 23 Oct 2013 06:45:41 -0700 (PDT)
Subject: [R] changing model matrix restriction in lm()
In-Reply-To: <CACk-te2RNsxsMoBX79cxtdd+msAztj0mwLa36Z5qafx08fAxcw@mail.gmail.com>
Message-ID: <1382535941.3665.YahooMailBasic@web164503.mail.gq1.yahoo.com>

Thank you very much!

Best,
Rafael.

--------------------------------------------
Em qua, 23/10/13, Bert Gunter <gunter.berton at gene.com> escreveu:

 Assunto: Re: [R] changing model matrix restriction in lm()

 Cc: "r-help at r-project.org" <r-help at r-project.org>
 Data: Quarta-feira, 23 de Outubro de 2013, 11:29

 ?contrasts
 ?C

 Cheers,
 Bert

 On Wed, Oct 23, 2013 at 6:00 AM, Rafael Moral

 wrote:
 > Dear useRs,
 > I was wondering if there was a way of changing the
 model matrix restriction automatically in the formula
 statement when fitting a model using, for example, lm().
 > When we do
 >
 > set.seed(100)
 > y <- rnorm(12)
 > A <- gl(3, 4)
 > summary(lm(y ~ A))
 >
 > we obtain A1=0 as a baseline and A2 and A3 as effects.
 > However, if I want to use A2=0 as a baseline, I can do
 >
 > X <- cbind(1, model.matrix(lm(y ~ A - 1)))[,-3]
 > summary(lm(y ~ X))
 >
 > I wonder if there is a way of specifying the
 restriction in the parameters directly in the formula
 argument instead of building the desired model matrix.
 >
 > Best wishes,
 > Rafael.
 >
 > ______________________________________________
 > R-help at r-project.org
 mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained,
 reproducible code.



 -- 

 Bert Gunter
 Genentech Nonclinical Biostatistics

 (650) 467-7374


From thibaut.vernay at outlook.com  Wed Oct 23 13:25:57 2013
From: thibaut.vernay at outlook.com (Thibaut Vernay)
Date: Wed, 23 Oct 2013 13:25:57 +0200
Subject: [R] ARIMA model and xreg with R
Message-ID: <DUB118-W45B76D67EA495E98AFB9E892030@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/308b9b78/attachment.pl>

From biopriyanka at gmail.com  Wed Oct 23 12:17:57 2013
From: biopriyanka at gmail.com (Priyanka Nannapaneni)
Date: Wed, 23 Oct 2013 12:17:57 +0200
Subject: [R] gplot
Message-ID: <CAPJiTW8L6=kxzZzJtJsvyZSoP_APjC4WNJT0CM0LF717evd+wQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/62c4e54b/attachment.pl>

From thiru_maniam2000 at yahoo.com  Wed Oct 23 12:51:49 2013
From: thiru_maniam2000 at yahoo.com (THIRU MANIAM)
Date: Wed, 23 Oct 2013 18:51:49 +0800 (SGT)
Subject: [R] Loop for R
Message-ID: <1382525509.56029.YahooMailNeo@web194003.mail.sg3.yahoo.com>

Hi,
I need kind help from you. I'm doing my assignment in IR and need to do script in R programming and using R studio tool.I don't have any knowledge in R but learning by Youtube. After so long,i successfully came out with below script for precision 10(P@)
But i don know how to do loop for 105 system. below script was for 5 system but i define it ?one by one.Can you help me ?
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: P at 10.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/38b9aff7/attachment.txt>

From carl at witthoft.com  Wed Oct 23 16:00:40 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Wed, 23 Oct 2013 07:00:40 -0700 (PDT)
Subject: [R] Hey guys I have one slight problem with my code
In-Reply-To: <1382493937329-4678840.post@n4.nabble.com>
References: <1382493937329-4678840.post@n4.nabble.com>
Message-ID: <1382536840664-4678877.post@n4.nabble.com>

What's the range of data you are trying to plot?  The error message is pretty
clear: you've selected a set of breaks which don't span the data range.
Maybe try breaks = c(min(x),seq(4,30,2),max(x))




--
View this message in context: http://r.789695.n4.nabble.com/Hey-guys-I-have-one-slight-problem-with-my-code-tp4678840p4678877.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Wed Oct 23 16:15:11 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 23 Oct 2013 07:15:11 -0700
Subject: [R] gplot
In-Reply-To: <CAPJiTW8L6=kxzZzJtJsvyZSoP_APjC4WNJT0CM0LF717evd+wQ@mail.gmail.com>
References: <CAPJiTW8L6=kxzZzJtJsvyZSoP_APjC4WNJT0CM0LF717evd+wQ@mail.gmail.com>
Message-ID: <3B7A5309-85F0-49B5-87B6-E4EA73D0018E@comcast.net>


On Oct 23, 2013, at 3:17 AM, Priyanka Nannapaneni wrote:

> Hi all,
> 
> I couldn't install gplots package.
>> install.packages("gplot")
> Warning message:
> package 'gplot' is not available (for R version 3.0.2)
> 
> i want to use heat maps.2 function.
> 
> can you please tell me how to install this package or are there any
> alternatives.

Correct spelling of the package name would be the best alternative.

> Thanks in advance :)
> 
> 	[[alternative HTML version deleted]]

Posting in plain text is not essential but it is preferred.
 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Wed Oct 23 16:25:54 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 23 Oct 2013 07:25:54 -0700
Subject: [R] Loop for R
In-Reply-To: <1382525509.56029.YahooMailNeo@web194003.mail.sg3.yahoo.com>
References: <1382525509.56029.YahooMailNeo@web194003.mail.sg3.yahoo.com>
Message-ID: <9a4de102-5fd0-4354-a57f-4691f6f88729@email.android.com>

As the Posting Guide ( http://www.R-project.org/posting-guide.html) indicates, this is not a homework help forum. Please use the resources provided by your educational institution for assistance.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

THIRU MANIAM <thiru_maniam2000 at yahoo.com> wrote:
>Hi,
>I need kind help from you. I'm doing my assignment in IR and need to do
>script in R programming and using R studio tool.I don't have any
>knowledge in R but learning by Youtube. After so long,i successfully
>came out with below script for precision 10(P@)
>But i don know how to do loop for 105 system. below script was for 5
>system but i define it ?one by one.Can you help me ?
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Wed Oct 23 16:36:42 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 23 Oct 2013 14:36:42 +0000
Subject: [R] Loop for R
In-Reply-To: <1382525509.56029.YahooMailNeo@web194003.mail.sg3.yahoo.com>
References: <1382525509.56029.YahooMailNeo@web194003.mail.sg3.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9A0B5@SRVEXCHMBX.precheza.cz>

Hi

I am a little bit curious how efficient can Youtube be in learning statistics. My understanding was that it is mainly for entertainment. However statistics can be also entertainment, especially considering R.

Anyway R-intro and help pages for functions are probably better source for serious learning.

And if you decided to read R-intro have a look at Posting guide too.
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of THIRU MANIAM
> Sent: Wednesday, October 23, 2013 12:52 PM
> To: r-help at R-project.org
> Subject: [R] Loop for R
> 
> Hi,
> I need kind help from you. I'm doing my assignment in IR and need to do
> script in R programming and using R studio tool.I don't have any
> knowledge in R but learning by Youtube. After so long,i successfully
> came out with below script for precision 10(P@) But i don know how to
> do loop for 105 system. below script was for 5 system but i define it
> ?one by one.Can you help me ?


From ingfimo at gmail.com  Wed Oct 23 18:21:34 2013
From: ingfimo at gmail.com (Filippo Monari)
Date: Wed, 23 Oct 2013 17:21:34 +0100
Subject: [R] garchFit
Message-ID: <5267F78E.9070802@gmail.com>

Hi,
I'm using "garchFit" function from packages fGarch, to fit some nose.
The weird thing is that in some cases the estimate for the alpha1 
coefficient is equal to 1, which can't be otherwise the model is not stable.
Even more alpha1 = 1 makes impossible to simulate the model.
My model is an ARMA(1,5)/GARCH(2,0), could be a probelm coused by 
overfitting? All my parameters seems to be significant...
Can anyone help me to undestand way this is happening?
Below there is the output from the function.
Thanks in advance , regards,
Filippo.

This is the output from the function:
Title:
GARCH Modelling

Call:
garchFit(formula = ~arma(1, 5) + garch(2, 0), data = Text.noise,
trace = F)

Mean and Variance Equation:
data ~ arma(1, 5) + garch(2, 0)
<environment: 0xca9e848>
[data = Text.noise]

Conditional Distribution:
norm

Coefficient(s):
mu ar1 ma1 ma2 ma3 ma4
-7.9290e-15 -4.1513e-01 -1.0000e+00 -6.4137e-01 5.0686e-01 2.0932e-01
ma5 omega alpha1 alpha2
-6.1404e-02 9.2491e-04 1.0000e+00 1.0000e+00

Std. Errors:
based on Hessian

Error Analysis:
Estimate Std. Error t value Pr(>|t|)
mu -7.929e-15 2.185e-05 0.000 1
ar1 -4.151e-01 2.091e-02 -19.851 < 2e-16 ***
ma1 -1.000e+00 1.996e-02 -50.088 < 2e-16 ***
ma2 -6.414e-01 3.833e-02 -16.732 < 2e-16 ***
ma3 5.069e-01 2.807e-02 18.056 < 2e-16 ***
ma4 2.093e-01 1.457e-02 14.369 < 2e-16 ***
ma5 -6.140e-02 1.345e-02 -4.567 4.96e-06 ***
omega 9.249e-04 1.093e-04 8.460 < 2e-16 ***
alpha1 1.000e+00 8.741e-02 11.441 < 2e-16 ***
alpha2 1.000e+00 7.845e-02 12.747 < 2e-16 ***
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Log Likelihood:
1359.009 normalized: 1.014943

Description:
Wed Oct 23 17:15:30 2013 by user:


From ingfimo at gmail.com  Wed Oct 23 19:34:47 2013
From: ingfimo at gmail.com (Filippo Monari)
Date: Wed, 23 Oct 2013 18:34:47 +0100
Subject: [R] garchFit updating
In-Reply-To: <5267F78E.9070802@gmail.com>
References: <5267F78E.9070802@gmail.com>
Message-ID: <526808B7.2000602@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/2d98b42e/attachment.pl>

From holtermann at hwwi.org  Wed Oct 23 15:50:33 2013
From: holtermann at hwwi.org (Linus Holtermann)
Date: Wed, 23 Oct 2013 15:50:33 +0200
Subject: [R] SUR and less observation than parameters
Message-ID: <AD0050057515F54084E7D5B93478C848093C50AF93@winxbede39.exchange.xchg>


   Hello,

   i  like  to  incorporate  a  SUR (Seemingly Unrelated Regression) in a
   multilevel-model. My panel-dataset includes variables for 400 regions from
   1990-2010.  In  case  of  SUR-models i found the following econometric
   requirement that time observations need to exceed unit observations, which
   is obviously not true in my dataset.
   Is it possible to avoid this requirement by using MCMC inference? I am given
   to understand that one advantage of MCMC estimation is due to the fact that
   the number of parameteres to be estimated can be larger than the observation
   number (because estimation does not rely on degree of freedoms). Can someone
   confirm my thoughts? In my case the discrepancy between time observations
   (20) and unit observations (400) is quite large. Is it possible to use a
   SUR_MCMC-model to handle this problem?

   Thanks in advance

   Mit freundlichen Gr????en



   Linus Holtermann

   Hamburgisches WeltWirtschaftsInstitut gemeinn??tzige GmbH (HWWI)
   Heimhuder Stra??e 71
   20148 Hamburg
   Tel +49-(0)40-340576-336
   Fax+49-(0)40-340576-776
   Internet: [1]www.hwwi.org
   Email: [2]holtermann at hwwi.org


   AmtsgerichtHamburg HRB 94303
   Gesch??ftsf??hrer: Prof. Dr. Thomas Straubhaar, Gunnar Geyer
   Umsatzsteuer-ID: DE 241849425

References

   1. http://www.hwwi.org/
   2. mailto:holtermann at hwwi.org

From michael.jensen at oliverwyman.com  Wed Oct 23 16:25:14 2013
From: michael.jensen at oliverwyman.com (smugg55)
Date: Wed, 23 Oct 2013 07:25:14 -0700 (PDT)
Subject: [R] Function not working as I'd like
Message-ID: <1382538313810-4678878.post@n4.nabble.com>

Hey all,

So I wrote/borrowed some code (no, I'm not trying to claim all of the work
I've done below as my own). Ideally what I'd like the code to do is
calculate ep for each iteration of q. Here's the code:

> gpdriskmeasures = function(x , prob =
> c(0,.1,.2,.25,.3,.4,.5,.6,.7,.75,.8,.9,.95,.99))
+ {
+ xi = gpd.model$par.ests["xi"]
+ beta = gpd.model$par.ests["beta"]
+ u = gpd.model$threshold
+ q = u + (beta*((1-prob)^(-xi)-1))/xi
+ es = (q + (beta - xi * u))/(1 - xi)
+ ep =
1-length(ninetyoneclaims$total.chg[ninetyoneclaims$total.chg>q])/length(ninetyoneclaims$total.chg)
+ ans = data.frame(p = prob, quantile = q, tail.expectation = es,
empirical.prob = ep)
+ ans
+ }

Note that there are no problems pulling xi, beta, and u, and es calculates
correctly. I'll also show what the results look like:

> gpdriskmeasures(ninetyoneclaims$total.chg)
      p  quantile tail.expectation empirical.prob
1  0.00  200000.0         336856.8      0.9878478
2  0.10  210058.6         351517.2      0.9878478
3  0.20  221704.1         368490.5      0.9878478
4  0.25  228270.1         378060.5      0.9878478

As you can see the empirical.prob (which is ep) is not calculating
correctly, as that number should be decreasing as the quantile (q)
increases.

Any help would be most appreciated! Thanks in advance for anyone that can
help.



--
View this message in context: http://r.789695.n4.nabble.com/Function-not-working-as-I-d-like-tp4678878.html
Sent from the R help mailing list archive at Nabble.com.


From nora-ern at gmx.ch  Wed Oct 23 16:40:17 2013
From: nora-ern at gmx.ch (Nora Ernst)
Date: Wed, 23 Oct 2013 16:40:17 +0200 (CEST)
Subject: [R]  raster package: merge/mosaic
Message-ID: <trinity-27d6aac2-4879-467b-8d6d-25caaa19ffff-1382539217132@3capp-gmx-bs36>


   Hi all,

   I'm working with raster data (satellite imagery) and the raster package. The
   idea is to merge two raster files that are partially overlaping, do have the
   same coordinate system and resolution but not the same origin. As expected,
   the functions mosaic(r1,r2) as well as merge(r1,r2)) give the error message:

Error in compareRaster(x, extent = FALSE, rowcol = FALSE, orig = TRUE,  : 
  different origin


> extent(r1)
class       : Extent 
xmin        : 24.14369 
xmax        : 37.81287 
ymin        : -31.1356 
ymax        : -14.72525 
> extent(r2)
class       : Extent 
xmin        : 26.80423 
xmax        : 42.15502 
ymin        : -19.33202 
ymax        : -7.643101

> origin(r1)
[1] 5.582522e-05 1.124150e-03
> origin(r2)
[1]  0.001054868 -0.001124150


   Can  anyone tell me how it is possible to merge rasters with different
   origin?

   Thanks in advance.

From hughesadam87 at gmail.com  Wed Oct 23 19:39:54 2013
From: hughesadam87 at gmail.com (Adam Hughes)
Date: Wed, 23 Oct 2013 13:39:54 -0400
Subject: [R] Scripting call to R-Studio compile PDF
Message-ID: <CAMHV+dCmvuv4o6xATuFm_efDf1_1_wBJone+ytpzCZ9OujMWHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/88cbb176/attachment.pl>

From hughesadam87 at gmail.com  Wed Oct 23 19:48:48 2013
From: hughesadam87 at gmail.com (Adam Hughes)
Date: Wed, 23 Oct 2013 13:48:48 -0400
Subject: [R] Scripting call to R-Studio compile PDF
In-Reply-To: <CAMHV+dCmvuv4o6xATuFm_efDf1_1_wBJone+ytpzCZ9OujMWHw@mail.gmail.com>
References: <CAMHV+dCmvuv4o6xATuFm_efDf1_1_wBJone+ytpzCZ9OujMWHw@mail.gmail.com>
Message-ID: <CAMHV+dCg3u-=us-6DNMr=WDiZjarObmBHUTQfmtXm4kzoK8U-A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/0353e927/attachment.pl>

From xie at yihui.name  Wed Oct 23 20:12:04 2013
From: xie at yihui.name (Yihui Xie)
Date: Wed, 23 Oct 2013 13:12:04 -0500
Subject: [R] Scripting call to R-Studio compile PDF
In-Reply-To: <CAMHV+dCg3u-=us-6DNMr=WDiZjarObmBHUTQfmtXm4kzoK8U-A@mail.gmail.com>
References: <CAMHV+dCmvuv4o6xATuFm_efDf1_1_wBJone+ytpzCZ9OujMWHw@mail.gmail.com>
	<CAMHV+dCg3u-=us-6DNMr=WDiZjarObmBHUTQfmtXm4kzoK8U-A@mail.gmail.com>
Message-ID: <CANROs4eWVeYcZet9XR98abzG7R-r_4sAZyVwo7VPtSUrUooNag@mail.gmail.com>

RStudio also uses a "script" to compile Rnw files to PDF; you can see
all the "magic" in the "Compile PDF" pane (next to your "Console"
pane) after you click the button "Compile PDF".

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Wed, Oct 23, 2013 at 12:48 PM, Adam Hughes <hughesadam87 at gmail.com> wrote:
> Sorry, just to clarify:
>
> When I ask "how to do this", I mean what does the RStudio compiler actually
> do?  Are there a series of commands that are sent to the shell, similar to
> how compiling a .tex file is a call to the command line using "pdflatex
> foofile.tex".  I'm hoping to just copy these shell commands using a python
> script, which is easy.
>
>
> On Wed, Oct 23, 2013 at 1:39 PM, Adam Hughes <hughesadam87 at gmail.com> wrote:
>
>> Hey everyone,
>>
>> I have several RStudio (.rnw) files that I am using a script to assemble
>> into a composite document.  For this purpose, it would be helpful if the
>> script could automatcially make a call to whatever is called when a user
>> opens up one of these files and manually clicks "Compile PDF".  Basically,
>> this would allow me to refresh all of the reports before assimilating their
>> pdf's into a composite document.
>>
>> Does anyone know offhand how to do this, or if I'm offbase in even trying?
>>
>> Thanks


From jluo.rhelp at gmail.com  Wed Oct 23 20:19:55 2013
From: jluo.rhelp at gmail.com (Jack Luo)
Date: Wed, 23 Oct 2013 14:19:55 -0400
Subject: [R] question regarding cv.glmnet in glmnet package
Message-ID: <CAD-E8+6p_BCnmEorAJYfkqU7ZDKPqvP8zFuP10WXqV=3gz=n7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/fff4ff8a/attachment.pl>

From dwinsemius at comcast.net  Wed Oct 23 20:20:53 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 23 Oct 2013 11:20:53 -0700
Subject: [R] Scripting call to R-Studio compile PDF
In-Reply-To: <CAMHV+dCg3u-=us-6DNMr=WDiZjarObmBHUTQfmtXm4kzoK8U-A@mail.gmail.com>
References: <CAMHV+dCmvuv4o6xATuFm_efDf1_1_wBJone+ytpzCZ9OujMWHw@mail.gmail.com>
	<CAMHV+dCg3u-=us-6DNMr=WDiZjarObmBHUTQfmtXm4kzoK8U-A@mail.gmail.com>
Message-ID: <4E341CF8-D07E-454B-99AE-54C0BB2355A9@comcast.net>


On Oct 23, 2013, at 10:48 AM, Adam Hughes wrote:

> Sorry, just to clarify:
> 
> When I ask "how to do this", I mean what does the RStudio compiler actually
> do?  Are there a series of commands that are sent to the shell, similar to
> how compiling a .tex file is a call to the command line using "pdflatex
> foofile.tex".  I'm hoping to just copy these shell commands using a python
> script, which is easy.
> 

There is an RStudio mailing list or forum for support of that product.

> 
> On Wed, Oct 23, 2013 at 1:39 PM, Adam Hughes <hughesadam87 at gmail.com> wrote:
> 
>> Hey everyone,
>> 
>> I have several RStudio (.rnw) files that I am using a script to assemble
>> into a composite document.  For this purpose, it would be helpful if the
>> script could automatcially make a call to whatever is called when a user
>> opens up one of these files and manually clicks "Compile PDF".  Basically,
>> this would allow me to refresh all of the reports before assimilating their
>> pdf's into a composite document.
>> 
>> Does anyone know offhand how to do this, or if I'm offbase in even trying?
>> 
>> Thanks
>> 
-- 

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Wed Oct 23 20:58:17 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 23 Oct 2013 13:58:17 -0500
Subject: [R] Function not working as I'd like
In-Reply-To: <1382538313810-4678878.post@n4.nabble.com>
References: <1382538313810-4678878.post@n4.nabble.com>
Message-ID: <05e701ced021$d54992f0$7fdcb8d0$@tamu.edu>

Your problem is here

ninetyoneclaims$total.chg>q

That produces a logical vector of TRUE/FALSE values, but the
length of the vector stays the same even though the number of
TRUEs is changing. Try 

sum(ninetyoneclaims$total.chg>q)

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of smugg55
Sent: Wednesday, October 23, 2013 9:25 AM
To: r-help at r-project.org
Subject: [R] Function not working as I'd like

Hey all,

So I wrote/borrowed some code (no, I'm not trying to claim all
of the work
I've done below as my own). Ideally what I'd like the code to do
is
calculate ep for each iteration of q. Here's the code:

> gpdriskmeasures = function(x , prob =
> c(0,.1,.2,.25,.3,.4,.5,.6,.7,.75,.8,.9,.95,.99))
+ {
+ xi = gpd.model$par.ests["xi"]
+ beta = gpd.model$par.ests["beta"]
+ u = gpd.model$threshold
+ q = u + (beta*((1-prob)^(-xi)-1))/xi
+ es = (q + (beta - xi * u))/(1 - xi)
+ ep =
1-length(ninetyoneclaims$total.chg[ninetyoneclaims$total.chg>q])
/length(ninetyoneclaims$total.chg)
+ ans = data.frame(p = prob, quantile = q, tail.expectation =
es,
empirical.prob = ep)
+ ans
+ }

Note that there are no problems pulling xi, beta, and u, and es
calculates
correctly. I'll also show what the results look like:

> gpdriskmeasures(ninetyoneclaims$total.chg)
      p  quantile tail.expectation empirical.prob
1  0.00  200000.0         336856.8      0.9878478
2  0.10  210058.6         351517.2      0.9878478
3  0.20  221704.1         368490.5      0.9878478
4  0.25  228270.1         378060.5      0.9878478

As you can see the empirical.prob (which is ep) is not
calculating
correctly, as that number should be decreasing as the quantile
(q)
increases.

Any help would be most appreciated! Thanks in advance for anyone
that can
help.



--
View this message in context:
http://r.789695.n4.nabble.com/Function-not-working-as-I-d-like-t
p4678878.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From dcarlson at tamu.edu  Wed Oct 23 21:06:04 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 23 Oct 2013 14:06:04 -0500
Subject: [R] Function not working as I'd like
References: <1382538313810-4678878.post@n4.nabble.com> 
Message-ID: <05ee01ced022$ebba6590$c32f30b0$@tamu.edu>

Actually I wrote too quickly. Since the logical vector is used
to subset a vector, the value of
length(ninetyoneclaims$total.chg[ninetyoneclaims$total.chg>q])
should be changing.

David

-----Original Message-----
From: David Carlson [mailto:dcarlson at tamu.edu] 
Sent: Wednesday, October 23, 2013 1:58 PM
To: 'smugg55'; 'r-help at r-project.org'
Subject: RE: [R] Function not working as I'd like

Your problem is here

ninetyoneclaims$total.chg>q

That produces a logical vector of TRUE/FALSE values, but the
length of the vector stays the same even though the number of
TRUEs is changing. Try 

sum(ninetyoneclaims$total.chg>q)

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of smugg55
Sent: Wednesday, October 23, 2013 9:25 AM
To: r-help at r-project.org
Subject: [R] Function not working as I'd like

Hey all,

So I wrote/borrowed some code (no, I'm not trying to claim all
of the work
I've done below as my own). Ideally what I'd like the code to do
is
calculate ep for each iteration of q. Here's the code:

> gpdriskmeasures = function(x , prob =
> c(0,.1,.2,.25,.3,.4,.5,.6,.7,.75,.8,.9,.95,.99))
+ {
+ xi = gpd.model$par.ests["xi"]
+ beta = gpd.model$par.ests["beta"]
+ u = gpd.model$threshold
+ q = u + (beta*((1-prob)^(-xi)-1))/xi
+ es = (q + (beta - xi * u))/(1 - xi)
+ ep =
1-length(ninetyoneclaims$total.chg[ninetyoneclaims$total.chg>q])
/length(ninetyoneclaims$total.chg)
+ ans = data.frame(p = prob, quantile = q, tail.expectation =
es,
empirical.prob = ep)
+ ans
+ }

Note that there are no problems pulling xi, beta, and u, and es
calculates
correctly. I'll also show what the results look like:

> gpdriskmeasures(ninetyoneclaims$total.chg)
      p  quantile tail.expectation empirical.prob
1  0.00  200000.0         336856.8      0.9878478
2  0.10  210058.6         351517.2      0.9878478
3  0.20  221704.1         368490.5      0.9878478
4  0.25  228270.1         378060.5      0.9878478

As you can see the empirical.prob (which is ep) is not
calculating
correctly, as that number should be decreasing as the quantile
(q)
increases.

Any help would be most appreciated! Thanks in advance for anyone
that can
help.



--
View this message in context:
http://r.789695.n4.nabble.com/Function-not-working-as-I-d-like-t
p4678878.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From smartpink111 at yahoo.com  Wed Oct 23 21:17:13 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 23 Oct 2013 12:17:13 -0700 (PDT)
Subject: [R] How to view un-sampled data from a randomly sampled dataset
Message-ID: <1382555833.65054.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
You may try:
set.seed(432)
?dat1 <- data.frame(Col1=1:150,Col2=rnorm(150))
?y <- dat1[sample(1:nrow(dat1),40,replace=FALSE),]
x <- dat1[-as.numeric(row.names(y)),]
?dim(x)
#[1] 110?? 2
intersect(row.names(x),row.names(y))
#character(0)

#or
?x1 <- dat1[!row.names(dat1) %in% row.names(y),]
?identical(x,x1)
#[1] TRUE



A.K.



Hi there- 

I have a 150 row dataset (data). I create "y" a randomly sampled (without replacement) set number of observations (40): 

y<-data[sample(1:nrow(data),40,replace=FALSE),] 

I would like to make a new variable "x" that contains the 
leftover non-sampled 110 observations. ?I am sure there is a fairly easy
 way to do this. 

Any help would be greatly appreciated. 

THANKS!


From macqueen1 at llnl.gov  Wed Oct 23 20:04:17 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 23 Oct 2013 18:04:17 +0000
Subject: [R] Where is element 30?
In-Reply-To: <1382440871.43333.YahooMailNeo@web125301.mail.ne1.yahoo.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D4DFB3E@PRDEXMBX-08.the-lab.llnl.gov>

Follow these examples:

> grep(5,1:10)
[1] 5

> grep(3, c(1,5,2,3,6))
[1] 4



-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/22/13 4:21 AM, "Alaios" <alaios at yahoo.com> wrote:

>Hi I have a vector like that
>
>readCsvFile$V1
> [1]  30  31  32  33  34  35  36  37  38  39 310 311 312 313 314 315 316
>317 318
>[20] 319 320 321  20  21  22  23  24  25  26  27  28  29 210 211 212 213
>214 215
>[39] 216 217 218 219 220 221 222 223  40  41  42  43  44  45  46  47  48
>49 410
>[58] 411 412 413 414 415 416 417 418 419 420 421
>
>
>and I am looking to find where the number 31 is located. So I need one
>function to return me the index of where the number 31 is.
>Is there a function for that in R?
>
>Regards
>Alex
>	[[alternative HTML version deleted]]
>


From erinu at jhu.edu  Wed Oct 23 20:13:49 2013
From: erinu at jhu.edu (erinu)
Date: Wed, 23 Oct 2013 11:13:49 -0700 (PDT)
Subject: [R] How to view un-sampled data from a randomly sampled dataset
Message-ID: <1382552028571-4678887.post@n4.nabble.com>

Hi there-

I have a 150 row dataset (data). I create "y" a randomly sampled (without
replacement) set number of observations (40):

y<-data[sample(1:nrow(data),40,replace=FALSE),]

I would like to make a new variable "x" that contains the leftover
non-sampled 110 observations.  I am sure there is a fairly easy way to do
this.

Any help would be greatly appreciated.

THANKS! 



--
View this message in context: http://r.789695.n4.nabble.com/How-to-view-un-sampled-data-from-a-randomly-sampled-dataset-tp4678887.html
Sent from the R help mailing list archive at Nabble.com.


From pdalgd at gmail.com  Wed Oct 23 21:27:38 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 23 Oct 2013 21:27:38 +0200
Subject: [R] Function not working as I'd like
In-Reply-To: <05ee01ced022$ebba6590$c32f30b0$@tamu.edu>
References: <1382538313810-4678878.post@n4.nabble.com>
	<05ee01ced022$ebba6590$c32f30b0$@tamu.edu>
Message-ID: <0BCA6AD5-E8D0-4345-95D5-6B8DB9F10E75@gmail.com>


On Oct 23, 2013, at 21:06 , David Carlson wrote:

> Actually I wrote too quickly. Since the logical vector is used
> to subset a vector, the value of
> length(ninetyoneclaims$total.chg[ninetyoneclaims$total.chg>q])
> should be changing.
> 

It would if q did, but q is a single vector which gets recycled to the length of total.chg. R's vectorization capabilities do not extend into "do what I mean"....

Presumably the intention was something like

sapply(q, function(qi) mean(ninetyoneclaims$total.chg <= qi) )

(untested)

-pd

> David
> 
> -----Original Message-----
> From: David Carlson [mailto:dcarlson at tamu.edu] 
> Sent: Wednesday, October 23, 2013 1:58 PM
> To: 'smugg55'; 'r-help at r-project.org'
> Subject: RE: [R] Function not working as I'd like
> 
> Your problem is here
> 
> ninetyoneclaims$total.chg>q
> 
> That produces a logical vector of TRUE/FALSE values, but the
> length of the vector stays the same even though the number of
> TRUEs is changing. Try 
> 
> sum(ninetyoneclaims$total.chg>q)
> 
> -------------------------------------
> David L Carlson
> Associate Professor of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of smugg55
> Sent: Wednesday, October 23, 2013 9:25 AM
> To: r-help at r-project.org
> Subject: [R] Function not working as I'd like
> 
> Hey all,
> 
> So I wrote/borrowed some code (no, I'm not trying to claim all
> of the work
> I've done below as my own). Ideally what I'd like the code to do
> is
> calculate ep for each iteration of q. Here's the code:
> 
>> gpdriskmeasures = function(x , prob =
>> c(0,.1,.2,.25,.3,.4,.5,.6,.7,.75,.8,.9,.95,.99))
> + {
> + xi = gpd.model$par.ests["xi"]
> + beta = gpd.model$par.ests["beta"]
> + u = gpd.model$threshold
> + q = u + (beta*((1-prob)^(-xi)-1))/xi
> + es = (q + (beta - xi * u))/(1 - xi)
> + ep =
> 1-length(ninetyoneclaims$total.chg[ninetyoneclaims$total.chg>q])
> /length(ninetyoneclaims$total.chg)
> + ans = data.frame(p = prob, quantile = q, tail.expectation =
> es,
> empirical.prob = ep)
> + ans
> + }
> 
> Note that there are no problems pulling xi, beta, and u, and es
> calculates
> correctly. I'll also show what the results look like:
> 
>> gpdriskmeasures(ninetyoneclaims$total.chg)
>      p  quantile tail.expectation empirical.prob
> 1  0.00  200000.0         336856.8      0.9878478
> 2  0.10  210058.6         351517.2      0.9878478
> 3  0.20  221704.1         368490.5      0.9878478
> 4  0.25  228270.1         378060.5      0.9878478
> 
> As you can see the empirical.prob (which is ep) is not
> calculating
> correctly, as that number should be decreasing as the quantile
> (q)
> increases.
> 
> Any help would be most appreciated! Thanks in advance for anyone
> that can
> help.
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Function-not-working-as-I-d-like-t
> p4678878.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
> code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Wed Oct 23 21:30:52 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 23 Oct 2013 21:30:52 +0200
Subject: [R] Where is element 30?
In-Reply-To: <5E1B812FAC2C4A49B3D99593B5A521910D4DFB3E@PRDEXMBX-08.the-lab.llnl.gov>
References: <5E1B812FAC2C4A49B3D99593B5A521910D4DFB3E@PRDEXMBX-08.the-lab.llnl.gov>
Message-ID: <8DFB161F-4B08-4C76-B0F1-80E332AC6CE4@gmail.com>


On Oct 23, 2013, at 20:04 , MacQueen, Don wrote:

> Follow these examples:
> 
>> grep(5,1:10)
> [1] 5
> 
>> grep(3, c(1,5,2,3,6))
> [1] 4
> 
> 

Don't:

> grep(5,1:15)
[1]  5 15

-pd
-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From 538280 at gmail.com  Wed Oct 23 21:36:04 2013
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 23 Oct 2013 13:36:04 -0600
Subject: [R] changing model matrix restriction in lm()
In-Reply-To: <1382535941.3665.YahooMailBasic@web164503.mail.gq1.yahoo.com>
References: <CACk-te2RNsxsMoBX79cxtdd+msAztj0mwLa36Z5qafx08fAxcw@mail.gmail.com>
	<1382535941.3665.YahooMailBasic@web164503.mail.gq1.yahoo.com>
Message-ID: <CAFEqCdy505gsgsTa36RnDtgs8o805zkdhWfKrX-bS98rKeeZjw@mail.gmail.com>

Also look at ?relevel

On Wed, Oct 23, 2013 at 7:45 AM, Rafael Moral
<rafa_moral2004 at yahoo.com.br> wrote:
> Thank you very much!
>
> Best,
> Rafael.
>
> --------------------------------------------
> Em qua, 23/10/13, Bert Gunter <gunter.berton at gene.com> escreveu:
>
>  Assunto: Re: [R] changing model matrix restriction in lm()
>
>  Cc: "r-help at r-project.org" <r-help at r-project.org>
>  Data: Quarta-feira, 23 de Outubro de 2013, 11:29
>
>  ?contrasts
>  ?C
>
>  Cheers,
>  Bert
>
>  On Wed, Oct 23, 2013 at 6:00 AM, Rafael Moral
>
>  wrote:
>  > Dear useRs,
>  > I was wondering if there was a way of changing the
>  model matrix restriction automatically in the formula
>  statement when fitting a model using, for example, lm().
>  > When we do
>  >
>  > set.seed(100)
>  > y <- rnorm(12)
>  > A <- gl(3, 4)
>  > summary(lm(y ~ A))
>  >
>  > we obtain A1=0 as a baseline and A2 and A3 as effects.
>  > However, if I want to use A2=0 as a baseline, I can do
>  >
>  > X <- cbind(1, model.matrix(lm(y ~ A - 1)))[,-3]
>  > summary(lm(y ~ X))
>  >
>  > I wonder if there is a way of specifying the
>  restriction in the parameters directly in the formula
>  argument instead of building the desired model matrix.
>  >
>  > Best wishes,
>  > Rafael.
>  >
>  > ______________________________________________
>  > R-help at r-project.org
>  mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>  > and provide commented, minimal, self-contained,
>  reproducible code.
>
>
>
>  --
>
>  Bert Gunter
>  Genentech Nonclinical Biostatistics
>
>  (650) 467-7374
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From pdalgd at gmail.com  Wed Oct 23 21:36:33 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 23 Oct 2013 21:36:33 +0200
Subject: [R] How to view un-sampled data from a randomly sampled dataset
In-Reply-To: <1382552028571-4678887.post@n4.nabble.com>
References: <1382552028571-4678887.post@n4.nabble.com>
Message-ID: <C5A43B73-5C95-4F48-BDF5-C422D400FA6F@gmail.com>


On Oct 23, 2013, at 20:13 , erinu wrote:

> Hi there-
> 
> I have a 150 row dataset (data). I create "y" a randomly sampled (without
> replacement) set number of observations (40):
> 
> y<-data[sample(1:nrow(data),40,replace=FALSE),]
> 
> I would like to make a new variable "x" that contains the leftover
> non-sampled 110 observations.  I am sure there is a fairly easy way to do
> this.
> 
> Any help would be greatly appreciated.
> 
> THANKS! 
> 

Just hold on to the indices:

s <- sample(1:nrow(data), 40, replace=FALSE)
y <- data[s,]
x <- data[-s,]

-pd


> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-view-un-sampled-data-from-a-randomly-sampled-dataset-tp4678887.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From NordlDJ at dshs.wa.gov  Wed Oct 23 21:39:51 2013
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Wed, 23 Oct 2013 19:39:51 +0000
Subject: [R] How to view un-sampled data from a randomly sampled dataset
In-Reply-To: <1382552028571-4678887.post@n4.nabble.com>
References: <1382552028571-4678887.post@n4.nabble.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276623936BFB@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of erinu
> Sent: Wednesday, October 23, 2013 11:14 AM
> To: r-help at r-project.org
> Subject: [R] How to view un-sampled data from a randomly sampled
> dataset
> 
> Hi there-
> 
> I have a 150 row dataset (data). I create "y" a randomly sampled
> (without
> replacement) set number of observations (40):
> 
> y<-data[sample(1:nrow(data),40,replace=FALSE),]
> 
> I would like to make a new variable "x" that contains the leftover
> non-sampled 110 observations.  I am sure there is a fairly easy way to
> do
> this.
> 
> Any help would be greatly appreciated.
> 
> THANKS!
> 
> 

Perhaps something like

ndx <- sample(1:nrow(data),40,replace=FALSE)
y <- data[ndx,]
x <- data[-ndx,]


hope this is helpful,

Dan

Daniel J. Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services



From erinu at jhu.edu  Wed Oct 23 21:42:38 2013
From: erinu at jhu.edu (erinu)
Date: Wed, 23 Oct 2013 12:42:38 -0700 (PDT)
Subject: [R] How to view un-sampled data from a randomly sampled dataset
In-Reply-To: <C5A43B73-5C95-4F48-BDF5-C422D400FA6F@gmail.com>
References: <1382552028571-4678887.post@n4.nabble.com>
	<C5A43B73-5C95-4F48-BDF5-C422D400FA6F@gmail.com>
Message-ID: <1382557358106-4678905.post@n4.nabble.com>

Thanks guys! Easy, quick fix! 



--
View this message in context: http://r.789695.n4.nabble.com/How-to-view-un-sampled-data-from-a-randomly-sampled-dataset-tp4678887p4678905.html
Sent from the R help mailing list archive at Nabble.com.


From gunter.berton at gene.com  Wed Oct 23 21:48:27 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 23 Oct 2013 12:48:27 -0700
Subject: [R] How to view un-sampled data from a randomly sampled dataset
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA276623936BFB@WAXMXOLYMB025.WAX.wa.lcl>
References: <1382552028571-4678887.post@n4.nabble.com>
	<F7E6D18CC2877149AB5296CE54EA276623936BFB@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <CACk-te0J0WXnyZLZ5AE9VrzragnwnYuTVd0i35t_1VKHyJ6uww@mail.gmail.com>

... which raises an interesting point: What if some of the values are
replicated? Does the OP want to have a random sample of everything or
of the unique values?

Cheers,
Bert

On Wed, Oct 23, 2013 at 12:39 PM, Nordlund, Dan (DSHS/RDA)
<NordlDJ at dshs.wa.gov> wrote:
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of erinu
>> Sent: Wednesday, October 23, 2013 11:14 AM
>> To: r-help at r-project.org
>> Subject: [R] How to view un-sampled data from a randomly sampled
>> dataset
>>
>> Hi there-
>>
>> I have a 150 row dataset (data). I create "y" a randomly sampled
>> (without
>> replacement) set number of observations (40):
>>
>> y<-data[sample(1:nrow(data),40,replace=FALSE),]
>>
>> I would like to make a new variable "x" that contains the leftover
>> non-sampled 110 observations.  I am sure there is a fairly easy way to
>> do
>> this.
>>
>> Any help would be greatly appreciated.
>>
>> THANKS!
>>
>>
>
> Perhaps something like
>
> ndx <- sample(1:nrow(data),40,replace=FALSE)
> y <- data[ndx,]
> x <- data[-ndx,]
>
>
> hope this is helpful,
>
> Dan
>
> Daniel J. Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From wdunlap at tibco.com  Wed Oct 23 21:50:05 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 23 Oct 2013 19:50:05 +0000
Subject: [R] How to view un-sampled data from a randomly sampled dataset
In-Reply-To: <C5A43B73-5C95-4F48-BDF5-C422D400FA6F@gmail.com>
References: <1382552028571-4678887.post@n4.nabble.com>
	<C5A43B73-5C95-4F48-BDF5-C422D400FA6F@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0F15C@PA-MBX01.na.tibco.com>

> s <- sample(1:nrow(data), 40, replace=FALSE)
> y <- data[s,]
> x <- data[-s,]

If you don't know the size of the sample and it might be 0 then
you have to be a bit more wordy:
    x <- data[setdiff(seq_len(nrow(data)), s), ]
or the uglier
   x <- if (length(s) > 0) x else x[-s,]

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of peter dalgaard
> Sent: Wednesday, October 23, 2013 12:37 PM
> To: erinu
> Cc: r-help at r-project.org
> Subject: Re: [R] How to view un-sampled data from a randomly sampled dataset
> 
> 
> On Oct 23, 2013, at 20:13 , erinu wrote:
> 
> > Hi there-
> >
> > I have a 150 row dataset (data). I create "y" a randomly sampled (without
> > replacement) set number of observations (40):
> >
> > y<-data[sample(1:nrow(data),40,replace=FALSE),]
> >
> > I would like to make a new variable "x" that contains the leftover
> > non-sampled 110 observations.  I am sure there is a fairly easy way to do
> > this.
> >
> > Any help would be greatly appreciated.
> >
> > THANKS!
> >
> 
> Just hold on to the indices:
> 
> s <- sample(1:nrow(data), 40, replace=FALSE)
> y <- data[s,]
> x <- data[-s,]
> 
> -pd
> 
> 
> >
> >
> > --
> > View this message in context: http://r.789695.n4.nabble.com/How-to-view-un-
> sampled-data-from-a-randomly-sampled-dataset-tp4678887.html
> > Sent from the R help mailing list archive at Nabble.com.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erinu at jhu.edu  Wed Oct 23 21:54:26 2013
From: erinu at jhu.edu (erinu)
Date: Wed, 23 Oct 2013 12:54:26 -0700 (PDT)
Subject: [R] How to view un-sampled data from a randomly sampled dataset
In-Reply-To: <CACk-te0J0WXnyZLZ5AE9VrzragnwnYuTVd0i35t_1VKHyJ6uww@mail.gmail.com>
References: <1382552028571-4678887.post@n4.nabble.com>
	<CACk-te0J0WXnyZLZ5AE9VrzragnwnYuTVd0i35t_1VKHyJ6uww@mail.gmail.com>
Message-ID: <1382558066086-4678908.post@n4.nabble.com>

hi bert-
  all of the values are unique, so the random sample of everything was also
a random sample of all unique numbers.

Erin



--
View this message in context: http://r.789695.n4.nabble.com/How-to-view-un-sampled-data-from-a-randomly-sampled-dataset-tp4678887p4678908.html
Sent from the R help mailing list archive at Nabble.com.


From macqueen1 at llnl.gov  Wed Oct 23 22:24:46 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 23 Oct 2013 20:24:46 +0000
Subject: [R] Where is element 30?
In-Reply-To: <8DFB161F-4B08-4C76-B0F1-80E332AC6CE4@gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D4E27C7@PRDEXMBX-08.the-lab.llnl.gov>

oops. Thank you for the correction.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/23/13 12:30 PM, "peter dalgaard" <pdalgd at gmail.com> wrote:

>
>On Oct 23, 2013, at 20:04 , MacQueen, Don wrote:
>
>> Follow these examples:
>> 
>>> grep(5,1:10)
>> [1] 5
>> 
>>> grep(3, c(1,5,2,3,6))
>> [1] 4
>> 
>> 
>
>Don't:
>
>> grep(5,1:15)
>[1]  5 15
>
>-pd
>-- 
>Peter Dalgaard, Professor,
>Center for Statistics, Copenhagen Business School
>Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>Phone: (+45)38153501
>Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>


From pdalgd at gmail.com  Wed Oct 23 22:47:23 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 23 Oct 2013 22:47:23 +0200
Subject: [R] How to view un-sampled data from a randomly sampled dataset
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA0F15C@PA-MBX01.na.tibco.com>
References: <1382552028571-4678887.post@n4.nabble.com>
	<C5A43B73-5C95-4F48-BDF5-C422D400FA6F@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA0F15C@PA-MBX01.na.tibco.com>
Message-ID: <DDD0D37F-407A-454F-8316-CAC0C4669AA3@gmail.com>


On Oct 23, 2013, at 21:50 , William Dunlap wrote:

>> s <- sample(1:nrow(data), 40, replace=FALSE)
>> y <- data[s,]
>> x <- data[-s,]
> 
> If you don't know the size of the sample and it might be 0 then
> you have to be a bit more wordy:
>    x <- data[setdiff(seq_len(nrow(data)), s), ]
> or the uglier
>   x <- if (length(s) > 0) x else x[-s,]

Yes, I took the liberty of assuming that 40 was not 0... (Your "ugly" example seems to have a few problems though. Surely you mean: if (length(s)) data[-s,] else data ).

There's also the option of a logical index:

N <- nrow(data)
n <- 40
ix <- sample(rep(c(TRUE,FALSE), c(n, N-n)))
y <- data[ix,]
x <- data[!ix,]


> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of peter dalgaard
>> Sent: Wednesday, October 23, 2013 12:37 PM
>> To: erinu
>> Cc: r-help at r-project.org
>> Subject: Re: [R] How to view un-sampled data from a randomly sampled dataset
>> 
>> 
>> On Oct 23, 2013, at 20:13 , erinu wrote:
>> 
>>> Hi there-
>>> 
>>> I have a 150 row dataset (data). I create "y" a randomly sampled (without
>>> replacement) set number of observations (40):
>>> 
>>> y<-data[sample(1:nrow(data),40,replace=FALSE),]
>>> 
>>> I would like to make a new variable "x" that contains the leftover
>>> non-sampled 110 observations.  I am sure there is a fairly easy way to do
>>> this.
>>> 
>>> Any help would be greatly appreciated.
>>> 
>>> THANKS!
>>> 
>> 
>> Just hold on to the indices:
>> 
>> s <- sample(1:nrow(data), 40, replace=FALSE)
>> y <- data[s,]
>> x <- data[-s,]
>> 
>> -pd
>> 
>> 
>>> 
>>> 
>>> --
>>> View this message in context: http://r.789695.n4.nabble.com/How-to-view-un-
>> sampled-data-from-a-randomly-sampled-dataset-tp4678887.html
>>> Sent from the R help mailing list archive at Nabble.com.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jim at bitwrit.com.au  Wed Oct 23 23:07:32 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 24 Oct 2013 08:07:32 +1100
Subject: [R] Loop for R
In-Reply-To: <1382525509.56029.YahooMailNeo@web194003.mail.sg3.yahoo.com>
References: <1382525509.56029.YahooMailNeo@web194003.mail.sg3.yahoo.com>
Message-ID: <52683A94.4020702@bitwrit.com.au>

On 10/23/2013 09:51 PM, THIRU MANIAM wrote:
> Hi,
> I need kind help from you. I'm doing my assignment in IR and need to do script in R programming and using R studio tool.I don't have any knowledge in R but learning by Youtube. After so long,i successfully came out with below script for precision 10(P@)
> But i don know how to do loop for 105 system. below script was for 5 system but i define it  one by one.Can you help me ?
>
Hi Thiru,
Anyone who can learn statistics on YouTube instead of watching cat 
videos deserves at least a hint, even for homework.

You want to loop over systems as you have done starting with this:

   ###########################
   #start    system Number 1#
   ##########################
   systemNumber=1
   systemName="input.acsys9mw0"
   systemFilePath="D:\\UM 
Studies_Master_MCS\\Semester_2\\WMGA6320_Special Topics In 
IS\\Group_Project\\input.acsys9mw0"

Without looking too carefully at the code, I see the three things above 
that differentiate the systems. I assume that your systems are numbered 
1 to 105. Somewhere there will be the 105 system names that you want to 
run. If they happen to be in a character vector, you could think about 
picking them off one by one using the system number.

systemFilePath looks the same every time except for the systemName 
tacked on the end. Think about the paste function.

So, if you can index your loop with systemNumber, set systemName using 
that number and paste systemName onto a constant file path, I think 
you've got it. All this without having to watch me talking to a video 
camera.

Jim


From hill0093 at umn.edu  Wed Oct 23 23:51:15 2013
From: hill0093 at umn.edu (Hurr)
Date: Wed, 23 Oct 2013 14:51:15 -0700 (PDT)
Subject: [R] labeling abscissa using a function of the plotted scale
In-Reply-To: <273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>
References: <1381510115791-4678075.post@n4.nabble.com>
	<273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>
Message-ID: <1382565075173-4678917.post@n4.nabble.com>

I studied the "Add an Axis to a Plot" document but 
I can't figure out where the 1/trueScaleValue goes.
Would someone help me?





--
View this message in context: http://r.789695.n4.nabble.com/labeling-abscissa-using-a-function-of-the-plotted-scale-tp4678075p4678917.html
Sent from the R help mailing list archive at Nabble.com.


From jonsleepy at gmail.com  Thu Oct 24 01:36:35 2013
From: jonsleepy at gmail.com (Jon BR)
Date: Wed, 23 Oct 2013 19:36:35 -0400
Subject: [R] data frame pointers?
Message-ID: <CA+d7zeTgom8WDBndBfYmcRa6-49qxWD76S+SuNCPQLnkmDDNdQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/dc862c15/attachment.pl>

From dwinsemius at comcast.net  Thu Oct 24 02:24:19 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 23 Oct 2013 17:24:19 -0700
Subject: [R] data frame pointers?
In-Reply-To: <CA+d7zeTgom8WDBndBfYmcRa6-49qxWD76S+SuNCPQLnkmDDNdQ@mail.gmail.com>
References: <CA+d7zeTgom8WDBndBfYmcRa6-49qxWD76S+SuNCPQLnkmDDNdQ@mail.gmail.com>
Message-ID: <317FAB66-D9A7-4B07-96E1-2A944EA753D4@comcast.net>


On Oct 23, 2013, at 4:36 PM, Jon BR wrote:

> Hello,
>    I've been running several programs in the unix shell, and it's time to
> combine results from several different pipelines.  I've been writing shell
> scripts with heavy use of awk and grep to make big text files, but I'm
> thinking it would be better to have all my data in one big structure in R
> so that I can query whatever attributes I like, and print several
> corresponding tables to separate files.
> 
> I haven't used R in years, so I was hoping somebody might be able to
> suggest a solution or combinatin of functions that could help me get
> oriented..
> 
> Right now, I can import my data into a data frame that looks like this:
> 
> df <-
> data.frame(case=c("case_1","case_1","case_2","case_3"),gene=c("gene1","gene1","gene1","gene2"),issue=c("nsyn","amp","del","UTR"))
>> df
>    case  gene issue
> 1 case_1 gene1  nsyn
> 2 case_1 gene1   amp
> 3 case_2 gene1   del
> 4 case_3 gene2   UTR
> 
> 
> I'd like to cook up some combination of functions/scripting that can
> convert a table like df to produce a list or a data frame/ matrix that
> looks like df2:
> 
>> df2
>        case_1 case_2 case_3
> gene1 nsyn,amp    del      0
> gene2        0      0    UTR
> 
> I can build df2 manually, like this:
> df2
> <-data.frame(case_1=c("nsyn,amp","0"),case_2=c("del","0"),case_3=c("0","UTR"))
> rownames(df2)<-c("gene1","gene2")

Factors will be a hassle:

 df <-
data.frame(case=c("case_1","case_1","case_2","case_3"), gene=c("gene1","gene1","gene1","gene2"), issue=c("nsyn","amp","del","UTR"), stringsAsFactors=FALSE)
df

with( df, matrix( tapply(issue, list(gene, case), list) ,
                   nrow=length(unique(gene)),ncol=length(unique(case)) )
      )

     [,1]        [,2]  [,3] 
[1,] Character,2 "del" NA   
[2,] NA          NA    "UTR"

> dmat[1,1]
[[1]]
[1] "nsyn" "amp" 

> as.data.frame(dmat)
         V1  V2  V3
1 nsyn, amp del  NA
2        NA  NA UTR


> 
> but obviously do not want to do this by hand; I want R to generate df2 from
> df.
> 
> Any pointers/ideas would be most welcome!
> 
> Thanks,
> Jonathan
> 
> 	[[alternative HTML version deleted]]

R is a plain text mailing list. Old school, admittedly,  but much better for coding questions. Surely an awk user can appreciate the wisdom of that request?

-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Oct 24 02:39:16 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 23 Oct 2013 17:39:16 -0700
Subject: [R] data frame pointers?
In-Reply-To: <317FAB66-D9A7-4B07-96E1-2A944EA753D4@comcast.net>
References: <CA+d7zeTgom8WDBndBfYmcRa6-49qxWD76S+SuNCPQLnkmDDNdQ@mail.gmail.com>
	<317FAB66-D9A7-4B07-96E1-2A944EA753D4@comcast.net>
Message-ID: <3C94419C-2E22-4820-93B5-CCA698E3A47B@comcast.net>


On Oct 23, 2013, at 5:24 PM, David Winsemius wrote:

> 
> On Oct 23, 2013, at 4:36 PM, Jon BR wrote:
> 
>> Hello,
>>   I've been running several programs in the unix shell, and it's time to
>> combine results from several different pipelines.  I've been writing shell
>> scripts with heavy use of awk and grep to make big text files, but I'm
>> thinking it would be better to have all my data in one big structure in R
>> so that I can query whatever attributes I like, and print several
>> corresponding tables to separate files.
>> 
>> I haven't used R in years, so I was hoping somebody might be able to
>> suggest a solution or combinatin of functions that could help me get
>> oriented..
>> 
>> Right now, I can import my data into a data frame that looks like this:
>> 
>> df <-
>> data.frame(case=c("case_1","case_1","case_2","case_3"),gene=c("gene1","gene1","gene1","gene2"),issue=c("nsyn","amp","del","UTR"))
>>> df
>>   case  gene issue
>> 1 case_1 gene1  nsyn
>> 2 case_1 gene1   amp
>> 3 case_2 gene1   del
>> 4 case_3 gene2   UTR
>> 
>> 
>> I'd like to cook up some combination of functions/scripting that can
>> convert a table like df to produce a list or a data frame/ matrix that
>> looks like df2:
>> 
>>> df2
>>       case_1 case_2 case_3
>> gene1 nsyn,amp    del      0
>> gene2        0      0    UTR
>> 
>> I can build df2 manually, like this:
>> df2
>> <-data.frame(case_1=c("nsyn,amp","0"),case_2=c("del","0"),case_3=c("0","UTR"))
>> rownames(df2)<-c("gene1","gene2")
> 
> Factors will be a hassle:
> 
> df <-
> data.frame(case=c("case_1","case_1","case_2","case_3"), gene=c("gene1","gene1","gene1","gene2"), issue=c("nsyn","amp","del","UTR"), stringsAsFactors=FALSE)

Note also that stringsAsFactors can be set globally with options as well as during input functions with any of hte cousins of read.table.


> df
> 
> with( df, matrix( tapply(issue, list(gene, case), list) ,
>                   nrow=length(unique(gene)),ncol=length(unique(case)) )
>      )
> 
>     [,1]        [,2]  [,3] 
> [1,] Character,2 "del" NA   
> [2,] NA          NA    "UTR"
> 
>> dmat[1,1]
> [[1]]
> [1] "nsyn" "amp" 
> 
>> as.data.frame(dmat)
>         V1  V2  V3
> 1 nsyn, amp del  NA
> 2        NA  NA UTR
> 

It's possible that coming back to R after many years you are not familiar with data.table. It's particularly well suited for large text files. It's syntax with argumets to "[" is quite different.

> dt <- data.table(df)
# To make a list in each category you would need to supply a "doubly `list`-ed" arguemtn to "j".

> dt[ , list(list(issue)), by=c("gene", 'case') ]
    gene   case       V1
1: gene1 case_1 nsyn,amp
2: gene1 case_2      del
3: gene2 case_3      UTR

> dt[ , list(issue), by=c("gene", 'case') ]
    gene   case issue
1: gene1 case_1  nsyn
2: gene1 case_1   amp
3: gene1 case_2   del
4: gene2 case_3   UTR



> 
>> 
>> but obviously do not want to do this by hand; I want R to generate df2 from
>> df.
>> 
>> Any pointers/ideas would be most welcome!
>> 
>> Thanks,
>> Jonathan
>> 
>> 	[[alternative HTML version deleted]]
> 
> R is a plain text mailing list. Old school, admittedly,  but much better for coding questions. Surely an awk user can appreciate the wisdom of that request?
> 
> -- 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From halim10-fes at sust.edu  Thu Oct 24 01:03:33 2013
From: halim10-fes at sust.edu (halim10-fes)
Date: Thu, 24 Oct 2013 06:03:33 +0700
Subject: [R] How to draw figures in a graph?
In-Reply-To: <20131023080028.GC4253@slingshot.co.nz>
References: <0765308CD028654885F30322557308D80E1DF378@NYCSM0208.rth.ad.rothschild.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A409@GOLD.corp.lgc-group.com>
	<CABdHhvFOYv-0A5W5M+-f3EyB_yvKiEeKTWnjf-7N75znn90+YA@mail.gmail.com>
	<20131022144358.M19935@sust.edu>
	<20131023080028.GC4253@slingshot.co.nz>
Message-ID: <20131023230024.M28624@sust.edu>

Hi Patric,

Thanks for your explanation and suggestions. I didn't know that it might 
happen. Sorry about that. A good lesson for the future post.

Thanks again.

Halim




On Wed, 23 Oct 2013 21:00:28 +1300, Patrick Connolly wrote
> This is a request to anyone who starts a new subject to begin with a
> new message and NOT reply to an existing one.  If your mail client is
> any good, it's very simple to set up an alias (mine is simply 'r') so
> that the tedious task of typing 'r-help at stat.math.ethz.ch' is
> unnecessary and it's quicker than scrolling through an address book.
> It's also quicker than deleting the previous subject.
> 
> Most mornings, I have as many as a hundred messages mostly from R-
> help and it's very useful to have them threaded.  However, the usefulness
> of threading is lost when posters reply to a message and then change
> the subject instead of creating a new message.
> 
> People who don't have a mail client that can display email in threads
> are probably unaware that this sort of thing can happen in ones that 
> do:
> 
>     37 N   25 Jan Luis Silva              ( 34) [R] plot/screen
>     38 N   25 Jan Uwe Ligges              ( 55) `-> 
>     39 N   25 Jan Fernando Henrique Ferra ( 20) [R] Plotting 
> coloured histograms ->  40 N   26 Jan Mohamed A. Kerasha      ( 12)
>  |->[R] Distributions.    41 N   26 Jan ripley at stats.ox.ac.uk   ( 26)
>  | |->    42     26 Jan Qin Xin                 (  9) | `->[R] how 
> could I add legends    43     27 Jan Ko-Kang Kevin Wang      ( 31) | 
>   `->    44 N   26 Jan Remigijus Lapinskas     ( 32) |->Re: [R] 
> Plotting coloured his    45 N   26 Jan Damon Wischik           (125) 
> `->     46 N   25 Jan Rex_Bryan at urscorp.com   ( 10) [R] plotting 
> primatives, ellipse    47 N   25 Jan Uwe Ligges              ( 19) `-
> >
> 
> As Martin Maechler explained some time ago, it also screws up the
> archives for a similar reason.  What's more, you run the risk of
> having your message deleted if it's in a thread that is being deleted
> for a reason quite unrelated to your question, so fewer people might
> see it.
> 
> Your cooperation will be greatly appreciated.
> 
> -- 
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.      
___    Patrick Connolly    {~._.~}                   Great minds discuss ideas     
_( Y )_  	         Average minds discuss events 
> (:_~*~_:)                  Small minds discuss people  
>  (_)-(_)  	                      ..... Eleanor Roosevelt
> 	  
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.


---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From carl at witthoft.com  Wed Oct 23 21:18:40 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Wed, 23 Oct 2013 12:18:40 -0700 (PDT)
Subject: [R] raster package: merge/mosaic
In-Reply-To: <trinity-27d6aac2-4879-467b-8d6d-25caaa19ffff-1382539217132@3capp-gmx-bs36>
References: <trinity-27d6aac2-4879-467b-8d6d-25caaa19ffff-1382539217132@3capp-gmx-bs36>
Message-ID: <1382555920572-4678899.post@n4.nabble.com>

According to ?merge,  you could try adjusting the default value of the
"tolerance" argument.



Nora Ernst wrote
> I'm working with raster data (satellite imagery) and the raster package.
> The
>    idea is to merge two raster files that are partially overlaping, do
> have the
>    same coordinate system and resolution but not the same origin. As
> expected,
>    the functions mosaic(r1,r2) as well as merge(r1,r2)) give the error
> message:
> 
> Error in compareRaster(x, extent = FALSE, rowcol = FALSE, orig = TRUE,  : 
>   different origin
> 
> 
>> origin(r1)
> [1] 5.582522e-05 1.124150e-03
>> origin(r2)
> [1]  0.001054868 -0.001124150
> 
> 
>    Can  anyone tell me how it is possible to merge rasters with different
>    origin?





--
View this message in context: http://r.789695.n4.nabble.com/raster-package-merge-mosaic-tp4678890p4678899.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Thu Oct 24 03:05:41 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 23 Oct 2013 18:05:41 -0700
Subject: [R] labeling abscissa using a function of the plotted scale
In-Reply-To: <1382565075173-4678917.post@n4.nabble.com>
References: <1381510115791-4678075.post@n4.nabble.com>
	<273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>
	<1382565075173-4678917.post@n4.nabble.com>
Message-ID: <58de215e-0e9f-4aa8-ade5-bcfd4700bd7a@email.android.com>

Not without a reproducible example. You can Google for suggestions about how to do that, with one result being [1].

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Hurr <hill0093 at umn.edu> wrote:
>I studied the "Add an Axis to a Plot" document but 
>I can't figure out where the 1/trueScaleValue goes.
>Would someone help me?
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/labeling-abscissa-using-a-function-of-the-plotted-scale-tp4678075p4678917.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Oct 24 03:50:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 23 Oct 2013 18:50:57 -0700 (PDT)
Subject: [R] data frame pointers?
In-Reply-To: <CA+d7zeTgom8WDBndBfYmcRa6-49qxWD76S+SuNCPQLnkmDDNdQ@mail.gmail.com>
References: <CA+d7zeTgom8WDBndBfYmcRa6-49qxWD76S+SuNCPQLnkmDDNdQ@mail.gmail.com>
Message-ID: <1382579457.7928.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,

You may try:
library(reshape2)
df <-
data.frame(case=c("case_1","case_1","case_2","case_3"), gene=c("gene1","gene1","gene1","gene2"), issue=c("nsyn","amp","del","UTR"), stringsAsFactors=FALSE)
res <- dcast(df,gene~case,value.var="issue",list)
?res
#?? gene??? case_1 case_2 case_3
#1 gene1 nsyn, amp??? del?????? 
#2 gene2???????????????????? UTR


A.K.


On Wednesday, October 23, 2013 7:38 PM, Jon BR <jonsleepy at gmail.com> wrote:
Hello,
? ? I've been running several programs in the unix shell, and it's time to
combine results from several different pipelines.? I've been writing shell
scripts with heavy use of awk and grep to make big text files, but I'm
thinking it would be better to have all my data in one big structure in R
so that I can query whatever attributes I like, and print several
corresponding tables to separate files.

I haven't used R in years, so I was hoping somebody might be able to
suggest a solution or combinatin of functions that could help me get
oriented..

Right now, I can import my data into a data frame that looks like this:

df <-
data.frame(case=c("case_1","case_1","case_2","case_3"),gene=c("gene1","gene1","gene1","gene2"),issue=c("nsyn","amp","del","UTR"))
> df
? ? case? gene issue
1 case_1 gene1? nsyn
2 case_1 gene1?  amp
3 case_2 gene1?  del
4 case_3 gene2?  UTR


I'd like to cook up some combination of functions/scripting that can
convert a table like df to produce a list or a data frame/ matrix that
looks like df2:

> df2
? ? ? ? case_1 case_2 case_3
gene1 nsyn,amp? ? del? ? ? 0
gene2? ? ? ? 0? ? ? 0? ? UTR

I can build df2 manually, like this:
df2
<-data.frame(case_1=c("nsyn,amp","0"),case_2=c("del","0"),case_3=c("0","UTR"))
rownames(df2)<-c("gene1","gene2")

but obviously do not want to do this by hand; I want R to generate df2 from
df.

Any pointers/ideas would be most welcome!

Thanks,
Jonathan

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jonsleepy at gmail.com  Thu Oct 24 04:44:40 2013
From: jonsleepy at gmail.com (Jon BR)
Date: Wed, 23 Oct 2013 22:44:40 -0400
Subject: [R] data frame pointers?
In-Reply-To: <1382579457.7928.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <CA+d7zeTgom8WDBndBfYmcRa6-49qxWD76S+SuNCPQLnkmDDNdQ@mail.gmail.com>
	<1382579457.7928.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CA+d7zeSMyAJsNrv31Ood8bVv+BP=7eJjKqHX6+wcOWXUtFdKbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/6710435a/attachment.pl>

From smartpink111 at yahoo.com  Thu Oct 24 05:12:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 23 Oct 2013 20:12:08 -0700 (PDT)
Subject: [R] data frame pointers?
In-Reply-To: <1382583891.91956.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CA+d7zeTgom8WDBndBfYmcRa6-49qxWD76S+SuNCPQLnkmDDNdQ@mail.gmail.com>	<1382579457.7928.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CA+d7zeSMyAJsNrv31Ood8bVv+BP=7eJjKqHX6+wcOWXUtFdKbA@mail.gmail.com>
	<1382583891.91956.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1382584328.37521.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,

Better would be:
res1 <- dcast(df,gene~case,value.var="issue",paste,collapse=",",fill="0") 

str(res1)
#'data.frame':??? 2 obs. of? 4 variables:
# $ gene? : chr? "gene1" "gene2"
# $ case_1: chr? "nsyn,amp" "0"
# $ case_2: chr? "del" "0"
# $ case_3: chr? "0" "UTR"

?write.table(res1,"test.txt",sep="\t",quote=FALSE,row.names=FALSE)


A.K.


On , arun <smartpink111 at yahoo.com> wrote:
Hi Jonathan,If you look at the str()
?str(res)
'data.frame':??? 2 obs. of? 4 variables:
?$ gene? : chr? "gene1" "gene2"
?$ case_1:List of 2
? ..$ : chr? "nsyn" "amp"
? ..$ : chr 
?$ case_2:List of 2
? ..$ : chr "del"
? ..$ : chr 
?$ case_3:List of 2
? ..$ : chr 
? ..$ : chr "UTR"

In this case, 

capture.output(res,file="test.txt") #should work

But, if you wanted to use ?write.table() and also to substitute zeros, perhaps:


res[,2:4] <- lapply(res[,2:4],function(x) {x1 <-unlist(lapply(x,paste,collapse=","));x1[x1==""] <- 0; x1})


?str(res)
#'data.frame':??? 2 obs. of? 4 variables:
# $ gene? : chr? "gene1" "gene2"
# $ case_1: chr? "nsyn,amp" "0"
# $ case_2: chr? "del" "0"
# $ case_3: chr? "0" "UTR"

?write.table(res,"test.txt",sep="\t",quote=FALSE,row.names=FALSE)


A.K.





On Wednesday, October 23, 2013 10:44 PM, Jon BR <jonsleepy at gmail.com> wrote:

Hi Arun,
? ?Your suggestion using dcast is simple and worked splendidly! ?Unfortunately, the resulting data frame does not play nicely with write.table.

Any idea how to could print this out to a tab-delimited text file, perhaps substituting zeros in for the empty cells?

See the error below:
> write.table(res,"test.txt")
Error in .External2(C_writetable, x, file, nrow(x), p, rnames, sep, eol, ?:?
? unimplemented type 'list' in 'EncodeElement'


Best,
Jonathan






On Wed, Oct 23, 2013 at 9:50 PM, arun <smartpink111 at yahoo.com> wrote:

HI,
>
>You may try:
>library(reshape2)
>df <-
>data.frame(case=c("case_1","case_1","case_2","case_3"), gene=c("gene1","gene1","gene1","gene2"), issue=c("nsyn","amp","del","UTR"), stringsAsFactors=FALSE)
>res <- dcast(df,gene~case,value.var="issue",list)
>?res
>#?? gene??? case_1 case_2 case_3
>#1 gene1 nsyn, amp??? del??????
>#2 gene2???????????????????? UTR
>
>
>A.K.
>
>
>
>On Wednesday, October 23, 2013 7:38 PM, Jon BR <jonsleepy at gmail.com> wrote:
>Hello,
>? ? I've been running several programs in the unix shell, and it's time to
>combine results from several different pipelines.? I've been writing shell
>scripts with heavy use of awk and grep to make big text files, but I'm
>thinking it would be better to have all my data in one big structure in R
>so that I can query whatever attributes I like, and print several
>corresponding tables to separate files.
>
>I haven't used R in years, so I was hoping somebody might be able to
>suggest a solution or combinatin of functions that could help me get
>oriented..
>
>Right now, I can import my data into a data frame that looks like this:
>
>df <-
>data.frame(case=c("case_1","case_1","case_2","case_3"),gene=c("gene1","gene1","gene1","gene2"),issue=c("nsyn","amp","del","UTR"))
>> df
>? ? case? gene issue
>1 case_1 gene1? nsyn
>2 case_1 gene1? ?amp
>3 case_2 gene1? ?del
>4 case_3 gene2? ?UTR
>
>
>I'd like to cook up some combination of functions/scripting that can
>convert a table like df to produce a list or a data frame/ matrix that
>looks like df2:
>
>> df2
>? ? ? ? case_1 case_2 case_3
>gene1 nsyn,amp? ? del? ? ? 0
>gene2? ? ? ? 0? ? ? 0? ? UTR
>
>I can build df2 manually, like this:
>df2
><-data.frame(case_1=c("nsyn,amp","0"),case_2=c("del","0"),case_3=c("0","UTR"))
>rownames(df2)<-c("gene1","gene2")
>
>but obviously do not want to do this by hand; I want R to generate df2 from
>df.
>
>Any pointers/ideas would be most welcome!
>
>Thanks,
>Jonathan
>
>??? [[alternative HTML version deleted]]
>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


From hill0093 at umn.edu  Thu Oct 24 04:49:55 2013
From: hill0093 at umn.edu (Hurr)
Date: Wed, 23 Oct 2013 19:49:55 -0700 (PDT)
Subject: [R] labeling abscissa using a function of the plotted scale
In-Reply-To: <58de215e-0e9f-4aa8-ade5-bcfd4700bd7a@email.android.com>
References: <1381510115791-4678075.post@n4.nabble.com>
	<273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>
	<1382565075173-4678917.post@n4.nabble.com>
	<58de215e-0e9f-4aa8-ade5-bcfd4700bd7a@email.android.com>
Message-ID: <1382582995862-4678927.post@n4.nabble.com>

Sorry, I wasn't aware that it was that difficult.
Here is the example scatter plot data:
xvalue,yvalue
1,9
2,3
3,4
4,7
5,2
6,5
7,3
8,6
Please show me how to label the x axis with 1/xvalue.
Hopefully, R plotter takes care of spacing, but maybe not.
Thanks




--
View this message in context: http://r.789695.n4.nabble.com/labeling-abscissa-using-a-function-of-the-plotted-scale-tp4678075p4678927.html
Sent from the R help mailing list archive at Nabble.com.


From jim at bitwrit.com.au  Thu Oct 24 07:51:42 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 24 Oct 2013 16:51:42 +1100
Subject: [R] labeling abscissa using a function of the plotted scale
In-Reply-To: <1382582995862-4678927.post@n4.nabble.com>
References: <1381510115791-4678075.post@n4.nabble.com>	<273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>	<1382565075173-4678917.post@n4.nabble.com>	<58de215e-0e9f-4aa8-ade5-bcfd4700bd7a@email.android.com>
	<1382582995862-4678927.post@n4.nabble.com>
Message-ID: <5268B56E.4010000@bitwrit.com.au>

On 10/24/2013 01:49 PM, Hurr wrote:
> Sorry, I wasn't aware that it was that difficult.
> Here is the example scatter plot data:
> xvalue,yvalue
> 1,9
> 2,3
> 3,4
> 4,7
> 5,2
> 6,5
> 7,3
> 8,6
> Please show me how to label the x axis with 1/xvalue.
> Hopefully, R plotter takes care of spacing, but maybe not.

Hi Hurr,
how about:

xvalue<-1:8
yvalue<-c(9,3,4,7,2,5,3,6)
plot(xvalue,yvalue,xaxt="n")
axis(1,at=xvalue,labels=round(1/xvalue,2))

Jim


From byron_dom at yahoo.com  Thu Oct 24 01:39:16 2013
From: byron_dom at yahoo.com (Byron Dom)
Date: Wed, 23 Oct 2013 16:39:16 -0700 (PDT)
Subject: [R] How can I use a script "l" (LaTeX \ell) in mathematical
	annotation of plots?
Message-ID: <1382571556.79906.YahooMailNeo@web142806.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/d6c2fb62/attachment.pl>

From hughesadam87 at gmail.com  Thu Oct 24 01:02:39 2013
From: hughesadam87 at gmail.com (Adam Hughes)
Date: Wed, 23 Oct 2013 19:02:39 -0400
Subject: [R] Scripting call to R-Studio compile PDF
In-Reply-To: <4E341CF8-D07E-454B-99AE-54C0BB2355A9@comcast.net>
References: <CAMHV+dCmvuv4o6xATuFm_efDf1_1_wBJone+ytpzCZ9OujMWHw@mail.gmail.com>
	<CAMHV+dCg3u-=us-6DNMr=WDiZjarObmBHUTQfmtXm4kzoK8U-A@mail.gmail.com>
	<4E341CF8-D07E-454B-99AE-54C0BB2355A9@comcast.net>
Message-ID: <CAMHV+dBmUW0MGvmtWiVtHBJkogGcmO3_N92cprMXmh9h4O0e9A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131023/008ba9d1/attachment.pl>

From michael.jensen at oliverwyman.com  Wed Oct 23 21:14:27 2013
From: michael.jensen at oliverwyman.com (smugg55)
Date: Wed, 23 Oct 2013 12:14:27 -0700 (PDT)
Subject: [R] Function not working as I'd like
In-Reply-To: <1382538313810-4678878.post@n4.nabble.com>
References: <1382538313810-4678878.post@n4.nabble.com>
Message-ID: <1382555667221-4678898.post@n4.nabble.com>

Could you please show me what the code should be then? 



--
View this message in context: http://r.789695.n4.nabble.com/Function-not-working-as-I-d-like-tp4678878p4678898.html
Sent from the R help mailing list archive at Nabble.com.


From long_vo_hai at yahoo.com.vn  Thu Oct 24 04:53:37 2013
From: long_vo_hai at yahoo.com.vn (Long Vo)
Date: Wed, 23 Oct 2013 19:53:37 -0700 (PDT)
Subject: [R] installing package from source
Message-ID: <1382583217853-4678928.post@n4.nabble.com>

Hi R users,
Currently I want to fit a FIGARCH model to a dataset. The only package that
allow for it that I could find is fGarch. However it seems that the FIGARCH
model class fitting of this package has been moved to Oxmetrics. I tried to
install the old versions of it using 'tar.gz' files from CRAN archive 
http://cran.r-project.org/src/contrib/Archive/fGarch/
<http://cran.r-project.org/src/contrib/Archive/fGarch/>   but not sure how
it works. I tried

install.packages("myfilepath\fGarch_260.71.tar.gz", repos = NULL,
type="source")

And received this error:

Warning: invalid package './I:_R filesGarch_260.71.tar.gz'
Error: ERROR: no packages specified
Warning messages:
1: running command '"I:/01_RFI~1/INSTAL~1/R-30~1.1/bin/i386/R" CMD INSTALL
-l "I:\01_R files\installment\R-3.0.1\library" "./I:_R files
Garch_260.71.tar.gz"' had status 1 
2: In install.packages("I:\001_R files\fGarch_260.71.tar.gz", repos = NULL, 
:
  installation of package ?./I:_R filesGarch_260.71.tar.gz? had non-zero
exit status

Any helps on this?

Regards,
Long



--
View this message in context: http://r.789695.n4.nabble.com/installing-package-from-source-tp4678928.html
Sent from the R help mailing list archive at Nabble.com.


From rizalsyamsul at gmail.com  Thu Oct 24 06:39:56 2013
From: rizalsyamsul at gmail.com (Syamsul Rizal)
Date: Thu, 24 Oct 2013 11:39:56 +0700
Subject: [R]  Variable operations
Message-ID: <CAO=CxemaiJf_xet=fDJ8Z+xSFpVYa7jBywPf2=vydM+dtf+tFg@mail.gmail.com>

Dear All:

I have

v = c(xy, xy^2, z)

dotv = sum(v*v)

I hope, I have the following result:

dotv = x^2*y^2 + x^2*y^4 + z^2  (still in variable x, y and z, not
numeric result)

How to make simple script, so that I have: dotv = x^2*y^2 + x^2*y^4 + z^2

Thanks a lot for your help.

Best regards, Rizal


From xie at yihui.name  Thu Oct 24 08:28:29 2013
From: xie at yihui.name (Yihui Xie)
Date: Thu, 24 Oct 2013 01:28:29 -0500
Subject: [R] Scripting call to R-Studio compile PDF
In-Reply-To: <CAMHV+dBmUW0MGvmtWiVtHBJkogGcmO3_N92cprMXmh9h4O0e9A@mail.gmail.com>
References: <CAMHV+dCmvuv4o6xATuFm_efDf1_1_wBJone+ytpzCZ9OujMWHw@mail.gmail.com>
	<CAMHV+dCg3u-=us-6DNMr=WDiZjarObmBHUTQfmtXm4kzoK8U-A@mail.gmail.com>
	<4E341CF8-D07E-454B-99AE-54C0BB2355A9@comcast.net>
	<CAMHV+dBmUW0MGvmtWiVtHBJkogGcmO3_N92cprMXmh9h4O0e9A@mail.gmail.com>
Message-ID: <CANROs4ekncC5PH35vVSwt=-fSTc6p39NhHi3skGMdk+zMorVbg@mail.gmail.com>

Yes, that is pretty much it. Setting the options useDingbats or
concordance is optional. You may or may not really need them. What is
essential is the knit() function.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Wed, Oct 23, 2013 at 6:02 PM, Adam Hughes <hughesadam87 at gmail.com> wrote:
> Thanks for the help guys.  Sorry, I will not post further RStudio questions
> here.  Yihui, thanks for the tip.  Looks like these commands would do:
>
> grDevices::pdf.options(useDingbats = FALSE); require(knitr);
> opts_knit$set(concordance = TRUE); knit('filename.rnw',
> encoding='UTF-8')
>
>
> pdflatex filename.tex
>
>
> evince filename.pdf
>


From halim10-fes at sust.edu  Thu Oct 24 07:01:46 2013
From: halim10-fes at sust.edu (halim10-fes)
Date: Thu, 24 Oct 2013 12:01:46 +0700
Subject: [R] raster package: merge/mosaic
In-Reply-To: <1382555920572-4678899.post@n4.nabble.com>
References: <trinity-27d6aac2-4879-467b-8d6d-25caaa19ffff-1382539217132@3capp-gmx-bs36>
	<1382555920572-4678899.post@n4.nabble.com>
Message-ID: <20131024050146.M87771@sust.edu>

Hi,

With the 'merge' function using different tolerance level, I've come up with a 
solution.

For e.g. consider r1 and r2 as two raster layers, attributes are as follows:

>r1 <- raster(xmx=-150, ymn=60, ncols=30, nrows=20)
>r1[]<-1:ncell(r1)
>r1

class       : RasterLayer 
dimensions  : 20, 30, 600  (nrow, ncol, ncell)
resolution  : 1, 1.5  (x, y)
extent      : -180, -150, 60, 90  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 
data source : in memory
names       : layer 
values      : 1, 600  (min, max)


>origin(r1)
[1] 0 0
 
>r2 <- raster(xmn=-100, xmx=-50, ymx=50, ymn=30,ncols=25,nrows=30)
>res(r2)<-c(xres(r1),yres(r1))
>r2[]<-1:ncell(r2)
> r2

class       : RasterLayer 
dimensions  : 13, 50, 650  (nrow, ncol, ncell)
resolution  : 1, 1.5  (x, y)
extent      : -100, -50, 30.5, 50  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 
data source : in memory
names       : layer 
values      : 1, 650  (min, max)

>origin(r2)
[1] 0.0 0.5

If we try to merge r1 and r2,

>merge(r1,r2)
Error in compareRaster(x, extent = FALSE, rowcol = FALSE, orig = TRUE,  : 
  different origin

So, they have different origins. Here the default tolerance value was = 0.05, 
I've changed it to 0.5 after a few trial and error.

So, finally,

>merge(r1,r2,tolerance=0.5)

class       : RasterLayer 
dimensions  : 40, 130, 5200  (nrow, ncol, ncell)
resolution  : 1, 1.5  (x, y)
extent      : -180, -50, 30.5, 90.5  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 
data source : in memory
names       : layer 
values      : 1, 650  (min, max)

Worked! 

Hope this might help you to solve your problem. And also see what others 
say...

Regards,

Halim

---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.


On Wed, 23 Oct 2013 12:18:40 -0700 (PDT), Carl Witthoft wrote
> According to ?merge,  you could try adjusting the default value of 
> the "tolerance" argument.
> 
> Nora Ernst wrote
> > I'm working with raster data (satellite imagery) and the raster package.
> > The
> >    idea is to merge two raster files that are partially overlaping, do
> > have the
> >    same coordinate system and resolution but not the same origin. As
> > expected,
> >    the functions mosaic(r1,r2) as well as merge(r1,r2)) give the error
> > message:
> > 
> > Error in compareRaster(x, extent = FALSE, rowcol = FALSE, orig = TRUE,  : 
> >   different origin
> > 
> > 
> >> origin(r1)
> > [1] 5.582522e-05 1.124150e-03
> >> origin(r2)
> > [1]  0.001054868 -0.001124150
> > 
> > 
> >    Can  anyone tell me how it is possible to merge rasters with different
> >    origin?
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/raster-
> package-merge-mosaic-tp4678890p4678899.html Sent from the R help 
> mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From Olivier.Eterradossi at mines-ales.fr  Thu Oct 24 08:54:21 2013
From: Olivier.Eterradossi at mines-ales.fr (Olivier Eterradossi)
Date: Thu, 24 Oct 2013 06:54:21 +0000
Subject: [R] problem with ecdf : "missing C_R_approxfun" message
Message-ID: <D2481C4481A28E4DB7720AE86BE937616DC2AA8C@SRV-AME-EX2KX.personnel.mines-ales.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/5ab2345a/attachment.pl>

From Olivier.Eterradossi at mines-ales.fr  Thu Oct 24 09:16:32 2013
From: Olivier.Eterradossi at mines-ales.fr (Olivier Eterradossi)
Date: Thu, 24 Oct 2013 07:16:32 +0000
Subject: [R] TR: problem with ecdf : "missing C_R_approxfun" message
Message-ID: <D2481C4481A28E4DB7720AE86BE937616DC2BAB0@SRV-AME-EX2KX.personnel.mines-ales.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/627f7231/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Oct 24 10:04:01 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Oct 2013 09:04:01 +0100
Subject: [R] problem with ecdf : "missing C_R_approxfun" message
In-Reply-To: <D2481C4481A28E4DB7720AE86BE937616DC2AA8C@SRV-AME-EX2KX.personnel.mines-ales.fr>
References: <D2481C4481A28E4DB7720AE86BE937616DC2AA8C@SRV-AME-EX2KX.personnel.mines-ales.fr>
Message-ID: <5268D471.8030603@stats.ox.ac.uk>

On 24/10/2013 07:54, Olivier Eterradossi wrote:
> Hi list,
>
> In June 2013, using R.2.15.1 (i386) on Windows 7, I calculated a set of ecdf which I stored in lists of records having a "size.ecdf" field, with following structure :

Note that R 2.15.1 was not current even then.

> [skip previous structure...]
> $ size.ecdf   :function (v)
>    ..- attr(*, "class")= chr [1:3] "ecdf" "stepfun" "function"
>    ..- attr(*, "call")=length 2 ecdf(test.moms[, "m.pxs"])
>    .. ..- attr(*, "srcref")=Class 'srcref'  atomic [1:8] 12 1 12 36 1 36 12 12
>    .. .. .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile' <environment: 0x07d7b3b0>
> [skip following structure...]
>
> In September I upgraded to R.3.0.1 under the same OS

And R 3.0.2 has been out for nearly a month now: see the posting guide.

> I need to use my previously recorded ecdfs again, and try to plot one  as in :
>
>> plot(first.list[[1]]$size.ecdf,col=couleurs[1],main="first ecdf")
> Which returns :
> Erreur dans x(0.5 * (ti.l + ti.r)) : objet 'C_R_approxfun' introuvable
> Sorry it's in French  ;-)  , it translates to "error in x(0.5 * (ti.l + ti.r)) : missing object 'C_R_approxfun' "
>
> The same message prints when trying to use other ecdf methods, or other records in my lists.
>
> I first searched the help and archives without success, here are four questions I cannot answer :
>
> What is this "C_R_approxfun" object and what is it intended to do ?
> What may have caused it is missing now (and was not in June) ?
> Does this mean that I should have recorded other useful parameters in June (such as environment parameters) ?
> Or anything else I cannot guess ?
>
> Thanks for helping, I'm stuck and I would prefer not to calculate all my "old" ecdfs again !

You have to.  The ones you have contain references to internal code 
found only in R < 3.0.0.

Note that storing objects in .RData is never intended to be a permanent 
form of storage, and you have done a *major* version update.  You should 
expect to have to re-create objects from your scripts.

It is actually rather easy to update the objects.  Consider Fn12 from 
example(ecdf) (which is random, so your mileage will vary).  The data 
are in the environment of Fn12, so

Fn12 <- eval(attr(Fn12, "call"), environment(Fn12))

recreates it.


>
> Regards, Olivier
>
> --------------------------
> Olivier ETERRADOSSI
> Ma?tre-Assistant, HDR
> Ecole des Mines d'Al?s (C2MA, site de Pau)
> Ing?nierie de l'aspect visuel et tactile des mat?riaux
> P?le ? Recherche sur les Interactions des Mat?riaux avec leur Environnement ? (RIME)
> H?lioparc, 2 av. P. Angot, F-64053 PAU CEDEX 9
> Tel : 05 59 30 90 35 (direct) - 05 59 30  54 25 (std)
> Fax : 05 59 30 63 68
> http://www.mines-ales.fr<http://www.mines-ales.fr/>
> http://www.mines-telecom.fr<http://www.mines-telecom.fr/>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From highstat at highstat.com  Thu Oct 24 10:34:27 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 24 Oct 2013 09:34:27 +0100
Subject: [R] Course: Mixed modelling  (with intro MCMC)
Message-ID: <5268DB93.30408@highstat.com>

We would like to announce the following stats course;

Course: Introduction to MCMC, Linear mixed effects models and GLMM with R
When: 20-24 January, 2014
Where: Bangor University, UK
Info: http://www.highstat.com/statscourse.htm
Flyer: http://www.highstat.com/Courses/Flyer2014_02Bangor.pdf

Kind regards,

Alain

-- 
Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007)
2. Mixed effects models and extensions in ecology with R (2009)
3. A Beginner's Guide to R (2009)
4. Zero Inflated Models and GLMM with R (2012)
5. A Beginner's Guide to GAM (2012)
6. A Beginner's Guide to GLM and GLMM (2013)

Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From E.Vettorazzi at uke.de  Thu Oct 24 11:50:19 2013
From: E.Vettorazzi at uke.de (Eik Vettorazzi)
Date: Thu, 24 Oct 2013 11:50:19 +0200
Subject: [R] How can I use a script "l" (LaTeX \ell) in mathematical
 annotation of plots?
In-Reply-To: <1382571556.79906.YahooMailNeo@web142806.mail.bf1.yahoo.com>
References: <1382571556.79906.YahooMailNeo@web142806.mail.bf1.yahoo.com>
Message-ID: <5268ED5B.3030204@uke.de>

this works for me:

plot(1,main="\u2113")

cheers

Am 24.10.2013 01:39, schrieb Byron Dom:
> 
> 
> Original post: On 13/10/2013 18:53, Byron Dom wrote:
> 
>>> Due to convention a script "l" - $$\ell$$ (LaTeX \ell) is used to 
>>> represent a certain quantity in something I'm working on. I'm 
>>> unable to figure out how to use it in R. It's not included in the 
>>> list on ?plotmath.
>>>
>>> Can anyone tell me how to use it?  Its unicode is U+2113. This 
>>> page has a list of various encodings of it: 
>>>
>  http://www.fileformat.info/info/unicode/char/2113/encoding.htm.  
>>> Is there a way to include it by using one of these encodings somehow?
> 
> -------------------------------------------------
> 
> On 13/10/2013 22:06 Prof Brian Ripley responded:
> 
>> What do you want to do with it?  plotmath is about plotting, but you
>> have not otherwise mentioned that, let alone the device on which you 
>> want to plot.
>>
>> Read the help for plotmath: on some plot devices, just use "\u2113".  It 
>> is not AFAICS in the Adobe symbol encoding.
>>
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel: 
>  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> -------------------------------------------------
> 
> My response:
> 
> Thanks I worked out how to do it based on your mention of "u2113".
> See below.
> 
> I'm sorry if my information wasn't complete enough. I assumed that 
> what I said, combined with the subject ("How can I use a script "l" 
> (LaTeX \ell) in
>  mathematical annotation of plots?") would have been 
> enough.
> 
> I just wanted to be able to do this on the default device, which 
> displays plots within the R session window. I have a simple path 
> to go from there to .png form, which I include in LaTeX documents
> and for other purposes. I am using R version 3.0.1 in Windows 7, 
> for which I believe the default plot device is "windows".
> 
> An example of the kind of thing I wanted to do is to include 
> "ylab = expression(hat(gamma))" (which is equivalent to the LaTex 
> "\hat{\gamma}}") among the base-graphics plot() arguments. That 
> works. In LaTeX a script "l" is produced with "\ell", but 
> something like "ylab = expression(ell)" doesn't work in R. 
> I wanted to be able to do the equivalent of that, but to obtain "?".
> 
> Here are a couple of examples using it that worked:
>   > plot(1:10,xlab="\u2113")
>   >
>  plot(1:10,xlab="\u2113(\u2113 + 1)")
> The only (slight) problem with this is the minor aesthetic issue 
> 
> that the "?" one gets this way is in an obviously different font 
> 
> from what one gets using the LaTeX "\lambda" command/symbol.
> 
> Strangely, earlier, when I tried 
>   > plot(1:10,xlab=expression(symbol("\u2113")))
> it did the same thing as 
>   > plot(1:10,xlab=expression(lambda))
> So I got a lower-case greek lambda - "?", rather than "?"
> (script "l").
> 
> When I used the unicode representation for lowercase 
> lambda - "?" - as follows
>   >
>  plot(1:10,xlab=expression(symbol("\u03bb")))
> I got this for an x-axis label: "<Y+03BB>". On the other hand,
> the following did work
>   > plot(1:10,xlab="\u03bb"), 
> giving me an x-axis label of lambda - "?".
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/7410-58243
F ++49/40/7410-57790
--

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Martin Zeitz (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From hill0093 at umn.edu  Thu Oct 24 11:09:18 2013
From: hill0093 at umn.edu (Hurr)
Date: Thu, 24 Oct 2013 02:09:18 -0700 (PDT)
Subject: [R] labeling abscissa using a function of the plotted scale
In-Reply-To: <5268B56E.4010000@bitwrit.com.au>
References: <1381510115791-4678075.post@n4.nabble.com>
	<273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>
	<1382565075173-4678917.post@n4.nabble.com>
	<58de215e-0e9f-4aa8-ade5-bcfd4700bd7a@email.android.com>
	<1382582995862-4678927.post@n4.nabble.com>
	<5268B56E.4010000@bitwrit.com.au>
Message-ID: <1382605758817-4678946.post@n4.nabble.com>

Thanks Jim, maybe now I can start learning.
Next I want to use my choice of n digits or width instead of round.




--
View this message in context: http://r.789695.n4.nabble.com/labeling-abscissa-using-a-function-of-the-plotted-scale-tp4678075p4678946.html
Sent from the R help mailing list archive at Nabble.com.


From lpfgarcia at gmail.com  Thu Oct 24 14:16:50 2013
From: lpfgarcia at gmail.com (=?ISO-8859-1?Q?Lu=EDs_Paulo_F=2E_Garcia?=)
Date: Thu, 24 Oct 2013 10:16:50 -0200
Subject: [R] RWeka and multicore package
In-Reply-To: <20131022091119.GB4253@slingshot.co.nz>
References: <CAPK6mFru7FFPXLnivwzpDxi_GMqk_yVNpDvNTXz2nUTyWgLeMQ@mail.gmail.com>
	<20131022091119.GB4253@slingshot.co.nz>
Message-ID: <CAPK6mFoR=ErtuexUhVcw2hO1ezVBdNrUVfwJCM1LjudmYdYg+Q@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/ba07ac83/attachment.pl>

From S.Ellison at lgcgroup.com  Thu Oct 24 14:54:26 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Thu, 24 Oct 2013 13:54:26 +0100
Subject: [R] nls model definition help
In-Reply-To: <823FB8AD8FD2F44A92284630A4AADF7E2F1B5B2D@seacmw-s-53401.europe.shell.com>
References: <823FB8AD8FD2F44A92284630A4AADF7E2F1B5B2D@seacmw-s-53401.europe.shell.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554DD8CDB@GOLD.corp.lgc-group.com>


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Wayne.W.Jones at shell.com
> Sent: 22 October 2013 18:52
> To: R-help at r-project.org
> Subject: [R] nls model definition help
> 
> Hi fellow R users,
> 
> I'm trying to fit a model using nls with the following model
> definition:
> 
> y(t+1)=(th1*x1 + R1*x2) * exp(a1*x3) + (1-th1*x1 + R1*x2)*y(t)
> 
> ...
>
> Any ideas if this is achievable and if not any ideas on how to fit this
> model?
I'm thinking not, as you have that (t+1) back-reference in there which makes the calculated y(t) part of the expression. Pretty sure nlm won't handle that in the formula interface. 

However, you could use nlm or optim if you write a function to predict y and then wrap that in a function to calculate the residual sum of squares (taking the parameter vector and y[obs] as parameters), then minimise the residual SS. The hessian from either can then be used to estimate standard errors using the usual least-squares formulae.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jonsleepy at gmail.com  Thu Oct 24 14:59:21 2013
From: jonsleepy at gmail.com (Jon BR)
Date: Thu, 24 Oct 2013 08:59:21 -0400
Subject: [R] data frame pointers?
In-Reply-To: <1382584328.37521.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <CA+d7zeTgom8WDBndBfYmcRa6-49qxWD76S+SuNCPQLnkmDDNdQ@mail.gmail.com>
	<1382579457.7928.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CA+d7zeSMyAJsNrv31Ood8bVv+BP=7eJjKqHX6+wcOWXUtFdKbA@mail.gmail.com>
	<1382583891.91956.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1382584328.37521.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CA+d7zeTt5QcCuddBb_BUbddj12XmO1KWivZDQA_SXFsOPba=jw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/c75987ee/attachment.pl>

From Thorn.Thaler at rdls.nestle.com  Thu Oct 24 15:13:11 2013
From: Thorn.Thaler at rdls.nestle.com (Thaler,Thorn,LAUSANNE,Applied Mathematics)
Date: Thu, 24 Oct 2013 13:13:11 +0000
Subject: [R] Use R to plot a directory tree
Message-ID: <EDB44DA865211646A192A94DF3C6FA670F72D6EB@DEMDCE0057.nestle.com>

Dear all,

I was wondering whether (or better: how) I can use R to read recursively a directory to get all the sub-folders and files located in the root folder and put it into a tree like structure where the leaves are files and intermediate nodes are the directories? The idea is that I'd like to plot the structure of a certain root folder to be able to restructure the file system.

Any ideas on that? I was googling a lot but apparently I did not use the right terms ("R tree folder" or "R tree directory" takes me mainly to pages about the "R-tree" a structure for spatial access methods [at least I learnt something new ;)])

Any pointer to the right function is highly appreciated.

Cheers,

Thorn Thaler 
NRC Lausanne
Applied Mathematics


From alaios at yahoo.com  Thu Oct 24 15:28:30 2013
From: alaios at yahoo.com (Alaios)
Date: Thu, 24 Oct 2013 06:28:30 -0700 (PDT)
Subject: [R] Plot.raster hides the axis layer
Message-ID: <1382621310.48602.YahooMailNeo@web125302.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/afb632c1/attachment.pl>

From gunter.berton at gene.com  Thu Oct 24 15:47:24 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 24 Oct 2013 06:47:24 -0700
Subject: [R] Use R to plot a directory tree
In-Reply-To: <EDB44DA865211646A192A94DF3C6FA670F72D6EB@DEMDCE0057.nestle.com>
References: <EDB44DA865211646A192A94DF3C6FA670F72D6EB@DEMDCE0057.nestle.com>
Message-ID: <CACk-te201_8YAOVR5+pypkJMwsJ04KY9zYVBVPXEKbj8AzpbOQ@mail.gmail.com>

A wild guess -- take a look at the CRAN "phylohenetics" task view, as
that sounds like the sort of thing that might have tree generation and
manipulation functions.

... but you may do better with some non-R tool out there.

(Hopefully, you'll get a better response, though).

Cheers,
Bert

On Thu, Oct 24, 2013 at 6:13 AM, Thaler,Thorn,LAUSANNE,Applied
Mathematics <Thorn.Thaler at rdls.nestle.com> wrote:
> Dear all,
>
> I was wondering whether (or better: how) I can use R to read recursively a directory to get all the sub-folders and files located in the root folder and put it into a tree like structure where the leaves are files and intermediate nodes are the directories? The idea is that I'd like to plot the structure of a certain root folder to be able to restructure the file system.
>
> Any ideas on that? I was googling a lot but apparently I did not use the right terms ("R tree folder" or "R tree directory" takes me mainly to pages about the "R-tree" a structure for spatial access methods [at least I learnt something new ;)])
>
> Any pointer to the right function is highly appreciated.
>
> Cheers,
>
> Thorn Thaler
> NRC Lausanne
> Applied Mathematics
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From hill0093 at umn.edu  Thu Oct 24 16:00:07 2013
From: hill0093 at umn.edu (Hurr)
Date: Thu, 24 Oct 2013 07:00:07 -0700 (PDT)
Subject: [R] labeling abscissa using a function of the plotted scale
In-Reply-To: <5268B56E.4010000@bitwrit.com.au>
References: <1381510115791-4678075.post@n4.nabble.com>
	<273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>
	<1382565075173-4678917.post@n4.nabble.com>
	<58de215e-0e9f-4aa8-ade5-bcfd4700bd7a@email.android.com>
	<1382582995862-4678927.post@n4.nabble.com>
	<5268B56E.4010000@bitwrit.com.au>
Message-ID: <1382623207350-4678954.post@n4.nabble.com>

Thanks Jim, maybe now I can start learning.
Here is a run of my trying to learn:
> xvalue<-c(5.2,1.3,9.7,2.8,8.1,4.7,6.6,7.4)
> yvalue<-c(9,3,4,7,2,5,3,6)
> plot(xvalue,yvalue)
> axis(1,at=NULL,labels=1/xvalue,digits=5)
Error in axis(1, at = NULL, labels = 1/xvalue, digits = 5) :
  'labels' is supplied and not 'at'
In addition: Warning message:
In axis(1, at = NULL, labels = 1/xvalue, digits = 5) :
  "digits" is not a graphical parameter
>
Why can't R automatically compute the spacing when I use the formula?
How can I specify n-digits or width instead of round or nothing? 




--
View this message in context: http://r.789695.n4.nabble.com/labeling-abscissa-using-a-function-of-the-plotted-scale-tp4678075p4678954.html
Sent from the R help mailing list archive at Nabble.com.


From marc_schwartz at me.com  Thu Oct 24 16:20:30 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 24 Oct 2013 09:20:30 -0500
Subject: [R] Use R to plot a directory tree
In-Reply-To: <CACk-te201_8YAOVR5+pypkJMwsJ04KY9zYVBVPXEKbj8AzpbOQ@mail.gmail.com>
References: <EDB44DA865211646A192A94DF3C6FA670F72D6EB@DEMDCE0057.nestle.com>
	<CACk-te201_8YAOVR5+pypkJMwsJ04KY9zYVBVPXEKbj8AzpbOQ@mail.gmail.com>
Message-ID: <2286BB55-7D5A-4EF4-8659-9619DC56A391@me.com>

One R package that might be of interest would be 'diagram':

  http://cran.r-project.org/web/packages/diagram/

I would also agree with Bert here and would point you in the direction of PSTricks, which can handle these sorts of complex figures. It would of course require learning LaTeX, but that is a good thing. :-)

More info here:

  http://tug.org/PSTricks/main.cgi/

and lots of examples with code here:

 http://tug.org/PSTricks/main.cgi?file=examples


I use PSTricks for creating things like subject disposition flow charts for clinical study reports.

Regards,

Marc Schwartz

  
On Oct 24, 2013, at 8:47 AM, Bert Gunter <gunter.berton at gene.com> wrote:

> A wild guess -- take a look at the CRAN "phylohenetics" task view, as
> that sounds like the sort of thing that might have tree generation and
> manipulation functions.
> 
> ... but you may do better with some non-R tool out there.
> 
> (Hopefully, you'll get a better response, though).
> 
> Cheers,
> Bert
> 
> On Thu, Oct 24, 2013 at 6:13 AM, Thaler,Thorn,LAUSANNE,Applied
> Mathematics <Thorn.Thaler at rdls.nestle.com> wrote:
>> Dear all,
>> 
>> I was wondering whether (or better: how) I can use R to read recursively a directory to get all the sub-folders and files located in the root folder and put it into a tree like structure where the leaves are files and intermediate nodes are the directories? The idea is that I'd like to plot the structure of a certain root folder to be able to restructure the file system.
>> 
>> Any ideas on that? I was googling a lot but apparently I did not use the right terms ("R tree folder" or "R tree directory" takes me mainly to pages about the "R-tree" a structure for spatial access methods [at least I learnt something new ;)])
>> 
>> Any pointer to the right function is highly appreciated.
>> 
>> Cheers,
>> 
>> Thorn Thaler
>> NRC Lausanne
>> Applied Mathematics
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> (650) 467-7374
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jttkim at googlemail.com  Thu Oct 24 17:38:32 2013
From: jttkim at googlemail.com (Jan Kim)
Date: Thu, 24 Oct 2013 16:38:32 +0100
Subject: [R] Use R to plot a directory tree
In-Reply-To: <2286BB55-7D5A-4EF4-8659-9619DC56A391@me.com>
References: <EDB44DA865211646A192A94DF3C6FA670F72D6EB@DEMDCE0057.nestle.com>
	<CACk-te201_8YAOVR5+pypkJMwsJ04KY9zYVBVPXEKbj8AzpbOQ@mail.gmail.com>
	<2286BB55-7D5A-4EF4-8659-9619DC56A391@me.com>
Message-ID: <20131024153831.GA14655@LIN-2F308X1.iah.ac.uk>

perhaps as a somewhat tamer guess than Bert's, it's probably not
very hard to write a function that pieces together a dendrogram
(S3 class provided by the stats package), using the list.dirs and
list.files functions.

This could then be plotted via the plot function, and you could
even designate attributes such as colours, line thicknesses etc.
to highlight e.g. the largest files.

I'm not too sure, though, how useful this would be for plotting
directory trees for restructuring them; any tree that's complex
enough to require the use of such auxiliary tools will very likely
have at least a few hundred files, and thus labels will end up
either overlapping everywhere or illegibly small.

Best regards, Jan

On Thu, Oct 24, 2013 at 09:20:30AM -0500, Marc Schwartz wrote:
> One R package that might be of interest would be 'diagram':
> 
>   http://cran.r-project.org/web/packages/diagram/
> 
> I would also agree with Bert here and would point you in the direction of PSTricks, which can handle these sorts of complex figures. It would of course require learning LaTeX, but that is a good thing. :-)
> 
> More info here:
> 
>   http://tug.org/PSTricks/main.cgi/
> 
> and lots of examples with code here:
> 
>  http://tug.org/PSTricks/main.cgi?file=examples
> 
> 
> I use PSTricks for creating things like subject disposition flow charts for clinical study reports.
> 
> Regards,
> 
> Marc Schwartz
> 
>   
> On Oct 24, 2013, at 8:47 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> 
> > A wild guess -- take a look at the CRAN "phylohenetics" task view, as
> > that sounds like the sort of thing that might have tree generation and
> > manipulation functions.
> > 
> > ... but you may do better with some non-R tool out there.
> > 
> > (Hopefully, you'll get a better response, though).
> > 
> > Cheers,
> > Bert
> > 
> > On Thu, Oct 24, 2013 at 6:13 AM, Thaler,Thorn,LAUSANNE,Applied
> > Mathematics <Thorn.Thaler at rdls.nestle.com> wrote:
> >> Dear all,
> >> 
> >> I was wondering whether (or better: how) I can use R to read recursively a directory to get all the sub-folders and files located in the root folder and put it into a tree like structure where the leaves are files and intermediate nodes are the directories? The idea is that I'd like to plot the structure of a certain root folder to be able to restructure the file system.
> >> 
> >> Any ideas on that? I was googling a lot but apparently I did not use the right terms ("R tree folder" or "R tree directory" takes me mainly to pages about the "R-tree" a structure for spatial access methods [at least I learnt something new ;)])
> >> 
> >> Any pointer to the right function is highly appreciated.
> >> 
> >> Cheers,
> >> 
> >> Thorn Thaler
> >> NRC Lausanne
> >> Applied Mathematics
> >> 
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> > 
> > 
> > 
> > -- 
> > 
> > Bert Gunter
> > Genentech Nonclinical Biostatistics
> > 
> > (650) 467-7374
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
 +- Jan T. Kim -------------------------------------------------------+
 |             email: jttkim at gmail.com                                |
 |             WWW:   http://www.jtkim.dreamhosters.com/              |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*


From macqueen1 at llnl.gov  Thu Oct 24 16:46:07 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 24 Oct 2013 14:46:07 +0000
Subject: [R] Plot.raster hides the axis layer
In-Reply-To: <1382621310.48602.YahooMailNeo@web125302.mail.ne1.yahoo.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D4E5340@PRDEXMBX-08.the-lab.llnl.gov>

This is by no means an explanation, but as a possible approach to consider:

 plot(0:1, 0:1, xaxt='n', asp=1)
 axis(1,at=c(0,1),labels=c("a","b"))
 plot(m,add=TRUE)


-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/24/13 6:28 AM, "Alaios" <alaios at yahoo.com> wrote:

>Hi all,
>I am trying to plot a raster object (I can explain why but the point is
>that it would be a raster obje?t)..
>
>I have selected a small code to show you exactly the problem
>
>
>require(raster)
>test<-matrix(data=runif(10000),nrow=100)
>m<-raster(test)
>plot(m,axes="FALSE")
>axis(1,at=c(0,1),labels=c("a","b")) # THIS DOES NOT CHANGE THE INVISIBLE
>AXIS WHILE
>
>
>
>
>plot(test,axes="FALSE")
>axis(1,at=c(0,1),labels=c("a","b")) # WHEN I AM PLOTTING A NON RASTER
>OBJECT THE AXIS APPEARS.
>
>Can someone explain me what I can do so a raster layer to show correctly
>the axis? Please remember that I have to do that on a raster object so
>coercing it will not help ..
>
>I would like to thank you in advance for your help
>
>Regards
>Alex
>
>	[[alternative HTML version deleted]]
>


From anna.c at greatwall-mold.com  Thu Oct 24 15:24:17 2013
From: anna.c at greatwall-mold.com (=?utf-8?B?QW5uYQ==?=)
Date: Thu, 24 Oct 2013 21:24:17 +0800 (CST)
Subject: [R] =?utf-8?q?Prototype_molds_and_plastic_molds?=
Message-ID: <3F4ED5D669B79FB57EBEBD4A97D5D6F7@ANNA_GREATWALL>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/3f0c349b/attachment.pl>

From alku at dtu.dk  Thu Oct 24 10:51:25 2013
From: alku at dtu.dk (Alexandra Kuznetsova)
Date: Thu, 24 Oct 2013 08:51:25 +0000
Subject: [R] bug in dummy.coef?
Message-ID: <0566E17B6DEC62459078112371B7508E0F1B7D@ait-pex02mbx05.win.dtu.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/c3908988/attachment.pl>

From kishor.tappita at gmail.com  Thu Oct 24 11:15:10 2013
From: kishor.tappita at gmail.com (Kishor Tappita)
Date: Thu, 24 Oct 2013 14:45:10 +0530
Subject: [R] ordinal data with binary response
Message-ID: <CAL_RqERKSV5hwNr-jPNwEyS02PeLY3K8oU1NKk6rnAfTSXaiEA@mail.gmail.com>

Dear R-users,

I am trying to analyze data with ordinal independent variables and
binary response . Could some one suggest me an appropriate statistic
for this kind of analysis.

Thanks,
Regards,
Kishir


From randolph_steven_d at lilly.com  Thu Oct 24 13:54:12 2013
From: randolph_steven_d at lilly.com (Steven Dwayne Randolph)
Date: Thu, 24 Oct 2013 11:54:12 +0000
Subject: [R] XML package not working
In-Reply-To: <3A91AE42-2C39-484B-B331-5E1E4EFFCDF0@xs4all.nl>
References: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>
	<5263226B.7070103@gmail.com>
	<66C71547284587479F8009E05C07DA9704F8E5D2@USTLMLLYC107.RF.lilly.com>
	<52640117.2010908@gmail.com>
	<66C71547284587479F8009E05C07DA9704F96EC4@USTLMLLYC107.RF.lilly.com>
	<CA+vqiLH9HP_T599Cbru+v=OZ126x1KBz==mweCuY-DXXtXD02g@mail.gmail.com>
	<66C71547284587479F8009E05C07DA9704F96FB5@USTLMLLYC107.RF.lilly.com>
	<3A91AE42-2C39-484B-B331-5E1E4EFFCDF0@xs4all.nl>
Message-ID: <66C71547284587479F8009E05C07DA9704F9A7FC@USTLMLLYC107.RF.lilly.com>

Berend.... Thanks.  I am aware of the missing kb's in the download.  However, my problem is that it only happens with this package.  I download other packages manually and via command-line install.packages() and 
Do not have any problems with completing full downloads of the entire file.   

Perhaps, if someone has the complete download for the XML package, both in *.zip and  *tar formats that they can either email to me or allow me to ftp from it would help me to move forward with this resolve.   

 

Thanks... 
 

 Steven

-----Original Message-----
From: Berend Hasselman [mailto:bhh at xs4all.nl] 
Sent: Tuesday, October 22, 2013 12:39 PM
To: Steven Dwayne Randolph
Cc: Ista Zahn; r-help at r-project.org; stevendrandolph at aol.com; Piyush Singh - Network
Subject: Re: [R] XML package not working


On 22-10-2013, at 15:19, Steven Dwayne Randolph <randolph_steven_d at lilly.com> wrote:

> Ista,... Thank you for your response.   Here is what is occurring when I attempt to command-line install.
> ----------------------------------------------------------------------
> ------------------------------------------------------------
>> install.packages('XML')
> Installing package into 'C:/Users/xxxxxxx/Documents/R/win-library/3.0'
> (as 'lib' is unspecified)
> trying URL 'http://cran.rstudio.com/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> Content type 'application/zip' length 4287270 bytes (4.1 Mb) opened 
> URL downloaded 4.1 Mb
> 
> Warning in install.packages :
>  downloaded length 4276224 != reported length 4287270


Look at what is reported here. The downloaded length is not equal to the reported (i.e. actual) length of  the zip.
What is the length if you download the .zip file manually?
So something has gone wrong with the download.
Can you open a .zip file in another program? If so see what happens if you open it in that program.
You have to do detective work.

Berend


> Warning in install.packages :
>  error 1 in extracting from zip file
> Warning in install.packages :
>  cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'
> Error in install.packages : cannot open the connection
> 
> ----------------------------------------------------------------------
> --------------------------------------------------------------------
> 
> STeven
> -----Original Message-----
> From: Ista Zahn [mailto:istazahn at gmail.com]
> Sent: Tuesday, October 22, 2013 8:09 AM
> To: Steven Dwayne Randolph
> Cc: Duncan Murdoch; r-help at r-project.org; stevendrandolph at aol.com; 
> Piyush Singh - Network
> Subject: Re: [R] XML package not working
> 
> Hi Steven,
> 
> I still don't understand why you are downloading it manually. What 
> happens when you
> 
> install.packages("XML")
> 
> ?
> 
> Best,
> Ista
> 
> On Tue, Oct 22, 2013 at 8:03 AM, Steven Dwayne Randolph <randolph_steven_d at lilly.com> wrote:
>> Duncan... Thank you.
>> 
>>        1.   I am able to download the XML file via my corporate network, other packages without this same issue, even rcurl and bitops which are pre-requisites on the same page as XML.
>>        2.   I  have attempted to download this from my own wifi at home using xfinity/Comcast to my personal pc and still get the same error on this package alone.
>>                3.   I am genuinely baffled by this package download and install experience.
>>                 4.  I would gladly build this from source, If indeed I could find the source and then use RTools to compile it.  That has been unsuccessful as well.   Nightmare? Slightly.
>> 
>> Thanks for your response.....
>> Steven
>> 
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: Sunday, October 20, 2013 12:13 PM
>> To: Steven Dwayne Randolph; r-help at r-project.org; Ista Zahn
>> Cc: stevendrandolph at aol.com
>> Subject: Re: [R] XML package not working
>> 
>> On 13-10-20 9:23 AM, Steven Dwayne Randolph wrote:
>>> My apologies for not conforming to the posting guideline.
>>> 
>>> 
>>> Sys.info()
>>>                      sysname                      release                      version
>>>                    "Windows"                      "7 x64" "build 7601, Service Pack 1"
>>>                     nodename                      machine                        login
>>>            "xxxxxxNU247BZ1S"                     "x86-64"                    "XXXXXX"
>>>                         user               effective_user
>>>                    "xxxxxxx"                    "xxxxxxx"
>>> 
>>> When I attempt to install a local copy of the xml.zip file:
>>> 
>>> in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>>   cannot open the connection
>>> In addition: Warning messages:
>>> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip 
>>> file
>>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>>   cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'
>> 
>> I think it is pretty clear that the problem is at your end:  you aren't downloading the file properly, even though everyone else is.  Perhaps you are behind a firewall, or something else is interfering with your downloads?
>> 
>> Duncan Murdoch
>> 
>>> 
>>> 
>>> -----Original Message-----
>>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>>> Sent: Saturday, October 19, 2013 8:23 PM
>>> To: Steven Dwayne Randolph; r-help at r-project.org
>>> Cc: stevendrandolph at aol.com
>>> Subject: Re: [R] XML package not working
>>> 
>>> On 13-10-19 3:47 PM, Steven Dwayne Randolph wrote:
>>>> I know I  cannot be the only one who is not able to install the XML package from CRAN (zip or tar file)  Many packages depend on this XML package.  Can someone help me either access the source for a good binary?  I have received no assistance from the author/developer of the package.
>>> 
>>> It installs fine for me.
>>> 
>>> Duncan Murdoch
>>> 
>> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lath at energidanmark.dk  Thu Oct 24 15:46:35 2013
From: lath at energidanmark.dk (Lasse Thorst)
Date: Thu, 24 Oct 2013 13:46:35 +0000
Subject: [R] Making a function and applying it over a list(?)
Message-ID: <4DF642A8A770C24090F37AC3560BBA14F67578@EDAEXCH02A.local.energidanmark.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/84cd25f6/attachment.pl>

From dmvxic at gmail.com  Thu Oct 24 16:15:09 2013
From: dmvxic at gmail.com (David Mora)
Date: Thu, 24 Oct 2013 08:15:09 -0600
Subject: [R] R: Optional argument to be used in a subset function
Message-ID: <CACaVdgQv6j1qDBq3VZQB69QkU7zy9VS7AZEH0dQfSUv6uB5wxw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/846dcad9/attachment.pl>

From marta_mtm at hotmail.com  Thu Oct 24 11:40:26 2013
From: marta_mtm at hotmail.com (=?iso-8859-1?B?TWFydGEgVG9iZfFh?=)
Date: Thu, 24 Oct 2013 11:40:26 +0200
Subject: [R] track on boats
Message-ID: <DUB119-W33824BB4C6058C7D8269A18F0C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/421b03c7/attachment.pl>

From bhh at xs4all.nl  Thu Oct 24 17:51:57 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 24 Oct 2013 17:51:57 +0200
Subject: [R] R: Optional argument to be used in a subset function
In-Reply-To: <CACaVdgQv6j1qDBq3VZQB69QkU7zy9VS7AZEH0dQfSUv6uB5wxw@mail.gmail.com>
References: <CACaVdgQv6j1qDBq3VZQB69QkU7zy9VS7AZEH0dQfSUv6uB5wxw@mail.gmail.com>
Message-ID: <D3A61CF1-B79C-4943-9D28-E421F9F981F4@xs4all.nl>


On 24-10-2013, at 16:15, David Mora <dmvxic at gmail.com> wrote:

> I'm writing a function that needs an optional variable. If the variable is
> given, then a subset must be made using that variable, but if the variable
> is not given the subset must be done using all the values for that variable
> (ignoring that variable).
> 
> Something like this:
> 
> *band <- function(file, fruit = "apple", optional=TRUE) {*
> 
> *data <- read.csv(file)*
> 
> *a <- nrow(subset(data, 'Column 1' == fruit & 'Column 2'=="hot" & 'Column 3'==
> optional))*
> 
> *b <- nrow(subset(data,'Column 1' == fruit & 'Column 2'=="cold" & 'Column 3'==
> optional)) *
> 
> *z <- a+b*
> 
> * print(z)*
> 
> * }*
> 
> What I need is that the function *band("file","orange")*,  subset the data
> frame using all possible values for Column 3 but is not doing it.
> 
> All ideas are welcome.
> 
> Thanks.
> 
> 
> David Mora
> 
> 	[[alternative HTML version deleted]]
> 

Please do not post in HTML.
And make stuff bold: in plain text it is converted to things like this:

* }*

which nonsense for R.

Berend

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From JSorkin at grecc.umaryland.edu  Thu Oct 24 17:54:46 2013
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Thu, 24 Oct 2013 11:54:46 -0400
Subject: [R] ordinal data with binary response
In-Reply-To: <CAL_RqERKSV5hwNr-jPNwEyS02PeLY3K8oU1NKk6rnAfTSXaiEA@mail.gmail.com>
References: <CAL_RqERKSV5hwNr-jPNwEyS02PeLY3K8oU1NKk6rnAfTSXaiEA@mail.gmail.com>
Message-ID: <52690A86020000CB000F59B1@smtp.medicine.umaryland.edu>

Kishor,
It sounds like you will need to use logistic regression. Although the following URL might help you better understand logistic regression, http://ww2.coastal.edu/kingw/statistics/R-tutorials/logistic.html  it would probably be most helpful if you would see help from a local statistician.
John

 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> Kishor Tappita <kishor.tappita at gmail.com> 10/24/2013 5:15 AM >>>
Dear R-users,

I am trying to analyze data with ordinal independent variables and
binary response . Could some one suggest me an appropriate statistic
for this kind of analysis.

Thanks,
Regards,
Kishir

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From jvadams at usgs.gov  Thu Oct 24 18:08:15 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 24 Oct 2013 11:08:15 -0500
Subject: [R] track on boats
In-Reply-To: <DUB119-W33824BB4C6058C7D8269A18F0C0@phx.gbl>
References: <DUB119-W33824BB4C6058C7D8269A18F0C0@phx.gbl>
Message-ID: <CAN5YmCFT8K8_yJbcV5sGjP63Gq8TOxPDfxxwT28thi4w6O3iUA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/02f8fd28/attachment.pl>

From kishor.tappita at gmail.com  Thu Oct 24 18:10:55 2013
From: kishor.tappita at gmail.com (Kishor Tappita)
Date: Thu, 24 Oct 2013 21:40:55 +0530
Subject: [R] ordinal data with binary response
In-Reply-To: <52690A86020000CB000F59B1@smtp.medicine.umaryland.edu>
References: <CAL_RqERKSV5hwNr-jPNwEyS02PeLY3K8oU1NKk6rnAfTSXaiEA@mail.gmail.com>
	<52690A86020000CB000F59B1@smtp.medicine.umaryland.edu>
Message-ID: <CAL_RqER=0s74dg2Td7EkS9n4_HJ4eMYeojr2BZ7EVRw42DZiwg@mail.gmail.com>

Dear John,

Thanks for the information. It is quite helpful.

Regards,
Kishor

On Thu, Oct 24, 2013 at 9:24 PM, John Sorkin
<JSorkin at grecc.umaryland.edu> wrote:
> Kishor,
> It sounds like you will need to use logistic regression. Although the
> following URL might help you better understand logistic regression,
> http://ww2.coastal.edu/kingw/statistics/R-tutorials/logistic.html  it would
> probably be most helpful if you would see help from a local statistician.
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>> Kishor Tappita <kishor.tappita at gmail.com> 10/24/2013 5:15 AM >>>
>
> Dear R-users,
>
> I am trying to analyze data with ordinal independent variables and
> binary response . Could some one suggest me an appropriate statistic
> for this kind of analysis.
>
> Thanks,
> Regards,
> Kishir
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> Confidentiality Statement:
>
> This email message, including any attachments, is for ...{{dropped:6}}


From dwinsemius at comcast.net  Thu Oct 24 18:38:36 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 24 Oct 2013 09:38:36 -0700
Subject: [R] installing package from source
In-Reply-To: <1382583217853-4678928.post@n4.nabble.com>
References: <1382583217853-4678928.post@n4.nabble.com>
Message-ID: <5E2F003A-FE6D-4FB3-A02B-E2A4BE1FC14B@comcast.net>


On Oct 23, 2013, at 7:53 PM, Long Vo wrote:

> Hi R users,
> Currently I want to fit a FIGARCH model to a dataset. The only package that
> allow for it that I could find is fGarch. However it seems that the FIGARCH
> model class fitting of this package has been moved to Oxmetrics. I tried to
> install the old versions of it using 'tar.gz' files from CRAN archive 
> http://cran.r-project.org/src/contrib/Archive/fGarch/
> <http://cran.r-project.org/src/contrib/Archive/fGarch/>   but not sure how
> it works. I tried
> 
> install.packages("myfilepath\fGarch_260.71.tar.gz", repos = NULL,
> type="source")
> 
> And received this error:
> 
> Warning: invalid package './I:_R filesGarch_260.71.tar.gz'
> Error: ERROR: no packages specified
> Warning messages:
> 1: running command '"I:/01_RFI~1/INSTAL~1/R-30~1.1/bin/i386/R" CMD INSTALL
> -l "I:\01_R files\installment\R-3.0.1\library" "./I:_R files
> Garch_260.71.tar.gz"' had status 1 
> 2: In install.packages("I:\001_R files\fGarch_260.71.tar.gz", repos = NULL, 
> :
>  installation of package ?./I:_R filesGarch_260.71.tar.gz? had non-zero
> exit status
> 
> Any helps on this?
> 

I've aways specified the package names and their locations separately in my call to install.packages, but I don't know if that is always needed. It also appears that you have no "/" separator between your path and the file name.

> Regards,
> Long
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/installing-package-from-source-tp4678928.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jvadams at usgs.gov  Thu Oct 24 18:52:07 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 24 Oct 2013 11:52:07 -0500
Subject: [R] Error in heatmap
In-Reply-To: <000c01cecf3b$75ff9fb0$61fedf10$@cinvestav.mx>
References: <000f01cece88$0442bdc0$0cc83940$@cinvestav.mx>
	<CAN5YmCEtBSgEKS6JgmqqqX2mBKRoiKxfYKmvrWRiewqyFK7szQ@mail.gmail.com>
	<000c01cecf3b$75ff9fb0$61fedf10$@cinvestav.mx>
Message-ID: <CAN5YmCEZb9d2wV1YX=PMgKwV=M=A_8RkWUJLOwPO50sPKHj=dg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/49b9f544/attachment.pl>

From vigibos at eio.upv.es  Thu Oct 24 18:59:45 2013
From: vigibos at eio.upv.es (Vicent Giner-Bosch)
Date: Thu, 24 Oct 2013 18:59:45 +0200
Subject: [R] Nonparametric k-way ANOVA
Message-ID: <CAHfSo7jFUaPzkV4oBxxkj=GM_POmE=2UB6_6fU6YfvJDrnaEQQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/70d18af5/attachment.pl>

From hb at biostat.ucsf.edu  Thu Oct 24 19:01:22 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 24 Oct 2013 10:01:22 -0700
Subject: [R] XML package not working
In-Reply-To: <66C71547284587479F8009E05C07DA9704F9A7FC@USTLMLLYC107.RF.lilly.com>
References: <66C71547284587479F8009E05C07DA9704F8805D@USTLMLLYC107.RF.lilly.com>
	<5263226B.7070103@gmail.com>
	<66C71547284587479F8009E05C07DA9704F8E5D2@USTLMLLYC107.RF.lilly.com>
	<52640117.2010908@gmail.com>
	<66C71547284587479F8009E05C07DA9704F96EC4@USTLMLLYC107.RF.lilly.com>
	<CA+vqiLH9HP_T599Cbru+v=OZ126x1KBz==mweCuY-DXXtXD02g@mail.gmail.com>
	<66C71547284587479F8009E05C07DA9704F96FB5@USTLMLLYC107.RF.lilly.com>
	<3A91AE42-2C39-484B-B331-5E1E4EFFCDF0@xs4all.nl>
	<66C71547284587479F8009E05C07DA9704F9A7FC@USTLMLLYC107.RF.lilly.com>
Message-ID: <CAFDcVCQFBEfnFqyqkWVcJWx6JAE7Cr0EyWiv8dS_Pq3awTC2uw@mail.gmail.com>

Have you tried to download from another CRAN mirror, e.g.

  http://cran.r-project.org/web/packages/XML/

More mirrors at http://cran.r-project.org/mirrors.html

As already others said, it's very unlikely that this is not an issue
on your end.

/Henrik


On Thu, Oct 24, 2013 at 4:54 AM, Steven Dwayne Randolph
<randolph_steven_d at lilly.com> wrote:
> Berend.... Thanks.  I am aware of the missing kb's in the download.  However, my problem is that it only happens with this package.  I download other packages manually and via command-line install.packages() and
> Do not have any problems with completing full downloads of the entire file.
>
> Perhaps, if someone has the complete download for the XML package, both in *.zip and  *tar formats that they can either email to me or allow me to ftp from it would help me to move forward with this resolve.
>
>
>
> Thanks...
>
>
>  Steven
>
> -----Original Message-----
> From: Berend Hasselman [mailto:bhh at xs4all.nl]
> Sent: Tuesday, October 22, 2013 12:39 PM
> To: Steven Dwayne Randolph
> Cc: Ista Zahn; r-help at r-project.org; stevendrandolph at aol.com; Piyush Singh - Network
> Subject: Re: [R] XML package not working
>
>
> On 22-10-2013, at 15:19, Steven Dwayne Randolph <randolph_steven_d at lilly.com> wrote:
>
>> Ista,... Thank you for your response.   Here is what is occurring when I attempt to command-line install.
>> ----------------------------------------------------------------------
>> ------------------------------------------------------------
>>> install.packages('XML')
>> Installing package into 'C:/Users/xxxxxxx/Documents/R/win-library/3.0'
>> (as 'lib' is unspecified)
>> trying URL 'http://cran.rstudio.com/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
>> Content type 'application/zip' length 4287270 bytes (4.1 Mb) opened
>> URL downloaded 4.1 Mb
>>
>> Warning in install.packages :
>>  downloaded length 4276224 != reported length 4287270
>
>
> Look at what is reported here. The downloaded length is not equal to the reported (i.e. actual) length of  the zip.
> What is the length if you download the .zip file manually?
> So something has gone wrong with the download.
> Can you open a .zip file in another program? If so see what happens if you open it in that program.
> You have to do detective work.
>
> Berend
>
>
>> Warning in install.packages :
>>  error 1 in extracting from zip file
>> Warning in install.packages :
>>  cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'
>> Error in install.packages : cannot open the connection
>>
>> ----------------------------------------------------------------------
>> --------------------------------------------------------------------
>>
>> STeven
>> -----Original Message-----
>> From: Ista Zahn [mailto:istazahn at gmail.com]
>> Sent: Tuesday, October 22, 2013 8:09 AM
>> To: Steven Dwayne Randolph
>> Cc: Duncan Murdoch; r-help at r-project.org; stevendrandolph at aol.com;
>> Piyush Singh - Network
>> Subject: Re: [R] XML package not working
>>
>> Hi Steven,
>>
>> I still don't understand why you are downloading it manually. What
>> happens when you
>>
>> install.packages("XML")
>>
>> ?
>>
>> Best,
>> Ista
>>
>> On Tue, Oct 22, 2013 at 8:03 AM, Steven Dwayne Randolph <randolph_steven_d at lilly.com> wrote:
>>> Duncan... Thank you.
>>>
>>>        1.   I am able to download the XML file via my corporate network, other packages without this same issue, even rcurl and bitops which are pre-requisites on the same page as XML.
>>>        2.   I  have attempted to download this from my own wifi at home using xfinity/Comcast to my personal pc and still get the same error on this package alone.
>>>                3.   I am genuinely baffled by this package download and install experience.
>>>                 4.  I would gladly build this from source, If indeed I could find the source and then use RTools to compile it.  That has been unsuccessful as well.   Nightmare? Slightly.
>>>
>>> Thanks for your response.....
>>> Steven
>>>
>>> -----Original Message-----
>>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>>> Sent: Sunday, October 20, 2013 12:13 PM
>>> To: Steven Dwayne Randolph; r-help at r-project.org; Ista Zahn
>>> Cc: stevendrandolph at aol.com
>>> Subject: Re: [R] XML package not working
>>>
>>> On 13-10-20 9:23 AM, Steven Dwayne Randolph wrote:
>>>> My apologies for not conforming to the posting guideline.
>>>>
>>>>
>>>> Sys.info()
>>>>                      sysname                      release                      version
>>>>                    "Windows"                      "7 x64" "build 7601, Service Pack 1"
>>>>                     nodename                      machine                        login
>>>>            "xxxxxxNU247BZ1S"                     "x86-64"                    "XXXXXX"
>>>>                         user               effective_user
>>>>                    "xxxxxxx"                    "xxxxxxx"
>>>>
>>>> When I attempt to install a local copy of the xml.zip file:
>>>>
>>>> in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>>>   cannot open the connection
>>>> In addition: Warning messages:
>>>> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
>>>> file
>>>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>>>   cannot open compressed file 'XML/DESCRIPTION', probable reason 'No such file or directory'
>>>
>>> I think it is pretty clear that the problem is at your end:  you aren't downloading the file properly, even though everyone else is.  Perhaps you are behind a firewall, or something else is interfering with your downloads?
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>>>> Sent: Saturday, October 19, 2013 8:23 PM
>>>> To: Steven Dwayne Randolph; r-help at r-project.org
>>>> Cc: stevendrandolph at aol.com
>>>> Subject: Re: [R] XML package not working
>>>>
>>>> On 13-10-19 3:47 PM, Steven Dwayne Randolph wrote:
>>>>> I know I  cannot be the only one who is not able to install the XML package from CRAN (zip or tar file)  Many packages depend on this XML package.  Can someone help me either access the source for a good binary?  I have received no assistance from the author/developer of the package.
>>>>
>>>> It installs fine for me.
>>>>
>>>> Duncan Murdoch
>>>>
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Thu Oct 24 19:25:37 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 24 Oct 2013 12:25:37 -0500
Subject: [R] installing package from source
In-Reply-To: <5E2F003A-FE6D-4FB3-A02B-E2A4BE1FC14B@comcast.net>
References: <1382583217853-4678928.post@n4.nabble.com>
	<5E2F003A-FE6D-4FB3-A02B-E2A4BE1FC14B@comcast.net>
Message-ID: <14C713F3-F390-4C92-99EE-839BE70D4FE6@me.com>


On Oct 24, 2013, at 11:38 AM, David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Oct 23, 2013, at 7:53 PM, Long Vo wrote:
> 
>> Hi R users,
>> Currently I want to fit a FIGARCH model to a dataset. The only package that
>> allow for it that I could find is fGarch. However it seems that the FIGARCH
>> model class fitting of this package has been moved to Oxmetrics. I tried to
>> install the old versions of it using 'tar.gz' files from CRAN archive 
>> http://cran.r-project.org/src/contrib/Archive/fGarch/
>> <http://cran.r-project.org/src/contrib/Archive/fGarch/>   but not sure how
>> it works. I tried
>> 
>> install.packages("myfilepath\fGarch_260.71.tar.gz", repos = NULL,
>> type="source")
>> 
>> And received this error:
>> 
>> Warning: invalid package './I:_R filesGarch_260.71.tar.gz'
>> Error: ERROR: no packages specified
>> Warning messages:
>> 1: running command '"I:/01_RFI~1/INSTAL~1/R-30~1.1/bin/i386/R" CMD INSTALL
>> -l "I:\01_R files\installment\R-3.0.1\library" "./I:_R files
>> Garch_260.71.tar.gz"' had status 1 
>> 2: In install.packages("I:\001_R files\fGarch_260.71.tar.gz", repos = NULL, 
>> :
>> installation of package ?./I:_R filesGarch_260.71.tar.gz? had non-zero
>> exit status
>> 
>> Any helps on this?
>> 
> 
> I've aways specified the package names and their locations separately in my call to install.packages, but I don't know if that is always needed. It also appears that you have no "/" separator between your path and the file name.


Long is trying to install a rather old version of the source R package that contains FORTRAN code on Windows.

Besides the immediate error in the way the path was constructed in the install.packages() call, using a single backslash, which needs to be escaped:

  http://cran.r-project.org/bin/windows/base/rw-FAQ.html#R-can_0027t-find-my-file

there are likely to be issues from trying to install an old version of the package on a newer version of R, perhaps the lack of the requisite development tools for compiling FORTRAN:

  http://cran.r-project.org/bin/windows/base/rw-FAQ.html#Can-I-install-packages-into-libraries-in-this-version_003f

and other issues as well.

Depending upon how far back you need to go in package versions, there may be pre-compiled Windows binaries (.zip files) available in directories here:

  http://cran.r-project.org/bin/windows/contrib/



Regards,

Marc Schwartz


> 
>> Regards,
>> Long


From jvadams at usgs.gov  Thu Oct 24 19:45:44 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 24 Oct 2013 12:45:44 -0500
Subject: [R] Problem with coordinates when trying to draw lines into a
 raster (image) file
In-Reply-To: <526532CE.6020404@btconnect.com>
References: <526532CE.6020404@btconnect.com>
Message-ID: <CAN5YmCFsW=rx=Liz_TWhKG5xDiPjHLDj3pUUuCrVf2_Hpn48MA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/06f9e1c5/attachment.pl>

From pdalgd at gmail.com  Thu Oct 24 20:00:46 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 24 Oct 2013 20:00:46 +0200
Subject: [R] Nonparametric k-way ANOVA
In-Reply-To: <CAHfSo7jFUaPzkV4oBxxkj=GM_POmE=2UB6_6fU6YfvJDrnaEQQ@mail.gmail.com>
References: <CAHfSo7jFUaPzkV4oBxxkj=GM_POmE=2UB6_6fU6YfvJDrnaEQQ@mail.gmail.com>
Message-ID: <2FA72E9B-479B-490E-9C29-6E5C2FBED279@gmail.com>


On Oct 24, 2013, at 18:59 , Vicent Giner-Bosch wrote:

> Sorry if this subject has been already dealt here.
> 
> Which are some common tests for nonparametric k-way ANOVA?
> 
> I have read about Kruskal-Wallis test as a kind of nonparametric one-way
> ANOVA, but I have not found anything about a general-setting (I mean k-way)
> nonparametric ANOVA.
> 
> Can you recommend me a good R package (or other reliable software) for that?

Can you provide reliable _theory_ for it? 

Some people have tried just to do ANOVA decompositions after replacing observations by their ranks, and referring sums of squares to chi-squared distributions. However, that derivation only holds under the global null hypothesis. In general, it is problematic to define additivity and interaction in a nonparametric setting since there are no parameters that effects can be additive in!

Stratified tests do exist and make OK sense. In those, you split data into groups and do the rank sums within groups, then look at a weighted sum of the  group rank sums, work out the mean and variance assuming no effect in any group, etc. For a two-way layout without replications, this is friedman.test(). I believe the "coin" package implements some more general cases.

-pd


> 
> Looking forward to your answers,
> 
> 
> --
> vicent
> @vginer_upv
> about.me/vginer_upv
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ripley at stats.ox.ac.uk  Thu Oct 24 20:11:57 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Oct 2013 19:11:57 +0100
Subject: [R] installing package from source
In-Reply-To: <14C713F3-F390-4C92-99EE-839BE70D4FE6@me.com>
References: <1382583217853-4678928.post@n4.nabble.com>	<5E2F003A-FE6D-4FB3-A02B-E2A4BE1FC14B@comcast.net>
	<14C713F3-F390-4C92-99EE-839BE70D4FE6@me.com>
Message-ID: <526962ED.7060604@stats.ox.ac.uk>

On 24/10/2013 18:25, Marc Schwartz wrote:
>
> On Oct 24, 2013, at 11:38 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>>
>> On Oct 23, 2013, at 7:53 PM, Long Vo wrote:
>>
>>> Hi R users,
>>> Currently I want to fit a FIGARCH model to a dataset. The only package that
>>> allow for it that I could find is fGarch. However it seems that the FIGARCH
>>> model class fitting of this package has been moved to Oxmetrics. I tried to
>>> install the old versions of it using 'tar.gz' files from CRAN archive
>>> http://cran.r-project.org/src/contrib/Archive/fGarch/
>>> <http://cran.r-project.org/src/contrib/Archive/fGarch/>   but not sure how
>>> it works. I tried
>>>
>>> install.packages("myfilepath\fGarch_260.71.tar.gz", repos = NULL,
>>> type="source")
>>>
>>> And received this error:
>>>
>>> Warning: invalid package './I:_R filesGarch_260.71.tar.gz'
>>> Error: ERROR: no packages specified
>>> Warning messages:
>>> 1: running command '"I:/01_RFI~1/INSTAL~1/R-30~1.1/bin/i386/R" CMD INSTALL
>>> -l "I:\01_R files\installment\R-3.0.1\library" "./I:_R files
>>> Garch_260.71.tar.gz"' had status 1
>>> 2: In install.packages("I:\001_R files\fGarch_260.71.tar.gz", repos = NULL,
>>> :
>>> installation of package ?./I:_R filesGarch_260.71.tar.gz? had non-zero
>>> exit status
>>>
>>> Any helps on this?
>>>
>>
>> I've aways specified the package names and their locations separately in my call to install.packages, but I don't know if that is always needed. It also appears that you have no "/" separator between your path and the file name.
>
>
> Long is trying to install a rather old version of the source R package that contains FORTRAN code on Windows.
>
> Besides the immediate error in the way the path was constructed in the install.packages() call, using a single backslash, which needs to be escaped:
>
>    http://cran.r-project.org/bin/windows/base/rw-FAQ.html#R-can_0027t-find-my-file
>
> there are likely to be issues from trying to install an old version of the package on a newer version of R, perhaps the lack of the requisite development tools for compiling FORTRAN:
>
>    http://cran.r-project.org/bin/windows/base/rw-FAQ.html#Can-I-install-packages-into-libraries-in-this-version_003f
>
> and other issues as well.
>
> Depending upon how far back you need to go in package versions, there may be pre-compiled Windows binaries (.zip files) available in directories here:
>
>    http://cran.r-project.org/bin/windows/contrib/

I don't think so: see NEWS

CHANGES IN R 3.0.0:

   SIGNIFICANT USER-VISIBLE CHANGES:

     ? Packages need to be (re-)installed under this version (3.0.0) of
       R.

so only those under bin/windows/contrib/3.0 will work, and there is only 
one for each package.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From byron_dom at yahoo.com  Thu Oct 24 18:44:31 2013
From: byron_dom at yahoo.com (Byron Dom)
Date: Thu, 24 Oct 2013 09:44:31 -0700 (PDT)
Subject: [R] How can I use a script "l" (LaTeX \ell) in mathematical
	annotation of plots?
In-Reply-To: <5268ED5B.3030204@uke.de>
References: <1382571556.79906.YahooMailNeo@web142806.mail.bf1.yahoo.com>
	<5268ED5B.3030204@uke.de>
Message-ID: <1382633071.57018.YahooMailNeo@web142805.mail.bf1.yahoo.com>




Thanks. That works for me too.

I had worked that out based on Brian's response to my original post.

If you read thru my response to him in detail, you'll see:

> Here are a couple of examples using it that worked:
>???> plot(1:10,xlab="\u2113")
>???>
>? plot(1:10,xlab="\u2113(\u2113 + 1)")




________________________________
From: Eik Vettorazzi <E.Vettorazzi at uke.de>
To: Byron Dom <byron_dom at yahoo.com>; r help <r-help at r-project.org> 
Cc: "ripley at stats.ox.ac.uk" <ripley at stats.ox.ac.uk> 
Sent: Thursday, October 24, 2013 2:50 AM
Subject: Re: [R] How can I use a script "l" (LaTeX \ell) in mathematical annotation of plots?


this works for me:

plot(1,main="\u2113")

cheers


Am 24.10.2013 01:39, schrieb Byron Dom:
> 
> 
> Original post: On 13/10/2013 18:53, Byron Dom wrote:
> 
>>> Due to convention a script "l" - $$\ell$$ (LaTeX \ell) is used to 
>>> represent a certain quantity in something I'm working on. I'm 
>>> unable to figure out how to use it in R. It's not included in the 
>>> list on ?plotmath.
>>>
>>> Can anyone tell me how to use it?? Its unicode is U+2113. This 
>>> page has a list of various encodings of it: 
>>>
>? http://www.fileformat.info/info/unicode/char/2113/encoding.htm.??
>>> Is there a way to include it by using one of these encodings somehow?
> 
> -------------------------------------------------
> 
> On 13/10/2013 22:06 Prof Brian Ripley responded:
> 
>> What do you want to do with it?? plotmath is about plotting, but you
>> have not otherwise mentioned that, let alone the device on which you 
>> want to plot.
>>
>> Read the help for plotmath: on some plot devices, just use "\u2113".? It 
>> is not AFAICS in the Adobe symbol encoding.
>>
>> -- 
>> Brian D. Ripley,? ? ? ? ? ? ? ? ? ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,? http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,? ? ? ? ? ???Tel: 
>? +44 1865 272861 (self)
>> 1 South Parks Road,? ? ? ? ? ? ? ? ? ???+44 1865 272866 (PA)
>> Oxford OX1 3TG, UK? ? ? ? ? ? ? ? Fax:? +44 1865 272595
> 
> -------------------------------------------------
> 
> My response:
> 
> Thanks I worked out how to do it based on your mention of "u2113".
> See below.
> 
> I'm sorry if my information wasn't complete enough. I assumed that 
> what I said, combined with the subject ("How can I use a script "l" 
> (LaTeX \ell) in
>? mathematical annotation of plots?") would have been 
> enough.
> 
> I just wanted to be able to do this on the default device, which 
> displays plots within the R session window. I have a simple path 
> to go from there to .png form, which I include in LaTeX documents
> and for other purposes. I am using R version 3.0.1 in Windows 7, 
> for which I believe the default plot device is "windows".
> 
> An example of the kind of thing I wanted to do is to include 
> "ylab = expression(hat(gamma))" (which is equivalent to the LaTex 
> "\hat{\gamma}}") among the base-graphics plot() arguments. That 
> works. In LaTeX a script "l" is produced with "\ell", but 
> something like "ylab = expression(ell)" doesn't work in R. 
> I wanted to be able to do the equivalent of that, but to obtain "?".
> 
> Here are a couple of examples using it that worked:
>???> plot(1:10,xlab="\u2113")
>???>
>? plot(1:10,xlab="\u2113(\u2113 + 1)")
> The only (slight) problem with this is the minor aesthetic issue 
> 
> that the "?" one gets this way is in an obviously different font 
> 
> from what one gets using the LaTeX "\lambda" command/symbol.
> 
> Strangely, earlier, when I tried 
>???> plot(1:10,xlab=expression(symbol("\u2113")))
> it did the same thing as 
>???> plot(1:10,xlab=expression(lambda))
> So I got a lower-case greek lambda - "?", rather than "?"
> (script "l").
> 
> When I used the unicode representation for lowercase 
> lambda - "?" - as follows
>???>
>? plot(1:10,xlab=expression(symbol("\u03bb")))
> I got this for an x-axis label: "<Y+03BB>". On the other hand,
> the following did work
>???> plot(1:10,xlab="\u03bb"), 
> giving me an x-axis label of lambda - "?".
> ??? [[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/7410-58243
F ++49/40/7410-57790
--

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Martin Zeitz (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From marc_schwartz at me.com  Thu Oct 24 20:34:14 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 24 Oct 2013 13:34:14 -0500
Subject: [R] installing package from source
In-Reply-To: <526962ED.7060604@stats.ox.ac.uk>
References: <1382583217853-4678928.post@n4.nabble.com>
	<5E2F003A-FE6D-4FB3-A02B-E2A4BE1FC14B@comcast.net>
	<14C713F3-F390-4C92-99EE-839BE70D4FE6@me.com>
	<526962ED.7060604@stats.ox.ac.uk>
Message-ID: <7B31320E-DF75-435A-933F-0CE75F53267A@me.com>


On Oct 24, 2013, at 1:11 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On 24/10/2013 18:25, Marc Schwartz wrote:
>> 
>> On Oct 24, 2013, at 11:38 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> 
>>> On Oct 23, 2013, at 7:53 PM, Long Vo wrote:
>>> 
>>>> Hi R users,
>>>> Currently I want to fit a FIGARCH model to a dataset. The only package that
>>>> allow for it that I could find is fGarch. However it seems that the FIGARCH
>>>> model class fitting of this package has been moved to Oxmetrics. I tried to
>>>> install the old versions of it using 'tar.gz' files from CRAN archive
>>>> http://cran.r-project.org/src/contrib/Archive/fGarch/
>>>> <http://cran.r-project.org/src/contrib/Archive/fGarch/>   but not sure how
>>>> it works. I tried
>>>> 
>>>> install.packages("myfilepath\fGarch_260.71.tar.gz", repos = NULL,
>>>> type="source")
>>>> 
>>>> And received this error:
>>>> 
>>>> Warning: invalid package './I:_R filesGarch_260.71.tar.gz'
>>>> Error: ERROR: no packages specified
>>>> Warning messages:
>>>> 1: running command '"I:/01_RFI~1/INSTAL~1/R-30~1.1/bin/i386/R" CMD INSTALL
>>>> -l "I:\01_R files\installment\R-3.0.1\library" "./I:_R files
>>>> Garch_260.71.tar.gz"' had status 1
>>>> 2: In install.packages("I:\001_R files\fGarch_260.71.tar.gz", repos = NULL,
>>>> :
>>>> installation of package ?./I:_R filesGarch_260.71.tar.gz? had non-zero
>>>> exit status
>>>> 
>>>> Any helps on this?
>>>> 
>>> 
>>> I've aways specified the package names and their locations separately in my call to install.packages, but I don't know if that is always needed. It also appears that you have no "/" separator between your path and the file name.
>> 
>> 
>> Long is trying to install a rather old version of the source R package that contains FORTRAN code on Windows.
>> 
>> Besides the immediate error in the way the path was constructed in the install.packages() call, using a single backslash, which needs to be escaped:
>> 
>>   http://cran.r-project.org/bin/windows/base/rw-FAQ.html#R-can_0027t-find-my-file
>> 
>> there are likely to be issues from trying to install an old version of the package on a newer version of R, perhaps the lack of the requisite development tools for compiling FORTRAN:
>> 
>>   http://cran.r-project.org/bin/windows/base/rw-FAQ.html#Can-I-install-packages-into-libraries-in-this-version_003f
>> 
>> and other issues as well.
>> 
>> Depending upon how far back you need to go in package versions, there may be pre-compiled Windows binaries (.zip files) available in directories here:
>> 
>>   http://cran.r-project.org/bin/windows/contrib/
> 
> I don't think so: see NEWS
> 
> CHANGES IN R 3.0.0:
> 
>  SIGNIFICANT USER-VISIBLE CHANGES:
> 
>    ? Packages need to be (re-)installed under this version (3.0.0) of
>      R.
> 
> so only those under bin/windows/contrib/3.0 will work, and there is only one for each package.
> 


Ah, OK. Thanks for noting that Prof. Ripley.

So, Long will need to make some decisions here and it may be worth contacting the fGARCH package maintainer to get any relevant insights into potential gotchas installing an older version of the package on a recent version of R, even from source after installing the needed tools, or having to revert to an older version of R to support the installation of the older package.

Older Windows binaries of R releases are available from:

  http://cran.r-project.org/bin/windows/base/old/

and R 2.6.1 would be about the release that corresponds to the particular version of fGARCH being used above, which is late 2007.

Regards,

Marc


From carl at witthoft.com  Thu Oct 24 20:45:12 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 24 Oct 2013 11:45:12 -0700 (PDT)
Subject: [R] Error in scan?
In-Reply-To: <1382637059013-4678976.post@n4.nabble.com>
References: <1382637059013-4678976.post@n4.nabble.com>
Message-ID: <1382640312758-4678982.post@n4.nabble.com>

Obviously row 11 is incomplete.
It may contain nothing more than a space or an EOL.

Using the "fill=TRUE" argument to 'scan' or 'read.table'  is your friend
here.



--
View this message in context: http://r.789695.n4.nabble.com/Error-in-scan-tp4678976p4678982.html
Sent from the R help mailing list archive at Nabble.com.


From ahmedatia80 at gmail.com  Thu Oct 24 21:10:12 2013
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Thu, 24 Oct 2013 14:10:12 -0500
Subject: [R] Text in a plot without x axis
Message-ID: <CAG6S0Okqm7dGxP1MjhQ1gv46L1E2Y=XcYv69pLYY+LZF29K6TQ@mail.gmail.com>

Dear R users,

Can I add a text to a plot without x axis?

I saw a function that enables placing the text with mouse

text(location, "text to place", pos, ...)

locator(1)

but it did not work out.

-- 
Ahmed M. Attia


Research Assistant
Dept. Of Soil&Crop Sciences
Texas A&M University
ahmed.attia at ag.tamu.edu
Cell phone: 001-979-248-5215


From jvadams at usgs.gov  Thu Oct 24 21:12:27 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 24 Oct 2013 14:12:27 -0500
Subject: [R] Error in heatmap
In-Reply-To: <000301ced0e6$5f806ab0$1e814010$@cinvestav.mx>
References: <000f01cece88$0442bdc0$0cc83940$@cinvestav.mx>
	<CAN5YmCEtBSgEKS6JgmqqqX2mBKRoiKxfYKmvrWRiewqyFK7szQ@mail.gmail.com>
	<000c01cecf3b$75ff9fb0$61fedf10$@cinvestav.mx>
	<CAN5YmCEZb9d2wV1YX=PMgKwV=M=A_8RkWUJLOwPO50sPKHj=dg@mail.gmail.com>
	<000301ced0e6$5f806ab0$1e814010$@cinvestav.mx>
Message-ID: <CAN5YmCHk4OV1ZKVULBeLDkuGj0aJv8oG0B_cFoxhAUMUVmmE3w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/da743da6/attachment.pl>

From smartpink111 at yahoo.com  Thu Oct 24 21:16:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 24 Oct 2013 12:16:00 -0700 (PDT)
Subject: [R] test wilcoxon sur R help!
Message-ID: <1382642160.40137.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
fun1 <- function(dat){
mat1 <- combn(colnames(dat1),2)
?res <- sapply(seq_len(ncol(mat1)),function(i) {x1<- dat[,mat1[,i]]; wilcox.test(x1[,1],x1[,2])$p.value})
names(res) <- apply(mat1,2,paste,collapse="_")
res
}

set.seed(432)
dat1 <- as.data.frame(matrix(sample(18*10,18*10,replace=FALSE),ncol=18))

? fun1(dat1) #gives the p-value for each pair of columns




Hi, 

I want to make a wilcoxon test, i have 18 columns each column 
corresponds to a different sample and i want to compare one to each 
other with a wilcoxon test in one step this is possible ? or do i 
compare two by tow? 

Does it exist a code for automation this test? like this i dont have to type the code for each couple. 

thanks! 
denisse


From ahmedatia80 at gmail.com  Thu Oct 24 21:24:03 2013
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Thu, 24 Oct 2013 14:24:03 -0500
Subject: [R] Custom x axis in a boxplot
Message-ID: <CAG6S0O=__7=viRBWG7=BX7q8-fq_PYyO=41bXKPuG_K1YrLB-A@mail.gmail.com>

Dear R users,

How can I customize x axis in a boxplot?

xaxt="n" to suppress x axis, but I would like to customize x axis for
different groups.

Thanks

-- 
Ahmed M. Attia


Research Assistant
Dept. Of Soil&Crop Sciences
Texas A&M University
ahmed.attia at ag.tamu.edu
Cell phone: 001-979-248-5215

From cadeb at usgs.gov  Thu Oct 24 21:34:49 2013
From: cadeb at usgs.gov (Cade, Brian)
Date: Thu, 24 Oct 2013 13:34:49 -0600
Subject: [R] Nonparametric k-way ANOVA
In-Reply-To: <2FA72E9B-479B-490E-9C29-6E5C2FBED279@gmail.com>
References: <CAHfSo7jFUaPzkV4oBxxkj=GM_POmE=2UB6_6fU6YfvJDrnaEQQ@mail.gmail.com>
	<2FA72E9B-479B-490E-9C29-6E5C2FBED279@gmail.com>
Message-ID: <CAM5M9BTw3cDzBD1+yUc+cWuX_9Ti+t4bSdUVfjSm=kKQvzs5FA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/503b82c2/attachment.pl>

From dcarlson at tamu.edu  Thu Oct 24 21:47:12 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 24 Oct 2013 14:47:12 -0500
Subject: [R] Text in a plot without x axis
In-Reply-To: <CAG6S0Okqm7dGxP1MjhQ1gv46L1E2Y=XcYv69pLYY+LZF29K6TQ@mail.gmail.com>
References: <CAG6S0Okqm7dGxP1MjhQ1gv46L1E2Y=XcYv69pLYY+LZF29K6TQ@mail.gmail.com>
Message-ID: <01a001ced0f1$d568e440$803aacc0$@tamu.edu>

You should provide an example of what you are trying to do. Try
this

> plot(0, 1, xlab="", xaxt="n")
> text(locator(1), "This is my text", xpd=TRUE)

The xpd= parameter controls the clipping region. The default
xpd=FALSE clips text to the plot region. You were not clear, but
if you were trying to plot outside the axes, you need xpd=TRUE
to clip to the figure region or xpd=NA to clip to the device
region.

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Ahmed Attia
Sent: Thursday, October 24, 2013 2:10 PM
To: r-help at r-project.org
Subject: [R] Text in a plot without x axis

Dear R users,

Can I add a text to a plot without x axis?

I saw a function that enables placing the text with mouse

text(location, "text to place", pos, ...)

locator(1)

but it did not work out.

-- 
Ahmed M. Attia


Research Assistant
Dept. Of Soil&Crop Sciences
Texas A&M University
ahmed.attia at ag.tamu.edu
Cell phone: 001-979-248-5215

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From dwinsemius at comcast.net  Thu Oct 24 22:07:04 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 24 Oct 2013 13:07:04 -0700
Subject: [R] labeling abscissa using a function of the plotted scale
In-Reply-To: <1382623207350-4678954.post@n4.nabble.com>
References: <1381510115791-4678075.post@n4.nabble.com>
	<273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>
	<1382565075173-4678917.post@n4.nabble.com>
	<58de215e-0e9f-4aa8-ade5-bcfd4700bd7a@email.android.com>
	<1382582995862-4678927.post@n4.nabble.com>
	<5268B56E.4010000@bitwrit.com.au>
	<1382623207350-4678954.post@n4.nabble.com>
Message-ID: <D26B9878-61FA-4F5F-AEC7-EC82D92F9F38@comcast.net>


On Oct 24, 2013, at 7:00 AM, Hurr wrote:

> Thanks Jim, maybe now I can start learning.
> Here is a run of my trying to learn:
>> xvalue<-c(5.2,1.3,9.7,2.8,8.1,4.7,6.6,7.4)
>> yvalue<-c(9,3,4,7,2,5,3,6)
>> plot(xvalue,yvalue)
>> axis(1,at=NULL,labels=1/xvalue,digits=5)
> Error in axis(1, at = NULL, labels = 1/xvalue, digits = 5) :
>  'labels' is supplied and not 'at'
> In addition: Warning message:
> In axis(1, at = NULL, labels = 1/xvalue, digits = 5) :
>  "digits" is not a graphical parameter
>> 
> Why can't R automatically compute the spacing when I use the formula?

I don't see any formula. If you are talking about the expression `1/xvalue`, it is going to be a decimal fraction and it will be coerced to a character value before being assigned to 'labels'. As explained in the help page for `axis`, when "at" is left as NULL, the positions will be computed from par("xaxt"). But you gave only a numeric argument to labels and did not tell axis where you wanted these values were to be placed. If those values were interpreted as being positions they would have been off the left side of the "paper".

 If you don't like the way 'axis' works, you are welcome to write a new axis function that processes numeric arguments to labels differently. But in this case you appear to think that R kept a record someplace of the argument to x in the preceding plot. _That_ is wishful thinking on your part. If you want a plotting paradigm that may record x and y values, then look at lattice or ggplot2. Base graphics is mostly ( memoryless ) ink-on-paper, although there may be some information accessible via `par`.

> How can I specify n-digits or width instead of round or nothing? 

?sprintf
?formatC
> 
-- 

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Thu Oct 24 22:32:07 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 24 Oct 2013 15:32:07 -0500
Subject: [R] Custom x axis in a boxplot
In-Reply-To: <CAG6S0O=__7=viRBWG7=BX7q8-fq_PYyO=41bXKPuG_K1YrLB-A@mail.gmail.com>
References: <CAG6S0O=__7=viRBWG7=BX7q8-fq_PYyO=41bXKPuG_K1YrLB-A@mail.gmail.com>
Message-ID: <01bf01ced0f8$1b8ceb50$52a6c1f0$@tamu.edu>

?axis

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Ahmed Attia
Sent: Thursday, October 24, 2013 2:24 PM
To: r-help at r-project.org
Subject: [R] Custom x axis in a boxplot

Dear R users,

How can I customize x axis in a boxplot?

xaxt="n" to suppress x axis, but I would like to customize x
axis for
different groups.

Thanks

-- 
Ahmed M. Attia


Research Assistant
Dept. Of Soil&Crop Sciences
Texas A&M University
ahmed.attia at ag.tamu.edu
Cell phone: 001-979-248-5215


From ruipbarradas at sapo.pt  Thu Oct 24 22:45:54 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 24 Oct 2013 21:45:54 +0100
Subject: [R] test wilcoxon sur R help!
In-Reply-To: <1382642160.40137.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1382642160.40137.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <52698702.6060907@sapo.pt>

Hello,

There's a bug in your function, it should be 'dat', not 'dat1'. In the 
line marked, below.

fun1 <- function(dat){
	mat1 <- combn(colnames(dat),2)  # Here, 'dat' not 'dat1'
	res <- sapply(seq_len(ncol(mat1)),function(i) {x1<- dat[,mat1[,i]]; 
wilcox.test(x1[,1],x1[,2])$p.value})
	names(res) <- apply(mat1,2,paste,collapse="_")
	res
}


Hope this helps,

Rui Barradas

Em 24-10-2013 20:16, arun escreveu:
> Hi,
> Try:
> fun1 <- function(dat){
> mat1 <- combn(colnames(dat1),2)
>   res <- sapply(seq_len(ncol(mat1)),function(i) {x1<- dat[,mat1[,i]]; wilcox.test(x1[,1],x1[,2])$p.value})
> names(res) <- apply(mat1,2,paste,collapse="_")
> res
> }
>
> set.seed(432)
> dat1 <- as.data.frame(matrix(sample(18*10,18*10,replace=FALSE),ncol=18))
>
>    fun1(dat1) #gives the p-value for each pair of columns
>
>
>
>
> Hi,
>
> I want to make a wilcoxon test, i have 18 columns each column
> corresponds to a different sample and i want to compare one to each
> other with a wilcoxon test in one step this is possible ? or do i
> compare two by tow?
>
> Does it exist a code for automation this test? like this i dont have to type the code for each couple.
>
> thanks!
> denisse
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Wed Oct 23 06:50:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 22 Oct 2013 21:50:47 -0700 (PDT)
Subject: [R] Help parsing from .txt
Message-ID: <1382503847.4061.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
You may try:
?list.files()
nm1 <- list.files(pattern=".txt")

res <- lapply(nm1,function(x) {
??? ??? ??? ??? ??? ??? ??? ??? ln1 <- readLines(x)
???????????????????????????????? indx1 <- grep("DATE PROCESSED",ln1)
???????????????????????????????? indx2 <- grep("[A-Z]",ln1)
???????????????????????????????? ln2 <- if(max(indx2)==indx1) ln1[1:length(ln1)] else ln1[1:(indx2[match(indx1,indx2)+1]-1)]
???????????????????????????????? ln2 <- ln2[ln2!=""]
???????????????????????????????? indx3 <- grepl("[A-Z]",ln2)
???????????????????????????????? indx4 <- cumsum(c(TRUE,diff(which(!indx3))>1))
??? ??? ??? ??? ??? ??? ??? ??? mat1 <- do.call(cbind, split(ln2[!indx3],indx4))
???????????????????????????????? colnames(mat1) <-? ln2[indx3][-1]
???????????????????????????????? write.table(mat1,paste0(ln2[indx3][1],".txt"),row.names=FALSE,quote=FALSE,sep="\t")})



A.K.


I have a number of .txt files (1,200) from which I need to parse a 
number of pieces of information. ?The files are read into R as such: 

TITLE 
EXAMPLE 
example 1 
example 2 
RELATED TITLE 
related title 1 
DATE PROCESSED 
06/12/2011 

Some of the files have examples 1-4, others 1-12 and beyond. ? 

How can I create a script that will grab the information from 
the different .txt files, put it in a matrix, and spit it out in a .csv 
file with appropriately named columns (the column titles are in CAPS 
above, where the information that will in the column is lower case). 

Thanks in advance.


From mdsumner at gmail.com  Thu Oct 24 22:57:38 2013
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 25 Oct 2013 07:57:38 +1100
Subject: [R] track on boats
In-Reply-To: <CAN5YmCFT8K8_yJbcV5sGjP63Gq8TOxPDfxxwT28thi4w6O3iUA@mail.gmail.com>
References: <DUB119-W33824BB4C6058C7D8269A18F0C0@phx.gbl>
	<CAN5YmCFT8K8_yJbcV5sGjP63Gq8TOxPDfxxwT28thi4w6O3iUA@mail.gmail.com>
Message-ID: <CAAcGz98Lp-bCyekmcn+TSxdV_T6+yOsb_V9j5ySe9tc1YQyN9Q@mail.gmail.com>

There are several packages for track data on CRAN and they don't all
force the data to have "specific variables" beyond position,
date-time, track ID. With trip you can do this easily enough, but
depending on your needs adehabitatLT or move might be better.  I wrote
trip so I know that you can do this (pseudo code that assumes columns
"X", "Y", "date", "ID" for the obvious components), you get plot
control of separate lines and basic data QC for free (welcome or not):

library(trip)
d <- read.csv("myfile.csv")
## sort out date-times
d$datetime <- as.POSIXct(d$date, [format etc])

## specify the X/Y coordinates (use your relevant column names)
coordinates(d) <- c("X", "Y")

## create trip object
tr <- trip(d, c("datetime", "ID"))

(If your data are out of order by ID,time or if there are duplicates
or missing values or other problems that will complain and not make
assumptions, but these are things that should be dealt with explicitly
IMO.)

## then you can plot the separate tracks in a minimal way
plot(tr)
lines(tr)

There is general support for reading and manipulating spatial data
with packages sp, raster, maptools and friends. See the "Spatial" and
"SpatioTemporal" Task Views, and consider R-Sig-Geo rather than R-help
for questions like this.  I agree that "Animal Tracking" is too
specific for your needs, but there's certainly room for generalizing
this to other domains easily enough. The trip package is too simple
and awkward for many things, but for basic use there's no built-in
assumptions that track data are from animals (though the label on the
lid does specify that).

HTH




On Fri, Oct 25, 2013 at 3:08 AM, Adams, Jean <jvadams at usgs.gov> wrote:
> It is difficult to advise you when you don't provide reproducible data.
>  For example, you could include the first 6 lines of your data using
>      dput(head(mydata))
>
> If you have GPS points stored as easting, northing, and if you have a
> variable that identifies the vessel, and if your data are sorted by date
> and time, then you might be able to get the plot you want using something
> like this:
>
> plot(easting[vessel="This One"], northing[vessel="This One"], type="l")
>
> Jean
>
>
> On Thu, Oct 24, 2013 at 4:40 AM, Marta Tobe?a <marta_mtm at hotmail.com> wrote:
>
>> Hi professors
>> I'm finding the best package in R for manage a big database about vessels.
>> I need to divided the travel of each boat into tracks. I have GPS points.
>>
>> I would join these points in a line on the map. I make that with the
>> function "lines", but I can't divided by vessel or by track,
>>
>> I saw several packages, for tracking animals but they had specifically
>> variables. And I don't add others like  "type","destination" or "status".
>>
>> Can you give me a suggestion, please
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Michael Sumner
Hobart, Australia
e-mail: mdsumner at gmail.com


From macqueen1 at llnl.gov  Thu Oct 24 23:08:33 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 24 Oct 2013 21:08:33 +0000
Subject: [R] track on boats
In-Reply-To: <DUB119-W33824BB4C6058C7D8269A18F0C0@phx.gbl>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D4EB03F@PRDEXMBX-08.the-lab.llnl.gov>

A good choice might be to store your data in objects of class
   SpatialLinesDataFrame

Then you can assign any attributes you want to each line, such as your
vessel, type, destination, or status.

This will make it relatively easy to, for example, plot subsets of tracks
specified by different attributes.

SpatialLinesDataFrame objects are defined in the sp package.

For further help, I would suggest the r-sig-geo mailing list. Also look at
the CRAN Task View "Spatial".

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/24/13 2:40 AM, "Marta Tobe?a" <marta_mtm at hotmail.com> wrote:

>Hi professors
>I'm finding the best package in R for manage a big database about
>vessels. I need to divided the travel of each boat into tracks. I have
>GPS points.
>
>I would join these points in a line on the map. I make that with the
>function "lines", but I can't divided by vessel or by track,
>
>I saw several packages, for tracking animals but they had specifically
>variables. And I don't add others like  "type","destination" or "status".
>
>Can you give me a suggestion, please
> 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Oct 25 00:24:40 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 24 Oct 2013 15:24:40 -0700 (PDT)
Subject: [R] How to calculate running 8-hour averages of temperature
Message-ID: <1382653480.29366.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
You may try
?rollmean from library(zoo)
?SMA from library(TTR)
dat1 <- structure(...
library(zoo)

res1 <- rollmean(dat1[-c(1:5),2],8)
library(TTR)
res2 <- SMA(dat1[-c(1:5),2],8)
?all.equal(res1,res2[!is.na(res2)])
#[1] TRUE



A.K.

Hi, 

How can I calculate running 8-hour averages of temperature 
values that start at specific date and time? In the example data set 
shown below I want to start the calculation on May 31, at 5pm (row 6). 
Reproducible data is provided. 

Thanks 
structure(list(date = structure(c(644148000, 644151600, 644155200, 
644158800, 644162400, 644166000, 644169600, 644173200, 644176800, 
644180400, 644184000, 644187600, 644191200, 644194800, 644198400, 
644202000, 644205600, 644209200, 644212800, 644216400, 644220000, 
644223600, 644227200, 644230800, 644234400, 644238000, 644241600, 
644245200, 644248800, 644252400, 644256000), class = c("POSIXct", 
"POSIXt"), tzone = ""), temp = c(17.7, 18.3, 18.9, 19.7, 19.5, 
19, 18.8, 18, 16.3, 15.1, 13.9, 12.7, 11.9, 10.6, 10, 8.7, 7.89999, 
8.09999, 9.29999, 12.4, 14.5, 15.9, 17.4, 18.6, 18.3, 18.4, 18.5, 
20.4, 19.7, 18.9, 18.1)), .Names = c("date", "temp"), row.names = 3613:3643, class = "data.frame")


From r.turner at auckland.ac.nz  Fri Oct 25 00:37:46 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 25 Oct 2013 11:37:46 +1300
Subject: [R] bug in dummy.coef?
In-Reply-To: <0566E17B6DEC62459078112371B7508E0F1B7D@ait-pex02mbx05.win.dtu.dk>
References: <0566E17B6DEC62459078112371B7508E0F1B7D@ait-pex02mbx05.win.dtu.dk>
Message-ID: <5269A13A.8040408@auckland.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131025/d1837f09/attachment.pl>

From jim at bitwrit.com.au  Fri Oct 25 00:49:55 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 25 Oct 2013 09:49:55 +1100
Subject: [R] labeling abscissa using a function of the plotted scale
In-Reply-To: <1382623207350-4678954.post@n4.nabble.com>
References: <1381510115791-4678075.post@n4.nabble.com>	<273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>	<1382565075173-4678917.post@n4.nabble.com>	<58de215e-0e9f-4aa8-ade5-bcfd4700bd7a@email.android.com>	<1382582995862-4678927.post@n4.nabble.com>	<5268B56E.4010000@bitwrit.com.au>
	<1382623207350-4678954.post@n4.nabble.com>
Message-ID: <5269A413.3030703@bitwrit.com.au>

On 10/25/2013 01:00 AM, Hurr wrote:
> Thanks Jim, maybe now I can start learning.
> Here is a run of my trying to learn:
>> xvalue<-c(5.2,1.3,9.7,2.8,8.1,4.7,6.6,7.4)
>> yvalue<-c(9,3,4,7,2,5,3,6)
>> plot(xvalue,yvalue)
>> axis(1,at=NULL,labels=1/xvalue,digits=5)
> Error in axis(1, at = NULL, labels = 1/xvalue, digits = 5) :
>    'labels' is supplied and not 'at'
> In addition: Warning message:
> In axis(1, at = NULL, labels = 1/xvalue, digits = 5) :
>    "digits" is not a graphical parameter
>>
> Why can't R automatically compute the spacing when I use the formula?
> How can I specify n-digits or width instead of round or nothing?
>
Hi Hurr,
Let's see, suppose I answered your message like this:

answer1<-NULL

You would be in the same position as the axis function. You have to tell 
the axis function where the labels are to be placed, or it can't place 
them there. Now for your second question. Suppose my answer was 
something like this:

answer2<-"wpsovmeksjhfhtieur" # language = Magungian

You might well respond that you don't understand Magungian. The argument 
"digits" doesn't tell the axis function anything useful. If you want 
labels with a certain number of digits, create them before you call the 
axis function:

mylabels<-round(1/xvalue,digits=5)

The round function understands Magungian.

Jim


From hill0093 at umn.edu  Fri Oct 25 00:56:02 2013
From: hill0093 at umn.edu (Hurr)
Date: Thu, 24 Oct 2013 15:56:02 -0700 (PDT)
Subject: [R] labeling abscissa using a function of the plotted scale
In-Reply-To: <D26B9878-61FA-4F5F-AEC7-EC82D92F9F38@comcast.net>
References: <1381510115791-4678075.post@n4.nabble.com>
	<273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>
	<1382565075173-4678917.post@n4.nabble.com>
	<58de215e-0e9f-4aa8-ade5-bcfd4700bd7a@email.android.com>
	<1382582995862-4678927.post@n4.nabble.com>
	<5268B56E.4010000@bitwrit.com.au>
	<1382623207350-4678954.post@n4.nabble.com>
	<D26B9878-61FA-4F5F-AEC7-EC82D92F9F38@comcast.net>
Message-ID: <1382655359855-4679004.post@n4.nabble.com>

Thanks David, did I use incorrect english to call "labels = 1/xvalue" a
formula or function?
Seems to me an obvious first try would be to place the labels where 
they would have been placed without the formula.
I haven't yet, but I will study from your suggestions.




--
View this message in context: http://r.789695.n4.nabble.com/labeling-abscissa-using-a-function-of-the-plotted-scale-tp4678075p4679004.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Fri Oct 25 00:57:36 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 24 Oct 2013 15:57:36 -0700
Subject: [R] bug in dummy.coef?
In-Reply-To: <0566E17B6DEC62459078112371B7508E0F1B7D@ait-pex02mbx05.win.dtu.dk>
References: <0566E17B6DEC62459078112371B7508E0F1B7D@ait-pex02mbx05.win.dtu.dk>
Message-ID: <839AE7D9-E55B-4605-BBD3-2C5ED3E4EEF6@comcast.net>


On Oct 24, 2013, at 1:51 AM, Alexandra Kuznetsova wrote:

> Dear all,
> 
> Running the following code produces an error in dummy.coef. I guess it might be a bug..
> 
>> ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
>> trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
>> group <- gl(2, 10, 20, labels = c("Ctl","Trt"))
>> weight <- c(ctl, trt)
>> x <- rnorm(length(weight))
>> lm.D9 <- lm(weight ~ group + x + I(x^2))
>> dummy.coef(lm.D9)
> Error in rep.int(xl[[i]][1L], nl) : invalid 'times' value

As Rolf Turner pointed out the help page says there are limitations to that function and its only desiged for specific purposes. What are you trying to accomplish?

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Oct 25 01:14:08 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 24 Oct 2013 16:14:08 -0700
Subject: [R] labeling abscissa using a function of the plotted scale
In-Reply-To: <1382655359855-4679004.post@n4.nabble.com>
References: <1381510115791-4678075.post@n4.nabble.com>
	<273BD2F5-3CB1-4AAE-84AD-9C6AA5B61130@comcast.net>
	<1382565075173-4678917.post@n4.nabble.com>
	<58de215e-0e9f-4aa8-ade5-bcfd4700bd7a@email.android.com>
	<1382582995862-4678927.post@n4.nabble.com>
	<5268B56E.4010000@bitwrit.com.au>
	<1382623207350-4678954.post@n4.nabble.com>
	<D26B9878-61FA-4F5F-AEC7-EC82D92F9F38@comcast.net>
	<1382655359855-4679004.post@n4.nabble.com>
Message-ID: <BCCA7457-396E-4028-BF10-E4E35D05A1C1@comcast.net>


On Oct 24, 2013, at 3:56 PM, Hurr wrote:

> Thanks David, did I use incorrect english to call "e" a
> formula or function?

Incorrect R terminology. A function in R is a specific sort of object and a formula is a different sort of object.  R terminology for the use of "labels = 1/xvalue" inside the arguments to a function may be something along the lines of "assignment in a pairlist". I was rather loosely calling it an "expression".

> Seems to me an obvious first try would be to place the labels where 
> they would have been placed without the formula.

And as I said in the context you have failed to include was that R does not "rememeber" or "store" the locations "where where they would have been placed without the formula." It doesn't have access to the arguments used in the prior plot call.

> I haven't yet, but I will study from your suggestions.

> 
> --
> View this message in context: http://r.789695.n4.nabble.com/labeling-abscissa-using-a-function-of-the-plotted-scale-tp4678075p4679004.html
> Sent from the R help mailing list archive at Nabble.com.

Nabble is not R-help. Please read the Posting Guide that Nabble suppresses in its effort to masquerade as Rhelp.

This should have appeared at the bottom of every posting were it not for Nabble suppressing it:

R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 
David Winsemius
Alameda, CA, USA


From dmvxic at gmail.com  Thu Oct 24 22:47:26 2013
From: dmvxic at gmail.com (David Mora)
Date: Thu, 24 Oct 2013 14:47:26 -0600
Subject: [R] Optional argument to be used in a subset function
In-Reply-To: <CACaVdgQv6j1qDBq3VZQB69QkU7zy9VS7AZEH0dQfSUv6uB5wxw@mail.gmail.com>
References: <CACaVdgQv6j1qDBq3VZQB69QkU7zy9VS7AZEH0dQfSUv6uB5wxw@mail.gmail.com>
Message-ID: <CACaVdgS0Yqz4UWR0sXsxWi2-qi_4bb1HEAX1-YeuKo3Z7POVgg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/8f190937/attachment.pl>

From ch.haeni at gmail.com  Thu Oct 24 20:59:36 2013
From: ch.haeni at gmail.com (=?ISO-8859-1?Q?Christoph_H=E4ni?=)
Date: Thu, 24 Oct 2013 20:59:36 +0200
Subject: [R] Making a function and applying it over a list(?)
In-Reply-To: <4DF642A8A770C24090F37AC3560BBA14F67578@EDAEXCH02A.local.energidanmark.dk>
References: <4DF642A8A770C24090F37AC3560BBA14F67578@EDAEXCH02A.local.energidanmark.dk>
Message-ID: <CAOKy5g_eX-+gVsLWuKEN1KocXCff4yutzLgG9BmKxPOJQoGBkA@mail.gmail.com>

You could store your first approach in a function and lapply it to
your by_hour variable:

  df <- data.frame(
hour = factor(rep(1:5,4)),
  id       = factor(rep(c("supply", "demand"), each = 10)),
  price    = c(5,7,9,11,13,15,17,19,21,23,
20,18,16,14,12,10,8,6,4,2 ),
  quantity = c(3,5,7,13,19,31,37,53,61,67,6,18,20,24,40,46,66,70,76,78)
)

myfu <- function(x){

df <- x # for simplicity

quantity_points <- with(
  df,
  seq(min(quantity), max(quantity), length.out = 500)
)

by_id <- split(df[, c("price", "quantity")], df$id)

interpolated_price <- lapply(
  by_id,
  function(x)
  {
    with(
      x,
      approx(
        quantity,
        price,
        xout = quantity_points
      )
    )$y
  }
)

index_of_equality <- with(interpolated_price, which.min(abs(supply - demand)))
quantity_points[index_of_equality]

}

by_hour <- split(df,df$hour)

lapply(by_hour,myfu)


Was that what you were looking for?

Cheers,
Christoph


2013/10/24 Lasse Thorst <lath at energidanmark.dk>:
> Hi All
>
> I've gotten some awesome help getting a formular that finds the intersection of two vectors. This works brilliantly, but I can't figure out how to make it run over another factor. A simple example looks likes this:
>
>   df <- data.frame(
>   id       = factor(rep(c("supply", "demand"), each = 10)),
>   price    = c(5,7,9,11,13,15,17,19,21,23,20,18,16,14,12,10,8,6,4,2 ),
>   quantity = c(3,5,7,13,19,31,37,53,61,67,6,18,20,24,40,46,66,70,76,78)
> )
>
> quantity_points <- with(
>   df,
>   seq(min(quantity), max(quantity), length.out = 500)
> )
>
> by_id <- split(df[, c("price", "quantity")], df$id)
>
> interpolated_price <- lapply(
>   by_id,
>   function(x)
>   {
>     with(
>       x,
>       approx(
>         quantity,
>         price,
>         xout = quantity_points
>       )
>     )$y
>   }
> )
>
> index_of_equality <- with(interpolated_price, which.min(abs(supply - demand)))
> quantity_points[index_of_equality]
>
> Question: I need to run this over a larger data frame, where I have the same data, but also a new factor variable (called hour). So if you have the original data frame and add:
>
>   df <- data.frame(
> hour = factor(seq(1:20)),
>   id       = factor(rep(c("supply", "demand"), each = 10)),
>   price    = c(5,7,9,11,13,15,17,19,21,23,20,18,16,14,12,10,8,6,4,2 ),
>   quantity = c(3,5,7,13,19,31,37,53,61,67,6,18,20,24,40,46,66,70,76,78)
> )
>
> How can I run it for each hour? I tried using:
> by_hour <- split(df[, c("price", "quantity")], df$hour)
> mapply(fx, by_hour)
>
> And gathering the above into a fx <- function(){"the neat code"}, but I can't get it to work.
>
> Kind Regards,
> Lasse
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alku at dtu.dk  Thu Oct 24 22:25:55 2013
From: alku at dtu.dk (Alexandra Kuznetsova)
Date: Thu, 24 Oct 2013 20:25:55 +0000
Subject: [R] bug in dummy.coef?
In-Reply-To: <0566E17B6DEC62459078112371B7508E0F1B7D@ait-pex02mbx05.win.dtu.dk>
References: <0566E17B6DEC62459078112371B7508E0F1B7D@ait-pex02mbx05.win.dtu.dk>
Message-ID: <0566E17B6DEC62459078112371B7508E0F1FC4@ait-pex02mbx05.win.dtu.dk>



Dear all,

Running the following code produces an error in dummy.coef. I guess it might be a bug..
> ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
> trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
> group <- gl(2, 10, 20, labels = c("Ctl","Trt"))
> weight <- c(ctl, trt)
> x <- rnorm(length(weight))
> lm.D9 <- lm(weight ~ group + x + I(x^2))
> dummy.coef(lm.D9)
Error in rep.int(xl[[i]][1L], nl) : invalid 'times' value

> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Danish_Denmark.1252  LC_CTYPE=Danish_Denmark.1252    LC_MONETARY=Danish_Denmark.1252
[4] LC_NUMERIC=C                    LC_TIME=Danish_Denmark.1252

attached base packages:
[1] parallel  splines   stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
 [1] pbkrtest_0.3-5    MASS_7.3-26       Hmisc_3.12-2      Formula_1.1-1     survival_2.37-4   numDeriv_2012.9-1
 [7] lmerTest_2.0-1    lme4_1.1-1        Matrix_1.0-12     lattice_0.20-15

loaded via a namespace (and not attached):
[1] cluster_1.14.4 gdata_2.13.2   gplots_2.11.3  grid_3.0.1     gtools_3.0.0   minqa_1.2.1    nlme_3.1-109
[8] rpart_4.1-1    tools_3.0.1


With best wishes,
Alexandra


________________________________________
From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on behalf of Alexandra Kuznetsova [alku at dtu.dk]
Sent: Thursday, October 24, 2013 10:51 AM
To: r-help at r-project.org
Subject: [R] bug in dummy.coef?

Dear all,

Running the following code produces an error in dummy.coef. I guess it might be a bug..

> ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
> trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
> group <- gl(2, 10, 20, labels = c("Ctl","Trt"))
> weight <- c(ctl, trt)
> x <- rnorm(length(weight))
> lm.D9 <- lm(weight ~ group + x + I(x^2))
> dummy.coef(lm.D9)
Error in rep.int(xl[[i]][1L], nl) : invalid 'times' value



> sessionInfo()

R version 3.0.1 (2013-05-16)

Platform: x86_64-w64-mingw32/x64 (64-bit)



locale:

[1] LC_COLLATE=Danish_Denmark.1252  LC_CTYPE=Danish_Denmark.1252    LC_MONETARY=Danish_Denmark.1252

[4] LC_NUMERIC=C                    LC_TIME=Danish_Denmark.1252



attached base packages:

[1] parallel  splines   stats     graphics  grDevices utils     datasets  methods   base



other attached packages:

 [1] pbkrtest_0.3-5    MASS_7.3-26       Hmisc_3.12-2      Formula_1.1-1     survival_2.37-4   numDeriv_2012.9-1

 [7] lmerTest_2.0-1    lme4_1.1-1        Matrix_1.0-12     lattice_0.20-15



loaded via a namespace (and not attached):

[1] cluster_1.14.4 gdata_2.13.2   gplots_2.11.3  grid_3.0.1     gtools_3.0.0   minqa_1.2.1    nlme_3.1-109

[8] rpart_4.1-1    tools_3.0.1




With best wishes,
Alexandra

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From dromero at mda.cinvestav.mx  Thu Oct 24 23:50:25 2013
From: dromero at mda.cinvestav.mx (David Romero)
Date: Thu, 24 Oct 2013 16:50:25 -0500
Subject: [R] Error in heatmap
In-Reply-To: <CAN5YmCHk4OV1ZKVULBeLDkuGj0aJv8oG0B_cFoxhAUMUVmmE3w@mail.gmail.com>
References: <000f01cece88$0442bdc0$0cc83940$@cinvestav.mx>
	<CAN5YmCEtBSgEKS6JgmqqqX2mBKRoiKxfYKmvrWRiewqyFK7szQ@mail.gmail.com>
	<000c01cecf3b$75ff9fb0$61fedf10$@cinvestav.mx>
	<CAN5YmCEZb9d2wV1YX=PMgKwV=M=A_8RkWUJLOwPO50sPKHj=dg@mail.gmail.com>
	<000301ced0e6$5f806ab0$1e814010$@cinvestav.mx>
	<CAN5YmCHk4OV1ZKVULBeLDkuGj0aJv8oG0B_cFoxhAUMUVmmE3w@mail.gmail.com>
Message-ID: <000e01ced103$0c301d70$24905850$@cinvestav.mx>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/5ea2f513/attachment.pl>

From pnelson at cfr-west.org  Fri Oct 25 02:02:28 2013
From: pnelson at cfr-west.org (Peter Nelson)
Date: Thu, 24 Oct 2013 17:02:28 -0700
Subject: [R] moving points labels in ordinations
Message-ID: <2F48CD93-2518-4078-8069-8CE673035CAC@cfr-west.org>

I'm trying to place labels so as to avoid covering points (and other labels) in an ordination plot. I've been trying to use orditkplot() for this  purpose, but get an error message, even when I try to replicate the example: 

>require("vegan")
>data(varespec)
> ord <- cca(varespec)
> orditkplot(ord, mar = c(4,4,1,1)+.1, font=3)
Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") : 
  [tcl] invalid command name "tk".
In addition: Warning message:
In fun(libname, pkgname) : couldn't connect to display ":0"
> 

Any ideas? Thanks, Pete

From mgstauff at gmail.com  Fri Oct 25 03:33:55 2013
From: mgstauff at gmail.com (Michael Stauffer)
Date: Thu, 24 Oct 2013 21:33:55 -0400
Subject: [R] 'yum install R' failing with tcl/tk issue
Message-ID: <CANBOegLZ0Q36J-Rddq0_OmSXyp6pFPCb5ORYiJhAS0jVkkdGhg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131024/00d09c5d/attachment.pl>

From blot_za at yahoo.com  Fri Oct 25 02:42:31 2013
From: blot_za at yahoo.com (busisiwe mlotshwa)
Date: Fri, 25 Oct 2013 02:42:31 +0200
Subject: [R] How Are You R-help?
Message-ID: <F1.18.04431.97EB9625@smtp01.insight.synacor.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131025/d44b4567/attachment.pl>

From babuawara at gmail.com  Fri Oct 25 06:05:04 2013
From: babuawara at gmail.com (vikram ranga)
Date: Fri, 25 Oct 2013 09:35:04 +0530
Subject: [R] test wilcoxon sur R help!
In-Reply-To: <52698702.6060907@sapo.pt>
References: <1382642160.40137.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<52698702.6060907@sapo.pt>
Message-ID: <CAL-ALVFrAH3Omi6fCx2ZKLmHzdVmVZP_46swpFmBMwKZ7q-MKw@mail.gmail.com>

Hi,
Check out this function:-
pairwise.wilcox.test {package=stats}.

example(pairwise.wilcox.test)


On Fri, Oct 25, 2013 at 2:15 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> There's a bug in your function, it should be 'dat', not 'dat1'. In the line
> marked, below.
>
> fun1 <- function(dat){
>         mat1 <- combn(colnames(dat),2)  # Here, 'dat' not 'dat1'
>
>         res <- sapply(seq_len(ncol(mat1)),function(i) {x1<- dat[,mat1[,i]];
> wilcox.test(x1[,1],x1[,2])$p.value})
>         names(res) <- apply(mat1,2,paste,collapse="_")
>         res
> }
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 24-10-2013 20:16, arun escreveu:
>
>> Hi,
>> Try:
>> fun1 <- function(dat){
>> mat1 <- combn(colnames(dat1),2)
>>   res <- sapply(seq_len(ncol(mat1)),function(i) {x1<- dat[,mat1[,i]];
>> wilcox.test(x1[,1],x1[,2])$p.value})
>> names(res) <- apply(mat1,2,paste,collapse="_")
>> res
>> }
>>
>> set.seed(432)
>> dat1 <- as.data.frame(matrix(sample(18*10,18*10,replace=FALSE),ncol=18))
>>
>>    fun1(dat1) #gives the p-value for each pair of columns
>>
>>
>>
>>
>> Hi,
>>
>> I want to make a wilcoxon test, i have 18 columns each column
>> corresponds to a different sample and i want to compare one to each
>> other with a wilcoxon test in one step this is possible ? or do i
>> compare two by tow?
>>
>> Does it exist a code for automation this test? like this i dont have to
>> type the code for each couple.
>>
>> thanks!
>> denisse
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Oct 25 06:38:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 24 Oct 2013 21:38:19 -0700 (PDT)
Subject: [R] test wilcoxon sur R help!
In-Reply-To: <CAL-ALVFrAH3Omi6fCx2ZKLmHzdVmVZP_46swpFmBMwKZ7q-MKw@mail.gmail.com>
References: <1382642160.40137.YahooMailNeo@web142606.mail.bf1.yahoo.com>	<52698702.6060907@sapo.pt>
	<CAL-ALVFrAH3Omi6fCx2ZKLmHzdVmVZP_46swpFmBMwKZ7q-MKw@mail.gmail.com>
Message-ID: <1382675899.90881.YahooMailNeo@web142606.mail.bf1.yahoo.com>

It looks much better than mine.


with p value adjustment:
p.adjust(fun1(dat1), method = "holm", n = 153)
#########

dat1$id <- 1:10
library(reshape2)
dat2 <- melt(dat1,id.var="id")
with(dat2,pairwise.wilcox.test(value,variable))
?with(dat2,pairwise.wilcox.test(value,variable,p.adj="none")) 


A.K.




On Friday, October 25, 2013 12:05 AM, vikram ranga <babuawara at gmail.com> wrote:
Hi,
Check out this function:-
pairwise.wilcox.test {package=stats}.

example(pairwise.wilcox.test)


On Fri, Oct 25, 2013 at 2:15 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> There's a bug in your function, it should be 'dat', not 'dat1'. In the line
> marked, below.
>
> fun1 <- function(dat){
>? ? ? ?  mat1 <- combn(colnames(dat),2)? # Here, 'dat' not 'dat1'
>
>? ? ? ?  res <- sapply(seq_len(ncol(mat1)),function(i) {x1<- dat[,mat1[,i]];
> wilcox.test(x1[,1],x1[,2])$p.value})
>? ? ? ?  names(res) <- apply(mat1,2,paste,collapse="_")
>? ? ? ?  res
> }
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 24-10-2013 20:16, arun escreveu:
>
>> Hi,
>> Try:
>> fun1 <- function(dat){
>> mat1 <- combn(colnames(dat1),2)
>>?  res <- sapply(seq_len(ncol(mat1)),function(i) {x1<- dat[,mat1[,i]];
>> wilcox.test(x1[,1],x1[,2])$p.value})
>> names(res) <- apply(mat1,2,paste,collapse="_")
>> res
>> }
>>
>> set.seed(432)
>> dat1 <- as.data.frame(matrix(sample(18*10,18*10,replace=FALSE),ncol=18))
>>
>>? ? fun1(dat1) #gives the p-value for each pair of columns
>>
>>
>>
>>
>> Hi,
>>
>> I want to make a wilcoxon test, i have 18 columns each column
>> corresponds to a different sample and i want to compare one to each
>> other with a wilcoxon test in one step this is possible ? or do i
>> compare two by tow?
>>
>> Does it exist a code for automation this test? like this i dont have to
>> type the code for each couple.
>>
>> thanks!
>> denisse
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From kridox at ymail.com  Fri Oct 25 07:35:30 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 25 Oct 2013 14:35:30 +0900
Subject: [R] 'yum install R' failing with tcl/tk issue
In-Reply-To: <CANBOegLZ0Q36J-Rddq0_OmSXyp6pFPCb5ORYiJhAS0jVkkdGhg@mail.gmail.com>
References: <CANBOegLZ0Q36J-Rddq0_OmSXyp6pFPCb5ORYiJhAS0jVkkdGhg@mail.gmail.com>
Message-ID: <CAAcyNCxiLstitD_pNxYQeMeVhUOymxs4BVFKW+pB6DBggcGrdQ@mail.gmail.com>

Hello,

Do you have headers installed (generally tcl-devel and tk-devel)?

Regards,
Pascal


On 25 October 2013 10:33, Michael Stauffer <mgstauff at gmail.com> wrote:
> Hi,
>
> I'm trying to install R on CentOS 6.4.
>
> Following some instructions online, I've done this:
>
> rpm -Uvh
> http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm
>
> yum install R
>
> But yum fails, with this (full output below):
>
> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>            Requires: libtcl8.4.so()(64bit)
> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>            Requires: libtk8.4.so()(64bit)
>
> I have tcl/tk 8.5 already installed. Does anyone have any suggestion?
> Thanks!
>
> Full output:
>
> [root at picsl-cluster ~]# yum install R
> Repository base is listed more than once in the configuration
> Rocks-6.1
>                           | 1.9 kB     00:00
> base
>                            | 3.7 kB     00:00
> Setting up Install Process
> Resolving Dependencies
> --> Running transaction check
> ---> Package R.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: libRmath-devel = 2.10.0-2.el5 for package:
> R-2.10.0-2.el5.x86_64
> --> Processing Dependency: R-devel = 2.10.0-2.el5 for package:
> R-2.10.0-2.el5.x86_64
> --> Running transaction check
> ---> Package R-devel.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: R-core = 2.10.0-2.el5 for package:
> R-devel-2.10.0-2.el5.x86_64
> ---> Package libRmath-devel.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: libRmath = 2.10.0-2.el5 for package:
> libRmath-devel-2.10.0-2.el5.x86_64
> --> Running transaction check
> ---> Package R-core.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: libtk8.4.so()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> --> Processing Dependency: libtcl8.4.so()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> --> Processing Dependency: libgfortran.so.1()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> ---> Package libRmath.x86_64 0:2.10.0-2.el5 will be installed
> --> Running transaction check
> ---> Package R-core.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: libtk8.4.so()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> --> Processing Dependency: libtcl8.4.so()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> ---> Package compat-libgfortran-41.x86_64 0:4.1.2-39.el6 will be installed
> --> Finished Dependency Resolution
> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>            Requires: libtcl8.4.so()(64bit)
> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>            Requires: libtk8.4.so()(64bit)
>  You could try using --skip-broken to work around the problem
> ** Found 57 pre-existing rpmdb problem(s), 'yum check' output follows:
> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Client)
> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Core)
> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Delta)
> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Ra)
> 1:guestfish-1.7.17-26.el6.x86_64 has missing requires of libguestfs = ('1',
> '1.7.17', '26.el6')
> opt-perl-AcePerl-1.92-0.el6.x86_64 has missing requires of
> perl(Ace::Browser::LocalSiteDefs)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Apache::DBI)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::ASN1::EntrezGene)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Expression::Contact)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Expression::DataSet)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Expression::Platform)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Expression::Sample)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Factory)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Forest::Tree)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::IO)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Matrices)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Matrices::Datum)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Matrices::Matrix)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Convert::Binary::C)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of perl(DBD::Pg)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(PostScript::TextBlock)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Test::Exception)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Test::Warn)
> opt-perl-BioPerl-DB-1.006900-0.el6.noarch has missing requires of
> perl(DBD::Oracle)
> opt-perl-BioPerl-Run-1.006900-0.el6.noarch has missing requires of
> perl(Bio::Tools::Run::StandAloneBlastPlus::BlastMethods)
> opt-perl-BioPerl-Run-1.006900-0.el6.noarch has missing requires of
> perl(Bio::Tools::Run::WrapperBase::CommandExts)
> opt-perl-Cache-Cache-1.06-0.el6.noarch has missing requires of
> perl(IPC::ShareLite)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Coro)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Coro::Handle)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Coro::Select)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(RPC::PlClient)
>>= ('0', '0.2000', None)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(RPC::PlServer)
>>= ('0', '0.2001', None)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Win32::ODBC)
> opt-perl-Data-Stag-0.11-0.el6.x86_64 has missing requires of perl(Tk)
> opt-perl-Data-Stag-0.11-0.el6.x86_64 has missing requires of perl(Tk::Label)
> opt-perl-Data-Stag-0.11-0.el6.x86_64 has missing requires of perl(Tk::Tree)
> opt-perl-Digest-Perl-MD5-1.8-0.el6.noarch has missing requires of
> /usr/bin/false
> opt-perl-HTTP-Cookies-6.01-0.el6.noarch has missing requires of perl(Win32)
> opt-perl-IPC-Run-0.92-0.el6.noarch has missing requires of
> perl(Win32::Process)
> opt-perl-IPC-Run-0.92-0.el6.noarch has missing requires of
> perl(Win32API::File)
> opt-perl-MLDBM-2.04-0.el6.noarch has missing requires of perl(FreezeThaw)
> opt-perl-Moose-2.0604-0.el6.x86_64 has missing requires of
> perl(Moose::Conflicts)
> opt-perl-Moose-2.0604-0.el6.x86_64 has missing requires of
> perl(Moose::Error::Util)
> opt-perl-Package-Stash-0.33-0.el6.noarch has missing requires of
> perl(Package::Stash::Conflicts)
> opt-perl-SOAP-Lite-0.715-0.el6.noarch has missing requires of
> perl(MIME::Lite)
> opt-perl-SOAP-Lite-0.715-0.el6.noarch has missing requires of
> perl(SOAP::Transport::TCP)
> opt-perl-Spreadsheet-ParseExcel-0.59-0.el6.noarch has missing requires of
> perl(Jcode)
> opt-perl-Spreadsheet-ParseExcel-0.59-0.el6.noarch has missing requires of
> perl(Spreadsheet::WriteExcel)
> opt-perl-Spreadsheet-ParseExcel-0.59-0.el6.noarch has missing requires of
> perl(Unicode::Map)
> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
> perl(XML::SAX::PurePerl::DTDDecls)
> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
> perl(XML::SAX::PurePerl::DocType)
> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
> perl(XML::SAX::PurePerl::EncodingDetect)
> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
> perl(XML::SAX::PurePerl::XMLDecl)
> opt-perl-YAML-0.84-0.el6.noarch has missing requires of perl(Test::Base) >=
> ('0', '0.47', None)
> opt-perl-YAML-0.84-0.el6.noarch has missing requires of
> perl(Test::Base::Filter)
> opt-perl-libwww-perl-6.04-0.el6.noarch has missing requires of
> perl(Authen::NTLM)
> opt-perl-libwww-perl-6.04-0.el6.noarch has missing requires of
> perl(HTTP::GHTTP)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From alku at dtu.dk  Fri Oct 25 08:24:56 2013
From: alku at dtu.dk (Alexandra Kuznetsova)
Date: Fri, 25 Oct 2013 06:24:56 +0000
Subject: [R] bug in dummy.coef?
In-Reply-To: <839AE7D9-E55B-4605-BBD3-2C5ED3E4EEF6@comcast.net>
References: <0566E17B6DEC62459078112371B7508E0F1B7D@ait-pex02mbx05.win.dtu.dk>
	<839AE7D9-E55B-4605-BBD3-2C5ED3E4EEF6@comcast.net>
Message-ID: <0566E17B6DEC62459078112371B7508E0F208C@ait-pex02mbx05.win.dtu.dk>

Thank  you for the reply!
I need to use it in the package for constructing the contrast matrices.
 Renaming a variable like y2 <- y^2 will not be a solution for me...
Will try to look whether the  function dummy.coef can be modified to work this issue.

With best regards,
Alexandra

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: 25. oktober 2013 00:58
To: Alexandra Kuznetsova
Cc: r-help at r-project.org
Subject: Re: [R] bug in dummy.coef?


On Oct 24, 2013, at 1:51 AM, Alexandra Kuznetsova wrote:

> Dear all,
> 
> Running the following code produces an error in dummy.coef. I guess it might be a bug..
> 
>> ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
>> trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
>> group <- gl(2, 10, 20, labels = c("Ctl","Trt")) weight <- c(ctl, trt) 
>> x <- rnorm(length(weight))
>> lm.D9 <- lm(weight ~ group + x + I(x^2))
>> dummy.coef(lm.D9)
> Error in rep.int(xl[[i]][1L], nl) : invalid 'times' value

As Rolf Turner pointed out the help page says there are limitations to that function and its only desiged for specific purposes. What are you trying to accomplish?

-- 

David Winsemius
Alameda, CA, USA


From ripley at stats.ox.ac.uk  Fri Oct 25 08:29:52 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Oct 2013 07:29:52 +0100
Subject: [R] 'yum install R' failing with tcl/tk issue
In-Reply-To: <CANBOegLZ0Q36J-Rddq0_OmSXyp6pFPCb5ORYiJhAS0jVkkdGhg@mail.gmail.com>
References: <CANBOegLZ0Q36J-Rddq0_OmSXyp6pFPCb5ORYiJhAS0jVkkdGhg@mail.gmail.com>
Message-ID: <526A0FE0.4090703@stats.ox.ac.uk>

On 25/10/2013 02:33, Michael Stauffer wrote:
> Hi,
>
> I'm trying to install R on CentOS 6.4.

This is not the right list.  But

- As the posting guide says, we only support current R here.  R 2.10.0 
is ancient, and other people seem to have found 3.0.1 RPMs for Centos 6.3.

- It seems your RPM is linked against Tcl/Tk 8.4, also ancient.  Tcl/Tk 
8.6 is current.

I suggest you install R 3.0.2 from the sources, in which case R-devel 
would be the right list.  For binary installations on CentOS, 
R-sig-Fedora is.

>
> Following some instructions online, I've done this:
>
> rpm -Uvh
> http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm
>
> yum install R
>
> But yum fails, with this (full output below):
>
> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>             Requires: libtcl8.4.so()(64bit)
> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>             Requires: libtk8.4.so()(64bit)
>
> I have tcl/tk 8.5 already installed. Does anyone have any suggestion?
> Thanks!
>
> Full output:
>
> [root at picsl-cluster ~]# yum install R
> Repository base is listed more than once in the configuration
> Rocks-6.1
>                            | 1.9 kB     00:00
> base
>                             | 3.7 kB     00:00
> Setting up Install Process
> Resolving Dependencies
> --> Running transaction check
> ---> Package R.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: libRmath-devel = 2.10.0-2.el5 for package:
> R-2.10.0-2.el5.x86_64
> --> Processing Dependency: R-devel = 2.10.0-2.el5 for package:
> R-2.10.0-2.el5.x86_64
> --> Running transaction check
> ---> Package R-devel.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: R-core = 2.10.0-2.el5 for package:
> R-devel-2.10.0-2.el5.x86_64
> ---> Package libRmath-devel.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: libRmath = 2.10.0-2.el5 for package:
> libRmath-devel-2.10.0-2.el5.x86_64
> --> Running transaction check
> ---> Package R-core.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: libtk8.4.so()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> --> Processing Dependency: libtcl8.4.so()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> --> Processing Dependency: libgfortran.so.1()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> ---> Package libRmath.x86_64 0:2.10.0-2.el5 will be installed
> --> Running transaction check
> ---> Package R-core.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: libtk8.4.so()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> --> Processing Dependency: libtcl8.4.so()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> ---> Package compat-libgfortran-41.x86_64 0:4.1.2-39.el6 will be installed
> --> Finished Dependency Resolution
> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>             Requires: libtcl8.4.so()(64bit)
> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>             Requires: libtk8.4.so()(64bit)
>   You could try using --skip-broken to work around the problem
> ** Found 57 pre-existing rpmdb problem(s), 'yum check' output follows:
> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Client)
> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Core)
> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Delta)
> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Ra)
> 1:guestfish-1.7.17-26.el6.x86_64 has missing requires of libguestfs = ('1',
> '1.7.17', '26.el6')
> opt-perl-AcePerl-1.92-0.el6.x86_64 has missing requires of
> perl(Ace::Browser::LocalSiteDefs)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Apache::DBI)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::ASN1::EntrezGene)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Expression::Contact)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Expression::DataSet)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Expression::Platform)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Expression::Sample)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Factory)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Forest::Tree)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::IO)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Matrices)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Matrices::Datum)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Matrices::Matrix)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Convert::Binary::C)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of perl(DBD::Pg)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(PostScript::TextBlock)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Test::Exception)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Test::Warn)
> opt-perl-BioPerl-DB-1.006900-0.el6.noarch has missing requires of
> perl(DBD::Oracle)
> opt-perl-BioPerl-Run-1.006900-0.el6.noarch has missing requires of
> perl(Bio::Tools::Run::StandAloneBlastPlus::BlastMethods)
> opt-perl-BioPerl-Run-1.006900-0.el6.noarch has missing requires of
> perl(Bio::Tools::Run::WrapperBase::CommandExts)
> opt-perl-Cache-Cache-1.06-0.el6.noarch has missing requires of
> perl(IPC::ShareLite)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Coro)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Coro::Handle)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Coro::Select)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(RPC::PlClient)
>> = ('0', '0.2000', None)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(RPC::PlServer)
>> = ('0', '0.2001', None)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Win32::ODBC)
> opt-perl-Data-Stag-0.11-0.el6.x86_64 has missing requires of perl(Tk)
> opt-perl-Data-Stag-0.11-0.el6.x86_64 has missing requires of perl(Tk::Label)
> opt-perl-Data-Stag-0.11-0.el6.x86_64 has missing requires of perl(Tk::Tree)
> opt-perl-Digest-Perl-MD5-1.8-0.el6.noarch has missing requires of
> /usr/bin/false
> opt-perl-HTTP-Cookies-6.01-0.el6.noarch has missing requires of perl(Win32)
> opt-perl-IPC-Run-0.92-0.el6.noarch has missing requires of
> perl(Win32::Process)
> opt-perl-IPC-Run-0.92-0.el6.noarch has missing requires of
> perl(Win32API::File)
> opt-perl-MLDBM-2.04-0.el6.noarch has missing requires of perl(FreezeThaw)
> opt-perl-Moose-2.0604-0.el6.x86_64 has missing requires of
> perl(Moose::Conflicts)
> opt-perl-Moose-2.0604-0.el6.x86_64 has missing requires of
> perl(Moose::Error::Util)
> opt-perl-Package-Stash-0.33-0.el6.noarch has missing requires of
> perl(Package::Stash::Conflicts)
> opt-perl-SOAP-Lite-0.715-0.el6.noarch has missing requires of
> perl(MIME::Lite)
> opt-perl-SOAP-Lite-0.715-0.el6.noarch has missing requires of
> perl(SOAP::Transport::TCP)
> opt-perl-Spreadsheet-ParseExcel-0.59-0.el6.noarch has missing requires of
> perl(Jcode)
> opt-perl-Spreadsheet-ParseExcel-0.59-0.el6.noarch has missing requires of
> perl(Spreadsheet::WriteExcel)
> opt-perl-Spreadsheet-ParseExcel-0.59-0.el6.noarch has missing requires of
> perl(Unicode::Map)
> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
> perl(XML::SAX::PurePerl::DTDDecls)
> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
> perl(XML::SAX::PurePerl::DocType)
> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
> perl(XML::SAX::PurePerl::EncodingDetect)
> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
> perl(XML::SAX::PurePerl::XMLDecl)
> opt-perl-YAML-0.84-0.el6.noarch has missing requires of perl(Test::Base) >=
> ('0', '0.47', None)
> opt-perl-YAML-0.84-0.el6.noarch has missing requires of
> perl(Test::Base::Filter)
> opt-perl-libwww-perl-6.04-0.el6.noarch has missing requires of
> perl(Authen::NTLM)
> opt-perl-libwww-perl-6.04-0.el6.noarch has missing requires of
> perl(HTTP::GHTTP)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Gerrit.Eichner at math.uni-giessen.de  Fri Oct 25 10:26:44 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Fri, 25 Oct 2013 10:26:44 +0200 (MEST)
Subject: [R] Nonparametric k-way ANOVA
In-Reply-To: <CAHfSo7jFUaPzkV4oBxxkj=GM_POmE=2UB6_6fU6YfvJDrnaEQQ@mail.gmail.com>
References: <CAHfSo7jFUaPzkV4oBxxkj=GM_POmE=2UB6_6fU6YfvJDrnaEQQ@mail.gmail.com>
Message-ID: <Pine.SOC.4.64.1310251023340.26497@solcom.hrz.uni-giessen.de>

Hello, Vincent,

you may want to take a look at "Nonparametric methods in factorial 
designs" by Edgar Brunner and Madan L. Puri in Statistical Papers 42, 1-52 
(2001).

There is the R-package nparcomp for one-way layouts, but the paper goes 
further (and mentions another software) and is maybe a starting point for 
you.

  Hth -- Gerrit

On Thu, 24 Oct 2013, Vicent Giner-Bosch wrote:

> Sorry if this subject has been already dealt here.
>
> Which are some common tests for nonparametric k-way ANOVA?
>
> I have read about Kruskal-Wallis test as a kind of nonparametric one-way
> ANOVA, but I have not found anything about a general-setting (I mean k-way)
> nonparametric ANOVA.
>
> Can you recommend me a good R package (or other reliable software) for that?
>
> Looking forward to your answers,
>
>
> --
> vicent
> @vginer_upv
> about.me/vginer_upv
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nalimilan at club.fr  Fri Oct 25 11:33:23 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Fri, 25 Oct 2013 11:33:23 +0200
Subject: [R] 'yum install R' failing with tcl/tk issue
In-Reply-To: <CANBOegLZ0Q36J-Rddq0_OmSXyp6pFPCb5ORYiJhAS0jVkkdGhg@mail.gmail.com>
References: <CANBOegLZ0Q36J-Rddq0_OmSXyp6pFPCb5ORYiJhAS0jVkkdGhg@mail.gmail.com>
Message-ID: <1382693603.7000.40.camel@milan>

Le jeudi 24 octobre 2013 ? 21:33 -0400, Michael Stauffer a ?crit :
> Hi,
> 
> I'm trying to install R on CentOS 6.4.
> 
> Following some instructions online, I've done this:
> 
> rpm -Uvh
> http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm
> 
> yum install R
> 
> But yum fails, with this (full output below):
> 
> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>            Requires: libtcl8.4.so()(64bit)
> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>            Requires: libtk8.4.so()(64bit)
> 
> I have tcl/tk 8.5 already installed. Does anyone have any suggestion?
> Thanks!
yum asks for tcl and tk 8.4, so if you have 8.5 it won't work.

You should have told us where you found those instructions. If these are
http://stackoverflow.com/questions/9468164/problems-installing-r-on-linux-centos-6-2
then please try what the poster did there.


Else, I've no idea whether it could work for your system, but the Tcl.Tk
8.4 RPM are available for Fedora 8 here:
ftp://ftp.pbone.net/mirror/archive.fedoraproject.org/fedora/linux/updates/8/x86_64.newkey/tcl-8.4.17-1.fc8.x86_64.rpm
ftp://ftp.pbone.net/mirror/archive.fedoraproject.org/fedora/linux/updates/8/x86_64.newkey/tk-8.4.17-2.fc8.x86_64.rpm



Regards

> Full output:
> 
> [root at picsl-cluster ~]# yum install R
> Repository base is listed more than once in the configuration
> Rocks-6.1
>                           | 1.9 kB     00:00
> base
>                            | 3.7 kB     00:00
> Setting up Install Process
> Resolving Dependencies
> --> Running transaction check
> ---> Package R.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: libRmath-devel = 2.10.0-2.el5 for package:
> R-2.10.0-2.el5.x86_64
> --> Processing Dependency: R-devel = 2.10.0-2.el5 for package:
> R-2.10.0-2.el5.x86_64
> --> Running transaction check
> ---> Package R-devel.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: R-core = 2.10.0-2.el5 for package:
> R-devel-2.10.0-2.el5.x86_64
> ---> Package libRmath-devel.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: libRmath = 2.10.0-2.el5 for package:
> libRmath-devel-2.10.0-2.el5.x86_64
> --> Running transaction check
> ---> Package R-core.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: libtk8.4.so()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> --> Processing Dependency: libtcl8.4.so()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> --> Processing Dependency: libgfortran.so.1()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> ---> Package libRmath.x86_64 0:2.10.0-2.el5 will be installed
> --> Running transaction check
> ---> Package R-core.x86_64 0:2.10.0-2.el5 will be installed
> --> Processing Dependency: libtk8.4.so()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> --> Processing Dependency: libtcl8.4.so()(64bit) for package:
> R-core-2.10.0-2.el5.x86_64
> ---> Package compat-libgfortran-41.x86_64 0:4.1.2-39.el6 will be installed
> --> Finished Dependency Resolution
> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>            Requires: libtcl8.4.so()(64bit)
> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>            Requires: libtk8.4.so()(64bit)
>  You could try using --skip-broken to work around the problem
> ** Found 57 pre-existing rpmdb problem(s), 'yum check' output follows:
> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Client)
> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Core)
> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Delta)
> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Ra)
> 1:guestfish-1.7.17-26.el6.x86_64 has missing requires of libguestfs = ('1',
> '1.7.17', '26.el6')
> opt-perl-AcePerl-1.92-0.el6.x86_64 has missing requires of
> perl(Ace::Browser::LocalSiteDefs)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Apache::DBI)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::ASN1::EntrezGene)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Expression::Contact)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Expression::DataSet)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Expression::Platform)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Expression::Sample)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Factory)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Forest::Tree)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::IO)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Matrices)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Matrices::Datum)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Bio::Phylo::Matrices::Matrix)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Convert::Binary::C)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of perl(DBD::Pg)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(PostScript::TextBlock)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Test::Exception)
> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
> perl(Test::Warn)
> opt-perl-BioPerl-DB-1.006900-0.el6.noarch has missing requires of
> perl(DBD::Oracle)
> opt-perl-BioPerl-Run-1.006900-0.el6.noarch has missing requires of
> perl(Bio::Tools::Run::StandAloneBlastPlus::BlastMethods)
> opt-perl-BioPerl-Run-1.006900-0.el6.noarch has missing requires of
> perl(Bio::Tools::Run::WrapperBase::CommandExts)
> opt-perl-Cache-Cache-1.06-0.el6.noarch has missing requires of
> perl(IPC::ShareLite)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Coro)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Coro::Handle)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Coro::Select)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(RPC::PlClient)
> >= ('0', '0.2000', None)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(RPC::PlServer)
> >= ('0', '0.2001', None)
> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Win32::ODBC)
> opt-perl-Data-Stag-0.11-0.el6.x86_64 has missing requires of perl(Tk)
> opt-perl-Data-Stag-0.11-0.el6.x86_64 has missing requires of perl(Tk::Label)
> opt-perl-Data-Stag-0.11-0.el6.x86_64 has missing requires of perl(Tk::Tree)
> opt-perl-Digest-Perl-MD5-1.8-0.el6.noarch has missing requires of
> /usr/bin/false
> opt-perl-HTTP-Cookies-6.01-0.el6.noarch has missing requires of perl(Win32)
> opt-perl-IPC-Run-0.92-0.el6.noarch has missing requires of
> perl(Win32::Process)
> opt-perl-IPC-Run-0.92-0.el6.noarch has missing requires of
> perl(Win32API::File)
> opt-perl-MLDBM-2.04-0.el6.noarch has missing requires of perl(FreezeThaw)
> opt-perl-Moose-2.0604-0.el6.x86_64 has missing requires of
> perl(Moose::Conflicts)
> opt-perl-Moose-2.0604-0.el6.x86_64 has missing requires of
> perl(Moose::Error::Util)
> opt-perl-Package-Stash-0.33-0.el6.noarch has missing requires of
> perl(Package::Stash::Conflicts)
> opt-perl-SOAP-Lite-0.715-0.el6.noarch has missing requires of
> perl(MIME::Lite)
> opt-perl-SOAP-Lite-0.715-0.el6.noarch has missing requires of
> perl(SOAP::Transport::TCP)
> opt-perl-Spreadsheet-ParseExcel-0.59-0.el6.noarch has missing requires of
> perl(Jcode)
> opt-perl-Spreadsheet-ParseExcel-0.59-0.el6.noarch has missing requires of
> perl(Spreadsheet::WriteExcel)
> opt-perl-Spreadsheet-ParseExcel-0.59-0.el6.noarch has missing requires of
> perl(Unicode::Map)
> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
> perl(XML::SAX::PurePerl::DTDDecls)
> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
> perl(XML::SAX::PurePerl::DocType)
> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
> perl(XML::SAX::PurePerl::EncodingDetect)
> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
> perl(XML::SAX::PurePerl::XMLDecl)
> opt-perl-YAML-0.84-0.el6.noarch has missing requires of perl(Test::Base) >=
> ('0', '0.47', None)
> opt-perl-YAML-0.84-0.el6.noarch has missing requires of
> perl(Test::Base::Filter)
> opt-perl-libwww-perl-6.04-0.el6.noarch has missing requires of
> perl(Authen::NTLM)
> opt-perl-libwww-perl-6.04-0.el6.noarch has missing requires of
> perl(HTTP::GHTTP)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alaios at yahoo.com  Fri Oct 25 11:38:11 2013
From: alaios at yahoo.com (Alaios)
Date: Fri, 25 Oct 2013 02:38:11 -0700 (PDT)
Subject: [R] add a color band
Message-ID: <1382693891.44547.YahooMailNeo@web125302.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131025/fee7ef1f/attachment.pl>

From jim at bitwrit.com.au  Fri Oct 25 11:48:25 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 25 Oct 2013 20:48:25 +1100
Subject: [R] add a color band
In-Reply-To: <1382693891.44547.YahooMailNeo@web125302.mail.ne1.yahoo.com>
References: <1382693891.44547.YahooMailNeo@web125302.mail.ne1.yahoo.com>
Message-ID: <526A3E69.2060103@bitwrit.com.au>

On 10/25/2013 08:38 PM, Alaios wrote:
> Hi all,
> I would like to ask your help to add a color band (?? am not sure regarding the right term, this color band at the right of the plot "describing" values with their corresponding color.
>
> For now I have only this code
>
>
>
> test<-matrix(data=runif(10000),nrow=100)
> plot(test,axes="FALSE")
>
> axis(1,at=c(0,1),labels=c("a","b")) #
>
> but?  I would like to add at the right?  side the color legend.
>
> How can I do that in R?
>
> I would like to thank you in advance for your help
>
Hi Alex,
If all else fails, look at color.legend (plotrix).

Jim


From E.Vettorazzi at uke.de  Fri Oct 25 12:40:57 2013
From: E.Vettorazzi at uke.de (Eik Vettorazzi)
Date: Fri, 25 Oct 2013 12:40:57 +0200
Subject: [R] How can I use a script "l" (LaTeX \ell) in mathematical
 annotation of plots?
In-Reply-To: <1382633071.57018.YahooMailNeo@web142805.mail.bf1.yahoo.com>
References: <1382571556.79906.YahooMailNeo@web142806.mail.bf1.yahoo.com>
	<5268ED5B.3030204@uke.de>
	<1382633071.57018.YahooMailNeo@web142805.mail.bf1.yahoo.com>
Message-ID: <526A4AB9.2000903@uke.de>

Hi Byron,
You may have a look at the tikzDevice package, it solves the aesthetic
issue of font mixing.
You can sweave the following example

\documentclass{article}
\usepackage{tikz}
\begin{document}
\SweaveOpts{concordance=TRUE}
\begin{figure}[!h]
\centering
<<fig1, echo=FALSE, fig=FALSE, results=hide>>=
library(tikzDevice)
plotfile<-"simpleEx.tex"
tikz(plotfile, width =3.5 , height =3.5)
plot(1, ,type="n")
text(1,1,"$\\ell$ within ordinary \\LaTeX text")
dev.off()
@
\input{\Sexpr{plotfile}}
\caption{Test TeX annotation}
\end{figure}
\end{document}

cheers

Am 24.10.2013 18:44, schrieb Byron Dom:
> 
> 
> 
> Thanks. That works for me too.
> 
> I had worked that out based on Brian's response to my original post.
> 
> If you read thru my response to him in detail, you'll see:
> 
>> Here are a couple of examples using it that worked:
>>    > plot(1:10,xlab="\u2113")
>>    >
>>   plot(1:10,xlab="\u2113(\u2113 + 1)")
> 
> 
> 
> 
> ________________________________
> From: Eik Vettorazzi <E.Vettorazzi at uke.de>
> To: Byron Dom <byron_dom at yahoo.com>; r help <r-help at r-project.org> 
> Cc: "ripley at stats.ox.ac.uk" <ripley at stats.ox.ac.uk> 
> Sent: Thursday, October 24, 2013 2:50 AM
> Subject: Re: [R] How can I use a script "l" (LaTeX \ell) in mathematical annotation of plots?
> 
> 
> this works for me:
> 
> plot(1,main="\u2113")
> 
> cheers
> 
> 
> Am 24.10.2013 01:39, schrieb Byron Dom:
>>
>>
>> Original post: On 13/10/2013 18:53, Byron Dom wrote:
>>
>>>> Due to convention a script "l" - $$\ell$$ (LaTeX \ell) is used to 
>>>> represent a certain quantity in something I'm working on. I'm 
>>>> unable to figure out how to use it in R. It's not included in the 
>>>> list on ?plotmath.
>>>>
>>>> Can anyone tell me how to use it?  Its unicode is U+2113. This 
>>>> page has a list of various encodings of it: 
>>>>
>>   http://www.fileformat.info/info/unicode/char/2113/encoding.htm.  
>>>> Is there a way to include it by using one of these encodings somehow?
>>
>> -------------------------------------------------
>>
>> On 13/10/2013 22:06 Prof Brian Ripley responded:
>>
>>> What do you want to do with it?  plotmath is about plotting, but you
>>> have not otherwise mentioned that, let alone the device on which you 
>>> want to plot.
>>>
>>> Read the help for plotmath: on some plot devices, just use "\u2113".  It 
>>> is not AFAICS in the Adobe symbol encoding.
>>>
>>> -- 
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford,             Tel: 
>>   +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> -------------------------------------------------
>>
>> My response:
>>
>> Thanks I worked out how to do it based on your mention of "u2113".
>> See below.
>>
>> I'm sorry if my information wasn't complete enough. I assumed that 
>> what I said, combined with the subject ("How can I use a script "l" 
>> (LaTeX \ell) in
>>   mathematical annotation of plots?") would have been 
>> enough.
>>
>> I just wanted to be able to do this on the default device, which 
>> displays plots within the R session window. I have a simple path 
>> to go from there to .png form, which I include in LaTeX documents
>> and for other purposes. I am using R version 3.0.1 in Windows 7, 
>> for which I believe the default plot device is "windows".
>>
>> An example of the kind of thing I wanted to do is to include 
>> "ylab = expression(hat(gamma))" (which is equivalent to the LaTex 
>> "\hat{\gamma}}") among the base-graphics plot() arguments. That 
>> works. In LaTeX a script "l" is produced with "\ell", but 
>> something like "ylab = expression(ell)" doesn't work in R. 
>> I wanted to be able to do the equivalent of that, but to obtain "?".
>>
>> Here are a couple of examples using it that worked:
>>    > plot(1:10,xlab="\u2113")
>>    >
>>   plot(1:10,xlab="\u2113(\u2113 + 1)")
>> The only (slight) problem with this is the minor aesthetic issue 
>>
>> that the "?" one gets this way is in an obviously different font 
>>
>> from what one gets using the LaTeX "\lambda" command/symbol.
>>
>> Strangely, earlier, when I tried 
>>    > plot(1:10,xlab=expression(symbol("\u2113")))
>> it did the same thing as 
>>    > plot(1:10,xlab=expression(lambda))
>> So I got a lower-case greek lambda - "?", rather than "?"
>> (script "l").
>>
>> When I used the unicode representation for lowercase 
>> lambda - "?" - as follows
>>    >
>>   plot(1:10,xlab=expression(symbol("\u03bb")))
>> I got this for an x-axis label: "<Y+03BB>". On the other hand,
>> the following did work
>>    > plot(1:10,xlab="\u03bb"), 
>> giving me an x-axis label of lambda - "?".
>>     [[alternative HTML version deleted]]
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/7410-58243
F ++49/40/7410-57790
--

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Martin Zeitz (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From marc_schwartz at me.com  Fri Oct 25 13:43:08 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 25 Oct 2013 06:43:08 -0500
Subject: [R] 'yum install R' failing with tcl/tk issue
In-Reply-To: <526A0FE0.4090703@stats.ox.ac.uk>
References: <CANBOegLZ0Q36J-Rddq0_OmSXyp6pFPCb5ORYiJhAS0jVkkdGhg@mail.gmail.com>
	<526A0FE0.4090703@stats.ox.ac.uk>
Message-ID: <4CE52BFE-4277-4BC3-9324-BB80EEE3C5C1@me.com>


On Oct 25, 2013, at 1:29 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On 25/10/2013 02:33, Michael Stauffer wrote:
>> Hi,
>> 
>> I'm trying to install R on CentOS 6.4.
> 
> This is not the right list.  But
> 
> - As the posting guide says, we only support current R here.  R 2.10.0 is ancient, and other people seem to have found 3.0.1 RPMs for Centos 6.3.
> 
> - It seems your RPM is linked against Tcl/Tk 8.4, also ancient.  Tcl/Tk 8.6 is current.
> 
> I suggest you install R 3.0.2 from the sources, in which case R-devel would be the right list.  For binary installations on CentOS, R-sig-Fedora is.
> 

There are several inconsistencies in the output, as 3.0.1 is available as an RPM from the EPEL repos:

  http://dl.fedoraproject.org/pub/epel/6/x86_64/repoview/R.html

In addition, the output below shows that the R rpm being installed is from 'el5', rather than 'el6'. If this was CentOS 5, rather than 6, R 2.15.2 is available:

  http://dl.fedoraproject.org/pub/epel/5/x86_64/repoview/R.html

Something seems to be amiss with the configuration not getting the right yum repo paths.

A Google search came up with this link:

  http://lancegatlin.org/tech/centos-6-clear-the-yum-cache

which might be helpful, as it suggests a similar issue of yum picking up incorrect versions. You may need to reinstall the EPEL repo RPM after these steps.

Regards,

Marc Schwartz


>> 
>> Following some instructions online, I've done this:
>> 
>> rpm -Uvh
>> http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm
>> 
>> yum install R
>> 
>> But yum fails, with this (full output below):
>> 
>> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>>            Requires: libtcl8.4.so()(64bit)
>> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>>            Requires: libtk8.4.so()(64bit)
>> 
>> I have tcl/tk 8.5 already installed. Does anyone have any suggestion?
>> Thanks!
>> 
>> Full output:
>> 
>> [root at picsl-cluster ~]# yum install R
>> Repository base is listed more than once in the configuration
>> Rocks-6.1
>>                           | 1.9 kB     00:00
>> base
>>                            | 3.7 kB     00:00
>> Setting up Install Process
>> Resolving Dependencies
>> --> Running transaction check
>> ---> Package R.x86_64 0:2.10.0-2.el5 will be installed
>> --> Processing Dependency: libRmath-devel = 2.10.0-2.el5 for package:
>> R-2.10.0-2.el5.x86_64
>> --> Processing Dependency: R-devel = 2.10.0-2.el5 for package:
>> R-2.10.0-2.el5.x86_64
>> --> Running transaction check
>> ---> Package R-devel.x86_64 0:2.10.0-2.el5 will be installed
>> --> Processing Dependency: R-core = 2.10.0-2.el5 for package:
>> R-devel-2.10.0-2.el5.x86_64
>> ---> Package libRmath-devel.x86_64 0:2.10.0-2.el5 will be installed
>> --> Processing Dependency: libRmath = 2.10.0-2.el5 for package:
>> libRmath-devel-2.10.0-2.el5.x86_64
>> --> Running transaction check
>> ---> Package R-core.x86_64 0:2.10.0-2.el5 will be installed
>> --> Processing Dependency: libtk8.4.so()(64bit) for package:
>> R-core-2.10.0-2.el5.x86_64
>> --> Processing Dependency: libtcl8.4.so()(64bit) for package:
>> R-core-2.10.0-2.el5.x86_64
>> --> Processing Dependency: libgfortran.so.1()(64bit) for package:
>> R-core-2.10.0-2.el5.x86_64
>> ---> Package libRmath.x86_64 0:2.10.0-2.el5 will be installed
>> --> Running transaction check
>> ---> Package R-core.x86_64 0:2.10.0-2.el5 will be installed
>> --> Processing Dependency: libtk8.4.so()(64bit) for package:
>> R-core-2.10.0-2.el5.x86_64
>> --> Processing Dependency: libtcl8.4.so()(64bit) for package:
>> R-core-2.10.0-2.el5.x86_64
>> ---> Package compat-libgfortran-41.x86_64 0:4.1.2-39.el6 will be installed
>> --> Finished Dependency Resolution
>> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>>            Requires: libtcl8.4.so()(64bit)
>> Error: Package: R-core-2.10.0-2.el5.x86_64 (Rocks-6.1)
>>            Requires: libtk8.4.so()(64bit)
>>  You could try using --skip-broken to work around the problem
>> ** Found 57 pre-existing rpmdb problem(s), 'yum check' output follows:
>> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Client)
>> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Core)
>> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Delta)
>> foundation-git-1.7.11.4-0.x86_64 has missing requires of perl(SVN::Ra)
>> 1:guestfish-1.7.17-26.el6.x86_64 has missing requires of libguestfs = ('1',
>> '1.7.17', '26.el6')
>> opt-perl-AcePerl-1.92-0.el6.x86_64 has missing requires of
>> perl(Ace::Browser::LocalSiteDefs)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Apache::DBI)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Bio::ASN1::EntrezGene)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Bio::Expression::Contact)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Bio::Expression::DataSet)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Bio::Expression::Platform)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Bio::Expression::Sample)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Bio::Phylo::Factory)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Bio::Phylo::Forest::Tree)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Bio::Phylo::IO)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Bio::Phylo::Matrices)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Bio::Phylo::Matrices::Datum)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Bio::Phylo::Matrices::Matrix)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Convert::Binary::C)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of perl(DBD::Pg)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(PostScript::TextBlock)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Test::Exception)
>> opt-perl-BioPerl-1.6.901-0.el6.noarch has missing requires of
>> perl(Test::Warn)
>> opt-perl-BioPerl-DB-1.006900-0.el6.noarch has missing requires of
>> perl(DBD::Oracle)
>> opt-perl-BioPerl-Run-1.006900-0.el6.noarch has missing requires of
>> perl(Bio::Tools::Run::StandAloneBlastPlus::BlastMethods)
>> opt-perl-BioPerl-Run-1.006900-0.el6.noarch has missing requires of
>> perl(Bio::Tools::Run::WrapperBase::CommandExts)
>> opt-perl-Cache-Cache-1.06-0.el6.noarch has missing requires of
>> perl(IPC::ShareLite)
>> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Coro)
>> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Coro::Handle)
>> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Coro::Select)
>> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(RPC::PlClient)
>>> = ('0', '0.2000', None)
>> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(RPC::PlServer)
>>> = ('0', '0.2001', None)
>> opt-perl-DBI-1.622-0.el6.x86_64 has missing requires of perl(Win32::ODBC)
>> opt-perl-Data-Stag-0.11-0.el6.x86_64 has missing requires of perl(Tk)
>> opt-perl-Data-Stag-0.11-0.el6.x86_64 has missing requires of perl(Tk::Label)
>> opt-perl-Data-Stag-0.11-0.el6.x86_64 has missing requires of perl(Tk::Tree)
>> opt-perl-Digest-Perl-MD5-1.8-0.el6.noarch has missing requires of
>> /usr/bin/false
>> opt-perl-HTTP-Cookies-6.01-0.el6.noarch has missing requires of perl(Win32)
>> opt-perl-IPC-Run-0.92-0.el6.noarch has missing requires of
>> perl(Win32::Process)
>> opt-perl-IPC-Run-0.92-0.el6.noarch has missing requires of
>> perl(Win32API::File)
>> opt-perl-MLDBM-2.04-0.el6.noarch has missing requires of perl(FreezeThaw)
>> opt-perl-Moose-2.0604-0.el6.x86_64 has missing requires of
>> perl(Moose::Conflicts)
>> opt-perl-Moose-2.0604-0.el6.x86_64 has missing requires of
>> perl(Moose::Error::Util)
>> opt-perl-Package-Stash-0.33-0.el6.noarch has missing requires of
>> perl(Package::Stash::Conflicts)
>> opt-perl-SOAP-Lite-0.715-0.el6.noarch has missing requires of
>> perl(MIME::Lite)
>> opt-perl-SOAP-Lite-0.715-0.el6.noarch has missing requires of
>> perl(SOAP::Transport::TCP)
>> opt-perl-Spreadsheet-ParseExcel-0.59-0.el6.noarch has missing requires of
>> perl(Jcode)
>> opt-perl-Spreadsheet-ParseExcel-0.59-0.el6.noarch has missing requires of
>> perl(Spreadsheet::WriteExcel)
>> opt-perl-Spreadsheet-ParseExcel-0.59-0.el6.noarch has missing requires of
>> perl(Unicode::Map)
>> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
>> perl(XML::SAX::PurePerl::DTDDecls)
>> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
>> perl(XML::SAX::PurePerl::DocType)
>> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
>> perl(XML::SAX::PurePerl::EncodingDetect)
>> opt-perl-XML-SAX-0.99-0.el6.noarch has missing requires of
>> perl(XML::SAX::PurePerl::XMLDecl)
>> opt-perl-YAML-0.84-0.el6.noarch has missing requires of perl(Test::Base) >=
>> ('0', '0.47', None)
>> opt-perl-YAML-0.84-0.el6.noarch has missing requires of
>> perl(Test::Base::Filter)
>> opt-perl-libwww-perl-6.04-0.el6.noarch has missing requires of
>> perl(Authen::NTLM)
>> opt-perl-libwww-perl-6.04-0.el6.noarch has missing requires of
>> perl(HTTP::GHTTP)


From alaios at yahoo.com  Fri Oct 25 14:16:54 2013
From: alaios at yahoo.com (Alaios)
Date: Fri, 25 Oct 2013 05:16:54 -0700 (PDT)
Subject: [R] add a color band
In-Reply-To: <526A3E69.2060103@bitwrit.com.au>
References: <1382693891.44547.YahooMailNeo@web125302.mail.ne1.yahoo.com>
	<526A3E69.2060103@bitwrit.com.au>
Message-ID: <1382703414.34947.YahooMailNeo@web125305.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131025/6c6f4419/attachment.pl>

From Anindita.C at mu-sigma.com  Fri Oct 25 14:19:26 2013
From: Anindita.C at mu-sigma.com (Anindita Chattopadhyay)
Date: Fri, 25 Oct 2013 12:19:26 +0000
Subject: [R] Revo R for Arima Implementation
Message-ID: <d7923fdac82a40a28fbfc92ae373318a@HKNPR04MB083.apcprd04.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131025/02bac65d/attachment.pl>

From s.karthiga1 at tcs.com  Fri Oct 25 09:57:16 2013
From: s.karthiga1 at tcs.com (S Karthiga1)
Date: Fri, 25 Oct 2013 13:27:16 +0530
Subject: [R] Regarding rgdal package installation in R
Message-ID: <OFABF260AA.E03F2876-ON65257C0F.002BB224-65257C0F.002BB228@tcs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131025/5bdc35cd/attachment.pl>

From S.Ellison at LGCGroup.com  Fri Oct 25 14:48:28 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 25 Oct 2013 13:48:28 +0100
Subject: [R] Regarding rgdal package installation in R
In-Reply-To: <OFABF260AA.E03F2876-ON65257C0F.002BB224-65257C0F.002BB228@tcs.com>
References: <OFABF260AA.E03F2876-ON65257C0F.002BB224-65257C0F.002BB228@tcs.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554DD9124@GOLD.corp.lgc-group.com>

> -----Original Message-----
> I'm in-need of rgdal installation for R in our CentOS 6 machine to
> handle shapefiles.

Is there any reason that you cannot run 
> install.packages("rgdal")

which would be the recommended way to install a package with all dependencies automatically downloaded and installed?

If you cannot do that, review the CRAN page for the packages which rgdal Depends on or Imports, and make sure those are also installed. Similarly, for each of those.


S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From friendly at yorku.ca  Fri Oct 25 15:04:24 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 25 Oct 2013 09:04:24 -0400
Subject: [R] Use R to plot a directory tree
In-Reply-To: <EDB44DA865211646A192A94DF3C6FA670F72D6EB@DEMDCE0057.nestle.com>
References: <EDB44DA865211646A192A94DF3C6FA670F72D6EB@DEMDCE0057.nestle.com>
Message-ID: <526A6C58.2000501@yorku.ca>

On 10/24/2013 9:13 AM, Thaler,Thorn,LAUSANNE,Applied Mathematics wrote:
> Dear all,
>
> I was wondering whether (or better: how) I can use R to read recursively a directory to get all the sub-folders and files located in the root folder and put it into a tree like structure where the leaves are files and intermediate nodes are the directories? The idea is that I'd like to plot the structure of a certain root folder to be able to restructure the file system.
>
> Any ideas on that? I was googling a lot but apparently I did not use the right terms ("R tree folder" or "R tree directory" takes me mainly to pages about the "R-tree" a structure for spatial access methods [at least I learnt something new ;)])
>
> Any pointer to the right function is highly appreciated.
>

In addition, or instead of, suggestions for plotting a file structure as 
a tree, you might consider a treemap (package of same name), which
was designed to show this more compactly, using nested rectangles
showing, e.g., file sizes or other attributes.

HTH


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From friendly at yorku.ca  Fri Oct 25 15:04:24 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 25 Oct 2013 09:04:24 -0400
Subject: [R] Use R to plot a directory tree
In-Reply-To: <EDB44DA865211646A192A94DF3C6FA670F72D6EB@DEMDCE0057.nestle.com>
References: <EDB44DA865211646A192A94DF3C6FA670F72D6EB@DEMDCE0057.nestle.com>
Message-ID: <526A6C58.2000501@yorku.ca>

On 10/24/2013 9:13 AM, Thaler,Thorn,LAUSANNE,Applied Mathematics wrote:
> Dear all,
>
> I was wondering whether (or better: how) I can use R to read recursively a directory to get all the sub-folders and files located in the root folder and put it into a tree like structure where the leaves are files and intermediate nodes are the directories? The idea is that I'd like to plot the structure of a certain root folder to be able to restructure the file system.
>
> Any ideas on that? I was googling a lot but apparently I did not use the right terms ("R tree folder" or "R tree directory" takes me mainly to pages about the "R-tree" a structure for spatial access methods [at least I learnt something new ;)])
>
> Any pointer to the right function is highly appreciated.
>

In addition, or instead of, suggestions for plotting a file structure as 
a tree, you might consider a treemap (package of same name), which
was designed to show this more compactly, using nested rectangles
showing, e.g., file sizes or other attributes.

HTH


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From ripley at stats.ox.ac.uk  Fri Oct 25 15:07:12 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Oct 2013 14:07:12 +0100
Subject: [R] Regarding rgdal package installation in R
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5554DD9124@GOLD.corp.lgc-group.com>
References: <OFABF260AA.E03F2876-ON65257C0F.002BB224-65257C0F.002BB228@tcs.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554DD9124@GOLD.corp.lgc-group.com>
Message-ID: <526A6D00.4020700@stats.ox.ac.uk>

On 25/10/2013 13:48, S Ellison wrote:
>> -----Original Message-----
>> I'm in-need of rgdal installation for R in our CentOS 6 machine to
>> handle shapefiles.
>
> Is there any reason that you cannot run
>> install.packages("rgdal")
>
> which would be the recommended way to install a package with all dependencies automatically downloaded and installed?

Not the system software dependencies.  For rgdal that is GDAL and PROJ.4 
(and its databases).  On any competent RPM-based system yum etc will 
download all their dependencies automatically.  For Fedora 18 all I 
needed was

yum install gdal-devel proj-devel proj-nad

I'd ask again on r-sig-geo if that fails.

> If you cannot do that, review the CRAN page for the packages which rgdal Depends on or Imports, and make sure those are also installed. Similarly, for each of those.
>
>
> S Ellison
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From smartin_sepia at orange.fr  Fri Oct 25 15:19:39 2013
From: smartin_sepia at orange.fr (Sylvie Martin)
Date: Fri, 25 Oct 2013 15:19:39 +0200 (CEST)
Subject: [R] What computer power for GAMM models
Message-ID: <635013693.33992.1382707179542.JavaMail.www@wwinf1v25>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131025/8f0110bc/attachment.pl>

From gunter.berton at gene.com  Fri Oct 25 16:25:54 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 25 Oct 2013 07:25:54 -0700
Subject: [R] What computer power for GAMM models
In-Reply-To: <635013693.33992.1382707179542.JavaMail.www@wwinf1v25>
References: <635013693.33992.1382707179542.JavaMail.www@wwinf1v25>
Message-ID: <CACk-te1hz3cQLYWtHCjPu7pn2zupQFOR5Rc2uKt=Aw-eh0ETDw@mail.gmail.com>

Sylvie:

I do not know whether your system lacks sufficient power, but its user
-- you --  may.

The models you are trying to fit are complex and nonlinear, and
possibly depending on your data -- do you have a lot of missingness?
How large are your data sets? Can they support your models -- you may
well be overfitting. Getting a faster system will not affect this --
you'll just get your error messages faster.

... and I would have thought the missing values error is self-explanatory.

Sounds to me like you should spend some time with a local statistical expert.

Cheers,
Bert

On Fri, Oct 25, 2013 at 6:19 AM, Sylvie Martin <smartin_sepia at orange.fr> wrote:
>
>
> Hello,
>
>  I use GAMM function (MGCV package) in R software to study relationship between pollen and pollinosis. My models include autoregressive terms. Here is an exemple:
>
> CupAR7_2&lt;-gamm(nb_rca_2~s(Trend,bs="ps",k=49) +Semaine
> &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; +s(TX03,bs="ps",k=8) +s(UN03,bs="ps",k=4)&nbsp; ......+pollen01
> ,correlation=corARMA(p=7,q=0,form=~Trend|Annees),
> niter=40,control=lmeControl(maxIter=100000,msMaxIter=100000)
> &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; ,family=quasipoisson, data=donnees, na=na.omit)
>
> Each model need 1/2 hour to 1 hour to get a result and I frequently get the following error messages:
>
> Erreur dans lme.formula(fixed = fixed, random = random, data = data, correlation = correlation,&nbsp; :
> &nbsp; nlminb problem, convergence error code = 1
> &nbsp; message = singular convergence (7)
>
> Erreur dans na.fail.default(list(Xr.4 = c(0.00374377951791214, 0.00438373736920182,&nbsp; :
> &nbsp; missing values in object
>
>
>  Does my computer lack power,(if so,what is required?) or is R&nbsp; limited in speed of execution or is my syntax not ok. Here are the features of my computer:
>
> processor: 3.10 GHz&nbsp; i5-2400 CPU
> RAM: 4 Go (3.87 Go)
> OS: 64 bits
> Windows 7 professionnel (Pack 1)
>
> Another question: how can we add a smoothing parameter in the model GAMM to help convergence ("sp =" is not accepted)?
>
> Thanks for your help
> Best regards
>
> Sylvie Martin
> SEPIA-Sant?
>
> Bureau d'?tudes en ?pid?miologie,
> biostatistiques, environnement
>
> 31 rue de Pontivy
>
> 56 150 BAUD
>
> FRANCE
> t?l : 02 97 28 80 38
> fax: 02 97 28 81 10
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From gunter.berton at gene.com  Fri Oct 25 16:54:02 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 25 Oct 2013 07:54:02 -0700
Subject: [R] What computer power for GAMM models
In-Reply-To: <635013693.33992.1382707179542.JavaMail.www@wwinf1v25>
References: <635013693.33992.1382707179542.JavaMail.www@wwinf1v25>
Message-ID: <CACk-te3420nGFHeuJGx-4dS7w7RoZHH8-_AzDcXyjHz9v6kAuA@mail.gmail.com>

... and, I should have added, your maxiter parameters in the call are
set way too high. Lowering them to something more sensible will also
get your error messages faster.

-- Bert

On Fri, Oct 25, 2013 at 6:19 AM, Sylvie Martin <smartin_sepia at orange.fr> wrote:
>
>
> Hello,
>
>  I use GAMM function (MGCV package) in R software to study relationship between pollen and pollinosis. My models include autoregressive terms. Here is an exemple:
>
> CupAR7_2&lt;-gamm(nb_rca_2~s(Trend,bs="ps",k=49) +Semaine
> &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; +s(TX03,bs="ps",k=8) +s(UN03,bs="ps",k=4)&nbsp; ......+pollen01
> ,correlation=corARMA(p=7,q=0,form=~Trend|Annees),
> niter=40,control=lmeControl(maxIter=100000,msMaxIter=100000)
> &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; ,family=quasipoisson, data=donnees, na=na.omit)
>
> Each model need 1/2 hour to 1 hour to get a result and I frequently get the following error messages:
>
> Erreur dans lme.formula(fixed = fixed, random = random, data = data, correlation = correlation,&nbsp; :
> &nbsp; nlminb problem, convergence error code = 1
> &nbsp; message = singular convergence (7)
>
> Erreur dans na.fail.default(list(Xr.4 = c(0.00374377951791214, 0.00438373736920182,&nbsp; :
> &nbsp; missing values in object
>
>
>  Does my computer lack power,(if so,what is required?) or is R&nbsp; limited in speed of execution or is my syntax not ok. Here are the features of my computer:
>
> processor: 3.10 GHz&nbsp; i5-2400 CPU
> RAM: 4 Go (3.87 Go)
> OS: 64 bits
> Windows 7 professionnel (Pack 1)
>
> Another question: how can we add a smoothing parameter in the model GAMM to help convergence ("sp =" is not accepted)?
>
> Thanks for your help
> Best regards
>
> Sylvie Martin
> SEPIA-Sant?
>
> Bureau d'?tudes en ?pid?miologie,
> biostatistiques, environnement
>
> 31 rue de Pontivy
>
> 56 150 BAUD
>
> FRANCE
> t?l : 02 97 28 80 38
> fax: 02 97 28 81 10
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From canamika at gmail.com  Fri Oct 25 17:11:24 2013
From: canamika at gmail.com (Anamika Chaudhuri)
Date: Fri, 25 Oct 2013 11:11:24 -0400
Subject: [R] Equation of an Ellipse in R
Message-ID: <CALv--dYGR=BVf9JcEBoPsinnz=SJQ4UCM0k+niJLaX0koOunPQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131025/269a2d07/attachment.pl>

From jdnewmil at dcn.davis.ca.us  Fri Oct 25 17:58:07 2013
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 25 Oct 2013 08:58:07 -0700 (PDT)
Subject: [R] Equation of an Ellipse in R
In-Reply-To: <CALv--dYGR=BVf9JcEBoPsinnz=SJQ4UCM0k+niJLaX0koOunPQ@mail.gmail.com>
References: <CALv--dYGR=BVf9JcEBoPsinnz=SJQ4UCM0k+niJLaX0koOunPQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1310250842410.91804@pedal.dcn.davis.ca.us>

See below.

On Fri, 25 Oct 2013, Anamika Chaudhuri wrote:

> Hi All:
>
> I was looking for some help to code the equation of an ellipse in R, given
> I have a Bivariate Normal distribution (X,Y) with mean (m1,m2) and
> var-covariance matrix (var1,cov12,cov12,var2).

Since you have posted on this topic before, this question is misleading 
because it omits whatever you have attempted already and what was 
unsatisfactory about that. This is not a statistics help forum... if you 
are having difficulty with some specific syntax or semantics of R, please 
read the Posting Guide mentioned below and try again. If you need to 
consult with a statistical expert, you may be best served by speaking 
directly with such an expert, or at least having your theory discussions 
on a statistics forum.

> Thanks
> Anamika
>
> 	[[alternative HTML version deleted]]

Posting in HTML leads to misunderstandings, since we do not in general
see what you see, and when you do finally post reproducible examples they
will be corrupted by the HTML translation to text.

>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please follow the above instructions carefully.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From ucfagls at gmail.com  Fri Oct 25 18:48:01 2013
From: ucfagls at gmail.com (Gavin Simpson)
Date: Fri, 25 Oct 2013 10:48:01 -0600
Subject: [R] What computer power for GAMM models
In-Reply-To: <635013693.33992.1382707179542.JavaMail.www@wwinf1v25>
References: <635013693.33992.1382707179542.JavaMail.www@wwinf1v25>
Message-ID: <CAAHES9w6Cd2-5=ZNBoTdfR=S0jExhCSvEgDPsVgEhixeN-_PCA@mail.gmail.com>

1) The model is far too complex. I have trouble imagining a system
where the trend potentially uses 49 degrees of freedom and yet the
unexplained variance within years follows an AR(7). It looks like you
have time points within years over many years; is that why you are
trying to use such a complex trend, to capture the repeated seasonal
patterns? If so, break that down and fit a spline using `bs = "cc"`
(or one of the other cyclic splines in mgcv) and a separate spline for
the trend. If you want to allow the seasonal pattern to vary with
time, then you can do that with multivariate splines, eg, this way you
can compare a model 1

m1 <- gamm(yi ~ ti(DayOfYear, bs = "cc") + ti(Time, bs = "cr"), ....)

with model 2

m2 <- gamm(yi ~ ti(DayOfYear, bs = "cc") + ti(Time, bs = "cr") +
ti(DayOfYear, Time, bs = c("cc","cr")), ....)

Of course, you'll need to fix the the ARAM structure at know
coefficient (currently you are estimating it) or you aren't really
just comparing the "fixed" part of the models.

2) You aren't heeding Simon's warnings about fiddling with lmeControl.
You don't want EM iterations, so you need at least to have
`lmeControl(niterEM = 0)`, alongside other options

A general word of advice with using gamm(), start simply and make sure
you have lots of RAM. These models are very complex so if you start
with simple models you will be less likely to run into convergence
issues and you get results more quickly. Get lots of RAM because
models with `correlation` arguments involve inverting potentially big
covariance matrices and that can quite quickly chew through RAM.

I've had pretty good success fitting models with non-linear trends etc
to environmental time series using gamm(), but the only time things
went a bit awry was when too complex a model was required (where I had
data covering hundreds of thousands of years from an ocean core and
the trend really was very wiggly, and then the correlation structure
and the trend fought for control as there was an identifiability
issue).

HTH

Gavin

On 25 October 2013 07:19, Sylvie Martin <smartin_sepia at orange.fr> wrote:
>
>
> Hello,
>
>  I use GAMM function (MGCV package) in R software to study relationship between pollen and pollinosis. My models include autoregressive terms. Here is an exemple:
>
> CupAR7_2&lt;-gamm(nb_rca_2~s(Trend,bs="ps",k=49) +Semaine
> &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; +s(TX03,bs="ps",k=8) +s(UN03,bs="ps",k=4)&nbsp; ......+pollen01
> ,correlation=corARMA(p=7,q=0,form=~Trend|Annees),
> niter=40,control=lmeControl(maxIter=100000,msMaxIter=100000)
> &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; ,family=quasipoisson, data=donnees, na=na.omit)
>
> Each model need 1/2 hour to 1 hour to get a result and I frequently get the following error messages:
>
> Erreur dans lme.formula(fixed = fixed, random = random, data = data, correlation = correlation,&nbsp; :
> &nbsp; nlminb problem, convergence error code = 1
> &nbsp; message = singular convergence (7)
>
> Erreur dans na.fail.default(list(Xr.4 = c(0.00374377951791214, 0.00438373736920182,&nbsp; :
> &nbsp; missing values in object
>
>
>  Does my computer lack power,(if so,what is required?) or is R&nbsp; limited in speed of execution or is my syntax not ok. Here are the features of my computer:
>
> processor: 3.10 GHz&nbsp; i5-2400 CPU
> RAM: 4 Go (3.87 Go)
> OS: 64 bits
> Windows 7 professionnel (Pack 1)
>
> Another question: how can we add a smoothing parameter in the model GAMM to help convergence ("sp =" is not accepted)?
>
> Thanks for your help
> Best regards
>
> Sylvie Martin
> SEPIA-Sant?
>
> Bureau d'?tudes en ?pid?miologie,
> biostatistiques, environnement
>
> 31 rue de Pontivy
>
> 56 150 BAUD
>
> FRANCE
> t?l : 02 97 28 80 38
> fax: 02 97 28 81 10
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gavin Simpson, PhD


From vigibos at eio.upv.es  Fri Oct 25 19:15:58 2013
From: vigibos at eio.upv.es (Vicent Giner-Bosch)
Date: Fri, 25 Oct 2013 19:15:58 +0200
Subject: [R] Nonparametric k-way ANOVA
In-Reply-To: <Pine.SOC.4.64.1310251023340.26497@solcom.hrz.uni-giessen.de>
References: <CAHfSo7jFUaPzkV4oBxxkj=GM_POmE=2UB6_6fU6YfvJDrnaEQQ@mail.gmail.com>
	<Pine.SOC.4.64.1310251023340.26497@solcom.hrz.uni-giessen.de>
Message-ID: <CAHfSo7hmgWKPj+RUm=pj5MEAe5qrdnpyHguWb_ynYDvktL1XKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131025/e1217e6f/attachment.pl>

From r.turner at auckland.ac.nz  Fri Oct 25 22:25:41 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 26 Oct 2013 09:25:41 +1300
Subject: [R] Revo R for Arima Implementation
In-Reply-To: <d7923fdac82a40a28fbfc92ae373318a@HKNPR04MB083.apcprd04.prod.outlook.com>
References: <d7923fdac82a40a28fbfc92ae373318a@HKNPR04MB083.apcprd04.prod.outlook.com>
Message-ID: <526AD3C5.6070207@auckland.ac.nz>


Your question is pretty well totally opaque to me.  Describe the model 
you want to
fit in mathematical terms, rather than referring to The Package That 
Must Not Be
Named.  This is the ***R***  list.

It is possible that you might want to make use of the "seasonal" 
argument to the
arima() function.

     cheers,

     Rolf Turner

On 10/26/13 01:19, Anindita Chattopadhyay wrote:
> Hello There,
>
> We have used ARIMA(multiplicative MA and additive AR) model in SAS to come to our results. Please let me know how could that be implemented in R.
>
> Like,  In SAS we can pass the variable  as AR= (1,7) and MA=(1)(7) which is additive and multiplicative respectively.
>
> In R we have the option as : order = c(0, 0, 0) which is (p,d,q).Is there any specific way/code such that we specify the additive  AR and multiplicative MA simultaneously?
>


From r.turner at auckland.ac.nz  Fri Oct 25 22:34:14 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 26 Oct 2013 09:34:14 +1300
Subject: [R] bug in dummy.coef?
In-Reply-To: <0566E17B6DEC62459078112371B7508E0F208C@ait-pex02mbx05.win.dtu.dk>
References: <0566E17B6DEC62459078112371B7508E0F1B7D@ait-pex02mbx05.win.dtu.dk>
	<839AE7D9-E55B-4605-BBD3-2C5ED3E4EEF6@comcast.net>
	<0566E17B6DEC62459078112371B7508E0F208C@ait-pex02mbx05.win.dtu.dk>
Message-ID: <526AD5C6.6040606@auckland.ac.nz>

On 10/25/13 19:24, Alexandra Kuznetsova wrote:
> Thank  you for the reply!
> I need to use it in the package for constructing the contrast matrices.
     Really?
>   Renaming a variable like y2 <- y^2 will not be a solution for me...

     With sufficient effort and diligence (and programming skill) I am 
sure that this
     technique could be made to work in your context.
> Will try to look whether the  function dummy.coef can be modified to work this issue.

     As I said before, the problem is really buried inside the 
all.vars() function, whose workings are
     buried in the R internals.  This would not be at all easy (and 
would probably be dangerous)
     to modify.


     cheers,

     Rolf


From jim at bitwrit.com.au  Fri Oct 25 23:43:22 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 26 Oct 2013 08:43:22 +1100
Subject: [R] add a color band
In-Reply-To: <1382703414.34947.YahooMailNeo@web125305.mail.ne1.yahoo.com>
References: <1382693891.44547.YahooMailNeo@web125302.mail.ne1.yahoo.com>
	<526A3E69.2060103@bitwrit.com.au>
	<1382703414.34947.YahooMailNeo@web125305.mail.ne1.yahoo.com>
Message-ID: <526AE5FA.3000604@bitwrit.com.au>

On 10/25/2013 11:16 PM, Alaios wrote:
> Hi Jim and thanks for help
>
> I will need some help to make
> -the legend visible (probably at the right side of the window)
> -split the legend at 0.1 steps -1,-0.9,-0.8.....1 and
> -assign a color heat.color(30). I have selected orange and reds
> -show me the way to change the size of legend if it would be needed
>
>
>
> par(mar=c(7,4,4,6))
> test<-matrix(data=runif(10000),nrow=100)
> color2D.matplot(test,axes="F",xlab="",ylab="",show.legend=FALSE)
> #,show.legend=TRUE
> axis(1,at=seq(1:nrow(test)),labels=seq(201,300)) #
> color.legend(11,6,11.8,9,seq(-1,1,length=10),rect.col=heat.colors(30),gradient="y")
>
Hi Alex,
You can do this in at least two ways. The first example uses the 
color.scale function to assign colors close to those of heat.colors. The 
second shows how to use heat.colors if you want that.

library(plotrix)
par(mar=c(7,4,4,6))
test<-matrix(data=runif(10000),nrow=100)
# this transforms the values of "test" into red->yellow
color2D.matplot(test,axes="F",xlab="",ylab="",main="color.scale",
  extremes=c("#FF0000","#FFFF00"),show.legend=FALSE)
axis(1,at=seq(1:nrow(test)),labels=seq(201,300))
# use par("usr") to find out the plot dimensions,
# then place the legend where you want it
color.legend(104,30,112,70,seq(-1,1,length=11),
  align="rb",rect.col=color.scale(1:30,1,c(0,1),0),gradient="y")
# now try it with heat.colors
test.cut<-matrix(as.numeric(cut(test,breaks=seq(0,1,length.out=30))),nrow=100)
color2D.matplot(test.cut,axes="F",xlab="",ylab="",main="heat.colors",
  cellcolors=heat.colors(30)[test.cut],show.legend=FALSE)
axis(1,at=seq(1:nrow(test)),labels=seq(201,300))
color.legend(104,30,112,70,seq(-1,1,length=11),
  align="rb",rect.col=heat.colors(30),gradient="y")

Jim


From hannah.hlx at gmail.com  Sat Oct 26 00:40:20 2013
From: hannah.hlx at gmail.com (li li)
Date: Fri, 25 Oct 2013 18:40:20 -0400
Subject: [R] Proportional Odds Model
Message-ID: <CAHLnndaSh4DZF3Uid-VStv0KWPpb0u9iymRYBm8eFG=CW0X-4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131025/a1ba6c86/attachment.pl>

From tom at maladmin.com  Fri Oct 25 17:29:48 2013
From: tom at maladmin.com (Tom Wright)
Date: Fri, 25 Oct 2013 11:29:48 -0400
Subject: [R] problem fitting 2 term exponential with nls
Message-ID: <1382714988.30170.15.camel@tom-laptop.sickkids.ca>

Hi,
Can anyone explain why the nls function is giving an error?
Thanks
Tom

> head(d)
        age  time
1 23.566667 223.0
2 42.633333 223.0
3 62.300000 222.0
4 32.933333 220.5
5  9.366667 228.0
6 23.833333 227.0

> fit<-nls(d$time~a1*exp(b1*d$age) + 
	a2*exp(b2*d$age)+c 
	,start(a1=10,b1=0,a2=250,b2=1,c=0)
	,trace=T)
Error in hasTsp(x) : argument "x" is missing, with no default


From Christian.Kramer at uibk.ac.at  Fri Oct 25 16:48:20 2013
From: Christian.Kramer at uibk.ac.at (Kramer, Christian)
Date: Fri, 25 Oct 2013 14:48:20 +0000
Subject: [R] Adding up normally distributed numbers seems to not create a
 t-distribution
Message-ID: <753E7A21-A21B-4C01-8D38-E42F7AC2EC1C@uibk.ac.at>

Hi there,

I have found a strange behavior in R that puzzles me - maybe it is a bug or a basic scientific misunderstanding of mine? anyway, I would highly appreciate some feedback on this, since I did not find anything on the internet.

I am trying to simulate a t-distribution by adding up normally distributed numbers:

a  <- (rnorm(1000) + rnorm(1000) + rnorm(1000) )/3

However, when I look at the distribution using

qqnorm(a)

this looks more like a normal distribution than a t-distribution:

b <- rt(1000,2)
qqnorm(b)

Is this to be expected? Or is this an issue with the random number generator or something else?

Thanks a lot for replies in advance,
Christian

--------------------------------------------
Dr. Christian Kramer
Theoretical Chemistry
University of Innsbruck
Innrain 82
A-6020 Innsbruck
Tel.: +43 512 507 57103
Homepage: http://homepage.uibk.ac.at/~c72448/kramer.html
Email: Christian.Kramer at uibk.ac.at


From gennady.margolin at gmail.com  Sat Oct 26 01:01:50 2013
From: gennady.margolin at gmail.com (Gennady Margolin)
Date: Fri, 25 Oct 2013 19:01:50 -0400
Subject: [R] failure to build R-3.0.1, R-3.0.2 from source
Message-ID: <CANnC5u3xNjgepA4PLcEjem1gqos+vbG_hEzZjxUCgwn6B0bZ=g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131025/3b4ff186/attachment.pl>

From Ssabri1 at jhu.edu  Sat Oct 26 06:18:52 2013
From: Ssabri1 at jhu.edu (helpwperl)
Date: Fri, 25 Oct 2013 21:18:52 -0700 (PDT)
Subject: [R] Quick help needed in coding quantile normalization
Message-ID: <1382761132334-4679072.post@n4.nabble.com>

I'm trying to code quantile normalization without using any fancy functions
(e.g., normalizeBetweenArrays(), normalize.quantities(), etc.). I'm having a
hard time trying to re-order the columns of my means matrix to match the
original unsorted matrix. I assume I will have to somehow utilize order() or
rank() but I'm having a hard time doing so. I'm essentially attempting to
mirror what is being performed on the third slide of page seven of this
(http://www.biostat.jhsph.edu/~ririzarr/Teaching/688/normalization.pdf)
lecture. I've posted below my current code:

samp <- cbind(samp1, samp2, samp3, samp4)
colnames(samp) <- c("samp1", "samp2", "samp3", "samp4")

samp.sorted <- apply(samp, 2, sort) 

row.means <- rowMeans(samp.sorted, na.rm = FALSE)
row.means <- as.matrix(row.means)
row.means <- cbind(row.means, row.means, row.means, row.means)

Any help would be greatly appreciated. 



--
View this message in context: http://r.789695.n4.nabble.com/Quick-help-needed-in-coding-quantile-normalization-tp4679072.html
Sent from the R help mailing list archive at Nabble.com.


From bhh at xs4all.nl  Sat Oct 26 06:53:30 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 26 Oct 2013 06:53:30 +0200
Subject: [R] problem fitting 2 term exponential with nls
In-Reply-To: <1382714988.30170.15.camel@tom-laptop.sickkids.ca>
References: <1382714988.30170.15.camel@tom-laptop.sickkids.ca>
Message-ID: <760A5EAC-21F7-407F-ACAD-E823AAB3D7EF@xs4all.nl>


On 25-10-2013, at 17:29, Tom Wright <tom at maladmin.com> wrote:

> Hi,
> Can anyone explain why the nls function is giving an error?
> Thanks
> Tom
> 
>> head(d)
>        age  time
> 1 23.566667 223.0
> 2 42.633333 223.0
> 3 62.300000 222.0
> 4 32.933333 220.5
> 5  9.366667 228.0
> 6 23.833333 227.0
> 
>> fit<-nls(d$time~a1*exp(b1*d$age) + 
> 	a2*exp(b2*d$age)+c 
> 	,start(a1=10,b1=0,a2=250,b2=1,c=0)

This line should read:  start=list(a1=10,b1=0,a2=250,b2=1,c=0)

Berend

> 	,trace=T)
> Error in hasTsp(x) : argument "x" is missing, with no default
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sat Oct 26 07:25:13 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 25 Oct 2013 22:25:13 -0700
Subject: [R] Adding up normally distributed numbers seems to not create
	a t-distribution
In-Reply-To: <753E7A21-A21B-4C01-8D38-E42F7AC2EC1C@uibk.ac.at>
References: <753E7A21-A21B-4C01-8D38-E42F7AC2EC1C@uibk.ac.at>
Message-ID: <cae76f6e-d418-4728-a7d6-c5e0740aba7a@email.android.com>

That would be an expected result. Recommend that you hit the books or use a search engine as basic theory like this is off topic here.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"Kramer, Christian" <Christian.Kramer at uibk.ac.at> wrote:
>Hi there,
>
>I have found a strange behavior in R that puzzles me - maybe it is a
>bug or a basic scientific misunderstanding of mine? anyway, I would
>highly appreciate some feedback on this, since I did not find anything
>on the internet.
>
>I am trying to simulate a t-distribution by adding up normally
>distributed numbers:
>
>a  <- (rnorm(1000) + rnorm(1000) + rnorm(1000) )/3
>
>However, when I look at the distribution using
>
>qqnorm(a)
>
>this looks more like a normal distribution than a t-distribution:
>
>b <- rt(1000,2)
>qqnorm(b)
>
>Is this to be expected? Or is this an issue with the random number
>generator or something else?
>
>Thanks a lot for replies in advance,
>Christian
>
>--------------------------------------------
>Dr. Christian Kramer
>Theoretical Chemistry
>University of Innsbruck
>Innrain 82
>A-6020 Innsbruck
>Tel.: +43 512 507 57103
>Homepage: http://homepage.uibk.ac.at/~c72448/kramer.html
>Email: Christian.Kramer at uibk.ac.at
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tsjerkw at gmail.com  Sat Oct 26 09:17:26 2013
From: tsjerkw at gmail.com (Tsjerk Wassenaar)
Date: Sat, 26 Oct 2013 09:17:26 +0200
Subject: [R] Adding up normally distributed numbers seems to not create
	a t-distribution
In-Reply-To: <753E7A21-A21B-4C01-8D38-E42F7AC2EC1C@uibk.ac.at>
References: <753E7A21-A21B-4C01-8D38-E42F7AC2EC1C@uibk.ac.at>
Message-ID: <CABzE1Shijaf_XOONj963Y7CSW6LseB3WNk-t9uHBrrRwN_VsgA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131026/dbfb0698/attachment.pl>

From timo_schmid at hotmail.com  Sat Oct 26 09:55:05 2013
From: timo_schmid at hotmail.com (Timo Schmid)
Date: Sat, 26 Oct 2013 09:55:05 +0200
Subject: [R] No speed effect by using RcppArmadillo compared to R in matrix
 operations
Message-ID: <DUB115-W13441104C769BAAD1B158A9970E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131026/70a14f2c/attachment.pl>

From zhangweiwu at realss.com  Sat Oct 26 10:03:17 2013
From: zhangweiwu at realss.com (Weiwu Zhang)
Date: Sat, 26 Oct 2013 16:03:17 +0800
Subject: [R] Am I working with regularly spaced time series?
In-Reply-To: <CAP01uRnP-SViqMv4zOMKu4xU3owTjTL-RH=AkHU9Eps4gSUgXQ@mail.gmail.com>
References: <mailman.23.1382436009.26591.r-help@r-project.org>
	<52669BBE.3050601@gmail.com>
	<CAP01uRnP-SViqMv4zOMKu4xU3owTjTL-RH=AkHU9Eps4gSUgXQ@mail.gmail.com>
Message-ID: <CAEvpD6385OZcGbhKnrv-w35jY-2A9BaTFfHSNAcc0Dj15rvMiQ@mail.gmail.com>

2013/10/22 Gabor Grothendieck <ggrothendieck at gmail.com>:
> Also note that the zoo package has two classes:
>
> 1. zoo for irregularly spaced series
> 2. zooreg for series with an underlying regularity but for which some
> of the points are missing (which seems to be the situation under
> discussion)
>
> The two classes are nearly the same but zooreg series have a frequency
> and some methods act differently -- most notably lag and diff.

Thank you very much and thank you Paul Gilbert . Your concise answer
fits exactly my question. I'll strart with zoo.

Best.


From meg.pollock at sruc.ac.uk  Fri Oct 25 22:49:57 2013
From: meg.pollock at sruc.ac.uk (MegP)
Date: Fri, 25 Oct 2013 13:49:57 -0700 (PDT)
Subject: [R] zero inflated Poisson - goodness of fit of distribution
Message-ID: <AF1F60F7CF8F0C4CBD19583F5D1694C0052C48@DAGAMB01.internal.domain.loc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131025/22c48ad0/attachment.pl>

From landronimirc at gmail.com  Sat Oct 26 10:06:24 2013
From: landronimirc at gmail.com (Liviu Andronic)
Date: Sat, 26 Oct 2013 10:06:24 +0200
Subject: [R] OT: The topic of reproducibility in the media
Message-ID: <CABxs9VmVK5+CUqKKqjrYOewhiintneiu-eaB_sV9gm0itM+ufg@mail.gmail.com>

Dear all,
I know that reproducibility is a big concern for the R community, so
it may be interesting to some of the readers on this list that The
Economist recently ran a series of articles denouncing the alarming
number of shoddy and non-reproducible published papers:
http://www.economist.com/news/leaders/21588069-scientific-research-has-changed-world-now-it-needs-change-itself-how-science-goes-wrong
http://www.economist.com/news/briefing/21588057-scientists-think-science-self-correcting-alarming-degree-it-not-trouble

They even went as far as stating that "most published scientific
research is probably false":
http://www.economist.com/blogs/graphicdetail/2013/10/daily-chart-2

Anyways, food for thought for the weekend. Regards,
Liviu


From r.turner at auckland.ac.nz  Sat Oct 26 10:14:36 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 26 Oct 2013 21:14:36 +1300
Subject: [R] Adding up normally distributed numbers seems to not create
 a t-distribution
In-Reply-To: <CABzE1Shijaf_XOONj963Y7CSW6LseB3WNk-t9uHBrrRwN_VsgA@mail.gmail.com>
References: <753E7A21-A21B-4C01-8D38-E42F7AC2EC1C@uibk.ac.at>
	<CABzE1Shijaf_XOONj963Y7CSW6LseB3WNk-t9uHBrrRwN_VsgA@mail.gmail.com>
Message-ID: <526B79EC.8080808@auckland.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131026/fc88e970/attachment.pl>

From tsjerkw at gmail.com  Sat Oct 26 10:20:50 2013
From: tsjerkw at gmail.com (Tsjerk Wassenaar)
Date: Sat, 26 Oct 2013 10:20:50 +0200
Subject: [R] Adding up normally distributed numbers seems to not create
	a t-distribution
In-Reply-To: <526B79EC.8080808@auckland.ac.nz>
References: <753E7A21-A21B-4C01-8D38-E42F7AC2EC1C@uibk.ac.at>
	<CABzE1Shijaf_XOONj963Y7CSW6LseB3WNk-t9uHBrrRwN_VsgA@mail.gmail.com>
	<526B79EC.8080808@auckland.ac.nz>
Message-ID: <CABzE1ShT42sxywtz_qcwDJ3Rd-O0nY8bZaCwk1=75A1ZkRhq-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131026/d6808cc9/attachment.pl>

From r.turner at auckland.ac.nz  Sat Oct 26 10:23:30 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 26 Oct 2013 21:23:30 +1300
Subject: [R] OT: The topic of reproducibility in the media
In-Reply-To: <CABxs9VmVK5+CUqKKqjrYOewhiintneiu-eaB_sV9gm0itM+ufg@mail.gmail.com>
References: <CABxs9VmVK5+CUqKKqjrYOewhiintneiu-eaB_sV9gm0itM+ufg@mail.gmail.com>
Message-ID: <526B7C02.5070401@auckland.ac.nz>


Reproducibility is indeed important.  From the point of view of those in 
the statistics
community and in particular in the R community, the key issue is that 
the data on which
a publication is based should be readily accessible so that others can 
replicate and
possibly extend the analysis, and propose and present alternative analyses.

But to say that "most published scientific research is probably false" 
is drivelous
nonsense.  That sort of assertion is made by right-wing ideologues who 
are afflicted
with envy of the academic community and slang off at it to alleviate 
their own sense
of inadequacy.

     cheers,

     Rolf Turner

On 10/26/13 21:06, Liviu Andronic wrote:
> Dear all,
> I know that reproducibility is a big concern for the R community, so
> it may be interesting to some of the readers on this list that The
> Economist recently ran a series of articles denouncing the alarming
> number of shoddy and non-reproducible published papers:
> http://www.economist.com/news/leaders/21588069-scientific-research-has-changed-world-now-it-needs-change-itself-how-science-goes-wrong
> http://www.economist.com/news/briefing/21588057-scientists-think-science-self-correcting-alarming-degree-it-not-trouble
>
> They even went as far as stating that "most published scientific
> research is probably false":
> http://www.economist.com/blogs/graphicdetail/2013/10/daily-chart-2
>
> Anyways, food for thought for the weekend.


From r.turner at auckland.ac.nz  Sat Oct 26 10:26:51 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 26 Oct 2013 21:26:51 +1300
Subject: [R] Adding up normally distributed numbers seems to not create
 a t-distribution
In-Reply-To: <CABzE1ShT42sxywtz_qcwDJ3Rd-O0nY8bZaCwk1=75A1ZkRhq-Q@mail.gmail.com>
References: <753E7A21-A21B-4C01-8D38-E42F7AC2EC1C@uibk.ac.at>
	<CABzE1Shijaf_XOONj963Y7CSW6LseB3WNk-t9uHBrrRwN_VsgA@mail.gmail.com>
	<526B79EC.8080808@auckland.ac.nz>
	<CABzE1ShT42sxywtz_qcwDJ3Rd-O0nY8bZaCwk1=75A1ZkRhq-Q@mail.gmail.com>
Message-ID: <526B7CCB.2080209@auckland.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131026/6a029a9c/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Sat Oct 26 10:32:38 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 26 Oct 2013 01:32:38 -0700
Subject: [R] Quick help needed in coding quantile normalization
In-Reply-To: <1382761132334-4679072.post@n4.nabble.com>
References: <1382761132334-4679072.post@n4.nabble.com>
Message-ID: <f65881c5-9450-405d-8213-bd57fbd82cbd@email.android.com>

Couple of problems:

1) The Posting Guide clearly states that this is not a homework help forum. We don't know what rules your study is constrained by, but if you are doing homework then we do know you have resources at your educational institution to rely on.

2) If this is not homework, why the reluctance to rely on tested code?

3) Your code is not reproducible. If we were to be able to assist you, you should be supplying appropriate sample data with which you could demonstrate your problem and desired solution.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

helpwperl <Ssabri1 at jhu.edu> wrote:
>I'm trying to code quantile normalization without using any fancy
>functions
>(e.g., normalizeBetweenArrays(), normalize.quantities(), etc.). I'm
>having a
>hard time trying to re-order the columns of my means matrix to match
>the
>original unsorted matrix. I assume I will have to somehow utilize
>order() or
>rank() but I'm having a hard time doing so. I'm essentially attempting
>to
>mirror what is being performed on the third slide of page seven of this
>(http://www.biostat.jhsph.edu/~ririzarr/Teaching/688/normalization.pdf)
>lecture. I've posted below my current code:
>
>samp <- cbind(samp1, samp2, samp3, samp4)
>colnames(samp) <- c("samp1", "samp2", "samp3", "samp4")
>
>samp.sorted <- apply(samp, 2, sort) 
>
>row.means <- rowMeans(samp.sorted, na.rm = FALSE)
>row.means <- as.matrix(row.means)
>row.means <- cbind(row.means, row.means, row.means, row.means)
>
>Any help would be greatly appreciated. 
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Quick-help-needed-in-coding-quantile-normalization-tp4679072.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From andrewcd at gmail.com  Sat Oct 26 10:33:40 2013
From: andrewcd at gmail.com (Andrew Crane-Droesch)
Date: Sat, 26 Oct 2013 11:33:40 +0300
Subject: [R] Inscrutable error message in mgcv:  1> prediction = predict(MI,
 se.fit=TRUE, newdata=rhc),
 Error in if (object$inter) X[[i]] <- PredictMat(object$margin[[i]], dat, : ,
 argument is of length zero
Message-ID: <526B7E64.2010806@gmail.com>

Dear List,

I am trying to reproduce a figure that I made for an analysis that I did 
a few months ago.  Between when I first made the figure and now, I've 
upgraded to R 3.0.2 and upgraded my operating system (ubuntu 13.04).  My 
codebase, which once works, is throwing an error when I try to use 
predict.gam on a model object that I saved:

1> prediction = predict(MI,se.fit=TRUE,newdata=rhc)
Error in if (object$inter) X[[i]] <- PredictMat(object$margin[[i]], dat,  :
   argument is of length zero

traceback() gives me the following:

1> traceback()
6: Predict.matrix.tensor.smooth(object, dk$data)
5: Predict.matrix(object, dk$data)
4: Predict.matrix3(object, data)
3: PredictMat(object$smooth[[k]], data)
2: predict.gam(MI, se.fit = TRUE, newdata = rhc)
1: predict(MI, se.fit = TRUE, newdata = rhc)

the final function being called looks like this:

1> Predict.matrix.tensor.smooth
function (object, data)
{
     m <- length(object$margin)
     X <- list()
     for (i in 1:m) {
         term <- object$margin[[i]]$term
         dat <- list()
         for (j in 1:length(term)) dat[[term[j]]] <- data[[term[j]]]
         if (object$inter)
             X[[i]] <- PredictMat(object$margin[[i]], dat, n = 
length(dat[[1]]))
         else X[[i]] <- Predict.matrix(object$margin[[i]], dat)
     }
     mxp <- length(object$XP)
     if (mxp > 0)
         for (i in 1:mxp) if (!is.null(object$XP[[i]]))
             X[[i]] <- X[[i]] %*% object$XP[[i]]
     T <- tensor.prod.model.matrix(X)
     T
}

Unfortunately, I can't say that I understand how that function is 
working, beyond that it takes a fitted model object and makes a piece of 
the model matrix.

Any ideas about what this could stem from?  Where to start looking to 
fix it?  I could probably do the entire analysis from scratch, but it is 
quite complex and I'd prefer to save the time.

Apologies for non-reproducible code -- the data is big and the script is 
long.

Thanks for any assistance,
Andrew


From jdnewmil at dcn.davis.CA.us  Sat Oct 26 10:44:08 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 26 Oct 2013 01:44:08 -0700
Subject: [R] No speed effect by using RcppArmadillo compared to R in
	matrix operations
In-Reply-To: <DUB115-W13441104C769BAAD1B158A9970E0@phx.gbl>
References: <DUB115-W13441104C769BAAD1B158A9970E0@phx.gbl>
Message-ID: <a70583db-e77a-47cc-8412-8ad1c5cca6a7@email.android.com>

I think you don't have accurate information about the speed of R in performing linear algebra computations. It relies on standard numerical libraries for that work, so it is as fast as those libraries are (you are unlikely to beat even an unoptimized version of those libraries with your ad hoc code). You can investigate installing custom versions of those libraries (e.g. [1]), but most performance issues arise due to inefficient handling of data during preparation or post processing.

[1] http://www.avrahamadler.com/2013/10/22/an-openblas-based-rblas-for-windows-64/
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Timo Schmid <timo_schmid at hotmail.com> wrote:
>Hello,
>
>I am looking for a way to do fast matrix operations (multiplication,
>Inversion) for
>large matrices (n=8000) in R. I know R is not that fast in linear
>algebra than
>other software. 
>So I wanted to write some code in C++ and incorporate this code in R. I
>have used the
>package RcppArmadillo, because a lot of people write that it is really
>fast in
>doing matrix algebra. So I have run a short example. See the code
>below.
>I was wondering that I got almost the same CPU time for the matrix
>algebra in my
>example. I expect that using C++ Code in R is faster than using the
>standard
>matrix operations in R. 
>
>Is there a way to do matrix algebra in R faster as the standard command
>(e.g. %*%) using
>the Rcpp or RcppArmadillo packages? I would be happy about any idea or
>advice.
>Thanks in advance
>
>
> > library(Rcpp)
>> library(RcppArmadillo)
>> library(inline)
>> library(RcppEigen)
>> library(devtools)
>> 
>> # Generation of the matrix
>> n=2000
>> A<-matrix(rnorm(n^2,0,1), n,n)
>> 
>> # Code in R 
>> system.time(
>+     D<-A%*%A%*%A+A)
>   user  system elapsed 
>  12.29    0.01   12.33 
>> 
>> # Code using RcppArmadillo
>> src <-
>+     '
>+ arma::mat X = Rcpp::as<arma::mat>(X_);
>+ arma::mat ans = X * X * X + X;
>+ return(wrap(ans));
>+ '
>> mprod6_inline_RcppArma <- cxxfunction(signature(X_="numeric"),
>+                                       body = src,
>plugin="RcppArmadillo")
>> 
>> system.time(
>+     C<-mprod6_inline_RcppArma(X=A))
>   user  system elapsed 
>  12.30    0.08   12.40 
>
> 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tsjerkw at gmail.com  Sat Oct 26 10:56:14 2013
From: tsjerkw at gmail.com (Tsjerk Wassenaar)
Date: Sat, 26 Oct 2013 10:56:14 +0200
Subject: [R] Adding up normally distributed numbers seems to not create
	a t-distribution
In-Reply-To: <526B7CCB.2080209@auckland.ac.nz>
References: <753E7A21-A21B-4C01-8D38-E42F7AC2EC1C@uibk.ac.at>
	<CABzE1Shijaf_XOONj963Y7CSW6LseB3WNk-t9uHBrrRwN_VsgA@mail.gmail.com>
	<526B79EC.8080808@auckland.ac.nz>
	<CABzE1ShT42sxywtz_qcwDJ3Rd-O0nY8bZaCwk1=75A1ZkRhq-Q@mail.gmail.com>
	<526B7CCB.2080209@auckland.ac.nz>
Message-ID: <CABzE1ShAfWZhFro=WEMU1487SdRMGhCM=Y+k2k8B03rkqE2S+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131026/3f8ca462/attachment.pl>

From smartpink111 at yahoo.com  Thu Oct 24 05:04:51 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 23 Oct 2013 20:04:51 -0700 (PDT)
Subject: [R] data frame pointers?
In-Reply-To: <CA+d7zeSMyAJsNrv31Ood8bVv+BP=7eJjKqHX6+wcOWXUtFdKbA@mail.gmail.com>
References: <CA+d7zeTgom8WDBndBfYmcRa6-49qxWD76S+SuNCPQLnkmDDNdQ@mail.gmail.com>	<1382579457.7928.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CA+d7zeSMyAJsNrv31Ood8bVv+BP=7eJjKqHX6+wcOWXUtFdKbA@mail.gmail.com>
Message-ID: <1382583891.91956.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi Jonathan,If you look at the str()
?str(res)
'data.frame':??? 2 obs. of? 4 variables:
?$ gene? : chr? "gene1" "gene2"
?$ case_1:List of 2
? ..$ : chr? "nsyn" "amp"
? ..$ : chr 
?$ case_2:List of 2
? ..$ : chr "del"
? ..$ : chr 
?$ case_3:List of 2
? ..$ : chr 
? ..$ : chr "UTR"

In this case, 

capture.output(res,file="test.txt") #should work

But, if you wanted to use ?write.table() and also to substitute zeros, perhaps:


res[,2:4] <- lapply(res[,2:4],function(x) {x1 <-unlist(lapply(x,paste,collapse=","));x1[x1==""] <- 0; x1})


?str(res)
#'data.frame':??? 2 obs. of? 4 variables:
# $ gene? : chr? "gene1" "gene2"
# $ case_1: chr? "nsyn,amp" "0"
# $ case_2: chr? "del" "0"
# $ case_3: chr? "0" "UTR"

?write.table(res,"test.txt",sep="\t",quote=FALSE,row.names=FALSE)


A.K.




On Wednesday, October 23, 2013 10:44 PM, Jon BR <jonsleepy at gmail.com> wrote:

Hi Arun,
? ?Your suggestion using dcast is simple and worked splendidly! ?Unfortunately, the resulting data frame does not play nicely with write.table.

Any idea how to could print this out to a tab-delimited text file, perhaps substituting zeros in for the empty cells?

See the error below:
> write.table(res,"test.txt")
Error in .External2(C_writetable, x, file, nrow(x), p, rnames, sep, eol, ?:?
? unimplemented type 'list' in 'EncodeElement'


Best,
Jonathan






On Wed, Oct 23, 2013 at 9:50 PM, arun <smartpink111 at yahoo.com> wrote:

HI,
>
>You may try:
>library(reshape2)
>df <-
>data.frame(case=c("case_1","case_1","case_2","case_3"), gene=c("gene1","gene1","gene1","gene2"), issue=c("nsyn","amp","del","UTR"), stringsAsFactors=FALSE)
>res <- dcast(df,gene~case,value.var="issue",list)
>?res
>#?? gene??? case_1 case_2 case_3
>#1 gene1 nsyn, amp??? del??????
>#2 gene2???????????????????? UTR
>
>
>A.K.
>
>
>
>On Wednesday, October 23, 2013 7:38 PM, Jon BR <jonsleepy at gmail.com> wrote:
>Hello,
>? ? I've been running several programs in the unix shell, and it's time to
>combine results from several different pipelines.? I've been writing shell
>scripts with heavy use of awk and grep to make big text files, but I'm
>thinking it would be better to have all my data in one big structure in R
>so that I can query whatever attributes I like, and print several
>corresponding tables to separate files.
>
>I haven't used R in years, so I was hoping somebody might be able to
>suggest a solution or combinatin of functions that could help me get
>oriented..
>
>Right now, I can import my data into a data frame that looks like this:
>
>df <-
>data.frame(case=c("case_1","case_1","case_2","case_3"),gene=c("gene1","gene1","gene1","gene2"),issue=c("nsyn","amp","del","UTR"))
>> df
>? ? case? gene issue
>1 case_1 gene1? nsyn
>2 case_1 gene1? ?amp
>3 case_2 gene1? ?del
>4 case_3 gene2? ?UTR
>
>
>I'd like to cook up some combination of functions/scripting that can
>convert a table like df to produce a list or a data frame/ matrix that
>looks like df2:
>
>> df2
>? ? ? ? case_1 case_2 case_3
>gene1 nsyn,amp? ? del? ? ? 0
>gene2? ? ? ? 0? ? ? 0? ? UTR
>
>I can build df2 manually, like this:
>df2
><-data.frame(case_1=c("nsyn,amp","0"),case_2=c("del","0"),case_3=c("0","UTR"))
>rownames(df2)<-c("gene1","gene2")
>
>but obviously do not want to do this by hand; I want R to generate df2 from
>df.
>
>Any pointers/ideas would be most welcome!
>
>Thanks,
>Jonathan
>
>??? [[alternative HTML version deleted]]
>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


From jim at bitwrit.com.au  Sat Oct 26 12:18:13 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 26 Oct 2013 21:18:13 +1100
Subject: [R] OT: The topic of reproducibility in the media
In-Reply-To: <CABxs9VmVK5+CUqKKqjrYOewhiintneiu-eaB_sV9gm0itM+ufg@mail.gmail.com>
References: <CABxs9VmVK5+CUqKKqjrYOewhiintneiu-eaB_sV9gm0itM+ufg@mail.gmail.com>
Message-ID: <526B96E5.30807@bitwrit.com.au>

On 10/26/2013 07:06 PM, Liviu Andronic wrote:
> Dear all,
> I know that reproducibility is a big concern for the R community, so
> it may be interesting to some of the readers on this list that The
> Economist recently ran a series of articles denouncing the alarming
> number of shoddy and non-reproducible published papers:
> http://www.economist.com/news/leaders/21588069-scientific-research-has-changed-world-now-it-needs-change-itself-how-science-goes-wrong
> http://www.economist.com/news/briefing/21588057-scientists-think-science-self-correcting-alarming-degree-it-not-trouble
>
> They even went as far as stating that "most published scientific
> research is probably false":
> http://www.economist.com/blogs/graphicdetail/2013/10/daily-chart-2
>
> Anyways, food for thought for the weekend. Regards,
> Liviu
>
Thanks, Liviu. Now I don't feel so bad about getting really grouchy with 
the stats in some of the papers I review.

Jim


From a.recktenwald at mx.uni-saarland.de  Sat Oct 26 12:59:05 2013
From: a.recktenwald at mx.uni-saarland.de (Andreas Recktenwald)
Date: Sat, 26 Oct 2013 12:59:05 +0200
Subject: [R] No speed effect by using RcppArmadillo compared to R in
 matrix operations
In-Reply-To: <DUB115-W13441104C769BAAD1B158A9970E0@phx.gbl>
References: <DUB115-W13441104C769BAAD1B158A9970E0@phx.gbl>
Message-ID: <20131026125905.Horde.AUflU8ajPV5Sa6B5GscS4pA@webmail.uni-saarland.de>

Hi,

another option if you're using Linux AND an Intel processor would be  
linking R against Intel MKL (Math Kernel Library). Under Linux you can  
get a (free) non-commercial licence for it.

Here I'm using an Intel(R) Core(TM) i5-3210M CPU @ 2.50GHz laptop  
processor with R 3.0.2 build with intel compilers and linked against  
Intel MKL 11 and get the following times:

> set.seed(123)
> n <- 2000
> A<-matrix(rnorm(n^2,0,1), n,n)
> system.time(D<-A%*%A%*%A+A)
        User      System verstrichen
       1.480       0.004       1.482

PS: I'm using the sequential version of Intel MKL.


Zitat von Timo Schmid <timo_schmid at hotmail.com>:

> Hello,
>
> I am looking for a way to do fast matrix operations (multiplication,  
> Inversion) for
> large matrices (n=8000) in R. I know R is not that fast in linear  
> algebra than
> other software.
> So I wanted to write some code in C++ and incorporate this code in  
> R. I have used the
> package RcppArmadillo, because a lot of people write that it is  
> really fast in
> doing matrix algebra. So I have run a short example. See the code below.
> I was wondering that I got almost the same CPU time for the matrix  
> algebra in my
> example. I expect that using C++ Code in R is faster than using the standard
> matrix operations in R.
>
> Is there a way to do matrix algebra in R faster as the standard  
> command (e.g. %*%) using
> the Rcpp or RcppArmadillo packages? I would be happy about any idea  
> or advice.
> Thanks in advance
>
>
>  > library(Rcpp)
>> library(RcppArmadillo)
>> library(inline)
>> library(RcppEigen)
>> library(devtools)
>>
>> # Generation of the matrix
>> n=2000
>> A<-matrix(rnorm(n^2,0,1), n,n)
>>
>> # Code in R
>> system.time(
> +     D<-A%*%A%*%A+A)
>    user  system elapsed
>   12.29    0.01   12.33
>>
>> # Code using RcppArmadillo
>> src <-
> +     '
> + arma::mat X = Rcpp::as<arma::mat>(X_);
> + arma::mat ans = X * X * X + X;
> + return(wrap(ans));
> + '
>> mprod6_inline_RcppArma <- cxxfunction(signature(X_="numeric"),
> +                                       body = src, plugin="RcppArmadillo")
>>
>> system.time(
> +     C<-mprod6_inline_RcppArma(X=A))
>    user  system elapsed
>   12.30    0.08   12.40
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sat Oct 26 16:50:32 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 26 Oct 2013 14:50:32 +0000
Subject: [R] problem fitting 2 term exponential with nls
In-Reply-To: <760A5EAC-21F7-407F-ACAD-E823AAB3D7EF@xs4all.nl>
References: <1382714988.30170.15.camel@tom-laptop.sickkids.ca>
	<760A5EAC-21F7-407F-ACAD-E823AAB3D7EF@xs4all.nl>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA10B89@PA-MBX01.na.tibco.com>

> >> fit<-nls(d$time~a1*exp(b1*d$age) +
> > 	a2*exp(b2*d$age)+c
> > 	,start(a1=10,b1=0,a2=250,b2=1,c=0)
> 
> This line should read:  start=list(a1=10,b1=0,a2=250,b2=1,c=0)

After you fix that you will run into another problem
   Error in nls(d$time ~ a1 * exp(b1 * d$age) + a2 * exp(b2 * d$age) + c,  : 
     parameters without starting value in 'data': age
Instead of using d$time and d$age, use data=d and just time and age:
fit<-nls(data=d, time~a1*exp(b1*age) + a2*exp(b2*age)+c 
     ,start=list(a1=10,b1=0,a2=250,b2=1,c=0)
     ,trace=T)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Berend Hasselman
> Sent: Friday, October 25, 2013 9:54 PM
> To: Tom Wright
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] problem fitting 2 term exponential with nls
> 
> 
> On 25-10-2013, at 17:29, Tom Wright <tom at maladmin.com> wrote:
> 
> > Hi,
> > Can anyone explain why the nls function is giving an error?
> > Thanks
> > Tom
> >
> >> head(d)
> >        age  time
> > 1 23.566667 223.0
> > 2 42.633333 223.0
> > 3 62.300000 222.0
> > 4 32.933333 220.5
> > 5  9.366667 228.0
> > 6 23.833333 227.0
> >
> >> fit<-nls(d$time~a1*exp(b1*d$age) +
> > 	a2*exp(b2*d$age)+c
> > 	,start(a1=10,b1=0,a2=250,b2=1,c=0)
> 
> This line should read:  start=list(a1=10,b1=0,a2=250,b2=1,c=0)
> 
> Berend
> 
> > 	,trace=T)
> > Error in hasTsp(x) : argument "x" is missing, with no default
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From andreas.nord at zooekol.lu.se  Sat Oct 26 17:01:21 2013
From: andreas.nord at zooekol.lu.se (anord)
Date: Sat, 26 Oct 2013 08:01:21 -0700 (PDT)
Subject: [R] Problems with lme random slope+intercept model
Message-ID: <1382799680418-4679104.post@n4.nabble.com>

Dear all, 
I'm trying to fit a model on ecological data in which I have measured a few
biotic and abiotic factors over the course of a few days in several
individuals. Specifically, I'm interested in modelling y ~ x1, with x2, x3,
and 'factor' as independent variables. Because data suggests both slope and
intercept (for y ~x1) might differ between individuals, I'd want to compare
model fit for a saturated model  with random intercept only, against that of
a model with random slope + intercept. Data are available in full from this
link: 
https://www.dropbox.com/s/mzk8utvgkzp4rtr/data.txt

The random intercept model seems to function appropriately:
data<-subset(data,data$id!='id225' & data$id!='id237' & data$id!='id233')
m1.lme<-with(data,lme(y~x1+x2+x3+factor,random=~1|id,na.action=na.omit))

However, fitting the random slope+intercept model produces an error message
I can't quite make sense of. 
m2.lme<-with(data,lme(y~x1+x2+x3+factor,random=~1+y|id,na.action=na.omit))
#Error in chol.default((value + t(value))/2) : 
#  the leading minor of order 2 is not positive definite

I also tried fitting the same model with a diagonal covariance structure,
which resulted in convergence failure.
m3.lme<-with(data,lme(y~x1+x2+x3+factor,random=reStruct(object=~1+y|id,pdClass="pdDiag"),na.action=na.omit))
#Error in lme.formula(y ~ x1 + x2 + x3, random = reStruct(object = ~y |  : 
#nlminb problem, convergence error code = 1
#message = false convergence (8)

However, changing lmeControl gets this model to run, but I can't make sense
of  the estimates for fixed effects, suggesting the model might be biased.
In addition, I'm not sure how changing lmeControl changes model
interpretation. Perhaps someone could fill me in on this?
m4.lme<-with(data,lme(y~x1+x2+x3+factor,random=reStruct(object=~y|id,pdClass="pdDiag"),na.action=na.omit,
                      control=lmeControl(opt = "optim")))

Any hints on how to proceed from this would be greatly appreciated.

Best, and thanks,
Andreas



--
View this message in context: http://r.789695.n4.nabble.com/Problems-with-lme-random-slope-intercept-model-tp4679104.html
Sent from the R help mailing list archive at Nabble.com.


From alaios at yahoo.com  Sat Oct 26 19:17:25 2013
From: alaios at yahoo.com (Alaios)
Date: Sat, 26 Oct 2013 10:17:25 -0700 (PDT)
Subject: [R] Compare two lists, with their sublists that have same structure
Message-ID: <1382807845.43761.YahooMailNeo@web125305.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131026/878455bb/attachment.pl>

From gunter.berton at gene.com  Sat Oct 26 20:21:54 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 26 Oct 2013 11:21:54 -0700
Subject: [R] Compare two lists,
	with their sublists that have same structure
In-Reply-To: <1382807845.43761.YahooMailNeo@web125305.mail.ne1.yahoo.com>
References: <1382807845.43761.YahooMailNeo@web125305.mail.ne1.yahoo.com>
Message-ID: <CACk-te10n5SNBRW12g+jg+y0q5QfgsMP4mr75Wg7keFi3O3XJw@mail.gmail.com>

Warning: This may not be helpful.

If I understand you correctly, you have two arbitrary lists of the
same structure whose contents you wish to "compare." You have not
specified exactly what sort of comparison you wish to make, e.g. just
"are they the same?" or "What is the nature of any differences?" ...
etc.

In any case, R lists are generic recursive structures, equivalent to
trees. So you may find something useful by searching on "recursive
tree walking in R" or some such, although I was not able to in a brief
try.

But more to the point, and again if I understand you correctly, what
you seek is a way to walk arbitrary lists and "compare" them. This is
not hard, but I think it requires writing a recursive algorithm in R,
which is a bit tricky, and might be too much to ask if you have no
experience with such things. I have a little, so it would probably
take me a day, as compared to under an hour for someone skilled in
such things. Maybe you'll get a more helpful response from someone
with such skills.Or someone can point you to such existing
functionality.

You also might want to have a look at the ?rapply  function, although
I didn't see how it immediately applied; but its name suggests it
might, so maybe I missed something.

Anyway, my message is that this may be a fairly tricky task if a
general solution is wanted, so either provide more details so that
someone can give you something that fits your specific needs (small,
reproducible examples are really useful for this), look around to see
if you can find something that handles the general task, or hope that
all my words will prod someone with more smarts to help.

Cheers,
Bert

On Sat, Oct 26, 2013 at 10:17 AM, Alaios <alaios at yahoo.com> wrote:
> Dear all,
> I would like to ask your help concering two R lists.
> If I did everything should have the same structure (that means the same number of sublists, and their sublists also the same number of sublists). What would change between the two lists is the contents of each element in the lists.
>
>
> Could you please help me understand how I can do that in R?
> I would like to thank you in advance for your help
>
> Regards
> Alex
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From noahsilverman at ucla.edu  Sat Oct 26 20:31:53 2013
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Sat, 26 Oct 2013 11:31:53 -0700
Subject: [R] Strange results from dbeta function
Message-ID: <62D9F8CE-78BE-4172-A684-24C00F3BE1FD@ucla.edu>

Hello,

I?m seeing some strange behavior from the dbeta() function in R.

For example:

> dbeta(0.0001, .4, .6 )
[1] 76.04555


How is it possible to get a PDF that is greater than 1??

Am I doing something wrong here, or is this a quirk of R.

Thanks,

--
Noah Silverman, M.S., C.Phil
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095


From gunter.berton at gene.com  Sat Oct 26 20:41:59 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 26 Oct 2013 11:41:59 -0700
Subject: [R] Strange results from dbeta function
In-Reply-To: <62D9F8CE-78BE-4172-A684-24C00F3BE1FD@ucla.edu>
References: <62D9F8CE-78BE-4172-A684-24C00F3BE1FD@ucla.edu>
Message-ID: <CACk-te0Lam4D6uQoEcHB=uPxsZJi3Bwu+hHSXdNCfg+0EgqEww@mail.gmail.com>

I suggest you review your stat101 text:

A cdf is between 0 and 1, not a pdf, which is a **density** function.

> dnorm(0, sd=.01)
[1] 39.89423

-- Bert


On Sat, Oct 26, 2013 at 11:31 AM, Noah Silverman <noahsilverman at ucla.edu> wrote:
> Hello,
>
> I?m seeing some strange behavior from the dbeta() function in R.
>
> For example:
>
>> dbeta(0.0001, .4, .6 )
> [1] 76.04555
>
>
> How is it possible to get a PDF that is greater than 1??
>
> Am I doing something wrong here, or is this a quirk of R.
>
> Thanks,
>
> --
> Noah Silverman, M.S., C.Phil
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From smartpink111 at yahoo.com  Sat Oct 26 21:05:20 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 26 Oct 2013 12:05:20 -0700 (PDT)
Subject: [R] find and add text
Message-ID: <1382814320.44052.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
You may try:
dat2 <- data.frame(col1=data,col2=as.character(factor(data,labels=c("positive","negative"))),stringsAsFactors=FALSE)


A.K.


Hello all, 

I have a data something like this; 

data<- c("a", "b","b","b","a","a","b","a","b") 

and I need to represent all "a"'s as "positive" ?and "b"'s "negative" in data.frame something like this; 

data.frame output= 
col1 ?col2 
a ? ? positive 
b ? ? negative 
b ? ? negative 
b ? ? negative 
a ? ? positive 
a ? ? positive 
b ? ? negative 
a ? ? positive 
b ? ? negative 

Thanks in advance for your solutions 

Thanks 
karthick


From smartpink111 at yahoo.com  Sat Oct 26 23:09:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 26 Oct 2013 14:09:58 -0700 (PDT)
Subject: [R] find and add text
In-Reply-To: <1382814320.44052.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1382814320.44052.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1382821798.24190.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,

No problem.

Try:
data.frame(col1=data,col2=as.character(factor(gsub("\\d+","",data),labels=c("positive","negative"))),stringsAsFactors=FALSE)
A.K.






Hello Arun, 

Thank you so much, ?it works great. 

But I some sets, the data contains some additional characters 
also, like a1, a2, a3....b1,b2 and so on. in this case how to tag 
positive and negative values? 

initial data: 

data<- c("a1", "b1","b","b2","a2","a3","b","a","b3") 

output expected: 

col1 ?col2 
a1 ? ? positive 
b1 ? ? negative 
b ? ? negative 
b2 ? ? negative 
a2 ? ? positive 
a ? ? positive 
b ? ? negative 
a ? ? positive 
b3 ? ? negative 

How to use grep and tag the annotations.. 

Thanks 
karthick 

On Saturday, October 26, 2013 3:10 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
You may try:
dat2 <- data.frame(col1=data,col2=as.character(factor(data,labels=c("positive","negative"))),stringsAsFactors=FALSE)

A.K.
Hello all, 

I have a data something like this; 

data<- c("a", "b","b","b","a","a","b","a","b") 

and I need to represent all "a"'s as "positive" ?and "b"'s "negative" in data.frame something like this; 

data.frame output= 
col1 ?col2 
a ? ? positive 
b ? ? negative 
b ? ? negative 
b ? ? negative 
a ? ? positive 
a ? ? positive 
b ? ? negative 
a ? ? positive 
b ? ? negative 

Thanks in advance for your solutions 

Thanks 
karthick

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From edd at debian.org  Sat Oct 26 23:33:41 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 26 Oct 2013 21:33:41 +0000
Subject: [R] No speed effect by using RcppArmadillo compared to R in
	matrix operations
References: <DUB115-W13441104C769BAAD1B158A9970E0@phx.gbl>
	<20131026125905.Horde.AUflU8ajPV5Sa6B5GscS4pA@webmail.uni-saarland.de>
Message-ID: <loom.20131026T232755-388@post.gmane.org>

Andreas Recktenwald <a.recktenwald <at> mx.uni-saarland.de> writes:
> another option if you're using Linux AND an Intel processor would be  
> linking R against Intel MKL (Math Kernel Library). Under Linux you can  

You do not have to "link" R against MKL. One simply builds and links R 
against _any_ BLAS implementation: reference BlAS, Atlas, GotoBLAS, 
OpenBLAS or MKL. (This assumes that you compiled R with the shared 
library option).

I have a package (and vignette / unfinished paper) on R-Forge which
implements a testing and timing comparison framework for this, using 
the fact that this is in fact plug&play -- look for 'gcbd' if interested.

Lastly, to come back to the OP's initial question, you are of course 
right. Armadillo calls the LAPACK / BLAS routines; so it ends up making
the same call as R does.  (Rcpp)Armadillo makes a lot of other 
transformations faster, but the core multiplication is about the same
as both R and Armadillo (and everybody else, apart from Eigen) "just" 
call the specialised BLAS. As one should.

Dirk


From alaios at yahoo.com  Sat Oct 26 23:39:11 2013
From: alaios at yahoo.com (Alaios)
Date: Sat, 26 Oct 2013 14:39:11 -0700 (PDT)
Subject: [R] add a color band
In-Reply-To: <526AE5FA.3000604@bitwrit.com.au>
References: <1382693891.44547.YahooMailNeo@web125302.mail.ne1.yahoo.com>
	<526A3E69.2060103@bitwrit.com.au>
	<1382703414.34947.YahooMailNeo@web125305.mail.ne1.yahoo.com>
	<526AE5FA.3000604@bitwrit.com.au>
Message-ID: <1382823551.43934.YahooMailNeo@web125302.mail.ne1.yahoo.com>

Hi Jim and thanks for your answer... I might be too tired with my new born or just exhausted.

I am attaching for everyone a small data snipset that you can load


load("DataToPlotAsImage.Rdata")
require(plotrix)
browser()
test<-data
# this transforms the values of "test" into red->yellow
color2D.matplot(test,axes="F",xlab="",ylab="",main="color.scale",
? extremes=c("#FF0000","#FFFF00"),show.legend=FALSE)
? 
axis(1,at=seq(1,ncol(test),length.out=10),labels=seq(201,300,length.out=10))
color.legend(104,30,112,70,seq(-110,-30,length=11),
? align="rb",rect.col=color.scale(1:30,1,c(0,1),0),gradient="y")

as you can see I have problems where the legend appears. My par("usr"? returned me
par("usr")
# [1]?? 0 351?? 0 200

but I am not sure how to read that to place the legend at a useful place.?
second I am not sure why the image is so full with black rows..

What I want is to have the legend visible
and later on customize the x axis to write custom string of different size... First I need though to fix the more severe problems as I have described

Regards
Alex




On Friday, October 25, 2013 11:45 PM, Jim Lemon <jim at bitwrit.com.au> wrote:
 
On 10/25/2013 11:16 PM, Alaios wrote:
> Hi Jim and thanks for help
>
> I will need some help to make
> -the legend visible (probably at the right side of the window)
> -split the legend at 0.1 steps -1,-0.9,-0.8.....1 and
> -assign a color heat.color(30). I have selected orange and reds
> -show me the way to change the size of legend if it would be needed
>
>
>
> par(mar=c(7,4,4,6))
> test<-matrix(data=runif(10000),nrow=100)
> color2D.matplot(test,axes="F",xlab="",ylab="",show.legend=FALSE)
> #,show.legend=TRUE
> axis(1,at=seq(1:nrow(test)),labels=seq(201,300)) #
> color.legend(11,6,11.8,9,seq(-1,1,length=10),rect.col=heat.colors(30),gradient="y")
>
Hi Alex,
You can do this in at least two ways. The first example uses the 
color.scale function to assign colors close to those of heat.colors. The 
second shows how to use heat.colors if you want that.

library(plotrix)
par(mar=c(7,4,4,6))
test<-matrix(data=runif(10000),nrow=100)
# this transforms the values of "test" into red->yellow
color2D.matplot(test,axes="F",xlab="",ylab="",main="color.scale",
? extremes=c("#FF0000","#FFFF00"),show.legend=FALSE)
axis(1,at=seq(1:nrow(test)),labels=seq(201,300))
# use par("usr") to find out the plot dimensions,
# then place the legend where you want it
color.legend(104,30,112,70,seq(-1,1,length=11),
? align="rb",rect.col=color.scale(1:30,1,c(0,1),0),gradient="y")
# now try it with heat.colors
test.cut<-matrix(as.numeric(cut(test,breaks=seq(0,1,length.out=30))),nrow=100)
color2D.matplot(test.cut,axes="F",xlab="",ylab="",main="heat.colors",
? cellcolors=heat.colors(30)[test.cut],show.legend=FALSE)
axis(1,at=seq(1:nrow(test)),labels=seq(201,300))
color.legend(104,30,112,70,seq(-1,1,length=11),
? align="rb",rect.col=heat.colors(30),gradient="y")


Jim

From pmaclean2011 at yahoo.com  Sat Oct 26 22:37:00 2013
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Sat, 26 Oct 2013 13:37:00 -0700 (PDT)
Subject: [R] Code Book from SPSS Data
Message-ID: <1382819820.82987.YahooMailNeo@web121701.mail.ne1.yahoo.com>

I do not have SPSS and I would like to create a code book in a data frame format using R. I am reading the SPSS file using "memisc package". The script is:
#Data for 2012 available at http://www.ark.ac.uk/nilt/datasets/
#Also attached
ibrary(memisc)
## change the working directory
getwd()
setwd('')
data <- spss.portable.file("NILT12w2.por")
Get names
names(data) 
#Get Variable Lebels
des <- as.data.frame(description(data))
#Descriptive Statistics & Code Book
#Results are very long for printing
codebook(data)
#How could I extract a codebook (without Summary statistics for printing)?



Peter Maclean
Department of Economics
UDSM
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: NILT12w2.por
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131026/ff4aac4c/attachment-0001.pl>

From collinl at cs.pitt.edu  Sun Oct 27 04:57:51 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Sat, 26 Oct 2013 23:57:51 -0400 (EDT)
Subject: [R] Heteroscedasticity and mgcv.
Message-ID: <Pine.LNX.4.44.1310262351240.17762-100000@hydrogen.cs.pitt.edu>

I have a two part question one about statistical theory and the other
about implementations in R.  Thank you for all help in advance.

(1) Am I correct in understanding that Heteroscedasticity is a problem for
Generalized Additive Models as it is for standard linear models?  I am
asking particularly about the GAMs as implemented in the mgcv package.
Based upon my online search it seems that some forms of penalized splines
can address heteroscedasticity while others cannot and I'm not sure what
is true of the methods used in mgcv.

(2) Assuming that heteroscedasticity is a problem for the mgcv GAMs, can
anyone recommend a good test implementation?  I am familiar with the
ncvTest method implemented in the car package but that applies only to
lms.

	Thank you,
	Collin Lynch.


From pragya.panchal23 at gmail.com  Sun Oct 27 02:56:18 2013
From: pragya.panchal23 at gmail.com (pragya.panchal23 at gmail.com)
Date: Sun, 27 Oct 2013 01:56:18 +0000
Subject: [R] =?utf-8?q?About_K-means_Clustering?=
Message-ID: <526c7372.c77ee00a.210b.7db6@mx.google.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/f6ae8d92/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Sun Oct 27 09:32:55 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 27 Oct 2013 08:32:55 +0000
Subject: [R] Code Book from SPSS Data
In-Reply-To: <eb65697bcbd046019906a8d1593da411@EX-0-HT0.lancs.local>
References: <eb65697bcbd046019906a8d1593da411@EX-0-HT0.lancs.local>
Message-ID: <CANVKczMM9g6VT8o03myenSKwuYUdEBomQfOxMrk8nhdtk7fXiQ@mail.gmail.com>

On Sat, Oct 26, 2013 at 9:37 PM, Peter Maclean <pmaclean2011 at yahoo.com> wrote:
> I do not have SPSS and I would like to create a code book in a data frame format using R.

> #How could I extract a codebook (without Summary statistics for printing)?

 This isn't that clear because I don't think 'codebook' is something
well-defined. Describe the rows and columns of the data frame you want
to create.

Barry


From ruipbarradas at sapo.pt  Sun Oct 27 11:05:14 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 27 Oct 2013 10:05:14 +0000
Subject: [R] About K-means Clustering
In-Reply-To: <526c7372.c77ee00a.210b.7db6@mx.google.com>
References: <526c7372.c77ee00a.210b.7db6@mx.google.com>
Message-ID: <526CE55A.5010609@sapo.pt>

Hello,

Both questions are answered in the help page for kmeans(). At an R 
prompt type

?kmeans

and read the section Value. The membership is given by 'cluster' and the 
centers by 'centers'. See also the very first example.

Hope this helps,

Rui Barradas

Em 27-10-2013 01:56, pragya.panchal23 at gmail.com escreveu:
> Hi,
>
> I need some answers regarding to R.  In K-means clustering ,for  K=2, How can I find the members of each cluster and  What are the coordinates for the cluster centers?
> Please send me a reply soon.
>
>
> Thank You
>
>
>
> Sent from Windows Mail
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jim at bitwrit.com.au  Sun Oct 27 12:23:16 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 27 Oct 2013 22:23:16 +1100
Subject: [R] add a color band
In-Reply-To: <1382823551.43934.YahooMailNeo@web125302.mail.ne1.yahoo.com>
References: <1382693891.44547.YahooMailNeo@web125302.mail.ne1.yahoo.com>
	<526A3E69.2060103@bitwrit.com.au>
	<1382703414.34947.YahooMailNeo@web125305.mail.ne1.yahoo.com>
	<526AE5FA.3000604@bitwrit.com.au>
	<1382823551.43934.YahooMailNeo@web125302.mail.ne1.yahoo.com>
Message-ID: <526CF7A4.4050709@bitwrit.com.au>

On 10/27/2013 08:39 AM, Alaios wrote:
> Hi Jim and thanks for your answer... I might be too tired with my new
> born or just exhausted.
>
> I am attaching for everyone a small data snipset that you can load
>
>
> load("DataToPlotAsImage.Rdata")
> require(plotrix)
> browser()
> test<-data
> # this transforms the values of "test" into red->yellow
> color2D.matplot(test,axes="F",xlab="",ylab="",main="color.scale",
> extremes=c("#FF0000","#FFFF00"),show.legend=FALSE)
>
> axis(1,at=seq(1,ncol(test),length.out=10),labels=seq(201,300,length.out=10))
> color.legend(104,30,112,70,seq(-110,-30,length=11),
> align="rb",rect.col=color.scale(1:30,1,c(0,1),0),gradient="y")
>
> as you can see I have problems where the legend appears. My par("usr"
> returned me
> par("usr")
> # [1] 0 351 0 200
>
> but I am not sure how to read that to place the legend at a useful place.
> second I am not sure why the image is so full with black rows..
>
> What I want is to have the legend visible
> and later on customize the x axis to write custom string of different
> size... First I need though to fix the more severe problems as I have
> described
>
Hi Alex,
I'm not sure why you have created a copy of "data" to plot it. I can get 
quite a sensible plot using this:

par(mar=c(5,4,4,5))
color2D.matplot(data,1,c(0,1),0,xlab="",ylab="",
  main="color.scale",xrange=c(-110,-50),border=NA)
color.legend(357,30,370,100,seq(-110,-50,length.out=6),
  align="rb",rect.col=color.scale(1:6,1,c(0,1),0),
  gradient="y")

Notice several things. First, when you have a large number of cells in a 
plot like this, setting the border to NA means that you don't get mostly 
borders (default = black) in the plot. The second thing is that your 
data range is -107.18150 to -54.07662. In order to get rounded numbers 
in your legend, I have set the xrange argument to -110 to -50. This 
gives a neat looking legend that spans your data, a bit like the
"pretty" function would do. It also means that the color mapping is to 
that range and is the same in the legend as in the plot. I have left 
enough space on the right of the plot to fit in the legend, as that was 
where you said you wanted it in your last email. What par("usr") tells 
you is the dimensions of the plot in user units. Here it is x=0 at the 
left, x=351 at the right, y=0 at the bottom and y=200 at the top.

Jim


From pavlidisp at gmail.com  Sun Oct 27 12:30:50 2013
From: pavlidisp at gmail.com (Pavlos Pavlidis)
Date: Sun, 27 Oct 2013 13:30:50 +0200
Subject: [R] how well *new data* fit a pre-computed model
Message-ID: <CABZ9MBXKDkDRXBRUXsuEEBt_LQ1z-0AWs_105conoVyuZ-kBBA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/1098a71a/attachment.pl>

From pavlidisp at gmail.com  Sun Oct 27 12:36:12 2013
From: pavlidisp at gmail.com (Pavlos Pavlidis)
Date: Sun, 27 Oct 2013 13:36:12 +0200
Subject: [R] how well *new data* fit a pre-computed model
In-Reply-To: <CABZ9MBXKDkDRXBRUXsuEEBt_LQ1z-0AWs_105conoVyuZ-kBBA@mail.gmail.com>
References: <CABZ9MBXKDkDRXBRUXsuEEBt_LQ1z-0AWs_105conoVyuZ-kBBA@mail.gmail.com>
Message-ID: <CABZ9MBUEuCVbF0WKRFuBtbWYKwjYzvvJmusmrypTFPa+yB=QSQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/5139379e/attachment.pl>

From motyocska at yahoo.com  Sun Oct 27 12:37:02 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Sun, 27 Oct 2013 04:37:02 -0700 (PDT)
Subject: [R] apply question
Message-ID: <1382873822.77541.YahooMailNeo@web140404.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/ab56a5bf/attachment.pl>

From pburns at pburns.seanet.com  Sun Oct 27 12:51:39 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sun, 27 Oct 2013 11:51:39 +0000
Subject: [R] apply question
In-Reply-To: <1382873822.77541.YahooMailNeo@web140404.mail.bf1.yahoo.com>
References: <1382873822.77541.YahooMailNeo@web140404.mail.bf1.yahoo.com>
Message-ID: <526CFE4B.6070408@pburns.seanet.com>

Homework?  A hint is:

?diff

Pat


On 27/10/2013 11:37, Andras Farkas wrote:
> Dear All,
>
> please help with the following problem:
>
> I have
>
>
> t <-seq(0,24,by=6)
> a <-600
> g <-0.05
> b <-a*exp(-g*t)
>
> I would like to establish a vector called z (for example) based on b where the results are calculated as :
>
> z <-c(a-b[1],b[1]-b[2],b[2]-b[3],b[3]-b[4],b[4]-b[5])
>
> so the results are:
>
> [1]   0.00000 155.50907 115.20395  85.34519  63.22527
>
>
> as always your input is appreciated
>
> Andras
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From motyocska at yahoo.com  Sun Oct 27 12:56:27 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Sun, 27 Oct 2013 04:56:27 -0700 (PDT)
Subject: [R] apply question
In-Reply-To: <526CFE4B.6070408@pburns.seanet.com>
References: <1382873822.77541.YahooMailNeo@web140404.mail.bf1.yahoo.com>
	<526CFE4B.6070408@pburns.seanet.com>
Message-ID: <1382874987.47498.YahooMailNeo@web140405.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/f29b7fd1/attachment.pl>

From bogaso.christofer at gmail.com  Sun Oct 27 16:17:06 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 27 Oct 2013 21:02:06 +0545
Subject: [R] Split a data.frame
Message-ID: <CA+dpOJ=P2FxQEQGY=974XRUmtmkkYm4gmUcqAXL17BX3i=ruTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/bb221ce4/attachment.pl>

From alaios at yahoo.com  Sun Oct 27 16:21:30 2013
From: alaios at yahoo.com (Alaios)
Date: Sun, 27 Oct 2013 08:21:30 -0700 (PDT)
Subject: [R] How to avoid this warning message
Message-ID: <1382887290.61393.YahooMailNeo@web125305.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/3960e0fd/attachment.pl>

From smartpink111 at yahoo.com  Sun Oct 27 17:48:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 27 Oct 2013 09:48:52 -0700 (PDT)
Subject: [R] Split a data.frame
In-Reply-To: <CA+dpOJ=P2FxQEQGY=974XRUmtmkkYm4gmUcqAXL17BX3i=ruTA@mail.gmail.com>
References: <CA+dpOJ=P2FxQEQGY=974XRUmtmkkYm4gmUcqAXL17BX3i=ruTA@mail.gmail.com>
Message-ID: <1382892532.1721.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
DF$Col2
# [1] a e b b a b c e b a c c e e a c d c c e
#Levels: a b c d e


"b" is not found in any of the "Grs".? Also Gr3 is not presnt in DF$Col2

So, I am not sure whether this works for you.

indx <- 1+ 2*DF$Col2 %in% Gr1 + 4*DF$Col2 %in% Gr2 + 8*DF$Col2 %in% Gr3
?indx <- indx[indx>1]
?split(DF[DF$Col2%in% c(Gr1,Gr2,Gr3),],indx)

A.K.





On Sunday, October 27, 2013 11:19 AM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
Hi again,

Let say I have following DF:

DF <- structure(list(Col1 = 1:20, Col2 = structure(c(1L, 5L, 2L, 2L,
1L, 2L, 3L, 5L, 2L, 1L, 3L, 3L, 5L, 5L, 1L, 3L, 4L, 3L, 3L, 5L
), .Label = c("a", "b", "c", "d", "e"), class = "factor")), .Names =
c("Col1",
"Col2"), row.names = c(NA, -20L), class = "data.frame")

DF


Now I create 3 groups like:

Gr1 <- c('a', 'c', 'd')
Gr2 <- c('e')
Gr3 <- c('f', 'x')


My goal is to split DF according to these groups. And to generate NULL (or
something like that) if a particular group contains no value.

So far I tried to split DF according to split() function. However it looks
to me like, this split() does not offer this kind of customization.


Can someone here help me how to split my data.frame according to this
criteria?

Thanks and regards,

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From tobebryant at me.com  Sun Oct 27 21:46:11 2013
From: tobebryant at me.com (tobias schlager)
Date: Sun, 27 Oct 2013 21:46:11 +0100
Subject: [R] Use correlation matrix to get values for a new data frame
Message-ID: <81F84997-4AE8-4EDD-AE43-9EA2B0BB779E@me.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/51f6be48/attachment.pl>

From pmaclean2011 at yahoo.com  Sun Oct 27 22:37:27 2013
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Sun, 27 Oct 2013 14:37:27 -0700 (PDT)
Subject: [R] Code Book from SPSS Data
In-Reply-To: <CANVKczMM9g6VT8o03myenSKwuYUdEBomQfOxMrk8nhdtk7fXiQ@mail.gmail.com>
References: <eb65697bcbd046019906a8d1593da411@EX-0-HT0.lancs.local>
	<CANVKczMM9g6VT8o03myenSKwuYUdEBomQfOxMrk8nhdtk7fXiQ@mail.gmail.com>
Message-ID: <1382909847.95072.YahooMailNeo@web121706.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/afc0d20d/attachment.pl>

From imran at sulug.stanford.edu  Sun Oct 27 20:49:43 2013
From: imran at sulug.stanford.edu (Imran Akbar)
Date: Sun, 27 Oct 2013 12:49:43 -0700
Subject: [R] dunnett test questions
Message-ID: <CABoH17dGoOx8XDd5fkaDgUuiuA38fZKa2PHwkbs38P5-DDtEKQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/67099ac6/attachment.pl>

From pragya.panchal23 at gmail.com  Sun Oct 27 22:27:04 2013
From: pragya.panchal23 at gmail.com (pragya panchal)
Date: Sun, 27 Oct 2013 17:27:04 -0400
Subject: [R] About K-means Clustering
In-Reply-To: <526c7372.c77ee00a.210b.7db6@mx.google.com>
References: <526c7372.c77ee00a.210b.7db6@mx.google.com>
Message-ID: <CAAxbT+00veE2Y9WRRgcQ61PTZMa_Nr4ugLGZCSosp4kkH=N4qg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/b8fa2e15/attachment.pl>

From william108 at gmail.com  Sun Oct 27 22:33:04 2013
From: william108 at gmail.com (Bill)
Date: Sun, 27 Oct 2013 14:33:04 -0700
Subject: [R] numeric data being interpreted as a factor -trouble with
 reading data into a dataframe in R
Message-ID: <CAJnbHtL1FaKnK67+g3Q4t=--BFs+4ojO=2-h2f6uSp7h+2y9xg@mail.gmail.com>

Hello.
trying to do one of the simplest actions -read in data into R.
I don't know why the FBfollowers column is being read as a factor and also
if I use as.numeric on it, it looks really strange and actually complety
alters the data.
I am attaching the data set here called ddd.csv
I used
data=read.csv("ddd.csv",header=TRUE)

fb=data$FBfollowers
fb
fb=as.numeric(fb)
fb

Thnxs in advance

From zsazsazsusy at gmail.com  Sun Oct 27 12:10:09 2013
From: zsazsazsusy at gmail.com (Hansol Yu)
Date: Sun, 27 Oct 2013 04:10:09 -0700
Subject: [R] nls function error
Message-ID: <CADVD-dCnORepJP8BPBZPuth4f8huhYHCSmF9sn2DVJWOY5sALA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/b87208aa/attachment.pl>

From r.rigby at londonmet.ac.uk  Sun Oct 27 16:50:10 2013
From: r.rigby at londonmet.ac.uk (Robert Rigby)
Date: Sun, 27 Oct 2013 15:50:10 +0000
Subject: [R] R-help Digest, Vol 128, Issue 29
In-Reply-To: <mailman.15.1382871606.12237.r-help@r-project.org>
References: <mailman.15.1382871606.12237.r-help@r-project.org>
Message-ID: <CAKmh6oEEQArfcTCamO2Gkbn2YFAbuGwEY7C0y3jiuc4i4hMB3g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/1b6662e7/attachment.pl>

From r.turner at auckland.ac.nz  Mon Oct 28 01:18:08 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 28 Oct 2013 13:18:08 +1300
Subject: [R] nls function error
In-Reply-To: <CADVD-dCnORepJP8BPBZPuth4f8huhYHCSmF9sn2DVJWOY5sALA@mail.gmail.com>
References: <CADVD-dCnORepJP8BPBZPuth4f8huhYHCSmF9sn2DVJWOY5sALA@mail.gmail.com>
Message-ID: <526DAD40.9060506@auckland.ac.nz>

On 10/28/13 00:10, Hansol Yu wrote:
> data(Boston, package='MASS')
> y <- Boston$nox
> x <- Boston$dis
> nls(y~ A + B * exp(C * x), start=list(A=1, B=1, C=1))
>
> Error in nls(y ~ A + B * exp(C * x), start = list(A = 1, B = 1, C = 1),  :
>    step factor 0.000488281 reduced below 'minFactor' of 0.000976562
>
> I don't know how to fix this error. I think my problem is that I set the
> wrong start. Could somebody help please?

Different starting values will indeed fix the problem.  Did you *try* 
different starting
values?  Take some initiative!

It is pretty clear that C has to be negative, so make the starting value 
negative.
Using 1, 1, -1 still doesn't work, but 0.5, 0.5, -0.5 does work.

The function optim() is more robust to starting values.  Try

foo <- function(par,x,y){
A <- par[1]
B <- par[2]
C <- par[3]
sum((y - (A+B*exp(C*x)))^2)
}

optim(c(1,1,-1),foo,x=x,y=y,method="BFGS")

The estimates given by optim() are the same as those given by nls() with the
0.5, 0.5, -0.5 starting values.

     cheers,

     Rolf Turner


From jdnewmil at dcn.davis.CA.us  Mon Oct 28 02:23:18 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 27 Oct 2013 18:23:18 -0700
Subject: [R] numeric data being interpreted as a factor -trouble with
	reading data into a dataframe in R
In-Reply-To: <CAJnbHtL1FaKnK67+g3Q4t=--BFs+4ojO=2-h2f6uSp7h+2y9xg@mail.gmail.com>
References: <CAJnbHtL1FaKnK67+g3Q4t=--BFs+4ojO=2-h2f6uSp7h+2y9xg@mail.gmail.com>
Message-ID: <84288e83-5f50-4fae-838f-e118be7689b2@email.android.com>

No data came through (I don't think "CSV" is one of the approved file types.)

You probably have some odd characters somewhere in the data. Try adding the argument stringsAsFactors=FALSE to the read.csv call before converting the troublesome column.. Converting factors to numeric converts the integer representation, not the character representation. Once you identify which rows are corrupt, you can look at them more closely. You may be able to formulate a regex pattern that removes the invalid characters with the sub function before conversion.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Bill <william108 at gmail.com> wrote:
>Hello.
>trying to do one of the simplest actions -read in data into R.
>I don't know why the FBfollowers column is being read as a factor and
>also
>if I use as.numeric on it, it looks really strange and actually
>complety
>alters the data.
>I am attaching the data set here called ddd.csv
>I used
>data=read.csv("ddd.csv",header=TRUE)
>
>fb=data$FBfollowers
>fb
>fb=as.numeric(fb)
>fb
>
>Thnxs in advance
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Mon Oct 28 03:23:23 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 28 Oct 2013 02:23:23 +0000
Subject: [R] Problems with lme random slope+intercept model
References: <1382799680418-4679104.post@n4.nabble.com>
Message-ID: <loom.20131028T032216-656@post.gmane.org>

anord <andreas.nord <at> zooekol.lu.se> writes:

> 
> Dear all, 
> I'm trying to fit a model on ecological data in which I have measured a few
> biotic and abiotic factors over the course of a few days in several
> individuals. Specifically, I'm interested in modelling y ~ x1, with x2, x3,
> and 'factor' as independent variables. Because data suggests both slope and
> intercept (for y ~x1) might differ between individuals, I'd want to compare
> model fit for a saturated model  with random intercept only, against
> that of
> a model with random slope + intercept. Data are available in
>  full from this
> link: 
> https://www.dropbox.com/s/mzk8utvgkzp4rtr/data.txt

  Sorry for snipping context, and for not really responding, but this
question might get more traction on the r-sig-mixed-models mailing list
(r-sig-mixed-models at r-project.org) ...
  I would guess that your model is overfitted/unidentifiable, but I would
have to look a lot more carefully to know for sure.

  Ben Bolker


From jwd at surewest.net  Mon Oct 28 04:24:05 2013
From: jwd at surewest.net (jwd)
Date: Sun, 27 Oct 2013 20:24:05 -0700
Subject: [R] Code Book from SPSS Data
In-Reply-To: <1382909847.95072.YahooMailNeo@web121706.mail.ne1.yahoo.com>
References: <eb65697bcbd046019906a8d1593da411@EX-0-HT0.lancs.local>
	<CANVKczMM9g6VT8o03myenSKwuYUdEBomQfOxMrk8nhdtk7fXiQ@mail.gmail.com>
	<1382909847.95072.YahooMailNeo@web121706.mail.ne1.yahoo.com>
Message-ID: <20131027202405.77373df8@draco.site>

On Sun, 27 Oct 2013 14:37:27 -0700 (PDT)
Peter Maclean <pmaclean2011 at yahoo.com> wrote:

It's not fully clear what you need, but, as I very vaguely recall, the
code book in SPSS provided labels for what are called levels in
"factors" in R, which are categorical variables. 

Try: "??categorical" at the prompt for starters.

Then ?factor

JWDougherty


From zsazsazsusy at gmail.com  Mon Oct 28 06:53:54 2013
From: zsazsazsusy at gmail.com (Hansol Yu)
Date: Sun, 27 Oct 2013 22:53:54 -0700
Subject: [R] plotting multiple variables
Message-ID: <CADVD-dB3OxRm1YGgN0Oe2ttLrSeKG=rXAn_FY_vt7H6=jZ3gjg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131027/d81efcbe/attachment.pl>

From jim at bitwrit.com.au  Mon Oct 28 07:24:35 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 28 Oct 2013 17:24:35 +1100
Subject: [R] plotting multiple variables
In-Reply-To: <CADVD-dB3OxRm1YGgN0Oe2ttLrSeKG=rXAn_FY_vt7H6=jZ3gjg@mail.gmail.com>
References: <CADVD-dB3OxRm1YGgN0Oe2ttLrSeKG=rXAn_FY_vt7H6=jZ3gjg@mail.gmail.com>
Message-ID: <526E0323.4010508@bitwrit.com.au>

On 10/28/2013 04:53 PM, Hansol Yu wrote:
> When my data has 50 rows, 100 columns and class column. How can I plot this
> data and show classes? Do I have to draw 100 lines?
>
Hi Hansol,
I doubt that anyone on the R help list really knows the answer to your 
question unless your lecturer is one of us.

Jim


From Achim.Zeileis at uibk.ac.at  Mon Oct 28 07:40:51 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 28 Oct 2013 07:40:51 +0100 (CET)
Subject: [R] dunnett test questions
In-Reply-To: <CABoH17dGoOx8XDd5fkaDgUuiuA38fZKa2PHwkbs38P5-DDtEKQ@mail.gmail.com>
References: <CABoH17dGoOx8XDd5fkaDgUuiuA38fZKa2PHwkbs38P5-DDtEKQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1310280722410.29651@paninaro.uibk.ac.at>

On Sun, 27 Oct 2013, Imran Akbar wrote:

> Hi,
>    I've got a data set with a control group and a number of experimental
> groups, that have unequal sample sizes, and am measuring the number of
> people in each that respond yes or no.  I'd like to use a dunnett test in
> R, where the syntax is supposed to be like:
>
> library(multcomp)
> test.dunnett=glht(anova_results,linfct=mcp(method="Dunnett"))
> confint(test.dunnett)
> plot(test.dunnett)
>
> but:
> 1)  How do I run a dunnett test without doing the ANOVA (which wouldn't
> have its requirements satisfied, as the measurements are not independent
> due to the control group)?

But the control group is a separate independent group from the three 
treatments A-C, isn't it? Then independence should not be a problem.

For the binary response you need something different than an ANOVA, e.g., 
an analysis of deviance in a logistic regression.

> 2)  Do I have to tell the test what my sample sizes are, or will it
> calculate the sums itself?

If you supply a suitable fitted model, then glht() can infer the group 
sizes from that:

## data and table
dat <- data.frame(
   freq = c(23, 19, 27, 53, 623, 523, 823, 469),
   resp = factor(rep(c("Yes", "No"), each = 4)),
   method = factor(rep(1:4, 2), labels = c("Control", "A", "B", "C"))
)
tab <- xtabs(freq ~ method + resp, data = dat)

## visualization and Pearson chi-squared test
spineplot(tab[, 2:1])
mosaicplot(tab, shade = TRUE, off = c(5, 0.5))
chisq.test(tab)

## Logistic regression and analysis of deviance chi-squared test
m <- glm(resp ~ method, weights = freq, data = dat, family = binomial)
anova(m, test = "Chisq")

## Odds ratios
exp(coef(m)[-1])

## Dunnett test
library("multcomp")
m_glht <- glht(m, linfct = mcp(method = "Dunnett"))
summary(m_glht)
confint(m_glht)
plot(m_glht)

> Here's my matrix:
>
>
>       Control        A           B           C
> Yes       23          19          27          53
> No        623         523         823         469
>
>
> thanks,
>
> imran
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From stefano.sofia at regione.marche.it  Mon Oct 28 07:56:47 2013
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Mon, 28 Oct 2013 06:56:47 +0000
Subject: [R] Different information between correlation and frequency of a
 seasonal time series
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F0DA2F508@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F0DA2F508@ESINO.regionemarche.intra>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F0DA2F51E@ESINO.regionemarche.intra>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/a3348c9d/attachment.pl>

From alaios at yahoo.com  Mon Oct 28 08:57:51 2013
From: alaios at yahoo.com (Alaios)
Date: Mon, 28 Oct 2013 00:57:51 -0700 (PDT)
Subject: [R] add a color band
In-Reply-To: <526CF7A4.4050709@bitwrit.com.au>
References: <1382693891.44547.YahooMailNeo@web125302.mail.ne1.yahoo.com>
	<526A3E69.2060103@bitwrit.com.au>
	<1382703414.34947.YahooMailNeo@web125305.mail.ne1.yahoo.com>
	<526AE5FA.3000604@bitwrit.com.au>
	<1382823551.43934.YahooMailNeo@web125302.mail.ne1.yahoo.com>
	<526CF7A4.4050709@bitwrit.com.au>
Message-ID: <1382947071.31098.YahooMailNeo@web125301.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/4709ecd9/attachment.pl>

From Markus.Gesmann at lloyds.com  Mon Oct 28 09:57:14 2013
From: Markus.Gesmann at lloyds.com (Gesmann, Markus)
Date: Mon, 28 Oct 2013 08:57:14 +0000
Subject: [R] Code Book from SPSS Data
In-Reply-To: <1382819820.82987.YahooMailNeo@web121701.mail.ne1.yahoo.com>
References: <1382819820.82987.YahooMailNeo@web121701.mail.ne1.yahoo.com>
Message-ID: <2D1AC19CDA3D5643B9D7AE596C377B280C1022DF@GBS0039303.lloyds.net>

Peter,

There is a function called codebook as part of the memisc package that probably does what you want.
See also the package vignette: http://cran.r-project.org/web/packages/memisc/vignettes/anes48.pdf

library(memisc)
fn <- "NILT12w2.por"
dat <- spss.portable.file(fn)
codebook(dat)
names(dat)
description(dat)

I hope this helps.

Markus



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Peter Maclean
Sent: 26 October 2013 21:37
To: r-help at r-project.org
Subject: Re: [R] Code Book from SPSS Data

I do not have SPSS and I would like to create a code book in a data frame format using R. I am reading the SPSS file using "memisc package". The script is:
#Data for 2012 available at https://urldefense.proofpoint.com/v1/url?u=http://www.ark.ac.uk/nilt/datasets/&k=VTIXiGvdT7U4yPSpeHcrHQ%3D%3D%0A&r=dUkLGPeM%2BYkyyiRRq50yGs%2BmEf8kG%2FyCNQPwZn%2FaQD0%3D%0A&m=GVKjmjUiiJIiVcY%2FZ%2B35UGhRSRtdr9OJQhLQUx7Ax7Q%3D%0A&s=4dfa4233895c7e2f635380b0f8392a989a28848049001908965f058667a15143
#Also attached
ibrary(memisc)
## change the working directory
getwd()
setwd('')
data <- spss.portable.file("NILT12w2.por")
Get names
names(data) 
#Get Variable Lebels
des <- as.data.frame(description(data))
#Descriptive Statistics & Code Book
#Results are very long for printing
codebook(data)
#How could I extract a codebook (without Summary statistics for printing)?



Peter Maclean
Department of Economics
UDSM

----------------------------------------------------------------------
The information in this E-Mail and in any attachments is...{{dropped:19}}


From rm at wippies.se  Mon Oct 28 10:00:30 2013
From: rm at wippies.se (rm)
Date: Mon, 28 Oct 2013 02:00:30 -0700 (PDT)
Subject: [R] coxph: how to define interaction terms?
Message-ID: <1382950829862-4679162.post@n4.nabble.com>

I?m trying to set up Cox Proptional Hazard model with interactions between
time and the covariates (which are categorical). The problem that I face is
that how to define the interactions, i.e. ?x+cutStart:x?, properly.

The code below illustrates the problem. R gives the error message ? X matrix
deemed to be singular?, because ?x+cutStart:x? includes too many
combinations of the dummies in the model. 

Any help is much appreciated!

aml2=survSplit(aml,cut=c(10,20,30),end='time',event='status',start='start')
aml2$cutStart=as.factor(aml2$start)
coxph(Surv(start,time,status)~x+cutStart:x,data=aml2)





--
View this message in context: http://r.789695.n4.nabble.com/coxph-how-to-define-interaction-terms-tp4679162.html
Sent from the R help mailing list archive at Nabble.com.


From babakbsn at gmail.com  Mon Oct 28 11:13:22 2013
From: babakbsn at gmail.com (Babak Bastan)
Date: Mon, 28 Oct 2013 03:13:22 -0700
Subject: [R] Package for PAV and MPAV algorithms
Message-ID: <CAF-JZQu1+Kc_ELSR3VYwuP5tw4YVr5wYN0xhsxjh1r+HC98uhg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/c1fbde7d/attachment.pl>

From dulcalma at bigpond.com  Mon Oct 28 12:25:18 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Mon, 28 Oct 2013 21:25:18 +1000
Subject: [R] plotting multiple variables
In-Reply-To: <526E0323.4010508@bitwrit.com.au>
References: <CADVD-dB3OxRm1YGgN0Oe2ttLrSeKG=rXAn_FY_vt7H6=jZ3gjg@mail.gmail.com>
	<526E0323.4010508@bitwrit.com.au>
Message-ID: <003c01ced3d0$62fb7cb0$28f27610$@bigpond.com>

Hi Hansol,

If you know the lattice system 

library(lattice)
library(latticeExtra)

useOuterStrips(
xyplot(y ~ x|class, data = dat, ...)
)

See also ? combineLimits

Otherwise

mfrow(10,10)

and loop your data  to plot

This is about as far as I can go - I have the same comment as Jim

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

           

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Jim Lemon
Sent: Monday, 28 October 2013 16:25
To: Hansol Yu
Cc: r-help at r-project.org
Subject: Re: [R] plotting multiple variables

On 10/28/2013 04:53 PM, Hansol Yu wrote:
> When my data has 50 rows, 100 columns and class column. How can I plot 
> this data and show classes? Do I have to draw 100 lines?
>
Hi Hansol,
I doubt that anyone on the R help list really knows the answer to your
question unless your lecturer is one of us.

Jim

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Mon Oct 28 12:59:56 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 28 Oct 2013 06:59:56 -0500
Subject: [R] Problem with coordinates when trying to draw lines into a
 raster (image) file
In-Reply-To: <526E2A7F.5020204@btconnect.com>
References: <526532CE.6020404@btconnect.com>
	<CAN5YmCFsW=rx=Liz_TWhKG5xDiPjHLDj3pUUuCrVf2_Hpn48MA@mail.gmail.com>
	<526E2A7F.5020204@btconnect.com>
Message-ID: <CAN5YmCHJkw8j2wSdHUY3M9HCfjDPECBDL9xjetJOeMpxd0MQrw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/61a887c6/attachment.pl>

From maechler at stat.math.ethz.ch  Mon Oct 28 13:37:38 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 28 Oct 2013 13:37:38 +0100
Subject: [R] bug in dummy.coef?
In-Reply-To: <526AD5C6.6040606@auckland.ac.nz>
References: <0566E17B6DEC62459078112371B7508E0F1B7D@ait-pex02mbx05.win.dtu.dk>
	<839AE7D9-E55B-4605-BBD3-2C5ED3E4EEF6@comcast.net>
	<0566E17B6DEC62459078112371B7508E0F208C@ait-pex02mbx05.win.dtu.dk>
	<526AD5C6.6040606@auckland.ac.nz>
Message-ID: <21102.23186.315341.979103@stat.math.ethz.ch>

>>>>> Rolf Turner <r.turner at auckland.ac.nz>
>>>>>     on Sat, 26 Oct 2013 09:34:14 +1300 writes:

    > On 10/25/13 19:24, Alexandra Kuznetsova wrote:
    >> Thank you for the reply!  I need to use it in the package
    >> for constructing the contrast matrices.
    >      Really?
    >> Renaming a variable like y2 <- y^2 will not be a solution
    >> for me...

    >      With sufficient effort and diligence (and programming
    > skill) I am sure that this technique could be made to work
    > in your context.
    >> Will try to look whether the function dummy.coef can be
    >> modified to work this issue.

    >      As I said before, the problem is really buried inside
    > the all.vars() function, whose workings are buried in the
    > R internals.  This would not be at all easy (and would
    > probably be dangerous) to modify.

Well, I've now spent much too much time on this now, trying to
explore possible changes.
It's definitely an order more complicated than you think, Rolf.

A change to all.vars() would break other cases and other code.
But I now strongly believe it's not even that part of
dummy.coef.lm() that needs to be amended.

Consider  example(dummy.coef) 's examples,
and also the test case from R/tests/reg-tests-1a.R, i.e., the
following block

  ## PR 1048 bug in dummy.coef.lm, Adrian Baddeley, 2001-08-10
  ## modified to give a sensible test
  old <- getOption("contrasts")
  options(contrasts=c("contr.helmert", "contr.poly"))
  DF <- data.frame(x=1:20,y=rnorm(20),z=factor(1:20 <= 10))
  dummy.coef(lm(y ~ z * I(x), data=DF))
  dummy.coef(lm(y ~ z * poly(x,1), data=DF))
  ## failed in 1.3.0.  Second one warns: deficiency of the method.
  options(contrasts=old)

where interestingly, there is no warning anymore, even though
the comment says there would be one, and I think I see the warning
in dummy.coef.lm's code ... which would been triggered somewhere in the
past ...

Many years ago, partly in S / S+ times, we used to advocate the
use of model.tables() over dummy.coef(), but as you can see on
its help page, it is neither implemented for all cases. 

Martin Maechler, ETH Zurich


From Anindita.C at mu-sigma.com  Mon Oct 28 14:26:47 2013
From: Anindita.C at mu-sigma.com (Anindita Chattopadhyay)
Date: Mon, 28 Oct 2013 13:26:47 +0000
Subject: [R] Revo R for Arima Implementation
In-Reply-To: <526AD3C5.6070207@auckland.ac.nz>
References: <d7923fdac82a40a28fbfc92ae373318a@HKNPR04MB083.apcprd04.prod.outlook.com>
	<526AD3C5.6070207@auckland.ac.nz>
Message-ID: <fb7ea8f3506e4058b25a8f0fe693b909@HKNPR04MB083.apcprd04.prod.outlook.com>

Hi Rolf,

Thanks for the response. I have re-phrased the problem. Hope this will help.

We're working on a project where our model tries to predict the value of bookings as a time series of past bookings as well as some external flags.
The data was found to be stationary using the Dicky-Fuller test.
We have only a non-seasonal component for the AR and MA terms (small p & q only).
No differencing was done.

Then, we used values of p = 1, 7, 8 and q = 1, 7.
The main issue is that the p values are additive and q values are multiplicative.
We need to understand how we can implement this in Revo R.

Just to add, since we have external flags , we cannot make use of SARIMA function.
Please let me know if any other questions.

Thank you in advance!

Regards,
Anindita Chattopadhyay | +919886800606 | www.mu-sigma.com |

-----Original Message-----
From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
Sent: Saturday, October 26, 2013 1:56 AM
To: Anindita Chattopadhyay
Cc: r-help at r-project.org; Harish K
Subject: Re: [R] Revo R for Arima Implementation


Your question is pretty well totally opaque to me.  Describe the model you want to fit in mathematical terms, rather than referring to The Package That Must Not Be Named.  This is the ***R***  list.

It is possible that you might want to make use of the "seasonal"
argument to the
arima() function.

     cheers,

     Rolf Turner

On 10/26/13 01:19, Anindita Chattopadhyay wrote:
> Hello There,
>
> We have used ARIMA(multiplicative MA and additive AR) model in SAS to come to our results. Please let me know how could that be implemented in R.
>
> Like,  In SAS we can pass the variable  as AR= (1,7) and MA=(1)(7) which is additive and multiplicative respectively.
>
> In R we have the option as : order = c(0, 0, 0) which is (p,d,q).Is there any specific way/code such that we specify the additive  AR and multiplicative MA simultaneously?
>
This email message may contain proprietary, private and confidential information. The information transmitted is intended only for the person(s) or entities to which it is addressed. Any review, retransmission, dissemination or other use of, or taking of any action in reliance upon, this information by persons or entities other than the intended recipient is prohibited and may be illegal. If you received this in error, please contact the sender and delete the message from your system. Mu Sigma takes all reasonable steps to ensure that its electronic communications are free from viruses. However, given Internet accessibility, the Company cannot accept liability for any virus introduced by this e-mail or any attachment and you are advised to use up-to-date virus checking software.


From OrtizJ at si.edu  Mon Oct 28 14:40:51 2013
From: OrtizJ at si.edu (Ortiz, John)
Date: Mon, 28 Oct 2013 13:40:51 +0000
Subject: [R] pie graphs in log scale axis
Message-ID: <690A755A58FD3641B5EC4EEEA1D00AB12BF349B3@si-msedag04.US.SINET.SI.EDU>


Dear list users,


I'm doing a plot integrating Grid output with Base Graphics output  (gridBase, Murrell 2012).

My goal is to produce a xy plot where each point is represented by a pie.  I could get it using the attach code,
but now I want to change the X axis to log scale.

when I introduce the log="x" parameter in the line:

plot(x, y, xlim=c(0.1, 1.2), log="x", ylim=c(0.1, 1.2), type="n")

I get this warning!

vps <- baseViewports()
Warning message:
In baseViewports() : viewport scales NOT set to user coordinates


This is the code to produce it without introduce log scale yet:

library(grid)
library(gridBase)
x <- c(0.88, 1.00, 0.67, 0.34)
y <- c(0.87, 0.43, 0.24, 0.94)
z <- matrix(runif(4*2), ncol=2)

oldpar <- par(no.readonly=TRUE)

plot(x, y, xlim=c(0.1, 1.2), ylim=c(0.1, 1.2), type="n")

vps <- baseViewports()
pushViewport(vps$inner, vps$figure, vps$plot)

for (i in 1:4) {
 pushViewport(viewport(x=unit(x[i], "native"),
 y=unit(y[i], "native"),
 width=0.1,
 height=0.1))
 par(plt=gridPLT(), new=TRUE)
 pie(z[i,], radius=1, labels=rep("", 2))
 popViewport()
 }

popViewport(2)
par(oldpar)

Thanks by some advice!!

Regards,


John Ortiz

Geologist
Smithsonian Tropical Research Institute Panama


From rm at wippies.se  Mon Oct 28 14:54:57 2013
From: rm at wippies.se (rm)
Date: Mon, 28 Oct 2013 06:54:57 -0700 (PDT)
Subject: [R] coxph: how to define interaction terms?
In-Reply-To: <1382950829862-4679162.post@n4.nabble.com>
References: <1382950829862-4679162.post@n4.nabble.com>
Message-ID: <1382968497507-4679176.post@n4.nabble.com>

The output is as follows. My question is how to include only the interaction
terms where x is equal to "Maintained".

(x has two possible values "Maintained" and "Nonmaintained".)





--
View this message in context: http://r.789695.n4.nabble.com/coxph-how-to-define-interaction-terms-tp4679162p4679176.html
Sent from the R help mailing list archive at Nabble.com.


From Ben-Ammar at gmx.de  Mon Oct 28 14:19:36 2013
From: Ben-Ammar at gmx.de (Ben Ammar)
Date: Mon, 28 Oct 2013 14:19:36 +0100 (CET)
Subject: [R] How to extract residuals from multiple regressions from a loop
Message-ID: <trinity-f79ade8e-cb4b-448c-8932-99830a621096-1382966376541@3capp-gmx-bs11>


   Dear all

   I've  got  the following problem, I want to extract the residuals from
   regression loops. The problem here is that some columns include NA's at the
   beginning and end (i.e. each time series of stocks starts at different
   points  in  time and ends at different points in time). When I want to
   transfer these residuals into a matrix to determine the residual matrix, I
   get the error message ("number of items to replace is not a multiple of
   replacement length"). I tried it with na.action=na.exclude but that doesn't
   work because that command doesn't actually change the vector length. With a
   loop I came this far:
   Number of stocks is 50 and maximum time period is 258 months:

   for (i in 1:50) {CAPM.res[,i] <- residuals(lm(timeseries[,i]~exc.mkt),
   na.action=na.exclude)}

   as I said it doesn't work because of the different column length in the
   matrix "timeseries". So right now I'm doing kind of manually which works
   perfectly but is quite intensive and looks like that:
   test.1 <- lm(timeseries[,1]~exc.mkt, na.action=na.exclude)
   residual.test.1 <- residuals(test.1)
   CAPM.res[,1] <- residual.Life.1

   test.2 <- lm(timeseries[,2]~exc.mkt, na.action=na.exclude)
   residual.test.2 <- residuals(test.2)
   CAPM.res[,2] <- residual.test.2

   ....and so on for the remaining 49 stocks. When I look at that I obviously
   see that this must be done with a loop but in the end I can't put in the
   matrix because of the different lengths. So far I got this:
   test<-matrix(0,50,258)
   residual.test<-matrix(0,50,258)
   for (i in 1:50) {lm(timeseries[,i]~exc.mkt, na.action=na.exclude)
                   {residual.test[i] <- residuals(test[i])
                   {CAPM.res[,i] <- residual.test[i]
   }}}

   but here I get the error message: "Error: $ operator is invalid for atomic
   vectors"
   and I don't think "test"  and "residual.test" is defined correctly because I
   don't know where to look for the residuals.

   Does anyone have an idea how to extract the residuals and put them in a
   258x50 matrix?
   Any help would be very much appreciated!

   Cheers,
   Ben

From k.moon at student.unimelb.edu.au  Mon Oct 28 13:07:07 2013
From: k.moon at student.unimelb.edu.au (kmmoon100)
Date: Mon, 28 Oct 2013 05:07:07 -0700 (PDT)
Subject: [R] Optimization failed in fitdistr (Weibull distribution)
Message-ID: <1382962027602-4679167.post@n4.nabble.com>

Hello everyone,

This is Kangmin.

I am trying to produce shape and scale of my wind data. My data is based on
wind speed frequency with 1km/hr increment. data is described below.

Windspeed (km/h)    Frequency
1	351
2	147
3	317
4	378
5	527
6	667
7	865
8	970
9	987
10	907
11	905
12	642
13	1000
14	983
15	847
16	842
17	757
18	698
19	632
20	626
21	599
22	529
23	325
24	391
25	356
26	267
27	230
28	223
29	190
30	142
31	124
32	104
33	97
34	37
35	62
36	46
37	42
38	24
39	9
40	13
41	9
42	5
43	2

R codes to calculate shape and scale are described below:

Pine.windfrequency.4weeks<-read.table("C:/Users/kmoon/Documents/Pine_frequency_4weeks.csv",header=TRUE,sep=",")
fitdistr(Pine.windfrequency.4weeks$Frequency, densfun="weibull")

I have got an error message when I was using 'fitdistr' function

"Error in fitdistr(Pine.windfrequency.4weeks$Frequency, densfun = "weibull")
: 
  optimization failed"

Please help me calculating shape and scale of weibull distribution.

And please understand that I am not an user familiar with R program but I am
really trying to make my analysis work on R!

Thank you!!!

Kangmin.



--
View this message in context: http://r.789695.n4.nabble.com/Optimization-failed-in-fitdistr-Weibull-distribution-tp4679167.html
Sent from the R help mailing list archive at Nabble.com.


From andreas.nord at biol.lu.se  Mon Oct 28 13:22:29 2013
From: andreas.nord at biol.lu.se (anord)
Date: Mon, 28 Oct 2013 05:22:29 -0700 (PDT)
Subject: [R] Problems with lme random slope+intercept model
In-Reply-To: <1382799680418-4679104.post@n4.nabble.com>
References: <1382799680418-4679104.post@n4.nabble.com>
Message-ID: <1382962949527-4679168.post@n4.nabble.com>

Dear Ben, 
Thank you, I agree. I have forwarded this to the r-sig-mixed-models list.

Best,
Andreas



--
View this message in context: http://r.789695.n4.nabble.com/Problems-with-lme-random-slope-intercept-model-tp4679104p4679168.html
Sent from the R help mailing list archive at Nabble.com.


From k.moon at student.unimelb.edu.au  Mon Oct 28 13:27:56 2013
From: k.moon at student.unimelb.edu.au (kmmoon100)
Date: Mon, 28 Oct 2013 05:27:56 -0700 (PDT)
Subject: [R] "Optimization fail" error from fitdistr (Weibull distribution)
Message-ID: <1382963276016-4679169.post@n4.nabble.com>

Hello everyone, 

This is Kangmin. 

I am trying to produce shape and scale of my wind data. My data is based on
wind speed frequency with 1km/hr increment. data is described below.
 
Windspeed (km/h)    Frequency 
1 351 
2 147 
3 317 
4 378 
5 527 
6 667 
7 865 
8 970 
9 987 
10 907 
11 905 
12 642 
13 1000 
14 983 
15 847 
16 842 
17 757 
18 698 
19 632 
20 626 
21 599 
22 529 
23 325 
24 391 
25 356 
26 267 
27 230 
28 223 
29 190 
30 142 
31 124 
32 104 
33 97 
34 37 
35 62 
36 46 
37 42 
38 24 
39 9 
40 13 
41 9 
42 5 
43 2 

R codes to calculate shape and scale are described below: 

Pine.windfrequency.4weeks<-read.table("C:/Users/kmoon/Documents/Pine_frequency_4weeks.csv",header=TRUE,sep=",")
 fitdistr(Pine.windfrequency.4weeks$Frequency, densfun="weibull") 

I have got an error message when I was using 'fitdistr' function 

"Error in fitdistr(Pine.windfrequency.4weeks$Frequency, densfun = "weibull")
: 
  optimization failed" 

Please help me calculating shape and scale of weibull distribution. 

And please understand that I am not an user familiar with R program but I am
really trying to make my analysis work on R!
 
Thank you!!! 

Kangmin. 



--
View this message in context: http://r.789695.n4.nabble.com/Optimization-fail-error-from-fitdistr-Weibull-distribution-tp4679169.html
Sent from the R help mailing list archive at Nabble.com.


From lorenz at usgs.gov  Mon Oct 28 14:27:09 2013
From: lorenz at usgs.gov (Lorenz, David)
Date: Mon, 28 Oct 2013 08:27:09 -0500
Subject: [R] R-help Digest, Vol 128, Issue 30
In-Reply-To: <mailman.15.1382958005.936.r-help@r-project.org>
References: <mailman.15.1382958005.936.r-help@r-project.org>
Message-ID: <CALxY2Ldfdr6hRZdjHfq776e-wv+aVwPV1gSvCEg+Qe3Bicvgnw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/d95d4ce3/attachment.pl>

From johannesradinger at gmail.com  Mon Oct 28 15:51:08 2013
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Mon, 28 Oct 2013 15:51:08 +0100
Subject: [R] indicating significant differences in boxplots
Message-ID: <CABsGe_yTp=uqZZfKBpQQH2aAhnfgp7OazHi3pw1Bo-L59CuTHA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/bb1350ff/attachment.pl>

From juliosergio at gmail.com  Mon Oct 28 16:01:05 2013
From: juliosergio at gmail.com (Julio Sergio Santana)
Date: Mon, 28 Oct 2013 15:01:05 +0000
Subject: [R] Countour for netCDF-like meshes
Message-ID: <loom.20131028T151637-992@post.gmane.org>

Hi,
A model gives me as output a netCDF file which I read with ncdf package. The 
output consists of three similar matrices: one contains the variable value, 
and the other two, the longitude and latitude coordinates. I need to do a 
contour graph with such information, however, the R contour function 
expects, 
two vectors X, Y, and a matrix Z, as its input. X and Y, being the same 
length as the number of rows and columns of Z matrix, respectively. This 
implies that the Z values in the same row, all have the same abscissa, and 
the Z values in the same colum, all have the same ordinate.

I know, in systems  similar to matlab, ferret, ncl, and the like, you just 
give the three matrices, and the system performs all the necessary 
interpolations to display the contour. Do you know if there is a way to do 
the same in R?

Though not exactly an output in a netCDF, I'm presenting here a very 
simplified example of the kind of output I need to plot.

  val <- matrix(c(rep(15,5),rep(c(15:17,16,15),2),rep(15,5)),nrow=4,byrow=T)
  v1 <- 1:5
  v2 <- 10:13
  xx <- cbind(v2, v2+.1, v2+.2, v2+.1, v2)
  yy <- rbind(v1, v1+0.1, v1+0.2, v1+0.1)

val: is the matrix with the values I want to plot.
xx: is the corresponding abscissa values.
yy: is the corresponging ordinate values.


Thanks,

  -Sergio.


From ruipbarradas at sapo.pt  Mon Oct 28 16:07:49 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 28 Oct 2013 15:07:49 +0000
Subject: [R] Optimization failed in fitdistr (Weibull distribution)
In-Reply-To: <1382962027602-4679167.post@n4.nabble.com>
References: <1382962027602-4679167.post@n4.nabble.com>
Message-ID: <526E7DC5.9020701@sapo.pt>

Hello,

I can't reproduce your error:

windfreq <-
c(1351L, 2147L, 3317L, 4378L, 5527L, 6667L, 7865L, 8970L, 9987L,
10907L, 11905L, 12642L, 131000L, 14983L, 15847L, 16842L, 17757L,
18698L, 19632L, 20626L, 21599L, 22529L, 23325L, 24391L, 25356L,
26267L, 27230L, 28223L, 29190L, 30142L, 31124L, 32104L, 3397L,
3437L, 3562L, 3646L, 3742L, 3824L, 399L, 4013L, 419L, 425L, 432L

library(MASS)

fitdistr(windfreq, "weibull")


Hope this helps,

Rui Barradas

Em 28-10-2013 12:07, kmmoon100 escreveu:
> Hello everyone,
>
> This is Kangmin.
>
> I am trying to produce shape and scale of my wind data. My data is based on
> wind speed frequency with 1km/hr increment. data is described below.
>
> Windspeed (km/h)    Frequency
> 1	351
> 2	147
> 3	317
> 4	378
> 5	527
> 6	667
> 7	865
> 8	970
> 9	987
> 10	907
> 11	905
> 12	642
> 13	1000
> 14	983
> 15	847
> 16	842
> 17	757
> 18	698
> 19	632
> 20	626
> 21	599
> 22	529
> 23	325
> 24	391
> 25	356
> 26	267
> 27	230
> 28	223
> 29	190
> 30	142
> 31	124
> 32	104
> 33	97
> 34	37
> 35	62
> 36	46
> 37	42
> 38	24
> 39	9
> 40	13
> 41	9
> 42	5
> 43	2
>
> R codes to calculate shape and scale are described below:
>
> Pine.windfrequency.4weeks<-read.table("C:/Users/kmoon/Documents/Pine_frequency_4weeks.csv",header=TRUE,sep=",")
> fitdistr(Pine.windfrequency.4weeks$Frequency, densfun="weibull")
>
> I have got an error message when I was using 'fitdistr' function
>
> "Error in fitdistr(Pine.windfrequency.4weeks$Frequency, densfun = "weibull")
> :
>    optimization failed"
>
> Please help me calculating shape and scale of weibull distribution.
>
> And please understand that I am not an user familiar with R program but I am
> really trying to make my analysis work on R!
>
> Thank you!!!
>
> Kangmin.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Optimization-failed-in-fitdistr-Weibull-distribution-tp4679167.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bhh at xs4all.nl  Mon Oct 28 16:24:16 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 28 Oct 2013 16:24:16 +0100
Subject: [R] Optimization failed in fitdistr (Weibull distribution)
In-Reply-To: <526E7DC5.9020701@sapo.pt>
References: <1382962027602-4679167.post@n4.nabble.com>
	<526E7DC5.9020701@sapo.pt>
Message-ID: <55020AD1-B809-4543-811F-DDEFB55A69EA@xs4all.nl>


On 28-10-2013, at 16:07, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
> 
> I can't reproduce your error:
> 
> windfreq <-
> c(1351L, 2147L, 3317L, 4378L, 5527L, 6667L, 7865L, 8970L, 9987L,
> 10907L, 11905L, 12642L, 131000L, 14983L, 15847L, 16842L, 17757L,
> 18698L, 19632L, 20626L, 21599L, 22529L, 23325L, 24391L, 25356L,
> 26267L, 27230L, 28223L, 29190L, 30142L, 31124L, 32104L, 3397L,
> 3437L, 3562L, 3646L, 3742L, 3824L, 399L, 4013L, 419L, 425L, 432L
> 
> library(MASS)
> 
> fitdistr(windfreq, "weibull")

You seem to have collapsed the two columns of data into a single column.
That's why it works for you.

The OP should use the dput function to show the data.
If I take the data as presented I get the same error (but I don't use sep="," since the data displayed don't contain a ,).
And show the actual code used such as library(MASS).

Berend


From ahmedatia80 at gmail.com  Mon Oct 28 16:30:54 2013
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Mon, 28 Oct 2013 10:30:54 -0500
Subject: [R] linear line in x, y plot
Message-ID: <CAG6S0OkJFeqf8+j6my3tMW3ZUN4O0mAucX87_bVGHDaakqTEqg@mail.gmail.com>

Hi

I have a question about drawing a linear line in x, y plot. I usually
use the following code, but for this time the x values are to small
(-0.08 to -0.02)

I wrote the following code, but r does not draw the line. However, it
does not give an error when it takes the code.


reg1<- lm(CWSI~NWI, data=Ahmed)

NWI <- seq(-0.08, -0.02, len = -0.02)
lines(NWI, predict(reg1, list(NWI =
NWI)),xlim=c(-0.08,-0.02),ylim=c(0,1),pch=1,col=1,lwd=2, lty=1)

When I wrote the following code

abline(reg1,pch=2,col=2,lwd=2, lty=2,xlim=c(-0.06,-0.02),ylim=c(0.3,0.8))

the line shows up, but I can not control the xlim or ylim. It bascally
goes across the figure

I appreciate your help
-- 
Ahmed M. Attia


Research Assistant
Dept. Of Soil&Crop Sciences
Texas A&M University
ahmed.attia at ag.tamu.edu
Cell phone: 001-979-248-5215


From wdunlap at tibco.com  Mon Oct 28 16:33:44 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 28 Oct 2013 15:33:44 +0000
Subject: [R] How to extract residuals from multiple regressions from a
 loop
In-Reply-To: <trinity-f79ade8e-cb4b-448c-8932-99830a621096-1382966376541@3capp-gmx-bs11>
References: <trinity-f79ade8e-cb4b-448c-8932-99830a621096-1382966376541@3capp-gmx-bs11>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA10E1B@PA-MBX01.na.tibco.com>

Can you trim down your example to a size where you can show us
the data (using dump() or dput()) and the commands you used so
one can just copy it from your mail and paste it into R to reproduce
the problem?

I don't see your problem when I made up data similar to what you described:

> timeseries <- ts(cbind(c(NA, 2:9, NA), c(1,NA,3,NA,5:10), c(rep(NA,9), 10)))
> exc.mkt <- log(1:10)
> for(i in 1:ncol(timeseries)) print(length(residuals(lm(timeseries[,i]~exc.mkt, na.action=na.exclude))))
[1] 10
[1] 10
[1] 10
> # without na.action=na.exclude residuals do vary in length
> for(i in 1:ncol(timeseries)) print(length(residuals(lm(timeseries[,i]~exc.mkt))))
[1] 8
[1] 8
[1] 1

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Ben Ammar
> Sent: Monday, October 28, 2013 6:20 AM
> To: r-help at r-project.org
> Subject: [R] How to extract residuals from multiple regressions from a loop
> 
> 
>    Dear all
> 
>    I've  got  the following problem, I want to extract the residuals from
>    regression loops. The problem here is that some columns include NA's at the
>    beginning and end (i.e. each time series of stocks starts at different
>    points  in  time and ends at different points in time). When I want to
>    transfer these residuals into a matrix to determine the residual matrix, I
>    get the error message ("number of items to replace is not a multiple of
>    replacement length"). I tried it with na.action=na.exclude but that doesn't
>    work because that command doesn't actually change the vector length. With a
>    loop I came this far:
>    Number of stocks is 50 and maximum time period is 258 months:
> 
>    for (i in 1:50) {CAPM.res[,i] <- residuals(lm(timeseries[,i]~exc.mkt),
>    na.action=na.exclude)}
> 
>    as I said it doesn't work because of the different column length in the
>    matrix "timeseries". So right now I'm doing kind of manually which works
>    perfectly but is quite intensive and looks like that:
>    test.1 <- lm(timeseries[,1]~exc.mkt, na.action=na.exclude)
>    residual.test.1 <- residuals(test.1)
>    CAPM.res[,1] <- residual.Life.1
> 
>    test.2 <- lm(timeseries[,2]~exc.mkt, na.action=na.exclude)
>    residual.test.2 <- residuals(test.2)
>    CAPM.res[,2] <- residual.test.2
> 
>    ....and so on for the remaining 49 stocks. When I look at that I obviously
>    see that this must be done with a loop but in the end I can't put in the
>    matrix because of the different lengths. So far I got this:
>    test<-matrix(0,50,258)
>    residual.test<-matrix(0,50,258)
>    for (i in 1:50) {lm(timeseries[,i]~exc.mkt, na.action=na.exclude)
>                    {residual.test[i] <- residuals(test[i])
>                    {CAPM.res[,i] <- residual.test[i]
>    }}}
> 
>    but here I get the error message: "Error: $ operator is invalid for atomic
>    vectors"
>    and I don't think "test"  and "residual.test" is defined correctly because I
>    don't know where to look for the residuals.
> 
>    Does anyone have an idea how to extract the residuals and put them in a
>    258x50 matrix?
>    Any help would be very much appreciated!
> 
>    Cheers,
>    Ben
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From babakbsn at gmail.com  Mon Oct 28 16:37:09 2013
From: babakbsn at gmail.com (Babak Bastan)
Date: Mon, 28 Oct 2013 08:37:09 -0700
Subject: [R] Error:Data is not atomic
Message-ID: <CAF-JZQsMZ4Zuf34ZHf0jyX=eNLOTorvef=dzeAZB77YYCfbfHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/294bf4fd/attachment.pl>

From jvadams at usgs.gov  Mon Oct 28 16:50:05 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 28 Oct 2013 10:50:05 -0500
Subject: [R] How to extract residuals from multiple regressions from a
	loop
In-Reply-To: <trinity-f79ade8e-cb4b-448c-8932-99830a621096-1382966376541@3capp-gmx-bs11>
References: <trinity-f79ade8e-cb4b-448c-8932-99830a621096-1382966376541@3capp-gmx-bs11>
Message-ID: <CAN5YmCHqbc8Xmu-XYLTUDn5oqwfu6LyVHQaYDKvoYufheTRvQA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/b52b41b8/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Mon Oct 28 16:53:58 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 28 Oct 2013 08:53:58 -0700
Subject: [R] Revo R for Arima Implementation
In-Reply-To: <fb7ea8f3506e4058b25a8f0fe693b909@HKNPR04MB083.apcprd04.prod.outlook.com>
References: <d7923fdac82a40a28fbfc92ae373318a@HKNPR04MB083.apcprd04.prod.outlook.com>
	<526AD3C5.6070207@auckland.ac.nz>
	<fb7ea8f3506e4058b25a8f0fe693b909@HKNPR04MB083.apcprd04.prod.outlook.com>
Message-ID: <938e7304-29f4-498a-84f7-3ecacd9acfb8@email.android.com>

You still don't seem to get the hint that support that is SPECIFIC to Revolution R is off- topic on this mailing list. Since you have identified your subject so clearly, we can only safely respond that we cannot answer you.

If you change your mind and decide to ask what can be done in R (which should also work in Revolution R but may not be optimal), you should also read the Posting Guide and post a reproducible example that demonstrates where you are in your analysis. You should also use the RSiteSearch function to look up packages that might address your needs, since this is not a statistics theory discussion forum either.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Anindita Chattopadhyay <Anindita.C at mu-sigma.com> wrote:
>Hi Rolf,
>
>Thanks for the response. I have re-phrased the problem. Hope this will
>help.
>
>We're working on a project where our model tries to predict the value
>of bookings as a time series of past bookings as well as some external
>flags.
>The data was found to be stationary using the Dicky-Fuller test.
>We have only a non-seasonal component for the AR and MA terms (small p
>& q only).
>No differencing was done.
>
>Then, we used values of p = 1, 7, 8 and q = 1, 7.
>The main issue is that the p values are additive and q values are
>multiplicative.
>We need to understand how we can implement this in Revo R.
>
>Just to add, since we have external flags , we cannot make use of
>SARIMA function.
>Please let me know if any other questions.
>
>Thank you in advance!
>
>Regards,
>Anindita Chattopadhyay | +919886800606 | www.mu-sigma.com |
>
>-----Original Message-----
>From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
>Sent: Saturday, October 26, 2013 1:56 AM
>To: Anindita Chattopadhyay
>Cc: r-help at r-project.org; Harish K
>Subject: Re: [R] Revo R for Arima Implementation
>
>
>Your question is pretty well totally opaque to me.  Describe the model
>you want to fit in mathematical terms, rather than referring to The
>Package That Must Not Be Named.  This is the ***R***  list.
>
>It is possible that you might want to make use of the "seasonal"
>argument to the
>arima() function.
>
>     cheers,
>
>     Rolf Turner
>
>On 10/26/13 01:19, Anindita Chattopadhyay wrote:
>> Hello There,
>>
>> We have used ARIMA(multiplicative MA and additive AR) model in SAS to
>come to our results. Please let me know how could that be implemented
>in R.
>>
>> Like,  In SAS we can pass the variable  as AR= (1,7) and MA=(1)(7)
>which is additive and multiplicative respectively.
>>
>> In R we have the option as : order = c(0, 0, 0) which is (p,d,q).Is
>there any specific way/code such that we specify the additive  AR and
>multiplicative MA simultaneously?
>>
>This email message may contain proprietary, private and confidential
>information. The information transmitted is intended only for the
>person(s) or entities to which it is addressed. Any review,
>retransmission, dissemination or other use of, or taking of any action
>in reliance upon, this information by persons or entities other than
>the intended recipient is prohibited and may be illegal. If you
>received this in error, please contact the sender and delete the
>message from your system. Mu Sigma takes all reasonable steps to ensure
>that its electronic communications are free from viruses. However,
>given Internet accessibility, the Company cannot accept liability for
>any virus introduced by this e-mail or any attachment and you are
>advised to use up-to-date virus checking software.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From hill0093 at umn.edu  Mon Oct 28 16:57:16 2013
From: hill0093 at umn.edu (hill0093 University of Minnesota)
Date: Mon, 28 Oct 2013 10:57:16 -0500
Subject: [R] Fwd: Undeliverable mail
In-Reply-To: <iss.839b3bf5.6c47.526e886d.ddec6.1@vs-m.tc.umn.edu>
References: <CA+ateGjQP96WNtwsLWovn1FsR+Xa82XfiOdogLt_daJ1YPqQNg@mail.gmail.com>
	<iss.839b3bf5.6c47.526e886d.ddec6.1@vs-m.tc.umn.edu>
Message-ID: <CA+ateGg8hRS28DWdcK30UTpgdw-LRCf99eyGdinBmh0NvEaXAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/dc2385f9/attachment.pl>

From f.harrell at Vanderbilt.Edu  Mon Oct 28 16:58:15 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Mon, 28 Oct 2013 10:58:15 -0500
Subject: [R] Code Book from SPSS Data
Message-ID: <526E8997.5020200@vanderbilt.edu>

Not certain about .por but this works with ordinary SPSS files:

require(Hmisc)
dat <- spss.get(...)  # gets variable labels, etc.
contents(dat)
html(contents(dat), ...)

The last command produces a hyperlinked data dictionary, e.g., for each 
variable the number of levels is given and you click on that number to 
see the levels.  Variables having the same levels are combined in the 
latter part.

Frank

-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University


From babakbsn at gmail.com  Mon Oct 28 17:01:26 2013
From: babakbsn at gmail.com (Baro)
Date: Mon, 28 Oct 2013 09:01:26 -0700
Subject: [R] Error: Data is not atomic
Message-ID: <CAF-JZQubgCJ=_EYftOBAXaKpuOP8NeDkpHKy4Xbf4Wvibdsr_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/68b6edf0/attachment.pl>

From jvadams at usgs.gov  Mon Oct 28 17:04:19 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 28 Oct 2013 11:04:19 -0500
Subject: [R] linear line in x, y plot
In-Reply-To: <CAG6S0OkJFeqf8+j6my3tMW3ZUN4O0mAucX87_bVGHDaakqTEqg@mail.gmail.com>
References: <CAG6S0OkJFeqf8+j6my3tMW3ZUN4O0mAucX87_bVGHDaakqTEqg@mail.gmail.com>
Message-ID: <CAN5YmCGrOoncoAYjmipe2L9waj+JwOeM8cpjLj1geh9LQtJbyA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/ed1d188a/attachment.pl>

From bhh at xs4all.nl  Mon Oct 28 17:10:14 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 28 Oct 2013 17:10:14 +0100
Subject: [R] Error: Data is not atomic
In-Reply-To: <CAF-JZQubgCJ=_EYftOBAXaKpuOP8NeDkpHKy4Xbf4Wvibdsr_A@mail.gmail.com>
References: <CAF-JZQubgCJ=_EYftOBAXaKpuOP8NeDkpHKy4Xbf4Wvibdsr_A@mail.gmail.com>
Message-ID: <2F600ACA-7BE1-4326-8446-E9F404C21C31@xs4all.nl>


On 28-10-2013, at 17:01, Baro <babakbsn at gmail.com> wrote:

> Hi experts,
> 
> I want to user haar wavelet transform. If I am using this simple command,
> it works nice:
> 
> k<-c(1,2,3,4,5,6,7,8)
> ywd<-wd(k,filter.number=1,family="DaubExPhase")
> 
> but if the K is a list like this:
> 
> *[[1]]*
> *[1] 401*
> *
> *
> *[[2]]*
> *[1] 481*
> *
> *
> *[[3]]*
> *[1] 480*
> *
> *
> *[[4]]*
> *[1] 482*
> *
> *
> *[[5]]*
> *[1] 395*
> *...*
> *
> *
> it doesnt work and I get this error:
> 
> Error in wd(k, filter.number = 1, family = "DaubExPhase") :
> * Data is not atomic*
> *
> *
> how can I solve this problem?how can I convert this list to a normal list?
> 

Please do not post in html as requested by the posting guide.
And don't post the same question twice within a short period of time.
Please do NOT put code or Routput in bold or whatever. Plain text only.
In plain text that is displayed as:

*[1] 395*

which is obviously nonsense.

Have a look at unlist().

Berend


> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Mon Oct 28 17:18:46 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 28 Oct 2013 17:18:46 +0100
Subject: [R] Error: Data is not atomic
In-Reply-To: <CAF-JZQu-BVx8SK_iWW2H86ey41z4b=_ZjoCaDXoxHrgzZRVG7Q@mail.gmail.com>
References: <CAF-JZQubgCJ=_EYftOBAXaKpuOP8NeDkpHKy4Xbf4Wvibdsr_A@mail.gmail.com>
	<2F600ACA-7BE1-4326-8446-E9F404C21C31@xs4all.nl>
	<CAF-JZQu-BVx8SK_iWW2H86ey41z4b=_ZjoCaDXoxHrgzZRVG7Q@mail.gmail.com>
Message-ID: <2370690A-6647-41FF-BA8E-7A205561332B@xs4all.nl>


On 28-10-2013, at 17:16, Baro <babakbsn at gmail.com> wrote:

> thank you so much. I will write my questions as you mentioned
> 
> 

Final advice. 
Please reply to the list only. Everybody can then see your reply and respond  if necessary.

Forwarded to the list.

Berend


From a.mosnier at gmail.com  Mon Oct 28 17:19:30 2013
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Mon, 28 Oct 2013 12:19:30 -0400
Subject: [R] speed of makeCluster (package parallel)
Message-ID: <CANkFkEetje4A6yBsiBY90ugtOvH0k-i8J9MLbikQg-y+uPerAQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/0eaf0c62/attachment.pl>

From Thorn.Thaler at rdls.nestle.com  Mon Oct 28 17:19:59 2013
From: Thorn.Thaler at rdls.nestle.com (Thaler,Thorn,LAUSANNE,Applied Mathematics)
Date: Mon, 28 Oct 2013 16:19:59 +0000
Subject: [R] Automatically Remove Aliased Terms from a Model
Message-ID: <EDB44DA865211646A192A94DF3C6FA670F72DC54@DEMDCE0057.nestle.com>

Dear all,

I am trying to implement a function which removes aliased terms from a model. The challenge I am facing is that with "alias" I get the aliased coefficients of the model, which I have to translate into the terms from the model formula. What I have tried so far:

------------------8<------------------
d <- expand.grid(a = 0:1, b=0:1)
d$c <- (d$a + d$b)  %% 2
d$y <- rnorm(4)
d <- within(d, {a <- factor(a); b <- factor(b); c <- factor(c)})
l <- lm(y ~ a * b + c, d)

removeAliased <- function(mod) {
  ## Retrieve all terms in the model
  X <- attr(mod$terms, "term.label")
  ## Get the aliased coefficients  
  rn <- rownames(alias(mod)$Complete)
  ## remove factor levels from coefficient names to retrieve the terms
  regex.base <- unique(unlist(lapply(mod$model[, sapply(mod$model, is.factor)], levels)))
  aliased <- gsub(paste(regex.base, "$", sep = "", collapse = "|"),  "", gsub(paste(regex.base, ":", sep = "", collapse = "|"), ":", rn))
  uF <- formula(paste(". ~ .", paste(aliased, collapse = "-"), sep = "-"))
  update(mod, uF)
}

removeAliased(l)
------------------>8------------------

This function works in principle, but this workaround with removing the factor levels is just, well, a workaround which could cause problems in some circumstances (when the name of a level matches the end of another variable, when I use a different contrast and R names the coefficients differently etc. - and I am not sure which other cases I am overlooking).

So my question is whether there are some more intelligent ways of doing what I want to achieve? Is there a function to translate a coefficient of a LM back to the term, something like:

termFromCoef("a1") ## a1
termFromCoef("a1:b1") ## a:b

With this I could simply translate the rownames from alias into the terms needed for the model update.

Thanks for your help.

Kind Regards,

Thorn Thaler 
NRC Lausanne
Applied Mathematics


From dwinsemius at comcast.net  Mon Oct 28 17:21:21 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 28 Oct 2013 09:21:21 -0700
Subject: [R] linear line in x, y plot
In-Reply-To: <CAG6S0OkJFeqf8+j6my3tMW3ZUN4O0mAucX87_bVGHDaakqTEqg@mail.gmail.com>
References: <CAG6S0OkJFeqf8+j6my3tMW3ZUN4O0mAucX87_bVGHDaakqTEqg@mail.gmail.com>
Message-ID: <8398D7BE-666E-41EF-BE4F-4EFBDBA69568@comcast.net>


On Oct 28, 2013, at 8:30 AM, Ahmed Attia wrote:

> Hi
>
> I have a question about drawing a linear line in x, y plot. I usually
> use the following code, but for this time the x values are to small
> (-0.08 to -0.02)

That is not the problem.

>
> I wrote the following code, but r does not draw the line. However, it
> does not give an error when it takes the code.
>
>
> reg1<- lm(CWSI~NWI, data=Ahmed)
>
> NWI <- seq(-0.08, -0.02, len = -0.02)

 >  seq(-0.08, -0.02, len = -0.02)
integer(0)

The length argument to seq doesn't make any sense. Please review:

?seq

--  
David
> lines(NWI, predict(reg1, list(NWI =
> NWI)),xlim=c(-0.08,-0.02),ylim=c(0,1),pch=1,col=1,lwd=2, lty=1)
>
> When I wrote the following code
>
> abline(reg1,pch=2,col=2,lwd=2,  
> lty=2,xlim=c(-0.06,-0.02),ylim=c(0.3,0.8))
>
> the line shows up, but I can not control the xlim or ylim. It bascally
> goes across the figure
>
> I appreciate your help
> -- 
> Ahmed M. Attia
>
>
> Research Assistant
> Dept. Of Soil&Crop Sciences
> Texas A&M University
> ahmed.attia at ag.tamu.edu
> Cell phone: 001-979-248-5215
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From szehnder at uni-bonn.de  Mon Oct 28 17:30:31 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Mon, 28 Oct 2013 17:30:31 +0100
Subject: [R] speed of makeCluster (package parallel)
In-Reply-To: <CANkFkEetje4A6yBsiBY90ugtOvH0k-i8J9MLbikQg-y+uPerAQ@mail.gmail.com>
References: <CANkFkEetje4A6yBsiBY90ugtOvH0k-i8J9MLbikQg-y+uPerAQ@mail.gmail.com>
Message-ID: <D51BD092-DA5D-449A-99FB-BC8D1FC4C2D6@uni-bonn.de>

See library(help = "parallel?)


On 28 Oct 2013, at 17:19, Arnaud Mosnier <a.mosnier at gmail.com> wrote:

> Hi all,
> 
> I am quite new in the world of parallelization and I wonder if there is a
> way to increase the speed of creation of a parallel socket cluster. The
> time spend to include threads increase exponentially with the number of
> thread considered and I use of computer with two 8 cores CPU and thus
> showing a total of 32 threads in windows 7.
> Currently, I use the default parameters (type = "PSOCK"), but is there any
> fine tuning parameters that I can use to take advantage of this system ?
> 
> Thanks in advance for your help !
> 
> Arnaud
> 
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Oct 28 17:42:26 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 28 Oct 2013 09:42:26 -0700
Subject: [R] pie graphs in log scale axis
In-Reply-To: <690A755A58FD3641B5EC4EEEA1D00AB12BF349B3@si-msedag04.US.SINET.SI.EDU>
References: <690A755A58FD3641B5EC4EEEA1D00AB12BF349B3@si-msedag04.US.SINET.SI.EDU>
Message-ID: <C3575B58-F442-4538-ACB6-732AE078EB78@comcast.net>


On Oct 28, 2013, at 6:40 AM, Ortiz, John wrote:

>
> Dear list users,
>
>
> I'm doing a plot integrating Grid output with Base Graphics output   
> (gridBase, Murrell 2012).
>
> My goal is to produce a xy plot where each point is represented by a  
> pie.  I could get it using the attach code,
> but now I want to change the X axis to log scale.
>
> when I introduce the log="x" parameter in the line:
>
> plot(x, y, xlim=c(0.1, 1.2), log="x", ylim=c(0.1, 1.2), type="n")
>
> I get this warning!
>
> vps <- baseViewports()
> Warning message:
> In baseViewports() : viewport scales NOT set to user coordinates
>
>
> This is the code to produce it without introduce log scale yet:
>
> library(grid)
> library(gridBase)
> x <- c(0.88, 1.00, 0.67, 0.34)
> y <- c(0.87, 0.43, 0.24, 0.94)
> z <- matrix(runif(4*2), ncol=2)
>
> oldpar <- par(no.readonly=TRUE)
>
> plot(x, y, xlim=c(0.1, 1.2), ylim=c(0.1, 1.2), type="n")
>
> vps <- baseViewports()
> pushViewport(vps$inner, vps$figure, vps$plot)
>
> for (i in 1:4) {
> pushViewport(viewport(x=unit(x[i], "native"),
> y=unit(y[i], "native"),
> width=0.1,
> height=0.1))
> par(plt=gridPLT(), new=TRUE)
> pie(z[i,], radius=1, labels=rep("", 2))
> popViewport()
> }
>
> popViewport(2)
> par(oldpar)
>
> Thanks by some advice!!

I haven't figured out the ratinale for this effort but this does  
result in a base log="xy" plot with pies

  library(grid)
library(gridBase)
x <- c(0.88, 1.00, 0.67, 0.34)
y <- c(0.87, 0.43, 0.24, 0.94)
z <- matrix(runif(4*2), ncol=2)

oldpar <- par(no.readonly=TRUE)

plot(x, y, xlim=c(0.01, 1.2), ylim=c(0.01, 1.2), type="n", log="xy")

# Note need to modify limits

vps <- baseViewports()
pushViewport(vps$inner, vps$figure, vps$plot)

for (i in 1:4) {
pushViewport(viewport(x=unit(log(x[i]), "native"),
# this seemed the sensible strategy
y=unit(log(y[i]), "native"),
# Didn't think log(units(...)) would be as successful
width=0.1,
height=0.1))
par(plt=gridPLT(), new=TRUE)
pie(z[i,], radius=1, labels=rep("", 2))
popViewport()
}

popViewport(2)
par(oldpar)

>
> Regards,
>
>
> John Ortiz
>
> Geologist
> Smithsonian Tropical Research Institute Panama
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From a.mosnier at gmail.com  Mon Oct 28 17:51:23 2013
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Mon, 28 Oct 2013 12:51:23 -0400
Subject: [R] speed of makeCluster (package parallel)
In-Reply-To: <D51BD092-DA5D-449A-99FB-BC8D1FC4C2D6@uni-bonn.de>
References: <CANkFkEetje4A6yBsiBY90ugtOvH0k-i8J9MLbikQg-y+uPerAQ@mail.gmail.com>
	<D51BD092-DA5D-449A-99FB-BC8D1FC4C2D6@uni-bonn.de>
Message-ID: <CANkFkEfdHTSMRmGZNmEz3QO2wvH2G7yf7x-20U417cGf7DM3hw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/0931bef5/attachment.pl>

From szehnder at uni-bonn.de  Mon Oct 28 18:41:32 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Mon, 28 Oct 2013 18:41:32 +0100
Subject: [R] speed of makeCluster (package parallel)
In-Reply-To: <CANkFkEfdHTSMRmGZNmEz3QO2wvH2G7yf7x-20U417cGf7DM3hw@mail.gmail.com>
References: <CANkFkEetje4A6yBsiBY90ugtOvH0k-i8J9MLbikQg-y+uPerAQ@mail.gmail.com>
	<D51BD092-DA5D-449A-99FB-BC8D1FC4C2D6@uni-bonn.de>
	<CANkFkEfdHTSMRmGZNmEz3QO2wvH2G7yf7x-20U417cGf7DM3hw@mail.gmail.com>
Message-ID: <A1D578C1-AAA9-46CF-831B-475408201DBA@uni-bonn.de>

First,

use only the number of cores as a number of thread - i.e. I would not use hyper threading, etc.. Each core has its own caches and it is always fortunate if a process has enough memory; hyper threads use all the same cache on the core they are running on. detectCores() gives me for example 4 - I know I have 2. I would therefore call makeCluster() with nnode = 2. mcaffinity() lets you perform a technique called process-pinning (see process affinity) and is only possible if the OS supports it. It makes sometimes sense to assign certain processes to certain CPUs such that each process has enough memory in caches (e.g. for a 16 Core machine using 8 processes on CPUs 1, 3, 5, 7, 9, 11, 13 and 15; so each process has the cache of two CPUs). 
A lot of functions though are not available for Windows. 

At first it comes always the problem you want to solve and then you look how much memory will be used in a process and how much you have (more often the memory bandwidth is the bottleneck and not the computing power). Look at the architecture of your chips (how much L1 Cache, how much L2 cache). Then you decide how many cores to use and if it makes sense to pin processes to certain cores. 

There are no general recipes for parallel computing - each problem is different. Some problems are even not scalable. 

Simon


On 28 Oct 2013, at 17:51, Arnaud Mosnier <a.mosnier at gmail.com> wrote:

> Thanks Simon,
> 
> I already read the parallel vignette but I did not found what I wanted.
> May be you can be more specific on a part of the document that can provide me hints !
> 
> Arnaud
> 
> 
> 2013/10/28 Simon Zehnder <szehnder at uni-bonn.de>
> See library(help = "parallel?)
> 
> 
> On 28 Oct 2013, at 17:19, Arnaud Mosnier <a.mosnier at gmail.com> wrote:
> 
> > Hi all,
> >
> > I am quite new in the world of parallelization and I wonder if there is a
> > way to increase the speed of creation of a parallel socket cluster. The
> > time spend to include threads increase exponentially with the number of
> > thread considered and I use of computer with two 8 cores CPU and thus
> > showing a total of 32 threads in windows 7.
> > Currently, I use the default parameters (type = "PSOCK"), but is there any
> > fine tuning parameters that I can use to take advantage of this system ?
> >
> > Thanks in advance for your help !
> >
> > Arnaud
> >
> > R version 3.0.1 (2013-05-16)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 


From ripley at stats.ox.ac.uk  Mon Oct 28 18:59:10 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 28 Oct 2013 17:59:10 +0000
Subject: [R] speed of makeCluster (package parallel)
In-Reply-To: <CANkFkEetje4A6yBsiBY90ugtOvH0k-i8J9MLbikQg-y+uPerAQ@mail.gmail.com>
References: <CANkFkEetje4A6yBsiBY90ugtOvH0k-i8J9MLbikQg-y+uPerAQ@mail.gmail.com>
Message-ID: <526EA5EE.9060109@stats.ox.ac.uk>

On 28/10/2013 16:19, Arnaud Mosnier wrote:
> Hi all,
>
> I am quite new in the world of parallelization and I wonder if there is a
> way to increase the speed of creation of a parallel socket cluster. The
> time spend to include threads increase exponentially with the number of

It increases linearly in my tests (or a decent OS).  But really if 
parallel computing is worthwhile you will be doing minutes of work on 
each worker process and the startup time will not be signifcant.

> thread considered and I use of computer with two 8 cores CPU and thus
> showing a total of 32 threads in windows 7.

The first way to speed things up: use a decent OS:  forking clusters is 
much faster.

> Currently, I use the default parameters (type = "PSOCK"), but is there any
> fine tuning parameters that I can use to take advantage of this system ?
>
> Thanks in advance for your help !
>
> Arnaud
>
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> 	[[alternative HTML version deleted]]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From smartpink111 at yahoo.com  Mon Oct 28 19:16:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 28 Oct 2013 11:16:10 -0700 (PDT)
Subject: [R] for loop help, repeat a function multiple times
Message-ID: <1382984170.62028.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
You may try:
x <- 1:5 
?set.seed(49)
?mat1 <- do.call(rbind,lapply(1:1000,function(y) sample(x,3)))

#or
mat2 <- matrix(0,ncol=3,nrow=1000)
set.seed(49)
?for(i in seq_len(nrow(mat2))) mat2[i,] <- sample(x,3)
all.equal(mat1,mat2)
#[1] TRUE

#or
set.seed(49)

mat3 <- t(replicate(1000,sample(x,3)))
?all.equal(mat2,mat3)
#[1] TRUE



A.K.





Hi, I have written a program that runs a series of calculations using 
random numbers, so that each time that I run the program I get a vector 
with different results. I need to repeat this program multiple times and combine all of the vectors into a single data frame or matrix. I am 
fairly certain that a "for loop" is what I need, but after digging 
around online and in multiple books, I am very confused about how to set up the loop. Just as an example, suppose that I want to randomly select 3 numbers from 1 to 5. I could do it using the following two lines: 
x <- 1:5 
y <- sample(x,3) 

now suppose that I want to do this 1000 times, how do I set up a
 loop that will give me 1000 iterations of y (i.e. it will select 1000 
sets of 3 values ranging from 1:5)? In other words, how do I loop y a 
specified number of times? 
Thanks for the help


From bogaso.christofer at gmail.com  Mon Oct 28 19:40:52 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Tue, 29 Oct 2013 00:25:52 +0545
Subject: [R] Split a data.frame
In-Reply-To: <1382892532.1721.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CA+dpOJ=P2FxQEQGY=974XRUmtmkkYm4gmUcqAXL17BX3i=ruTA@mail.gmail.com>
	<1382892532.1721.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CA+dpOJkDnCoftakQvHXA2FFcq2_2CVdT_zEPd-0y5k9m1jUKGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/9587bdc0/attachment.pl>

From alaios at yahoo.com  Mon Oct 28 19:42:01 2013
From: alaios at yahoo.com (Alaios)
Date: Mon, 28 Oct 2013 11:42:01 -0700 (PDT)
Subject: [R] Create Time Lists with a for loop
Message-ID: <1382985721.84267.YahooMailNeo@web125302.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/701d83a5/attachment.pl>

From TIN-CHI.LIN at libertymutual.com  Mon Oct 28 17:45:48 2013
From: TIN-CHI.LIN at libertymutual.com (Lin, Tin-Chi)
Date: Mon, 28 Oct 2013 16:45:48 +0000
Subject: [R] high cross-validation errors ( xerror ) in regression tree?
Message-ID: <077630AE1E6DC448B64A2907B676BD2C5AC89A18@LM-HSEXMSG-P12P.lm.lmig.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/0855856e/attachment.pl>

From minusone at alumni.princeton.edu  Mon Oct 28 18:13:02 2013
From: minusone at alumni.princeton.edu (Rob Bernard)
Date: Mon, 28 Oct 2013 13:13:02 -0400
Subject: [R] Chess Playing Software Written in R
Message-ID: <CAGRj5Sai_KRJ91VTZWG9Aesvv9-yCP94++FArWHp2Zd9ZM3t1w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/2d28714a/attachment.pl>

From b00295766 at essec.edu  Mon Oct 28 18:00:35 2013
From: b00295766 at essec.edu (Shantanu MULLICK)
Date: Mon, 28 Oct 2013 18:00:35 +0100
Subject: [R] Optimize function in R: unable to find maximum of logistic
	function
Message-ID: <CAMWfkYCn0W2QwJ-FcE+NDs3=EeO5NvOexXhSCbfeWs+FC_BnTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/f3bfa476/attachment.pl>

From jdenton at amnh.org  Mon Oct 28 18:39:09 2013
From: jdenton at amnh.org (John Denton)
Date: Mon, 28 Oct 2013 17:39:09 +0000
Subject: [R] make system() output invisible on mac
Message-ID: <9DB18CB85B13594BA44ADD67DC99C602F01D5F01@MAIL-MBX-004.internal.amnh.org>

Hi,

I'm trying to figure out a way to make the output of a call to system() invisible on the R mac GUI. Is there a mac equivalent for the calls invisible=TRUE, show.output.on.console=FALSE, intern=TRUE for the mac environment? Thanks.

~John

From lminer at hotmail.com  Mon Oct 28 20:14:27 2013
From: lminer at hotmail.com (Luke Miner)
Date: Mon, 28 Oct 2013 19:14:27 +0000
Subject: [R] gmmBoost creating huge 500+ gb vectors
Message-ID: <DUB119-W31FE684C92CEF31CB3CF99DE080@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/e9573077/attachment.pl>

From a.mosnier at gmail.com  Mon Oct 28 20:33:48 2013
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Mon, 28 Oct 2013 15:33:48 -0400
Subject: [R] speed of makeCluster (package parallel)
In-Reply-To: <A1D578C1-AAA9-46CF-831B-475408201DBA@uni-bonn.de>
References: <CANkFkEetje4A6yBsiBY90ugtOvH0k-i8J9MLbikQg-y+uPerAQ@mail.gmail.com>
	<D51BD092-DA5D-449A-99FB-BC8D1FC4C2D6@uni-bonn.de>
	<CANkFkEfdHTSMRmGZNmEz3QO2wvH2G7yf7x-20U417cGf7DM3hw@mail.gmail.com>
	<A1D578C1-AAA9-46CF-831B-475408201DBA@uni-bonn.de>
Message-ID: <CANkFkEdMjTT5EEE_XxBX=41hjOm=wKCAdn3sym8jPg4h=pn4=A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/178d75db/attachment.pl>

From jim at bitwrit.com.au  Mon Oct 28 20:57:49 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 29 Oct 2013 06:57:49 +1100
Subject: [R] indicating significant differences in boxplots
In-Reply-To: <CABsGe_yTp=uqZZfKBpQQH2aAhnfgp7OazHi3pw1Bo-L59CuTHA@mail.gmail.com>
References: <CABsGe_yTp=uqZZfKBpQQH2aAhnfgp7OazHi3pw1Bo-L59CuTHA@mail.gmail.com>
Message-ID: <526EC1BD.5020807@bitwrit.com.au>

On 10/29/2013 01:51 AM, Johannes Radinger wrote:
> Hi,
>
> I'd like to follow up an older discussion on adding significance stars to
> boxplots.
> (
> http://r.789695.n4.nabble.com/indicating-significant-differences-in-boxplots-td862335.html
> )
> As suggested by Jim Lemon, there is following solution for a single boxplot:
>
> boxplot(count ~ spray, data = InsectSprays, col = "lightgray")
>
> #and we'll assume that the second and third boxplots require a star:
> par(xpd=TRUE)
> yrange<-par("usr")[3:4]
> ypos<-yrange[2]+diff(yrange)/40
> segments(2,ypos,3,ypos)
> text(2.5,ypos+diff(yrange)/40,"*",cex=2)
> par(xpd=FALSE)
>
> But what if one wants to plot two boxplots (e.g. with each only two groups
> which are significantly different) and
> add such stars to each of the boxplots. I usually use par(mfrow(1,2)) to
> plot all boxplots in a row.
> How can I also add segments and stars on top of each plot?
>
Hi johannes,
The general strategy above can be applied. Fortunately, boxplots are 
centered on successive integers (i.e. 1,2,...) by default. The 
calculations for ypos yield 1/40th of the vertical span of the plot 
above the top of the plot. Just add the segments and stars after each 
plot, as each boxplot advances to the next frame in your plot matrix.

Jim


From jim at bitwrit.com.au  Mon Oct 28 21:00:27 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 29 Oct 2013 07:00:27 +1100
Subject: [R] linear line in x, y plot
In-Reply-To: <CAG6S0OkJFeqf8+j6my3tMW3ZUN4O0mAucX87_bVGHDaakqTEqg@mail.gmail.com>
References: <CAG6S0OkJFeqf8+j6my3tMW3ZUN4O0mAucX87_bVGHDaakqTEqg@mail.gmail.com>
Message-ID: <526EC25B.20102@bitwrit.com.au>

On 10/29/2013 02:30 AM, Ahmed Attia wrote:
> Hi
>
> I have a question about drawing a linear line in x, y plot. I usually
> use the following code, but for this time the x values are to small
> (-0.08 to -0.02)
>
> I wrote the following code, but r does not draw the line. However, it
> does not give an error when it takes the code.
>
>
> reg1<- lm(CWSI~NWI, data=Ahmed)
>
> NWI<- seq(-0.08, -0.02, len = -0.02)
> lines(NWI, predict(reg1, list(NWI =
> NWI)),xlim=c(-0.08,-0.02),ylim=c(0,1),pch=1,col=1,lwd=2, lty=1)
>
> When I wrote the following code
>
> abline(reg1,pch=2,col=2,lwd=2, lty=2,xlim=c(-0.06,-0.02),ylim=c(0.3,0.8))
>
> the line shows up, but I can not control the xlim or ylim. It bascally
> goes across the figure
>
Hi Ahmed,
Have a look at ablineclip in the plotrix package.

Jim


From collinl at cs.pitt.edu  Mon Oct 28 21:09:42 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Mon, 28 Oct 2013 16:09:42 -0400 (EDT)
Subject: [R] fitdistr: was Heteroscedasity...
In-Reply-To: <CAKmh6oEEQArfcTCamO2Gkbn2YFAbuGwEY7C0y3jiuc4i4hMB3g@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.1310281559180.12430-100000@neodymium.cs.pitt.edu>

Hello again, first off thank you for your suggestion Mr. Rigby, I'll take
a look at the GAMLSS package.

I have a (slightly) related followup question regarding the 'fitdistr'
function.  I was examining my data, a sample of which is attached, using
this function and I am confused about the interpretation of the loglik
result.

Based upon my experience I understand log-likelyhood value returned from
this function should be in the range -Inf - 0 with values closer to 0
being the best choice.  However when I test this data I get the following
results:

fitdistr(E, "normal")$loglik
[1] 11.15125

fitdistr(E + 1, "lognormal")$loglik
[1] -0.8575117

fitdistr(E, "exponential")$loglik
[1] -73.18107

Is this a sign of error, in my system or on my part?  And if not am I
correct in interpreting lognormal as the best choice?

	Thank you in advance,
	Collin Lynch.


From jdnewmil at dcn.davis.CA.us  Mon Oct 28 21:26:49 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 28 Oct 2013 13:26:49 -0700
Subject: [R] Chess Playing Software Written in R
In-Reply-To: <CAGRj5Sai_KRJ91VTZWG9Aesvv9-yCP94++FArWHp2Zd9ZM3t1w@mail.gmail.com>
References: <CAGRj5Sai_KRJ91VTZWG9Aesvv9-yCP94++FArWHp2Zd9ZM3t1w@mail.gmail.com>
Message-ID: <db485702-81f2-47b8-a4ed-1a27f82f0395@email.android.com>

Please avail yourself of search tools before posting here, and reference why they did not answer your question.

RSiteSearch( "chess" )

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Rob Bernard <minusone at alumni.princeton.edu> wrote:
>Have there been attempts to build a chess engine in R?  If so, is it
>available anywhere?
>
>I recognize that R really isn?t the right language for a chess engine,
>but
>I was more curious if it had been attempted.
>
>Thank you.
>
>Rob Bernard


From ruipbarradas at sapo.pt  Mon Oct 28 21:47:55 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 28 Oct 2013 20:47:55 +0000
Subject: [R] Create Time Lists with a for loop
In-Reply-To: <1382985721.84267.YahooMailNeo@web125302.mail.ne1.yahoo.com>
References: <1382985721.84267.YahooMailNeo@web125302.mail.ne1.yahoo.com>
Message-ID: <526ECD7B.1010801@sapo.pt>

Hello,

Instead of string manipulation you should think of POSIXt objects. And 
maybe ?seq.POSIXt will help.


first <- strptime("2011-10-12 10:59:00","%Y-%m-%d %H:%M:%S")
last <- strptime("2011-10-12 11:13:00","%Y-%m-%d %H:%M:%S")

seq(first, last, by = "5 min")


Hope this helps,

Rui Barradas

Em 28-10-2013 18:42, Alaios escreveu:
> Dear all,
> in my code I have written the following list
>
> TimeFramesShort <-list(c(strptime("2011-10-12 10:59:00","%Y-%m-%d %H:%M:%S"),strptime("2011-10-13 11:02:00","%Y-%m-%d %H:%M:%S"))              # rest items were truncated
>
>
> I was wondering if could somehow  take the first element of the list and create element that are only 5 minutes apart something like
> list(c(strptime("2011-10-12 10:59:00","%Y-%m-%d %H:%M:%S"),strptime("2011-10-12 11:04:00","%Y-%m-%d %H:%M:%S"),
> c(strptime("2011-10-12 11:04:00","%Y-%m-%d %H:%M:%S"),strptime("2011-10-12 11:09:00","%Y-%m-%d %H:%M:%S"),
> c(strptime("2011-10-12 11:09:00","%Y-%m-%d %H:%M:%S"),strptime("2011-10-12 11:13:00","%Y-%m-%d %H:%M:%S")
> ...
> and so on.
>
> The problem I see is that pure string manipulation will not work as after one hour that should also make changes in the hours.
>
> Regards
> Alex
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Mon Oct 28 21:49:29 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 28 Oct 2013 20:49:29 +0000
Subject: [R] Optimize function in R: unable to find maximum of logistic
 function
In-Reply-To: <CAMWfkYCn0W2QwJ-FcE+NDs3=EeO5NvOexXhSCbfeWs+FC_BnTA@mail.gmail.com>
References: <CAMWfkYCn0W2QwJ-FcE+NDs3=EeO5NvOexXhSCbfeWs+FC_BnTA@mail.gmail.com>
Message-ID: <526ECDD9.6070208@sapo.pt>

Hello,

This seems like a bug, removing 'maximum = TRUE' has no effect except 
that the returned value says it's a minimum, not a maximum.

Rui Barradas

Em 28-10-2013 17:00, Shantanu MULLICK escreveu:
> Hello Everyone,
>
> I want to perform a 1-D optimization by using the optimize() function. I
> want to find the maximum value of a "logistic" function. The optimize()
> function gives the wrong result.
>
> My code:
> f= function (k) {
> T_s = 20
> result = (2- 2/(1+ exp(-2*T_s*k)))
> return(result)
> }
> optimize(f, c(0, 5), tol = 0.0000000000001, maximum= TRUE)
>
> The maximum value for the function happens at k=0, and the maximum value is
> 1. Yet  the optimise function, says that the maximum value happens at k=
> 4.9995, and the maximum value is 0.
>
> Thanks in advance!
>
> Warm Regards,
> Shantanu
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r.turner at auckland.ac.nz  Mon Oct 28 22:01:16 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 29 Oct 2013 10:01:16 +1300
Subject: [R] Optimize function in R: unable to find maximum of logistic
 function
In-Reply-To: <CAMWfkYCn0W2QwJ-FcE+NDs3=EeO5NvOexXhSCbfeWs+FC_BnTA@mail.gmail.com>
References: <CAMWfkYCn0W2QwJ-FcE+NDs3=EeO5NvOexXhSCbfeWs+FC_BnTA@mail.gmail.com>
Message-ID: <526ED09C.7060900@auckland.ac.nz>


This could be described as a bug, perhaps.  Or it could be described as
an indication that numerical optimization is inevitably tricky. Notice that
if you narrow down your search interval from [0,5] to [0,0.5] you get the
right answer:

 > optimize(f, c(0, 0.5), maximum= TRUE,tol=1e-10)
$maximum
[1] 4.192436e-11

$objective
[1] 1

I guess there's a problem with finding a gradient that is effectively
(numerically) zero when "k" is equal to 5.


     cheers,

     Rolf Turner


On 10/29/13 06:00, Shantanu MULLICK wrote:
> Hello Everyone,
>
> I want to perform a 1-D optimization by using the optimize() function. I
> want to find the maximum value of a "logistic" function. The optimize()
> function gives the wrong result.
>
> My code:
> f= function (k) {
> T_s = 20
> result = (2- 2/(1+ exp(-2*T_s*k)))
> return(result)
> }
> optimize(f, c(0, 5), tol = 0.0000000000001, maximum= TRUE)
>
> The maximum value for the function happens at k=0, and the maximum value is
> 1. Yet  the optimise function, says that the maximum value happens at k=
> 4.9995, and the maximum value is 0.
>


From r.turner at auckland.ac.nz  Mon Oct 28 22:07:29 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 29 Oct 2013 10:07:29 +1300
Subject: [R] Revo R for Arima Implementation
In-Reply-To: <fb7ea8f3506e4058b25a8f0fe693b909@HKNPR04MB083.apcprd04.prod.outlook.com>
References: <d7923fdac82a40a28fbfc92ae373318a@HKNPR04MB083.apcprd04.prod.outlook.com>
	<526AD3C5.6070207@auckland.ac.nz>
	<fb7ea8f3506e4058b25a8f0fe693b909@HKNPR04MB083.apcprd04.prod.outlook.com>
Message-ID: <526ED211.70108@auckland.ac.nz>


Your question still makes no sense at all to me.  You provide no example 
code
and no data.  You do not specify, in any comprehensible way, what model you
are trying to fit.

And as Jeff Newmiller said, if you are concerned with "Revo R" why are 
you posting
to "r-help"?

Please get your act together or stop cluttering up the r-help list.

     cheers,

     Rolf Turner

On 10/29/13 02:26, Anindita Chattopadhyay wrote:
> Hi Rolf,
>
> Thanks for the response. I have re-phrased the problem. Hope this will help.
>
> We're working on a project where our model tries to predict the value of bookings as a time series of past bookings as well as some external flags.
> The data was found to be stationary using the Dicky-Fuller test.
> We have only a non-seasonal component for the AR and MA terms (small p & q only).
> No differencing was done.
>
> Then, we used values of p = 1, 7, 8 and q = 1, 7.
> The main issue is that the p values are additive and q values are multiplicative.
> We need to understand how we can implement this in Revo R.
>
> Just to add, since we have external flags , we cannot make use of SARIMA function.
> Please let me know if any other questions.
>
> Thank you in advance!
>
> Regards,
> Anindita Chattopadhyay | +919886800606 | www.mu-sigma.com |
>
> -----Original Message-----
> From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
> Sent: Saturday, October 26, 2013 1:56 AM
> To: Anindita Chattopadhyay
> Cc: r-help at r-project.org; Harish K
> Subject: Re: [R] Revo R for Arima Implementation
>
>
> Your question is pretty well totally opaque to me.  Describe the model you want to fit in mathematical terms, rather than referring to The Package That Must Not Be Named.  This is the ***R***  list.
>
> It is possible that you might want to make use of the "seasonal"
> argument to the
> arima() function.
>
>       cheers,
>
>       Rolf Turner
>
> On 10/26/13 01:19, Anindita Chattopadhyay wrote:
>> Hello There,
>>
>> We have used ARIMA(multiplicative MA and additive AR) model in SAS to come to our results. Please let me know how could that be implemented in R.
>>
>> Like,  In SAS we can pass the variable  as AR= (1,7) and MA=(1)(7) which is additive and multiplicative respectively.
>>
>> In R we have the option as : order = c(0, 0, 0) which is (p,d,q).Is there any specific way/code such that we specify the additive  AR and multiplicative MA simultaneously?


From wdunlap at tibco.com  Mon Oct 28 23:02:52 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 28 Oct 2013 22:02:52 +0000
Subject: [R] Optimize function in R: unable to find maximum of logistic
 function
In-Reply-To: <526ED09C.7060900@auckland.ac.nz>
References: <CAMWfkYCn0W2QwJ-FcE+NDs3=EeO5NvOexXhSCbfeWs+FC_BnTA@mail.gmail.com>
	<526ED09C.7060900@auckland.ac.nz>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1100A@PA-MBX01.na.tibco.com>

Note that f(x) returns exactly zero for all x above 1, hence its estimated
derivative is 0 everywhere in that region.   You are asking optimize to find
the non-zero part of a function which is 0 in more than 80% of its domain.

You can put a trace on f() to see where optimize() looks:
   > trace(f, quote(cat("k=", deparse(k), "\n")), print=FALSE)
  [1] "f"
  > optimize(f, c(0, 5), tol = 1e-14, maximum= TRUE)
  k= 1.90983005625053 
  k= 3.09016994374947 
  k= 3.81966011250105 
  k= 4.27050983124842 
  k= 4.54915028125263 
  k= 4.72135954999579 
  k= 4.82779073125683 
  k= 4.89356881873896
  ... eventually homing in on 5 ...
It looks in a few places, but f() is 0 in all of them so it figures that
is the mininum and the maximum value it ever takes.  I suppose
you could ask that optimize look in more places for a place with
a non-zero derivative but it would be very expensive to look in all
(c. 2^50) places.

You probably should have it maximize the log of your objective
function, which gives you more range to play with, and you will
have to do some numerical analysis to minimize underflow and
roundoff error.  E.g., one could use
    f1 <- function (k)  {
        # log(f(k))
        T_s <- 20
        log(2) - 2 * T_s * k - log1p(exp(-2 * T_s * k))
   }
where log1p(x) calculates log(1+x) more accurately than a computer's
'log' and '+' can.  (Remember that 1+10^-17 exactly equals 1 here.)

One can do better yet by using the logspace_add(logx, logy) function
available in the C API to R, but there is currently not an R-language interface
to that (or logspace_subtract(logx,logy)).  They calculate log(exp(logx) +- exp(logy))
with minimal roundoff error.

You could probably also use the built-in plogis() function, with its log=TRUE and
perhaps lower.tail=FALSE arguments.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Rolf Turner
> Sent: Monday, October 28, 2013 2:01 PM
> To: Shantanu MULLICK
> Cc: r-help at r-project.org
> Subject: Re: [R] Optimize function in R: unable to find maximum of logistic function
> 
> 
> This could be described as a bug, perhaps.  Or it could be described as
> an indication that numerical optimization is inevitably tricky. Notice that
> if you narrow down your search interval from [0,5] to [0,0.5] you get the
> right answer:
> 
>  > optimize(f, c(0, 0.5), maximum= TRUE,tol=1e-10)
> $maximum
> [1] 4.192436e-11
> 
> $objective
> [1] 1
> 
> I guess there's a problem with finding a gradient that is effectively
> (numerically) zero when "k" is equal to 5.
> 
> 
>      cheers,
> 
>      Rolf Turner
> 
> 
> On 10/29/13 06:00, Shantanu MULLICK wrote:
> > Hello Everyone,
> >
> > I want to perform a 1-D optimization by using the optimize() function. I
> > want to find the maximum value of a "logistic" function. The optimize()
> > function gives the wrong result.
> >
> > My code:
> > f= function (k) {
> > T_s = 20
> > result = (2- 2/(1+ exp(-2*T_s*k)))
> > return(result)
> > }
> > optimize(f, c(0, 5), tol = 0.0000000000001, maximum= TRUE)
> >
> > The maximum value for the function happens at k=0, and the maximum value is
> > 1. Yet  the optimise function, says that the maximum value happens at k=
> > 4.9995, and the maximum value is 0.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jwd at surewest.net  Mon Oct 28 23:03:36 2013
From: jwd at surewest.net (jwd)
Date: Mon, 28 Oct 2013 15:03:36 -0700
Subject: [R] pie graphs in log scale axis
In-Reply-To: <690A755A58FD3641B5EC4EEEA1D00AB12BF349B3@si-msedag04.US.SINET.SI.EDU>
References: <690A755A58FD3641B5EC4EEEA1D00AB12BF349B3@si-msedag04.US.SINET.SI.EDU>
Message-ID: <20131028150336.34428056@draco.site>

On Mon, 28 Oct 2013 13:40:51 +0000
"Ortiz, John" <OrtizJ at si.edu> wrote:

> 
> Dear list users,
> 
> 
> I'm doing a plot integrating Grid output with Base Graphics output
> (gridBase, Murrell 2012).
> 
> My goal is to produce a xy plot where each point is represented by a
> pie.  I could get it using the attach code, but now I want to change
> the X axis to log scale.
> 
> when I introduce the log="x" parameter in the line:
> 
> plot(x, y, xlim=c(0.1, 1.2), log="x", ylim=c(0.1, 1.2), type="n")
> 
> I get this warning!
> 
> vps <- baseViewports()
> Warning message:
> In baseViewports() : viewport scales NOT set to user coordinates
> 
It is not clear what you want.  Why is there an 'x = "log"' term in
plot()?  If you want to plot log(x) try using:

plot(log(x), y, xlim=c(0.1, 1.2), ylim=c(0.1, 1.2), type="n")

That generates an x/y plot with pies at various points.


From jwd at surewest.net  Tue Oct 29 01:43:32 2013
From: jwd at surewest.net (jwd)
Date: Mon, 28 Oct 2013 17:43:32 -0700
Subject: [R] pie graphs in log scale axis
In-Reply-To: <20131028150336.34428056@draco.site>
References: <690A755A58FD3641B5EC4EEEA1D00AB12BF349B3@si-msedag04.US.SINET.SI.EDU>
	<20131028150336.34428056@draco.site>
Message-ID: <20131028174332.2adfd121@draco.site>

On Mon, 28 Oct 2013 15:03:36 -0700
jwd <jwd at surewest.net> wrote:

> On Mon, 28 Oct 2013 13:40:51 +0000
> "Ortiz, John" <OrtizJ at si.edu> wrote:
...
> > 
> It is not clear what you want.  Why is there an 'x = "log"' term in
> plot()?  If you want to plot log(x) try using:

Got that backward typing, should be log = "x"


From wdunlap at tibco.com  Tue Oct 29 03:25:07 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 29 Oct 2013 02:25:07 +0000
Subject: [R] Optimize function in R: unable to find maximum of logistic
 function
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1100A@PA-MBX01.na.tibco.com>
References: <CAMWfkYCn0W2QwJ-FcE+NDs3=EeO5NvOexXhSCbfeWs+FC_BnTA@mail.gmail.com>
	<526ED09C.7060900@auckland.ac.nz>
	<E66794E69CFDE04D9A70842786030B933FA1100A@PA-MBX01.na.tibco.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1105E@PA-MBX01.na.tibco.com>

> One can do better yet by using the logspace_add(logx, logy) function
> available in the C API to R, but there is currently not an R-language interface
> to that (or logspace_subtract(logx,logy)).  They calculate log(exp(logx) +- exp(logy))
> with minimal roundoff error.
> 
> You could probably also use the built-in plogis() function, with its log=TRUE and
> perhaps lower.tail=FALSE arguments.

Here are functions, "f2" and "f3", which compute log(f()), via the above algorithms,
along with your original "f" and my first suggestion "f1".  f2 and f3 give almost
identical results over a wide range of inputs (pos. and neg.).  f1 agrees with them
for positive inputs but falls apart for larger negative inputs.  Any of f1, f2, or f3 will
do your optimization, although I don't know why you want to optimize a monotonic
function.

f <-
function (k, T_s = 20) {
    2 - 2/(1 + exp(-2*T_s*k))
}
f1 <-
function(k, T_s = 20) {
    # log(f(k))
    log(2) - 2*T_s*k - log1p(exp(-2*T_s*k))
}
f2 <-
function(k, T_s = 20) {
    # log(f(k))
    log(2) - logspace_add(2*T_s*k, 0)
}
logspace_add <-
function(logx, logy)
{
    # log(exp(logx) + exp(logy))
    mn <- pmin(logx, logy)
    mx <- pmax(logx, logy)
    mx + log1p(exp(mn - mx))
}
f3 <-
function(k, T_s = 20) {
    # log(f(k))
    log(2) + plogis(k, lower.tail=FALSE, log=TRUE, scale=1/(T_s*2))
}

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of William Dunlap
> Sent: Monday, October 28, 2013 3:03 PM
> To: Rolf Turner; Shantanu MULLICK
> Cc: r-help at r-project.org
> Subject: Re: [R] Optimize function in R: unable to find maximum of logistic function
> 
> Note that f(x) returns exactly zero for all x above 1, hence its estimated
> derivative is 0 everywhere in that region.   You are asking optimize to find
> the non-zero part of a function which is 0 in more than 80% of its domain.
> 
> You can put a trace on f() to see where optimize() looks:
>    > trace(f, quote(cat("k=", deparse(k), "\n")), print=FALSE)
>   [1] "f"
>   > optimize(f, c(0, 5), tol = 1e-14, maximum= TRUE)
>   k= 1.90983005625053
>   k= 3.09016994374947
>   k= 3.81966011250105
>   k= 4.27050983124842
>   k= 4.54915028125263
>   k= 4.72135954999579
>   k= 4.82779073125683
>   k= 4.89356881873896
>   ... eventually homing in on 5 ...
> It looks in a few places, but f() is 0 in all of them so it figures that
> is the mininum and the maximum value it ever takes.  I suppose
> you could ask that optimize look in more places for a place with
> a non-zero derivative but it would be very expensive to look in all
> (c. 2^50) places.
> 
> You probably should have it maximize the log of your objective
> function, which gives you more range to play with, and you will
> have to do some numerical analysis to minimize underflow and
> roundoff error.  E.g., one could use
>     f1 <- function (k)  {
>         # log(f(k))
>         T_s <- 20
>         log(2) - 2 * T_s * k - log1p(exp(-2 * T_s * k))
>    }
> where log1p(x) calculates log(1+x) more accurately than a computer's
> 'log' and '+' can.  (Remember that 1+10^-17 exactly equals 1 here.)
> 
> One can do better yet by using the logspace_add(logx, logy) function
> available in the C API to R, but there is currently not an R-language interface
> to that (or logspace_subtract(logx,logy)).  They calculate log(exp(logx) +- exp(logy))
> with minimal roundoff error.
> 
> You could probably also use the built-in plogis() function, with its log=TRUE and
> perhaps lower.tail=FALSE arguments.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> > Of Rolf Turner
> > Sent: Monday, October 28, 2013 2:01 PM
> > To: Shantanu MULLICK
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Optimize function in R: unable to find maximum of logistic function
> >
> >
> > This could be described as a bug, perhaps.  Or it could be described as
> > an indication that numerical optimization is inevitably tricky. Notice that
> > if you narrow down your search interval from [0,5] to [0,0.5] you get the
> > right answer:
> >
> >  > optimize(f, c(0, 0.5), maximum= TRUE,tol=1e-10)
> > $maximum
> > [1] 4.192436e-11
> >
> > $objective
> > [1] 1
> >
> > I guess there's a problem with finding a gradient that is effectively
> > (numerically) zero when "k" is equal to 5.
> >
> >
> >      cheers,
> >
> >      Rolf Turner
> >
> >
> > On 10/29/13 06:00, Shantanu MULLICK wrote:
> > > Hello Everyone,
> > >
> > > I want to perform a 1-D optimization by using the optimize() function. I
> > > want to find the maximum value of a "logistic" function. The optimize()
> > > function gives the wrong result.
> > >
> > > My code:
> > > f= function (k) {
> > > T_s = 20
> > > result = (2- 2/(1+ exp(-2*T_s*k)))
> > > return(result)
> > > }
> > > optimize(f, c(0, 5), tol = 0.0000000000001, maximum= TRUE)
> > >
> > > The maximum value for the function happens at k=0, and the maximum value is
> > > 1. Yet  the optimise function, says that the maximum value happens at k=
> > > 4.9995, and the maximum value is 0.
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From b00295766 at essec.edu  Mon Oct 28 23:02:06 2013
From: b00295766 at essec.edu (Shantanu MULLICK)
Date: Mon, 28 Oct 2013 23:02:06 +0100
Subject: [R] Optimize function in R: unable to find maximum of logistic
	function
In-Reply-To: <526ED09C.7060900@auckland.ac.nz>
References: <CAMWfkYCn0W2QwJ-FcE+NDs3=EeO5NvOexXhSCbfeWs+FC_BnTA@mail.gmail.com>
	<526ED09C.7060900@auckland.ac.nz>
Message-ID: <CAMWfkYA1-QanuoShPPka1s5oXOtkqt+sGjwL5O4t+6sb5fsDgA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131028/5e4cd522/attachment.pl>

From k.moon at student.unimelb.edu.au  Tue Oct 29 00:35:13 2013
From: k.moon at student.unimelb.edu.au (kmmoon100)
Date: Mon, 28 Oct 2013 16:35:13 -0700 (PDT)
Subject: [R] Optimization failed in fitdistr (Weibull distribution)
In-Reply-To: <55020AD1-B809-4543-811F-DDEFB55A69EA@xs4all.nl>
References: <1382962027602-4679167.post@n4.nabble.com>
	<526E7DC5.9020701@sapo.pt>
	<55020AD1-B809-4543-811F-DDEFB55A69EA@xs4all.nl>
Message-ID: <1383003313964-4679232.post@n4.nabble.com>

Hi Berend,

Thank you for your reply.
How can I use dput function for this type of data?
I looked up the description of the function but I still can't understand how
to use it for solving my error.

Regards,

Kangmin.



--
View this message in context: http://r.789695.n4.nabble.com/Optimization-failed-in-fitdistr-Weibull-distribution-tp4679178p4679232.html
Sent from the R help mailing list archive at Nabble.com.


From glennmschultz at me.com  Tue Oct 29 01:05:08 2013
From: glennmschultz at me.com (Glenn Schultz)
Date: Tue, 29 Oct 2013 00:05:08 +0000 (GMT)
Subject: [R] need some help with this example
Message-ID: <708c1330-1a8d-4de5-97ad-e4ff9e396896@me.com>

I have a class Details that contains information needed by FirstSet to do some calculations then a super class that returns Details and FirstSet. ?The problem seems to be in FirstSet where I use the function getAnumber(id). ?

setClass("Details",
? ? ? ? ?representation(
? ? ? ? ? ?ID = "character",
? ? ? ? ? ?Anumber = "numeric"))

setGeneric("Details",
? ? ? ? ? ?def = function(object){standardGeneric("Details")})

setMethod("initialize",
? ? ? ? ? signature(.Object = "Details"),
? ? ? ? ? function(.Object, ID = "character", Anumber = numeric()){
? ? ? ? ? ? .Object at ID = ID
? ? ? ? ? ? .Object at Anumber = 2
? ? ? ? ? ? return(.Object)
? ? ? ? ? })

# getter for A number
setGeneric("getAnumber", function(object){standardGeneric("getAnumber")})

setMethod("getAnumber","Details",
? ? ? ? ? function(object){return(Object at Anumber)})

setClass("FirstSet",
? ? ? ? ?representation(
? ? ? ? ? ?Anothernumber = "numeric"))

setGeneric(
? name = "FirstSet",
? def = function(object){standardGeneric("FirstSet")}
)
setMethod("initialize",
? ? ? ? ? signature(.Object = "FirstSet"),
? ? ? ? ? function (.Object, id = "character", multiplier = numeric())
? ? ? ? ? { x = getAnumber(id)
? ? ? ? ? ? y = x * multiplier
? ? ? ? ? ? .Object at Anothernumber = y
? ? ? ? ? ? return(.Object)
? ? ? ? ? }
)

setClass("Super", contains = c("Details", "FirstSet"))

setGeneric("Super",
? ? ? ? ? ?def = function(object){standardGeneric("Super")})

setMethod("initialize",
? ? ? ? ? signature(.Object = "Super"),
? ? ? ? ? function(.Object, id = "character", Anumber = Anumber()){
? ? ? ? ? ? Details<- new("Details", ID = id, Anumber = number)
? ? ? ? ? ? FirstSet <- new("FirstSet", Anothernumber = Anothernumber)
? ? ? ? ? ? Super <- new("Super", Details, FirstSet)
? ? ? ? ? ? return(.Object)
? ? ? ? ? })


From bhh at xs4all.nl  Tue Oct 29 06:30:58 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 29 Oct 2013 06:30:58 +0100
Subject: [R] Optimization failed in fitdistr (Weibull distribution)
In-Reply-To: <1383003313964-4679232.post@n4.nabble.com>
References: <1382962027602-4679167.post@n4.nabble.com>
	<526E7DC5.9020701@sapo.pt>
	<55020AD1-B809-4543-811F-DDEFB55A69EA@xs4all.nl>
	<1383003313964-4679232.post@n4.nabble.com>
Message-ID: <DD1D516D-0ED5-4EB5-B78A-86BDA5D3269C@xs4all.nl>


On 29-10-2013, at 00:35, kmmoon100 <k.moon at student.unimelb.edu.au> wrote:

> Hi Berend,
> 
> Thank you for your reply.
> How can I use dput function for this type of data?
> I looked up the description of the function but I still can't understand how
> to use it for solving my error.
> 

You don't use dput() to solve your error.
You use dput to get a plain text representation of your data.

Select the output in any editor, copy and paste it in a mail to the list.
If the output is huge then of course you can do dput(head(?.,?)) to create a reproducible example.
And then maybe people on the list can suggest solutions.

Berend

> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Optimization-failed-in-fitdistr-Weibull-distribution-tp4679178p4679232.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Tue Oct 29 07:44:49 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 29 Oct 2013 07:44:49 +0100
Subject: [R] Optimization failed in fitdistr (Weibull distribution)
In-Reply-To: <1382962027602-4679167.post@n4.nabble.com>
References: <1382962027602-4679167.post@n4.nabble.com>
Message-ID: <20E86E70-305F-4C4A-95AA-BAFE294823A0@gmail.com>


On 28 Oct 2013, at 13:07 , kmmoon100 <k.moon at student.unimelb.edu.au> wrote:

> Hello everyone,
> 
> This is Kangmin.
> 
> I am trying to produce shape and scale of my wind data. My data is based on
> wind speed frequency with 1km/hr increment. data is described below.
> 
> Windspeed (km/h)    Frequency
> 1	351
> 2	147
> 3	317
> 4	378
> 5	527
> 6	667
> 7	865
> 8	970
> 9	987
> 10	907
> 11	905
> 12	642
> 13	1000
> 14	983
> 15	847
> 16	842
> 17	757
> 18	698
> 19	632
> 20	626
> 21	599
> 22	529
> 23	325
> 24	391
> 25	356
> 26	267
> 27	230
> 28	223
> 29	190
> 30	142
> 31	124
> 32	104
> 33	97
> 34	37
> 35	62
> 36	46
> 37	42
> 38	24
> 39	9
> 40	13
> 41	9
> 42	5
> 43	2
> 
> R codes to calculate shape and scale are described below:
> 
> Pine.windfrequency.4weeks<-read.table("C:/Users/kmoon/Documents/Pine_frequency_4weeks.csv",header=TRUE,sep=",")
> fitdistr(Pine.windfrequency.4weeks$Frequency, densfun="weibull")
> 
> I have got an error message when I was using 'fitdistr' function
> 
> "Error in fitdistr(Pine.windfrequency.4weeks$Frequency, densfun = "weibull")
> : 
>  optimization failed"
> 
> Please help me calculating shape and scale of weibull distribution.
> 
> And please understand that I am not an user familiar with R program but I am
> really trying to make my analysis work on R!

There really is no substitute for knowledge and understanding! Did it not occur to you that the Windspeed column needs to enter into your analysis? 

I suppose you wanted the following:

> tt<-read.delim("/tmp/foo")
> summary(tt)
 Windspeed..km.h.   Frequency     
 Min.   : 1.0     Min.   :   2.0  
 1st Qu.:11.5     1st Qu.: 100.5  
 Median :22.0     Median : 351.0  
 Mean   :22.0     Mean   : 415.7  
 3rd Qu.:32.5     3rd Qu.: 682.5  
 Max.   :43.0     Max.   :1000.0  
> x <- rep(tt$Windspeed..km.h., tt$Frequency)
> library(MASS) 
> fitdistr(x, densfun="weibull")
      shape         scale   
   1.99900495   16.43640142 
 ( 0.01174133) ( 0.06468371)
Warning messages:
1: In densfun(x, parm[1], parm[2], ...) : NaNs produced
2: In densfun(x, parm[1], parm[2], ...) : NaNs produced
3: In densfun(x, parm[1], parm[2], ...) : NaNs produced
4: In densfun(x, parm[1], parm[2], ...)


> 
> Thank you!!!
> 
> Kangmin.
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Optimization-failed-in-fitdistr-Weibull-distribution-tp4679167.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From babakbsn at gmail.com  Tue Oct 29 12:14:35 2013
From: babakbsn at gmail.com (Baro)
Date: Tue, 29 Oct 2013 04:14:35 -0700
Subject: [R] Showing a reduced Time series in a plot
Message-ID: <CAF-JZQtUbvPLiGayHYRXrdmJKZ0L6Ku2RaQjYDN+=EFJsAyyXw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/4278266b/attachment.pl>

From rm at wippies.se  Tue Oct 29 12:38:45 2013
From: rm at wippies.se (rm)
Date: Tue, 29 Oct 2013 04:38:45 -0700 (PDT)
Subject: [R] coxph: how to define interaction terms?
In-Reply-To: <1382950829862-4679162.post@n4.nabble.com>
References: <1382950829862-4679162.post@n4.nabble.com>
Message-ID: <1383046725232-4679249.post@n4.nabble.com>

Any ideas would be much appreciated; I suspect that this problem of
constructing the dummies applies not only to function coxph but to other
regression models in R as well. Effectively, my question is how to better
control for which dummies and interactions to include in the model and which
not.

The following code shows a workaround. It works here reasonably well since x
has only two levels, but if x has more levels, constructing the dummies
manually for each level and keeping track of each of them becomes very
difficult.



A weird thing is that if onle replace line 4 with



the problem reappears. Any idea why? A numeric (0 or 1) variable produces
different interactions than a logical variable (FALSE or TRUE).



--
View this message in context: http://r.789695.n4.nabble.com/coxph-how-to-define-interaction-terms-tp4679162p4679249.html
Sent from the R help mailing list archive at Nabble.com.


From alaios at yahoo.com  Tue Oct 29 12:57:28 2013
From: alaios at yahoo.com (Alaios)
Date: Tue, 29 Oct 2013 04:57:28 -0700 (PDT)
Subject: [R] TelosB external modules, guide
Message-ID: <1383047848.72396.YahooMailNeo@web125306.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/df67cbfe/attachment.pl>

From bhh at xs4all.nl  Tue Oct 29 13:03:18 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 29 Oct 2013 13:03:18 +0100
Subject: [R] TelosB external modules, guide
In-Reply-To: <1383047848.72396.YahooMailNeo@web125306.mail.ne1.yahoo.com>
References: <1383047848.72396.YahooMailNeo@web125306.mail.ne1.yahoo.com>
Message-ID: <C4B15690-14EC-46CE-846A-7ED5E653E69D@xs4all.nl>


On 29-10-2013, at 12:57, Alaios <alaios at yahoo.com> wrote:

> Hi all,
> I would like to ask your help regarding connecting external modules to telosb. I have found that tiny os offers many possibilities for that as 
> 
> ADC,
> GPIOs, SPI, UART, I2C
> 
> I have never learned anything regarding those. Can someone please let me know if there is any simple
> guide on these "interfaces" to show with a primitive example how to start with?
> 
> I would like to thank you in advance for your help
> 

What does this have to do with R?

Berend


From a.mosnier at gmail.com  Tue Oct 29 13:49:44 2013
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Tue, 29 Oct 2013 08:49:44 -0400
Subject: [R] speed of makeCluster (package parallel)
Message-ID: <CANkFkEcyEotu9h2OAN9i16jMpJ-rVz-EKQkJGu+b17mexmQt-A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/7b53749a/attachment.pl>

From eliza_botto at hotmail.com  Tue Oct 29 15:14:31 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Tue, 29 Oct 2013 14:14:31 +0000
Subject: [R] maximum value replacement
Message-ID: <BLU170-W532ACFCD06F18BDB79CA8A89090@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/80c4ff1d/attachment.pl>

From smartpink111 at yahoo.com  Tue Oct 29 15:27:07 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 29 Oct 2013 07:27:07 -0700 (PDT)
Subject: [R] maximum value replacement
In-Reply-To: <BLU170-W532ACFCD06F18BDB79CA8A89090@phx.gbl>
References: <BLU170-W532ACFCD06F18BDB79CA8A89090@phx.gbl>
Message-ID: <1383056827.57463.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:
?sapply(seq_len(ncol(A)),function(i) {indx <- which(A[,i]%in% max(A[,i])); A[,i][indx] <- B[,i]; A[,i]})

A.K.




On Tuesday, October 29, 2013 10:16 AM, eliza botto <eliza_botto at hotmail.com> wrote:
Dear Users,
I have two matrices, one with 12 rows and 124 columns(A) and the other with 1 row and 124 column(B). i want to replace the maximum value in all columns of A with each (single) column value of B. 
How can i do it??
Thanks indeed in advance,

Eliza ??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From honza.snecek at gmail.com  Tue Oct 29 09:04:41 2013
From: honza.snecek at gmail.com (Slomo)
Date: Tue, 29 Oct 2013 17:04:41 +0900
Subject: [R] How to set default font for lattice graphics?
Message-ID: <CAKmuQ98pomV5bqdtryKkhrHgZV0jRjWVjpYudTjGZUY-Tz-g_Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/a4f78db4/attachment.pl>

From ucakche at ucl.ac.uk  Tue Oct 29 14:17:11 2013
From: ucakche at ucl.ac.uk (Christian Hennig)
Date: Tue, 29 Oct 2013 13:17:11 +0000
Subject: [R] R CMD check Error: package MASS was built before R 3.0.0 - not
 true!?
Message-ID: <alpine.GSO.2.00.1310291312540.21554@socrates-a.ucl.ac.uk>

Hi there,

I just updated my R to 3.0.2 and ran
R CMD check --as-cran on the just produced new version of fpc.

I got an error
Error: package "MASS" was built before R 3.0.0: please re-install it

- but I actually *did* re-install MASS without error just before that and 
within R library(MASS) works just fine.

What can I do about this?

Best wishes,
Christian

*** --- ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
c.hennig at ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche


From jdnewmil at dcn.davis.CA.us  Tue Oct 29 16:12:39 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 29 Oct 2013 08:12:39 -0700
Subject: [R] R CMD check Error: package MASS was built before R 3.0.0 -
	not true!?
In-Reply-To: <alpine.GSO.2.00.1310291312540.21554@socrates-a.ucl.ac.uk>
References: <alpine.GSO.2.00.1310291312540.21554@socrates-a.ucl.ac.uk>
Message-ID: <32d5ee74-2bc5-4756-bfa0-4d3d90626367@email.android.com>

Perhaps check your R_LIBS* variables?

http://stat.ethz.ch/R-manual/R-devel/library/base/html/libPaths.html
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Christian Hennig <ucakche at ucl.ac.uk> wrote:
>Hi there,
>
>I just updated my R to 3.0.2 and ran
>R CMD check --as-cran on the just produced new version of fpc.
>
>I got an error
>Error: package "MASS" was built before R 3.0.0: please re-install it
>
>- but I actually *did* re-install MASS without error just before that
>and 
>within R library(MASS) works just fine.
>
>What can I do about this?
>
>Best wishes,
>Christian
>
>*** --- ***
>Christian Hennig
>University College London, Department of Statistical Science
>Gower St., London WC1E 6BT, phone +44 207 679 1698
>c.hennig at ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Oct 29 16:30:13 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 29 Oct 2013 08:30:13 -0700
Subject: [R] maximum value replacement
In-Reply-To: <1383056827.57463.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <BLU170-W532ACFCD06F18BDB79CA8A89090@phx.gbl>
	<1383056827.57463.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CACk-te0KA0Z_ymX=4X3h8aMZWfKrzb8uMiYk7Wygv+JXBAuHGA@mail.gmail.com>

To Eliza: What if the max in a column is not unique?

Given the small size of A, the solution given by Arun seems completely
adequate. However, I was wondering if it could be done without the
R-level loop in sapply by taking advantage of pmax() . Of course it
can. Here's code to illustrate how:

A<- matrix(sample(15),nr=3)
A
B <- matrix(0,nr=1,nc=5)
m <- do.call(pmax,data.frame(t(A)))
d <- dim(A)
A[which(A==matrix(m,nr=d[1],nc=d[2],byrow=TRUE))] <- B
A

Note that:

1. This does not generalize to functions other than max or min, afaik.
2. I don't even know if it would be faster for large data, because the
data.frame call may slow things down.

But it is fully vectorized (I think). So for illustration only, maybe...

Cheers,
Bert



On Tue, Oct 29, 2013 at 7:27 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> Try:
>  sapply(seq_len(ncol(A)),function(i) {indx <- which(A[,i]%in% max(A[,i])); A[,i][indx] <- B[,i]; A[,i]})
>
> A.K.
>
>
>
>
> On Tuesday, October 29, 2013 10:16 AM, eliza botto <eliza_botto at hotmail.com> wrote:
> Dear Users,
> I have two matrices, one with 12 rows and 124 columns(A) and the other with 1 row and 124 column(B). i want to replace the maximum value in all columns of A with each (single) column value of B.
> How can i do it??
> Thanks indeed in advance,
>
> Eliza
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From eliza_botto at hotmail.com  Tue Oct 29 16:46:36 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Tue, 29 Oct 2013 15:46:36 +0000
Subject: [R] maximum value replacement
In-Reply-To: <CACk-te0KA0Z_ymX=4X3h8aMZWfKrzb8uMiYk7Wygv+JXBAuHGA@mail.gmail.com>
References: <BLU170-W532ACFCD06F18BDB79CA8A89090@phx.gbl>,
	<1383056827.57463.YahooMailNeo@web142605.mail.bf1.yahoo.com>,
	<CACk-te0KA0Z_ymX=4X3h8aMZWfKrzb8uMiYk7Wygv+JXBAuHGA@mail.gmail.com>
Message-ID: <BLU170-W73B0542CB14593CF546D5C89090@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/19a3c501/attachment.pl>

From erinm.hodgess at gmail.com  Tue Oct 29 17:01:59 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 29 Oct 2013 11:01:59 -0500
Subject: [R] sh /bin/sh bad interpreter error when loading certain packages
Message-ID: <CACxE24mN0bkcftTL-tRbqJwGA8z62NZqjiOQSsnMakAGB6cvMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/d9c40aac/attachment.pl>

From gunter.berton at gene.com  Tue Oct 29 17:09:13 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 29 Oct 2013 09:09:13 -0700
Subject: [R] maximum value replacement
In-Reply-To: <BLU170-W73B0542CB14593CF546D5C89090@phx.gbl>
References: <BLU170-W532ACFCD06F18BDB79CA8A89090@phx.gbl>
	<1383056827.57463.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CACk-te0KA0Z_ymX=4X3h8aMZWfKrzb8uMiYk7Wygv+JXBAuHGA@mail.gmail.com>
	<BLU170-W73B0542CB14593CF546D5C89090@phx.gbl>
Message-ID: <CACk-te1bstkbuT5UV6i-KEskHw6wFz6CWTk9xx1VgG4Xy_xFHw@mail.gmail.com>

... and while I'm being OCD, note that the which() call in my code can
and should be omitted. It's completely superfluous. :-(

-- Bert



On Tue, Oct 29, 2013 at 8:46 AM, eliza botto <eliza_botto at hotmail.com> wrote:
> Thanks bert!!!
> it worked out perfectly well.
> thankyou onceagain,
>
> Eliza
>
>> Date: Tue, 29 Oct 2013 08:30:13 -0700
>> Subject: Re: [R] maximum value replacement
>> From: gunter.berton at gene.com
>> To: smartpink111 at yahoo.com; eliza_botto at hotmail.com
>> CC: r-help at r-project.org
>>
>> To Eliza: What if the max in a column is not unique?
>>
>> Given the small size of A, the solution given by Arun seems completely
>> adequate. However, I was wondering if it could be done without the
>> R-level loop in sapply by taking advantage of pmax() . Of course it
>> can. Here's code to illustrate how:
>>
>> A<- matrix(sample(15),nr=3)
>> A
>> B <- matrix(0,nr=1,nc=5)
>> m <- do.call(pmax,data.frame(t(A)))
>> d <- dim(A)
>> A[which(A==matrix(m,nr=d[1],nc=d[2],byrow=TRUE))] <- B
>> A
>>
>> Note that:
>>
>> 1. This does not generalize to functions other than max or min, afaik.
>> 2. I don't even know if it would be faster for large data, because the
>> data.frame call may slow things down.
>>
>> But it is fully vectorized (I think). So for illustration only, maybe...
>>
>> Cheers,
>> Bert
>>
>>
>>
>> On Tue, Oct 29, 2013 at 7:27 AM, arun <smartpink111 at yahoo.com> wrote:
>> > Hi,
>> > Try:
>> > sapply(seq_len(ncol(A)),function(i) {indx <- which(A[,i]%in%
>> > max(A[,i])); A[,i][indx] <- B[,i]; A[,i]})
>> >
>> > A.K.
>> >
>> >
>> >
>> >
>> > On Tuesday, October 29, 2013 10:16 AM, eliza botto
>> > <eliza_botto at hotmail.com> wrote:
>> > Dear Users,
>> > I have two matrices, one with 12 rows and 124 columns(A) and the other
>> > with 1 row and 124 column(B). i want to replace the maximum value in all
>> > columns of A with each (single) column value of B.
>> > How can i do it??
>> > Thanks indeed in advance,
>> >
>> > Eliza
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> (650) 467-7374



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From rshepard at appl-ecosys.com  Tue Oct 29 17:21:33 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Tue, 29 Oct 2013 09:21:33 -0700
Subject: [R] sh /bin/sh bad interpreter error when loading certain
 packages
In-Reply-To: <CACxE24mN0bkcftTL-tRbqJwGA8z62NZqjiOQSsnMakAGB6cvMA@mail.gmail.com>
References: <CACxE24mN0bkcftTL-tRbqJwGA8z62NZqjiOQSsnMakAGB6cvMA@mail.gmail.com>
Message-ID: <alpine.LNX.2.00.1310290918400.2280@salmo.appl-ecosys.com>

On Tue, 29 Oct 2013, Erin Hodgess wrote:

> I'm on a Centos 5 Red Hat system and I'm trying to install such packages as
> Cairo, Rserve, etc.
> However, I keep getting an error:  sh:/bin/sh bad interpreter.

Erin,

   A Web search shows several possible causes, including incorrect options in
/etc/fstab for the partition you're using and working with a DOS-formatted
file that uses CR/LF instead of \n (dos2unix cures that).

   I've not worked with any Red Hat flavor for the past decade but look at
results for that search string and you may find a solution appropriate for
you.

HTH,

Rich

-- 
Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
Applied Ecosystem Services, Inc.   |
<http://www.appl-ecosys.com>     Voice: 503-667-4517      Fax: 503-667-8863


From f.calboli at imperial.ac.uk  Tue Oct 29 17:21:41 2013
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 29 Oct 2013 16:21:41 +0000
Subject: [R] R vs octave development strategy (and success)
Message-ID: <63480AAE-BCDA-4CAC-B0F3-44613A662499@imperial.ac.uk>

Hi All,

if memory serves me well I recall some paper comparing the relative success in getting mainstream acceptance (as mainstream as statistics can be) of both R and Octave.  I remember vaguely that the fact the development strategies (core team vs one main developer) played a major role in the relative success of the two programs.  I tried to find this paper, but my goggle skills are failing me.  Would anyone know where to find it?

Best

F
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 881 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/330ac429/attachment.bin>

From dwinsemius at comcast.net  Tue Oct 29 17:56:25 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 29 Oct 2013 09:56:25 -0700
Subject: [R] coxph: how to define interaction terms?
In-Reply-To: <1383046725232-4679249.post@n4.nabble.com>
References: <1382950829862-4679162.post@n4.nabble.com>
	<1383046725232-4679249.post@n4.nabble.com>
Message-ID: <708CE7D7-B2DC-4D94-ABB5-79560F6CFC3F@comcast.net>


On Oct 29, 2013, at 4:38 AM, rm wrote:

> Any ideas would be much appreciated; I suspect that this problem of
> constructing the dummies applies not only to function coxph but to other
> regression models in R as well. Effectively, my question is how to better
> control for which dummies and interactions to include in the model and which
> not.
> 
> The following code shows a workaround. It works here reasonably well since x
> has only two levels, but if x has more levels, constructing the dummies
> manually for each level and keeping track of each of them becomes very
> difficult.
> 
> 
> 
> A weird thing is that if onle replace line 4 with
> 
> 

You should go to the R-help Archive to see what the vast majority of readers of this mailing list are seeing.

https://stat.ethz.ch/pipermail/r-help/2013-October/362203.html

> 
> the problem reappears. Any idea why? A numeric (0 or 1) variable produces
> different interactions than a logical variable (FALSE or TRUE).
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/coxph-how-to-define-interaction-terms-tp4679162p4679249.html
> Sent from the R help mailing list archive at Nabble.com.
> 
______________________________________________
"R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html"
^^^^^^^^^^^^^^^^^^

And you should read both the fine posting guide and the messages that Nabble suppresses in its effort to masquerade as Rhelp.

"and provide commented, minimal, self-contained, reproducible code."

-- 

David Winsemius
Alameda, CA, USA


From lopez235 at llnl.gov  Tue Oct 29 18:13:25 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Tue, 29 Oct 2013 17:13:25 +0000
Subject: [R] Regular Expression returning unexpected results
Message-ID: <56180B40A4F72A4083C75B30DA86297333D9B844@PRDEXMBX-05.the-lab.llnl.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/33bc3ee5/attachment.pl>

From s.wood at bath.ac.uk  Tue Oct 29 18:19:24 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Tue, 29 Oct 2013 18:19:24 +0100
Subject: [R] Inscrutable error message in mgcv: 1> prediction =
 predict(MI, se.fit=TRUE, newdata=rhc),
 Error in if (object$inter) X[[i]] <- PredictMat(object$margin[[i]], dat, : ,
 argument is of length zero
In-Reply-To: <526B7E64.2010806@gmail.com>
References: <526B7E64.2010806@gmail.com>
Message-ID: <526FEE1C.4000803@bath.ac.uk>

Sorry, this relates to ?"mgcv-FAQ" number 5, unfortunately. 'ti' terms 
were introduced as a much better and cleaner way of allowing smooth main 
effects and interactions where the interactions are based on 'te' terms: 
this required some re-engineering of the tensor product smooth objects 
(the offending 'iter' element of the smooth is how 'ti' terms are 
distinguished from normal 'te' terms internally). I'm afraid this won't 
work in the current mgcv without re-fitting the original model.

Simon


On 26/10/13 10:33, Andrew Crane-Droesch wrote:
> Dear List,
>
> I am trying to reproduce a figure that I made for an analysis that I did
> a few months ago.  Between when I first made the figure and now, I've
> upgraded to R 3.0.2 and upgraded my operating system (ubuntu 13.04).  My
> codebase, which once works, is throwing an error when I try to use
> predict.gam on a model object that I saved:
>
> 1> prediction = predict(MI,se.fit=TRUE,newdata=rhc)
> Error in if (object$inter) X[[i]] <- PredictMat(object$margin[[i]], dat,  :
>    argument is of length zero
>
> traceback() gives me the following:
>
> 1> traceback()
> 6: Predict.matrix.tensor.smooth(object, dk$data)
> 5: Predict.matrix(object, dk$data)
> 4: Predict.matrix3(object, data)
> 3: PredictMat(object$smooth[[k]], data)
> 2: predict.gam(MI, se.fit = TRUE, newdata = rhc)
> 1: predict(MI, se.fit = TRUE, newdata = rhc)
>
> the final function being called looks like this:
>
> 1> Predict.matrix.tensor.smooth
> function (object, data)
> {
>      m <- length(object$margin)
>      X <- list()
>      for (i in 1:m) {
>          term <- object$margin[[i]]$term
>          dat <- list()
>          for (j in 1:length(term)) dat[[term[j]]] <- data[[term[j]]]
>          if (object$inter)
>              X[[i]] <- PredictMat(object$margin[[i]], dat, n =
> length(dat[[1]]))
>          else X[[i]] <- Predict.matrix(object$margin[[i]], dat)
>      }
>      mxp <- length(object$XP)
>      if (mxp > 0)
>          for (i in 1:mxp) if (!is.null(object$XP[[i]]))
>              X[[i]] <- X[[i]] %*% object$XP[[i]]
>      T <- tensor.prod.model.matrix(X)
>      T
> }
>
> Unfortunately, I can't say that I understand how that function is
> working, beyond that it takes a fitted model object and makes a piece of
> the model matrix.
>
> Any ideas about what this could stem from?  Where to start looking to
> fix it?  I could probably do the entire analysis from scratch, but it is
> quite complex and I'd prefer to save the time.
>
> Apologies for non-reproducible code -- the data is big and the script is
> long.
>
> Thanks for any assistance,
> Andrew
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From COLLINL at pitt.edu  Tue Oct 29 18:24:34 2013
From: COLLINL at pitt.edu (COLLINL at pitt.edu)
Date: Tue, 29 Oct 2013 13:24:34 -0400
Subject: [R] sh /bin/sh bad interpreter error when loading certain
	packages
In-Reply-To: <alpine.LNX.2.00.1310290918400.2280@salmo.appl-ecosys.com>
References: <CACxE24mN0bkcftTL-tRbqJwGA8z62NZqjiOQSsnMakAGB6cvMA@mail.gmail.com>
	<alpine.LNX.2.00.1310290918400.2280@salmo.appl-ecosys.com>
Message-ID: <86d143c1500a0396348d8a9a41a115f4.squirrel@webmail.pitt.edu>

> On Tue, 29 Oct 2013, Erin Hodgess wrote:
>
>> I'm on a Centos 5 Red Hat system and I'm trying to install such packages
>> as
>> Cairo, Rserve, etc.
>> However, I keep getting an error:  sh:/bin/sh bad interpreter.

Erin, just to add to what Rich wrote, this may be a disk related result as
well.  I get this error occasionally on my posix systems.  Assuming that
you are using install.packages I would check the disk permissions for the
files and for the disk they reside on.  If, for example, you are
installing them on a disk partition that does not have the executable flag
set in fstab you may get this error because the system is unwilling to run
code resident on those partitions.

    Collin.


From s.wood at bath.ac.uk  Tue Oct 29 18:27:56 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Tue, 29 Oct 2013 18:27:56 +0100
Subject: [R] Heteroscedasticity and mgcv.
In-Reply-To: <Pine.LNX.4.44.1310262351240.17762-100000@hydrogen.cs.pitt.edu>
References: <Pine.LNX.4.44.1310262351240.17762-100000@hydrogen.cs.pitt.edu>
Message-ID: <526FF01C.10106@bath.ac.uk>


> (1) Am I correct in understanding that Heteroscedasticity is a problem for
> Generalized Additive Models as it is for standard linear models?  I am
> asking particularly about the GAMs as implemented in the mgcv package.
> Based upon my online search it seems that some forms of penalized splines
> can address heteroscedasticity while others cannot and I'm not sure what
> is true of the methods used in mgcv.
- Yes, the mgcv implementation estimates the models via penalized 
likelihood maximisation, and will be as sensitive to violation of the 
assumed mean variance relationship as any GLM fitted by MLE.

>
> (2) Assuming that heteroscedasticity is a problem for the mgcv GAMs, can
> anyone recommend a good test implementation?  I am familiar with the
> ncvTest method implemented in the car package but that applies only to
> lms.
- I tend to check for heteroscedasticity graphically using the usual 
plots of residuals vs fitted values, predictors (and possibly 
combinations of predictors). I like the way that plots often point 
towards a solution to any problem they show.

best,
Simon




>
> 	Thank you,
> 	Collin Lynch.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From COLLINL at pitt.edu  Tue Oct 29 18:29:57 2013
From: COLLINL at pitt.edu (COLLINL at pitt.edu)
Date: Tue, 29 Oct 2013 13:29:57 -0400
Subject: [R] Heteroscedasticity and mgcv.
In-Reply-To: <526FF01C.10106@bath.ac.uk>
References: <Pine.LNX.4.44.1310262351240.17762-100000@hydrogen.cs.pitt.edu>
	<526FF01C.10106@bath.ac.uk>
Message-ID: <3bdf3bb77da8961a6647ea00fbb0b646.squirrel@webmail.pitt.edu>

Thank you Simon that's quite helpful!  I'll compare that with the GLMSS
models.

        Best,
        Collin.

>
>> (1) Am I correct in understanding that Heteroscedasticity is a problem
>> for
>> Generalized Additive Models as it is for standard linear models?  I am
>> asking particularly about the GAMs as implemented in the mgcv package.
>> Based upon my online search it seems that some forms of penalized
>> splines
>> can address heteroscedasticity while others cannot and I'm not sure what
>> is true of the methods used in mgcv.
> - Yes, the mgcv implementation estimates the models via penalized
> likelihood maximisation, and will be as sensitive to violation of the
> assumed mean variance relationship as any GLM fitted by MLE.
>
>>
>> (2) Assuming that heteroscedasticity is a problem for the mgcv GAMs, can
>> anyone recommend a good test implementation?  I am familiar with the
>> ncvTest method implemented in the car package but that applies only to
>> lms.
> - I tend to check for heteroscedasticity graphically using the usual
> plots of residuals vs fitted values, predictors (and possibly
> combinations of predictors). I like the way that plots often point
> towards a solution to any problem they show.
>
> best,
> Simon
>
>
>
>
>>
>> 	Thank you,
>> 	Collin Lynch.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
> +44 (0)1225 386603               http://people.bath.ac.uk/sw283
>


From dcarlson at tamu.edu  Tue Oct 29 18:32:02 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 29 Oct 2013 12:32:02 -0500
Subject: [R] R vs octave development strategy (and success)
In-Reply-To: <63480AAE-BCDA-4CAC-B0F3-44613A662499@imperial.ac.uk>
References: <63480AAE-BCDA-4CAC-B0F3-44613A662499@imperial.ac.uk>
Message-ID: <074701ced4cc$c75c60a0$561521e0$@tamu.edu>

This covers the topic you mention, but from the perspective of
the role of the R Core team. The point about Octave is a single
sentence/footnote:

Fox, John. 2009. Aspects of the Social Organization and
Trajectory of the R Project. The R Journal 1/2: 5-13.

http://rjournal.github.io/archive/2009-2/RJournal_2009-2_Fox.pdf

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Federico
Calboli
Sent: Tuesday, October 29, 2013 11:22 AM
To: r-help
Subject: [R] R vs octave development strategy (and success)

Hi All,

if memory serves me well I recall some paper comparing the
relative success in getting mainstream acceptance (as mainstream
as statistics can be) of both R and Octave.  I remember vaguely
that the fact the development strategies (core team vs one main
developer) played a major role in the relative success of the
two programs.  I tried to find this paper, but my goggle skills
are failing me.  Would anyone know where to find it?

Best

F


From sarah.goslee at gmail.com  Tue Oct 29 18:44:25 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 29 Oct 2013 13:44:25 -0400
Subject: [R] Regular Expression returning unexpected results
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333D9B844@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333D9B844@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <CAM_vjum9OhapbG-F3=eZmUOSE2g5Wv73CCfRdiV7u50zZKCOxQ@mail.gmail.com>

On Tue, Oct 29, 2013 at 1:13 PM, Lopez, Dan <lopez235 at llnl.gov> wrote:
> grep("^([a-z]+) +\1 +[a-z]+ [0-9]",lines)

Your expression has a typo:

R> grep("^([a-z]+) +\\1 +[a-z]+ [0-9]",lines)
[1] 2


-- 
Sarah Goslee
http://www.functionaldiversity.org


From jdnewmil at dcn.davis.CA.us  Tue Oct 29 19:08:14 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 29 Oct 2013 11:08:14 -0700
Subject: [R] Regular Expression returning unexpected results
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333D9B844@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333D9B844@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <19d82256-f568-47c3-922b-8a34afe4f1a8@email.android.com>

Please read and follow the Posting Guide, in particular re plain text email.

You need to keep in mind that the characters in literal strings in R source have to make it into RAM before the regex code can parse it. Since regex needs a single backslash to escape normal parsing and interpret 1 as a back reference, but the R parser also recognizes and removes backslashes in string literals as escape characters, you need to escape the backslash with a backslash in your R string literal. 

nchar tells you how many characters are in the string. print renders the string as it would need to be entered as R source code. cat sends the string directly to the output (console). Study the output of the following commands at the R prompt.

?Quotes

nchar("^([a-z]+) +\1 +[a-z]+ [0-9]")
print("^([a-z]+) +\1 +[a-z]+ [0-9]")
cat("^([a-z]+) +\1 +[a-z]+ [0-9]")

On most systems, a raw character code 1 is also known as Control-A, but the effect it has on the terminal used as the console may vary according to your setup, and it's effect on my system is  not clear to me.

nchar("^([a-z]+) +\\1 +[a-z]+ [0-9]")
print("^([a-z]+) +\\1 +[a-z]+ [0-9]")
cat("^([a-z]+) +\\1 +[a-z]+ [0-9]")
grep("^([a-z]+) +\\1 +[a-z]+ [0-9]",lines)

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"Lopez, Dan" <lopez235 at llnl.gov> wrote:
>Hi,
>
>So I just took an intro to R programming class and one of the lectures
>was on Regular Expressions. I've been playing around with various R
>functions that use Regular Expressions.
>But this has me stumped. This was part of a quiz and I got it right
>through understanding the syntax. But when I try to run the thing it
>returns 'integer(0)'. Can you please tell me what I am doing wrong?
>
>#I copied and pasted this:
>going up and up and up
>night night at 8
>bye bye from up high
>heading, heading by 9
>
>#THEN
>lines<-readLines("clipboard")
>#This is what it looks like in R
>lines
>[1] "going up and up and up"
>[2] "night night at 8"
>[3] "bye bye from up high"
>[4] "heading, heading by 9"
>
>#THIS IS WHAT IS NOT WORKING THE WAY I THOUGHT. I was expecting it to
>return 2.
># "night night at 8" follows the pattern: Begins with a word then has
>at least one space then the same word then has at least one space then
>a word then a space then a single digit number.
>grep("^([a-z]+) +\1 +[a-z]+ [0-9]",lines)
>integer(0)
>
>#But simple examples DO work
>grep("[Hh]",lines)
>[1] 2 3 4
>grep('[0-9]',lines)
>[1] 2 4
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From erinm.hodgess at gmail.com  Tue Oct 29 19:19:50 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 29 Oct 2013 13:19:50 -0500
Subject: [R] sh /bin/sh bad interpreter error when loading certain
	packages
In-Reply-To: <86d143c1500a0396348d8a9a41a115f4.squirrel@webmail.pitt.edu>
References: <CACxE24mN0bkcftTL-tRbqJwGA8z62NZqjiOQSsnMakAGB6cvMA@mail.gmail.com>
	<alpine.LNX.2.00.1310290918400.2280@salmo.appl-ecosys.com>
	<86d143c1500a0396348d8a9a41a115f4.squirrel@webmail.pitt.edu>
Message-ID: <CACxE24myoCUY5aWs8TMJm1rcO0Py-_h-vmMSGgxYvb67jqacbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/26d41852/attachment.pl>

From pdalgd at gmail.com  Tue Oct 29 19:56:25 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 29 Oct 2013 19:56:25 +0100
Subject: [R] R vs octave development strategy (and success)
In-Reply-To: <074701ced4cc$c75c60a0$561521e0$@tamu.edu>
References: <63480AAE-BCDA-4CAC-B0F3-44613A662499@imperial.ac.uk>
	<074701ced4cc$c75c60a0$561521e0$@tamu.edu>
Message-ID: <97E212CC-0964-4D94-86E8-4E17E60F3526@gmail.com>

This is from the other perspective

http://www.r-project.org/conferences/DSC-2001/Proceedings/Eaton.pdf

I can?t spot any direct comparison (and there is no mention of R in the references), but I recall the ideas contrasting the two projects being bandied about at the time. That discussion is likely what is echoed in the Fox paper. John Eaton was running out of steam at the time and the paper is not making a secret of it. 

-pd

On 29 Oct 2013, at 18:32 , David Carlson <dcarlson at tamu.edu> wrote:

> This covers the topic you mention, but from the perspective of
> the role of the R Core team. The point about Octave is a single
> sentence/footnote:
> 
> Fox, John. 2009. Aspects of the Social Organization and
> Trajectory of the R Project. The R Journal 1/2: 5-13.
> 
> http://rjournal.github.io/archive/2009-2/RJournal_2009-2_Fox.pdf
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Federico
> Calboli
> Sent: Tuesday, October 29, 2013 11:22 AM
> To: r-help
> Subject: [R] R vs octave development strategy (and success)
> 
> Hi All,
> 
> if memory serves me well I recall some paper comparing the
> relative success in getting mainstream acceptance (as mainstream
> as statistics can be) of both R and Octave.  I remember vaguely
> that the fact the development strategies (core team vs one main
> developer) played a major role in the relative success of the
> two programs.  I tried to find this paper, but my goggle skills
> are failing me.  Would anyone know where to find it?
> 
> Best
> 
> F
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dcarlson at tamu.edu  Tue Oct 29 20:05:38 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 29 Oct 2013 14:05:38 -0500
Subject: [R] Regular Expression returning unexpected results
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333D9B844@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333D9B844@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <074901ced4d9$db0babd0$91230370$@tamu.edu>

>From ?regex

"(do remember that backslashes need to be doubled when entering
R character strings, e.g. from the keyboard)."

> lines[grep("^([a-z]+) +\\1 +[a-z]+ [0-9]",lines)]
[1] "night night at 8"

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Lopez, Dan
Sent: Tuesday, October 29, 2013 12:13 PM
To: R help (r-help at r-project.org)
Subject: [R] Regular Expression returning unexpected results

Hi,

So I just took an intro to R programming class and one of the
lectures was on Regular Expressions. I've been playing around
with various R functions that use Regular Expressions.
But this has me stumped. This was part of a quiz and I got it
right through understanding the syntax. But when I try to run
the thing it returns 'integer(0)'. Can you please tell me what I
am doing wrong?

#I copied and pasted this:
going up and up and up
night night at 8
bye bye from up high
heading, heading by 9

#THEN
lines<-readLines("clipboard")
#This is what it looks like in R
lines
[1] "going up and up and up"
[2] "night night at 8"
[3] "bye bye from up high"
[4] "heading, heading by 9"

#THIS IS WHAT IS NOT WORKING THE WAY I THOUGHT. I was expecting
it to return 2.
# "night night at 8" follows the pattern: Begins with a word
then has at least one space then the same word then has at least
one space then a word then a space then a single digit number.
grep("^([a-z]+) +\1 +[a-z]+ [0-9]",lines)
integer(0)

#But simple examples DO work
grep("[Hh]",lines)
[1] 2 3 4
grep('[0-9]',lines)
[1] 2 4

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From lopez235 at llnl.gov  Tue Oct 29 20:09:59 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Tue, 29 Oct 2013 19:09:59 +0000
Subject: [R] Regular Expression returning unexpected results
In-Reply-To: <19d82256-f568-47c3-922b-8a34afe4f1a8@email.android.com>
References: <56180B40A4F72A4083C75B30DA86297333D9B844@PRDEXMBX-05.the-lab.llnl.gov>
	<19d82256-f568-47c3-922b-8a34afe4f1a8@email.android.com>
Message-ID: <56180B40A4F72A4083C75B30DA86297333D9B948@PRDEXMBX-05.the-lab.llnl.gov>

Hi Jeff,

I was reviewing my old lecture notes and see that the professor did use \1 so I think he was talking about regex in a non-platform specific context. But obviously \\1 is the way to do it in R.
The examples you gave me to study really helped.

I was also going to ask how to identify empty strings AND blank character strings but you will be happy to know that I figured it out on my own:
grep("^ *$",x)

Thank you. 

Thank you Sarah, Bert and David too

Dan


-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us] 
Sent: Tuesday, October 29, 2013 11:08 AM
To: Lopez, Dan; R help (r-help at r-project.org)
Subject: Re: [R] Regular Expression returning unexpected results

Please read and follow the Posting Guide, in particular re plain text email.

You need to keep in mind that the characters in literal strings in R source have to make it into RAM before the regex code can parse it. Since regex needs a single backslash to escape normal parsing and interpret 1 as a back reference, but the R parser also recognizes and removes backslashes in string literals as escape characters, you need to escape the backslash with a backslash in your R string literal. 

nchar tells you how many characters are in the string. print renders the string as it would need to be entered as R source code. cat sends the string directly to the output (console). Study the output of the following commands at the R prompt.

?Quotes

nchar("^([a-z]+) +\1 +[a-z]+ [0-9]")
print("^([a-z]+) +\1 +[a-z]+ [0-9]")
cat("^([a-z]+) +\1 +[a-z]+ [0-9]")

On most systems, a raw character code 1 is also known as Control-A, but the effect it has on the terminal used as the console may vary according to your setup, and it's effect on my system is  not clear to me.

nchar("^([a-z]+) +\\1 +[a-z]+ [0-9]")
print("^([a-z]+) +\\1 +[a-z]+ [0-9]")
cat("^([a-z]+) +\\1 +[a-z]+ [0-9]")
grep("^([a-z]+) +\\1 +[a-z]+ [0-9]",lines)

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

"Lopez, Dan" <lopez235 at llnl.gov> wrote:
>Hi,
>
>So I just took an intro to R programming class and one of the lectures 
>was on Regular Expressions. I've been playing around with various R 
>functions that use Regular Expressions.
>But this has me stumped. This was part of a quiz and I got it right 
>through understanding the syntax. But when I try to run the thing it 
>returns 'integer(0)'. Can you please tell me what I am doing wrong?
>
>#I copied and pasted this:
>going up and up and up
>night night at 8
>bye bye from up high
>heading, heading by 9
>
>#THEN
>lines<-readLines("clipboard")
>#This is what it looks like in R
>lines
>[1] "going up and up and up"
>[2] "night night at 8"
>[3] "bye bye from up high"
>[4] "heading, heading by 9"
>
>#THIS IS WHAT IS NOT WORKING THE WAY I THOUGHT. I was expecting it to 
>return 2.
># "night night at 8" follows the pattern: Begins with a word then has 
>at least one space then the same word then has at least one space then 
>a word then a space then a single digit number.
>grep("^([a-z]+) +\1 +[a-z]+ [0-9]",lines)
>integer(0)
>
>#But simple examples DO work
>grep("[Hh]",lines)
>[1] 2 3 4
>grep('[0-9]',lines)
>[1] 2 4
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From paladini at trustindata.de  Tue Oct 29 18:02:52 2013
From: paladini at trustindata.de (paladini at trustindata.de)
Date: Tue, 29 Oct 2013 18:02:52 +0100
Subject: [R] mapping data to a geographic map of Europe
Message-ID: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>

Hello,
I would like to draw a map of Europe. Each country should be colored  
depending on how it scores in an index called GPIndex.
Say a dark red for real bad countries a light red for those which are  
not so bad, light blue for the fairly good ones and so on up to the  
really good ones in a dark blue.
I never worked with geographic maps before so I tried library maps but  
I didn't get far,- especially because all examples I found only seem  
to work for the United states. So I'm a bit lost.
I would be nice if somebody could help me.

Thanking you in anticipation!

Best regards

Claudia


From edd at debian.org  Tue Oct 29 16:11:35 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 29 Oct 2013 15:11:35 +0000
Subject: [R] R CMD check Error: package MASS was built before R 3.0.0 -
	not true!?
References: <alpine.GSO.2.00.1310291312540.21554@socrates-a.ucl.ac.uk>
Message-ID: <loom.20131029T161054-163@post.gmane.org>

Christian Hennig <ucakche <at> ucl.ac.uk> writes:
> I just updated my R to 3.0.2 and ran
> R CMD check --as-cran on the just produced new version of fpc.
> 
> I got an error
> Error: package "MASS" was built before R 3.0.0: please re-install it
> 
> - but I actually *did* re-install MASS without error just before that and 
> within R library(MASS) works just fine.
> 
> What can I do about this?

Look at .libPaths() and check the directories it lists for a different 
copy of MASS.

Dirk


From c.hennig at ucl.ac.uk  Tue Oct 29 18:08:13 2013
From: c.hennig at ucl.ac.uk (Hennig, Christian)
Date: Tue, 29 Oct 2013 17:08:13 +0000
Subject: [R] R CMD check Error: package MASS was built before R 3.0.0 -
 not true!?
In-Reply-To: <32d5ee74-2bc5-4756-bfa0-4d3d90626367@email.android.com>
References: <alpine.GSO.2.00.1310291312540.21554@socrates-a.ucl.ac.uk>,
	<32d5ee74-2bc5-4756-bfa0-4d3d90626367@email.android.com>
Message-ID: <75c53e1cbcea4d1982c6dd19a93115a3@AM3PR01MB209.eurprd01.prod.exchangelabs.com>

Dear Jeff,

thanks. Somehow R didn't install MASS where it later looked for it. I still haven't understood properly what caused the problem but I managed to fix it now (by specifying lib when installing it).

Best wishes,
Christian

*** --- ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
c.hennig at ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche

________________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
Sent: 29 October 2013 15:12
To: Hennig, Christian; r-help-request Mailing List
Subject: Re: [R] R CMD check Error: package MASS was built before R 3.0.0 - not true!?

Perhaps check your R_LIBS* variables?

http://stat.ethz.ch/R-manual/R-devel/library/base/html/libPaths.html
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

Christian Hennig <ucakche at ucl.ac.uk> wrote:
>Hi there,
>
>I just updated my R to 3.0.2 and ran
>R CMD check --as-cran on the just produced new version of fpc.
>
>I got an error
>Error: package "MASS" was built before R 3.0.0: please re-install it
>
>- but I actually *did* re-install MASS without error just before that
>and
>within R library(MASS) works just fine.
>
>What can I do about this?
>
>Best wishes,
>Christian
>
>*** --- ***
>Christian Hennig
>University College London, Department of Statistical Science
>Gower St., London WC1E 6BT, phone +44 207 679 1698
>c.hennig at ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.




From mgstauff at gmail.com  Tue Oct 29 18:27:07 2013
From: mgstauff at gmail.com (Michael Stauffer)
Date: Tue, 29 Oct 2013 13:27:07 -0400
Subject: [R] 'yum install R' failing with tcl/tk issue
Message-ID: <CANBOegKE=P=Oc-4mKDhGfxfBa3-3orkiyO4GpG+PEzvSBjJg4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/c5cd677a/attachment.pl>

From stefaan.rossenu at merck.com  Tue Oct 29 16:31:17 2013
From: stefaan.rossenu at merck.com (Rossenu, Stefaan)
Date: Tue, 29 Oct 2013 16:31:17 +0100
Subject: [R] calculating quantiles
Message-ID: <283BADBCB74E69438047FA030D918EE58C063F6E02@BEBRMXP51006.merck.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/2cc39c18/attachment.pl>

From pmilin at gmail.com  Tue Oct 29 20:27:13 2013
From: pmilin at gmail.com (Petar Milin)
Date: Tue, 29 Oct 2013 20:27:13 +0100
Subject: [R] How to save very large matrix?
Message-ID: <F51E600F-39FF-43D0-9F2C-63F3511AD321@gmail.com>

Hello!
I have a very large matrix of results: 50000x100000. I saved it as RDS, but I would also need to save it as txt or csv. Is there a way to do it? Now, with write.table I am receiving an error:
Error in .External2(C_writetable, x, file, nrow(x), p, rnames, sep, eol,  : 
  long vectors not supported yet: io.c:1116

Please, help! Many thanks!

PM

From marius.hofert at math.ethz.ch  Tue Oct 29 21:16:51 2013
From: marius.hofert at math.ethz.ch (Marius Hofert)
Date: Tue, 29 Oct 2013 21:16:51 +0100
Subject: [R] (gam) formula: Why different results for terms being factor vs.
	numeric?
Message-ID: <CAM3-Kja0oDJ+koJFPpN404F+uKRWC8iinfVbVhDZH=30atQ2Dg@mail.gmail.com>

Dear expeRts,

If I specify group = as.factor(rep(1:2, each=n)) in the below
definition of dat, I get the expected behavior I am looking for. I
wonder why I
don't get it if group is *not* a factor... My guess was that,
internally, factors are treated as natural numbers (and this indeed
seems to be true if you convert the latter to factors [essentially
meaning changing the levels]), but replacing factors by numeric values
(as below) does not provide the same answer.

Cheers,
Marius


require(mgcv)

n <- 10
yrs <- 2000+seq_len(n)
set.seed(271)
dat <- data.frame(year  = rep(yrs, 2),
                  group = rep(1:2, each=n), # *not* a factor
(as.factor() provides the expected behavior)
                  resp  = c(seq_len(n)+runif(n), 5+seq_len(n)+runif(n)))
fit3 <- gam(resp ~ year + group - 1, data=dat)
plot(yrs, fit3$fitted.values[seq_len(n)], type="l", ylim=range(dat$resp),
     xlab="Year", ylab="Response") # fit group A; mean over all
responses in this group
lines (yrs, fit3$fitted.values[n+seq_len(n)], col="blue") # fit group
B; mean over all responses in this group
points(yrs, dat$resp[seq_len(n)]) # actual response group A
points(yrs, dat$resp[n+seq_len(n)], col="blue") # actual response group B
## => hmmm... because it is not a factor (?), this does not give an
expected answer,
##    but gam() still correctly figures out that there are two groups


From ron_michael70 at yahoo.com  Tue Oct 29 21:26:43 2013
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Wed, 30 Oct 2013 04:26:43 +0800 (SGT)
Subject: [R] R function to locate Excel sheet?
Message-ID: <1383078403.49158.YahooMailNeo@web190503.mail.sg3.yahoo.com>

Hi,

I am looking for some R function which will tell me, whether a particular sheet in an Excel file (.xlsx/.xls) exists or not. I just need to get some TRUE/FALSE type of answer.

Can somebody give me any pointer if such function exists or not?

Thanks and regards,


From jvadams at usgs.gov  Tue Oct 29 21:26:04 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 29 Oct 2013 15:26:04 -0500
Subject: [R] mapping data to a geographic map of Europe
In-Reply-To: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>
References: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>
Message-ID: <CAN5YmCHnKATgmwohcaHyTbzRSi4vyqcYg-jphxJ7AQ2m-wCbZg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/19d1cab4/attachment.pl>

From gunter.berton at gene.com  Tue Oct 29 21:31:00 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 29 Oct 2013 13:31:00 -0700
Subject: [R] (gam) formula: Why different results for terms being factor
 vs. numeric?
In-Reply-To: <CAM3-Kja0oDJ+koJFPpN404F+uKRWC8iinfVbVhDZH=30atQ2Dg@mail.gmail.com>
References: <CAM3-Kja0oDJ+koJFPpN404F+uKRWC8iinfVbVhDZH=30atQ2Dg@mail.gmail.com>
Message-ID: <CACk-te1b7v8WXD1Ws9DZjsxjwyewmM8n5nSZXGyO5nGxYUW6VA@mail.gmail.com>

Think about it. How can one define a smooth term with a factor???

Further discussion is probably offtopic. Post on
stats.stackexchange.com if it still isn't obvious.

Cheers,
Bert

On Tue, Oct 29, 2013 at 1:16 PM, Marius Hofert
<marius.hofert at math.ethz.ch> wrote:
> Dear expeRts,
>
> If I specify group = as.factor(rep(1:2, each=n)) in the below
> definition of dat, I get the expected behavior I am looking for. I
> wonder why I
> don't get it if group is *not* a factor... My guess was that,
> internally, factors are treated as natural numbers (and this indeed
> seems to be true if you convert the latter to factors [essentially
> meaning changing the levels]), but replacing factors by numeric values
> (as below) does not provide the same answer.
>
> Cheers,
> Marius
>
>
> require(mgcv)
>
> n <- 10
> yrs <- 2000+seq_len(n)
> set.seed(271)
> dat <- data.frame(year  = rep(yrs, 2),
>                   group = rep(1:2, each=n), # *not* a factor
> (as.factor() provides the expected behavior)
>                   resp  = c(seq_len(n)+runif(n), 5+seq_len(n)+runif(n)))
> fit3 <- gam(resp ~ year + group - 1, data=dat)
> plot(yrs, fit3$fitted.values[seq_len(n)], type="l", ylim=range(dat$resp),
>      xlab="Year", ylab="Response") # fit group A; mean over all
> responses in this group
> lines (yrs, fit3$fitted.values[n+seq_len(n)], col="blue") # fit group
> B; mean over all responses in this group
> points(yrs, dat$resp[seq_len(n)]) # actual response group A
> points(yrs, dat$resp[n+seq_len(n)], col="blue") # actual response group B
> ## => hmmm... because it is not a factor (?), this does not give an
> expected answer,
> ##    but gam() still correctly figures out that there are two groups
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From jvadams at usgs.gov  Tue Oct 29 21:31:40 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 29 Oct 2013 15:31:40 -0500
Subject: [R] How to save very large matrix?
In-Reply-To: <F51E600F-39FF-43D0-9F2C-63F3511AD321@gmail.com>
References: <F51E600F-39FF-43D0-9F2C-63F3511AD321@gmail.com>
Message-ID: <CAN5YmCGfp9X0FPsQNNu=Reca_kRwSx6k1HQiLA-379M2Wx-4dA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/1bb488b0/attachment.pl>

From jim at bitwrit.com.au  Tue Oct 29 21:32:02 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 30 Oct 2013 07:32:02 +1100
Subject: [R] mapping data to a geographic map of Europe
In-Reply-To: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>
References: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>
Message-ID: <52701B42.3090200@bitwrit.com.au>

On 10/30/2013 04:02 AM, paladini at trustindata.de wrote:
> Hello,
> I would like to draw a map of Europe. Each country should be colored
> depending on how it scores in an index called GPIndex.
> Say a dark red for real bad countries a light red for those which are
> not so bad, light blue for the fairly good ones and so on up to the
> really good ones in a dark blue.
> I never worked with geographic maps before so I tried library maps but I
> didn't get far,- especially because all examples I found only seem to
> work for the United states. So I'm a bit lost.
> I would be nice if somebody could help me.
>
Hi Claudia,
If you draw a map of Europe something like this:

world.map<-map('world', fill = TRUE,
  col = 1:10,xlim=c(-15,40),ylim=c(37,70))

you have a "col" argument that you can pass the colors you want. What 
you must do is look at the "names" component of "world.map":

$names
   [1] "Denmark"
   [2] "USSR"
   [3] "Italy"
   [4] "Netherlands"
   [5] "Iraq"
...

to get the indices of the countries. Say Denmark was fairly good, USSR 
was fairly bad, and so on. You could then pass colors like this:

col=c("lightblue","lightred",...)

in the call to map for as many countries as you wanted. Pass NA for 
those countries that you don't want to color.

Jim


From r.turner at auckland.ac.nz  Tue Oct 29 21:35:14 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 30 Oct 2013 09:35:14 +1300
Subject: [R] Optimization failed in fitdistr (Weibull distribution)
In-Reply-To: <20E86E70-305F-4C4A-95AA-BAFE294823A0@gmail.com>
References: <1382962027602-4679167.post@n4.nabble.com>
	<20E86E70-305F-4C4A-95AA-BAFE294823A0@gmail.com>
Message-ID: <52701C02.1020009@auckland.ac.nz>

On 10/29/13 19:44, peter dalgaard wrote:


     <SNIP>
> There really is no substitute for knowledge and understanding! Did it not occur to you that the Windspeed column needs to enter into your analysis?

     <SNIP>

Fortune!

     cheers,

     Rolf Turner


From sue.lewis at ed.ac.uk  Tue Oct 29 20:54:36 2013
From: sue.lewis at ed.ac.uk (Sue Lewis)
Date: Tue, 29 Oct 2013 19:54:36 -0000
Subject: [R] Conditional wald statistics in ASRemlR
Message-ID: <001c01ced4e0$b2b03be0$1810b3a0$@ed.ac.uk>

Hi, I'm running a model in ASRemlR and the conditional wald statistics table
is producing groupings for the marginality of some variables (A's B's and
C's in the tables below) that we are struggling to understand. From our
understanding of the model we are fitting and the reference manual, we were
expecting main effects to be grouped together (e.g Maring "A") and the two
way interactions to be grouped together (e.g. Margin "B") and to be marginal
with respect to main effects and then the three-way interactions to be
grouped together (e.g. Margin "C") and to be marginal with respect to
two-way interactions and main effects. However, this doesn't seem to be
happening. For example, the main effect of yr (year - of which there are 2
and is a factor) appears to be given Margin "C",which groups it with a
number of 2-way interactions and the three-way interactions in terms of
marginality. Does anyone have any suggestions as to why is this the case?

I have been told that ASReml has a general algorithm for determining the
groupings which is not fool proof.  Stand-alone ASReml allows you to
redefine the groupings.  What we would like to know is whether those
capabilities exist for the R version, and if not, are there other ways we
can set up the model to get the terms in the appropriate grouping.

 

Thanks so much for any suggestions,

Sue

 

> W1<-wald.asreml(m1.asreml, ssType="conditional")

 

  asreml 3.0 (15 April 2013), Library: 3.0hj (15 November 2011), X86_64

     LogLik         S2      DF      wall     cpu

   -50111.3907      0.0010 51482  09:02:03    15.9

 

> W1$Wald$p<-round(1-pf(W1$Wald[,2], W1$Wald[,1], 90),3)

> W1

$Wald

                                Df           F.inc
F.con                     Margin    p

(Intercept)         1              1772.0000            585100.0
0.000

yr                             1             7.6790                   9030.0
C             0.007

months                5              9.1350                   10790.0
A            0.000

dayc                       1              21.9900                 19780.0
B             0.000

haschicks             1              38.0200                 50740.0
B             0.000

chickagec             1              6.5720                   14020.0
B             0.012

bsc                         1               191.3000             192600.0
B             0.000

sex                          1             0.7405                   742.4
A             0.392

winspc                   1             45.7700                  44840.0
A             0.000

sinwinc                 1              3.4120                   2586.0
A             0.068

rainc                      1              16.4300                 15910.0
A             0.000

months:dayc         5          15.2400                 14320.0
C             0.000

months:sex          5            5.3200                   669.1
B             0.000

haschicks:sex       1           7.7330                   8906.0
C             0.007

chickagec:sex       1           0.2351                   288.6
C             0.629

bsc:sex                  1             1.9470                   1726.0
C             0.166

sex:winspc          1             23.1700                 19900.0
B             0.000

sex:sinwinc         1             12.4700                 5766.0
B             0.001

sex:rainc               1             0.7769                   625.3
B             0.380

months:sex:winspc  10    2.7480                 2258.0                   C
0.005

months:sex:sinwinc 10    2.6850                 1834.0                   C
0.006

months:sex:rainc   10    1.7060                   1706.0                   C
0.091

 

 

 

 

 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Sue Lewis

NERC fellow

Institute of Evolutionary Biology

School of Biological Sciences

University of Edinburgh

Edinburgh, EH9 3JT, UK

 

Email: sue.lewis at ed.ac.uk

Tel: +44 (0)131 6505444

http://lewis.bio.ed.ac.uk <http://lewis.bio.ed.ac.uk/> 

 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

 

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/38802e1a/attachment.pl>

From jvadams at usgs.gov  Tue Oct 29 21:36:06 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 29 Oct 2013 15:36:06 -0500
Subject: [R] R function to locate Excel sheet?
In-Reply-To: <1383078403.49158.YahooMailNeo@web190503.mail.sg3.yahoo.com>
References: <1383078403.49158.YahooMailNeo@web190503.mail.sg3.yahoo.com>
Message-ID: <CAN5YmCEmL-oy0EW7uOi=-yOFDz8bA6=gWMFBP66ti5wXXSRKHg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/d35d0306/attachment.pl>

From djandrija at gmail.com  Tue Oct 29 21:37:44 2013
From: djandrija at gmail.com (andrija djurovic)
Date: Tue, 29 Oct 2013 21:37:44 +0100
Subject: [R] R function to locate Excel sheet?
In-Reply-To: <1383078403.49158.YahooMailNeo@web190503.mail.sg3.yahoo.com>
References: <1383078403.49158.YahooMailNeo@web190503.mail.sg3.yahoo.com>
Message-ID: <CABcwgRRCJFJ9ub0Fr_eL2yPxpVOd+mfTRoSXOyWhLsZsWsEKSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/056a4503/attachment.pl>

From ruipbarradas at sapo.pt  Tue Oct 29 21:42:47 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 29 Oct 2013 20:42:47 +0000
Subject: [R] How to save very large matrix?
In-Reply-To: <F51E600F-39FF-43D0-9F2C-63F3511AD321@gmail.com>
References: <F51E600F-39FF-43D0-9F2C-63F3511AD321@gmail.com>
Message-ID: <52701DC7.8000808@sapo.pt>

Hello,

You can use the argument to write.csv or write.table  append = TRUE to 
write the matrix in chunks. Something like the following.



bigwrite <- function(x, file, rows = 1000L, ...){
	passes <- NROW(x) %/% rows
	remaining <- NROW(x) %% rows
	k <- 1L
	write.table(x[k:rows, ], file, row.names = FALSE, ...)
	k <- k + rows
	for(i in seq_len(passes)[-1]){
		write.table(x[k:(rows*i), ], file, append = TRUE, row.names = FALSE, 
col.names = FALSE, ...)
		k <- k + rows
	}
	if(remaining > 0)
		write.table(x[k:NROW(x), ], file, append = TRUE, row.names = FALSE, 
col.names = FALSE, ...)
}

f <- "temp"
m <- matrix(0, 50012, 10)

bigwrite(m, f, sep = ",")  # Use 'sep' to get a csv file



Hope this helps,

Rui Barradas


Em 29-10-2013 19:27, Petar Milin escreveu:
> Hello!
> I have a very large matrix of results: 50000x100000. I saved it as RDS, but I would also need to save it as txt or csv. Is there a way to do it? Now, with write.table I am receiving an error:
> Error in .External2(C_writetable, x, file, nrow(x), p, rnames, sep, eol,  :
>    long vectors not supported yet: io.c:1116
>
> Please, help! Many thanks!
>
> PM
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From E.Vettorazzi at uke.de  Tue Oct 29 21:47:07 2013
From: E.Vettorazzi at uke.de (Eik Vettorazzi)
Date: Tue, 29 Oct 2013 21:47:07 +0100
Subject: [R] Automatically Remove Aliased Terms from a Model
In-Reply-To: <EDB44DA865211646A192A94DF3C6FA670F72DC54@DEMDCE0057.nestle.com>
References: <EDB44DA865211646A192A94DF3C6FA670F72DC54@DEMDCE0057.nestle.com>
Message-ID: <52701ECB.30101@uke.de>

Hi Thorn,
it is not entirely clear (at least for me) what you want to accomplish.
an easy and fail safe way of extracting used terms in a (g)lm-object is
names(model.frame(l))
if you want to extract terms to finally select a model, have a look at
drop1 and/or MASS::dropterm

Hth

Am 28.10.2013 17:19, schrieb Thaler,Thorn,LAUSANNE,Applied Mathematics:
> Dear all,
> 
> I am trying to implement a function which removes aliased terms from a model. The challenge I am facing is that with "alias" I get the aliased coefficients of the model, which I have to translate into the terms from the model formula. What I have tried so far:
> 
> ------------------8<------------------
> d <- expand.grid(a = 0:1, b=0:1)
> d$c <- (d$a + d$b)  %% 2
> d$y <- rnorm(4)
> d <- within(d, {a <- factor(a); b <- factor(b); c <- factor(c)})
> l <- lm(y ~ a * b + c, d)
> 
> removeAliased <- function(mod) {
>   ## Retrieve all terms in the model
>   X <- attr(mod$terms, "term.label")
>   ## Get the aliased coefficients  
>   rn <- rownames(alias(mod)$Complete)
>   ## remove factor levels from coefficient names to retrieve the terms
>   regex.base <- unique(unlist(lapply(mod$model[, sapply(mod$model, is.factor)], levels)))
>   aliased <- gsub(paste(regex.base, "$", sep = "", collapse = "|"),  "", gsub(paste(regex.base, ":", sep = "", collapse = "|"), ":", rn))
>   uF <- formula(paste(". ~ .", paste(aliased, collapse = "-"), sep = "-"))
>   update(mod, uF)
> }
> 
> removeAliased(l)
> ------------------>8------------------
> 
> This function works in principle, but this workaround with removing the factor levels is just, well, a workaround which could cause problems in some circumstances (when the name of a level matches the end of another variable, when I use a different contrast and R names the coefficients differently etc. - and I am not sure which other cases I am overlooking).
> 
> So my question is whether there are some more intelligent ways of doing what I want to achieve? Is there a function to translate a coefficient of a LM back to the term, something like:
> 
> termFromCoef("a1") ## a1
> termFromCoef("a1:b1") ## a:b
> 
> With this I could simply translate the rownames from alias into the terms needed for the model update.
> 
> Thanks for your help.
> 
> Kind Regards,
> 
> Thorn Thaler 
> NRC Lausanne
> Applied Mathematics
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/7410-58243
F ++49/40/7410-57790
--

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Martin Zeitz (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From smartpink111 at yahoo.com  Tue Oct 29 22:06:55 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 29 Oct 2013 14:06:55 -0700 (PDT)
Subject: [R] Mean error
Message-ID: <1383080815.87521.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try either:
res1 <- apply(mydata[,1:2],2,mean)
?res2 <- colMeans(mydata[,1:2])
?identical(res1,res2)
#[1] TRUE

# Also if you need to find means for each group ("Ungrazed vs. "Grazed")
by(mydata[,-3],mydata[,3],colMeans)

#or if column names are "V1", "V2", "V3"
aggregate(.~V3,mydata,mean)
#or
library(plyr)
?ddply(mydata,.(V3),numcolwise(mean))


A.K.


I have a data set with two columns of data that I want to find the mean of. ? 
1 ? 6.225 ?59.77 Ungrazed 
2 ? 6.487 ?60.98 Ungrazed 
3 ? 4.919 ?14.73 Ungrazed 
4 ? 5.130 ?19.28 Ungrazed 
5 ? 5.417 ?34.25 Ungrazed 
6 ? 5.359 ?35.53 Ungrazed 
7 ? 7.614 ?87.73 Ungrazed 
8 ? 6.352 ?63.21 Ungrazed 
9 ? 4.975 ?24.25 Ungrazed 
10 ?6.930 ?64.34 Ungrazed 
11 ?6.248 ?52.92 Ungrazed 
12 ?5.451 ?32.35 Ungrazed 
13 ?6.013 ?53.61 Ungrazed 
14 ?5.928 ?54.86 Ungrazed 
15 ?6.264 ?64.81 Ungrazed 
16 ?7.181 ?73.24 Ungrazed 
17 ?7.001 ?80.64 Ungrazed 
18 ?4.426 ?18.89 Ungrazed 
19 ?7.302 ?75.49 Ungrazed 
20 ?5.836 ?46.73 Ungrazed 
21 10.253 116.05 Ungrazed 
22 ?6.958 ?38.94 ? Grazed 
23 ?8.001 ?60.77 ? Grazed 
24 ?9.039 ?84.37 ? Grazed 
25 ?8.910 ?70.11 ? Grazed 
26 ?6.106 ?14.95 ? Grazed 
27 ?7.691 ?70.70 ? Grazed 
28 ?8.988 ?80.31 ? Grazed 
29 ?8.975 ?82.35 ? Grazed 
30 ?9.844 105.07 ? Grazed 
31 ?8.508 ?73.79 ? Grazed 
32 ?7.354 ?50.08 ? Grazed 
33 ?8.643 ?78.28 ? Grazed 
34 ?7.916 ?41.48 ? Grazed 
35 ?9.351 ?98.47 ? Grazed 
36 ?7.066 ?40.15 ? Grazed 
37 ?8.158 ?52.26 ? Grazed 
38 ?7.382 ?46.64 ? Grazed 
39 ?8.515 ?71.01 ? Grazed 
40 ?8.530 ?83.03 ? Grazed 

This is from an introduction handout that instructs me to enter the command 
>mean(mydata[,1:2]) 
but when I enter it, I get an error message 
Warning message: 
In mean.default(mydata[, 1:2]) : 
? argument is not numeric or logical: returning NA 
I've tried tacking on na.rm=T to the end of it, but I get the same 
message. Can someone tell me what I'm doing wrong, or how to fix it? 

I've tried searching the forum, but can't find a post relevant to this problem.


From ripley at stats.ox.ac.uk  Tue Oct 29 22:16:50 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 29 Oct 2013 21:16:50 +0000
Subject: [R] How to save very large matrix?
In-Reply-To: <52701DC7.8000808@sapo.pt>
References: <F51E600F-39FF-43D0-9F2C-63F3511AD321@gmail.com>
	<52701DC7.8000808@sapo.pt>
Message-ID: <527025C2.6050409@stats.ox.ac.uk>

On 29/10/2013 20:42, Rui Barradas wrote:
> Hello,
>
> You can use the argument to write.csv or write.table  append = TRUE to
> write the matrix in chunks. Something like the following.

That was going to be my suggestion. But the reason long vectors have not 
been implemented is that is rather implausible to be useful.   A text 
file with the values of such a numeric matrix is likely to be 100GB. 
What are you going to do with such a file?  For transfer to another 
program I would seriously consider a binary format (e.g. use writeBin), 
as it is the conversion to and from text that is time consuming.

Some experiments suggest that it would take hours to write and at least 
an hour to read such a file[*], on a very fast machine with a 
start-of-the-art SSD.

[*] a file with reasonable-precision real numbers, not zeroes.

>
>
>
> bigwrite <- function(x, file, rows = 1000L, ...){
>      passes <- NROW(x) %/% rows
>      remaining <- NROW(x) %% rows
>      k <- 1L
>      write.table(x[k:rows, ], file, row.names = FALSE, ...)
>      k <- k + rows
>      for(i in seq_len(passes)[-1]){
>          write.table(x[k:(rows*i), ], file, append = TRUE, row.names =
> FALSE, col.names = FALSE, ...)
>          k <- k + rows
>      }
>      if(remaining > 0)
>          write.table(x[k:NROW(x), ], file, append = TRUE, row.names =
> FALSE, col.names = FALSE, ...)
> }
>
> f <- "temp"
> m <- matrix(0, 50012, 10)
>
> bigwrite(m, f, sep = ",")  # Use 'sep' to get a csv file
>
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> Em 29-10-2013 19:27, Petar Milin escreveu:
>> Hello!
>> I have a very large matrix of results: 50000x100000. I saved it as
>> RDS, but I would also need to save it as txt or csv. Is there a way to
>> do it? Now, with write.table I am receiving an error:
>> Error in .External2(C_writetable, x, file, nrow(x), p, rnames, sep,
>> eol,  :
>>    long vectors not supported yet: io.c:1116
>>
>> Please, help! Many thanks!
>>
>> PM


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pmilin at gmail.com  Tue Oct 29 22:34:03 2013
From: pmilin at gmail.com (Petar Milin)
Date: Tue, 29 Oct 2013 22:34:03 +0100
Subject: [R] How to save very large matrix?
In-Reply-To: <527025C2.6050409@stats.ox.ac.uk>
References: <F51E600F-39FF-43D0-9F2C-63F3511AD321@gmail.com>
	<52701DC7.8000808@sapo.pt> <527025C2.6050409@stats.ox.ac.uk>
Message-ID: <99C95D6B-E53A-4EB0-B1E2-87E54700D546@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/ca1baa50/attachment.pl>

From ron_michael70 at yahoo.com  Tue Oct 29 22:55:21 2013
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Wed, 30 Oct 2013 05:55:21 +0800 (SGT)
Subject: [R] Can not read Excel file correctly
Message-ID: <1383083721.52026.YahooMailNeo@web190501.mail.sg3.yahoo.com>

Hi,

I need to read an Excel file which can be available in following link:
http://www45.zippyshare.com/v/43626889/file.html

Now I wanted to read the 1st sheet of this Excel file. Below are my code so far (I saved that file in 'F:' drive):

> library(XLConnect)
Loading required package: rJava
XLConnect 0.2-5 by Mirai Solutions GmbH
http://www.mirai-solutions.com ,
http://miraisolutions.wordpress.com
> readWorksheetFromFile("f:/Dat1.xlsx", sheet = 1)
? ? ? ? Col1 ? ? ? ? ? ? Col2 ? ? ? Col3 ? Col4
1 ? ? ? <NA> ? ? ? ? ? ? ? NA 2013-05-01 ? <NA>
2 ? ? ? <NA> ? ? ? ? ? ? ? NA ? ? ? <NA> ? <NA>
3 1930-01-01 ? ? ? ? ? ? ? NA ? ? ? <NA> ? <NA>
4 ? ? ? <NA> 3127312736128730 ? ? ? <NA> ? <NA>
5 ? ? ? <NA> ? ? ? ? ? ? ? NA ? ? ? <NA> ? <NA>
6 ? ? ? <NA> ? ? ? ? ? ? ? NA ? ? ? <NA> SAsSag


What I saw that, the element in A1 cell is missing. Also the data in C1 & A4 are read in different format. In Excel file, it is Month-Year format, however what I see is Year-Month-Day format.

I have many such files, therefore I do not want to convert them to csv (or any other). Doing so will be cumbersome.

Can somebody here help me how to read that file in proper format?

Thanks for your time.


From hpages at fhcrc.org  Wed Oct 30 00:14:13 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 29 Oct 2013 16:14:13 -0700
Subject: [R] How to save very large matrix?
In-Reply-To: <99C95D6B-E53A-4EB0-B1E2-87E54700D546@gmail.com>
References: <F51E600F-39FF-43D0-9F2C-63F3511AD321@gmail.com>	<52701DC7.8000808@sapo.pt>
	<527025C2.6050409@stats.ox.ac.uk>
	<99C95D6B-E53A-4EB0-B1E2-87E54700D546@gmail.com>
Message-ID: <52704145.9030207@fhcrc.org>

Hi Petar,

If you're going to share this matrix across R sessions, save()/load() is
probably one of your best options.

Otherwise, you could try the rhdf5 package from Bioconductor:

1. Install the package with:

      source("http://bioconductor.org/biocLite.R")
      biocLite("rhdf5")

2. Then:

      library(rhdf5)

      h5createFile("my_big_matrix.h5")

      # write a matrix
      my_big_matrix <- matrix(runif(5000*10000), nrow=5000)
      attr(my_big_matrix, "scale") <- "liter"
      h5write(my_big_matrix, "my_big_matrix.h5", "my_big_matrix")  # 
takes 1 min.
      # file size on disk is 248M

      # read a matrix
      my_big_matrix <- h5read("my_big_matrix.h5", "my_big_matrix")  # 
takes 7.4 sec.

Multiply the above numbers (obtained on a laptop with a traditional
hard drive) by 100 for your monster matrix, or less if you have super
fast I/O.

2 advantages of using the HDF5 format: (1) should not be too hard to use
the HDF5 C library in the C code you're going to use to read the matrix,
and (2) my understanding is that HDF5 is good at letting you access
arbitrary slices of the data so chunk-processing should be easy and
efficient:

   http://www.hdfgroup.org/HDF5/

Cheers,
H.


On 10/29/2013 02:34 PM, Petar Milin wrote:
> Hello,
>
> On Oct 29, 2013, at 10:16 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
>> On 29/10/2013 20:42, Rui Barradas wrote:
>>> Hello,
>>>
>>> You can use the argument to write.csv or write.table  append = TRUE to
>>> write the matrix in chunks. Something like the following.
>>
>> That was going to be my suggestion. But the reason long vectors have not been implemented is that is rather implausible to be useful.   A text file with the values of such a numeric matrix is likely to be 100GB. What are you going to do with such a file?  For transfer to another program I would seriously consider a binary format (e.g. use writeBin), as it is the conversion to and from text that is time consuming.
>
> I need to submit it to a cluster analysis (k-means). From an independent source I have been advised to use means algorithm written in C which is very fast and efficient. It asks for a txt file as an input.
>
> I tried few options in R, where I am more comfortable, but solution never came, even after too many hours.
>
> Thanks!
> Best,
> PM
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From joseclaudio.faria at gmail.com  Wed Oct 30 00:42:47 2013
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Tue, 29 Oct 2013 21:42:47 -0200
Subject: [R] deparse: replacing all " by \"
Message-ID: <CAN+Emd-FHk3q4+GQagk=rqj9DobB-gcawKgGNq5o3fW6JqOw7g@mail.gmail.com>

Dear list,

I need to use the function "deparse" in a specific situation.
But, it always replace any occurence of " by \".

For example:

> arg <- deparse(args(cov), width.cutoff = 100L)[1]

> arg
[1] "function (x, y = NULL, use = \"everything\", method =
c(\"pearson\", \"kendall\", \"spearman\")) "

Some characters added by deparse are not desirable: \ before all " and
final space.

How is the best way to get the result (using deparse) clean like below?
[1] "function (x, y = NULL, use = "everything", method = c("pearson",
"kendall", "spearman"))"

Any help is welcome!

Best,
-- 
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)9100.7351 - TIM
55(73)8817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\


From murdoch.duncan at gmail.com  Wed Oct 30 00:54:33 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 29 Oct 2013 19:54:33 -0400
Subject: [R] deparse: replacing all " by \"
In-Reply-To: <CAN+Emd-FHk3q4+GQagk=rqj9DobB-gcawKgGNq5o3fW6JqOw7g@mail.gmail.com>
References: <CAN+Emd-FHk3q4+GQagk=rqj9DobB-gcawKgGNq5o3fW6JqOw7g@mail.gmail.com>
Message-ID: <52704AB9.3000209@gmail.com>

On 13-10-29 7:42 PM, Jose Claudio Faria wrote:
> Dear list,
>
> I need to use the function "deparse" in a specific situation.
> But, it always replace any occurence of " by \".

No it doesn't.  That's just how print() displays quotes.  Use cat() and 
you can see what's really there.

Duncan Murdoch

>
> For example:
>
>> arg <- deparse(args(cov), width.cutoff = 100L)[1]
>
>> arg
> [1] "function (x, y = NULL, use = \"everything\", method =
> c(\"pearson\", \"kendall\", \"spearman\")) "
>
> Some characters added by deparse are not desirable: \ before all " and
> final space.
>
> How is the best way to get the result (using deparse) clean like below?
> [1] "function (x, y = NULL, use = "everything", method = c("pearson",
> "kendall", "spearman"))"
>
> Any help is welcome!
>
> Best,
>


From tuechler at gmx.at  Wed Oct 30 01:00:24 2013
From: tuechler at gmx.at (Heinz Tuechler)
Date: Wed, 30 Oct 2013 01:00:24 +0100
Subject: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
Message-ID: <52704C18.6020905@gmx.at>

Dear All,

is it known that source works much faster in  R 2.15.2 than in R 3.0.2 ?
In the example below I observe e.g. for a data.frame with 10^7 rows the 
following timings:

R version 2.15.2 Patched (2012-11-29 r61184)
length: 1e+07
    user  system elapsed
   62.04    0.22   62.26

R version 3.0.2 Patched (2013-10-27 r64116)
length: 1e+07
    user  system elapsed
  388.63  176.42  566.41

Is there a way to speed R version 3.0.2 up to the performance of R 
version 2.15.2?

best regards,

Heinz T?chler


example:
sessionInfo()
sample.vec <-
   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from', 'the',
     'named', 'file', 'or', 'URL', 'or', 'connection')
dmp.size <- c(10^(1:7))
set.seed(37)

for(i in dmp.size) {
   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
   dump('df0', file='testdump')
   cat('length:', i, '\n')
   print(system.time(source('testdump', keep.source = FALSE,
                            encoding='')))
}

output for R version 2.15.2 Patched (2012-11-29 r61184):
> sessionInfo()
R version 2.15.2 Patched (2012-11-29 r61184)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
[3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
[5] LC_TIME=German_Switzerland.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> sample.vec <-
+   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from', 
'the',
+     'named', 'file', 'or', 'URL', 'or', 'connection')
> dmp.size <- c(10^(1:7))
> set.seed(37)
>
> for(i in dmp.size) {
+   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
+   dump('df0', file='testdump')
+   cat('length:', i, '\n')
+   print(system.time(source('testdump', keep.source = FALSE,
+                            encoding='')))
+ }
length: 10
    user  system elapsed
       0       0       0
length: 100
    user  system elapsed
       0       0       0
length: 1000
    user  system elapsed
       0       0       0
length: 10000
    user  system elapsed
    0.02    0.00    0.01
length: 1e+05
    user  system elapsed
    0.21    0.00    0.20
length: 1e+06
    user  system elapsed
    4.47    0.04    4.51
length: 1e+07
    user  system elapsed
   62.04    0.22   62.26
>


output for R version 3.0.2 Patched (2013-10-27 r64116):
> sessionInfo()
R version 3.0.2 Patched (2013-10-27 r64116)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
[3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
[5] LC_TIME=German_Switzerland.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> sample.vec <-
+   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from', 
'the',
+     'named', 'file', 'or', 'URL', 'or', 'connection')
> dmp.size <- c(10^(1:7))
> set.seed(37)
>
> for(i in dmp.size) {
+   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
+   dump('df0', file='testdump')
+   cat('length:', i, '\n')
+   print(system.time(source('testdump', keep.source = FALSE,
+                            encoding='')))
+ }
length: 10
    user  system elapsed
       0       0       0
length: 100
    user  system elapsed
       0       0       0
length: 1000
    user  system elapsed
       0       0       0
length: 10000
    user  system elapsed
    0.01    0.00    0.01
length: 1e+05
    user  system elapsed
    0.36    0.06    0.42
length: 1e+06
    user  system elapsed
    6.02    1.86    7.88
length: 1e+07
    user  system elapsed
  388.63  176.42  566.41
>



-- 
Heinz T?chler +4317146261 / +436605653878


From 538280 at gmail.com  Wed Oct 30 01:28:27 2013
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 29 Oct 2013 18:28:27 -0600
Subject: [R] Use correlation matrix to get values for a new data frame
In-Reply-To: <81F84997-4AE8-4EDD-AE43-9EA2B0BB779E@me.com>
References: <81F84997-4AE8-4EDD-AE43-9EA2B0BB779E@me.com>
Message-ID: <CAFEqCdw7PdUSuW2-1wOV8fsEQzcLcEuETy1zNQWGOWNa3O1hfg@mail.gmail.com>

I am not sure that I fully understand your question, but the mvrnorm
function in the MASS package may do what you want.  It will generate
multivariate normal data with a specified correlation(covariance).  If
that is not what you want then try to explain a bit more about what
you want your final result to be.

On Sun, Oct 27, 2013 at 2:46 PM, tobias schlager <tobebryant at me.com> wrote:
> Dear all,
>
> i am a bit stuck with a problem right now. Specifically, I have a correlation matrix, and a dataframe on which I want to project the values. However, I am not sure how I can do this.
> Here the calculations I made, I wanted to get a matrix that shows the values for each of the combinations of the ten variables in ?d", so the new data is ?newdat?. How might this be possible?
>
> Thanks a lot,
> Tobi
>
>
> x1  <- c(1,0,0,1,0,1,0,0,0,0)
> x2  <- c(0,1,0,0,0,1,0,0,0,1)
> x3  <- c(0,0,1,0,1,0,1,0,0,0)
> x4  <- c(1,0,0,1,0,0,0,0,1,0)
> x5  <- c(0,0,1,0,1,0,0,1,0,1)
> x6  <- c(1,1,0,0,0,1,0,0,0,0)
> x7  <- c(0,0,1,0,0,0,1,1,0,0)
> x8  <- c(0,0,0,0,1,0,1,1,0,0)
> x9  <- c(0,0,0,1,0,0,0,0,1,0)
> x10 <- c(0,1,0,0,1,0,0,0,0,1)
>
> x1c  <- ifelse(x1==1,  runif(4, -1, 1), 0);
> x2c  <- ifelse(x2==1,  runif(4, -1, 1), 0);
> x3c  <- ifelse(x3==1,  runif(4, -1, 1), 0);
> x4c  <- ifelse(x4==1,  runif(4, -1, 1), 0);
> x5c  <- ifelse(x5==1,  runif(4, -1, 1), 0);
> x6c  <- ifelse(x6==1,  runif(4, -1, 1), 0);
> x7c  <- ifelse(x7==1,  runif(4, -1, 1), 0);
> x8c  <- ifelse(x8==1,  runif(4, -1, 1), 0);
> x9c  <- ifelse(x9==1,  runif(4, -1, 1), 0);
> x10c <- ifelse(x10==1, runif(4, -1, 1), 0);
>
> c <- cbind(x1c,x2c,x3c,x4c,x5c,x6c,x7c,x8c,x9c,x10c); c
>
> c <- data.frame(c)
> c[1,1] <- 1; c[2,2] <- 1; c[3,3] <- 1; c[4,4] <- 1; c[5,5] <- 1; c[6,6] <- 1; c[7,7] <- 1; c[8,8] <- 1; c[9,9] <- 1; c[10,10] <- 1;
>
> # get symmetry
> c[2,1]  <-c[1,2]; c[3,1]  <-c[1,3]; c[4,1]  <-c[1,4]; c[5,1]  <-c[1,5]; c[6,1]  <-c[1,6]; c[7,1]  <-c[1,7]; c[8,1]  <-c[1,8]; c[9,1]  <-c[1,9]; c[10,1] <-c[1,10];
> c[3,2]  <-c[2,3]; c[4,2]  <-c[2,4]; c[5,2]  <-c[2,5]; c[6,2]  <-c[2,6]; c[7,2]  <-c[2,7]; c[8,2]  <-c[2,8]; c[9,2]  <-c[2,9]; c[10,2] <-c[2,10];
> c[4,3]  <-c[3,4]; c[5,3]  <-c[3,5]; c[6,3]  <-c[3,6]; c[7,3]  <-c[3,7]; c[8,3]  <-c[3,8]; c[9,3]  <-c[3,9]; c[10,3] <-c[3,10];
> c[5,4]  <-c[4,5]; c[6,4]  <-c[4,6]; c[7,4]  <-c[4,7]; c[8,4]  <-c[4,8]; c[9,4]  <-c[4,9]; c[10,4] <-c[4,10];
> c[6,5]  <-c[5,6]; c[7,5]  <-c[5,7]; c[8,5]  <-c[5,8]; c[9,5]  <-c[5,9]; c[10,5] <-c[5,10];
> c[7,6]  <-c[6,7]; c[8,6]  <-c[6,8]; c[9,6]  <-c[6,9]; c[10,6] <-c[6,10];
> c[8,7]  <-c[7,8]; c[9,7]  <-c[7,9]; c[10,7] <-c[7,10];
> c[9,8]  <-c[8,9]; c[10,8] <-c[8,10];
> c[10,9] <-c[9,10];
>
> d <- c (c[,1], c[,2], c[,3],c[,4],c[,5],c[,6],c[,7],c[,8],c[,9],c[,10])
>
>
> newdat <- expand.grid(x1c=c(1,0),x2c=c(1,0),x3c=c(1,0),x4c=c(1,0),x5c=c(1,0),x6c=c(1,0),x7c=c(1,0),x8c=c(1,0),x9c=c(1,0),x10c=c(1,0))
>
> ____________________________
> Dr. Tobias Schlager
> Projektleiter
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From alaios at yahoo.com  Wed Oct 30 02:34:33 2013
From: alaios at yahoo.com (Alaios)
Date: Tue, 29 Oct 2013 18:34:33 -0700 (PDT)
Subject: [R] add a color bar in a plot
Message-ID: <1383096873.6076.YahooMailNeo@web125306.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/fd53563d/attachment.pl>

From smartpink111 at yahoo.com  Wed Oct 30 04:22:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 29 Oct 2013 20:22:08 -0700 (PDT)
Subject: [R] "merging" rows that share columns (but not all of them)
Message-ID: <1383103328.37699.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
May be this helps.? 
library(plyr)
res <-? join_all(lapply(my.list,function(x) as.data.frame(t(unlist(x)))),type="full")

?res
#????? AICc? Intercept?? Burned?? StandAge TreeDensity RoadDensity Intercept.SE
#1 108.2303 -1.3358063 1.351866 0.05606852? -0.1886327 -0.03904008??? 0.8392739
#2 207.4494? 0.1749414?????? NA???????? NA????????? NA????????? NA??? 0.1644731
?# Burned.SE StandAge.SE TreeDensity.SE RoadDensity.SE
#1 0.5440936 0.009632702???? 0.03885338???? 0.02995221
#2??????? NA????????? NA???????????? NA???????????? NA


A.K.


Hi, 

I have a list where the columns are generally subsets of a full 
set of columns. ?Below is an example where the 1st vector in the list 
has the full set of columns and the 2nd has a very reduced set of those 
columns. ?What is a good way to "merge" these lists together so that the
 resulting data.frame has all of the columns and either blanks or NA's 
(whatever) in the empty elements for the reduced set? 

Hopefully that makes sense, and I thank you ahead of time for any suggestions. 
Chuck 


my.list <- ?dput( list(out.j[[4]], out.j[[5]]) ) 
list(list(structure(c(108.230267668738, -1.33580630289532, 1.35186573380126, 
0.0560685186378393, -0.188632664093942, -0.0390400817030916, 
0.839273914449761, 0.544093628209087, 0.00963270189999436, 0.038853380878141, 
0.0299522140838543), .Names = c("AICc", "Intercept", "Burned", 
"StandAge", "TreeDensity", "RoadDensity", "Intercept.SE", "Burned.SE", 
"StandAge.SE", "TreeDensity.SE", "RoadDensity.SE"))), structure(c(207.449399095215, 
0.174941449287965, 0.164473092811635), .Names = c("AICc", "Intercept", 
"Intercept.SE"))) 



From schandra at greatbridgecorp.com  Wed Oct 30 01:39:52 2013
From: schandra at greatbridgecorp.com (Sashikanth Chandrasekaran)
Date: Tue, 29 Oct 2013 17:39:52 -0700
Subject: [R] Fitting multiple horizontal lines to data
Message-ID: <CABsq69b34goC+pveW6yscwbVKJBdMYxzppTLWauA3gZKzcLSPA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/569e05c3/attachment.pl>

From erinm.hodgess at gmail.com  Wed Oct 30 05:06:56 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 29 Oct 2013 23:06:56 -0500
Subject: [R]  rpy2 and user defined functions from R
Message-ID: <CACxE24nOJK9jdGiAOW65edrpTUHihjJfBVGNBW73=CUr=GnAOg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131029/92e4fc65/attachment.pl>

From alaios at yahoo.com  Wed Oct 30 09:14:36 2013
From: alaios at yahoo.com (Alaios)
Date: Wed, 30 Oct 2013 01:14:36 -0700 (PDT)
Subject: [R] Select fixed number of elements
Message-ID: <1383120876.53829.YahooMailNeo@web125303.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/6a6011d1/attachment.pl>

From fei0315 at gmail.com  Wed Oct 30 09:38:01 2013
From: fei0315 at gmail.com (hsin-fei tu)
Date: Wed, 30 Oct 2013 16:38:01 +0800
Subject: [R] cannot coerce class ""function"" to a data.frame
Message-ID: <CAEnG10Ekwbxchiwyjudsa6RO=BhpRKruYjRwYjb6ZMtL8cWFtQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/1ea77bc9/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Wed Oct 30 09:41:02 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 30 Oct 2013 09:41:02 +0100 (MET)
Subject: [R] Select fixed number of elements
In-Reply-To: <1383120876.53829.YahooMailNeo@web125303.mail.ne1.yahoo.com>
References: <1383120876.53829.YahooMailNeo@web125303.mail.ne1.yahoo.com>
Message-ID: <Pine.SOC.4.64.1310300935510.209@solcom.hrz.uni-giessen.de>

Hello, Alaois,

if x is your vector maybe

n <- length( x)
positions <- trunc( quantile( seq( n), prob = 0:5/5))
x[ positions]

comes close to what you want.

  Hth  --  Gerrit

> Hi all, I have in my code some vectors that are not of equal size. I 
> would like to be able for each of these vectors select 6 elements that 
> are (almost) equally spaced. So the first one would be at (or close) to 
> the beginning the last one at (or close) to the end and the other 4 
> equally spaced between first and last element.
>
> How can I do something like that on a vector of not known size?
>
> I would like to thank you in advance for your help
>
> Regards
> Alex
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ken.knoblauch at inserm.fr  Wed Oct 30 09:52:00 2013
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Wed, 30 Oct 2013 08:52:00 +0000
Subject: [R] Select fixed number of elements
References: <1383120876.53829.YahooMailNeo@web125303.mail.ne1.yahoo.com>
Message-ID: <loom.20131030T094829-218@post.gmane.org>

Alaios <alaios <at> yahoo.com> writes:

> I have in my code some vectors that are not of equal size. 
I would like to be able for each of these vectors
> select 6 elements that are (almost) equally spaced. 
So the first one would be at (or close) to the beginning
> the last one at (or close) to the end and the other 4 
equally spaced between first and last element.
> 
> How can I do something like that on a vector of
 not known size?
> 
> I would like to thank you in advance 
for your help
Would something like this be what you are
looking for?

N <- 20
set.seed(16121952)
x <- runif(N)
x
rx <- range(x)
br <- seq(rx[1], rx[2], len = 6)
sapply(br, function(bx){
	x[which.min(abs(x - bx))]
})

[1] 0.02910779 0.22708582 0.39239718 
     0.52419265 0.68940262 0.86889817

> 
> Regards
> Alex

-- 
Kenneth Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From jholtman at gmail.com  Wed Oct 30 09:56:15 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Wed, 30 Oct 2013 04:56:15 -0400
Subject: [R] cannot coerce class ""function"" to a data.frame
In-Reply-To: <CAEnG10Ekwbxchiwyjudsa6RO=BhpRKruYjRwYjb6ZMtL8cWFtQ@mail.gmail.com>
References: <CAEnG10Ekwbxchiwyjudsa6RO=BhpRKruYjRwYjb6ZMtL8cWFtQ@mail.gmail.com>
Message-ID: <AB1D8E68-C590-4733-86EE-69435F6782DD@gmail.com>

you never defined "data" and "data" is a function in the "base".

type in "data" just before "merge" and see what is output (debuggung 101)

Sent from my iPad

On Oct 30, 2013, at 4:38, hsin-fei tu <fei0315 at gmail.com> wrote:

> Hello?
> 
> I use the "egonet" function and have a problem
> 
> idx <- sapply(mats,index.egonet)
> 
> idx <- as.data.frame(t(idx))
> 
> idx <- cbind(idx,filename=rownames(idx))
> 
> data <- merge(data,idx,by="filename")
> 
> 
> 
> cannot coerce class ""function"" to a data.frame
> 
> 
> can someone please help me with this problm?
> 
> 
> Thank you!!
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From katherine_gobin at yahoo.com  Wed Oct 30 09:59:03 2013
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Wed, 30 Oct 2013 16:59:03 +0800 (SGT)
Subject: [R] Yield to maturity in R
Message-ID: <1383123543.17795.YahooMailNeo@web193202.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/85dcbc55/attachment.pl>

From dan.abner99 at gmail.com  Wed Oct 30 12:07:33 2013
From: dan.abner99 at gmail.com (Dan Abner)
Date: Wed, 30 Oct 2013 07:07:33 -0400
Subject: [R] Subtotals by id for a large number of columns XXXX
Message-ID: <CAPRGo-=jnn6Jq_aP0nSwOcajfeqN132y64coC51Mpq3RQWiTRQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/800c361c/attachment.pl>

From alaios at yahoo.com  Wed Oct 30 12:51:41 2013
From: alaios at yahoo.com (Alaios)
Date: Wed, 30 Oct 2013 04:51:41 -0700 (PDT)
Subject: [R] Select fixed number of elements
In-Reply-To: <Pine.SOC.4.64.1310300935510.209@solcom.hrz.uni-giessen.de>
References: <1383120876.53829.YahooMailNeo@web125303.mail.ne1.yahoo.com>
	<Pine.SOC.4.64.1310300935510.209@solcom.hrz.uni-giessen.de>
Message-ID: <1383133901.35890.YahooMailNeo@web125303.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/d21d5e1b/attachment.pl>

From ruipbarradas at sapo.pt  Wed Oct 30 13:01:20 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 30 Oct 2013 12:01:20 +0000
Subject: [R] Subtotals by id for a large number of columns XXXX
In-Reply-To: <CAPRGo-=jnn6Jq_aP0nSwOcajfeqN132y64coC51Mpq3RQWiTRQ@mail.gmail.com>
References: <CAPRGo-=jnn6Jq_aP0nSwOcajfeqN132y64coC51Mpq3RQWiTRQ@mail.gmail.com>
Message-ID: <5270F510.1000609@sapo.pt>

Hello,

If I understand it correctly, just change mysum to the following.


mysum<-function(x) tapply(x,d1$id,sum)


Hope this helps,

Rui Barradas

Em 30-10-2013 11:07, Dan Abner escreveu:
> Hi everybody,
>
> I have data in the format of the example data below where essentially a
> large number of indicator variables (coded [0,1]) reflect traits of the
> same id across multiple rows. I need to represent the data in a 1 row per
> id format. I see this as being similar to converting from long to wide
> format, however, there is no time component here: The multiple rows here
> are all characteristics observed at the same measurement occasion. So,
> really I just need an individual sum for each variable (for a large number
> of variables) and for these to be all saved in the same row (along with the
> id variable and other demographics (e.g., "location").
>
> Here is the example df and the method I used first:
>
>
> d1<-data.frame(id=c(1,1,1,2,2,2,2,3,3,4),location=factor(c(rep(0,7),rep(1,3)),
>   labels=c("A","B")),var1=as.logical(round(runif(10))),
>   var2=as.logical(round(runif(10))),var3=as.logical(round(runif(10))))
> d1
> mysum<-function(x) aggregate(x,by=list(d1$id),sum)
> d2<-sapply(d1[2:4],mysum)
> d2
>
> Any help is appreciated!!
>
> Thanks!
>
> Dan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From michael.weylandt at gmail.com  Wed Oct 30 13:01:41 2013
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Wed, 30 Oct 2013 08:01:41 -0400
Subject: [R] rpy2 and user defined functions from R
In-Reply-To: <CACxE24nOJK9jdGiAOW65edrpTUHihjJfBVGNBW73=CUr=GnAOg@mail.gmail.com>
References: <CACxE24nOJK9jdGiAOW65edrpTUHihjJfBVGNBW73=CUr=GnAOg@mail.gmail.com>
Message-ID: <B92AF2D5-CB5D-4542-B36C-59451AC708DB@gmail.com>

Presumably you need to define 'buzz' first, but I don't see evidence that you've done so. 

Michael

On Oct 30, 2013, at 0:06, Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> Hello again!
> 
> I'm using python with a module rpy2 to call functions from R.
> 
> It works fine on built in R functions like rnorm.
> 
> However, I would like to access user-defined functions as well.  For those
> of you who use this, I have:
> 
> import rpy2.robjects as R
> x = R.r.buzz(3)
> R object as no attribute buzz
> 
> (user defined function of buzz)
> 
> This is on a Centos 5 machine with R-3.0.2 and python of 2.7.5.
> 
> Thanks for any help.
> Sincerely,
> Erin
> 
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msuzen at gmail.com  Wed Oct 30 13:02:31 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Wed, 30 Oct 2013 13:02:31 +0100
Subject: [R] Revo R for Arima Implementation
In-Reply-To: <fb7ea8f3506e4058b25a8f0fe693b909@HKNPR04MB083.apcprd04.prod.outlook.com>
References: <d7923fdac82a40a28fbfc92ae373318a@HKNPR04MB083.apcprd04.prod.outlook.com>
	<526AD3C5.6070207@auckland.ac.nz>
	<fb7ea8f3506e4058b25a8f0fe693b909@HKNPR04MB083.apcprd04.prod.outlook.com>
Message-ID: <CAPtbhHznotvRLki-ZwZoJPh0y5gF0vThq4fxhx8zdReOqWFpsg@mail.gmail.com>

On 28 October 2013 14:26, Anindita Chattopadhyay
<Anindita.C at mu-sigma.com> wrote:
> We need to understand how we can implement this in Revo R.

Most of the people here contribute to community of R not Revo R. I
think it is unfair of you to request from this list to solve your Revo
R issue.


From carl at witthoft.com  Wed Oct 30 13:22:51 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Wed, 30 Oct 2013 05:22:51 -0700 (PDT)
Subject: [R] Fitting multiple horizontal lines to data
In-Reply-To: <CABsq69b34goC+pveW6yscwbVKJBdMYxzppTLWauA3gZKzcLSPA@mail.gmail.com>
References: <CABsq69b34goC+pveW6yscwbVKJBdMYxzppTLWauA3gZKzcLSPA@mail.gmail.com>
Message-ID: <1383135771884-4679345.post@n4.nabble.com>

Your question doesn't make much sense if you really believe that the best fit
is to draw a horizontal line at every unique value of y.   What is the
actual problem you are trying to solve?   Clearly it's not a matter of
linear fits, so forget about using "lm" or other regression tools. 



--
View this message in context: http://r.789695.n4.nabble.com/Fitting-multiple-horizontal-lines-to-data-tp4679324p4679345.html
Sent from the R help mailing list archive at Nabble.com.


From dan.abner99 at gmail.com  Wed Oct 30 13:24:24 2013
From: dan.abner99 at gmail.com (Dan Abner)
Date: Wed, 30 Oct 2013 08:24:24 -0400
Subject: [R] Subtotals by id for a large number of columns XXXX
In-Reply-To: <5270F510.1000609@sapo.pt>
References: <CAPRGo-=jnn6Jq_aP0nSwOcajfeqN132y64coC51Mpq3RQWiTRQ@mail.gmail.com>
	<5270F510.1000609@sapo.pt>
Message-ID: <CAPRGo-nvFp81DmgMokJnmyFFghegHZcmTDz60Uv8bH5qSGQUtw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/a3b41d5c/attachment.pl>

From carl at witthoft.com  Wed Oct 30 13:28:47 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Wed, 30 Oct 2013 05:28:47 -0700 (PDT)
Subject: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
In-Reply-To: <52704C18.6020905@gmx.at>
References: <52704C18.6020905@gmx.at>
Message-ID: <1383136127835-4679346.post@n4.nabble.com>

Did you run the identical code on the identical machine, and did you verify
there were no other tasks running which might have limited the RAM available
to R?  And equally important, did you run these tests in the reverse order
(in case R was storing large objects from the first run, thus chewing up
RAM)?



Dear All,

is it known that source works much faster in  R 2.15.2 than in R 3.0.2 ?
In the example below I observe e.g. for a data.frame with 10^7 rows the 
following timings:

R version 2.15.2 Patched (2012-11-29 r61184)
length: 1e+07
    user  system elapsed
   62.04    0.22   62.26

R version 3.0.2 Patched (2013-10-27 r64116)
length: 1e+07
    user  system elapsed
  388.63  176.42  566.41

Is there a way to speed R version 3.0.2 up to the performance of R 
version 2.15.2?

best regards,

Heinz T?chler


example:
sessionInfo()
sample.vec <-
   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from', 'the',
     'named', 'file', 'or', 'URL', 'or', 'connection')
dmp.size <- c(10^(1:7))
set.seed(37)

for(i in dmp.size) {
   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
   dump('df0', file='testdump')
   cat('length:', i, '\n')
   print(system.time(source('testdump', keep.source = FALSE,
                            encoding='')))
}

output for R version 2.15.2 Patched (2012-11-29 r61184):
> sessionInfo()
R version 2.15.2 Patched (2012-11-29 r61184)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
[3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
[5] LC_TIME=German_Switzerland.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> sample.vec <-
+   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from', 
'the',
+     'named', 'file', 'or', 'URL', 'or', 'connection')
> dmp.size <- c(10^(1:7))
> set.seed(37)
>
> for(i in dmp.size) {
+   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
+   dump('df0', file='testdump')
+   cat('length:', i, '\n')
+   print(system.time(source('testdump', keep.source = FALSE,
+                            encoding='')))
+ }
length: 10
    user  system elapsed
       0       0       0
length: 100
    user  system elapsed
       0       0       0
length: 1000
    user  system elapsed
       0       0       0
length: 10000
    user  system elapsed
    0.02    0.00    0.01
length: 1e+05
    user  system elapsed
    0.21    0.00    0.20
length: 1e+06
    user  system elapsed
    4.47    0.04    4.51
length: 1e+07
    user  system elapsed
   62.04    0.22   62.26
>


output for R version 3.0.2 Patched (2013-10-27 r64116):
> sessionInfo()
R version 3.0.2 Patched (2013-10-27 r64116)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
[3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
[5] LC_TIME=German_Switzerland.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> sample.vec <-
+   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from', 
'the',
+     'named', 'file', 'or', 'URL', 'or', 'connection')
> dmp.size <- c(10^(1:7))
> set.seed(37)
>
> for(i in dmp.size) {
+   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
+   dump('df0', file='testdump')
+   cat('length:', i, '\n')
+   print(system.time(source('testdump', keep.source = FALSE,
+                            encoding='')))
+ }
length: 10
    user  system elapsed
       0       0       0
length: 100
    user  system elapsed
       0       0       0
length: 1000
    user  system elapsed
       0       0       0
length: 10000
    user  system elapsed
    0.01    0.00    0.01
length: 1e+05
    user  system elapsed
    0.36    0.06    0.42
length: 1e+06
    user  system elapsed
    6.02    1.86    7.88
length: 1e+07
    user  system elapsed
  388.63  176.42  566.41
>





--
View this message in context: http://r.789695.n4.nabble.com/big-speed-difference-in-source-btw-R-2-15-2-and-R-3-0-2-tp4679314p4679346.html
Sent from the R help mailing list archive at Nabble.com.


From carl at witthoft.com  Wed Oct 30 13:39:47 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Wed, 30 Oct 2013 05:39:47 -0700 (PDT)
Subject: [R] Can not read Excel file correctly
In-Reply-To: <1383083721.52026.YahooMailNeo@web190501.mail.sg3.yahoo.com>
References: <1383083721.52026.YahooMailNeo@web190501.mail.sg3.yahoo.com>
Message-ID: <1383136787736-4679350.post@n4.nabble.com>

Dunno how to break this to you, but R reads exactly what is in that file,
with the data in exactly the proper row/column locations.  



--
View this message in context: http://r.789695.n4.nabble.com/Can-not-read-Excel-file-correctly-tp4679306p4679350.html
Sent from the R help mailing list archive at Nabble.com.


From carl at witthoft.com  Wed Oct 30 13:41:55 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Wed, 30 Oct 2013 05:41:55 -0700 (PDT)
Subject: [R] Optimization failed in fitdistr (Weibull distribution)
In-Reply-To: <526E7DC5.9020701@sapo.pt>
References: <1382962027602-4679167.post@n4.nabble.com>
	<526E7DC5.9020701@sapo.pt>
Message-ID: <1383136915309-4679351.post@n4.nabble.com>


Which suggests the OP should verify that the data in "...$Frequency" is the
data he expects to be there.


Rui Barradas wrote
> Hello,
> 
> I can't reproduce your error:
> 
> windfreq <-
> c(1351L, 2147L, 3317L, 4378L, 5527L, 6667L, 7865L, 8970L, 9987L,
> 10907L, 11905L, 12642L, 131000L, 14983L, 15847L, 16842L, 17757L,
> 18698L, 19632L, 20626L, 21599L, 22529L, 23325L, 24391L, 25356L,
> 26267L, 27230L, 28223L, 29190L, 30142L, 31124L, 32104L, 3397L,
> 3437L, 3562L, 3646L, 3742L, 3824L, 399L, 4013L, 419L, 425L, 432L
> 
> library(MASS)
> 
> fitdistr(windfreq, "weibull")
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 28-10-2013 12:07, kmmoon100 escreveu:
>> Hello everyone,
>>
>> This is Kangmin.
>>
>> I am trying to produce shape and scale of my wind data. My data is based
>> on
>> wind speed frequency with 1km/hr increment. data is described below.
>>
>> Windspeed (km/h)    Frequency
>> 1	351
>> 2	147
>> 3	317
>> 4	378
>> 5	527
>> 6	667
>> 7	865
>> 8	970
>> 9	987
>> 10	907
>> 11	905
>> 12	642
>> 13	1000
>> 14	983
>> 15	847
>> 16	842
>> 17	757
>> 18	698
>> 19	632
>> 20	626
>> 21	599
>> 22	529
>> 23	325
>> 24	391
>> 25	356
>> 26	267
>> 27	230
>> 28	223
>> 29	190
>> 30	142
>> 31	124
>> 32	104
>> 33	97
>> 34	37
>> 35	62
>> 36	46
>> 37	42
>> 38	24
>> 39	9
>> 40	13
>> 41	9
>> 42	5
>> 43	2
>>
>> R codes to calculate shape and scale are described below:
>>
>> Pine.windfrequency.4weeks<-read.table("C:/Users/kmoon/Documents/Pine_frequency_4weeks.csv",header=TRUE,sep=",")
>> fitdistr(Pine.windfrequency.4weeks$Frequency, densfun="weibull")
>>
>> I have got an error message when I was using 'fitdistr' function
>>
>> "Error in fitdistr(Pine.windfrequency.4weeks$Frequency, densfun =
>> "weibull")
>> :
>>    optimization failed"
>>
>> Please help me calculating shape and scale of weibull distribution.
>>
>> And please understand that I am not an user familiar with R program but I
>> am
>> really trying to make my analysis work on R!
>>
>> Thank you!!!
>>
>> Kangmin.
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Optimization-failed-in-fitdistr-Weibull-distribution-tp4679167.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> 

> R-help@

>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/Optimization-failed-in-fitdistr-Weibull-distribution-tp4679178p4679351.html
Sent from the R help mailing list archive at Nabble.com.


From stevan.lauriault at gmail.com  Wed Oct 30 13:03:20 2013
From: stevan.lauriault at gmail.com (Stevan Lauriault)
Date: Wed, 30 Oct 2013 08:03:20 -0400
Subject: [R] (no subject)
Message-ID: <CAFQvP01n8Y+hu5yNw1Fxz9GqYexbSpxbTLhaFnCBVd3eNWShFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/92dc8aff/attachment.pl>

From tuechler at gmx.at  Wed Oct 30 13:49:02 2013
From: tuechler at gmx.at (Heinz Tuechler)
Date: Wed, 30 Oct 2013 13:49:02 +0100
Subject: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
In-Reply-To: <1383136127835-4679346.post@n4.nabble.com>
References: <52704C18.6020905@gmx.at>
	<1383136127835-4679346.post@n4.nabble.com>
Message-ID: <5271003E.2080707@gmx.at>

All was run on the identical machine in independent sessions. I did not 
restart Windows. I also tried 32bit R 3.0.2 and it seemed slightly 
faster than 64bit.
Using Process Explorer v15.23 
(http://technet.microsoft.com/de-de/sysinternals/bb896653) my impression 
was that R 3.0.2 manages memory in a different way than R 2.15.2. While 
in R 2.15.2 the physical memory used grows steadily, when sourcing a big 
file, in R 3.0.2 growth and shrinking cycle.

best,
Heinz

on/am 30.10.2013 13:28, Carl Witthoft wrote/hat geschrieben:
> Did you run the identical code on the identical machine, and did you verify
> there were no other tasks running which might have limited the RAM available
> to R?  And equally important, did you run these tests in the reverse order
> (in case R was storing large objects from the first run, thus chewing up
> RAM)?
>
>
>
> Dear All,
>
> is it known that source works much faster in  R 2.15.2 than in R 3.0.2 ?
> In the example below I observe e.g. for a data.frame with 10^7 rows the
> following timings:
>
> R version 2.15.2 Patched (2012-11-29 r61184)
> length: 1e+07
>      user  system elapsed
>     62.04    0.22   62.26
>
> R version 3.0.2 Patched (2013-10-27 r64116)
> length: 1e+07
>      user  system elapsed
>    388.63  176.42  566.41
>
> Is there a way to speed R version 3.0.2 up to the performance of R
> version 2.15.2?
>
> best regards,
>
> Heinz T?chler
>
>
> example:
> sessionInfo()
> sample.vec <-
>     c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from', 'the',
>       'named', 'file', 'or', 'URL', 'or', 'connection')
> dmp.size <- c(10^(1:7))
> set.seed(37)
>
> for(i in dmp.size) {
>     df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
>     dump('df0', file='testdump')
>     cat('length:', i, '\n')
>     print(system.time(source('testdump', keep.source = FALSE,
>                              encoding='')))
> }
>
> output for R version 2.15.2 Patched (2012-11-29 r61184):
>> sessionInfo()
> R version 2.15.2 Patched (2012-11-29 r61184)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Switzerland.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>> sample.vec <-
> +   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from',
> 'the',
> +     'named', 'file', 'or', 'URL', 'or', 'connection')
>> dmp.size <- c(10^(1:7))
>> set.seed(37)
>>
>> for(i in dmp.size) {
> +   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
> +   dump('df0', file='testdump')
> +   cat('length:', i, '\n')
> +   print(system.time(source('testdump', keep.source = FALSE,
> +                            encoding='')))
> + }
> length: 10
>      user  system elapsed
>         0       0       0
> length: 100
>      user  system elapsed
>         0       0       0
> length: 1000
>      user  system elapsed
>         0       0       0
> length: 10000
>      user  system elapsed
>      0.02    0.00    0.01
> length: 1e+05
>      user  system elapsed
>      0.21    0.00    0.20
> length: 1e+06
>      user  system elapsed
>      4.47    0.04    4.51
> length: 1e+07
>      user  system elapsed
>     62.04    0.22   62.26
>>
>
>
> output for R version 3.0.2 Patched (2013-10-27 r64116):
>> sessionInfo()
> R version 3.0.2 Patched (2013-10-27 r64116)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Switzerland.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>> sample.vec <-
> +   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from',
> 'the',
> +     'named', 'file', 'or', 'URL', 'or', 'connection')
>> dmp.size <- c(10^(1:7))
>> set.seed(37)
>>
>> for(i in dmp.size) {
> +   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
> +   dump('df0', file='testdump')
> +   cat('length:', i, '\n')
> +   print(system.time(source('testdump', keep.source = FALSE,
> +                            encoding='')))
> + }
> length: 10
>      user  system elapsed
>         0       0       0
> length: 100
>      user  system elapsed
>         0       0       0
> length: 1000
>      user  system elapsed
>         0       0       0
> length: 10000
>      user  system elapsed
>      0.01    0.00    0.01
> length: 1e+05
>      user  system elapsed
>      0.36    0.06    0.42
> length: 1e+06
>      user  system elapsed
>      6.02    1.86    7.88
> length: 1e+07
>      user  system elapsed
>    388.63  176.42  566.41
>>
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/big-speed-difference-in-source-btw-R-2-15-2-and-R-3-0-2-tp4679314p4679346.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From therneau at mayo.edu  Wed Oct 30 13:55:13 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 30 Oct 2013 07:55:13 -0500
Subject: [R] calculating quantiles
In-Reply-To: <mailman.33.1383130809.19786.r-help@r-project.org>
References: <mailman.33.1383130809.19786.r-help@r-project.org>
Message-ID: <527101B1.1010803@mayo.edu>



On 10/30/2013 06:00 AM, r-help-request at r-project.org wrote:
> Hi,
>
> I'm having the following loop:
>
> result<- vector("list",100)
> for (i in 1:max(dat$simNumber))
> {  result[[i]]<-survfit(Surv(dat[dat$simNumber==i,]$TAFD,dat[dat$simNumber==i,]$DV)~1)
>
> }
>
> In a next step, I would like to calculate the mean, 5% and 95% PI of the Kaplan-Meier estimates of the 100 simulated problems stored under result in the result[[i]]$surv.
>
> Can anyone help me with this?
>
> Tx!
>

I don't know what a "95% PI" is, but for the mean survival I can help.

options(survfit.rmean="common")  #defaults to "none" in the routine
means <- lapply(result, function(x) summary(x)$table[5:6])

This gives a list, each element of which is the estimated mean and se(mean) for that curve.

Terry Therneau


From ihok at hotmail.com  Wed Oct 30 14:04:13 2013
From: ihok at hotmail.com (Jack Tanner)
Date: Wed, 30 Oct 2013 13:04:13 +0000
Subject: [R] omitting integer(0) rows from data frame
Message-ID: <loom.20131030T140101-323@post.gmane.org>

I'm not sure if this is correct behavior or not, but it seems counterintuitive 
to me:

dat <- data.frame(id=1:5, let=letters[1:5])
# A. omits the first row
dat[- 1, ]

# B. unexpectedly omits ALL rows
dat[- integer(0), ]

It would be less surprising if there were no rows omitted in the (B) case.


From erinm.hodgess at gmail.com  Wed Oct 30 14:11:38 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 30 Oct 2013 08:11:38 -0500
Subject: [R] rpy2 and user defined functions from R
In-Reply-To: <B92AF2D5-CB5D-4542-B36C-59451AC708DB@gmail.com>
References: <CACxE24nOJK9jdGiAOW65edrpTUHihjJfBVGNBW73=CUr=GnAOg@mail.gmail.com>
	<B92AF2D5-CB5D-4542-B36C-59451AC708DB@gmail.com>
Message-ID: <CACxE24n-8cMOYqfatT0eHB5tJpSHEVvjKUZVUnEkq54xf_sCRg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/0fabd5c2/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Wed Oct 30 14:18:40 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 30 Oct 2013 14:18:40 +0100
Subject: [R] omitting integer(0) rows from data frame
In-Reply-To: <loom.20131030T140101-323@post.gmane.org>
References: <loom.20131030T140101-323@post.gmane.org>
Message-ID: <Pine.SOC.4.64.1310301412160.2063@solcom.hrz.uni-giessen.de>

Hi, Jack,

well, I disagree: What do you expect to grab out of a bucket (= data 
frame) if you do not at all grab into it (indexing with an _empty_ index, 
i.e. with nothing)? And changing the sign of nothing is still nothing ...

  Hth --  Gerrit

On Wed, 30 Oct 2013, Jack Tanner wrote:

> I'm not sure if this is correct behavior or not, but it seems counterintuitive
> to me:
>
> dat <- data.frame(id=1:5, let=letters[1:5])
> # A. omits the first row
> dat[- 1, ]
>
> # B. unexpectedly omits ALL rows
> dat[- integer(0), ]
>
> It would be less surprising if there were no rows omitted in the (B) case.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.rigby at londonmet.ac.uk  Wed Oct 30 14:23:24 2013
From: r.rigby at londonmet.ac.uk (Robert Rigby)
Date: Wed, 30 Oct 2013 13:23:24 +0000
Subject: [R]  Heteroscedasticity and mgcv.
Message-ID: <CAKmh6oFJ=EkquiT5GAZKWYboHKQ_uWZh91n1Aq4_o+ic=TWpLg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/42236677/attachment.pl>

From smartpink111 at yahoo.com  Wed Oct 30 14:27:31 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 30 Oct 2013 06:27:31 -0700 (PDT)
Subject: [R] Subtotals by id for a large number of columns XXXX
In-Reply-To: <CAPRGo-nvFp81DmgMokJnmyFFghegHZcmTDz60Uv8bH5qSGQUtw@mail.gmail.com>
References: <CAPRGo-=jnn6Jq_aP0nSwOcajfeqN132y64coC51Mpq3RQWiTRQ@mail.gmail.com>	<5270F510.1000609@sapo.pt>
	<CAPRGo-nvFp81DmgMokJnmyFFghegHZcmTDz60Uv8bH5qSGQUtw@mail.gmail.com>
Message-ID: <1383139651.80056.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be:

apply(d1[3:5],2, mysum)
? var1 var2 var3
1??? 2??? 0??? 1
2??? 2??? 2??? 3
3??? 1??? 1??? 1
4??? 0??? 1??? 0

#or
sapply(d1[3:5],mysum)

#or
library(plyr)
ddply(d1[,-2],.(id),colwise(sum))
A.K.



On Wednesday, October 30, 2013 8:30 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
Hi Rui,

Thanks for responding. When I make this change, I get an error message:

> mysum<-function(x) tapply(x,d1$id,sum)
>
> d2<-apply(d1[2:4],mysum)
Error in match.fun(FUN) : argument "FUN" is missing, with no default
Thoughts?



On Wed, Oct 30, 2013 at 8:01 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> If I understand it correctly, just change mysum to the following.
>
>
> mysum<-function(x) tapply(x,d1$id,sum)
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 30-10-2013 11:07, Dan Abner escreveu:
>
>> Hi everybody,
>>
>> I have data in the format of the example data below where essentially a
>> large number of indicator variables (coded [0,1]) reflect traits of the
>> same id across multiple rows. I need to represent the data in a 1 row per
>> id format. I see this as being similar to converting from long to wide
>> format, however, there is no time component here: The multiple rows here
>> are all characteristics observed at the same measurement occasion. So,
>> really I just need an individual sum for each variable (for a large number
>> of variables) and for these to be all saved in the same row (along with
>> the
>> id variable and other demographics (e.g., "location").
>>
>> Here is the example df and the method I used first:
>>
>>
>> d1<-data.frame(id=c(1,1,1,2,2,**2,2,3,3,4),location=factor(c(**
>> rep(0,7),rep(1,3)),
>>?  labels=c("A","B")),var1=as.**logical(round(runif(10))),
>>?  var2=as.logical(round(runif(**10))),var3=as.logical(round(**
>> runif(10))))
>> d1
>> mysum<-function(x) aggregate(x,by=list(d1$id),**sum)
>> d2<-sapply(d1[2:4],mysum)
>> d2
>>
>> Any help is appreciated!!
>>
>> Thanks!
>>
>> Dan
>>
>>? ? ? ?  [[alternative HTML version deleted]]
>>
>> ______________________________**________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/**
>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.

>>
>>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From S.Ellison at lgcgroup.com  Wed Oct 30 15:02:32 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Wed, 30 Oct 2013 14:02:32 +0000
Subject: [R] omitting integer(0) rows from data frame
In-Reply-To: <Pine.SOC.4.64.1310301412160.2063@solcom.hrz.uni-giessen.de>
References: <loom.20131030T140101-323@post.gmane.org>
	<Pine.SOC.4.64.1310301412160.2063@solcom.hrz.uni-giessen.de>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554EA9ACC@GOLD.corp.lgc-group.com>

> >  dat[- integer(0), ]
> > .... unexpectedly omits ALL rows
> >
> > It would be less surprising if there were no rows omitted in the (B) case.

I tried this on two experienced R users here and their first thought* was, interestingly, as Jack indicated; that -integer(0) should drop nothing.

But Gerrit is correct; -integer(0) still evaluates to a zero length vector, not a negative, and asking for a zero-length set of rows is equivalent to asking for no rows.

Steve E

*Second thought, actually; their first thought was 'why would you do that?'. 
To be fair we did note that dropping according to an empty 'which' criterion or an unmatched grep() would do this. The 'obvious' fix would presumably be not to wrap the selection in which() at all (eg use 1:5 == 6 directly and not which(1:5 == 6) ), to use regexpr(...)>0 instead of grep etc. 




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From pdalgd at gmail.com  Wed Oct 30 15:11:18 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 30 Oct 2013 15:11:18 +0100
Subject: [R] Optimization failed in fitdistr (Weibull distribution)
In-Reply-To: <52701C02.1020009@auckland.ac.nz>
References: <1382962027602-4679167.post@n4.nabble.com>
	<20E86E70-305F-4C4A-95AA-BAFE294823A0@gmail.com>
	<52701C02.1020009@auckland.ac.nz>
Message-ID: <A369691A-DCDA-4D29-A203-3F077792BCD7@gmail.com>


On 29 Oct 2013, at 21:35 , Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 10/29/13 19:44, peter dalgaard wrote:
> 
> 
>    <SNIP>
>> There really is no substitute for knowledge and understanding! Did it not occur to you that the Windspeed column needs to enter into your analysis?
> 
>    <SNIP>
> 
> Fortune!

Actually, I felt that that one came out a bit harsher than actually deserved. 

It?s quite interesting though, that the regular busybodies complained about the lack of easily reproducible data, but didn?t pick up on the fact that Frequency couldn?t be the right thing to analyze...

> 
>    cheers,
> 
>    Rolf Turner

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dimitri.liakhovitski at gmail.com  Wed Oct 30 15:35:11 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 30 Oct 2013 10:35:11 -0400
Subject: [R] ggplot2 question: keeping the order as in the input data
Message-ID: <CAN2xGJaGms3TDLHFoz9FwoO3BDSzuZ2=FgfykakJ+KsiiuB2uQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/90d0550e/attachment.pl>

From dimitri.liakhovitski at gmail.com  Wed Oct 30 15:47:41 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 30 Oct 2013 10:47:41 -0400
Subject: [R] Shiny question: what happens after hitting F5
Message-ID: <CAN2xGJZcMKp1MabYT1YaJie_XuJPTAGoY1qYCXBzTUJKYrhSwg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/d2bba461/attachment.pl>

From macqueen1 at llnl.gov  Wed Oct 30 15:50:22 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 30 Oct 2013 14:50:22 +0000
Subject: [R] Can not read Excel file correctly
In-Reply-To: <1383083721.52026.YahooMailNeo@web190501.mail.sg3.yahoo.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D503981@PRDEXMBX-08.the-lab.llnl.gov>

I can't help you with cell A1, but I can make a guess at your date format
issue. To start, I would suggest you read thoroughly the XLConnect
documentation for how it handles dates (and probably also ?Date in R).

In both Excel and R, dates are stored internally as a number, and then
displayed with a user-selected format. In Excel, apparently, you have
chosen a month-year format. R's default display format is year-month-day.
So, it's not an issue with reading the data in, it's an issue of how dates
are displayed.

If you want to display your dates as month-year, you can do something like
  mydata$Col3 <- format(mydata$Col3, '%m-%Y')
But if you do that, you will then have character data, not dates, so you
won't be able to do any date calculations.

All of this assumes XLConnect is recognizing the Excel date columns as
dates, and automatically converting them to the R Date class. If that's
not what you want it to do, then you'll have to find the XLConnect
documentation that tells you how to prevent it.

Hope this helps.

-Don
 
-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/29/13 2:55 PM, "Ron Michael" <ron_michael70 at yahoo.com> wrote:

>Hi,
>
>I need to read an Excel file which can be available in following link:
>http://www45.zippyshare.com/v/43626889/file.html
>
>Now I wanted to read the 1st sheet of this Excel file. Below are my code
>so far (I saved that file in 'F:' drive):
>
>> library(XLConnect)
>Loading required package: rJava
>XLConnect 0.2-5 by Mirai Solutions GmbH
>http://www.mirai-solutions.com ,
>http://miraisolutions.wordpress.com
>> readWorksheetFromFile("f:/Dat1.xlsx", sheet = 1)
>        Col1             Col2       Col3   Col4
>1       <NA>               NA 2013-05-01   <NA>
>2       <NA>               NA       <NA>   <NA>
>3 1930-01-01               NA       <NA>   <NA>
>4       <NA> 3127312736128730       <NA>   <NA>
>5       <NA>               NA       <NA>   <NA>
>6       <NA>               NA       <NA> SAsSag
>
>
>What I saw that, the element in A1 cell is missing. Also the data in C1 &
>A4 are read in different format. In Excel file, it is Month-Year format,
>however what I see is Year-Month-Day format.
>
>I have many such files, therefore I do not want to convert them to csv
>(or any other). Doing so will be cumbersome.
>
>Can somebody here help me how to read that file in proper format?
>
>Thanks for your time.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Wed Oct 30 15:56:39 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 30 Oct 2013 09:56:39 -0500
Subject: [R] (no subject)
In-Reply-To: <CAFQvP01n8Y+hu5yNw1Fxz9GqYexbSpxbTLhaFnCBVd3eNWShFg@mail.gmail.com>
References: <CAFQvP01n8Y+hu5yNw1Fxz9GqYexbSpxbTLhaFnCBVd3eNWShFg@mail.gmail.com>
Message-ID: <CAN5YmCHD+QNhKiDUCccH_pAN9WjgZtDfwsRsR1umrzhSq4dxwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/fbc10a29/attachment.pl>

From michael.weylandt at gmail.com  Wed Oct 30 16:03:21 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Wed, 30 Oct 2013 11:03:21 -0400
Subject: [R] rpy2 and user defined functions from R
In-Reply-To: <CACxE24n-8cMOYqfatT0eHB5tJpSHEVvjKUZVUnEkq54xf_sCRg@mail.gmail.com>
References: <CACxE24nOJK9jdGiAOW65edrpTUHihjJfBVGNBW73=CUr=GnAOg@mail.gmail.com>
	<B92AF2D5-CB5D-4542-B36C-59451AC708DB@gmail.com>
	<CACxE24n-8cMOYqfatT0eHB5tJpSHEVvjKUZVUnEkq54xf_sCRg@mail.gmail.com>
Message-ID: <F971C72F-DC88-4067-91D6-FDC001362104@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/e17ba099/attachment.pl>

From collinl at cs.pitt.edu  Wed Oct 30 16:16:43 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Wed, 30 Oct 2013 11:16:43 -0400
Subject: [R] rpy2 and user defined functions from R
In-Reply-To: <CACxE24nOJK9jdGiAOW65edrpTUHihjJfBVGNBW73=CUr=GnAOg@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.1310301113460.21189-100000@nitrogen.cs.pitt.edu>

Erin, one question, can you access the defined functions by key?

In lieu of:
> x = R.r.buzz(3)

Can you do:
  x = R.r['buzz'](3)


Alternatively if you need only one or two custom functions have you
considered just defining them via python as in:

PStr = """
function(LM) {
  S <- summary(LM);
  print(S$fstatistic);
  F <- S$fstatistic;
  P <- pf(F[1], F[2], F[3], lower=FALSE);
  return(P);
}
"""
r_LMPValFunc = robjects.r(PStr)

	Best,
	Collin.


On Tue, 29 Oct 2013, Erin Hodgess wrote:

> Hello again!
>
> I'm using python with a module rpy2 to call functions from R.
>
> It works fine on built in R functions like rnorm.
>
> However, I would like to access user-defined functions as well.  For those
> of you who use this, I have:
>
> import rpy2.robjects as R
> R object as no attribute buzz
>
> (user defined function of buzz)
>
> This is on a Centos 5 machine with R-3.0.2 and python of 2.7.5.
>
> Thanks for any help.
> Sincerely,
> Erin
>
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Wed Oct 30 16:23:02 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 30 Oct 2013 10:23:02 -0500
Subject: [R] Subtotals by id for a large number of columns XXXX
In-Reply-To: <CAPRGo-nvFp81DmgMokJnmyFFghegHZcmTDz60Uv8bH5qSGQUtw@mail.gmail.com>
References: <CAPRGo-=jnn6Jq_aP0nSwOcajfeqN132y64coC51Mpq3RQWiTRQ@mail.gmail.com>	<5270F510.1000609@sapo.pt>
	<CAPRGo-nvFp81DmgMokJnmyFFghegHZcmTDz60Uv8bH5qSGQUtw@mail.gmail.com>
Message-ID: <006d01ced583$ecb303b0$c6190b10$@tamu.edu>

apply() is a different function from sapply() and has different
arguments.

-------------------------------------
David L Carlson
Deparment of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Dan Abner
Sent: Wednesday, October 30, 2013 7:24 AM
To: Rui Barradas
Cc: r-help at r-project.org
Subject: Re: [R] Subtotals by id for a large number of columns
XXXX

Hi Rui,

Thanks for responding. When I make this change, I get an error
message:

> mysum<-function(x) tapply(x,d1$id,sum)
>
> d2<-apply(d1[2:4],mysum)
Error in match.fun(FUN) : argument "FUN" is missing, with no
default
Thoughts?



On Wed, Oct 30, 2013 at 8:01 AM, Rui Barradas
<ruipbarradas at sapo.pt> wrote:

> Hello,
>
> If I understand it correctly, just change mysum to the
following.
>
>
> mysum<-function(x) tapply(x,d1$id,sum)
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 30-10-2013 11:07, Dan Abner escreveu:
>
>> Hi everybody,
>>
>> I have data in the format of the example data below where
essentially a
>> large number of indicator variables (coded [0,1]) reflect
traits of the
>> same id across multiple rows. I need to represent the data in
a 1 row per
>> id format. I see this as being similar to converting from
long to wide
>> format, however, there is no time component here: The
multiple rows here
>> are all characteristics observed at the same measurement
occasion. So,
>> really I just need an individual sum for each variable (for a
large number
>> of variables) and for these to be all saved in the same row
(along with
>> the
>> id variable and other demographics (e.g., "location").
>>
>> Here is the example df and the method I used first:
>>
>>
>>
d1<-data.frame(id=c(1,1,1,2,2,**2,2,3,3,4),location=factor(c(**
>> rep(0,7),rep(1,3)),
>>   labels=c("A","B")),var1=as.**logical(round(runif(10))),
>>
var2=as.logical(round(runif(**10))),var3=as.logical(round(**
>> runif(10))))
>> d1
>> mysum<-function(x) aggregate(x,by=list(d1$id),**sum)
>> d2<-sapply(d1[2:4],mysum)
>> d2
>>
>> Any help is appreciated!!
>>
>> Thanks!
>>
>> Dan
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________**________________
>> R-help at r-project.org mailing list
>>
https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz
.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/**
>> posting-guide.html
<http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible
code.
>>
>>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From S.Ellison at lgcgroup.com  Wed Oct 30 16:50:52 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Wed, 30 Oct 2013 15:50:52 +0000
Subject: [R] Shiny question: what happens after hitting F5
In-Reply-To: <CAN2xGJZcMKp1MabYT1YaJie_XuJPTAGoY1qYCXBzTUJKYrhSwg@mail.gmail.com>
References: <CAN2xGJZcMKp1MabYT1YaJie_XuJPTAGoY1qYCXBzTUJKYrhSwg@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554EA9B9B@GOLD.corp.lgc-group.com>

>  I
> get warnings (one for each file) that look like this:
> 
> Warning in dir.create(dir) :
> 
> 'C:\Users\DIMITR~1.LIA\AppData\Local\Temp\RtmpklHtMJ\435e92e733e5f0
> a8a00f342d'
> already exists
> 
> It is still working. But: how could I get rid of these warnings?

Delete the temporary files before running the code?

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From wdunlap at tibco.com  Wed Oct 30 17:04:34 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 30 Oct 2013 16:04:34 +0000
Subject: [R] ggplot2 question: keeping the order as in the input data
In-Reply-To: <CAN2xGJaGms3TDLHFoz9FwoO3BDSzuZ2=FgfykakJ+KsiiuB2uQ@mail.gmail.com>
References: <CAN2xGJaGms3TDLHFoz9FwoO3BDSzuZ2=FgfykakJ+KsiiuB2uQ@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA115B3@PA-MBX01.na.tibco.com>

Try making att_levels (or att.levels, whatever you really call it)
into a factor with the levels in the order you like.  E.g.,
    aes(x = factor(att_levels, levels=unique(att_levels)), y = WTP)
instead of
    aes(x = att_levels, y = WTP) 

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Dimitri Liakhovitski
> Sent: Wednesday, October 30, 2013 7:35 AM
> To: r-help
> Subject: [R] ggplot2 question: keeping the order as in the input data
> 
> Hello!
> 
> I am using ggplot2 (see the code below) to plot the data in 'myplotdata'.
> The first column of 'myplotdata' is called "att.levels" and contains
> strings; the second column is called "WTP" and contains numeric values.
> Notice - I use 'coord.flip()'
> 
> The command aes(x=att_levels, y=WTP), if I understand correctly, sorts
> things alphabetically based on the column 'att_levels'.
> Question 1: How can I reverse the order for x in the plot (also
> alphabetically but in the opposite direction)?
> Question 2: How can I just have exactly the same order as in the object
> 'myplotdata'?
> 
> Thanks a lot!
> 
> ggplot(myplotdata, aes(x=att_levels, y=WTP)) +
>                 geom_bar(stat="identity",fill="dark orange",colour="black",
> alpha = 1,position = "identity") +
> 
> geom_text(aes(label=WTP),colour="black",size=4,hjust=1.1,position='dodge') +
>                 coord_flip() +
>                 xlab("") +
>                 ylab("")
> 
> 
> 
> 
> --
> Dimitri Liakhovitski
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erinm.hodgess at gmail.com  Wed Oct 30 17:05:50 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 30 Oct 2013 11:05:50 -0500
Subject: [R] rpy2 and user defined functions from R
In-Reply-To: <Pine.LNX.4.44.1310301113460.21189-100000@nitrogen.cs.pitt.edu>
References: <CACxE24nOJK9jdGiAOW65edrpTUHihjJfBVGNBW73=CUr=GnAOg@mail.gmail.com>
	<Pine.LNX.4.44.1310301113460.21189-100000@nitrogen.cs.pitt.edu>
Message-ID: <CACxE24nraEizjgEmN2t5mKnA3snWC-QwocM+5RP=zOH2TtqxQQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/03983810/attachment.pl>

From pburns at pburns.seanet.com  Wed Oct 30 17:12:30 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Wed, 30 Oct 2013 16:12:30 +0000
Subject: [R] omitting integer(0) rows from data frame
In-Reply-To: <loom.20131030T140101-323@post.gmane.org>
References: <loom.20131030T140101-323@post.gmane.org>
Message-ID: <52712FEE.4090809@pburns.seanet.com>

This is Circle 8.1.13 of 'The R Inferno'.

http://www.burns-stat.com/documents/books/the-r-inferno/

Pat


On 30/10/2013 13:04, Jack Tanner wrote:
> I'm not sure if this is correct behavior or not, but it seems counterintuitive
> to me:
>
> dat <- data.frame(id=1:5, let=letters[1:5])
> # A. omits the first row
> dat[- 1, ]
>
> # B. unexpectedly omits ALL rows
> dat[- integer(0), ]
>
> It would be less surprising if there were no rows omitted in the (B) case.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From alaios at yahoo.com  Wed Oct 30 18:09:15 2013
From: alaios at yahoo.com (Alaios)
Date: Wed, 30 Oct 2013 10:09:15 -0700 (PDT)
Subject: [R] help me align the legend bar
Message-ID: <1383152955.50964.YahooMailNeo@web125305.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/6d2c744b/attachment.pl>

From dwinsemius at comcast.net  Wed Oct 30 18:17:42 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 30 Oct 2013 10:17:42 -0700
Subject: [R] Subtotals by id for a large number of columns XXXX
In-Reply-To: <CAPRGo-=jnn6Jq_aP0nSwOcajfeqN132y64coC51Mpq3RQWiTRQ@mail.gmail.com>
References: <CAPRGo-=jnn6Jq_aP0nSwOcajfeqN132y64coC51Mpq3RQWiTRQ@mail.gmail.com>
Message-ID: <BE1E5C87-6A69-46D7-963D-DB8C2BC2B38F@comcast.net>


On Oct 30, 2013, at 4:07 AM, Dan Abner wrote:

> Hi everybody,
> 
> I have data in the format of the example data below where essentially a
> large number of indicator variables (coded [0,1]) reflect traits of the
> same id across multiple rows. I need to represent the data in a 1 row per
> id format. I see this as being similar to converting from long to wide
> format, however, there is no time component here: The multiple rows here
> are all characteristics observed at the same measurement occasion. So,
> really I just need an individual sum for each variable (for a large number
> of variables) and for these to be all saved in the same row (along with the
> id variable and other demographics (e.g., "location").
> 
> Here is the example df and the method I used first:
> 
> 
> d1<-data.frame(id=c(1,1,1,2,2,2,2,3,3,4),location=factor(c(rep(0,7),rep(1,3)),
> labels=c("A","B")),var1=as.logical(round(runif(10))),
> var2=as.logical(round(runif(10))),var3=as.logical(round(runif(10))))
> d1

Perhaps.

> mysum<-aggregate(d1[-(1:2)],by=d1[1:2] ,sum)
> mysum
  id location var1 var2 var3
1  1        A    0    2    1
2  2        A    1    2    1
3  3        B    1    0    2
4  4        B    1    1    0

> 
> 	[[alternative HTML version deleted]]

Please learn to use your mail client to post in plain text. (All of the free mailer services support plain text, so continuing to post in HYML is evidence of willful refusal to adhere to the posting guidelines.)

-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Oct 30 18:28:08 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 30 Oct 2013 10:28:08 -0700
Subject: [R] omitting integer(0) rows from data frame
In-Reply-To: <loom.20131030T140101-323@post.gmane.org>
References: <loom.20131030T140101-323@post.gmane.org>
Message-ID: <20D7B157-BF89-4DBD-9CC7-4937DA26BC07@comcast.net>


On Oct 30, 2013, at 6:04 AM, Jack Tanner wrote:

> I'm not sure if this is correct behavior or not, but it seems counterintuitive 
> to me:
> 
> dat <- data.frame(id=1:5, let=letters[1:5])
> # A. omits the first row
> dat[- 1, ]
> 
> # B. unexpectedly omits ALL rows
> dat[- integer(0), ]
> 
> It would be less surprising if there were no rows omitted in the (B) case.

Yes. It is surprising. It is also teh reason why the construction is also not returning what a user might expect:

dat[-which(dat$id >5), ]
#[1] id  let
#<0 rows> (or 0-length row.names)

(And yes I know that many people never use which with a logical. I'm just not one of those for what I consider good reasons.)

`subset` may be preferred,  at least for console interaction:

 subset( dat, !(id >5) )
  id let
1  1   a
2  2   b
3  3   c
4  4   d
5  5   e

-- 

David Winsemius
Alameda, CA, USA


From dan.abner99 at gmail.com  Wed Oct 30 18:31:05 2013
From: dan.abner99 at gmail.com (Dan Abner)
Date: Wed, 30 Oct 2013 13:31:05 -0400
Subject: [R] Subtotals by id for a large number of columns XXXX
In-Reply-To: <BE1E5C87-6A69-46D7-963D-DB8C2BC2B38F@comcast.net>
References: <CAPRGo-=jnn6Jq_aP0nSwOcajfeqN132y64coC51Mpq3RQWiTRQ@mail.gmail.com>
	<BE1E5C87-6A69-46D7-963D-DB8C2BC2B38F@comcast.net>
Message-ID: <CAPRGo-nhxoQ3A=2ybhuvMu3ssDisM8gu7iGqJSaOADG6-XQu3A@mail.gmail.com>

Hi David,

1) Thanks very much. Your code shows that this was much simpler than I
anticipated.

2) I have made the appropriate changes to email in plain text. My apologies.

Thanks!

Dan


On Wed, Oct 30, 2013 at 1:17 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Oct 30, 2013, at 4:07 AM, Dan Abner wrote:
>
>> Hi everybody,
>>
>> I have data in the format of the example data below where essentially a
>> large number of indicator variables (coded [0,1]) reflect traits of the
>> same id across multiple rows. I need to represent the data in a 1 row per
>> id format. I see this as being similar to converting from long to wide
>> format, however, there is no time component here: The multiple rows here
>> are all characteristics observed at the same measurement occasion. So,
>> really I just need an individual sum for each variable (for a large number
>> of variables) and for these to be all saved in the same row (along with the
>> id variable and other demographics (e.g., "location").
>>
>> Here is the example df and the method I used first:
>>
>>
>> d1<-data.frame(id=c(1,1,1,2,2,2,2,3,3,4),location=factor(c(rep(0,7),rep(1,3)),
>> labels=c("A","B")),var1=as.logical(round(runif(10))),
>> var2=as.logical(round(runif(10))),var3=as.logical(round(runif(10))))
>> d1
>
> Perhaps.
>
>> mysum<-aggregate(d1[-(1:2)],by=d1[1:2] ,sum)
>> mysum
>   id location var1 var2 var3
> 1  1        A    0    2    1
> 2  2        A    1    2    1
> 3  3        B    1    0    2
> 4  4        B    1    1    0
>
>>
>>       [[alternative HTML version deleted]]
>
> Please learn to use your mail client to post in plain text. (All of the free mailer services support plain text, so continuing to post in HYML is evidence of willful refusal to adhere to the posting guidelines.)
>
> --
> David Winsemius
> Alameda, CA, USA
>


From jvadams at usgs.gov  Wed Oct 30 18:58:00 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 30 Oct 2013 12:58:00 -0500
Subject: [R] (no subject)
In-Reply-To: <CAFQvP01sh6UrFJXykBfea3OjEnL5LAOi0p_TJX9H-f-ZytT11A@mail.gmail.com>
References: <CAFQvP01n8Y+hu5yNw1Fxz9GqYexbSpxbTLhaFnCBVd3eNWShFg@mail.gmail.com>
	<CAN5YmCHD+QNhKiDUCccH_pAN9WjgZtDfwsRsR1umrzhSq4dxwQ@mail.gmail.com>
	<CAFQvP01sh6UrFJXykBfea3OjEnL5LAOi0p_TJX9H-f-ZytT11A@mail.gmail.com>
Message-ID: <CAN5YmCFgFdJXqD3bmmiRJ2sG1i-7J3-F6F1e1n7rr018xLQkYw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/efbf4f6a/attachment.pl>

From dimitri.liakhovitski at gmail.com  Wed Oct 30 19:04:26 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 30 Oct 2013 14:04:26 -0400
Subject: [R] ggplot2 question: keeping the order as in the input data
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA115B3@PA-MBX01.na.tibco.com>
References: <CAN2xGJaGms3TDLHFoz9FwoO3BDSzuZ2=FgfykakJ+KsiiuB2uQ@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA115B3@PA-MBX01.na.tibco.com>
Message-ID: <CAN2xGJZtgtfAptD18_A-BuW_uBG4op6g2ct7ACFWXy+M4+m2RA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/06e1778b/attachment.pl>

From erinm.hodgess at gmail.com  Wed Oct 30 19:06:04 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 30 Oct 2013 13:06:04 -0500
Subject: [R] rpy2 and user defined functions from R
In-Reply-To: <CACxE24nraEizjgEmN2t5mKnA3snWC-QwocM+5RP=zOH2TtqxQQ@mail.gmail.com>
References: <CACxE24nOJK9jdGiAOW65edrpTUHihjJfBVGNBW73=CUr=GnAOg@mail.gmail.com>
	<Pine.LNX.4.44.1310301113460.21189-100000@nitrogen.cs.pitt.edu>
	<CACxE24nraEizjgEmN2t5mKnA3snWC-QwocM+5RP=zOH2TtqxQQ@mail.gmail.com>
Message-ID: <CACxE24=J0Ucq6GEoQsKSp1kWJGQua18knLo746qS+wLSjqiHYg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/cd02e5c9/attachment.pl>

From clint at ecy.wa.gov  Wed Oct 30 19:09:38 2013
From: clint at ecy.wa.gov (Clint Bowman)
Date: Wed, 30 Oct 2013 11:09:38 -0700 (PDT)
Subject: [R] (no subject)
In-Reply-To: <CAN5YmCFgFdJXqD3bmmiRJ2sG1i-7J3-F6F1e1n7rr018xLQkYw@mail.gmail.com>
References: <CAFQvP01n8Y+hu5yNw1Fxz9GqYexbSpxbTLhaFnCBVd3eNWShFg@mail.gmail.com>
	<CAN5YmCHD+QNhKiDUCccH_pAN9WjgZtDfwsRsR1umrzhSq4dxwQ@mail.gmail.com>
	<CAFQvP01sh6UrFJXykBfea3OjEnL5LAOi0p_TJX9H-f-ZytT11A@mail.gmail.com>
	<CAN5YmCFgFdJXqD3bmmiRJ2sG1i-7J3-F6F1e1n7rr018xLQkYw@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1310301108310.5831@ecy.wa.gov>

Just guessing, would the following help?

list1 <- c("john", "eric", "steve", "john", "eric", "scott", "john")
list2 <- c("john", "john", "john", "eric", "eric", "steve", "scott")
max(rle(list1)$lengths)
max(rle(list2)$lengths)

Clint

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Wed, 30 Oct 2013, Adams, Jean wrote:

> You should cc r-help on all correspondence so everyone can follow the
> thread.
>
> Clearly I'm missing something.  Perhaps others are, too.  I don't  know
> what you mean by "a score based on the co-localization of names" unless you
> give an example.
>
> Jean
>
>
> On Wed, Oct 30, 2013 at 10:34 AM, Stevan Lauriault <
> stevan.lauriault at gmail.com> wrote:
>
>> It would depend on the algorithm.  Which is why I'm writing.  I'm asking
>> if anyone knows of a preexisting algorithm that would calculate a score
>> based on the co-localization of names.
>>
>> S
>>
>>
>>
>>
>>
>> On Wed, Oct 30, 2013 at 10:56 AM, Adams, Jean <jvadams at usgs.gov> wrote:
>>
>>> What would the calculated score be for the example you give?
>>>
>>> Jean
>>>
>>>
>>> On Wed, Oct 30, 2013 at 7:03 AM, Stevan Lauriault <
>>> stevan.lauriault at gmail.com> wrote:
>>>
>>>> Hi,
>>>>
>>>> I'm looking for a function that takes a list and calculates a score
>>>> based on
>>>> how well "like attracts like".
>>>> For example:
>>>>
>>>> list1 <- c(john, eric, steve, john, eric, scott, john)
>>>> list2 <- c(john, john, john, eric, eric, steve, scott)
>>>>
>>>> score(list1) < score(list2)
>>>>
>>>> Both lists are composed of the same names and frequency of each
>>>> name.
>>>>
>>>> Not sure how else to put it.  I am relatively new to R.  Have tried the
>>>> modularity function, but can't seem to get it to work for this purpose.
>>>>
>>>>
>>>> Any help is appreciated.
>>>>
>>>> Steve
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dimitri.liakhovitski at gmail.com  Wed Oct 30 19:11:37 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 30 Oct 2013 14:11:37 -0400
Subject: [R] ggplot2 - how to get rid of bar boarder lines
Message-ID: <CAN2xGJZeEzGqbc9JC=ucM-K8etJMP=xyYtxCgouEUV1oZY=p0w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/10bd5e60/attachment.pl>

From jvadams at usgs.gov  Wed Oct 30 19:12:20 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 30 Oct 2013 13:12:20 -0500
Subject: [R] mapping data to a geographic map of Europe
In-Reply-To: <20131030171421.Horde.dPu6YWuryyixwFIzcAFtoQ1@webmail.df.eu>
References: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>
	<CAN5YmCHnKATgmwohcaHyTbzRSi4vyqcYg-jphxJ7AQ2m-wCbZg@mail.gmail.com>
	<20131030171421.Horde.dPu6YWuryyixwFIzcAFtoQ1@webmail.df.eu>
Message-ID: <CAN5YmCHRt7+bYz7tFqNEVp9CS0AqCy2=xnBzUa8ERL=eY8QNYQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/600f644d/attachment.pl>

From wdunlap at tibco.com  Wed Oct 30 20:11:33 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 30 Oct 2013 19:11:33 +0000
Subject: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
In-Reply-To: <1383136127835-4679346.post@n4.nabble.com>
References: <52704C18.6020905@gmx.at>
	<1383136127835-4679346.post@n4.nabble.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA11732@PA-MBX01.na.tibco.com>

I see a big 2.15.2/3.0.2 speed difference in parse() (which is used by source())
when it is parsing long vectors of numeric data.  dump/source has never been an efficient
way of transferring data between different R session, but it is much worse
now for long vectors.   In 2.15.2 doubling the size of the vector (of lengths
in the range 10^4 to 10^7) makes the time to parse go up by a factor of c. 2.1.
In 3.0.2 that factor is more like 4.4.

       n elapsed-2.15.2 elapsed-3.0.2
    2048          0.003         0.018
    4096          0.006         0.065
    8192          0.013         0.254
   16384          0.025         1.067
   32768          0.050         4.114
   65536          0.100        16.236
  131072          0.219        66.013
  262144          0.808       291.883
  524288          2.022      1285.265
 1048576          4.918            NA
 2097152          9.857            NA
 4194304         22.916            NA
 8388608         49.671            NA
16777216        101.042            NA
33554432        512.719            NA

I tried this with 64-bit R on a Linux box.  The NA's represent sizes that did not
finish while I was at a 1 1/2 hour dentist's apppointment.  The timing function
was:
  test <- function(n = 2^(11:25))
  {
      tf <- tempfile()
      on.exit(unlink(tf))
      t(sapply(n, function(n){
          dput(log(seq_len(n)), file=tf)
          print(c(n=n, system.time(parse(file=tf))[1:3]))
      }))
  }

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Carl Witthoft
> Sent: Wednesday, October 30, 2013 5:29 AM
> To: r-help at r-project.org
> Subject: Re: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
> 
> Did you run the identical code on the identical machine, and did you verify
> there were no other tasks running which might have limited the RAM available
> to R?  And equally important, did you run these tests in the reverse order
> (in case R was storing large objects from the first run, thus chewing up
> RAM)?
> 
> 
> 
> Dear All,
> 
> is it known that source works much faster in  R 2.15.2 than in R 3.0.2 ?
> In the example below I observe e.g. for a data.frame with 10^7 rows the
> following timings:
> 
> R version 2.15.2 Patched (2012-11-29 r61184)
> length: 1e+07
>     user  system elapsed
>    62.04    0.22   62.26
> 
> R version 3.0.2 Patched (2013-10-27 r64116)
> length: 1e+07
>     user  system elapsed
>   388.63  176.42  566.41
> 
> Is there a way to speed R version 3.0.2 up to the performance of R
> version 2.15.2?
> 
> best regards,
> 
> Heinz T?chler
> 
> 
> example:
> sessionInfo()
> sample.vec <-
>    c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from', 'the',
>      'named', 'file', 'or', 'URL', 'or', 'connection')
> dmp.size <- c(10^(1:7))
> set.seed(37)
> 
> for(i in dmp.size) {
>    df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
>    dump('df0', file='testdump')
>    cat('length:', i, '\n')
>    print(system.time(source('testdump', keep.source = FALSE,
>                             encoding='')))
> }
> 
> output for R version 2.15.2 Patched (2012-11-29 r61184):
> > sessionInfo()
> R version 2.15.2 Patched (2012-11-29 r61184)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Switzerland.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> > sample.vec <-
> +   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from',
> 'the',
> +     'named', 'file', 'or', 'URL', 'or', 'connection')
> > dmp.size <- c(10^(1:7))
> > set.seed(37)
> >
> > for(i in dmp.size) {
> +   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
> +   dump('df0', file='testdump')
> +   cat('length:', i, '\n')
> +   print(system.time(source('testdump', keep.source = FALSE,
> +                            encoding='')))
> + }
> length: 10
>     user  system elapsed
>        0       0       0
> length: 100
>     user  system elapsed
>        0       0       0
> length: 1000
>     user  system elapsed
>        0       0       0
> length: 10000
>     user  system elapsed
>     0.02    0.00    0.01
> length: 1e+05
>     user  system elapsed
>     0.21    0.00    0.20
> length: 1e+06
>     user  system elapsed
>     4.47    0.04    4.51
> length: 1e+07
>     user  system elapsed
>    62.04    0.22   62.26
> >
> 
> 
> output for R version 3.0.2 Patched (2013-10-27 r64116):
> > sessionInfo()
> R version 3.0.2 Patched (2013-10-27 r64116)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Switzerland.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> > sample.vec <-
> +   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from',
> 'the',
> +     'named', 'file', 'or', 'URL', 'or', 'connection')
> > dmp.size <- c(10^(1:7))
> > set.seed(37)
> >
> > for(i in dmp.size) {
> +   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
> +   dump('df0', file='testdump')
> +   cat('length:', i, '\n')
> +   print(system.time(source('testdump', keep.source = FALSE,
> +                            encoding='')))
> + }
> length: 10
>     user  system elapsed
>        0       0       0
> length: 100
>     user  system elapsed
>        0       0       0
> length: 1000
>     user  system elapsed
>        0       0       0
> length: 10000
>     user  system elapsed
>     0.01    0.00    0.01
> length: 1e+05
>     user  system elapsed
>     0.36    0.06    0.42
> length: 1e+06
>     user  system elapsed
>     6.02    1.86    7.88
> length: 1e+07
>     user  system elapsed
>   388.63  176.42  566.41
> >
> 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/big-speed-difference-in-
> source-btw-R-2-15-2-and-R-3-0-2-tp4679314p4679346.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From paladini at trustindata.de  Wed Oct 30 17:04:58 2013
From: paladini at trustindata.de (paladini at trustindata.de)
Date: Wed, 30 Oct 2013 17:04:58 +0100
Subject: [R] mapping data to a geographic map of Europe
In-Reply-To: <52701B42.3090200@bitwrit.com.au>
References: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>
	<52701B42.3090200@bitwrit.com.au>
Message-ID: <20131030170458.Horde.BRzJMm0tJPM44BSTPT6Ngw7@webmail.df.eu>

Hi Jim,
thats the second time that you helped  me in a short while so thanks a lot!

But it seems to me quite laborious  and error-prone to first select  
all the relevant countries in this long list and then to create a  
color  vector.
But perhaps I get it all wrong.


For the color vector I first did this

imagecolors<-color.scale(mydata$GPIndex ,c(1,0,0),0,c(0,0,1))

because I wanted the colors to scale from dark red (bad ones) to dark  
blue (good ones).
But it went somehow wrong. By the way can you tell me what I did wrong?

Nevertheless I than createt a color vector looking loke this:

eurocol=c("#FF0000FF",8,"#710000FF","#390000FF",8,8,"#390000FF",rep(8,10),"#2F0000FF"
,8,"#000000FF",8,"#000000FF","#000000FF" ,"#000055FF",8,"#000064FF",2,  
"#000083FF",8,8,"#00008BFF" ,"#0000F0FF" ,rep(8,20),"#0000F7FF"  
,rep(8,18),"#0000FFFF", rep(8,120))


And than

  world.map<-map('world', fill = TRUE,col =eurocol  
,xlim=c(-12,35),ylim=c(37,70))

Beside the wrong colors it worked okay.
But I am not really happy with this solution.

Did I misapprehend you?


Best regards and thanks again

Claudi



Zitat von Jim Lemon <jim at bitwrit.com.au>:

> On 10/30/2013 04:02 AM, paladini at trustindata.de wrote:
>> Hello,
>> I would like to draw a map of Europe. Each country should be colored
>> depending on how it scores in an index called GPIndex.
>> Say a dark red for real bad countries a light red for those which are
>> not so bad, light blue for the fairly good ones and so on up to the
>> really good ones in a dark blue.
>> I never worked with geographic maps before so I tried library maps but I
>> didn't get far,- especially because all examples I found only seem to
>> work for the United states. So I'm a bit lost.
>> I would be nice if somebody could help me.
>>
> Hi Claudia,
> If you draw a map of Europe something like this:
>
> world.map<-map('world', fill = TRUE,
>  col = 1:10,xlim=c(-15,40),ylim=c(37,70))
>
> you have a "col" argument that you can pass the colors you want.  
> What you must do is look at the "names" component of "world.map":
>
> $names
>   [1] "Denmark"
>   [2] "USSR"
>   [3] "Italy"
>   [4] "Netherlands"
>   [5] "Iraq"
> ...
>
> to get the indices of the countries. Say Denmark was fairly good,  
> USSR was fairly bad, and so on. You could then pass colors like this:
>
> col=c("lightblue","lightred",...)
>
> in the call to map for as many countries as you wanted. Pass NA for  
> those countries that you don't want to color.
>
> Jim


From zhifaliu at gmail.com  Wed Oct 30 19:39:10 2013
From: zhifaliu at gmail.com (Zhifa Liu)
Date: Wed, 30 Oct 2013 13:39:10 -0500
Subject: [R] multiple concurrent write in R
Message-ID: <CAAiXAJghkpnMkJ5C=7xeN_QLEdmaKuzi0H+495JKgXJZW39Efw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/c490525e/attachment.pl>

From carl at witthoft.com  Wed Oct 30 20:18:39 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Wed, 30 Oct 2013 12:18:39 -0700 (PDT)
Subject: [R] omitting integer(0) rows from data frame
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5554EA9ACC@GOLD.corp.lgc-group.com>
References: <loom.20131030T140101-323@post.gmane.org>
	<Pine.SOC.4.64.1310301412160.2063@solcom.hrz.uni-giessen.de>
	<A4E5A0B016B8CB41A485FC629B633CED5554EA9ACC@GOLD.corp.lgc-group.com>
Message-ID: <1383160719882-4679386.post@n4.nabble.com>

Both PBurns and DWin are correct.  I just thought I'd add a clunky "safety
check" approach I use now and then:

Before doing the actual subset, i.e.   df[-which(something),]  ,  do
something like 

if (length(which(something)) <1 ) {skip the subsetting} else
df[-which(something)]





--
View this message in context: http://r.789695.n4.nabble.com/omitting-integer-0-rows-from-data-frame-tp4679353p4679386.html
Sent from the R help mailing list archive at Nabble.com.


From wdunlap at tibco.com  Wed Oct 30 20:19:43 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 30 Oct 2013 19:19:43 +0000
Subject: [R] omitting integer(0) rows from data frame
In-Reply-To: <20D7B157-BF89-4DBD-9CC7-4937DA26BC07@comcast.net>
References: <loom.20131030T140101-323@post.gmane.org>
	<20D7B157-BF89-4DBD-9CC7-4937DA26BC07@comcast.net>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1175E@PA-MBX01.na.tibco.com>

> > It would be less surprising if there were no rows omitted in the (B) case.

-integer(0) is identical to integer(0), so how could '[' handle them differently?

> Yes. It is surprising. It is also teh reason why the construction is also not returning what a
> user might expect:
> 
> dat[-which(dat$id >5), ]
> #[1] id  let
> #<0 rows> (or 0-length row.names)
> 
> (And yes I know that many people never use which with a logical. I'm just not one of
> those for what I consider good reasons.)
> 
> `subset` may be preferred,  at least for console interaction:
> 
>  subset( dat, !(id >5) )

Preferring to use which(logical) is ok, as long as you are careful, but subset() will not let you use which().
  > subset(dat, -which(id>5))
  Error in subset.data.frame(dat, -which(id > 5)) :
    'subset' must evaluate to logical

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of David Winsemius
> Sent: Wednesday, October 30, 2013 10:28 AM
> To: Jack Tanner
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] omitting integer(0) rows from data frame
> 
> 
> On Oct 30, 2013, at 6:04 AM, Jack Tanner wrote:
> 
> > I'm not sure if this is correct behavior or not, but it seems counterintuitive
> > to me:
> >
> > dat <- data.frame(id=1:5, let=letters[1:5])
> > # A. omits the first row
> > dat[- 1, ]
> >
> > # B. unexpectedly omits ALL rows
> > dat[- integer(0), ]
> >
> > It would be less surprising if there were no rows omitted in the (B) case.
> 
> Yes. It is surprising. It is also teh reason why the construction is also not returning what a
> user might expect:
> 
> dat[-which(dat$id >5), ]
> #[1] id  let
> #<0 rows> (or 0-length row.names)
> 
> (And yes I know that many people never use which with a logical. I'm just not one of
> those for what I consider good reasons.)
> 
> `subset` may be preferred,  at least for console interaction:
> 
>  subset( dat, !(id >5) )
>   id let
> 1  1   a
> 2  2   b
> 3  3   c
> 4  4   d
> 5  5   e
> 
> --
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From forecast.statistics at gmail.com  Wed Oct 30 13:58:22 2013
From: forecast.statistics at gmail.com (forecast statistics)
Date: Wed, 30 Oct 2013 13:58:22 +0100
Subject: [R] getPortfolio(frontier)$weight
Message-ID: <CALkHSvv8eUH=rsc6BB3_JapsMESewmY77tqvDhS+9-9Q1hD6Ow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/cfb5e8ff/attachment.pl>

From collinl at cs.pitt.edu  Wed Oct 30 20:40:46 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Wed, 30 Oct 2013 15:40:46 -0400
Subject: [R] rpy2 and user defined functions from R
In-Reply-To: <CACxE24nraEizjgEmN2t5mKnA3snWC-QwocM+5RP=zOH2TtqxQQ@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.1310301539240.10079-100000@arsenic.cs.pitt.edu>

I don't believe that rpy2 will load a saved workspace.  When I have worked
with this I always load my functions by sourcing an r file separately:

R.r['source'](MyFuncs.r)


	Best,
	Collin.

On Wed, 30 Oct 2013, Erin Hodgess wrote:

> Here we go:
>
> > buzz
> function(x) {
> y <- x + pi
> return(y)
> }
> > q()
> Save workspace image? [y/n/c]: python
> Save workspace image? [y/n/c]: y
> root at erinminfo [/home/erinminf/public_html]# python
> Python 2.7.5 (default, Sep 11 2013, 02:14:06)
> [GCC 4.1.2 20080704 (Red Hat 4.1.2-54)] on linux2
> Type "help", "copyright", "credits" or "license" for more information.
> >>> import rpy2.robjects as R
> >>> R.r.buzz(3)
> Traceback (most recent call last):
>   File "<stdin>", line 1, in <module>
>   File "/usr/local/lib/python2.7/site-packages/rpy2/robjects/__init__.py",
> line 213, in __getattribute__
>     raise orig_ae
> AttributeError: 'R' object has no attribute 'buzz'
> >>> R.r['buzz'](3)
> Traceback (most recent call last):
>   File "<stdin>", line 1, in <module>
>   File "/usr/local/lib/python2.7/site-packages/rpy2/robjects/__init__.py",
> line 216, in __getitem__
>     res = _globalenv.get(item)
> LookupError: 'buzz' not found
> >>>
> root at erinminfo [/home/erinminf/public_html]#
>
>
> On Wed, Oct 30, 2013 at 10:16 AM, Collin Lynch <collinl at cs.pitt.edu> wrote:
>
> > Erin, one question, can you access the defined functions by key?
> >
> > In lieu of:
> > > x = R.r.buzz(3)
> >
> > Can you do:
> >   x = R.r['buzz'](3)
> >
> >
> > Alternatively if you need only one or two custom functions have you
> > considered just defining them via python as in:
> >
> > PStr = """
> > function(LM) {
> >   S <- summary(LM);
> >   print(S$fstatistic);
> >   F <- S$fstatistic;
> >   P <- pf(F[1], F[2], F[3], lower=FALSE);
> >   return(P);
> > }
> > """
> > r_LMPValFunc = robjects.r(PStr)
> >
> >         Best,
> >         Collin.
> >
> >
> > On Tue, 29 Oct 2013, Erin Hodgess wrote:
> >
> > > Hello again!
> > >
> > > I'm using python with a module rpy2 to call functions from R.
> > >
> > > It works fine on built in R functions like rnorm.
> > >
> > > However, I would like to access user-defined functions as well.  For
> > those
> > > of you who use this, I have:
> > >
> > > import rpy2.robjects as R
> > > R object as no attribute buzz
> > >
> > > (user defined function of buzz)
> > >
> > > This is on a Centos 5 machine with R-3.0.2 and python of 2.7.5.
> > >
> > > Thanks for any help.
> > > Sincerely,
> > > Erin
> > >
> > >
> > >
> > > --
> > > Erin Hodgess
> > > Associate Professor
> > > Department of Computer and Mathematical Sciences
> > > University of Houston - Downtown
> > > mailto: erinm.hodgess at gmail.com
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>


From jdnewmil at dcn.davis.CA.us  Wed Oct 30 20:58:16 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 30 Oct 2013 12:58:16 -0700
Subject: [R] multiple concurrent write in R
In-Reply-To: <CAAiXAJghkpnMkJ5C=7xeN_QLEdmaKuzi0H+495JKgXJZW39Efw@mail.gmail.com>
References: <CAAiXAJghkpnMkJ5C=7xeN_QLEdmaKuzi0H+495JKgXJZW39Efw@mail.gmail.com>
Message-ID: <10c96505-1c63-49db-a0ec-ca9b028ec5f4@email.android.com>

I think the answer is no. Use the master process to manage IO.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Zhifa Liu <zhifaliu at gmail.com> wrote:
>I have over 200  CPUs could write to the same file at the same time, 
>does
>someone know how to handle the multiple concurrent write in R?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From liuwensui at gmail.com  Wed Oct 30 21:42:47 2013
From: liuwensui at gmail.com (Wensui Liu)
Date: Wed, 30 Oct 2013 16:42:47 -0400
Subject: [R] rpy2 and user defined functions from R
In-Reply-To: <CACxE24nOJK9jdGiAOW65edrpTUHihjJfBVGNBW73=CUr=GnAOg@mail.gmail.com>
References: <CACxE24nOJK9jdGiAOW65edrpTUHihjJfBVGNBW73=CUr=GnAOg@mail.gmail.com>
Message-ID: <CAKyN3iDJUx+6cDJ7v8F8n4hCVHnz6JOJf6fBPoTBEYxjpBNjSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/7abdb89c/attachment.pl>

From tuechler at gmx.at  Wed Oct 30 21:42:53 2013
From: tuechler at gmx.at (Heinz Tuechler)
Date: Wed, 30 Oct 2013 21:42:53 +0100
Subject: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA11732@PA-MBX01.na.tibco.com>
References: <52704C18.6020905@gmx.at>
	<1383136127835-4679346.post@n4.nabble.com>
	<E66794E69CFDE04D9A70842786030B933FA11732@PA-MBX01.na.tibco.com>
Message-ID: <52716F4D.7040009@gmx.at>

Best thanks for confirming my impression. I use dump for storing large 
data.frames with a number of attributes for each variable. save/load is 
much faster, but I am unsure, if such files will be readable by R 
versions years later.
What format/functions would you suggest for data storage/transfer 
between different (future) R versions?

best regards,
Heinz

on/am 30.10.2013 20:11, William Dunlap wrote/hat geschrieben:
> I see a big 2.15.2/3.0.2 speed difference in parse() (which is used by source())
> when it is parsing long vectors of numeric data.  dump/source has never been an efficient
> way of transferring data between different R session, but it is much worse
> now for long vectors.   In 2.15.2 doubling the size of the vector (of lengths
> in the range 10^4 to 10^7) makes the time to parse go up by a factor of c. 2.1.
> In 3.0.2 that factor is more like 4.4.
>
>         n elapsed-2.15.2 elapsed-3.0.2
>      2048          0.003         0.018
>      4096          0.006         0.065
>      8192          0.013         0.254
>     16384          0.025         1.067
>     32768          0.050         4.114
>     65536          0.100        16.236
>    131072          0.219        66.013
>    262144          0.808       291.883
>    524288          2.022      1285.265
>   1048576          4.918            NA
>   2097152          9.857            NA
>   4194304         22.916            NA
>   8388608         49.671            NA
> 16777216        101.042            NA
> 33554432        512.719            NA
>
> I tried this with 64-bit R on a Linux box.  The NA's represent sizes that did not
> finish while I was at a 1 1/2 hour dentist's apppointment.  The timing function
> was:
>    test <- function(n = 2^(11:25))
>    {
>        tf <- tempfile()
>        on.exit(unlink(tf))
>        t(sapply(n, function(n){
>            dput(log(seq_len(n)), file=tf)
>            print(c(n=n, system.time(parse(file=tf))[1:3]))
>        }))
>    }
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Carl Witthoft
>> Sent: Wednesday, October 30, 2013 5:29 AM
>> To: r-help at r-project.org
>> Subject: Re: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
>>
>> Did you run the identical code on the identical machine, and did you verify
>> there were no other tasks running which might have limited the RAM available
>> to R?  And equally important, did you run these tests in the reverse order
>> (in case R was storing large objects from the first run, thus chewing up
>> RAM)?
>>
>>
>>
>> Dear All,
>>
>> is it known that source works much faster in  R 2.15.2 than in R 3.0.2 ?
>> In the example below I observe e.g. for a data.frame with 10^7 rows the
>> following timings:
>>
>> R version 2.15.2 Patched (2012-11-29 r61184)
>> length: 1e+07
>>      user  system elapsed
>>     62.04    0.22   62.26
>>
>> R version 3.0.2 Patched (2013-10-27 r64116)
>> length: 1e+07
>>      user  system elapsed
>>    388.63  176.42  566.41
>>
>> Is there a way to speed R version 3.0.2 up to the performance of R
>> version 2.15.2?
>>
>> best regards,
>>
>> Heinz T?chler
>>
>>
>> example:
>> sessionInfo()
>> sample.vec <-
>>     c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from', 'the',
>>       'named', 'file', 'or', 'URL', 'or', 'connection')
>> dmp.size <- c(10^(1:7))
>> set.seed(37)
>>
>> for(i in dmp.size) {
>>     df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
>>     dump('df0', file='testdump')
>>     cat('length:', i, '\n')
>>     print(system.time(source('testdump', keep.source = FALSE,
>>                              encoding='')))
>> }
>>
>> output for R version 2.15.2 Patched (2012-11-29 r61184):
>>> sessionInfo()
>> R version 2.15.2 Patched (2012-11-29 r61184)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
>> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
>> [5] LC_TIME=German_Switzerland.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> sample.vec <-
>> +   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from',
>> 'the',
>> +     'named', 'file', 'or', 'URL', 'or', 'connection')
>>> dmp.size <- c(10^(1:7))
>>> set.seed(37)
>>>
>>> for(i in dmp.size) {
>> +   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
>> +   dump('df0', file='testdump')
>> +   cat('length:', i, '\n')
>> +   print(system.time(source('testdump', keep.source = FALSE,
>> +                            encoding='')))
>> + }
>> length: 10
>>      user  system elapsed
>>         0       0       0
>> length: 100
>>      user  system elapsed
>>         0       0       0
>> length: 1000
>>      user  system elapsed
>>         0       0       0
>> length: 10000
>>      user  system elapsed
>>      0.02    0.00    0.01
>> length: 1e+05
>>      user  system elapsed
>>      0.21    0.00    0.20
>> length: 1e+06
>>      user  system elapsed
>>      4.47    0.04    4.51
>> length: 1e+07
>>      user  system elapsed
>>     62.04    0.22   62.26
>>>
>>
>>
>> output for R version 3.0.2 Patched (2013-10-27 r64116):
>>> sessionInfo()
>> R version 3.0.2 Patched (2013-10-27 r64116)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
>> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
>> [5] LC_TIME=German_Switzerland.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> sample.vec <-
>> +   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from',
>> 'the',
>> +     'named', 'file', 'or', 'URL', 'or', 'connection')
>>> dmp.size <- c(10^(1:7))
>>> set.seed(37)
>>>
>>> for(i in dmp.size) {
>> +   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
>> +   dump('df0', file='testdump')
>> +   cat('length:', i, '\n')
>> +   print(system.time(source('testdump', keep.source = FALSE,
>> +                            encoding='')))
>> + }
>> length: 10
>>      user  system elapsed
>>         0       0       0
>> length: 100
>>      user  system elapsed
>>         0       0       0
>> length: 1000
>>      user  system elapsed
>>         0       0       0
>> length: 10000
>>      user  system elapsed
>>      0.01    0.00    0.01
>> length: 1e+05
>>      user  system elapsed
>>      0.36    0.06    0.42
>> length: 1e+06
>>      user  system elapsed
>>      6.02    1.86    7.88
>> length: 1e+07
>>      user  system elapsed
>>    388.63  176.42  566.41
>>>
>>
>>
>>
>>
>>
>> --
>> View this message in context: http://r.789695.n4.nabble.com/big-speed-difference-in-
>> source-btw-R-2-15-2-and-R-3-0-2-tp4679314p4679346.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Wed Oct 30 22:13:11 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 30 Oct 2013 21:13:11 +0000
Subject: [R] multiple concurrent write in R
In-Reply-To: <10c96505-1c63-49db-a0ec-ca9b028ec5f4@email.android.com>
References: <CAAiXAJghkpnMkJ5C=7xeN_QLEdmaKuzi0H+495JKgXJZW39Efw@mail.gmail.com>
	<10c96505-1c63-49db-a0ec-ca9b028ec5f4@email.android.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA117E5@PA-MBX01.na.tibco.com>

On Linux, at least, you can have various processes write into the same file, by opening
it with "r+" mode and calling seek() to position the file pointer before writing.   E.g.,

> library(parallel)
> cl4 <- makeCluster(4)
> tf <- tempfile()
> cat(rep("--------", 2*length(cl4)), sep="\n", file=tf)
> readLines(tf)
[1] "--------" "--------" "--------" "--------" "--------" "--------" "--------"
[8] "--------"
> z <- parLapply(cl4, 8:1, function(i, tf){
                                                 f <- file(tf, open="r+")
                                                 on.exit(close(f))
                                                 seek(f, (i-1)*9, rw="w") 
                                                 ret <- c(i, Sys.getpid())
                                                 cat(ret, file=f); ret},
                                               tf=tf)
> readLines(tf)
[1] "1 22406-" "2 22406-" "3 22397-" "4 22397-" "5 22388-" "6 22388-" "7 22379-"
[8] "8 22379-"

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Jeff Newmiller
> Sent: Wednesday, October 30, 2013 12:58 PM
> To: Zhifa Liu; r-help at r-project.org
> Subject: Re: [R] multiple concurrent write in R
> 
> I think the answer is no. Use the master process to manage IO.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
> 
> Zhifa Liu <zhifaliu at gmail.com> wrote:
> >I have over 200  CPUs could write to the same file at the same time,
> >does
> >someone know how to handle the multiple concurrent write in R?
> >
> >	[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Wed Oct 30 22:14:45 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 30 Oct 2013 16:14:45 -0500
Subject: [R] help me align the legend bar
In-Reply-To: <1383152955.50964.YahooMailNeo@web125305.mail.ne1.yahoo.com>
References: <1383152955.50964.YahooMailNeo@web125305.mail.ne1.yahoo.com>
Message-ID: <CAN5YmCF7botn=1U7JwNLRvPpL93RxPF4Esnu8DGd=mde=7S=dg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/f336223d/attachment.pl>

From wdunlap at tibco.com  Wed Oct 30 22:15:20 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 30 Oct 2013 21:15:20 +0000
Subject: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
In-Reply-To: <52716F4D.7040009@gmx.at>
References: <52704C18.6020905@gmx.at>
	<1383136127835-4679346.post@n4.nabble.com>
	<E66794E69CFDE04D9A70842786030B933FA11732@PA-MBX01.na.tibco.com>
	<52716F4D.7040009@gmx.at>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA117F8@PA-MBX01.na.tibco.com>

I have to defer to others for policy declarations like how long
the current format used by load and save should be readable.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Heinz Tuechler [mailto:tuechler at gmx.at]
> Sent: Wednesday, October 30, 2013 1:43 PM
> To: William Dunlap
> Cc: Carl Witthoft; r-help at r-project.org
> Subject: Re: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
> 
> Best thanks for confirming my impression. I use dump for storing large
> data.frames with a number of attributes for each variable. save/load is
> much faster, but I am unsure, if such files will be readable by R
> versions years later.
> What format/functions would you suggest for data storage/transfer
> between different (future) R versions?
> 
> best regards,
> Heinz
> 
> on/am 30.10.2013 20:11, William Dunlap wrote/hat geschrieben:
> > I see a big 2.15.2/3.0.2 speed difference in parse() (which is used by source())
> > when it is parsing long vectors of numeric data.  dump/source has never been an
> efficient
> > way of transferring data between different R session, but it is much worse
> > now for long vectors.   In 2.15.2 doubling the size of the vector (of lengths
> > in the range 10^4 to 10^7) makes the time to parse go up by a factor of c. 2.1.
> > In 3.0.2 that factor is more like 4.4.
> >
> >         n elapsed-2.15.2 elapsed-3.0.2
> >      2048          0.003         0.018
> >      4096          0.006         0.065
> >      8192          0.013         0.254
> >     16384          0.025         1.067
> >     32768          0.050         4.114
> >     65536          0.100        16.236
> >    131072          0.219        66.013
> >    262144          0.808       291.883
> >    524288          2.022      1285.265
> >   1048576          4.918            NA
> >   2097152          9.857            NA
> >   4194304         22.916            NA
> >   8388608         49.671            NA
> > 16777216        101.042            NA
> > 33554432        512.719            NA
> >
> > I tried this with 64-bit R on a Linux box.  The NA's represent sizes that did not
> > finish while I was at a 1 1/2 hour dentist's apppointment.  The timing function
> > was:
> >    test <- function(n = 2^(11:25))
> >    {
> >        tf <- tempfile()
> >        on.exit(unlink(tf))
> >        t(sapply(n, function(n){
> >            dput(log(seq_len(n)), file=tf)
> >            print(c(n=n, system.time(parse(file=tf))[1:3]))
> >        }))
> >    }
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf
> >> Of Carl Witthoft
> >> Sent: Wednesday, October 30, 2013 5:29 AM
> >> To: r-help at r-project.org
> >> Subject: Re: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
> >>
> >> Did you run the identical code on the identical machine, and did you verify
> >> there were no other tasks running which might have limited the RAM available
> >> to R?  And equally important, did you run these tests in the reverse order
> >> (in case R was storing large objects from the first run, thus chewing up
> >> RAM)?
> >>
> >>
> >>
> >> Dear All,
> >>
> >> is it known that source works much faster in  R 2.15.2 than in R 3.0.2 ?
> >> In the example below I observe e.g. for a data.frame with 10^7 rows the
> >> following timings:
> >>
> >> R version 2.15.2 Patched (2012-11-29 r61184)
> >> length: 1e+07
> >>      user  system elapsed
> >>     62.04    0.22   62.26
> >>
> >> R version 3.0.2 Patched (2013-10-27 r64116)
> >> length: 1e+07
> >>      user  system elapsed
> >>    388.63  176.42  566.41
> >>
> >> Is there a way to speed R version 3.0.2 up to the performance of R
> >> version 2.15.2?
> >>
> >> best regards,
> >>
> >> Heinz T?chler
> >>
> >>
> >> example:
> >> sessionInfo()
> >> sample.vec <-
> >>     c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from', 'the',
> >>       'named', 'file', 'or', 'URL', 'or', 'connection')
> >> dmp.size <- c(10^(1:7))
> >> set.seed(37)
> >>
> >> for(i in dmp.size) {
> >>     df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
> >>     dump('df0', file='testdump')
> >>     cat('length:', i, '\n')
> >>     print(system.time(source('testdump', keep.source = FALSE,
> >>                              encoding='')))
> >> }
> >>
> >> output for R version 2.15.2 Patched (2012-11-29 r61184):
> >>> sessionInfo()
> >> R version 2.15.2 Patched (2012-11-29 r61184)
> >> Platform: x86_64-w64-mingw32/x64 (64-bit)
> >>
> >> locale:
> >> [1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
> >> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
> >> [5] LC_TIME=German_Switzerland.1252
> >>
> >> attached base packages:
> >> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>> sample.vec <-
> >> +   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from',
> >> 'the',
> >> +     'named', 'file', 'or', 'URL', 'or', 'connection')
> >>> dmp.size <- c(10^(1:7))
> >>> set.seed(37)
> >>>
> >>> for(i in dmp.size) {
> >> +   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
> >> +   dump('df0', file='testdump')
> >> +   cat('length:', i, '\n')
> >> +   print(system.time(source('testdump', keep.source = FALSE,
> >> +                            encoding='')))
> >> + }
> >> length: 10
> >>      user  system elapsed
> >>         0       0       0
> >> length: 100
> >>      user  system elapsed
> >>         0       0       0
> >> length: 1000
> >>      user  system elapsed
> >>         0       0       0
> >> length: 10000
> >>      user  system elapsed
> >>      0.02    0.00    0.01
> >> length: 1e+05
> >>      user  system elapsed
> >>      0.21    0.00    0.20
> >> length: 1e+06
> >>      user  system elapsed
> >>      4.47    0.04    4.51
> >> length: 1e+07
> >>      user  system elapsed
> >>     62.04    0.22   62.26
> >>>
> >>
> >>
> >> output for R version 3.0.2 Patched (2013-10-27 r64116):
> >>> sessionInfo()
> >> R version 3.0.2 Patched (2013-10-27 r64116)
> >> Platform: x86_64-w64-mingw32/x64 (64-bit)
> >>
> >> locale:
> >> [1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
> >> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
> >> [5] LC_TIME=German_Switzerland.1252
> >>
> >> attached base packages:
> >> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>> sample.vec <-
> >> +   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from',
> >> 'the',
> >> +     'named', 'file', 'or', 'URL', 'or', 'connection')
> >>> dmp.size <- c(10^(1:7))
> >>> set.seed(37)
> >>>
> >>> for(i in dmp.size) {
> >> +   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
> >> +   dump('df0', file='testdump')
> >> +   cat('length:', i, '\n')
> >> +   print(system.time(source('testdump', keep.source = FALSE,
> >> +                            encoding='')))
> >> + }
> >> length: 10
> >>      user  system elapsed
> >>         0       0       0
> >> length: 100
> >>      user  system elapsed
> >>         0       0       0
> >> length: 1000
> >>      user  system elapsed
> >>         0       0       0
> >> length: 10000
> >>      user  system elapsed
> >>      0.01    0.00    0.01
> >> length: 1e+05
> >>      user  system elapsed
> >>      0.36    0.06    0.42
> >> length: 1e+06
> >>      user  system elapsed
> >>      6.02    1.86    7.88
> >> length: 1e+07
> >>      user  system elapsed
> >>    388.63  176.42  566.41
> >>>
> >>
> >>
> >>
> >>
> >>
> >> --
> >> View this message in context: http://r.789695.n4.nabble.com/big-speed-difference-
> in-
> >> source-btw-R-2-15-2-and-R-3-0-2-tp4679314p4679346.html
> >> Sent from the R help mailing list archive at Nabble.com.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From jim at bitwrit.com.au  Wed Oct 30 22:38:18 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 31 Oct 2013 08:38:18 +1100
Subject: [R] (no subject)
In-Reply-To: <CAFQvP01n8Y+hu5yNw1Fxz9GqYexbSpxbTLhaFnCBVd3eNWShFg@mail.gmail.com>
References: <CAFQvP01n8Y+hu5yNw1Fxz9GqYexbSpxbTLhaFnCBVd3eNWShFg@mail.gmail.com>
Message-ID: <52717C4A.8020105@bitwrit.com.au>

On 10/30/2013 11:03 PM, Stevan Lauriault wrote:
> Hi,
>
> I'm looking for a function that takes a list and calculates a score based on
> how well "like attracts like".
> For example:
>
> list1<- c(john, eric, steve, john, eric, scott, john)
> list2<- c(john, john, john, eric, eric, steve, scott)
>
> score(list1)<  score(list2)
>
> Both lists are composed of the same names and frequency of each
> name.
>
> Not sure how else to put it.  I am relatively new to R.  Have tried the
> modularity function, but can't seem to get it to work for this purpose.
>
>
Hi Steve,
My first guess would be a distance function. Something like the variance 
of the indices of the various names:

by(1:length(list1),list1,var)
by(1:length(list2),list2,var)

How you will handle the NAs generated by single names is another matter.

Jim


From jim at bitwrit.com.au  Wed Oct 30 22:59:18 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 31 Oct 2013 08:59:18 +1100
Subject: [R] mapping data to a geographic map of Europe
In-Reply-To: <20131030170458.Horde.BRzJMm0tJPM44BSTPT6Ngw7@webmail.df.eu>
References: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>
	<52701B42.3090200@bitwrit.com.au>
	<20131030170458.Horde.BRzJMm0tJPM44BSTPT6Ngw7@webmail.df.eu>
Message-ID: <52718136.1080500@bitwrit.com.au>

On 10/31/2013 03:04 AM, paladini at trustindata.de wrote:
> Hi Jim,
> thats the second time that you helped me in a short while so thanks a lot!
>
> But it seems to me quite laborious and error-prone to first select all
> the relevant countries in this long list and then to create a color vector.
> But perhaps I get it all wrong.
>
>
> For the color vector I first did this
>
> imagecolors<-color.scale(mydata$GPIndex ,c(1,0,0),0,c(0,0,1))
>
> because I wanted the colors to scale from dark red (bad ones) to dark
> blue (good ones).
> But it went somehow wrong. By the way can you tell me what I did wrong?
>
> Nevertheless I than createt a color vector looking loke this:
>
> eurocol=c("#FF0000FF",8,"#710000FF","#390000FF",8,8,"#390000FF",rep(8,10),"#2F0000FF"
>
> ,8,"#000000FF",8,"#000000FF","#000000FF" ,"#000055FF",8,"#000064FF",2,
> "#000083FF",8,8,"#00008BFF" ,"#0000F0FF" ,rep(8,20),"#0000F7FF"
> ,rep(8,18),"#0000FFFF", rep(8,120))
>
>
> And than
>
> world.map<-map('world', fill = TRUE,col =eurocol
> ,xlim=c(-12,35),ylim=c(37,70))
>
> Beside the wrong colors it worked okay.
> But I am not really happy with this solution.
>
> Did I misapprehend you?
>
Hi Claudi,
Maybe. You write that the transformation of GPIndex to colors "went 
wrong". Let's see:

# make up GPIndex
GPIndex<-c(sample(1:100,33),rep(NA,165))
# transform to colors
eurocol<-color.scale(GPIndex,c(1,0),0,c(0,1))
world.map<-map('world',fill=TRUE,
  col=eurocol,xlim=c(-12,35),ylim=c(37,70))

This gives me what I would expect, and checking the colors against the 
country names (world.map$names) looks like the correct colors have been 
displayed. Obviously I left a lot of areas out (missed UK and Ireland 
for example) as I didn't want to overplot individual countries with 
areas. Does this look okay to you?

Jim


From erinm.hodgess at gmail.com  Thu Oct 31 01:32:09 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 30 Oct 2013 19:32:09 -0500
Subject: [R]  an rpy2, R cgi type question
Message-ID: <CACxE24k8-BDeMxpcC-uMVga7FhKrA1Bu2BV9nLVzbvEQDr2FFQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/cc016e62/attachment.pl>

From p.drioux at gmail.com  Wed Oct 30 22:34:06 2013
From: p.drioux at gmail.com (Patrick Rioux)
Date: Wed, 30 Oct 2013 17:34:06 -0400
Subject: [R] Rterm
Message-ID: <CACuK3vhPmdE9yvMM==raL_Y=rjRXREXs0zkeSHg_665cApjg8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/f88df196/attachment.pl>

From sartene at voila.fr  Wed Oct 30 23:41:58 2013
From: sartene at voila.fr (sartene at voila.fr)
Date: Wed, 30 Oct 2013 23:41:58 +0100 (CET)
Subject: [R] Irregular time series frequencies
Message-ID: <1373698256.137741383172918499.JavaMail.www@wwinf7139>

Hi everyone,

I have a data frame with email addresses in the first column and in the second column a list of times (of different lengths) at which an email was sent from the 
user in the first column.

Here is an example of my data:

Email Email_sent
john at doe.com "2013-09-26 15:59:55" "2013-09-27 09:48:29" "2013-09-27 10:00:02" "2013-09-27 10:12:54" 
jane at shoe.com "2013-09-26 09:50:28" "2013-09-26 14:41:24" "2013-09-26 14:51:36" "2013-09-26 17:50:10" "2013-09-27 13:34:02" "2013-09-27 14:41:10" 
"2013-09-27 15:37:36"
...

I cannot find any way to calculate the frequencies between each email sent for each user:
john at doe.com 0.02 email / hour
jane at shoe.com 0.15 email / hour
...

Can anyone help me on this problem?

The ultimate goal (which seems amibitious at this time) is to calculate, for each user, the frequencies between each mail per day, between the first email sent 
and the last email sent each day (to avoid taking nights into account), i.e.:

2013-09-26 2013-09-27
john at doe.com 1.32 emails / hour 0.56 emails / hour
jane at shoe.com 10.57 emails / hour 2.54 emails / hour
...

At this time it seems pretty impossible, but I guess I will eventually find a way :-)

Thanks a lot,


Sartene Bel
R learner
___________________________________________________________
Qu'y a-t-il ce soir ? la t?l? ? D'un coup d'?il, visualisez le programme sur Voila.fr http://tv.voila.fr/programmes/chaines-tnt/ce-soir.html


From robert.b.lynch at gmail.com  Thu Oct 31 03:27:05 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Wed, 30 Oct 2013 19:27:05 -0700
Subject: [R] getting p-value for comparing to gam's from gmcv
Message-ID: <CACYeG1ii+5S0brmPrL+wwi4mwvTSk5cXkVtgo1xZ6xKADPB0sA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131030/3916eee9/attachment.pl>

From collinl at cs.pitt.edu  Thu Oct 31 04:51:37 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Wed, 30 Oct 2013 23:51:37 -0400
Subject: [R] an rpy2, R cgi type question
In-Reply-To: <CACxE24k8-BDeMxpcC-uMVga7FhKrA1Bu2BV9nLVzbvEQDr2FFQ@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.1310302350580.12472-100000@oxygen.cs.pitt.edu>

Erin can you share the internal error details?

As a first guess are the files executable by all?  CGI requires world rwx.

	Best,
	Collin.

On Wed, 30 Oct 2013, Erin Hodgess wrote:

> Hi again.
>
> I'm putting together a little project with R, python, and a website.  So I
> have an HTML file, a py file, an R file.
>
> Here is the HTML file:
> <form action="/cgi-bin/radio4.py" method="post" target="_blank">
> <input type="radio" name="subject" value="Integrate" /> Integrate
> <input type="radio" name="subject" value="Differentiate" /> Differentiate
> <input type="radio" name="subject" value="Graph" /> Graph
> Function <input type="text"  name="func1" <br />
> <input type="submit" value="Select Subject" />
> </form>
>
> Now the radio4.py file:
>
> # Import modules for CGI handling
> import cgi, cgitb
> from sympy import *
> import sys
>
> from rpy2.robjects.packages import SignatureTranslatedAnonymousPackage as
> STAP
> with open("bz2.R","r") as f:
>     string=''.join(f.readlines())
> etest = STAP(string,"etest")
> etest.etest(500)
>
>
> # Create instance of FieldStorage
> form = cgi.FieldStorage()
>
> # Get data from fields
> if form.getvalue('subject'):
>    subject = form.getvalue('subject')
> else:
>    subject = "Not set"
>
> if form.getvalue('func1'):
>    func1 = form.getvalue('func1')
> else:
>    func1 = "Not entered"
>
>
>
>
>
> print "Content-type:text/html\r\n\r\n"
> print "<html>"
> print "<head>"
> print "<title>Test Project</title>"
> print "</head>"
> print "<body>"
> print "<h2> Selected Action is %s</h2>" % subject
> print "<h3> output function is %s</h3>" % func1
> print "</body>"
> print "</html>"
>
>
> Finally, the bz2.R file:
>
> etest <- function(n=100) {
>     y <- rnorm(n)
>     pdf(file="lap1.png")
>     plot(y)
>     dev.off()
> }
>
>
> The radio4.py file is in a cgi-bin directory, along with the bz2.R file.
>
> I keep getting the Internal server error.
>
> Thanks for any help.
>
> Sincerely,
> Erin
>
> This is R version 3.0.2 and Python 2.7.5
>
> --
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From erinm.hodgess at gmail.com  Thu Oct 31 06:50:34 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 31 Oct 2013 00:50:34 -0500
Subject: [R] an rpy2, R cgi type question
In-Reply-To: <Pine.LNX.4.44.1310302350580.12472-100000@oxygen.cs.pitt.edu>
References: <CACxE24k8-BDeMxpcC-uMVga7FhKrA1Bu2BV9nLVzbvEQDr2FFQ@mail.gmail.com>
	<Pine.LNX.4.44.1310302350580.12472-100000@oxygen.cs.pitt.edu>
Message-ID: <CACxE24nQEnLeoV+xen7QC-JGmosJWbC9bOaz8y9jQdLgF=9kcQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/b4e94c82/attachment.pl>

From Achim.Zeileis at uibk.ac.at  Thu Oct 31 08:48:07 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 31 Oct 2013 08:48:07 +0100 (CET)
Subject: [R] Irregular time series frequencies
In-Reply-To: <1373698256.137741383172918499.JavaMail.www@wwinf7139>
References: <1373698256.137741383172918499.JavaMail.www@wwinf7139>
Message-ID: <alpine.DEB.2.10.1310310839510.13198@paninaro.uibk.ac.at>

On Wed, 30 Oct 2013, sartene at voila.fr wrote:

> Hi everyone,
>
> I have a data frame with email addresses in the first column and in the second column a list of times (of different lengths) at which an email was sent from the 
> user in the first column.
>
> Here is an example of my data:
>
> Email Email_sent
> john at doe.com "2013-09-26 15:59:55" "2013-09-27 09:48:29" "2013-09-27 10:00:02" "2013-09-27 10:12:54" 
> jane at shoe.com "2013-09-26 09:50:28" "2013-09-26 14:41:24" "2013-09-26 14:51:36" "2013-09-26 17:50:10" "2013-09-27 13:34:02" "2013-09-27 14:41:10" 
> "2013-09-27 15:37:36"
> ...
>
> I cannot find any way to calculate the frequencies between each email sent for each user:
> john at doe.com 0.02 email / hour
> jane at shoe.com 0.15 email / hour
> ...
>
> Can anyone help me on this problem?

You could do something like this:

## scan your data file
d <- scan(<yourfile>, what = "character")

## here I use the data from above
d <- scan(textConnection('john at doe.com "2013-09-26 15:59:55"
"2013-09-27 09:48:29" "2013-09-27 10:00:02" "2013-09-27 10:12:54"
jane at shoe.com "2013-09-26 09:50:28" "2013-09-26 14:41:24"
"2013-09-26 14:51:36" "2013-09-26 17:50:10" "2013-09-27 13:34:02"
"2013-09-27 14:41:10" "2013-09-27 15:37:36"'), what = "character")

## find position of e-mail addresses
n <- grep("@", dc, fixed = TRUE)

## extract list of dates
n <- c(n, length(d) + 1)
x <- lapply(1:(length(n) - 1),
   function(i) as.POSIXct(d[(n[i] + 1):(n[i+1] - 1)]))

## add e-mail addresses as names
names(x) <- d[head(n, -1)]

## functions that could extract quantities of interest such as
## number of mails per hour or mean time difference etc.
meantime <- function(timevec)
   mean(as.numeric(diff(timevec), units = "hours"))
numperhour <- function(timevec)
   length(timevec) / as.numeric(diff(range(timevec)), units = "hours")

## apply to full list
sapply(x, numperhour)
sapply(x, meantime)

## apply to list by date
sapply(x, function(timevec) tapply(timevec, as.Date(timevec), numperhour))
sapply(x, function(timevec) tapply(timevec, as.Date(timevec), meantime))

hth,
Z

> The ultimate goal (which seems amibitious at this time) is to calculate, for each user, the frequencies between each mail per day, between the first email sent 
> and the last email sent each day (to avoid taking nights into account), i.e.:
>
> 2013-09-26 2013-09-27
> john at doe.com 1.32 emails / hour 0.56 emails / hour
> jane at shoe.com 10.57 emails / hour 2.54 emails / hour
> ...
>
> At this time it seems pretty impossible, but I guess I will eventually find a way :-)
>
> Thanks a lot,
>
>
> Sartene Bel
> R learner
> ___________________________________________________________
> Qu'y a-t-il ce soir ? la t?l? ? D'un coup d'?il, visualisez le programme sur Voila.fr http://tv.voila.fr/programmes/chaines-tnt/ce-soir.html
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From es at enricoschumann.net  Thu Oct 31 08:52:53 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Thu, 31 Oct 2013 08:52:53 +0100
Subject: [R] Yield to maturity in R
In-Reply-To: <1383123543.17795.YahooMailNeo@web193202.mail.sg3.yahoo.com>
	(Katherine Gobin's message of "Wed, 30 Oct 2013 16:59:03 +0800 (SGT)")
References: <1383123543.17795.YahooMailNeo@web193202.mail.sg3.yahoo.com>
Message-ID: <87iowdj2qy.fsf@enricoschumann.net>

On Wed, 30 Oct 2013, Katherine Gobin <katherine_gobin at yahoo.com> writes:

> Dear R forum,
>
> Just want to know if there is any function / package in R which will calculate Yield to Maturity in R for a given bond?
>
> Regards
>
> Katherine


require("sos")
findFn("yield to maturity")


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From ripley at stats.ox.ac.uk  Thu Oct 31 09:12:33 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 31 Oct 2013 08:12:33 +0000
Subject: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA117F8@PA-MBX01.na.tibco.com>
References: <52704C18.6020905@gmx.at>	<1383136127835-4679346.post@n4.nabble.com>	<E66794E69CFDE04D9A70842786030B933FA11732@PA-MBX01.na.tibco.com>	<52716F4D.7040009@gmx.at>
	<E66794E69CFDE04D9A70842786030B933FA117F8@PA-MBX01.na.tibco.com>
Message-ID: <527210F1.9050605@stats.ox.ac.uk>

On 30/10/2013 21:15, William Dunlap wrote:
> I have to defer to others for policy declarations like how long
> the current format used by load and save should be readable.

You could also ask how long R will last ....

R can still read (but not write) save() formats used in the 1990's.  We 
would expect R to be able to read saves since R 1.0.0 for as long as R 
exists.  And as R is Open Source, you would be able to compile it and 
dump the objects you want for as long as suitable compilers and OSes 
exist ....  And of course R is not the only application which will read 
the format.

There is no guarantee that source() will be able to parse dumps from 
earlier versions of R, and that has not always been true.

People commenting on parse() speed should note the NEWS for R-devel:

     ? The parser has been modified to use less memory.


>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: Heinz Tuechler [mailto:tuechler at gmx.at]
>> Sent: Wednesday, October 30, 2013 1:43 PM
>> To: William Dunlap
>> Cc: Carl Witthoft; r-help at r-project.org
>> Subject: Re: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
>>
>> Best thanks for confirming my impression. I use dump for storing large
>> data.frames with a number of attributes for each variable. save/load is
>> much faster, but I am unsure, if such files will be readable by R
>> versions years later.
>> What format/functions would you suggest for data storage/transfer
>> between different (future) R versions?
>>
>> best regards,
>> Heinz
>>
>> on/am 30.10.2013 20:11, William Dunlap wrote/hat geschrieben:
>>> I see a big 2.15.2/3.0.2 speed difference in parse() (which is used by source())
>>> when it is parsing long vectors of numeric data.  dump/source has never been an
>> efficient
>>> way of transferring data between different R session, but it is much worse
>>> now for long vectors.   In 2.15.2 doubling the size of the vector (of lengths
>>> in the range 10^4 to 10^7) makes the time to parse go up by a factor of c. 2.1.
>>> In 3.0.2 that factor is more like 4.4.
>>>
>>>          n elapsed-2.15.2 elapsed-3.0.2
>>>       2048          0.003         0.018
>>>       4096          0.006         0.065
>>>       8192          0.013         0.254
>>>      16384          0.025         1.067
>>>      32768          0.050         4.114
>>>      65536          0.100        16.236
>>>     131072          0.219        66.013
>>>     262144          0.808       291.883
>>>     524288          2.022      1285.265
>>>    1048576          4.918            NA
>>>    2097152          9.857            NA
>>>    4194304         22.916            NA
>>>    8388608         49.671            NA
>>> 16777216        101.042            NA
>>> 33554432        512.719            NA
>>>
>>> I tried this with 64-bit R on a Linux box.  The NA's represent sizes that did not
>>> finish while I was at a 1 1/2 hour dentist's apppointment.  The timing function
>>> was:
>>>     test <- function(n = 2^(11:25))
>>>     {
>>>         tf <- tempfile()
>>>         on.exit(unlink(tf))
>>>         t(sapply(n, function(n){
>>>             dput(log(seq_len(n)), file=tf)
>>>             print(c(n=n, system.time(parse(file=tf))[1:3]))
>>>         }))
>>>     }
>>>
>>> Bill Dunlap
>>> Spotfire, TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>>> -----Original Message-----
>>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
>> Behalf
>>>> Of Carl Witthoft
>>>> Sent: Wednesday, October 30, 2013 5:29 AM
>>>> To: r-help at r-project.org
>>>> Subject: Re: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
>>>>
>>>> Did you run the identical code on the identical machine, and did you verify
>>>> there were no other tasks running which might have limited the RAM available
>>>> to R?  And equally important, did you run these tests in the reverse order
>>>> (in case R was storing large objects from the first run, thus chewing up
>>>> RAM)?
>>>>
>>>>
>>>>
>>>> Dear All,
>>>>
>>>> is it known that source works much faster in  R 2.15.2 than in R 3.0.2 ?
>>>> In the example below I observe e.g. for a data.frame with 10^7 rows the
>>>> following timings:
>>>>
>>>> R version 2.15.2 Patched (2012-11-29 r61184)
>>>> length: 1e+07
>>>>       user  system elapsed
>>>>      62.04    0.22   62.26
>>>>
>>>> R version 3.0.2 Patched (2013-10-27 r64116)
>>>> length: 1e+07
>>>>       user  system elapsed
>>>>     388.63  176.42  566.41
>>>>
>>>> Is there a way to speed R version 3.0.2 up to the performance of R
>>>> version 2.15.2?
>>>>
>>>> best regards,
>>>>
>>>> Heinz T?chler
>>>>
>>>>
>>>> example:
>>>> sessionInfo()
>>>> sample.vec <-
>>>>      c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from', 'the',
>>>>        'named', 'file', 'or', 'URL', 'or', 'connection')
>>>> dmp.size <- c(10^(1:7))
>>>> set.seed(37)
>>>>
>>>> for(i in dmp.size) {
>>>>      df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
>>>>      dump('df0', file='testdump')
>>>>      cat('length:', i, '\n')
>>>>      print(system.time(source('testdump', keep.source = FALSE,
>>>>                               encoding='')))
>>>> }
>>>>
>>>> output for R version 2.15.2 Patched (2012-11-29 r61184):
>>>>> sessionInfo()
>>>> R version 2.15.2 Patched (2012-11-29 r61184)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
>>>> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
>>>> [5] LC_TIME=German_Switzerland.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>> sample.vec <-
>>>> +   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from',
>>>> 'the',
>>>> +     'named', 'file', 'or', 'URL', 'or', 'connection')
>>>>> dmp.size <- c(10^(1:7))
>>>>> set.seed(37)
>>>>>
>>>>> for(i in dmp.size) {
>>>> +   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
>>>> +   dump('df0', file='testdump')
>>>> +   cat('length:', i, '\n')
>>>> +   print(system.time(source('testdump', keep.source = FALSE,
>>>> +                            encoding='')))
>>>> + }
>>>> length: 10
>>>>       user  system elapsed
>>>>          0       0       0
>>>> length: 100
>>>>       user  system elapsed
>>>>          0       0       0
>>>> length: 1000
>>>>       user  system elapsed
>>>>          0       0       0
>>>> length: 10000
>>>>       user  system elapsed
>>>>       0.02    0.00    0.01
>>>> length: 1e+05
>>>>       user  system elapsed
>>>>       0.21    0.00    0.20
>>>> length: 1e+06
>>>>       user  system elapsed
>>>>       4.47    0.04    4.51
>>>> length: 1e+07
>>>>       user  system elapsed
>>>>      62.04    0.22   62.26
>>>>>
>>>>
>>>>
>>>> output for R version 3.0.2 Patched (2013-10-27 r64116):
>>>>> sessionInfo()
>>>> R version 3.0.2 Patched (2013-10-27 r64116)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
>>>> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
>>>> [5] LC_TIME=German_Switzerland.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>> sample.vec <-
>>>> +   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from',
>>>> 'the',
>>>> +     'named', 'file', 'or', 'URL', 'or', 'connection')
>>>>> dmp.size <- c(10^(1:7))
>>>>> set.seed(37)
>>>>>
>>>>> for(i in dmp.size) {
>>>> +   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
>>>> +   dump('df0', file='testdump')
>>>> +   cat('length:', i, '\n')
>>>> +   print(system.time(source('testdump', keep.source = FALSE,
>>>> +                            encoding='')))
>>>> + }
>>>> length: 10
>>>>       user  system elapsed
>>>>          0       0       0
>>>> length: 100
>>>>       user  system elapsed
>>>>          0       0       0
>>>> length: 1000
>>>>       user  system elapsed
>>>>          0       0       0
>>>> length: 10000
>>>>       user  system elapsed
>>>>       0.01    0.00    0.01
>>>> length: 1e+05
>>>>       user  system elapsed
>>>>       0.36    0.06    0.42
>>>> length: 1e+06
>>>>       user  system elapsed
>>>>       6.02    1.86    7.88
>>>> length: 1e+07
>>>>       user  system elapsed
>>>>     388.63  176.42  566.41
>>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> View this message in context: http://r.789695.n4.nabble.com/big-speed-difference-
>> in-
>>>> source-btw-R-2-15-2-and-R-3-0-2-tp4679314p4679346.html
>>>> Sent from the R help mailing list archive at Nabble.com.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Thorn.Thaler at rdls.nestle.com  Thu Oct 31 09:16:26 2013
From: Thorn.Thaler at rdls.nestle.com (Thaler,Thorn,LAUSANNE,Applied Mathematics)
Date: Thu, 31 Oct 2013 08:16:26 +0000
Subject: [R] Automatically Remove Aliased Terms from a Model
In-Reply-To: <52701ECB.30101@uke.de>
References: <EDB44DA865211646A192A94DF3C6FA670F72DC54@DEMDCE0057.nestle.com>
	<52701ECB.30101@uke.de>
Message-ID: <EDB44DA865211646A192A94DF3C6FA670F72E3CB@DEMDCE0057.nestle.com>

Dear Eik,

Thanks for your answer. I think indeed I was not to clear of what I want to achieve. So let me rephrase:

In case that there are aliased predictors in my model, I will see them via the alias function:

d <- expand.grid(a = 0:1, b=0:1)
d$c <- (d$a + d$b)  %% 2
d$y <- rnorm(4)
d <- within(d, {a <- factor(a); b <- factor(b); c <- factor(c)})
l <- lm(y ~ a * b + c, d)
alias(l)
Model :

y ~ a * b + c

Complete :
      (Intercept) a1   b1   c1  
a1:b1    0         1/2  1/2 -1/2

I see from alias that the _coefficient_ a1:b1 is aliased and can thus not be estimated. Hence, I want to remove the _term_ a:b from the model. While this is a straight forward thing if we were talking about continuous predictors, it is not that easy to do so if we have aliased quantitative predictors (i.e. factors), because a _term_ like a:b (i.e. an interaction between two 2-level factors) will yield 1 _coefficient_ a1:b1. But in order to use the update function I have to translate the output of aliased (which gives aliased _coefficients_) back to _terms_. Something like update(l, . ~ . - a1:b1) would not work for apparent reasons and I have to use update(l, . ~ . - a:b), which means I have to translate a1:b1 somehow to a:b.

Overall, I want to remove any continuous/quantitative predictor if any associated coefficient  cannot be estimated.

Is that clearer now?


KR,

-Thorn

-----Original Message-----
From: Eik Vettorazzi [mailto:E.Vettorazzi at uke.de] 
Sent: Dienstag, 29. Oktober 2013 21:47
To: Thaler,Thorn,LAUSANNE,Applied Mathematics; R-Help Mailing List (r-help at r-project.org)
Subject: Re: [R] Automatically Remove Aliased Terms from a Model

Hi Thorn,
it is not entirely clear (at least for me) what you want to accomplish.
an easy and fail safe way of extracting used terms in a (g)lm-object is
names(model.frame(l))
if you want to extract terms to finally select a model, have a look at
drop1 and/or MASS::dropterm

Hth

Am 28.10.2013 17:19, schrieb Thaler,Thorn,LAUSANNE,Applied Mathematics:
> Dear all,
> 
> I am trying to implement a function which removes aliased terms from a model. The challenge I am facing is that with "alias" I get the aliased coefficients of the model, which I have to translate into the terms from the model formula. What I have tried so far:
> 
> ------------------8<------------------
> d <- expand.grid(a = 0:1, b=0:1)
> d$c <- (d$a + d$b)  %% 2
> d$y <- rnorm(4)
> d <- within(d, {a <- factor(a); b <- factor(b); c <- factor(c)}) l <- 
> lm(y ~ a * b + c, d)
> 
> removeAliased <- function(mod) {
>   ## Retrieve all terms in the model
>   X <- attr(mod$terms, "term.label")
>   ## Get the aliased coefficients  
>   rn <- rownames(alias(mod)$Complete)
>   ## remove factor levels from coefficient names to retrieve the terms
>   regex.base <- unique(unlist(lapply(mod$model[, sapply(mod$model, is.factor)], levels)))
>   aliased <- gsub(paste(regex.base, "$", sep = "", collapse = "|"),  "", gsub(paste(regex.base, ":", sep = "", collapse = "|"), ":", rn))
>   uF <- formula(paste(". ~ .", paste(aliased, collapse = "-"), sep = "-"))
>   update(mod, uF)
> }
> 
> removeAliased(l)
> ------------------>8------------------
> 
> This function works in principle, but this workaround with removing the factor levels is just, well, a workaround which could cause problems in some circumstances (when the name of a level matches the end of another variable, when I use a different contrast and R names the coefficients differently etc. - and I am not sure which other cases I am overlooking).
> 
> So my question is whether there are some more intelligent ways of doing what I want to achieve? Is there a function to translate a coefficient of a LM back to the term, something like:
> 
> termFromCoef("a1") ## a1
> termFromCoef("a1:b1") ## a:b
> 
> With this I could simply translate the rownames from alias into the terms needed for the model update.
> 
> Thanks for your help.
> 
> Kind Regards,
> 
> Thorn Thaler
> NRC Lausanne
> Applied Mathematics
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

--
Eik Vettorazzi

Department of Medical Biometry and Epidemiology University Medical Center Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/7410-58243
F ++49/40/7410-57790
--

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Martin Zeitz (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik _____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From alaios at yahoo.com  Thu Oct 31 10:23:17 2013
From: alaios at yahoo.com (Alaios)
Date: Thu, 31 Oct 2013 02:23:17 -0700 (PDT)
Subject: [R] remap values from one vector to the other
Message-ID: <1383211397.23057.YahooMailNeo@web125305.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/c5527882/attachment.pl>

From petr.pikal at precheza.cz  Thu Oct 31 10:28:29 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 31 Oct 2013 09:28:29 +0000
Subject: [R] numeric data being interpreted as a factor -trouble with
 reading data into a dataframe in R
In-Reply-To: <CAJnbHtL1FaKnK67+g3Q4t=--BFs+4ojO=2-h2f6uSp7h+2y9xg@mail.gmail.com>
References: <CAJnbHtL1FaKnK67+g3Q4t=--BFs+4ojO=2-h2f6uSp7h+2y9xg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9B4CA@SRVEXCHMBX.precheza.cz>

Hi

Reading numeric as factor can have many causes from weird formating to some nonumeric characters. If you can not clean it when making *.csv file you shall either adopt reading function by using different options

see ?read.table

or if it does not help, you can either polish your values by some regular expressions.

For simple changing factor values to numeric you shall use

fb <- as.numeric(as.character(fb))

But all values which are not transferable to numeric will be changed to NA

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Bill
> Sent: Sunday, October 27, 2013 10:33 PM
> To: r-help at r-project.org
> Subject: [R] numeric data being interpreted as a factor -trouble with
> reading data into a dataframe in R
> 
> Hello.
> trying to do one of the simplest actions -read in data into R.
> I don't know why the FBfollowers column is being read as a factor and
> also if I use as.numeric on it, it looks really strange and actually
> complety alters the data.
> I am attaching the data set here called ddd.csv I used
> data=read.csv("ddd.csv",header=TRUE)
> 
> fb=data$FBfollowers
> fb
> fb=as.numeric(fb)
> fb
> 
> Thnxs in advance


From Gerrit.Eichner at math.uni-giessen.de  Thu Oct 31 10:50:56 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Thu, 31 Oct 2013 10:50:56 +0100 (MET)
Subject: [R] remap values from one vector to the other
In-Reply-To: <1383211397.23057.YahooMailNeo@web125305.mail.ne1.yahoo.com>
References: <1383211397.23057.YahooMailNeo@web125305.mail.ne1.yahoo.com>
Message-ID: <Pine.SOC.4.64.1310311045180.16754@solcom.hrz.uni-giessen.de>

Alex,

it is a bit unclear what you mean by "remap" etc., but maybe

y0 <- 880e6;   y1 <- 1020e6
x0 <- 1;       x1 <- ncol(x)

y0 + (x0-1):x1 * (y1 - y0)/(x1 - (x0-1))

gives what you want.

  Hth  --  Gerrit


On Thu, 31 Oct 2013, Alaios wrote:

> Hi everyone,
> I am plotting some legend and I am using the axis(at=..) to specify the place to plot the marks I want.
>
> My plotted data have ncol(x) so the at places have values that span from 1 to ncol(x)
>
> there I would like to be able to map values that go from 880e6 to 1020e6.....
> so
> 880e6 remaps to 1
> ....
>
> 1020e6 repams to ncol(x)
>
> what I do not know how to do is to remap the values that are between 880e6 and 1020e6 between then 1 and ncol(x).
>
> Can someone help me find an appropriate function for that?
>
> I would like to thank you in advance for your help
>
> Regards
> Alex
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wobbegong85 at gmail.com  Thu Oct 31 10:53:51 2013
From: wobbegong85 at gmail.com (Wobbe Gong)
Date: Thu, 31 Oct 2013 10:53:51 +0100
Subject: [R] SIAR problem with model running
Message-ID: <CAAnm=Su5ZokEwQ4eQ=g0PgNoRik-kWszVX=DbWfMtJCfp3hGzQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/dc70602c/attachment.pl>

From jim at bitwrit.com.au  Thu Oct 31 11:01:39 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 31 Oct 2013 21:01:39 +1100
Subject: [R] remap values from one vector to the other
In-Reply-To: <1383211397.23057.YahooMailNeo@web125305.mail.ne1.yahoo.com>
References: <1383211397.23057.YahooMailNeo@web125305.mail.ne1.yahoo.com>
Message-ID: <52722A83.5030205@bitwrit.com.au>

On 10/31/2013 08:23 PM, Alaios wrote:
> Hi everyone,
> I am plotting some legend and I am using the axis(at=..) to specify the place to plot the marks I want.
>
> My plotted data have ncol(x) so the at places have values that span from 1 to ncol(x)
>
> there I would like to be able to map values that go from 880e6 to 1020e6.....
> so
> 880e6 remaps to 1
> ....
>
> 1020e6 repams to ncol(x)
>
> what I do not know how to do is to remap the values that are between 880e6 and 1020e6 between then 1 and ncol(x).
>
> Can someone help me find an appropriate function for that?
>
Hi Alex,
Try rescale in plotrix.

Jim


From taquito2007 at gmail.com  Thu Oct 31 11:14:10 2013
From: taquito2007 at gmail.com (Takatsugu Kobayashi)
Date: Thu, 31 Oct 2013 19:14:10 +0900
Subject: [R] Efficient way to convert covariance to Euclidian distance matrix
Message-ID: <CADL0PchYe4SGAAErKUDqfLi4Z67SUi6xfE4bzMv=Gw8JjTQCFw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/de8c4054/attachment.pl>

From tuechler at gmx.at  Thu Oct 31 11:25:18 2013
From: tuechler at gmx.at (Heinz Tuechler)
Date: Thu, 31 Oct 2013 11:25:18 +0100
Subject: [R] big speed difference in source btw. R 2.15.2 and R 3.0.2 ?
In-Reply-To: <527210F1.9050605@stats.ox.ac.uk>
References: <52704C18.6020905@gmx.at>	<1383136127835-4679346.post@n4.nabble.com>	<E66794E69CFDE04D9A70842786030B933FA11732@PA-MBX01.na.tibco.com>	<52716F4D.7040009@gmx.at>
	<E66794E69CFDE04D9A70842786030B933FA117F8@PA-MBX01.na.tibco.com>
	<527210F1.9050605@stats.ox.ac.uk>
Message-ID: <5272300E.8050902@gmx.at>

on/am 31.10.2013 09:12, Prof Brian Ripley wrote/hat geschrieben:
> On 30/10/2013 21:15, William Dunlap wrote:
>> I have to defer to others for policy declarations like how long
>> the current format used by load and save should be readable.
>
> You could also ask how long R will last ....
>
> R can still read (but not write) save() formats used in the 1990's.  We
> would expect R to be able to read saves since R 1.0.0 for as long as R
> exists.  And as R is Open Source, you would be able to compile it and
> dump the objects you want for as long as suitable compilers and OSes
> exist ....  And of course R is not the only application which will read
> the format.
>
> There is no guarantee that source() will be able to parse dumps from
> earlier versions of R, and that has not always been true.
>
> People commenting on parse() speed should note the NEWS for R-devel:
>
>      ? The parser has been modified to use less memory.
>
>
Thank you for the hint.
It appears to me that source() in R-devel performs at about the same 
speed as in R 2.15.2.
>>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>>
>>
>>> -----Original Message-----
>>> From: Heinz Tuechler [mailto:tuechler at gmx.at]
>>> Sent: Wednesday, October 30, 2013 1:43 PM
>>> To: William Dunlap
>>> Cc: Carl Witthoft; r-help at r-project.org
>>> Subject: Re: [R] big speed difference in source btw. R 2.15.2 and R
>>> 3.0.2 ?
>>>
>>> Best thanks for confirming my impression. I use dump for storing large
>>> data.frames with a number of attributes for each variable. save/load is
>>> much faster, but I am unsure, if such files will be readable by R
>>> versions years later.
>>> What format/functions would you suggest for data storage/transfer
>>> between different (future) R versions?
>>>
>>> best regards,
>>> Heinz
>>>
>>> on/am 30.10.2013 20:11, William Dunlap wrote/hat geschrieben:
>>>> I see a big 2.15.2/3.0.2 speed difference in parse() (which is used
>>>> by source())
>>>> when it is parsing long vectors of numeric data.  dump/source has
>>>> never been an
>>> efficient
>>>> way of transferring data between different R session, but it is much
>>>> worse
>>>> now for long vectors.   In 2.15.2 doubling the size of the vector
>>>> (of lengths
>>>> in the range 10^4 to 10^7) makes the time to parse go up by a factor
>>>> of c. 2.1.
>>>> In 3.0.2 that factor is more like 4.4.
>>>>
>>>>          n elapsed-2.15.2 elapsed-3.0.2
>>>>       2048          0.003         0.018
>>>>       4096          0.006         0.065
>>>>       8192          0.013         0.254
>>>>      16384          0.025         1.067
>>>>      32768          0.050         4.114
>>>>      65536          0.100        16.236
>>>>     131072          0.219        66.013
>>>>     262144          0.808       291.883
>>>>     524288          2.022      1285.265
>>>>    1048576          4.918            NA
>>>>    2097152          9.857            NA
>>>>    4194304         22.916            NA
>>>>    8388608         49.671            NA
>>>> 16777216        101.042            NA
>>>> 33554432        512.719            NA
>>>>
>>>> I tried this with 64-bit R on a Linux box.  The NA's represent sizes
>>>> that did not
>>>> finish while I was at a 1 1/2 hour dentist's apppointment.  The
>>>> timing function
>>>> was:
>>>>     test <- function(n = 2^(11:25))
>>>>     {
>>>>         tf <- tempfile()
>>>>         on.exit(unlink(tf))
>>>>         t(sapply(n, function(n){
>>>>             dput(log(seq_len(n)), file=tf)
>>>>             print(c(n=n, system.time(parse(file=tf))[1:3]))
>>>>         }))
>>>>     }
>>>>
>>>> Bill Dunlap
>>>> Spotfire, TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>
>>>>> -----Original Message-----
>>>>> From: r-help-bounces at r-project.org
>>>>> [mailto:r-help-bounces at r-project.org] On
>>> Behalf
>>>>> Of Carl Witthoft
>>>>> Sent: Wednesday, October 30, 2013 5:29 AM
>>>>> To: r-help at r-project.org
>>>>> Subject: Re: [R] big speed difference in source btw. R 2.15.2 and R
>>>>> 3.0.2 ?
>>>>>
>>>>> Did you run the identical code on the identical machine, and did
>>>>> you verify
>>>>> there were no other tasks running which might have limited the RAM
>>>>> available
>>>>> to R?  And equally important, did you run these tests in the
>>>>> reverse order
>>>>> (in case R was storing large objects from the first run, thus
>>>>> chewing up
>>>>> RAM)?
>>>>>
>>>>>
>>>>>
>>>>> Dear All,
>>>>>
>>>>> is it known that source works much faster in  R 2.15.2 than in R
>>>>> 3.0.2 ?
>>>>> In the example below I observe e.g. for a data.frame with 10^7 rows
>>>>> the
>>>>> following timings:
>>>>>
>>>>> R version 2.15.2 Patched (2012-11-29 r61184)
>>>>> length: 1e+07
>>>>>       user  system elapsed
>>>>>      62.04    0.22   62.26
>>>>>
>>>>> R version 3.0.2 Patched (2013-10-27 r64116)
>>>>> length: 1e+07
>>>>>       user  system elapsed
>>>>>     388.63  176.42  566.41
>>>>>
>>>>> Is there a way to speed R version 3.0.2 up to the performance of R
>>>>> version 2.15.2?
>>>>>
>>>>> best regards,
>>>>>
>>>>> Heinz T?chler
>>>>>
>>>>>
>>>>> example:
>>>>> sessionInfo()
>>>>> sample.vec <-
>>>>>      c('source', 'causes', 'R', 'to', 'accept', 'its', 'input',
>>>>> 'from', 'the',
>>>>>        'named', 'file', 'or', 'URL', 'or', 'connection')
>>>>> dmp.size <- c(10^(1:7))
>>>>> set.seed(37)
>>>>>
>>>>> for(i in dmp.size) {
>>>>>      df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
>>>>>      dump('df0', file='testdump')
>>>>>      cat('length:', i, '\n')
>>>>>      print(system.time(source('testdump', keep.source = FALSE,
>>>>>                               encoding='')))
>>>>> }
>>>>>
>>>>> output for R version 2.15.2 Patched (2012-11-29 r61184):
>>>>>> sessionInfo()
>>>>> R version 2.15.2 Patched (2012-11-29 r61184)
>>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>>
>>>>> locale:
>>>>> [1] LC_COLLATE=German_Switzerland.1252
>>>>> LC_CTYPE=German_Switzerland.1252
>>>>> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
>>>>> [5] LC_TIME=German_Switzerland.1252
>>>>>
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>> sample.vec <-
>>>>> +   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from',
>>>>> 'the',
>>>>> +     'named', 'file', 'or', 'URL', 'or', 'connection')
>>>>>> dmp.size <- c(10^(1:7))
>>>>>> set.seed(37)
>>>>>>
>>>>>> for(i in dmp.size) {
>>>>> +   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
>>>>> +   dump('df0', file='testdump')
>>>>> +   cat('length:', i, '\n')
>>>>> +   print(system.time(source('testdump', keep.source = FALSE,
>>>>> +                            encoding='')))
>>>>> + }
>>>>> length: 10
>>>>>       user  system elapsed
>>>>>          0       0       0
>>>>> length: 100
>>>>>       user  system elapsed
>>>>>          0       0       0
>>>>> length: 1000
>>>>>       user  system elapsed
>>>>>          0       0       0
>>>>> length: 10000
>>>>>       user  system elapsed
>>>>>       0.02    0.00    0.01
>>>>> length: 1e+05
>>>>>       user  system elapsed
>>>>>       0.21    0.00    0.20
>>>>> length: 1e+06
>>>>>       user  system elapsed
>>>>>       4.47    0.04    4.51
>>>>> length: 1e+07
>>>>>       user  system elapsed
>>>>>      62.04    0.22   62.26
>>>>>>
>>>>>
>>>>>
>>>>> output for R version 3.0.2 Patched (2013-10-27 r64116):
>>>>>> sessionInfo()
>>>>> R version 3.0.2 Patched (2013-10-27 r64116)
>>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>>
>>>>> locale:
>>>>> [1] LC_COLLATE=German_Switzerland.1252
>>>>> LC_CTYPE=German_Switzerland.1252
>>>>> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
>>>>> [5] LC_TIME=German_Switzerland.1252
>>>>>
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>> sample.vec <-
>>>>> +   c('source', 'causes', 'R', 'to', 'accept', 'its', 'input', 'from',
>>>>> 'the',
>>>>> +     'named', 'file', 'or', 'URL', 'or', 'connection')
>>>>>> dmp.size <- c(10^(1:7))
>>>>>> set.seed(37)
>>>>>>
>>>>>> for(i in dmp.size) {
>>>>> +   df0 <- data.frame(x=sample(sample.vec, i, replace=TRUE))
>>>>> +   dump('df0', file='testdump')
>>>>> +   cat('length:', i, '\n')
>>>>> +   print(system.time(source('testdump', keep.source = FALSE,
>>>>> +                            encoding='')))
>>>>> + }
>>>>> length: 10
>>>>>       user  system elapsed
>>>>>          0       0       0
>>>>> length: 100
>>>>>       user  system elapsed
>>>>>          0       0       0
>>>>> length: 1000
>>>>>       user  system elapsed
>>>>>          0       0       0
>>>>> length: 10000
>>>>>       user  system elapsed
>>>>>       0.01    0.00    0.01
>>>>> length: 1e+05
>>>>>       user  system elapsed
>>>>>       0.36    0.06    0.42
>>>>> length: 1e+06
>>>>>       user  system elapsed
>>>>>       6.02    1.86    7.88
>>>>> length: 1e+07
>>>>>       user  system elapsed
>>>>>     388.63  176.42  566.41
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> View this message in context:
>>>>> http://r.789695.n4.nabble.com/big-speed-difference-
>>> in-
>>>>> source-btw-R-2-15-2-and-R-3-0-2-tp4679314p4679346.html
>>>>> Sent from the R help mailing list archive at Nabble.com.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From J.Kiplimo at cgiar.org  Thu Oct 31 10:41:25 2013
From: J.Kiplimo at cgiar.org (Kiplimo, Jusper (ILRI))
Date: Thu, 31 Oct 2013 09:41:25 +0000
Subject: [R] Read ENVI files and extract stats in R
References: <7205E5BE63A0214BAB03B3C8DAEB9528AD36DE8D@CGIARMBX1.nochub.CGIARAD.ORG>
	<CANtt_hxHGrT1oRt5nz415zupfDf1TYX1_UoiOuGvH4-i4i9jqw@mail.gmail.com> 
Message-ID: <7205E5BE63A0214BAB03B3C8DAEB9528AD36FC9C@CGIARMBX1.nochub.CGIARAD.ORG>

Dear All,

A friend shared an ENVI made file for NDVI 1998- 2012. I would like to use R to read the file in and extract NDVI values over some points shapefile.
The file attached is a snapshot of the file contents as previewed in ArcGis. 

I have managed to get my way around a bit. See below my code....might need a little cleaning. Still new!

###################################Start#######################

library(raster)

mybrick8 <- brick("E:/Jr/SLF/HealthyFutures/ShapeFiles/NDVI_1km/aNTONndvi/SPOT_VGT_filtered_Ethiopia.img")#read NDVI file
names(mybrick8)
dim(mybrick8)
plot(mybrick8, y = 1)

plot(mybrick8, y = 2:13,col = terrain.colors( length(seq(0,250, by = 50))-1),
	breaks= seq(0, 250, by = 50), axes = T,xlab = 'Longitude', ylab = 'Latitude', 
   	  cex.lab = 1, cex.axis = 1 )

mybrick9<-((mybrick8*0.004)-0.1)# the NDVI file is in reflectance values, so extracting actual NDVI values
names(mybrick9)
plot(mybrick9, y = 1)

mymap5 <- readShapePoints('Y:/D/HealthFutures/Neaural/25kmptsethiopia.shp')
plot(mymap5, add = T)

NDVIspot041998_072012_25kmPtsETH121998072013 <- extract(mybrick9, mymap5, # summary over the points of interest
                                             fun = mean, small = T, 
                                             na.rm = T, 
                                             layer = 1, 
                                             n = 1000) 

write.csv(NDVIspot041998_072012_25kmPtsETH121998072013, file = "Y:/D/HealthFutures/Neaural/NDVIspot041998_072012_25kmPtsETH121998072013.csv")

###################################End#######################

The data however is in decadal; every month has 3 readings, for example V1_1998_04_01, V1_1998_04_11, and V1_1998_04_21 for the month April 1998. I would wish to get the average per month. How do I go about this?

Is it possible to write out single files at a selected time period, as raster, to a folder that I could later perform some geo-processing tasks?

Regards,
Jusper	

-------------- next part --------------
A non-text attachment was scrubbed...
Name: EnviSnapShot.png
Type: image/png
Size: 159720 bytes
Desc: EnviSnapShot.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/5a4a47eb/attachment.png>

From J.Kiplimo at cgiar.org  Thu Oct 31 12:09:09 2013
From: J.Kiplimo at cgiar.org (Kiplimo, Jusper (ILRI))
Date: Thu, 31 Oct 2013 11:09:09 +0000
Subject: [R] Make Multiple plots in R
Message-ID: <7205E5BE63A0214BAB03B3C8DAEB9528AD36FCED@CGIARMBX1.nochub.CGIARAD.ORG>

Dear All,

I would wish to make multiple plots and give title/ headings same time, is there a simpler/ tidier way compared to below(, especially the headings as they are missing)? See output attached.

#####################################Making multiple Plots start########################

plot(mybrick9, y = 2, col = terrain.colors( length(seq(0,1, by = .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
     main = 'April 2006',
     xlab = 'Longitude', ylab = 'Latitude', 
     cex.lab = 1, cex.axis = 1 )
plot(mymap3, add = T)

plot(mybrick9, y = 5, col = terrain.colors( length(seq(0,1, by = .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
     main = 'May 2006',
     xlab = 'Longitude', ylab = 'Latitude', 
     cex.lab = 1, cex.axis = 1 )
plot(mymap3, add = T)

plot(mybrick9, y = 8, col = terrain.colors( length(seq(0,1, by = .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
     main = 'June 2006',
     xlab = 'Longitude', ylab = 'Latitude', 
     cex.lab = 1, cex.axis = 1 )
plot(mymap3, add = T)

plot(mybrick9, y = 11, col = terrain.colors( length(seq(0,1, by = .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
     main = 'July 2006',
     xlab = 'Longitude', ylab = 'Latitude', 
     cex.lab = 1, cex.axis = 1 )
plot(mymap3, add = T)

#####################################Making multiple Plots end########################

Regards,
Jusper	 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ndviAprilJuly2006.png
Type: image/png
Size: 54145 bytes
Desc: ndviAprilJuly2006.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/76123b61/attachment.png>

From helwig.b at gmail.com  Thu Oct 31 12:11:50 2013
From: helwig.b at gmail.com (Bridget Helwig)
Date: Thu, 31 Oct 2013 08:11:50 -0300
Subject: [R] Matrix calculations from database linked to in RODBC
Message-ID: <CAAaNr1q7SZZAyrAkzLhk7EFyBLXzU4Rs7Weqiy+BcpOYQzyaSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/35e002ac/attachment.pl>

From S.Ellison at lgcgroup.com  Thu Oct 31 12:16:38 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Thu, 31 Oct 2013 11:16:38 +0000
Subject: [R] Efficient way to convert covariance to Euclidian distance
 matrix
In-Reply-To: <CADL0PchYe4SGAAErKUDqfLi4Z67SUi6xfE4bzMv=Gw8JjTQCFw@mail.gmail.com>
References: <CADL0PchYe4SGAAErKUDqfLi4Z67SUi6xfE4bzMv=Gw8JjTQCFw@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554EA9DDD@GOLD.corp.lgc-group.com>



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Takatsugu Kobayashi
> 
> I am struggling to come up with an efficient vectorized way to convert
> 20Kx20K covariance matrix to a Euclidian distance matrix as a surrogate for
> dissimilarity matrix. Hopefully I can apply multidimensional scaling for
> mapping these 20K points (commercial products).
> 
> I understand that Distance(ij) = sigma(i) + sigma(j) - 2cov(ij). 

I suspect there's a typo or two in here.

sigma(i)^2 + sigma(j)^2 - 2cov(ij)

would be the variance of a difference x[i ]- x[j]. That's not in the same units as the difference itself, so one might well want the standard deviation of the difference, that is, sqrt(sigma(i)^2 + sigma(j)^2 - 2cov(ij)).

I don't envy your attempt to work with 20k*20k matrices, though. That's about 3Gbytes per object, and a lot of distances for MDS to optimise. 
If it's just about visual display, perhaps prcomp on the original data would provide (visually) similar results without the overhead of a large covariance matrix?


S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From carlos.nasher at googlemail.com  Thu Oct 31 12:20:44 2013
From: carlos.nasher at googlemail.com (Carlos Nasher)
Date: Thu, 31 Oct 2013 12:20:44 +0100
Subject: [R] Count number of consecutive zeros by group
Message-ID: <CAP=BVWPwu7B9WHtmyhCapQby2EX=YXjLnquoZrmqDdLyd=rh-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/bedd1024/attachment.pl>

From murdoch.duncan at gmail.com  Thu Oct 31 12:27:57 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 31 Oct 2013 07:27:57 -0400
Subject: [R] Rterm
In-Reply-To: <CACuK3vhPmdE9yvMM==raL_Y=rjRXREXs0zkeSHg_665cApjg8g@mail.gmail.com>
References: <CACuK3vhPmdE9yvMM==raL_Y=rjRXREXs0zkeSHg_665cApjg8g@mail.gmail.com>
Message-ID: <52723EBD.8010704@gmail.com>

On 13-10-30 5:34 PM, Patrick Rioux wrote:
> Hi,
>
> Whenever I try to open R from Emacs, it says :
> "apply: Searching for program: permission denied, Rterm"
>
> I have the new ESS with the latest Emacs version and R-3.0.2. Also, when I
> open Emacs, it says : "No version of R could be found on your system". I
> wonder if there is anything I could do to fix the problem.
>
> Please help me,
>

There is an ESS mailing list (called ESS-help, info here: 
https://stat.ethz.ch/mailman/listinfo/ess-help).  You'll probably get 
better help there.

Duncan Murdoch


From carl at witthoft.com  Thu Oct 31 12:27:03 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 31 Oct 2013 04:27:03 -0700 (PDT)
Subject: [R] Beginner having issues with making pie charts and other
	graphs
In-Reply-To: <1383192995000-4679418.post@n4.nabble.com>
References: <1383192995000-4679418.post@n4.nabble.com>
Message-ID: <1383218823618-4679443.post@n4.nabble.com>

Rule Number One:  Don't use pie charts.

Rule Number Two:  NEVER EVER USE PIE CHARTS!

To learn how to create graphs in R, start with ?plot , ?points,  ?lines.  
Later on you can investigate ?lattice, ?grid,  and ?ggplot2 .
The fact that you're looking 'online' instead of in R's builtin help
mechanisms is disconcerting.




blindchicken11 wrote
> I just started using R software and I'm having some issues making
> graphs/charts.[snip]
> 
> I want to start off by just making a pie chart for the categorical data
> like south, sex, etc. But I've tried everything and can't seem to find any
> information online to help me. The few pie graphs I've gotten to show have
> been giant black and white blobs with no information on them. Any help
> would be greatly appreciated!





--
View this message in context: http://r.789695.n4.nabble.com/Beginner-having-issues-with-making-pie-charts-and-other-graphs-tp4679418p4679443.html
Sent from the R help mailing list archive at Nabble.com.


From S.Ellison at LGCGroup.com  Thu Oct 31 12:34:32 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 31 Oct 2013 11:34:32 +0000
Subject: [R] Count number of consecutive zeros by group
In-Reply-To: <CAP=BVWPwu7B9WHtmyhCapQby2EX=YXjLnquoZrmqDdLyd=rh-g@mail.gmail.com>
References: <CAP=BVWPwu7B9WHtmyhCapQby2EX=YXjLnquoZrmqDdLyd=rh-g@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554EA9DFB@GOLD.corp.lgc-group.com>



> -----Original Message-----
> So I want to get the max number of consecutive zeros of variable x for each
> ID. I found rle() to be helpful for this task; so I did:
> 
> FUN <- function(x) {
>   rles <- rle(x == 0)
> }
> consec <- lapply(split(df[,2],df[,1]), FUN)

You're probably better off with tapply and a function that returns what you want. You're probably also better off with a data frame name that isn't a function name, so I'll use dfr instead of df...

dfr<- data.frame(x=rpois(500, 1.5), ID=gl(5,100)) #5 ID groups numbered 1-5, equal size but that doesn't matter for tapply

f2 <-   function(x) {
	max( rle(x == 0)$lengths )
}
with(dfr, tapply(x, ID, f2))


S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jrkrideau at inbox.com  Thu Oct 31 12:45:49 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 31 Oct 2013 03:45:49 -0800
Subject: [R] Make Multiple plots in R
In-Reply-To: <7205E5BE63A0214BAB03B3C8DAEB9528AD36FCED@CGIARMBX1.nochub.CGIARAD.ORG>
Message-ID: <402D2EFF2FF.0000095Ejrkrideau@inbox.com>

Without knowing what the data looks like it is a bit difficult to know.  See ?dput on how to supply sample data.

However I think that something like the ggplot2 package would be a good way to go, 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: j.kiplimo at cgiar.org
> Sent: Thu, 31 Oct 2013 11:09:09 +0000
> To: r-help at r-project.org
> Subject: [R] Make Multiple plots in R
> 
> Dear All,
> 
> I would wish to make multiple plots and give title/ headings same time,
> is there a simpler/ tidier way compared to below(, especially the
> headings as they are missing)? See output attached.
> 
> #####################################Making multiple Plots
> start########################
> 
> plot(mybrick9, y = 2, col = terrain.colors( length(seq(0,1, by =
> .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
>      main = 'April 2006',
>      xlab = 'Longitude', ylab = 'Latitude',
>      cex.lab = 1, cex.axis = 1 )
> plot(mymap3, add = T)
> 
> plot(mybrick9, y = 5, col = terrain.colors( length(seq(0,1, by =
> .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
>      main = 'May 2006',
>      xlab = 'Longitude', ylab = 'Latitude',
>      cex.lab = 1, cex.axis = 1 )
> plot(mymap3, add = T)
> 
> plot(mybrick9, y = 8, col = terrain.colors( length(seq(0,1, by =
> .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
>      main = 'June 2006',
>      xlab = 'Longitude', ylab = 'Latitude',
>      cex.lab = 1, cex.axis = 1 )
> plot(mymap3, add = T)
> 
> plot(mybrick9, y = 11, col = terrain.colors( length(seq(0,1, by =
> .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
>      main = 'July 2006',
>      xlab = 'Longitude', ylab = 'Latitude',
>      cex.lab = 1, cex.axis = 1 )
> plot(mymap3, add = T)
> 
> #####################################Making multiple Plots
> end########################
> 
> Regards,
> Jusper
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From jrkrideau at inbox.com  Thu Oct 31 12:55:05 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 31 Oct 2013 03:55:05 -0800
Subject: [R] ggplot2 - how to get rid of bar boarder lines
In-Reply-To: <CAN2xGJZeEzGqbc9JC=ucM-K8etJMP=xyYtxCgouEUV1oZY=p0w@mail.gmail.com>
Message-ID: <4041E51814D.00000973jrkrideau@inbox.com>

At a guess, don't use colour.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: dimitri.liakhovitski at gmail.com
> Sent: Wed, 30 Oct 2013 14:11:37 -0400
> To: r-help at r-project.org
> Subject: [R] ggplot2 - how to get rid of bar boarder lines
> 
> Hello!
> 
> I am using ggplot2:
> 
> ggplot(myplotdata, aes(x=att_levels, y=WTP)) +
>                 geom_bar(stat="identity",fill="dark
> orange",colour="black",
> alpha = 1,position = "identity") +
> 
geom_text(aes(label=WTP),colour="black",size=4,hjust=1.1,position='dodge')
> +
>                 coord_flip() +
>                 xlab("") +
>                 ylab("")
> 
> How could I get rid of the border lines on the bars (just leave the fill,
> but no border)?
> Thank you!
> 
> --
> Dimitri Liakhovitski
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From michael.weylandt at gmail.com  Thu Oct 31 13:04:54 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Thu, 31 Oct 2013 08:04:54 -0400
Subject: [R] an rpy2, R cgi type question
In-Reply-To: <CACxE24nQEnLeoV+xen7QC-JGmosJWbC9bOaz8y9jQdLgF=9kcQ@mail.gmail.com>
References: <CACxE24k8-BDeMxpcC-uMVga7FhKrA1Bu2BV9nLVzbvEQDr2FFQ@mail.gmail.com>
	<Pine.LNX.4.44.1310302350580.12472-100000@oxygen.cs.pitt.edu>
	<CACxE24nQEnLeoV+xen7QC-JGmosJWbC9bOaz8y9jQdLgF=9kcQ@mail.gmail.com>
Message-ID: <864DA490-5E81-4739-9118-90987563A34C@gmail.com>



On Oct 31, 2013, at 1:50, Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> Hi again:
> 
> Here is the web output:
> 
> Internal Server Error
> 
> The server encountered an internal error or misconfiguration and was unable
> to complete your request.

So your Python code is raising an exception somewhere, not the apache config. 
> 
> Please contact the server administrator, webmaster at erinm.info and inform
> them of the time the error occurred, and anything you might have done that
> may have caused the error.
> 
> More information about this error may be available in the server error log.

Can you check these?

> 
> Additionally, a 404 Not Found error was encountered while trying to use an
> ErrorDocument to handle the request.
> I did indeed check permissions and they seem to be in order.

Yes, they do seem to be; you'd be getting a 403 otherwise. 

> 
> Thanks,
> Erin
> 
> 
> 
> On Wed, Oct 30, 2013 at 10:51 PM, Collin Lynch <collinl at cs.pitt.edu> wrote:
> 
>> Erin can you share the internal error details?
>> 
>> As a first guess are the files executable by all?  CGI requires world rwx.
>> 
>>        Best,
>>        Collin.
>> 
>> On Wed, 30 Oct 2013, Erin Hodgess wrote:
>> 
>>> Hi again.
>>> 
>>> I'm putting together a little project with R, python, and a website.  So
>> I
>>> have an HTML file, a py file, an R file.
>>> 
>>> Here is the HTML file:
>>> <form action="/cgi-bin/radio4.py" method="post" target="_blank">
>>> <input type="radio" name="subject" value="Integrate" /> Integrate
>>> <input type="radio" name="subject" value="Differentiate" /> Differentiate
>>> <input type="radio" name="subject" value="Graph" /> Graph
>>> Function <input type="text"  name="func1" <br />
>>> <input type="submit" value="Select Subject" />
>>> </form>
>>> 
>>> Now the radio4.py file:
>>> 
>>> # Import modules for CGI handling
>>> import cgi, cgitb
>>> from sympy import *
>>> import sys
>>> 
>>> from rpy2.robjects.packages import SignatureTranslatedAnonymousPackage as
>>> STAP
>>> with open("bz2.R","r") as f:
>>>    string=''.join(f.readlines())
>>> etest = STAP(string,"etest")
>>> etest.etest(500)
>>> 
>>> 
>>> # Create instance of FieldStorage
>>> form = cgi.FieldStorage()
>>> 
>>> # Get data from fields
>>> if form.getvalue('subject'):
>>>   subject = form.getvalue('subject')
>>> else:
>>>   subject = "Not set"
>>> 
>>> if form.getvalue('func1'):
>>>   func1 = form.getvalue('func1')
>>> else:
>>>   func1 = "Not entered"
>>> 
>>> 
>>> 
>>> 
>>> 
>>> print "Content-type:text/html\r\n\r\n"
>>> print "<html>"
>>> print "<head>"
>>> print "<title>Test Project</title>"
>>> print "</head>"
>>> print "<body>"
>>> print "<h2> Selected Action is %s</h2>" % subject
>>> print "<h3> output function is %s</h3>" % func1
>>> print "</body>"
>>> print "</html>"
>>> 
>>> 
>>> Finally, the bz2.R file:
>>> 
>>> etest <- function(n=100) {
>>>    y <- rnorm(n)
>>>    pdf(file="lap1.png")
>>>    plot(y)
>>>    dev.off()
>>> }
>>> 
>>> 
>>> The radio4.py file is in a cgi-bin directory, along with the bz2.R file.
>>> 
>>> I keep getting the Internal server error.
>>> 
>>> Thanks for any help.
>>> 
>>> Sincerely,
>>> Erin
>>> 
>>> This is R version 3.0.2 and Python 2.7.5
>>> 
>>> --
>>> Erin Hodgess
>>> Associate Professor
>>> Department of Computer and Mathematical Sciences
>>> University of Houston - Downtown
>>> mailto: erinm.hodgess at gmail.com
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From carl at witthoft.com  Thu Oct 31 12:24:12 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 31 Oct 2013 04:24:12 -0700 (PDT)
Subject: [R] Read ENVI files and extract stats in R
In-Reply-To: <7205E5BE63A0214BAB03B3C8DAEB9528AD36FC9C@CGIARMBX1.nochub.CGIARAD.ORG>
References: <7205E5BE63A0214BAB03B3C8DAEB9528AD36FC9C@CGIARMBX1.nochub.CGIARAD.ORG>
Message-ID: <1383218652328-4679441.post@n4.nabble.com>

That is not an ENVI file.  That's an image file... or something.

If you can post a small, reproducible sample of the data array containing
the dates you wish to manipulate, we may be able to help.




--
View this message in context: http://r.789695.n4.nabble.com/Read-ENVI-files-and-extract-stats-in-R-tp4679439p4679441.html
Sent from the R help mailing list archive at Nabble.com.


From erinm.hodgess at gmail.com  Thu Oct 31 14:12:45 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 31 Oct 2013 08:12:45 -0500
Subject: [R] an rpy2, R cgi type question
In-Reply-To: <864DA490-5E81-4739-9118-90987563A34C@gmail.com>
References: <CACxE24k8-BDeMxpcC-uMVga7FhKrA1Bu2BV9nLVzbvEQDr2FFQ@mail.gmail.com>
	<Pine.LNX.4.44.1310302350580.12472-100000@oxygen.cs.pitt.edu>
	<CACxE24nQEnLeoV+xen7QC-JGmosJWbC9bOaz8y9jQdLgF=9kcQ@mail.gmail.com>
	<864DA490-5E81-4739-9118-90987563A34C@gmail.com>
Message-ID: <CACxE24kVVyFzH2XRD+SqCio_1TKv6sDOGYen1_PHzMhgskWbGQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/a64e1e43/attachment.pl>

From dcarlson at tamu.edu  Thu Oct 31 14:42:47 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 31 Oct 2013 08:42:47 -0500
Subject: [R] Make Multiple plots in R
In-Reply-To: <402D2EFF2FF.0000095Ejrkrideau@inbox.com>
References: <7205E5BE63A0214BAB03B3C8DAEB9528AD36FCED@CGIARMBX1.nochub.CGIARAD.ORG>
	<402D2EFF2FF.0000095Ejrkrideau@inbox.com>
Message-ID: <014a01ced63f$15d494a0$417dbde0$@tamu.edu>

You've left out all the critical code where you set graphics parameters (par()) to place four figures on one page. Probably you have reduced the margins so that there is no room for your labels. Note that xlab is printed but not ylab and there is no space for it. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of John Kane
Sent: Thursday, October 31, 2013 6:46 AM
To: Kiplimo Jusper (ILRI); r-help at r-project.org
Subject: Re: [R] Make Multiple plots in R

Without knowing what the data looks like it is a bit difficult to know.  See ?dput on how to supply sample data.

However I think that something like the ggplot2 package would be a good way to go, 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: j.kiplimo at cgiar.org
> Sent: Thu, 31 Oct 2013 11:09:09 +0000
> To: r-help at r-project.org
> Subject: [R] Make Multiple plots in R
> 
> Dear All,
> 
> I would wish to make multiple plots and give title/ headings same time,
> is there a simpler/ tidier way compared to below(, especially the
> headings as they are missing)? See output attached.
> 
> #####################################Making multiple Plots
> start########################
> 
> plot(mybrick9, y = 2, col = terrain.colors( length(seq(0,1, by =
> .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
>      main = 'April 2006',
>      xlab = 'Longitude', ylab = 'Latitude',
>      cex.lab = 1, cex.axis = 1 )
> plot(mymap3, add = T)
> 
> plot(mybrick9, y = 5, col = terrain.colors( length(seq(0,1, by =
> .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
>      main = 'May 2006',
>      xlab = 'Longitude', ylab = 'Latitude',
>      cex.lab = 1, cex.axis = 1 )
> plot(mymap3, add = T)
> 
> plot(mybrick9, y = 8, col = terrain.colors( length(seq(0,1, by =
> .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
>      main = 'June 2006',
>      xlab = 'Longitude', ylab = 'Latitude',
>      cex.lab = 1, cex.axis = 1 )
> plot(mymap3, add = T)
> 
> plot(mybrick9, y = 11, col = terrain.colors( length(seq(0,1, by =
> .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
>      main = 'July 2006',
>      xlab = 'Longitude', ylab = 'Latitude',
>      cex.lab = 1, cex.axis = 1 )
> plot(mymap3, add = T)
> 
> #####################################Making multiple Plots
> end########################
> 
> Regards,
> Jusper
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Oct 31 15:21:01 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 31 Oct 2013 14:21:01 +0000
Subject: [R] Beginner having issues with making pie charts and
	other	graphs
In-Reply-To: <1383218823618-4679443.post@n4.nabble.com>
References: <1383192995000-4679418.post@n4.nabble.com>
	<1383218823618-4679443.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9B6F3@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Carl Witthoft
> Sent: Thursday, October 31, 2013 12:27 PM
> To: r-help at r-project.org
> Subject: Re: [R] Beginner having issues with making pie charts and
> other graphs
> 
> Rule Number One:  Don't use pie charts.
> 
> Rule Number Two:  NEVER EVER USE PIE CHARTS!

However, if you still, despite of beeing warned, want to use pie chart see

?pie
pie(rep(1, 24), col = rainbow(24), radius = 0.9)

Regards
Petr


> 
> To learn how to create graphs in R, start with ?plot , ?points,
> ?lines.
> Later on you can investigate ?lattice, ?grid,  and ?ggplot2 .
> The fact that you're looking 'online' instead of in R's builtin help
> mechanisms is disconcerting.
> 
> 
> 
> 
> blindchicken11 wrote
> > I just started using R software and I'm having some issues making
> > graphs/charts.[snip]
> >
> > I want to start off by just making a pie chart for the categorical
> > data like south, sex, etc. But I've tried everything and can't seem
> to
> > find any information online to help me. The few pie graphs I've
> gotten
> > to show have been giant black and white blobs with no information on
> > them. Any help would be greatly appreciated!
> 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Beginner-
> having-issues-with-making-pie-charts-and-other-graphs-
> tp4679418p4679443.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michael.weylandt at gmail.com  Thu Oct 31 16:01:44 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Thu, 31 Oct 2013 11:01:44 -0400
Subject: [R] an rpy2, R cgi type question
In-Reply-To: <CACxE24kVVyFzH2XRD+SqCio_1TKv6sDOGYen1_PHzMhgskWbGQ@mail.gmail.com>
References: <CACxE24k8-BDeMxpcC-uMVga7FhKrA1Bu2BV9nLVzbvEQDr2FFQ@mail.gmail.com>
	<Pine.LNX.4.44.1310302350580.12472-100000@oxygen.cs.pitt.edu>
	<CACxE24nQEnLeoV+xen7QC-JGmosJWbC9bOaz8y9jQdLgF=9kcQ@mail.gmail.com>
	<864DA490-5E81-4739-9118-90987563A34C@gmail.com>
	<CACxE24kVVyFzH2XRD+SqCio_1TKv6sDOGYen1_PHzMhgskWbGQ@mail.gmail.com>
Message-ID: <81200F08-1F6F-4F7C-A7E8-2C2F844F6119@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/3342f0e0/attachment.pl>

From lorenzo.isella at gmail.com  Thu Oct 31 16:38:52 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Thu, 31 Oct 2013 16:38:52 +0100
Subject: [R] Download CSV Files from EUROSTAT Website
Message-ID: <op.w5tse2qzzqkd1e@bam>

Dear All,
I often need to do some work on some data which is publicly available on  
the EUROSTAT website.
I saw several ways to download automatically mainly the bulk data from  
EUROSTAT to later on postprocess it with R, for instance

http://bit.ly/HrDICj
http://bit.ly/HrDL10
http://bit.ly/HrDTgT

However, what I would like to do is to be able to download directly the  
csv file corresponding to a properly formatted dataset (typically a  
dynamic dataset) from EUROSTAT.
To fix the ideas, please consider the dataset at the following link

http://bit.ly/1coCohq

what I would like to do is to automatically read its content into R, or at  
least to automatically download it as a csv file (full extraction, single  
file, no flags and footnotes) which I can then manipulate easily.
Any suggestion is appreciated.
Cheers

Lorenzo


From dan.abner99 at gmail.com  Thu Oct 31 16:55:44 2013
From: dan.abner99 at gmail.com (Dan Abner)
Date: Thu, 31 Oct 2013 11:55:44 -0400
Subject: [R] arules package apriori() fn error message XXXX
Message-ID: <CAPRGo-kvbyybV=1ZcH+hUnUFd3w0cQ3EfXQGt71=Rx5=+o6nxw@mail.gmail.com>

 Hi everybody,

I am using the apriori() fn in the arules package and am encountered an error.

rules <- apriori(rdayst,parameter = list(support = 0.01, confidence = 0.6))

"You chose a very low absolute support count of 0. You might run of memory."

I assume this is related to the value of .01 specified for the support
= argument. If so, what is a safe and reliable max value for support =
to try? Are there other ways of addressing this problem?

Any insight is appreciated.

Thanks!

Dan


From erinm.hodgess at gmail.com  Thu Oct 31 17:37:28 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 31 Oct 2013 11:37:28 -0500
Subject: [R] an rpy2, R cgi type question
In-Reply-To: <81200F08-1F6F-4F7C-A7E8-2C2F844F6119@gmail.com>
References: <CACxE24k8-BDeMxpcC-uMVga7FhKrA1Bu2BV9nLVzbvEQDr2FFQ@mail.gmail.com>
	<Pine.LNX.4.44.1310302350580.12472-100000@oxygen.cs.pitt.edu>
	<CACxE24nQEnLeoV+xen7QC-JGmosJWbC9bOaz8y9jQdLgF=9kcQ@mail.gmail.com>
	<864DA490-5E81-4739-9118-90987563A34C@gmail.com>
	<CACxE24kVVyFzH2XRD+SqCio_1TKv6sDOGYen1_PHzMhgskWbGQ@mail.gmail.com>
	<81200F08-1F6F-4F7C-A7E8-2C2F844F6119@gmail.com>
Message-ID: <CACxE24k-pfPzURr4mpe8JAUL-ZdfzFvMG-dwfhXovuR7RxCccQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/b92d9226/attachment.pl>

From dwinsemius at comcast.net  Thu Oct 31 17:58:31 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 31 Oct 2013 09:58:31 -0700
Subject: [R] getting p-value for comparing to gam's from gmcv
In-Reply-To: <CACYeG1ii+5S0brmPrL+wwi4mwvTSk5cXkVtgo1xZ6xKADPB0sA@mail.gmail.com>
References: <CACYeG1ii+5S0brmPrL+wwi4mwvTSk5cXkVtgo1xZ6xKADPB0sA@mail.gmail.com>
Message-ID: <65F7D586-E379-46C5-A63D-63D4CD3A4981@comcast.net>


On Oct 30, 2013, at 7:27 PM, Robert Lynch wrote:

> I am trying to compare two different GAM fits.
> I have something like
> Course.bam20 <-bam(zGrade ~ Rep + ISE   + White + Female + Years + AP_TOTAL
> + MATH + HSGPA+ EOP + factor(P7APrior, ordered = FALSE)+s(Yfrm7A,k=20),
> data= Course, na.action = na.exclude,samfrac =0.1)
> 
> Course.bam4 <-bam(zGrade ~ Rep + ISE   + White + Female + Years + AP_TOTAL
> + MATH + HSGPA+ EOP + factor(P7APrior, ordered = FALSE)+s(Yfrm7A,k=4),
> data= Course, na.action = na.exclude,samfrac =0.1)
> 
> anova(Course.bam20, Course.bam4)
> 
> Model 1: zGrade ~ Rep + ISE + White + Female + Years + AP_TOTAL + MATH +
>    HSGPA + EOP + factor(P7APrior, ordered = FALSE) + s(Yfrm7A,
>    k = 20)
> Model 2: zGrade ~ Rep + ISE + White + Female + Years + AP_TOTAL + MATH +
>    HSGPA + EOP + factor(P7APrior, ordered = FALSE) + s(Yfrm7A,
>    k = 4)
>  Resid. Df Resid. Dev      Df Deviance
> 1    4721.7     1907.0
> 2    4724.5     1913.5 -2.7919  -6.4986
> 
> How can I get a p-value out of the anova?
> 
> 	[[alternative HTML version deleted]]

I suspect that the reason no one has answered this is that it appears to be a) a request to explain a fairly simple step in statistical analysis and such requests are generally considered off-topic on r-help, and supporting that notion ...  b) your naming conventions suggests that this is homework, also off-topic here.

> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

If you wnat to appeal this "decision", then please to read the Posting Guide first.

> and provide commented, minimal, self-contained, reproducible code.

-- 

David Winsemius
Alameda, CA, USA


From collinl at cs.pitt.edu  Thu Oct 31 18:21:36 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Thu, 31 Oct 2013 13:21:36 -0400
Subject: [R] an rpy2, R cgi type question
In-Reply-To: <CACxE24nQEnLeoV+xen7QC-JGmosJWbC9bOaz8y9jQdLgF=9kcQ@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.1310311320420.20518-100000@neodymium.cs.pitt.edu>

Not terribly verbose.  If you google it there is a cgitb flag you can set
to get verbose python output.  It is off by default for deployment as it
is a security hole but it is useful now.

	Collin.

On Thu, 31 Oct 2013, Erin Hodgess wrote:

> Hi again:
>
> Here is the web output:
>
> Internal Server Error
>
> The server encountered an internal error or misconfiguration and was unable
> to complete your request.
>
> Please contact the server administrator, webmaster at erinm.info and inform
> them of the time the error occurred, and anything you might have done that
> may have caused the error.
>
> More information about this error may be available in the server error log.
>
> Additionally, a 404 Not Found error was encountered while trying to use an
> ErrorDocument to handle the request.
> I did indeed check permissions and they seem to be in order.
>
> Thanks,
> Erin
>
>
>
> On Wed, Oct 30, 2013 at 10:51 PM, Collin Lynch <collinl at cs.pitt.edu> wrote:
>
> > Erin can you share the internal error details?
> >
> > As a first guess are the files executable by all?  CGI requires world rwx.
> >
> >         Best,
> >         Collin.
> >
> > On Wed, 30 Oct 2013, Erin Hodgess wrote:
> >
> > > Hi again.
> > >
> > > I'm putting together a little project with R, python, and a website.  So
> > I
> > > have an HTML file, a py file, an R file.
> > >
> > > Here is the HTML file:
> > > <form action="/cgi-bin/radio4.py" method="post" target="_blank">
> > > <input type="radio" name="subject" value="Integrate" /> Integrate
> > > <input type="radio" name="subject" value="Differentiate" /> Differentiate
> > > <input type="radio" name="subject" value="Graph" /> Graph
> > > Function <input type="text"  name="func1" <br />
> > > <input type="submit" value="Select Subject" />
> > > </form>
> > >
> > > Now the radio4.py file:
> > >
> > > # Import modules for CGI handling
> > > import cgi, cgitb
> > > from sympy import *
> > > import sys
> > >
> > > from rpy2.robjects.packages import SignatureTranslatedAnonymousPackage as
> > > STAP
> > > with open("bz2.R","r") as f:
> > >     string=''.join(f.readlines())
> > > etest = STAP(string,"etest")
> > > etest.etest(500)
> > >
> > >
> > > # Create instance of FieldStorage
> > > form = cgi.FieldStorage()
> > >
> > > # Get data from fields
> > > if form.getvalue('subject'):
> > >    subject = form.getvalue('subject')
> > > else:
> > >    subject = "Not set"
> > >
> > > if form.getvalue('func1'):
> > >    func1 = form.getvalue('func1')
> > > else:
> > >    func1 = "Not entered"
> > >
> > >
> > >
> > >
> > >
> > > print "Content-type:text/html\r\n\r\n"
> > > print "<html>"
> > > print "<head>"
> > > print "<title>Test Project</title>"
> > > print "</head>"
> > > print "<body>"
> > > print "<h2> Selected Action is %s</h2>" % subject
> > > print "<h3> output function is %s</h3>" % func1
> > > print "</body>"
> > > print "</html>"
> > >
> > >
> > > Finally, the bz2.R file:
> > >
> > > etest <- function(n=100) {
> > >     y <- rnorm(n)
> > >     pdf(file="lap1.png")
> > >     plot(y)
> > >     dev.off()
> > > }
> > >
> > >
> > > The radio4.py file is in a cgi-bin directory, along with the bz2.R file.
> > >
> > > I keep getting the Internal server error.
> > >
> > > Thanks for any help.
> > >
> > > Sincerely,
> > > Erin
> > >
> > > This is R version 3.0.2 and Python 2.7.5
> > >
> > > --
> > > Erin Hodgess
> > > Associate Professor
> > > Department of Computer and Mathematical Sciences
> > > University of Houston - Downtown
> > > mailto: erinm.hodgess at gmail.com
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>


From ccampbell at mango-solutions.com  Thu Oct 31 18:24:43 2013
From: ccampbell at mango-solutions.com (Chris Campbell)
Date: Thu, 31 Oct 2013 17:24:43 +0000
Subject: [R] Make Multiple plots in R
In-Reply-To: <7205E5BE63A0214BAB03B3C8DAEB9528AD36FCED@CGIARMBX1.nochub.CGIARAD.ORG>
References: <7205E5BE63A0214BAB03B3C8DAEB9528AD36FCED@CGIARMBX1.nochub.CGIARAD.ORG>
Message-ID: <2C2DB2ABEE65DB40B7946E54C71A8C098D4B1889@mexchange.Mango.local>

Hi Jusper   
   
The function plot is generic; the method used to create the image depends on the type of the data object with which you are working. So for example calling plot on an "lm" object actually calls plot.lm.    
   
If you type:   
> class(mybrick9)   
   
You will see the class of your object. The plot is often created by a method named after that class. For example, if the object is a class "geomap" object, then the plot is created by plot.geomap. To read the help on this function, type:   
> ?plot.geomap    
   
If you want to check the methods available for your object, you can type:    
> methods(class = "geomap")   
   
I hope this helps.   
   
Best wishes   
   
Chris    


Chris Campbell, PhD   
Tel. +44 (0) 1249 705 450?| Mobile. +44 (0) 7929 628 349   
ccampbell at mango-solutions.com?| http://www.mango-solutions.com   
Data Analysis the Delivers   
Mango Solutions   
2 Methuen Park, Chippenham, Wiltshire. SN14 OGB UK   

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Kiplimo, Jusper (ILRI)
Sent: 31 October 2013 11:09
To: r-help at r-project.org
Subject: [R] Make Multiple plots in R

Dear All,

I would wish to make multiple plots and give title/ headings same time, is there a simpler/ tidier way compared to below(, especially the headings as they are missing)? See output attached.

#####################################Making multiple Plots start########################

plot(mybrick9, y = 2, col = terrain.colors( length(seq(0,1, by = .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
     main = 'April 2006',
     xlab = 'Longitude', ylab = 'Latitude', 
     cex.lab = 1, cex.axis = 1 )
plot(mymap3, add = T)

plot(mybrick9, y = 5, col = terrain.colors( length(seq(0,1, by = .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
     main = 'May 2006',
     xlab = 'Longitude', ylab = 'Latitude', 
     cex.lab = 1, cex.axis = 1 )
plot(mymap3, add = T)

plot(mybrick9, y = 8, col = terrain.colors( length(seq(0,1, by = .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
     main = 'June 2006',
     xlab = 'Longitude', ylab = 'Latitude', 
     cex.lab = 1, cex.axis = 1 )
plot(mymap3, add = T)

plot(mybrick9, y = 11, col = terrain.colors( length(seq(0,1, by = .2))-1),breaks= seq(0, 1, by = 0.2), axes = T,
     main = 'July 2006',
     xlab = 'Longitude', ylab = 'Latitude', 
     cex.lab = 1, cex.axis = 1 )
plot(mymap3, add = T)

#####################################Making multiple Plots end########################

Regards,
Jusper	 

--

LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}


From S.Ellison at LGCGroup.com  Thu Oct 31 18:33:37 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 31 Oct 2013 17:33:37 +0000
Subject: [R] getting p-value for comparing to gam's from gmcv
In-Reply-To: <65F7D586-E379-46C5-A63D-63D4CD3A4981@comcast.net>
References: <CACYeG1ii+5S0brmPrL+wwi4mwvTSk5cXkVtgo1xZ6xKADPB0sA@mail.gmail.com>
	<65F7D586-E379-46C5-A63D-63D4CD3A4981@comcast.net>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554EAA05E@GOLD.corp.lgc-group.com>

> > I am trying to compare two different GAM fits.
> > ...
> > How can I get a p-value out of the anova?

See ?anova.gam and pay attention to the 'test' argument.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From carlos.nasher at googlemail.com  Thu Oct 31 18:45:54 2013
From: carlos.nasher at googlemail.com (Carlos Nasher)
Date: Thu, 31 Oct 2013 18:45:54 +0100
Subject: [R] Count number of consecutive zeros by group
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5554EA9DFB@GOLD.corp.lgc-group.com>
References: <CAP=BVWPwu7B9WHtmyhCapQby2EX=YXjLnquoZrmqDdLyd=rh-g@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554EA9DFB@GOLD.corp.lgc-group.com>
Message-ID: <CAP=BVWN+wD10GCiRFCJiMQRHZ0AA8Y=e+G1i3UGDqkP0w0ixzQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/05cf50a0/attachment.pl>

From alex at fafula.com  Thu Oct 31 17:02:32 2013
From: alex at fafula.com (olo)
Date: Thu, 31 Oct 2013 09:02:32 -0700 (PDT)
Subject: [R] Moving averages shading / two colours / polygon
Message-ID: <1383235351829-4679460.post@n4.nabble.com>

I am stuck at the following problem.

I have two moving averages. One is faster than another. After plotting them
I need to shade area between them in green when the faster is above slower
and red where faster is below slower.

Something like this:
http://charts.stocktwits.com/production/original_9205513.png?1345576091

I tried with polygon but I can't do it. Any hints?

Regards
olo



--
View this message in context: http://r.789695.n4.nabble.com/Moving-averages-shading-two-colours-polygon-tp4679460.html
Sent from the R help mailing list archive at Nabble.com.


From ranjanmano167 at gmail.com  Thu Oct 31 13:25:46 2013
From: ranjanmano167 at gmail.com (Manoranjan Muthusamy)
Date: Thu, 31 Oct 2013 13:25:46 +0100
Subject: [R] Extracting values from a ecdf (empirical cumulative
 distribution function) curve
Message-ID: <CANqyHbR3PP=My5CfqZANs8Q5aL=sYkrxieZhr7_thdLZpX_J5g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/2c659b8b/attachment.pl>

From smartpink111 at yahoo.com  Thu Oct 31 14:20:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 31 Oct 2013 06:20:25 -0700 (PDT)
Subject: [R] Count number of consecutive zeros by group
In-Reply-To: <CAP=BVWPwu7B9WHtmyhCapQby2EX=YXjLnquoZrmqDdLyd=rh-g@mail.gmail.com>
References: <CAP=BVWPwu7B9WHtmyhCapQby2EX=YXjLnquoZrmqDdLyd=rh-g@mail.gmail.com>
Message-ID: <1383225625.14405.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
May be this helps:
fun1 <- function(dat){
?lst1 <- lapply(split(dat,dat$ID),function(y){
?rl <- rle(y$x)
?data.frame(ID=unique(y$ID),MAXZero=max(rl$lengths[rl$values==0]))
?})
?do.call(rbind,lst1)
?}

fun1(df)
#? ID MAXZero
#1? 1?????? 2
#2? 2?????? 2
#3? 3?????? 1

A.K. 








On Thursday, October 31, 2013 7:22 AM, Carlos Nasher <carlos.nasher at googlemail.com> wrote:
Dear R-helpers,

I need to count the maximum number of consecutive zero values of a variable
in a dataframe by different groups. My dataframe looks like this:

ID <- c(1,1,1,2,2,3,3,3,3)
x <- c(1,0,0,0,0,1,1,0,1)
df <- data.frame(ID=ID,x=x)
rm(ID,x)

So I want to get the max number of consecutive zeros of variable x for each
ID. I found rle() to be helpful for this task; so I did:

FUN <- function(x) {
? rles <- rle(x == 0)
}
consec <- lapply(split(df[,2],df[,1]), FUN)

consec is now an rle object containing lists f?r each ID that contain
$lenghts: int as the counts for every consecutive number and $values: logi
indicating if the consecutive numbers are zero or not.

Unfortunately I'm not very experienced with lists. Could you help me how to
extract the max number of consec zeros for each ID and return the result as
a dataframe containing ID and max number of consecutive zeros?

Different approaches are also welcome. Since the real dataframe is quite
large, a fast solution is appreciated.

Best regards,
Carlos


-- 
-----------------------------------------------------------------
Carlos Nasher
Buchenstr. 12
22299 Hamburg

tel:? ? ? ? ? ? +49 (0)40 67952962
mobil:? ? ? ? +49 (0)175 9386725
mail:? ? ? ? ? carlos.nasher at gmail.com

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From S.Ellison at LGCGroup.com  Thu Oct 31 19:26:56 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 31 Oct 2013 18:26:56 +0000
Subject: [R] Count number of consecutive zeros by group
In-Reply-To: <CAP=BVWN+wD10GCiRFCJiMQRHZ0AA8Y=e+G1i3UGDqkP0w0ixzQ@mail.gmail.com>
References: <CAP=BVWPwu7B9WHtmyhCapQby2EX=YXjLnquoZrmqDdLyd=rh-g@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554EA9DFB@GOLD.corp.lgc-group.com>
	<CAP=BVWN+wD10GCiRFCJiMQRHZ0AA8Y=e+G1i3UGDqkP0w0ixzQ@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554EAA072@GOLD.corp.lgc-group.com>

> If I apply your function to my test data:
> 
....
> the result is
> 1 2 3
> 2 2 2
> 
...
> I think f2 does not return the max of consecutive zeros, but the max of any
> consecutve number... Any idea how to fix this?

The toy example of tapply using f2 does indeed return the maximum run lengths irrespective of the value repeated. 
If you want to select runs of a particular value, you can select according to use $values element of the rle object, again inside the function.
Modifying to accommodate that (and again avoiding a data frame name the same as a base R  function name - you managed it again!):

dfr <- data.frame(ID = c(1,1,1,2,2,3,3,3,3), x = c(1,0,0,0,0,1,1,0,1))

f3 <-   function(x) {
  runs <- rle(x == 0L) #Often wise to be careful with == and numbers ... see FAQ 7.31
  with(runs, max(lengths[values])) 
	#This works because in this case the values in 
	#$values are TRUE for x==0 and FALSE otherwise; see ?'[' for why those work 
}
with(dfr, tapply(x, ID, f3)) 

or, more or less equivalently but a shade more generally

f4 <-   function(x, select=0L) {
  runs <- rle(x )
  with(runs, max(lengths[values == select])) 
}
with(dfr, tapply(x, ID, f4)) 

None of this checks that runs of zero exist in a group; if they don't, you'll get warnings and -Inf in the output as max takes maxima of nothing. You can add extra checks inside the function if that bothers you. 




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From alex at fafula.com  Thu Oct 31 19:48:17 2013
From: alex at fafula.com (olo)
Date: Thu, 31 Oct 2013 11:48:17 -0700 (PDT)
Subject: [R] Moving averages shading / two colours / polygon
In-Reply-To: <1383235351829-4679460.post@n4.nabble.com>
References: <1383235351829-4679460.post@n4.nabble.com>
Message-ID: <1383245297069-4679479.post@n4.nabble.com>

Solution: 

http://learnr.wordpress.com/2009/10/22/ggplot2-two-color-xy-area-combo-chart/



--
View this message in context: http://r.789695.n4.nabble.com/Moving-averages-shading-two-colours-polygon-tp4679460p4679479.html
Sent from the R help mailing list archive at Nabble.com.


From hpages at fhcrc.org  Thu Oct 31 19:54:55 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 31 Oct 2013 11:54:55 -0700
Subject: [R] Count number of consecutive zeros by group
In-Reply-To: <CAP=BVWPwu7B9WHtmyhCapQby2EX=YXjLnquoZrmqDdLyd=rh-g@mail.gmail.com>
References: <CAP=BVWPwu7B9WHtmyhCapQby2EX=YXjLnquoZrmqDdLyd=rh-g@mail.gmail.com>
Message-ID: <5272A77F.6090101@fhcrc.org>

Hi Carlos,

With Bioconductor, this can simply be done with:

   library(IRanges)
   ID <- Rle(1:3, c(3,2,4))
   x <- Rle(c(1,0,0,0,0,1,1,0,1))
   groups <- split(x, ID)
   idx <- groups == 0

Then:

   > max(runLength(idx)[runValue(idx)])
   1 2 3
   2 2 1

Should be fast even with hundreds of thousands of groups (should take
< 10 sec).

HTH,
H.


On 10/31/2013 04:20 AM, Carlos Nasher wrote:
> Dear R-helpers,
>
> I need to count the maximum number of consecutive zero values of a variable
> in a dataframe by different groups. My dataframe looks like this:
>
> ID <- c(1,1,1,2,2,3,3,3,3)
> x <- c(1,0,0,0,0,1,1,0,1)
> df <- data.frame(ID=ID,x=x)
> rm(ID,x)
>
> So I want to get the max number of consecutive zeros of variable x for each
> ID. I found rle() to be helpful for this task; so I did:
>
> FUN <- function(x) {
>    rles <- rle(x == 0)
> }
> consec <- lapply(split(df[,2],df[,1]), FUN)
>
> consec is now an rle object containing lists f?r each ID that contain
> $lenghts: int as the counts for every consecutive number and $values: logi
> indicating if the consecutive numbers are zero or not.
>
> Unfortunately I'm not very experienced with lists. Could you help me how to
> extract the max number of consec zeros for each ID and return the result as
> a dataframe containing ID and max number of consecutive zeros?
>
> Different approaches are also welcome. Since the real dataframe is quite
> large, a fast solution is appreciated.
>
> Best regards,
> Carlos
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From wdunlap at tibco.com  Thu Oct 31 20:07:25 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 31 Oct 2013 19:07:25 +0000
Subject: [R] Count number of consecutive zeros by group
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5554EAA072@GOLD.corp.lgc-group.com>
References: <CAP=BVWPwu7B9WHtmyhCapQby2EX=YXjLnquoZrmqDdLyd=rh-g@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554EA9DFB@GOLD.corp.lgc-group.com>
	<CAP=BVWN+wD10GCiRFCJiMQRHZ0AA8Y=e+G1i3UGDqkP0w0ixzQ@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554EAA072@GOLD.corp.lgc-group.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA11BF1@PA-MBX01.na.tibco.com>

> None of this checks that runs of zero exist in a group; if they don't, you'll get warnings
> and -Inf in the output as max takes maxima of nothing. You can add extra checks inside
> the function if that bothers you.

Just adding a second argument, 0, to the call to max() will take care of that.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of S Ellison
> Sent: Thursday, October 31, 2013 11:27 AM
> To: Carlos Nasher; r-help at r-project.org
> Subject: Re: [R] Count number of consecutive zeros by group
> 
> > If I apply your function to my test data:
> >
> ....
> > the result is
> > 1 2 3
> > 2 2 2
> >
> ...
> > I think f2 does not return the max of consecutive zeros, but the max of any
> > consecutve number... Any idea how to fix this?
> 
> The toy example of tapply using f2 does indeed return the maximum run lengths
> irrespective of the value repeated.
> If you want to select runs of a particular value, you can select according to use $values
> element of the rle object, again inside the function.
> Modifying to accommodate that (and again avoiding a data frame name the same as a
> base R  function name - you managed it again!):
> 
> dfr <- data.frame(ID = c(1,1,1,2,2,3,3,3,3), x = c(1,0,0,0,0,1,1,0,1))
> 
> f3 <-   function(x) {
>   runs <- rle(x == 0L) #Often wise to be careful with == and numbers ... see FAQ 7.31
>   with(runs, max(lengths[values]))
> 	#This works because in this case the values in
> 	#$values are TRUE for x==0 and FALSE otherwise; see ?'[' for why those work
> }
> with(dfr, tapply(x, ID, f3))
> 
> or, more or less equivalently but a shade more generally
> 
> f4 <-   function(x, select=0L) {
>   runs <- rle(x )
>   with(runs, max(lengths[values == select]))
> }
> with(dfr, tapply(x, ID, f4))
> 
> None of this checks that runs of zero exist in a group; if they don't, you'll get warnings
> and -Inf in the output as max takes maxima of nothing. You can add extra checks inside
> the function if that bothers you.
> 
> 
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From entropy053 at gmail.com  Thu Oct 31 20:58:12 2013
From: entropy053 at gmail.com (Yasin Gocgun)
Date: Thu, 31 Oct 2013 15:58:12 -0400
Subject: [R] set difference between two data frames
Message-ID: <CAJJuoES01oF4c7JBjc8erv_=cWcOdHpWhZBKARpg2DMqHRjYgw@mail.gmail.com>

Hi,

I have two data frames, say, x and y, where y is a subset of x. How
can I find the set difference of these two data frames (i.e., x-y)?

Thanks,

-- 
Yasin Gocgun


From gunter.berton at gene.com  Thu Oct 31 21:07:13 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 31 Oct 2013 13:07:13 -0700
Subject: [R] set difference between two data frames
In-Reply-To: <CAJJuoES01oF4c7JBjc8erv_=cWcOdHpWhZBKARpg2DMqHRjYgw@mail.gmail.com>
References: <CAJJuoES01oF4c7JBjc8erv_=cWcOdHpWhZBKARpg2DMqHRjYgw@mail.gmail.com>
Message-ID: <CACk-te1Tn=kzH+Uj8z8wgngC4bhaeAe33M-EgoSbC+bctMHrfw@mail.gmail.com>

lapply() setdiff() by columns.

Unless you have failed to tell us something, you almost certainly will
not get a data frame (same number of rows/column) as your answer.

-- Bert

On Thu, Oct 31, 2013 at 12:58 PM, Yasin Gocgun <entropy053 at gmail.com> wrote:
> Hi,
>
> I have two data frames, say, x and y, where y is a subset of x. How
> can I find the set difference of these two data frames (i.e., x-y)?
>
> Thanks,
>
> --
> Yasin Gocgun
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From Mike.Conklin at gfk.com  Thu Oct 31 21:08:02 2013
From: Mike.Conklin at gfk.com (Conklin, Mike (GfK))
Date: Thu, 31 Oct 2013 21:08:02 +0100
Subject: [R]  help with ggplot legend specification
Message-ID: <FB454C9C2759D64BA12708C3073C30BB6A0E63C098@NUEW-EXMBCRB1.gfk.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/5cc0daf7/attachment.pl>

From ruipbarradas at sapo.pt  Thu Oct 31 21:25:00 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 31 Oct 2013 20:25:00 +0000
Subject: [R] set difference between two data frames
In-Reply-To: <CAJJuoES01oF4c7JBjc8erv_=cWcOdHpWhZBKARpg2DMqHRjYgw@mail.gmail.com>
References: <CAJJuoES01oF4c7JBjc8erv_=cWcOdHpWhZBKARpg2DMqHRjYgw@mail.gmail.com>
Message-ID: <5272BC9C.9090401@sapo.pt>

Hello,

Try the following. (I don't remember who wrote this function but I saw 
it in R-Help)



setdiffDF <- function(A, B){
     f <- function(A, B)
         A[!duplicated(rbind(B, A))[nrow(B) + 1:nrow(A)], ]
     df1 <- f(A, B)
     df2 <- f(B, A)
     rbind(df1, df2)
}

df1 <- data.frame(A = 1:10, B = 11:20)
df2 <- data.frame(A = 1:5, B = 11:15)
setdiffDF(df1, df2)


Hope this helps,

Rui Barradas

Em 31-10-2013 19:58, Yasin Gocgun escreveu:
> Hi,
>
> I have two data frames, say, x and y, where y is a subset of x. How
> can I find the set difference of these two data frames (i.e., x-y)?
>
> Thanks,
>


From andreas.leha at med.uni-goettingen.de  Thu Oct 31 21:27:55 2013
From: andreas.leha at med.uni-goettingen.de (Andreas Leha)
Date: Thu, 31 Oct 2013 21:27:55 +0100
Subject: [R] quickly extract response from formula
Message-ID: <87ob652njo.fsf@med.uni-goettingen.de>

Hi all,

what is the recommended way to quickly (and without much burden on the
memory) extract the response from a formula?

The standard way to extract the response from a formula seems to be via
model.frame() or model.extract(), but that is very memory intensive.

Here is a quick example, that (BEWARE) consumes a lot of memory:

--8<---------------cut here---------------start------------->8---
require("ALL")
data("ALL")
y <- pData(ALL)$sex
x <- t(exprs(ALL))
mf <- cbind(as.data.frame(x), y=y)

extractResponse <- function(formula, data)
{
  m <- match.call(expand.dots = FALSE)
  m[[1L]] <- quote(stats::model.frame)
  m <- eval.parent(m)
  y <- model.extract(m, "response")

  y
}
extractResponse(y~., data=mf)

extractResponseFast <- function(formula, data)
{
  y <- eval(as.symbol(as.character(formula)[2]),
            environment(formula))

  y
}
extractResponseFast(y~., data=mf)
--8<---------------cut here---------------end--------------->8---



Or, to put my question differently, is the following approach
robust?

--8<---------------cut here---------------start------------->8---
require("ALL")
data("ALL")
y <- pData(ALL)$sex
x <- t(exprs(ALL))
mf <- cbind(as.data.frame(x), y=y)

extractResponseFast <- function(formula, data)
{
  y <- eval(as.symbol(as.character(formula)[2]),
            environment(formula))

  y
}
extractResponseFast(y~., data=mf)
--8<---------------cut here---------------end--------------->8---


Many thanks in advance!

Regards,
Andreas


From entropy053 at gmail.com  Thu Oct 31 21:41:51 2013
From: entropy053 at gmail.com (Yasin Gocgun)
Date: Thu, 31 Oct 2013 16:41:51 -0400
Subject: [R] set difference between two data frames
In-Reply-To: <CACk-te1Tn=kzH+Uj8z8wgngC4bhaeAe33M-EgoSbC+bctMHrfw@mail.gmail.com>
References: <CAJJuoES01oF4c7JBjc8erv_=cWcOdHpWhZBKARpg2DMqHRjYgw@mail.gmail.com>
	<CACk-te1Tn=kzH+Uj8z8wgngC4bhaeAe33M-EgoSbC+bctMHrfw@mail.gmail.com>
Message-ID: <CAJJuoER_x8g+Gc62K35TnbR9K5MwqBKyw=tQ0P4Exc5TWTWLdA@mail.gmail.com>

Thanks. Actually, I forgot to add that both have the same number of columns.

On Thu, Oct 31, 2013 at 4:07 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> lapply() setdiff() by columns.
>
> Unless you have failed to tell us something, you almost certainly will
> not get a data frame (same number of rows/column) as your answer.
>
> -- Bert
>
> On Thu, Oct 31, 2013 at 12:58 PM, Yasin Gocgun <entropy053 at gmail.com> wrote:
>> Hi,
>>
>> I have two data frames, say, x and y, where y is a subset of x. How
>> can I find the set difference of these two data frames (i.e., x-y)?
>>
>> Thanks,
>>
>> --
>> Yasin Gocgun
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374



-- 
Yasin Gocgun


From richardkwock at gmail.com  Thu Oct 31 21:41:51 2013
From: richardkwock at gmail.com (Richard Kwock)
Date: Thu, 31 Oct 2013 13:41:51 -0700
Subject: [R] Lattice Legend/Key by row instead of by column
Message-ID: <CAJU8Py06n=EBxAP=HBbiUBcGjyXK7ye=qQCat2L_LvTHP+w2Lg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131031/b65be27a/attachment.pl>

From szehnder at uni-bonn.de  Thu Oct 31 21:51:40 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Thu, 31 Oct 2013 21:51:40 +0100
Subject: [R] set difference between two data frames
In-Reply-To: <CAJJuoER_x8g+Gc62K35TnbR9K5MwqBKyw=tQ0P4Exc5TWTWLdA@mail.gmail.com>
References: <CAJJuoES01oF4c7JBjc8erv_=cWcOdHpWhZBKARpg2DMqHRjYgw@mail.gmail.com>
	<CACk-te1Tn=kzH+Uj8z8wgngC4bhaeAe33M-EgoSbC+bctMHrfw@mail.gmail.com>
	<CAJJuoER_x8g+Gc62K35TnbR9K5MwqBKyw=tQ0P4Exc5TWTWLdA@mail.gmail.com>
Message-ID: <AD26724C-23F9-45A8-BEFC-C20300499FB0@uni-bonn.de>

You could e.g. take the data.table package (every data.table is a data.frame) and make a join:

dt.x <- data.table(x)
dt.y <- data.table(y)
merge.xy <- x[y, nomatch = 0]
diff.xy <- x[!merge.xy]



On 31 Oct 2013, at 21:41, Yasin Gocgun <entropy053 at gmail.com> wrote:

> Thanks. Actually, I forgot to add that both have the same number of columns.
> 
> On Thu, Oct 31, 2013 at 4:07 PM, Bert Gunter <gunter.berton at gene.com> wrote:
>> lapply() setdiff() by columns.
>> 
>> Unless you have failed to tell us something, you almost certainly will
>> not get a data frame (same number of rows/column) as your answer.
>> 
>> -- Bert
>> 
>> On Thu, Oct 31, 2013 at 12:58 PM, Yasin Gocgun <entropy053 at gmail.com> wrote:
>>> Hi,
>>> 
>>> I have two data frames, say, x and y, where y is a subset of x. How
>>> can I find the set difference of these two data frames (i.e., x-y)?
>>> 
>>> Thanks,
>>> 
>>> --
>>> Yasin Gocgun
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> --
>> 
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> 
>> (650) 467-7374
> 
> 
> 
> -- 
> Yasin Gocgun
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Oct 31 21:51:53 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 31 Oct 2013 13:51:53 -0700 (PDT)
Subject: [R] set difference between two data frames
In-Reply-To: <5272BC9C.9090401@sapo.pt>
References: <CAJJuoES01oF4c7JBjc8erv_=cWcOdHpWhZBKARpg2DMqHRjYgw@mail.gmail.com>
	<5272BC9C.9090401@sapo.pt>
Message-ID: <1383252713.83983.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Also, you could try:
library(sqldf)
sqldf('SELECT * FROM df1 EXCEPT SELECT * FROM df2')

A.K.




On Thursday, October 31, 2013 4:28 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
Hello,

Try the following. (I don't remember who wrote this function but I saw 
it in R-Help)



setdiffDF <- function(A, B){
? ?  f <- function(A, B)
? ? ? ?  A[!duplicated(rbind(B, A))[nrow(B) + 1:nrow(A)], ]
? ?  df1 <- f(A, B)
? ?  df2 <- f(B, A)
? ?  rbind(df1, df2)
}

df1 <- data.frame(A = 1:10, B = 11:20)
df2 <- data.frame(A = 1:5, B = 11:15)
setdiffDF(df1, df2)


Hope this helps,

Rui Barradas


Em 31-10-2013 19:58, Yasin Gocgun escreveu:
> Hi,
>
> I have two data frames, say, x and y, where y is a subset of x. How
> can I find the set difference of these two data frames (i.e., x-y)?
>
> Thanks,
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ruipbarradas at sapo.pt  Thu Oct 31 22:53:28 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 31 Oct 2013 21:53:28 +0000
Subject: [R] Extracting values from a ecdf (empirical cumulative
 distribution function) curve
In-Reply-To: <CANqyHbR3PP=My5CfqZANs8Q5aL=sYkrxieZhr7_thdLZpX_J5g@mail.gmail.com>
References: <CANqyHbR3PP=My5CfqZANs8Q5aL=sYkrxieZhr7_thdLZpX_J5g@mail.gmail.com>
Message-ID: <5272D158.6090408@sapo.pt>

Hello,

As for the problem of finding y given the ecdf and x, it's very easy, 
just use the ecdf:

f <- ecdf(rnorm(100))

x <- rnorm(10)
y <- f(x)

If you want to get the x corresponding to given y, use linear interpolation.

inv_ecdf <- function(f){
	x <- environment(f)$x
	y <- environment(f)$y
	approxfun(y, x)
}

g <- inv_ecdf(f)
g(0.5)


Hope this helps,

Rui Barradas

Em 31-10-2013 12:25, Manoranjan Muthusamy escreveu:
> Hi R users,
>
> I am a new user, still learning basics of R. Is there anyway to extract y
> (or x) value for a known x (or y) value from ecdf (empirical cumulative
> distribution function) curve?
>
> Thanks in advance.
> Mano.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Thu Oct 31 22:57:44 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 31 Oct 2013 14:57:44 -0700
Subject: [R] quickly extract response from formula
In-Reply-To: <87ob652njo.fsf@med.uni-goettingen.de>
References: <87ob652njo.fsf@med.uni-goettingen.de>
Message-ID: <4AF2DBF0-F14B-40B1-97FA-5F64DC9A5A8F@comcast.net>


On Oct 31, 2013, at 1:27 PM, Andreas Leha wrote:

> Hi all,
> 
> what is the recommended way to quickly (and without much burden on the
> memory) extract the response from a formula?

If you want its expression value its just form[[2]]

If you wnat it evaluated in the environment of a dataframe then this should be fairly efficient:

x <- stats::runif(20)
y <- stats::runif(20)
dfrm <- data.frame(x=x,y=y)
extractResponse <- function(frm, dat) { resp <- frm[[2]]; print(resp) # that's optional
                                         fdat <- eval(resp, envir=dat); return(fdat) }
> extractResponse(y ~. , dat=dfrm)
y
 [1] 0.80458147 0.90447989 0.54874785 0.04227895 0.11540969 0.98003767 0.37372573 0.58013515
 [9] 0.47227247 0.22361616 0.45076628 0.57091106 0.36290661 0.69673890 0.87650224 0.96496587
[17] 0.14923759 0.25083936 0.32139801 0.91958308

> 
> The standard way to extract the response from a formula seems to be via
> model.frame() or model.extract(), but that is very memory intensive.
> 
> Here is a quick example, that (BEWARE) consumes a lot of memory:
> 
> --8<---------------cut here---------------start------------->8---
> require("ALL")
> data("ALL")
> y <- pData(ALL)$sex
> x <- t(exprs(ALL))
> mf <- cbind(as.data.frame(x), y=y)
> 
> extractResponse <- function(formula, data)
> {
>  m <- match.call(expand.dots = FALSE)
>  m[[1L]] <- quote(stats::model.frame)
>  m <- eval.parent(m)
>  y <- model.extract(m, "response")
> 
>  y
> }
> extractResponse(y~., data=mf)
> 
> extractResponseFast <- function(formula, data)
> {
>  y <- eval(as.symbol(as.character(formula)[2]),
>            environment(formula))
> 
>  y
> }
> extractResponseFast(y~., data=mf)
> --8<---------------cut here---------------end--------------->8---
> 
> 
> 
> Or, to put my question differently, is the following approach
> robust?
> 
> --8<---------------cut here---------------start------------->8---
> require("ALL")
> data("ALL")
> y <- pData(ALL)$sex
> x <- t(exprs(ALL))
> mf <- cbind(as.data.frame(x), y=y)
> 
> extractResponseFast <- function(formula, data)
> {
>  y <- eval(as.symbol(as.character(formula)[2]),
>            environment(formula))
> 
>  y
> }
> extractResponseFast(y~., data=mf)
> --8<---------------cut here---------------end--------------->8---
> 
> 
> Many thanks in advance!
> 
> Regards,
> Andreas
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dulcalma at bigpond.com  Thu Oct 31 23:47:47 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 1 Nov 2013 08:47:47 +1000
Subject: [R] Lattice Legend/Key by row instead of by column
In-Reply-To: <CAJU8Py06n=EBxAP=HBbiUBcGjyXK7ye=qQCat2L_LvTHP+w2Lg@mail.gmail.com>
References: <CAJU8Py06n=EBxAP=HBbiUBcGjyXK7ye=qQCat2L_LvTHP+w2Lg@mail.gmail.com>
Message-ID: <000001ced68b$39004400$ab00cc00$@bigpond.com>

Hi Richard

If you cannot get a better suggestion this example from Deepayan Sarkar may
help. 
It is way back in the archives and I do not have a reference for it.

I have used it about a year ago as a template to do a complicated key

fl <- grid.layout(nrow = 2, ncol = 6, 
                  heights = unit(rep(1, 2), "lines"),
                  widths = unit(c(2, 1, 2, 1, 2, 1), 
 
c("cm","strwidth","cm","strwidth","cm","strwidth"), 
                  data = list(NULL,"John",NULL,"George",NULL,"The
Beatles"))) 

foo <- frameGrob(layout = fl)
foo <- placeGrob(foo, 
                 pointsGrob(.5, .5, pch=19, 
                            gp = gpar(col="red", cex=0.5)), 
                 row = 1, col = 1) 
foo <- placeGrob(foo, 
                 linesGrob(c(0.2, 0.8), c(.5, .5), 
                           gp = gpar(col="blue")), 
                 row = 2, col = 1) 
foo <- placeGrob(foo, 
                 linesGrob(c(0.2, 0.8), c(.5, .5), 
                           gp = gpar(col="green")), 
                 row = 1, col = 3) 
foo <- placeGrob(foo, 
                 linesGrob(c(0.2, 0.8), c(.5, .5), 
                           gp = gpar(col="orange")), 
                 row = 2, col = 3) 
foo <- placeGrob(foo, 
                 rectGrob(width = 0.6, 
                          gp = gpar(col="#FFFFCC", 
                          fill = "#FFFFCC")), 
                 row = 1, col = 5) 
foo <- placeGrob(foo, 
                 textGrob(lab = "John"), 
                 row = 1, col = 2) 
foo <- placeGrob(foo, 
                 textGrob(lab = "Paul"), 
                 row = 2, col = 2) 
foo <- placeGrob(foo, 
                 textGrob(lab = "George"), 
                 row = 1, col = 4) 
foo <- placeGrob(foo, 
                 textGrob(lab = "Ringo"), 
                 row = 2, col = 4) 
foo <- placeGrob(foo, 
                 textGrob(lab = "The Beatles"), 
                 row = 1, col = 6) 

xyplot(1 ~ 1, legend = list(top = list(fun = foo)))

In my case I changed  "strwidth" to "cm" for the text as I was cramped for
space

HTH

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Richard Kwock
Sent: Friday, 1 November 2013 06:42
To: R help
Subject: [R] Lattice Legend/Key by row instead of by column

Hi All,

I am having some trouble getting lattice to display the legend names by row
instead of by column (default).

Example:

library(lattice)
set.seed(456846)
data <- matrix(c(1:10) + runif(50), ncol = 5, nrow = 10) dataset <-
data.frame(data = as.vector(data), group = rep(1:5, each = 10), time = 1:10)

xyplot(data ~ time, group = group, dataset, t = "l",
  key = list(text = list(paste("group", unique(dataset$group)) ),
    lines = list(col = trellis.par.get()$superpose.symbol$col[1:5]),
    columns = 4
  )
)

What I'm hoping for are 4 columns in the legend, like this:
Legend row 1: "group 1", "group 2", "group 3", "group 4"
Legend row 2: "group 5"

However, I'm getting:
Legend row 1: "group 1", "group 3", "group 5"
Legend row 2: "group 2", "group 4"

I can see how this might work if I include blanks/NULLs in the legend as
placeholders, but that might get messy in data sets with many groups.

Any ideas on how to get around this?

Thanks,
Richard

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


