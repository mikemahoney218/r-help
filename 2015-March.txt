From roy.mendelssohn at noaa.gov  Sun Mar  1 00:32:17 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Sat, 28 Feb 2015 15:32:17 -0800
Subject: [R] Lubridate and NameSpace
In-Reply-To: <81c14e41-059c-481c-83c6-98742e78851b@me.com>
References: <81c14e41-059c-481c-83c6-98742e78851b@me.com>
Message-ID: <FDE907D9-DC96-469A-AA0B-D41ECE7C0A21@noaa.gov>

Not certain but perhaps:

>  lubridate::%m+%

there is a subtle difference between what the two and three colons do.

-Roy

On Feb 28, 2015, at 9:25 AM, Glenn Schultz <glennmschultz at me.com> wrote:

> Hello All,
> 
> I am working on a package very near completion - roxygenizing it now.  The namespace imports from lubridate importFrom(lubridate,"%m+%").  The problem is:
> 
> Lubridate will not load with bondlab, I have to manually click on lubridate in R Studio to load it
> I tried calling function using lubridate:::%m+% within my function based on some discussion I found online.  This is likely the correct idea but I don't think I am calling the function correctly since it does not work in the code when I use the above syntax.
> Any suggestions are appreciated>
> 
> Best Glenn 
> 
> The description file is as follows: 
> 
> Package: BondLab
> Type: Package
> Title: A package for the analysis of structured products
> Version: 0.0.0
> Date: 2013-12-08
> Author: Glenn Schultz, CFA
> Maintainer: Glenn Schultz <glennmschultz at me.com>
> Description: The package provides a suite of software utilities for the analysis of Mortgage and Asset Backed securities
> LazyLoad: yes
> License: GPL(>=3.0)
> Imports:  termstrc, 
>           lubridate, 
>           methods, 
>           optimx,
> Suggests: knitr,
>           devtools,
>           testthat
> VignetteBuilder: knitr
> 
> The Namespace is as follows:
> # Generated by roxygen2 (4.1.0): do not edit by hand
> 
> export(CPR.To.SMM)
> export(DollarRoll)
> export(Effective.Convexity)
> export(Effective.Duration)
> export(EstimYTM)
> export(MakeScenario)
> export(Mortgage.Monthly.Payment)
> export(MortgageCashFlow)
> export(PPC.Ramp)
> export(PassThroughAnalytics)
> export(PassThroughOAS)
> export(Rates)
> export(Remain.Balance)
> export(SMM.To.CPR)
> export(SMMVector.To.CPR)
> export(Sched.Prin)
> export(TermStructure)
> export(TimeValue)
> export(bondprice)
> import(methods)
> import(optimx)
> importFrom(lubridate,"%m+%")
> importFrom(termstrc,create_cashflows_matrix)
> importFrom(termstrc,create_maturities_matrix)
> importFrom(termstrc,estim_cs)
> importFrom(termstrc,estim_nss)
> importFrom(termstrc,forwardrates)
> importFrom(termstrc,spotrates)
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From r.turner at auckland.ac.nz  Sun Mar  1 00:43:09 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 01 Mar 2015 12:43:09 +1300
Subject: [R] Firefox not showing R help.
In-Reply-To: <54F23A47.8070700@gmail.com>
References: <54F22EBC.1070400@auckland.ac.nz> <54F23A47.8070700@gmail.com>
Message-ID: <54F2528D.9080101@auckland.ac.nz>


See inline below.

On 01/03/15 10:59, Duncan Murdoch wrote:
> On 28/02/2015 4:10 PM, Rolf Turner wrote:
>>
>> Firefox recently updated itself on my laptop.  Now when I ask for R help
>> --- e.g. ?plot --- I just get my home page. And no help. If I do "?plot"
>> again after Firefox has opened its window, I just get yet another
>> Firefox window, opened to my home page.  (I have my preferences set to
>>
>>       "When Firefox starts Show my homepage"
>>
>> --- as I always have had in the past.)
>
> I would guess that browseURL() won't work for any URL.  Is that right?

Yes.  That is correct. E.g. if I do

     browseURL("http://www.r-project.org/")

I get taken to my home page, rather than to the R home page.

>
> What does getOption("browser") give you in R?

"/usr/bin/firefox"

> If it is just a character
> string (e.g. "xdg-open" is what I get in Ubuntu), does it work from your
> command line, outside of R, e.g. for me that test would be
>
> xdg-open http://www.r-project.org

I tried

    /usr/bin/firefox http://www.r-project.org/

from the Linux command line and was taken to the R home page, 
seamlessly.  I also tried

     xdg-open http://www.r-project.org/

and that worked equally well.

Finally I tried

     options(browser="xdg-open")

and then

     ?plot

and BINGO!!! the HTML help came up as requested.

So I have a working solution to my problem.  But I *really* don't 
understand why changing the browser from "/usr/bin/firefox" to 
"xdg-open" made a difference.  (Since there appears to be no difference 
at the Linux command line.)

Anyway; thanks very much for solving my problem.

cheers,

Rolf

>
> If that doesn't work, but you can figure out a command line way to open
> a particular URL, change getOption("browser") to use that.
>
> Duncan Murdoch
>
>>
>> The Firefox that I am currently running is (according Firefox help
>> --> "About Firefox") is version 36.0.
>>
>> Can anyone suggest to me how I can get my html R help back?
>>
>> For what it's worth:  I am using Linux, Fedora 17.  (Yes, I know it's
>> elderly, but then so am I. :-) )
>>
>> Also in case it has any relevance:
>>
>>>> sessionInfo()
>>> R version 3.1.2 (2014-10-31)
>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>
>>> locale:
>>>   [1] LC_CTYPE=en_NZ.utf8       LC_NUMERIC=C
>>>   [3] LC_TIME=en_NZ.utf8        LC_COLLATE=en_NZ.utf8
>>>   [5] LC_MONETARY=en_NZ.utf8    LC_MESSAGES=en_NZ.utf8
>>>   [7] LC_PAPER=en_NZ.utf8       LC_NAME=C
>>>   [9] LC_ADDRESS=C              LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_NZ.utf8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] spatstat_1.40-0.064 misc_0.0-16
>>>
>>> loaded via a namespace (and not attached):
>>>   [1] abind_1.4-0     deldir_0.1-7    goftest_1.0-2   grid_3.1.2
>>>   [5] lattice_0.20-29 Matrix_1.1-4    mgcv_1.8-3      nlme_3.1-118
>>>   [9] polyclip_1.3-1  tensor_1.5      tools_3.1.2


-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From jdnewmil at dcn.davis.CA.us  Sun Mar  1 00:56:06 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 28 Feb 2015 15:56:06 -0800
Subject: [R] r script in web
In-Reply-To: <CALsy4AzcEtCKLdEzcON1SakP6FoBbwDz_cras_cfz-qdc5bctQ@mail.gmail.com>
References: <CALsy4AzcEtCKLdEzcON1SakP6FoBbwDz_cras_cfz-qdc5bctQ@mail.gmail.com>
Message-ID: <3A442D26-4410-44E5-A3B4-A14493EC8B9C@dcn.davis.CA.us>

I cannot see how that would be possible. R must be installed in order to use it.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 28, 2015 12:29:17 PM PST, hamid-reza kadkhodazadeh <hrk1366 at gmail.com> wrote:
>hi
>i want to run r script in web without install r on server(my server is
>windows).
>is it possible?how?
>
>thank you
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From alrik.thiem at gmail.com  Sun Mar  1 08:06:38 2015
From: alrik.thiem at gmail.com (Alrik Thiem)
Date: Sun, 1 Mar 2015 08:06:38 +0100
Subject: [R] Substring replacement in string
In-Reply-To: <54F24124.8020207@fredhutch.org>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>
	<54F24124.8020207@fredhutch.org>
Message-ID: <000601d053ee$43bfceb0$cb3f6c10$@gmail.com>

Dear Herv?,

Many thanks for your suggestion. Gabor Grothendieck proposed a simple
one-liner that works perfectly for my purposes:

gsub("(\\b[a-oq-z][a-z0-9]*)", "1-\\U\\1", x, perl = TRUE)

where x is the respective string.

Best wishes,
Alrik

-----Urspr?ngliche Nachricht-----
Von: Herv? Pag?s [mailto:hpages at fredhutch.org] 
Gesendet: Samstag, 28. Februar 2015 23:29
An: Alrik Thiem; r-help at r-project.org
Betreff: Re: [R] Substring replacement in string

Hi Alrik,

With the Biostrings/IRanges infrastructure (Bioconductor packages), you
can do this with:

   library(Biostrings)
   x0 <- BString("pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, 
z1))")
   donttouch_words <- c("pmin", "pmax")

   ## Extract the substrings to modify (target substrings).
   donttouch_regions <- reduce(do.call("c", lapply(donttouch_words, 
matchPattern, x0)))
   target_regions <- ranges(gaps(donttouch_regions))
   target_substrings <- extractAt(x0, target_regions)

   ## Modify them.
   old <- paste0(letters, collapse="")
   new <- paste0(LETTERS, collapse="")
   target_substrings <- chartr(old, new, target_substrings)

   ## Replace in original string.
   x1 <- replaceAt(x0, target_regions, target_substrings)

Then:

   > x1
     57-letter "BString" instance
   seq: pmin(pmax(pmin(X1, X2), pmin(X3, X4)) == Y, pmax(Z1, Z1))

   > as.character(x1)
   [1] "pmin(pmax(pmin(X1, X2), pmin(X3, X4)) == Y, pmax(Z1, Z1))"

Hope this helps,
H.

On 02/27/2015 02:19 PM, Alrik Thiem wrote:
> Dear R-help list,
>
> I would like to replace all lower-case letters in a string that are not
part
> of certain fixed expressions. For example, I have the string:
>
> "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
>
> Where I would like to replace all lower-case letters that do not belong to
> the functions "pmin" and "pmax" by 1 - toupper(...) to get
>
> "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"
>
> Any ideas on how I could achieve that?
>
> Many thanks and best wishes,
>
> Alrik
>
>
> ********************************
> Alrik Thiem
> Post-Doctoral Researcher
>
> Department of Philosophy
> University of Geneva
> Rue de Candolle 2
> CH-1211 Geneva
>
> +41 76 527 80 83
>
> http://www.alrik-thiem.net
> http://www.compasss.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fredhutch.org  Sun Mar  1 10:38:25 2015
From: hpages at fredhutch.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Sun, 01 Mar 2015 01:38:25 -0800
Subject: [R] Substring replacement in string
In-Reply-To: <000601d053ee$43bfceb0$cb3f6c10$@gmail.com>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>
	<54F24124.8020207@fredhutch.org>
	<000601d053ee$43bfceb0$cb3f6c10$@gmail.com>
Message-ID: <54F2DE11.4020809@fredhutch.org>

Hi Alrik,

On 02/28/2015 11:06 PM, Alrik Thiem wrote:
> Dear Herv?,
>
> Many thanks for your suggestion. Gabor Grothendieck proposed a simple
> one-liner that works perfectly for my purposes:
>
> gsub("(\\b[a-oq-z][a-z0-9]*)", "1-\\U\\1", x, perl = TRUE)
>
> where x is the respective string.

Sounds good. I didn't realize that you also wanted to prefix the lower
case letters with "1 - " so my solution was not doing the right thing
anyway. Here is the corrected solution, just in case:

   library(Biostrings)

   funnyReplace <- function(x, protected_words)
   {
     x <- BString(x)

     ## Extract the substrings to modify (target substrings).
     protected_regions <- reduce(do.call("c", lapply(protected_words, 
matchPattern, x)))
     target_regions <- ranges(gaps(protected_regions))
     target_substrings <- extractAt(x, target_regions)

     ## Modify them (using a reg exp almost like Gabbor's except
     ## that "p" is not treated as an exception).
     target_substrings <- gsub("(\\b[a-z][a-z0-9]*)", "1 - \\U\\1", 
target_substrings, perl=TRUE)

     ## Replace in original string.
     x <- replaceAt(x, target_regions, target_substrings)
     as.character(x)
}

Then:

   > x <- "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
   > funnyReplace(x, c("pmin", "pmax"))
   [1] "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"

It works even if a variable name starts with a "p":

   > funnyReplace("pmin(p)", c("pmin", "pmax"))
   [1] "pmin(1 - P)"

and you can specify an arbitrary number of protected words.

Cheers,
H.

>
> Best wishes,
> Alrik
>
> -----Urspr?ngliche Nachricht-----
> Von: Herv? Pag?s [mailto:hpages at fredhutch.org]
> Gesendet: Samstag, 28. Februar 2015 23:29
> An: Alrik Thiem; r-help at r-project.org
> Betreff: Re: [R] Substring replacement in string
>
> Hi Alrik,
>
> With the Biostrings/IRanges infrastructure (Bioconductor packages), you
> can do this with:
>
>     library(Biostrings)
>     x0 <- BString("pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1,
> z1))")
>     donttouch_words <- c("pmin", "pmax")
>
>     ## Extract the substrings to modify (target substrings).
>     donttouch_regions <- reduce(do.call("c", lapply(donttouch_words,
> matchPattern, x0)))
>     target_regions <- ranges(gaps(donttouch_regions))
>     target_substrings <- extractAt(x0, target_regions)
>
>     ## Modify them.
>     old <- paste0(letters, collapse="")
>     new <- paste0(LETTERS, collapse="")
>     target_substrings <- chartr(old, new, target_substrings)
>
>     ## Replace in original string.
>     x1 <- replaceAt(x0, target_regions, target_substrings)
>
> Then:
>
>     > x1
>       57-letter "BString" instance
>     seq: pmin(pmax(pmin(X1, X2), pmin(X3, X4)) == Y, pmax(Z1, Z1))
>
>     > as.character(x1)
>     [1] "pmin(pmax(pmin(X1, X2), pmin(X3, X4)) == Y, pmax(Z1, Z1))"
>
> Hope this helps,
> H.
>
> On 02/27/2015 02:19 PM, Alrik Thiem wrote:
>> Dear R-help list,
>>
>> I would like to replace all lower-case letters in a string that are not
> part
>> of certain fixed expressions. For example, I have the string:
>>
>> "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
>>
>> Where I would like to replace all lower-case letters that do not belong to
>> the functions "pmin" and "pmax" by 1 - toupper(...) to get
>>
>> "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"
>>
>> Any ideas on how I could achieve that?
>>
>> Many thanks and best wishes,
>>
>> Alrik
>>
>>
>> ********************************
>> Alrik Thiem
>> Post-Doctoral Researcher
>>
>> Department of Philosophy
>> University of Geneva
>> Rue de Candolle 2
>> CH-1211 Geneva
>>
>> +41 76 527 80 83
>>
>> http://www.alrik-thiem.net
>> http://www.compasss.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From pdalgd at gmail.com  Sun Mar  1 10:55:46 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 1 Mar 2015 10:55:46 +0100
Subject: [R] Lubridate and NameSpace
In-Reply-To: <FDE907D9-DC96-469A-AA0B-D41ECE7C0A21@noaa.gov>
References: <81c14e41-059c-481c-83c6-98742e78851b@me.com>
	<FDE907D9-DC96-469A-AA0B-D41ECE7C0A21@noaa.gov>
Message-ID: <7E7AABDC-05B3-4B50-AE5A-EEE22DD794C2@gmail.com>


> On 01 Mar 2015, at 00:32 , Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> 
>> lubridate::%m+%

Actually trying it would have revealed

> lubridate::%m+%
Error: unexpected SPECIAL in "lubridate::%m+%"

Notice that this is a syntactical problem, not a semantic one; you cannot juxtapose two operators (:: and %m+%). Quoting is needed. Either of the following seems to work:

lubridate::"%m+%"
lubridate::`%m+%`

In the same vein, notice that the result of the above is not an operator unless assigned to something of the form %foo%. I.e.

lubridate::`%m+%`(a,b)
f <- lubridate::`%m+%`
f(a,b)
`%mym+%` <- f
a %mym+% b


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bogaso.christofer at gmail.com  Sun Mar  1 12:33:38 2015
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 1 Mar 2015 17:18:38 +0545
Subject: [R] Folder size
Message-ID: <CA+dpOJnNi4OxB9CXmNRC7Zaa2gF8G1e9VosDT6em5Pq3a==7ug@mail.gmail.com>

Hi again,

I am wondering if there is any way to extract the Folder size. For
example, I want to get information of size for all folders in my C:
drive.

It seems that the function file.info() only work for File, not on Folder.

Appreciate any pointer.

Thanks and regards,


From luca.cerone at gmail.com  Sun Mar  1 12:59:57 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Sun, 1 Mar 2015 12:59:57 +0100
Subject: [R] Folder size
In-Reply-To: <CA+dpOJnNi4OxB9CXmNRC7Zaa2gF8G1e9VosDT6em5Pq3a==7ug@mail.gmail.com>
References: <CA+dpOJnNi4OxB9CXmNRC7Zaa2gF8G1e9VosDT6em5Pq3a==7ug@mail.gmail.com>
Message-ID: <CAFnz2-9Lyp2GWAFWQQqLJMjdL7O2uqszMD0yziS8jV8RsHGNSg@mail.gmail.com>

Hi Christopher,

sum(file.info(list.files(".", all.files = TRUE, recursive = TRUE))$size)

should do the trick.

Cheers,
Luca

On Sun, Mar 1, 2015 at 12:33 PM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hi again,
>
> I am wondering if there is any way to extract the Folder size. For
> example, I want to get information of size for all folders in my C:
> drive.
>
> It seems that the function file.info() only work for File, not on Folder.
>
> Appreciate any pointer.
>
> Thanks and regards,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From luca.cerone at gmail.com  Sun Mar  1 13:02:05 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Sun, 1 Mar 2015 13:02:05 +0100
Subject: [R] Folder size
In-Reply-To: <CAFnz2-9Lyp2GWAFWQQqLJMjdL7O2uqszMD0yziS8jV8RsHGNSg@mail.gmail.com>
References: <CA+dpOJnNi4OxB9CXmNRC7Zaa2gF8G1e9VosDT6em5Pq3a==7ug@mail.gmail.com>
	<CAFnz2-9Lyp2GWAFWQQqLJMjdL7O2uqszMD0yziS8jV8RsHGNSg@mail.gmail.com>
Message-ID: <CAFnz2-8k7VV6+AGLmAxBMQgeMbV8L==8f0wcZcm25VKcUOvNHg@mail.gmail.com>

of course you can substitute "." with a path to your folder.. and you
might want to set fullnames = TRUE and maybe include.dirs = TRUE
in list.files

On Sun, Mar 1, 2015 at 12:59 PM, Luca Cerone <luca.cerone at gmail.com> wrote:
> Hi Christopher,
>
> sum(file.info(list.files(".", all.files = TRUE, recursive = TRUE))$size)
>
> should do the trick.
>
> Cheers,
> Luca
>
> On Sun, Mar 1, 2015 at 12:33 PM, Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
>> Hi again,
>>
>> I am wondering if there is any way to extract the Folder size. For
>> example, I want to get information of size for all folders in my C:
>> drive.
>>
>> It seems that the function file.info() only work for File, not on Folder.
>>
>> Appreciate any pointer.
>>
>> Thanks and regards,
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sun Mar  1 13:14:47 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 01 Mar 2015 07:14:47 -0500
Subject: [R] Firefox not showing R help.
In-Reply-To: <54F2528D.9080101@auckland.ac.nz>
References: <54F22EBC.1070400@auckland.ac.nz> <54F23A47.8070700@gmail.com>
	<54F2528D.9080101@auckland.ac.nz>
Message-ID: <54F302B7.2070307@gmail.com>

On 28/02/2015 6:43 PM, Rolf Turner wrote:
> 
> See inline below.
> 
> On 01/03/15 10:59, Duncan Murdoch wrote:
>> On 28/02/2015 4:10 PM, Rolf Turner wrote:
>>>
>>> Firefox recently updated itself on my laptop.  Now when I ask for R help
>>> --- e.g. ?plot --- I just get my home page. And no help. If I do "?plot"
>>> again after Firefox has opened its window, I just get yet another
>>> Firefox window, opened to my home page.  (I have my preferences set to
>>>
>>>       "When Firefox starts Show my homepage"
>>>
>>> --- as I always have had in the past.)
>>
>> I would guess that browseURL() won't work for any URL.  Is that right?
> 
> Yes.  That is correct. E.g. if I do
> 
>      browseURL("http://www.r-project.org/")
> 
> I get taken to my home page, rather than to the R home page.
> 
>>
>> What does getOption("browser") give you in R?
> 
> "/usr/bin/firefox"
> 
>> If it is just a character
>> string (e.g. "xdg-open" is what I get in Ubuntu), does it work from your
>> command line, outside of R, e.g. for me that test would be
>>
>> xdg-open http://www.r-project.org
> 
> I tried
> 
>     /usr/bin/firefox http://www.r-project.org/
> 
> from the Linux command line and was taken to the R home page, 
> seamlessly.  I also tried
> 
>      xdg-open http://www.r-project.org/
> 
> and that worked equally well.
> 
> Finally I tried
> 
>      options(browser="xdg-open")
> 
> and then
> 
>      ?plot
> 
> and BINGO!!! the HTML help came up as requested.
> 
> So I have a working solution to my problem.  But I *really* don't 
> understand why changing the browser from "/usr/bin/firefox" to 
> "xdg-open" made a difference.  (Since there appears to be no difference 
> at the Linux command line.)
> 
> Anyway; thanks very much for solving my problem.

I believe browseURL will quote the URL, i.e. it would execute

/usr/bin/firefox "http://www.r-project.org/"

Perhaps Firefox is confused by the quotes?  Doesn't seem likely...

Duncan Murdoch


> 
> cheers,
> 
> Rolf
> 
>>
>> If that doesn't work, but you can figure out a command line way to open
>> a particular URL, change getOption("browser") to use that.
>>
>> Duncan Murdoch
>>
>>>
>>> The Firefox that I am currently running is (according Firefox help
>>> --> "About Firefox") is version 36.0.
>>>
>>> Can anyone suggest to me how I can get my html R help back?
>>>
>>> For what it's worth:  I am using Linux, Fedora 17.  (Yes, I know it's
>>> elderly, but then so am I. :-) )
>>>
>>> Also in case it has any relevance:
>>>
>>>>> sessionInfo()
>>>> R version 3.1.2 (2014-10-31)
>>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>>
>>>> locale:
>>>>   [1] LC_CTYPE=en_NZ.utf8       LC_NUMERIC=C
>>>>   [3] LC_TIME=en_NZ.utf8        LC_COLLATE=en_NZ.utf8
>>>>   [5] LC_MONETARY=en_NZ.utf8    LC_MESSAGES=en_NZ.utf8
>>>>   [7] LC_PAPER=en_NZ.utf8       LC_NAME=C
>>>>   [9] LC_ADDRESS=C              LC_TELEPHONE=C
>>>> [11] LC_MEASUREMENT=en_NZ.utf8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> other attached packages:
>>>> [1] spatstat_1.40-0.064 misc_0.0-16
>>>>
>>>> loaded via a namespace (and not attached):
>>>>   [1] abind_1.4-0     deldir_0.1-7    goftest_1.0-2   grid_3.1.2
>>>>   [5] lattice_0.20-29 Matrix_1.1-4    mgcv_1.8-3      nlme_3.1-118
>>>>   [9] polyclip_1.3-1  tensor_1.5      tools_3.1.2
> 
>


From pdalgd at gmail.com  Sun Mar  1 14:05:07 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 1 Mar 2015 14:05:07 +0100
Subject: [R] Why does R replace all row values with NAs
In-Reply-To: <54F086EA.7020800@gmail.com>
References: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>
	<54F07B99.90005@gmail.com>
	<CAN2xGJYmhkJmndSBVBL3WD+hEBFVKLhUGDDX_oi2WOQt+uDTiQ@mail.gmail.com>
	<54F086EA.7020800@gmail.com>
Message-ID: <16178441-C208-4B5A-907B-86CCBD454820@gmail.com>


> On 27 Feb 2015, at 16:02 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> Yes.  Indexing with a logical NA is probably a mistake, and this is one
> way to signal it without actually triggering a warning or error.

There are cases where it isn't (usually) a mistake, e.g. pch=c(25,24)[sex], where it is quite crucial that the result has the same length as the index (i.e., sex) and where it makes good sense to use an NA plotting character if sex is unknown.

For logical index, it is harder to come up with a good excuse for the NA behaviour, except that R's NA is by default logical so there would be trouble explaining differences between c(x[NA], x[1]) and x[c(NA, 1)].

(The annoyance of getting a data frame half-full of NA was the reason that subset() was written so that it removes rows corresponding to NA indices).

-pd 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From samrobertsmith at gmail.com  Sun Mar  1 15:41:10 2015
From: samrobertsmith at gmail.com (linda.s)
Date: Sun, 1 Mar 2015 09:41:10 -0500
Subject: [R] R and Python
Message-ID: <CA+hgA4awRmE7=M4yt8rMuB7G_TkfSQd0eky5zYAmtL6C+pd-Ww@mail.gmail.com>

Is there any good example codes of integrating R and Python?
Thanks.
Linda

	[[alternative HTML version deleted]]


From samrobertsmith at gmail.com  Sun Mar  1 15:50:04 2015
From: samrobertsmith at gmail.com (linda.s)
Date: Sun, 1 Mar 2015 09:50:04 -0500
Subject: [R] figure resolution
Message-ID: <CA+hgA4YZfF+QA72g5L4SJh2W6E_2wD8KTbk8A2J_RzKaf25xzw@mail.gmail.com>

when using R for exporting figures to folder, how to improve the figure
resolution?
Thanks.
Linda

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Mar  1 16:11:35 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 01 Mar 2015 07:11:35 -0800
Subject: [R] figure resolution
In-Reply-To: <CA+hgA4YZfF+QA72g5L4SJh2W6E_2wD8KTbk8A2J_RzKaf25xzw@mail.gmail.com>
References: <CA+hgA4YZfF+QA72g5L4SJh2W6E_2wD8KTbk8A2J_RzKaf25xzw@mail.gmail.com>
Message-ID: <6C7FB745-E20D-4F49-A7B3-227D9FAF0984@dcn.davis.CA.us>

Read documentation?

There is even documentation for how to ask questions about R [1] [2], since questions like this one fail to explain what you are actually doing. Asking a clear question allows someone to offer answers specific enough to your problem to seem more helpful than the above above.

Protip: HTML email gets messed up in the conversion to plain text that happens on this list. When providing example code for your problem, this can change what we see to be different than what you "wrote". Set your email program to send out plain text next time.

[1] http://www.R-project.org/posting-guide.html
[2] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 1, 2015 6:50:04 AM PST, "linda.s" <samrobertsmith at gmail.com> wrote:
>when using R for exporting figures to folder, how to improve the figure
>resolution?
>Thanks.
>Linda
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Sun Mar  1 16:13:16 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 1 Mar 2015 10:13:16 -0500
Subject: [R] Firefox not showing R help.
In-Reply-To: <54F302B7.2070307@gmail.com>
References: <54F22EBC.1070400@auckland.ac.nz> <54F23A47.8070700@gmail.com>
	<54F2528D.9080101@auckland.ac.nz> <54F302B7.2070307@gmail.com>
Message-ID: <CA+vqiLGNacx7bGW4ubHv4hNeCDCREjVZCNhis1McEU0Zyaui7w@mail.gmail.com>

I think this might be due to the removal of the -remote option in
firefox. Some discussion and details are available at
https://lists.gnu.org/archive/html/emacs-orgmode/2015-02/msg00946.html

Best,
Ista

On Sun, Mar 1, 2015 at 7:14 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 28/02/2015 6:43 PM, Rolf Turner wrote:
>>
>> See inline below.
>>
>> On 01/03/15 10:59, Duncan Murdoch wrote:
>>> On 28/02/2015 4:10 PM, Rolf Turner wrote:
>>>>
>>>> Firefox recently updated itself on my laptop.  Now when I ask for R help
>>>> --- e.g. ?plot --- I just get my home page. And no help. If I do "?plot"
>>>> again after Firefox has opened its window, I just get yet another
>>>> Firefox window, opened to my home page.  (I have my preferences set to
>>>>
>>>>       "When Firefox starts Show my homepage"
>>>>
>>>> --- as I always have had in the past.)
>>>
>>> I would guess that browseURL() won't work for any URL.  Is that right?
>>
>> Yes.  That is correct. E.g. if I do
>>
>>      browseURL("http://www.r-project.org/")
>>
>> I get taken to my home page, rather than to the R home page.
>>
>>>
>>> What does getOption("browser") give you in R?
>>
>> "/usr/bin/firefox"
>>
>>> If it is just a character
>>> string (e.g. "xdg-open" is what I get in Ubuntu), does it work from your
>>> command line, outside of R, e.g. for me that test would be
>>>
>>> xdg-open http://www.r-project.org
>>
>> I tried
>>
>>     /usr/bin/firefox http://www.r-project.org/
>>
>> from the Linux command line and was taken to the R home page,
>> seamlessly.  I also tried
>>
>>      xdg-open http://www.r-project.org/
>>
>> and that worked equally well.
>>
>> Finally I tried
>>
>>      options(browser="xdg-open")
>>
>> and then
>>
>>      ?plot
>>
>> and BINGO!!! the HTML help came up as requested.
>>
>> So I have a working solution to my problem.  But I *really* don't
>> understand why changing the browser from "/usr/bin/firefox" to
>> "xdg-open" made a difference.  (Since there appears to be no difference
>> at the Linux command line.)
>>
>> Anyway; thanks very much for solving my problem.
>
> I believe browseURL will quote the URL, i.e. it would execute
>
> /usr/bin/firefox "http://www.r-project.org/"
>
> Perhaps Firefox is confused by the quotes?  Doesn't seem likely...
>
> Duncan Murdoch
>
>
>>
>> cheers,
>>
>> Rolf
>>
>>>
>>> If that doesn't work, but you can figure out a command line way to open
>>> a particular URL, change getOption("browser") to use that.
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> The Firefox that I am currently running is (according Firefox help
>>>> --> "About Firefox") is version 36.0.
>>>>
>>>> Can anyone suggest to me how I can get my html R help back?
>>>>
>>>> For what it's worth:  I am using Linux, Fedora 17.  (Yes, I know it's
>>>> elderly, but then so am I. :-) )
>>>>
>>>> Also in case it has any relevance:
>>>>
>>>>>> sessionInfo()
>>>>> R version 3.1.2 (2014-10-31)
>>>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>>>
>>>>> locale:
>>>>>   [1] LC_CTYPE=en_NZ.utf8       LC_NUMERIC=C
>>>>>   [3] LC_TIME=en_NZ.utf8        LC_COLLATE=en_NZ.utf8
>>>>>   [5] LC_MONETARY=en_NZ.utf8    LC_MESSAGES=en_NZ.utf8
>>>>>   [7] LC_PAPER=en_NZ.utf8       LC_NAME=C
>>>>>   [9] LC_ADDRESS=C              LC_TELEPHONE=C
>>>>> [11] LC_MEASUREMENT=en_NZ.utf8 LC_IDENTIFICATION=C
>>>>>
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>
>>>>> other attached packages:
>>>>> [1] spatstat_1.40-0.064 misc_0.0-16
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>>   [1] abind_1.4-0     deldir_0.1-7    goftest_1.0-2   grid_3.1.2
>>>>>   [5] lattice_0.20-29 Matrix_1.1-4    mgcv_1.8-3      nlme_3.1-118
>>>>>   [9] polyclip_1.3-1  tensor_1.5      tools_3.1.2
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Sun Mar  1 16:17:01 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 1 Mar 2015 10:17:01 -0500
Subject: [R] R and Python
In-Reply-To: <CA+hgA4awRmE7=M4yt8rMuB7G_TkfSQd0eky5zYAmtL6C+pd-Ww@mail.gmail.com>
References: <CA+hgA4awRmE7=M4yt8rMuB7G_TkfSQd0eky5zYAmtL6C+pd-Ww@mail.gmail.com>
Message-ID: <CAM_vjuk+9ar7tnuCK87Fxz6pcQZV__-ZE46d3Tepm1JHOyrRtg@mail.gmail.com>

You mean like rPython? Or rpy? Or rpy2?

Googling R Python is a great place to start.

Sarah

On Sun, Mar 1, 2015 at 9:41 AM, linda.s <samrobertsmith at gmail.com> wrote:
> Is there any good example codes of integrating R and Python?
> Thanks.
> Linda
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From murdoch.duncan at gmail.com  Sun Mar  1 18:21:02 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 01 Mar 2015 12:21:02 -0500
Subject: [R] Firefox not showing R help.
In-Reply-To: <CA+vqiLGNacx7bGW4ubHv4hNeCDCREjVZCNhis1McEU0Zyaui7w@mail.gmail.com>
References: <54F22EBC.1070400@auckland.ac.nz> <54F23A47.8070700@gmail.com>
	<54F2528D.9080101@auckland.ac.nz> <54F302B7.2070307@gmail.com>
	<CA+vqiLGNacx7bGW4ubHv4hNeCDCREjVZCNhis1McEU0Zyaui7w@mail.gmail.com>
Message-ID: <54F34A7E.8080008@gmail.com>

On 01/03/2015 10:13 AM, Ista Zahn wrote:
> I think this might be due to the removal of the -remote option in
> firefox. Some discussion and details are available at
> https://lists.gnu.org/archive/html/emacs-orgmode/2015-02/msg00946.html

Yes, that's it.  R uses -remote if isLocal is TRUE; I had thought it
wasn't.

The -remote arg is also used for mozilla and opera; is it needed there?

Duncan Murdoch

> 
> Best,
> Ista
> 
> On Sun, Mar 1, 2015 at 7:14 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 28/02/2015 6:43 PM, Rolf Turner wrote:
>>>
>>> See inline below.
>>>
>>> On 01/03/15 10:59, Duncan Murdoch wrote:
>>>> On 28/02/2015 4:10 PM, Rolf Turner wrote:
>>>>>
>>>>> Firefox recently updated itself on my laptop.  Now when I ask for R help
>>>>> --- e.g. ?plot --- I just get my home page. And no help. If I do "?plot"
>>>>> again after Firefox has opened its window, I just get yet another
>>>>> Firefox window, opened to my home page.  (I have my preferences set to
>>>>>
>>>>>       "When Firefox starts Show my homepage"
>>>>>
>>>>> --- as I always have had in the past.)
>>>>
>>>> I would guess that browseURL() won't work for any URL.  Is that right?
>>>
>>> Yes.  That is correct. E.g. if I do
>>>
>>>      browseURL("http://www.r-project.org/")
>>>
>>> I get taken to my home page, rather than to the R home page.
>>>
>>>>
>>>> What does getOption("browser") give you in R?
>>>
>>> "/usr/bin/firefox"
>>>
>>>> If it is just a character
>>>> string (e.g. "xdg-open" is what I get in Ubuntu), does it work from your
>>>> command line, outside of R, e.g. for me that test would be
>>>>
>>>> xdg-open http://www.r-project.org
>>>
>>> I tried
>>>
>>>     /usr/bin/firefox http://www.r-project.org/
>>>
>>> from the Linux command line and was taken to the R home page,
>>> seamlessly.  I also tried
>>>
>>>      xdg-open http://www.r-project.org/
>>>
>>> and that worked equally well.
>>>
>>> Finally I tried
>>>
>>>      options(browser="xdg-open")
>>>
>>> and then
>>>
>>>      ?plot
>>>
>>> and BINGO!!! the HTML help came up as requested.
>>>
>>> So I have a working solution to my problem.  But I *really* don't
>>> understand why changing the browser from "/usr/bin/firefox" to
>>> "xdg-open" made a difference.  (Since there appears to be no difference
>>> at the Linux command line.)
>>>
>>> Anyway; thanks very much for solving my problem.
>>
>> I believe browseURL will quote the URL, i.e. it would execute
>>
>> /usr/bin/firefox "http://www.r-project.org/"
>>
>> Perhaps Firefox is confused by the quotes?  Doesn't seem likely...
>>
>> Duncan Murdoch
>>
>>
>>>
>>> cheers,
>>>
>>> Rolf
>>>
>>>>
>>>> If that doesn't work, but you can figure out a command line way to open
>>>> a particular URL, change getOption("browser") to use that.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>>
>>>>> The Firefox that I am currently running is (according Firefox help
>>>>> --> "About Firefox") is version 36.0.
>>>>>
>>>>> Can anyone suggest to me how I can get my html R help back?
>>>>>
>>>>> For what it's worth:  I am using Linux, Fedora 17.  (Yes, I know it's
>>>>> elderly, but then so am I. :-) )
>>>>>
>>>>> Also in case it has any relevance:
>>>>>
>>>>>>> sessionInfo()
>>>>>> R version 3.1.2 (2014-10-31)
>>>>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>>>>
>>>>>> locale:
>>>>>>   [1] LC_CTYPE=en_NZ.utf8       LC_NUMERIC=C
>>>>>>   [3] LC_TIME=en_NZ.utf8        LC_COLLATE=en_NZ.utf8
>>>>>>   [5] LC_MONETARY=en_NZ.utf8    LC_MESSAGES=en_NZ.utf8
>>>>>>   [7] LC_PAPER=en_NZ.utf8       LC_NAME=C
>>>>>>   [9] LC_ADDRESS=C              LC_TELEPHONE=C
>>>>>> [11] LC_MEASUREMENT=en_NZ.utf8 LC_IDENTIFICATION=C
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>>
>>>>>> other attached packages:
>>>>>> [1] spatstat_1.40-0.064 misc_0.0-16
>>>>>>
>>>>>> loaded via a namespace (and not attached):
>>>>>>   [1] abind_1.4-0     deldir_0.1-7    goftest_1.0-2   grid_3.1.2
>>>>>>   [5] lattice_0.20-29 Matrix_1.1-4    mgcv_1.8-3      nlme_3.1-118
>>>>>>   [9] polyclip_1.3-1  tensor_1.5      tools_3.1.2
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From christian at echoffmann.ch  Sun Mar  1 15:50:11 2015
From: christian at echoffmann.ch (Christian Hoffmann)
Date: Sun, 01 Mar 2015 15:50:11 +0100
Subject: [R] R CMD wants (unnecessary) packages ?
Message-ID: <54F32723.2020607@echoffmann.ch>

When executing  R CMD check etc. on a package, 00install.out tells me

Warning in file.copy(file.path(.Library, pkg, "DESCRIPTION"), pd) :
   problem copying 
/Library/Frameworks/R.framework/Resources/library/MASS/DESCRIPTION to 
/var/....

although I do not use MASS ( and all the other recently uninstalled 
packages).

Any help ?
TIA

-- 
Christian W. Hoffmann
CH - 8915 Hausen am Albis, Schweiz
Rigiblickstrasse 15 b, Tel.+41-44-7640853
mailto: christian at echoffmann.ch
home: www.echoffmann.ch


From javad.zendedel at birjand.ac.ir  Sun Mar  1 17:43:15 2015
From: javad.zendedel at birjand.ac.ir (javad.zendedel at birjand.ac.ir)
Date: Sun, 1 Mar 2015 20:13:15 +0330
Subject: [R] R help
Message-ID: <1425228195662010300@birjand.ac.ir>

?How can i plot the  "scaled TTT-transform" with R? And how can i plot " Empirical Hazard function plot" ? Thank you in advance
	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Sun Mar  1 18:35:40 2015
From: rhelpmaillist at 163.com (PO SU)
Date: Mon, 2 Mar 2015 01:35:40 +0800 (CST)
Subject: [R] RWebdriver and RSelenium returns the same error while trying to
 connect the java server
Message-ID: <3c7295b7.8d5f.14bd668636b.Coremail.rhelpmaillist@163.com>



Dear expeRts,
? ?when i using?RWebdriver and RSelenium ,?



> require(RSelenium)
Loading required package: RSelenium
> remDr <- remoteDriver(remoteServerAddr = "localhost"?
+ ? ? ? ? ? ? ? ? ? ? ? , port = 4444
+ ? ? ? ? ? ? ? ? ? ? ? , browserName = "firefox"
+ )
> remDr$open()
[1] "Connecting to remote server"



Error: 	 Summary: UnknownError
?	 Detail: An unknown server-side error occurred while processing the command.
?	 class: org.openqa.selenium.firefox.NotConnectedException


from the cmd lines, it show "unable to connect 127.0.0.1 7055 after 45000ms "


i don't know why, is there anybody who happens to know it ?
--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From javad.zendedel at gmail.com  Sun Mar  1 18:31:04 2015
From: javad.zendedel at gmail.com (Javad Zendedel)
Date: Sun, 1 Mar 2015 21:01:04 +0330
Subject: [R] (no subject)
Message-ID: <CAMYmiVgYwr-sEB8za4CaDEf9bCwWf+hzxMnjy2XK5mrU=j45=w@mail.gmail.com>

How can i plot the  "scaled TTT-transform" with R? And how can i plot "
Empirical Hazard function plot" ? Thank you in advance

-- 

yours sincerely

J.Zendedel

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Sun Mar  1 19:39:46 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Sun, 1 Mar 2015 18:39:46 +0000
Subject: [R] figure resolution
In-Reply-To: <CA+hgA4YZfF+QA72g5L4SJh2W6E_2wD8KTbk8A2J_RzKaf25xzw@mail.gmail.com>
References: <CA+hgA4YZfF+QA72g5L4SJh2W6E_2wD8KTbk8A2J_RzKaf25xzw@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED66042D9F0D@GOLD.corp.lgc-group.com>

See ?tiff, ?png etc and look for 'res'

S Ellison
________________________________________
From: R-help [r-help-bounces at r-project.org] On Behalf Of linda.s [samrobertsmith at gmail.com]
Sent: 01 March 2015 14:50
To: r-help
Subject: [R] figure resolution

when using R for exporting figures to folder, how to improve the figure
resolution?
Thanks.
Linda

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From gunter.berton at gene.com  Sun Mar  1 19:48:39 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 1 Mar 2015 10:48:39 -0800
Subject: [R] (no subject)
In-Reply-To: <CAMYmiVgYwr-sEB8za4CaDEf9bCwWf+hzxMnjy2XK5mrU=j45=w@mail.gmail.com>
References: <CAMYmiVgYwr-sEB8za4CaDEf9bCwWf+hzxMnjy2XK5mrU=j45=w@mail.gmail.com>
Message-ID: <CACk-te3f_ZOgh90UQ_TyU0ZHPCv8U7dhYMJCdZhhyDTH-KWBog@mail.gmail.com>

1. Do not multiple post -- it's rude.

2. Use plain text emails, not HTML
 (although it makes no difference here).

3. Homework? -- This list has a no homework policy.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Mar 1, 2015 at 9:31 AM, Javad Zendedel <javad.zendedel at gmail.com> wrote:
> How can i plot the  "scaled TTT-transform" with R? And how can i plot "
> Empirical Hazard function plot" ? Thank you in advance
>
> --
>
> yours sincerely
>
> J.Zendedel
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sun Mar  1 19:54:48 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 1 Mar 2015 10:54:48 -0800
Subject: [R] R CMD wants (unnecessary) packages ?
In-Reply-To: <54F32723.2020607@echoffmann.ch>
References: <54F32723.2020607@echoffmann.ch>
Message-ID: <CACk-te2zBuSGVB3TDNDov7ATnnB5fhRDPhD+pei53C2K5n96dw@mail.gmail.com>

1. In future, for Mac issues you are more likely to get a helpful
reply on the R-sig-mac list.

2. This is a warning only, not an error. You seem to indicate MASS was
uninstalled (???), so I would guess that it wasn't there when it
looked for it -- ergo the warning. My question: why uninstall these
core packages, as they may be necessary for key functionality that you
use, directly or indirectly.

And apologies if I have misinterpreted...

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Mar 1, 2015 at 6:50 AM, Christian Hoffmann
<christian at echoffmann.ch> wrote:
> When executing  R CMD check etc. on a package, 00install.out tells me
>
> Warning in file.copy(file.path(.Library, pkg, "DESCRIPTION"), pd) :
>   problem copying
> /Library/Frameworks/R.framework/Resources/library/MASS/DESCRIPTION to
> /var/....
>
> although I do not use MASS ( and all the other recently uninstalled
> packages).
>
> Any help ?
> TIA
>
> --
> Christian W. Hoffmann
> CH - 8915 Hausen am Albis, Schweiz
> Rigiblickstrasse 15 b, Tel.+41-44-7640853
> mailto: christian at echoffmann.ch
> home: www.echoffmann.ch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Sun Mar  1 20:09:18 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 1 Mar 2015 14:09:18 -0500
Subject: [R] R CMD wants (unnecessary) packages ?
In-Reply-To: <54F32723.2020607@echoffmann.ch>
References: <54F32723.2020607@echoffmann.ch>
Message-ID: <CAM_vjunnYTJmHDY+ODm9oXMLja3wWar8iNrKiNhnDvUv-vS4Ow@mail.gmail.com>

I would be very careful about removing the packages that are installed
by default with R,

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Which-add_002don-packages-exist-for-R_003f

either the base packages listed in that FAQ or the recommended ones in
the list right below it.

Removing those packages can cause all sorts of unexpected problems,
since they are installed automatically and assumed to be present.

I'm not even sure how you know that you don't use them: have you
checked the requirements of all the packages that you do use?

Sarah

On Sun, Mar 1, 2015 at 9:50 AM, Christian Hoffmann
<christian at echoffmann.ch> wrote:
> When executing  R CMD check etc. on a package, 00install.out tells me
>
> Warning in file.copy(file.path(.Library, pkg, "DESCRIPTION"), pd) :
>   problem copying
> /Library/Frameworks/R.framework/Resources/library/MASS/DESCRIPTION to
> /var/....
>
> although I do not use MASS ( and all the other recently uninstalled
> packages).
>
> Any help ?
> TIA
>
> --
> Christian W. Hoffmann
> CH - 8915 Hausen am Albis, Schweiz
> Rigiblickstrasse 15 b, Tel.+41-44-7640853
> mailto: christian at echoffmann.ch
> home: www.echoffmann.ch
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From istazahn at gmail.com  Sun Mar  1 21:09:26 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 1 Mar 2015 15:09:26 -0500
Subject: [R] RWebdriver and RSelenium returns the same error while
 trying to connect the java server
In-Reply-To: <3c7295b7.8d5f.14bd668636b.Coremail.rhelpmaillist@163.com>
References: <3c7295b7.8d5f.14bd668636b.Coremail.rhelpmaillist@163.com>
Message-ID: <CA+vqiLEnxHr_8inU1wOaNo1nPYp+1ujmEgRN8t-hdSmQKsDbZA@mail.gmail.com>

Do you have a server running? Can you connect to localhost directly
from a browser?

Best,
Ista

On Sun, Mar 1, 2015 at 12:35 PM, PO SU <rhelpmaillist at 163.com> wrote:
>
>
> Dear expeRts,
>    when i using RWebdriver and RSelenium ,
>
>
>
>> require(RSelenium)
> Loading required package: RSelenium
>> remDr <- remoteDriver(remoteServerAddr = "localhost"
> +                       , port = 4444
> +                       , browserName = "firefox"
> + )
>> remDr$open()
> [1] "Connecting to remote server"
>
>
>
> Error:   Summary: UnknownError
>          Detail: An unknown server-side error occurred while processing the command.
>          class: org.openqa.selenium.firefox.NotConnectedException
>
>
> from the cmd lines, it show "unable to connect 127.0.0.1 7055 after 45000ms "
>
>
> i don't know why, is there anybody who happens to know it ?
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cflynch at ncsu.edu  Sun Mar  1 22:01:56 2015
From: cflynch at ncsu.edu (Collin Lynch)
Date: Sun, 1 Mar 2015 16:01:56 -0500
Subject: [R] R and Python
In-Reply-To: <CAM_vjuk+9ar7tnuCK87Fxz6pcQZV__-ZE46d3Tepm1JHOyrRtg@mail.gmail.com>
References: <CA+hgA4awRmE7=M4yt8rMuB7G_TkfSQd0eky5zYAmtL6C+pd-Ww@mail.gmail.com>
	<CAM_vjuk+9ar7tnuCK87Fxz6pcQZV__-ZE46d3Tepm1JHOyrRtg@mail.gmail.com>
Message-ID: <CAE=6FXb=okejO8hrbOE-W=C9XK4zZ+ed4miUXGoyRS8s64fJtg@mail.gmail.com>

I recommend rpy2.  http://rpy.sourceforge.net/rpy2.html

It provides direct access to a running R instance with full support for R
functions including package loading.  It has some minor issues with
graphics drivers making it best for programmatic and not interactive use
but it is excellent for munging data in python and then passing it off to R
for calculations.

    Collin.

On Sun, Mar 1, 2015 at 10:17 AM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> You mean like rPython? Or rpy? Or rpy2?
>
> Googling R Python is a great place to start.
>
> Sarah
>
> On Sun, Mar 1, 2015 at 9:41 AM, linda.s <samrobertsmith at gmail.com> wrote:
> > Is there any good example codes of integrating R and Python?
> > Thanks.
> > Linda
> >
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From liuwensui at gmail.com  Sun Mar  1 22:08:03 2015
From: liuwensui at gmail.com (Wensui Liu)
Date: Sun, 1 Mar 2015 15:08:03 -0600
Subject: [R] R and Python
In-Reply-To: <CA+hgA4awRmE7=M4yt8rMuB7G_TkfSQd0eky5zYAmtL6C+pd-Ww@mail.gmail.com>
References: <CA+hgA4awRmE7=M4yt8rMuB7G_TkfSQd0eky5zYAmtL6C+pd-Ww@mail.gmail.com>
Message-ID: <CAKyN3iC+=sjK+FJWJXyqks0rnvJqpzPSSoNEdk=Joez965YHWA@mail.gmail.com>

depending on what you want.
if you'd like to run r within python, there are 2 solutions as far as i've
known, either by rpys or by pyper.
here is a brief comparison i did before
https://statcompute.wordpress.com/2012/12/10/a-brief-comparison-between-rpy2-and-pyper/


On Sun, Mar 1, 2015 at 8:41 AM, linda.s <samrobertsmith at gmail.com> wrote:

> Is there any good example codes of integrating R and Python?
> Thanks.
> Linda
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
==============================
WenSui Liu
Credit Risk Manager, 53 Bancorp
wensui.liu at 53.com
513-295-4370
==============================

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sun Mar  1 22:13:23 2015
From: jholtman at gmail.com (jim holtman)
Date: Sun, 1 Mar 2015 16:13:23 -0500
Subject: [R] Using a text file as a removeWord dictionary in tm_map
In-Reply-To: <54F1C6BD.5000401@gmail.com>
References: <54F1C6BD.5000401@gmail.com>
Message-ID: <CAAxdm-5zK167OtGg7ZE_zOr-V-7EM-Ys2hE5mMDeTd2CxHCrug@mail.gmail.com>

The 'read.table' was creating a data.frame (not a vector) and applying
'c' to it converted it to a list.  You should alway look at the object
you are creating.  You probably want to use 'scan'.

======================
> testFile <- "Although,this,query,applies,specifically,to,the,tm,package"
> # read in with read.table create a data.frame
> df_words <- read.table(text = testFile, sep = ',')
> df_words  # not a vector
        V1   V2    V3      V4           V5 V6  V7 V8      V9
1 Although this query applies specifically to the tm package
> c(df_words)  # this results in a list
$V1
[1] Although
Levels: Although
$V2
[1] this
Levels: this
$V3
[1] query
Levels: query
$V4
[1] applies
Levels: applies
$V5
[1] specifically
Levels: specifically
$V6
[1] to
Levels: to
$V7
[1] the
Levels: the
$V8
[1] tm
Levels: tm
$V9
[1] package
Levels: package
>
> # now read with 'scan'
> scan_words <- scan(text = testFile, what = '', sep = ',')
Read 9 items
> scan_words
[1] "Although"     "this"         "query"        "applies"
"specifically" "to"
[7] "the"          "tm"           "package"
>
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sat, Feb 28, 2015 at 8:46 AM, Sun Shine <phaedrusv at gmail.com> wrote:
> Hi list
>
> Although this query applies specifically to the tm package, perhaps it's
> something that others might be able to lend a thought to.
>
> Using tm to do some initial text mining, I want to include an external (to
> R) generated dictionary of words that I want removed from the corpus.
>
> I have created a comma separated list of terms in " " marks in a
> stopList.txt plain UTF-8 file. I want to read this into R, so do:
>
>> stopDict <- read.table('~/path/to/file/stopList.txt', sep=',')
>
> When I want to load it as part of the removeWords function in tm, I do:
>
>> docs <- tm_map(docs, removeWords, stopDict)
>
> which has no effect. Neither does:
>
>> docs <- tm_map(docs, removeWords, c(stopDict))
>
> What am I not seeing/ doing?
>
> How do I pass a text file with pre-defined terms to the removeWords
> transform of tm?
>
> Thanks for any ideas.
>
> Cheers
>
> Sun
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marius.hofert at uwaterloo.ca  Mon Mar  2 02:58:03 2015
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Sun, 1 Mar 2015 20:58:03 -0500
Subject: [R] How to convert a C vector to an SEXP for using it in
	R_orderVector()?
Message-ID: <CAM3-KjaxxSsCWc+2FOeY3-noVSj7Lou6xhpE3XCxPVO1XYrY=g@mail.gmail.com>

Hi,

Inside a C function (foo()), I need to call R's order(). Writing R
Extensions (2014, Section 6.10) gave me the hint to use
R_orderVector() for this task. The third argument of this function
needs an SEXP containing (in my case) the vector x (of which I would
like to determine order()).

My question is: How can I convert the given C vector to an SEXP
acceptable by R_orderVector() [or, if there is an even more efficient
way to call a sort of order() from within C?]?

Here is how my setup roughly looks like: x and y are numeric(n) (but C
vectors obviously). The function should sort x oppositely to y. In R I
can simply do sort(x)[rev(rank(y))] (I wish everything was as easy as
in R...). The problem is: This function is called a million times and
a profiling revealed that 98% of the time is spend there... that's why
I'm looking for a C version (and also to see who much faster the C
version is *and* also to finally go to the dark side and learn a bit
of C again). Here is what my C code looks like so far:

double *foo(double *x, double *y, int n) {
    int *indx = malloc(n * sizeof(int)); /* R's order(); will contain
the order (permutation of 0:(n-1)) */
    R_orderVector(indx, n, Rf_lang1(*x), /* convert x to SEXP: HOW? */
                  TRUE, /* nalast (use same default as order()) */
                  TRUE); /* decreasing */
    /* => indx == rev(rank(y)) */
    R_rsort(x, n); /* R's sort(x) for real x */
    double *res = malloc(n * sizeof(double));
    for(int i=0; i<n; i++) res[i] = x[indx[i]];
    return res;
}

What I get is:
error: incompatible type for argument 1 of ?Rf_lang1?

It's been a while since I programmed in C... the above function should
(run time wise) be efficient. If you see any room for improvement, I'd
be more than happy to hear about it.

Thanks & cheers,
Marius


From phaedrusv at gmail.com  Mon Mar  2 08:36:50 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Mon, 02 Mar 2015 07:36:50 +0000
Subject: [R] Using a text file as a removeWord dictionary in tm_map
In-Reply-To: <CAAxdm-5zK167OtGg7ZE_zOr-V-7EM-Ys2hE5mMDeTd2CxHCrug@mail.gmail.com>
References: <54F1C6BD.5000401@gmail.com>
	<CAAxdm-5zK167OtGg7ZE_zOr-V-7EM-Ys2hE5mMDeTd2CxHCrug@mail.gmail.com>
Message-ID: <54F41312.6000707@gmail.com>

Thanks Jim.

I thought that I was passing a vector, not realising I had converted 
this to a list object.

I haven't come across the scan() function so far, so this is good to know.

Good explanation - I'll give this a go when I can get back to that piece 
of work later today.

Thanks again.

Regards,

Sun


On 01/03/15 21:13, jim holtman wrote:
> The 'read.table' was creating a data.frame (not a vector) and applying
> 'c' to it converted it to a list.  You should alway look at the object
> you are creating.  You probably want to use 'scan'.
>
> ======================
>> testFile <- "Although,this,query,applies,specifically,to,the,tm,package"
>> # read in with read.table create a data.frame
>> df_words <- read.table(text = testFile, sep = ',')
>> df_words  # not a vector
>          V1   V2    V3      V4           V5 V6  V7 V8      V9
> 1 Although this query applies specifically to the tm package
>> c(df_words)  # this results in a list
> $V1
> [1] Although
> Levels: Although
> $V2
> [1] this
> Levels: this
> $V3
> [1] query
> Levels: query
> $V4
> [1] applies
> Levels: applies
> $V5
> [1] specifically
> Levels: specifically
> $V6
> [1] to
> Levels: to
> $V7
> [1] the
> Levels: the
> $V8
> [1] tm
> Levels: tm
> $V9
> [1] package
> Levels: package
>> # now read with 'scan'
>> scan_words <- scan(text = testFile, what = '', sep = ',')
> Read 9 items
>> scan_words
> [1] "Although"     "this"         "query"        "applies"
> "specifically" "to"
> [7] "the"          "tm"           "package"
>>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Sat, Feb 28, 2015 at 8:46 AM, Sun Shine <phaedrusv at gmail.com> wrote:
>> Hi list
>>
>> Although this query applies specifically to the tm package, perhaps it's
>> something that others might be able to lend a thought to.
>>
>> Using tm to do some initial text mining, I want to include an external (to
>> R) generated dictionary of words that I want removed from the corpus.
>>
>> I have created a comma separated list of terms in " " marks in a
>> stopList.txt plain UTF-8 file. I want to read this into R, so do:
>>
>>> stopDict <- read.table('~/path/to/file/stopList.txt', sep=',')
>> When I want to load it as part of the removeWords function in tm, I do:
>>
>>> docs <- tm_map(docs, removeWords, stopDict)
>> which has no effect. Neither does:
>>
>>> docs <- tm_map(docs, removeWords, c(stopDict))
>> What am I not seeing/ doing?
>>
>> How do I pass a text file with pre-defined terms to the removeWords
>> transform of tm?
>>
>> Thanks for any ideas.
>>
>> Cheers
>>
>> Sun
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Mon Mar  2 09:18:30 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 02 Mar 2015 08:18:30 +0000
Subject: [R] Firefox not showing R help.
In-Reply-To: <54F34A7E.8080008@gmail.com>
References: <54F22EBC.1070400@auckland.ac.nz>
	<54F23A47.8070700@gmail.com>	<54F2528D.9080101@auckland.ac.nz>
	<54F302B7.2070307@gmail.com>	<CA+vqiLGNacx7bGW4ubHv4hNeCDCREjVZCNhis1McEU0Zyaui7w@mail.gmail.com>
	<54F34A7E.8080008@gmail.com>
Message-ID: <54F41CD6.8040707@stats.ox.ac.uk>

On 01/03/2015 17:21, Duncan Murdoch wrote:
> On 01/03/2015 10:13 AM, Ista Zahn wrote:
>> I think this might be due to the removal of the -remote option in
>> firefox. Some discussion and details are available at
>> https://lists.gnu.org/archive/html/emacs-orgmode/2015-02/msg00946.html
>
> Yes, that's it.  R uses -remote if isLocal is TRUE; I had thought it
> wasn't.
>
> The -remote arg is also used for mozilla and opera; is it needed there?

R 3.1.3RC has been updated to work with Firefox 36.0.

>
> Duncan Murdoch
>
>>
>> Best,
>> Ista
>>
>> On Sun, Mar 1, 2015 at 7:14 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>> On 28/02/2015 6:43 PM, Rolf Turner wrote:
>>>>
>>>> See inline below.
>>>>
>>>> On 01/03/15 10:59, Duncan Murdoch wrote:
>>>>> On 28/02/2015 4:10 PM, Rolf Turner wrote:
>>>>>>
>>>>>> Firefox recently updated itself on my laptop.  Now when I ask for R help
>>>>>> --- e.g. ?plot --- I just get my home page. And no help. If I do "?plot"
>>>>>> again after Firefox has opened its window, I just get yet another
>>>>>> Firefox window, opened to my home page.  (I have my preferences set to
>>>>>>
>>>>>>        "When Firefox starts Show my homepage"
>>>>>>
>>>>>> --- as I always have had in the past.)
>>>>>
>>>>> I would guess that browseURL() won't work for any URL.  Is that right?
>>>>
>>>> Yes.  That is correct. E.g. if I do
>>>>
>>>>       browseURL("http://www.r-project.org/")
>>>>
>>>> I get taken to my home page, rather than to the R home page.
>>>>
>>>>>
>>>>> What does getOption("browser") give you in R?
>>>>
>>>> "/usr/bin/firefox"
>>>>
>>>>> If it is just a character
>>>>> string (e.g. "xdg-open" is what I get in Ubuntu), does it work from your
>>>>> command line, outside of R, e.g. for me that test would be
>>>>>
>>>>> xdg-open http://www.r-project.org
>>>>
>>>> I tried
>>>>
>>>>      /usr/bin/firefox http://www.r-project.org/
>>>>
>>>> from the Linux command line and was taken to the R home page,
>>>> seamlessly.  I also tried
>>>>
>>>>       xdg-open http://www.r-project.org/
>>>>
>>>> and that worked equally well.
>>>>
>>>> Finally I tried
>>>>
>>>>       options(browser="xdg-open")
>>>>
>>>> and then
>>>>
>>>>       ?plot
>>>>
>>>> and BINGO!!! the HTML help came up as requested.
>>>>
>>>> So I have a working solution to my problem.  But I *really* don't
>>>> understand why changing the browser from "/usr/bin/firefox" to
>>>> "xdg-open" made a difference.  (Since there appears to be no difference
>>>> at the Linux command line.)
>>>>
>>>> Anyway; thanks very much for solving my problem.
>>>
>>> I believe browseURL will quote the URL, i.e. it would execute
>>>
>>> /usr/bin/firefox "http://www.r-project.org/"
>>>
>>> Perhaps Firefox is confused by the quotes?  Doesn't seem likely...
>>>
>>> Duncan Murdoch
>>>
>>>
>>>>
>>>> cheers,
>>>>
>>>> Rolf
>>>>
>>>>>
>>>>> If that doesn't work, but you can figure out a command line way to open
>>>>> a particular URL, change getOption("browser") to use that.
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>>
>>>>>> The Firefox that I am currently running is (according Firefox help
>>>>>> --> "About Firefox") is version 36.0.
>>>>>>
>>>>>> Can anyone suggest to me how I can get my html R help back?
>>>>>>
>>>>>> For what it's worth:  I am using Linux, Fedora 17.  (Yes, I know it's
>>>>>> elderly, but then so am I. :-) )
>>>>>>
>>>>>> Also in case it has any relevance:
>>>>>>
>>>>>>>> sessionInfo()
>>>>>>> R version 3.1.2 (2014-10-31)
>>>>>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>>>>>
>>>>>>> locale:
>>>>>>>    [1] LC_CTYPE=en_NZ.utf8       LC_NUMERIC=C
>>>>>>>    [3] LC_TIME=en_NZ.utf8        LC_COLLATE=en_NZ.utf8
>>>>>>>    [5] LC_MONETARY=en_NZ.utf8    LC_MESSAGES=en_NZ.utf8
>>>>>>>    [7] LC_PAPER=en_NZ.utf8       LC_NAME=C
>>>>>>>    [9] LC_ADDRESS=C              LC_TELEPHONE=C
>>>>>>> [11] LC_MEASUREMENT=en_NZ.utf8 LC_IDENTIFICATION=C
>>>>>>>
>>>>>>> attached base packages:
>>>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>>>
>>>>>>> other attached packages:
>>>>>>> [1] spatstat_1.40-0.064 misc_0.0-16
>>>>>>>
>>>>>>> loaded via a namespace (and not attached):
>>>>>>>    [1] abind_1.4-0     deldir_0.1-7    goftest_1.0-2   grid_3.1.2
>>>>>>>    [5] lattice_0.20-29 Matrix_1.1-4    mgcv_1.8-3      nlme_3.1-118
>>>>>>>    [9] polyclip_1.3-1  tensor_1.5      tools_3.1.2
>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From Jose.Iparraguirre at ageuk.org.uk  Mon Mar  2 10:49:43 2015
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Mon, 2 Mar 2015 09:49:43 +0000
Subject: [R] Dummy variable in ARIMA
In-Reply-To: <CACM6noY+DLzN-JgfYZw2ZNUyCotu9SawAqB+QZgTN5-=QAvqpw@mail.gmail.com>
References: <CACM6noY+DLzN-JgfYZw2ZNUyCotu9SawAqB+QZgTN5-=QAvqpw@mail.gmail.com>
Message-ID: <5F8EC5C77B9AE547A8959F690F04C7B243FECC66@AGEPXMB006.uk.age.local>

Have a look at the caschrono package. 
There's an excellent associated book by the author of the package -Yves Aragon- but it's in French; if you don't read French, the package documentation is very clear. 
Jos?

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mikael Olai Milh?j
Sent: 26 February 2015 16:03
To: r-help at r-project.org
Subject: [R] Dummy variable in ARIMA

Hi all

I have been searching on the web in vain. I want to include a dummy variable in my ARIMA model. Let's say that I want to make an AR(1) model for X including a dummy variable which should be 1 for observation 4,5,6 and zero otherwise (let's say that there is 50 observations in total). How do I make that?

This does the trick but seems inefficient: dummy<-c(rep(0,3), rep(1,3),
rep(0,44))

Thx in advance

Best regards
/Mikael

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Age UK Group

Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798) Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA. 

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited. Age UK Enterprises Limited is authorised and regulated by the Financial Conduct Authority.

Charitable Services are offered through Age UK (the Charity) and commercial products and services are offered by the Charity?s subsidiary companies. The Age UK Group comprises of Age UK, and its subsidiary companies and charities, dedicated to improving the lives of people in later life. Our network includes the three national charities Age Cymru, Age NI and Age Scotland and more than 160 local Age UK charities.

This email and any files transmitted with it are confide...{{dropped:11}}


From pdalgd at gmail.com  Mon Mar  2 11:19:31 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 2 Mar 2015 11:19:31 +0100
Subject: [R] RWebdriver and RSelenium returns the same error while
	trying to connect the java server
In-Reply-To: <CA+vqiLEnxHr_8inU1wOaNo1nPYp+1ujmEgRN8t-hdSmQKsDbZA@mail.gmail.com>
References: <3c7295b7.8d5f.14bd668636b.Coremail.rhelpmaillist@163.com>
	<CA+vqiLEnxHr_8inU1wOaNo1nPYp+1ujmEgRN8t-hdSmQKsDbZA@mail.gmail.com>
Message-ID: <522AD6F9-EEBA-43C9-8B56-5AA719C3F444@gmail.com>

Is this a very recent version of Firefox? Have a look at the thread 

Re: [R] Firefox not showing R help.

It could be related, in which case you might want to try the up-to-the-minute latest version of R-patched (aka 3.1.3RC). 

Otherwise, as usual, you may need to talk with the relevant package maintainers.

-pd

On 01 Mar 2015, at 21:09 , Ista Zahn <istazahn at gmail.com> wrote:

> Do you have a server running? Can you connect to localhost directly
> from a browser?
> 
> Best,
> Ista
> 
> On Sun, Mar 1, 2015 at 12:35 PM, PO SU <rhelpmaillist at 163.com> wrote:
>> 
>> 
>> Dear expeRts,
>>   when i using RWebdriver and RSelenium ,
>> 
>> 
>> 
>>> require(RSelenium)
>> Loading required package: RSelenium
>>> remDr <- remoteDriver(remoteServerAddr = "localhost"
>> +                       , port = 4444
>> +                       , browserName = "firefox"
>> + )
>>> remDr$open()
>> [1] "Connecting to remote server"
>> 
>> 
>> 
>> Error:   Summary: UnknownError
>>         Detail: An unknown server-side error occurred while processing the command.
>>         class: org.openqa.selenium.firefox.NotConnectedException
>> 
>> 
>> from the cmd lines, it show "unable to connect 127.0.0.1 7055 after 45000ms "
>> 
>> 
>> i don't know why, is there anybody who happens to know it ?
>> --
>> 
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From geoffrey_klein at etu.u-bourgogne.fr  Mon Mar  2 12:11:14 2015
From: geoffrey_klein at etu.u-bourgogne.fr (jeff6868)
Date: Mon, 2 Mar 2015 03:11:14 -0800 (PST)
Subject: [R] How to speed up a double loop?
Message-ID: <1425294674325-4704054.post@n4.nabble.com>

Dear R-users,

I would like to speed up a double-loop I developed for detecting and
removing outliers in my whole data.frame. The idea is to remove data with a
too big difference with the previous value. If detected, this test must be
done here on maximum the next 10 values following the last correct one (and
put an index on another column).

It works well on a small data frame, but really too slowly for my real DF
with 500 000 rows.
Here's a fake data example and the double-loop:

    myts <- data.frame(x=c(1,2,50,40,30,40,100,1,50,1,2,3,3,5,4),y=NA)    
    
    for(jj in 1:(nrow(myts)-10)){
        for(nn in ((jj+1):(jj+10))) {
           if((!is.na(myts[jj,1])) & (!is.na(myts[nn,1])) &
(abs((myts[nn,1])-(myts[jj,1]))>15))
               { myts[nn,2] <- 1
                 myts[nn,1] <- NA } } } 

Can somebody explain me how can I speed this up easily? I heard about
vectorization but I don't really understand how it works.




--
View this message in context: http://r.789695.n4.nabble.com/How-to-speed-up-a-double-loop-tp4704054.html
Sent from the R help mailing list archive at Nabble.com.


From geoffrey_klein at etu.u-bourgogne.fr  Mon Mar  2 13:02:53 2015
From: geoffrey_klein at etu.u-bourgogne.fr (jeff6868)
Date: Mon, 2 Mar 2015 04:02:53 -0800 (PST)
Subject: [R] Sorting data frame by prepared order
In-Reply-To: <1425247108502-4704038.post@n4.nabble.com>
References: <1425247108502-4704038.post@n4.nabble.com>
Message-ID: <1425297773886-4704058.post@n4.nabble.com>

Hi,

Maybe a beginning of solution with this?

test <-
data.frame(x=c(1,1,1,1,1,1,2,2,2,2,2,2),y=c("a","a","a","b","b","b","a","a","b","b","b","a"))
test[order(test$x),]

out <- split(test,test$x)

for (i in 1:length(out)) {
    foo <- unique(out[[i]][,2])
       out[[i]][,2] <- rep(foo,(nrow(out[[i]])/(length(foo)))) }

Seems to work for an length with a even value of your unique values in your
first column. But still a problem for odd lengths. Maybe solved by adding
fake rows that you can remove afterwords (with a specific index for
example).



--
View this message in context: http://r.789695.n4.nabble.com/Sorting-data-frame-by-prepared-order-tp4704038p4704058.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Mon Mar  2 14:53:14 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 2 Mar 2015 13:53:14 +0000
Subject: [R] How to speed up a double loop?
In-Reply-To: <1425294674325-4704054.post@n4.nabble.com>
References: <1425294674325-4704054.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C22250@SRVEXCHMBX.precheza.cz>

Hi

I do not see much logic in your removal of "outliers".

you can easily find which values differ from previous one by more than 15

myts[c(FALSE,abs(diff(myts$x))>15),]

but I did not understand why do you keep values from row 8 and 10.

Your example can be solved by

myts$y[myts$x>15]<-1
myts$x<-myts$x*(myts$x<15)

but it probably is not what you want.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> jeff6868
> Sent: Monday, March 02, 2015 12:11 PM
> To: r-help at r-project.org
> Subject: [R] How to speed up a double loop?
>
> Dear R-users,
>
> I would like to speed up a double-loop I developed for detecting and
> removing outliers in my whole data.frame. The idea is to remove data
> with a
> too big difference with the previous value. If detected, this test must
> be
> done here on maximum the next 10 values following the last correct one
> (and
> put an index on another column).
>
> It works well on a small data frame, but really too slowly for my real
> DF
> with 500 000 rows.
> Here's a fake data example and the double-loop:
>
>     myts <- data.frame(x=c(1,2,50,40,30,40,100,1,50,1,2,3,3,5,4),y=NA)
>
>     for(jj in 1:(nrow(myts)-10)){
>         for(nn in ((jj+1):(jj+10))) {
>            if((!is.na(myts[jj,1])) & (!is.na(myts[nn,1])) &
> (abs((myts[nn,1])-(myts[jj,1]))>15))
>                { myts[nn,2] <- 1
>                  myts[nn,1] <- NA } } }
>
> Can somebody explain me how can I speed this up easily? I heard about
> vectorization but I don't really understand how it works.
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-
> speed-up-a-double-loop-tp4704054.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From HDoran at air.org  Mon Mar  2 17:00:39 2015
From: HDoran at air.org (Doran, Harold)
Date: Mon, 2 Mar 2015 16:00:39 +0000
Subject: [R] readHTMLTable() in XML package
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686CF3B78DB@DC1VEX10MB001.air.org>

I'm having trouble pulling down data from a website with my code below as I keep encountering the same error, but the error occurs on different pages.

My code below loops through a wensite and grabs data from the html table. The error appears on different pages at different times and I'm not sure of the root cause.

Error in readHTMLTable(readLines(url), which = 1, header = TRUE) :
  error in evaluating the argument 'doc' in selecting a method for function 'readHTMLTable': Error in readHTMLTable(readLines(url), which = 1, header = TRUE) :
  error in evaluating the argument 'doc' in selecting a method for function 'readHTMLTable':

library(XML)
for(i in 1:1000){
                url <- paste(paste('http://games.crossfit.com/scores/leaderboard.php?stage=5&sort=0&page=', i, sep=''), '&division=1&region=0&numberperpage=100&competition=0&frontpage=0&expanded=1&year=15&full=1&showtoggles=0&hidedropdowns=0&showathleteac=1&=&is_mobile=0', sep='')
    tmp <- readHTMLTable(readLines(url), which=1, header=TRUE)
                names(tmp) <- gsub("\\n", "", names(tmp))
                names(tmp) <- gsub(" +", "", names(tmp))
    tmp[] <- lapply(tmp, function(x) gsub("\\n", "", x))

    if(i == 1){
                dat <- tmp
                } else {
                dat <- rbind(dat, tmp)
                }
                cat('Grabbing data from page', i, '\n')
                }

Thanks,
Harold

	[[alternative HTML version deleted]]


From emorway at usgs.gov  Mon Mar  2 18:43:55 2015
From: emorway at usgs.gov (Morway, Eric)
Date: Mon, 2 Mar 2015 09:43:55 -0800
Subject: [R] numbering consecutive rows based on length criteria
Message-ID: <CAPoqHzpPaDedyxCoyLJ6-cvRLJgz1fksZXrLBpNVzzGB-1b_2w@mail.gmail.com>

Using this dataset:

dat <- read.table(textConnection("day    noRes.Q    wRes.Q
 1  237074.41 215409.41
 2 2336240.20 164835.16
 3   84855.42 357062.72
 4   76993.48 386326.78
 5   73489.47 307144.09
 6   70246.96  75885.75
 7   69630.09  74054.33
 8   66714.78  70071.80
 9  122296.90  66579.08
10   63502.71  65811.37
11   63401.84  64795.12
12   63387.84  64401.14
13   63186.10  64163.95
14   63160.74  63468.25
15   60471.15  60719.15
16   58235.63  57655.14
17   58089.73  58061.34
18   57846.39  57357.89
19   57839.42  56495.69
20   57740.06  56219.97
21   58068.57  55810.91
22   58358.34  56437.81
23   76284.90  73722.92
24  105138.31 100729.00
25  147203.03 178079.38
26  109996.02 111113.95
27   91424.20  87391.56
28   89065.91  87196.69
29   86628.74  84809.07
30   79357.60  77555.62"),header=T)

I'm attempting to generate a column that continuously numbers consecutive
rows where wRes.Q is greater than noRes.Q.  To that end, I've come up with
the following:

dat$flg <- dat$wRes.Q>dat$noRes.Q
dat$cnt <- with(dat, ave(integer(length(flg)), flg, FUN=seq_along))

The problem with dat$cnt is that it doesn't start over with 1 when a 'new'
group of either true or false is encountered.  Thus, row 9's cnt value
should start over at 1, as should dat$cnt[10], and dat$cnt[11]==2, etc.
(the desired result is shown below)

In the larger dataset I'm working with (>6,000 rows), there are blocks of
rows where the number of consecutive rows with dat$cnt==TRUE exceeds 100.
My goal is to plot these blocks of rows as polygons in a time series plot.
If, for the small example provided, the number of consecutive rows with
dat$cnt==TRUE is greater than or equal to 5 (the 2 blocks of rows
satisfying this criteria in this small example are rows 3-8 and 10-15), is
there a way to add a column that uniquely numbers these blocks of rows? I'd
like to end up with the following, which shows the correct "cnt" column and
a column called "plygn" that is my ultimate goal:

dat
# day    noRes.Q    wRes.Q   flg cnt  plygn
#   1  237074.41 215409.41 FALSE   1     NA
#   2 2336240.20 164835.16 FALSE   2     NA
#   3   84855.42 357062.72  TRUE   1      1
#   4   76993.48 386326.78  TRUE   2      1
#   5   73489.47 307144.09  TRUE   3      1
#   6   70246.96  75885.75  TRUE   4      1
#   7   69630.09  74054.33  TRUE   5      1
#   8   66714.78  70071.80  TRUE   6      1
#   9  122296.90  66579.08 FALSE   1     NA
#  10   63502.71  65811.37  TRUE   1      2
#  11   63401.84  64795.12  TRUE   2      2
#  12   63387.84  64401.14  TRUE   3      2
#  13   63186.10  64163.95  TRUE   4      2
#  14   63160.74  63468.25  TRUE   5      2
#  15   60471.15  60719.15  TRUE   6      2
#  16   58235.63  57655.14 FALSE   1     NA
#  17   58089.73  58061.34 FALSE   2     NA
#  18   57846.39  57357.89 FALSE   3     NA
#  19   57839.42  56495.69 FALSE   4     NA
#  20   57740.06  56219.97 FALSE   5     NA
#  21   58068.57  55810.91 FALSE   6     NA
#  22   58358.34  56437.81 FALSE   7     NA
#  23   76284.90  73722.92 FALSE   8     NA
#  24  105138.31 100729.00 FALSE   9     NA
#  25  147203.03 178079.38  TRUE   1     NA
#  26  109996.02 111113.95  TRUE   2     NA
#  27   91424.20  87391.56 FALSE   1     NA
#  28   89065.91  87196.69 FALSE   2     NA
#  29   86628.74  84809.07 FALSE   3     NA
#  30   79357.60  77555.62 FALSE   4     NA

Thanks, Eric

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Mon Mar  2 18:56:01 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 02 Mar 2015 11:56:01 -0600
Subject: [R] numbering consecutive rows based on length criteria
In-Reply-To: <CAPoqHzpPaDedyxCoyLJ6-cvRLJgz1fksZXrLBpNVzzGB-1b_2w@mail.gmail.com>
References: <CAPoqHzpPaDedyxCoyLJ6-cvRLJgz1fksZXrLBpNVzzGB-1b_2w@mail.gmail.com>
Message-ID: <F459B32A-F936-464D-9DBA-0B53E30268B3@me.com>

On Mar 2, 2015, at 11:43 AM, Morway, Eric <emorway at usgs.gov> wrote:
> 
> Using this dataset:
> 
> dat <- read.table(textConnection("day    noRes.Q    wRes.Q
> 1  237074.41 215409.41
> 2 2336240.20 164835.16
> 3   84855.42 357062.72
> 4   76993.48 386326.78
> 5   73489.47 307144.09
> 6   70246.96  75885.75
> 7   69630.09  74054.33
> 8   66714.78  70071.80
> 9  122296.90  66579.08
> 10   63502.71  65811.37
> 11   63401.84  64795.12
> 12   63387.84  64401.14
> 13   63186.10  64163.95
> 14   63160.74  63468.25
> 15   60471.15  60719.15
> 16   58235.63  57655.14
> 17   58089.73  58061.34
> 18   57846.39  57357.89
> 19   57839.42  56495.69
> 20   57740.06  56219.97
> 21   58068.57  55810.91
> 22   58358.34  56437.81
> 23   76284.90  73722.92
> 24  105138.31 100729.00
> 25  147203.03 178079.38
> 26  109996.02 111113.95
> 27   91424.20  87391.56
> 28   89065.91  87196.69
> 29   86628.74  84809.07
> 30   79357.60  77555.62"),header=T)
> 
> I'm attempting to generate a column that continuously numbers consecutive
> rows where wRes.Q is greater than noRes.Q.  To that end, I've come up with
> the following:
> 
> dat$flg <- dat$wRes.Q>dat$noRes.Q
> dat$cnt <- with(dat, ave(integer(length(flg)), flg, FUN=seq_along))
> 
> The problem with dat$cnt is that it doesn't start over with 1 when a 'new'
> group of either true or false is encountered.  Thus, row 9's cnt value
> should start over at 1, as should dat$cnt[10], and dat$cnt[11]==2, etc.
> (the desired result is shown below)
> 
> In the larger dataset I'm working with (>6,000 rows), there are blocks of
> rows where the number of consecutive rows with dat$cnt==TRUE exceeds 100.
> My goal is to plot these blocks of rows as polygons in a time series plot.
> If, for the small example provided, the number of consecutive rows with
> dat$cnt==TRUE is greater than or equal to 5 (the 2 blocks of rows
> satisfying this criteria in this small example are rows 3-8 and 10-15), is
> there a way to add a column that uniquely numbers these blocks of rows? I'd
> like to end up with the following, which shows the correct "cnt" column and
> a column called "plygn" that is my ultimate goal:
> 
> dat
> # day    noRes.Q    wRes.Q   flg cnt  plygn
> #   1  237074.41 215409.41 FALSE   1     NA
> #   2 2336240.20 164835.16 FALSE   2     NA
> #   3   84855.42 357062.72  TRUE   1      1
> #   4   76993.48 386326.78  TRUE   2      1
> #   5   73489.47 307144.09  TRUE   3      1
> #   6   70246.96  75885.75  TRUE   4      1
> #   7   69630.09  74054.33  TRUE   5      1
> #   8   66714.78  70071.80  TRUE   6      1
> #   9  122296.90  66579.08 FALSE   1     NA
> #  10   63502.71  65811.37  TRUE   1      2
> #  11   63401.84  64795.12  TRUE   2      2
> #  12   63387.84  64401.14  TRUE   3      2
> #  13   63186.10  64163.95  TRUE   4      2
> #  14   63160.74  63468.25  TRUE   5      2
> #  15   60471.15  60719.15  TRUE   6      2
> #  16   58235.63  57655.14 FALSE   1     NA
> #  17   58089.73  58061.34 FALSE   2     NA
> #  18   57846.39  57357.89 FALSE   3     NA
> #  19   57839.42  56495.69 FALSE   4     NA
> #  20   57740.06  56219.97 FALSE   5     NA
> #  21   58068.57  55810.91 FALSE   6     NA
> #  22   58358.34  56437.81 FALSE   7     NA
> #  23   76284.90  73722.92 FALSE   8     NA
> #  24  105138.31 100729.00 FALSE   9     NA
> #  25  147203.03 178079.38  TRUE   1     NA
> #  26  109996.02 111113.95  TRUE   2     NA
> #  27   91424.20  87391.56 FALSE   1     NA
> #  28   89065.91  87196.69 FALSE   2     NA
> #  29   86628.74  84809.07 FALSE   3     NA
> #  30   79357.60  77555.62 FALSE   4     NA
> 
> Thanks, Eric


Hi,

See ?rle

> unlist(sapply(rle(with(dat, wRes.Q > noRes.Q))$lengths, seq))
 [1] 1 2 1 2 3 4 5 6 1 1 2 3 4 5 6 1 2 3 4 5 6 7 8 9 1 2 1 2 3 4

cbind() the result above to your data frame.

Regards,

Marc Schwartz


From thierry.onkelinx at inbo.be  Mon Mar  2 19:02:07 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 2 Mar 2015 19:02:07 +0100
Subject: [R] numbering consecutive rows based on length criteria
In-Reply-To: <CAPoqHzpPaDedyxCoyLJ6-cvRLJgz1fksZXrLBpNVzzGB-1b_2w@mail.gmail.com>
References: <CAPoqHzpPaDedyxCoyLJ6-cvRLJgz1fksZXrLBpNVzzGB-1b_2w@mail.gmail.com>
Message-ID: <CAJuCY5xJNVcJcQzVR3Sm1a-SWaZTenno94PSJWzmsHo+OyXCoQ@mail.gmail.com>

Dear Eric,

Here is a solution using the plyr package.

library(plyr)
dat$flg <- dat$wRes.Q>dat$noRes.Q
dat$group <- cumsum(c(0, abs(diff(dat$flg))))
ddply(dat, "group", function(x){
  if(x$flg[1] && nrow(x) >= 5){
    x$plygn <- seq_along(x$group)
  } else {
    x$plygn <- NA
  }
  x
})

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-02 18:43 GMT+01:00 Morway, Eric <emorway at usgs.gov>:

> Using this dataset:
>
> dat <- read.table(textConnection("day    noRes.Q    wRes.Q
>  1  237074.41 215409.41
>  2 2336240.20 164835.16
>  3   84855.42 357062.72
>  4   76993.48 386326.78
>  5   73489.47 307144.09
>  6   70246.96  75885.75
>  7   69630.09  74054.33
>  8   66714.78  70071.80
>  9  122296.90  66579.08
> 10   63502.71  65811.37
> 11   63401.84  64795.12
> 12   63387.84  64401.14
> 13   63186.10  64163.95
> 14   63160.74  63468.25
> 15   60471.15  60719.15
> 16   58235.63  57655.14
> 17   58089.73  58061.34
> 18   57846.39  57357.89
> 19   57839.42  56495.69
> 20   57740.06  56219.97
> 21   58068.57  55810.91
> 22   58358.34  56437.81
> 23   76284.90  73722.92
> 24  105138.31 100729.00
> 25  147203.03 178079.38
> 26  109996.02 111113.95
> 27   91424.20  87391.56
> 28   89065.91  87196.69
> 29   86628.74  84809.07
> 30   79357.60  77555.62"),header=T)
>
> I'm attempting to generate a column that continuously numbers consecutive
> rows where wRes.Q is greater than noRes.Q.  To that end, I've come up with
> the following:
>
> dat$flg <- dat$wRes.Q>dat$noRes.Q
> dat$cnt <- with(dat, ave(integer(length(flg)), flg, FUN=seq_along))
>
> The problem with dat$cnt is that it doesn't start over with 1 when a 'new'
> group of either true or false is encountered.  Thus, row 9's cnt value
> should start over at 1, as should dat$cnt[10], and dat$cnt[11]==2, etc.
> (the desired result is shown below)
>
> In the larger dataset I'm working with (>6,000 rows), there are blocks of
> rows where the number of consecutive rows with dat$cnt==TRUE exceeds 100.
> My goal is to plot these blocks of rows as polygons in a time series plot.
> If, for the small example provided, the number of consecutive rows with
> dat$cnt==TRUE is greater than or equal to 5 (the 2 blocks of rows
> satisfying this criteria in this small example are rows 3-8 and 10-15), is
> there a way to add a column that uniquely numbers these blocks of rows? I'd
> like to end up with the following, which shows the correct "cnt" column and
> a column called "plygn" that is my ultimate goal:
>
> dat
> # day    noRes.Q    wRes.Q   flg cnt  plygn
> #   1  237074.41 215409.41 FALSE   1     NA
> #   2 2336240.20 164835.16 FALSE   2     NA
> #   3   84855.42 357062.72  TRUE   1      1
> #   4   76993.48 386326.78  TRUE   2      1
> #   5   73489.47 307144.09  TRUE   3      1
> #   6   70246.96  75885.75  TRUE   4      1
> #   7   69630.09  74054.33  TRUE   5      1
> #   8   66714.78  70071.80  TRUE   6      1
> #   9  122296.90  66579.08 FALSE   1     NA
> #  10   63502.71  65811.37  TRUE   1      2
> #  11   63401.84  64795.12  TRUE   2      2
> #  12   63387.84  64401.14  TRUE   3      2
> #  13   63186.10  64163.95  TRUE   4      2
> #  14   63160.74  63468.25  TRUE   5      2
> #  15   60471.15  60719.15  TRUE   6      2
> #  16   58235.63  57655.14 FALSE   1     NA
> #  17   58089.73  58061.34 FALSE   2     NA
> #  18   57846.39  57357.89 FALSE   3     NA
> #  19   57839.42  56495.69 FALSE   4     NA
> #  20   57740.06  56219.97 FALSE   5     NA
> #  21   58068.57  55810.91 FALSE   6     NA
> #  22   58358.34  56437.81 FALSE   7     NA
> #  23   76284.90  73722.92 FALSE   8     NA
> #  24  105138.31 100729.00 FALSE   9     NA
> #  25  147203.03 178079.38  TRUE   1     NA
> #  26  109996.02 111113.95  TRUE   2     NA
> #  27   91424.20  87391.56 FALSE   1     NA
> #  28   89065.91  87196.69 FALSE   2     NA
> #  29   86628.74  84809.07 FALSE   3     NA
> #  30   79357.60  77555.62 FALSE   4     NA
>
> Thanks, Eric
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Mon Mar  2 20:04:42 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 2 Mar 2015 13:04:42 -0600
Subject: [R] readHTMLTable() in XML package
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686CF3B78DB@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686CF3B78DB@DC1VEX10MB001.air.org>
Message-ID: <CABdHhvFoo0C5N-yE4P-g3WdBx3FC33HWvw=cbrCg8e2bkPuJFg@mail.gmail.com>

This somewhat simpler rvest code does the trick for me:

library(rvest)
library(dplyr)

i <- 1:10
urls <- paste0('http://games.crossfit.com/scores/leaderboard.php?stage=5',
  '&sort=0&division=1&region=0&numberperpage=100&competition=0&frontpage=0',
  '&expanded=1&year=15&full=1&showtoggles=0&hidedropdowns=0&showathleteac=1',
  '&is_mobile=0&page=', i)

results_table <- function(url) {
  url %>% html %>% html_table(fill = TRUE) %>% .[[1]]
}

results <- lapply(urls, results_table)
out <- results %>% bind_rows()

Hadley

On Mon, Mar 2, 2015 at 10:00 AM, Doran, Harold <HDoran at air.org> wrote:
> I'm having trouble pulling down data from a website with my code below as I keep encountering the same error, but the error occurs on different pages.
>
> My code below loops through a wensite and grabs data from the html table. The error appears on different pages at different times and I'm not sure of the root cause.
>
> Error in readHTMLTable(readLines(url), which = 1, header = TRUE) :
>   error in evaluating the argument 'doc' in selecting a method for function 'readHTMLTable': Error in readHTMLTable(readLines(url), which = 1, header = TRUE) :
>   error in evaluating the argument 'doc' in selecting a method for function 'readHTMLTable':
>
> library(XML)
> for(i in 1:1000){
>                 url <- paste(paste('http://games.crossfit.com/scores/leaderboard.php?stage=5&sort=0&page=', i, sep=''), '&division=1&region=0&numberperpage=100&competition=0&frontpage=0&expanded=1&year=15&full=1&showtoggles=0&hidedropdowns=0&showathleteac=1&=&is_mobile=0', sep='')
>     tmp <- readHTMLTable(readLines(url), which=1, header=TRUE)
>                 names(tmp) <- gsub("\\n", "", names(tmp))
>                 names(tmp) <- gsub(" +", "", names(tmp))
>     tmp[] <- lapply(tmp, function(x) gsub("\\n", "", x))
>
>     if(i == 1){
>                 dat <- tmp
>                 } else {
>                 dat <- rbind(dat, tmp)
>                 }
>                 cat('Grabbing data from page', i, '\n')
>                 }
>
> Thanks,
> Harold
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From adrian.torchiana at gmail.com  Mon Mar  2 16:49:14 2015
From: adrian.torchiana at gmail.com (Adrian Torchiana)
Date: Mon, 2 Mar 2015 16:49:14 +0100
Subject: [R] R crashes when I run rgeos::gDistance
Message-ID: <CAMBOG9MOceipr5YAWnQoKRjh2PZR5b8zEH9izsqLJqRDwZXHhw@mail.gmail.com>

Hi,

This is my first post to R-help.  I'm having trouble getting rgeos to work.

Info on the server and packages I'm using:

$ *uname -a*
Linux some-server.somewhere.com 2.6.32-431.11.2.el6.x86_64 #1 SMP Tue Mar
25 19:59:55 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux

$ *R --version*
R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-redhat-linux-gnu (64-bit)

$ *lsb_release -a*
LSB Version:
:base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch
Distributor ID: CentOS
Description: CentOS release 6.5 (Final)
Release: 6.5
Codename: Final

$ *rpm -qa | grep geos*
geos-devel-3.4.2-1.rhel6.x86_64
geos-3.4.2-1.rhel6.x86_64

$ *rpm -qa | grep gdal*
gdal-1.9.2-6.rhel6.x86_64
gdal-libs-1.9.2-6.rhel6.x86_64
gdal-devel-1.9.2-6.rhel6.x86_64
gdal-java-1.9.2-6.rhel6.x86_64

$ *R -q*
> *library(rgeos)*
rgeos version: 0.3-8, (SVN revision 460)
 GEOS runtime version: 3.4.2-CAPI-1.8.2 r3921
 Polygon checking: TRUE

> *example(gDistance)*

gDstnc> pt1 = readWKT("POINT(0.5 0.5)")

gDstnc> pt2 = readWKT("POINT(2 2)")

gDstnc> p1 = readWKT("POLYGON((0 0,1 0,1 1,0 1,0 0))")

gDstnc> p2 = readWKT("POLYGON((2 0,3 1,4 0,2 0))")

gDstnc> gDistance(pt1,pt2)
R: GeometryComponentFilter.cpp:34: virtual void
geos::geom::GeometryComponentFilter::filter_ro(const
geos::geom::Geometry*): Assertion `0' failed.
Aborted (core dumped)


I'd like to be able to use the gDistance function.  What should I do to fix
this?

Please let me know if any additional information would be helpful.

Thank you for your time,

Adrian

	[[alternative HTML version deleted]]


From geoffrey_klein at etu.u-bourgogne.fr  Mon Mar  2 15:12:44 2015
From: geoffrey_klein at etu.u-bourgogne.fr (jeff6868)
Date: Mon, 2 Mar 2015 06:12:44 -0800 (PST)
Subject: [R] How to speed up a double loop?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C22250@SRVEXCHMBX.precheza.cz>
References: <1425294674325-4704054.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C22250@SRVEXCHMBX.precheza.cz>
Message-ID: <1425305564921-4704061.post@n4.nabble.com>

Hi Petr,

Thanks for your reply,

Actually it's not what I'm looking for. The aim is not simply to remove each
value > 15. 

In my loop, I consider the first numeric value of my column as "correct".
Then, I want to test the second value. If the absolute difference with the
previous correct one is <15, it's a new correct one, but if it's >15, then
it's a wrong one. 
If it's a wrong one, it has to test the third one to check if it's still >15
from the last correct value (first one).
The value becomes correct again when the difference with the last correct
one goes under 15 (and so, this value is the new "correct" one, and so one
for the rest of the column).

My loop is already doing the trick, but I just want to speed it up (or maybe
another faster way to do the job).
Hope it's more understandable right now! 





--
View this message in context: http://r.789695.n4.nabble.com/How-to-speed-up-a-double-loop-tp4704054p4704061.html
Sent from the R help mailing list archive at Nabble.com.


From melloa at wit.edu  Mon Mar  2 17:53:22 2015
From: melloa at wit.edu (Mello Cavallo, Alice)
Date: Mon, 2 Mar 2015 16:53:22 +0000
Subject: [R] Installed R to Windows, but having trouble with read.csv
Message-ID: <8CFBF20CB9E9C348A283BAB1A16869A547F98592@exmbx1>

I copied the file into the bin folder of R ...



> perf_data <- read.csv("PerfResultsCSv.csv")
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'PerfResultsCSv.csv': No such file or directory

I also installed and load RWeka package, but canot open.



It seems like I am having some issue of directories...

I am new to R, any help appreciated.

Thanks,

Alice

	[[alternative HTML version deleted]]


From oma.gonzales at gmail.com  Mon Mar  2 20:56:39 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Mon, 2 Mar 2015 14:56:39 -0500
Subject: [R] Installed R to Windows, but having trouble with read.csv
In-Reply-To: <8CFBF20CB9E9C348A283BAB1A16869A547F98592@exmbx1>
References: <8CFBF20CB9E9C348A283BAB1A16869A547F98592@exmbx1>
Message-ID: <CAM-xyZhTvPJE7N5oru0m=qCV07pcEbHyusYbeuo1d1YZh1nC+w@mail.gmail.com>

Is this file in your working directory? (To know your working directory
use: getwd()   )

If not, put it in there.

2015-03-02 11:53 GMT-05:00 Mello Cavallo, Alice <melloa at wit.edu>:

> I copied the file into the bin folder of R ...
>
>
>
> > perf_data <- read.csv("PerfResultsCSv.csv")
> Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>   cannot open file 'PerfResultsCSv.csv': No such file or directory
>
> I also installed and load RWeka package, but canot open.
>
>
>
> It seems like I am having some issue of directories...
>
> I am new to R, any help appreciated.
>
> Thanks,
>
> Alice
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maicel at infomed.sld.cu  Mon Mar  2 21:31:50 2015
From: maicel at infomed.sld.cu (maicel at infomed.sld.cu)
Date: Mon, 02 Mar 2015 15:31:50 -0500
Subject: [R] table
Message-ID: <20150302153150.65894iss8h5tsxbq@webmail.sld.cu>

Hello List,

I am trying to obtain a table containing absolute and relative  
frequencies but it must be done by strata. Each strata have to contain  
totals and subtotals being the sum of the subtotals equal to the total  
in upper strata in same column. As this could be some vague I am  
including an example of such table:


data<-data.frame(Provincial=rep(c("Prov1","Prov2","Prov1","Prov3"),10),  
Municipios=rep(c("Mun1","Mun2","Mun3","Mun4"),10),unit=rep(c("unit1","unit2","unit3","unit4"),10))

Variable 	N	%
Province (i)
Municipalities (j)
Health units (k)
&#8721;i,  &#8721;j, &#8721;k
And so on 
 i = 1 to 16

&#8721;i,  &#8721;j, &#8721;k

If you could help me to obtain a function to get such table I would  
appreciate very much.

Best and thank you
.
maicel monzon MD. MSc.



----------------------------------------------------------------




--
Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/


From markseeto at gmail.com  Mon Mar  2 21:49:51 2015
From: markseeto at gmail.com (Mark Seeto)
Date: Tue, 3 Mar 2015 07:49:51 +1100
Subject: [R] rms package: error with Glm
Message-ID: <CAK2mLtN9vNahxVf1UfZiRF-o2PQz+pkYpKq1=rWpUzNn_m4HQg@mail.gmail.com>

Dear R-help,

I'm getting an error with Glm (from the rms package) when the
equivalent model using glm does not give an error. This is using rms
4.3-0 in R 3.1.1.

An example is shown below. I have set the seed value, but the error is
not specific to this seed value.

Thanks for any help anyone can give.

Mark Seeto

#############################################################################
library(rms)

set.seed(1)

n <- 100  # sample size

beta0 <- 3.7
beta1 <- 1.5
beta2 <- 0.9
beta3 <- 0.5

rate.x1 <- 2
mean.x2 <- 1
sd.x2 <- 2

nu <- 1.3

d <- data.frame(x1 = rexp(n, rate = rate.x1),
                x2 = rnorm(n, mean.x2, sd.x2))

d$y <- rgamma(n, shape = nu,
              rate = nu/exp(beta0 + beta1*d$x1 + beta2*d$x2 + beta3*d$x2^2))

glm(y ~ x1 + x2 + I(x2^2), family = Gamma(link=log), data=d)  # No error

Glm(y ~ x1 + pol(x2, 2), family = Gamma(link=log), data=d)  # Error shown below

## Error in glm.fit(x = X[, "Intercept", drop = FALSE], y = Y, weights
= weights,  :
##   NA/NaN/Inf in 'x'
## In addition: Warning message:
## step size truncated due to divergence


From yanwu1205 at gmail.com  Mon Mar  2 21:13:53 2015
From: yanwu1205 at gmail.com (Yan Wu)
Date: Mon, 2 Mar 2015 14:13:53 -0600
Subject: [R] How to decide " weight" in WLS model in R ?
Message-ID: <CAKq6KjQfwvUsj7qDq5-soN5Nk01_PN_9ukQXezuT0cdgFNcgTw@mail.gmail.com>

Hi,

I would like to know how to decide the "weight" in a WLS model in R?

For example, In the" pipeline " data from faraway, I try to fit a
regression model Lab ~ Field (non-constant variance). I wish to use weights
to account for the non-constant variance. So how to decide the weight in
the WLS model?

For the "pipeline" data, they split the range of Field into 12 groups of
size 9. within each group, and they compute the variance of Lab as "varlab"
and the mean of Field as "meanfield". In addition, they suppose that the
variance in the response is linked to the predictor in the following way:
var(Lab)=a*(Field^b).

So we could get a estimate of a and b by regress log(varlab) on
log(meanfield). But how to determine weights in a WLS fit of Lab on Field
in R?

I guess that it may require the function of 'VarConstPower' in R in the
example above. So could you please explain how to use 'VarConstPower' in R?

I will appreciate it if you could please answer the two questions above.

Thanks!
Angela
-

	[[alternative HTML version deleted]]


From Rami.Alzebdieh at etu.unige.ch  Mon Mar  2 10:38:07 2015
From: Rami.Alzebdieh at etu.unige.ch (Rami Alzebdieh)
Date: Mon, 2 Mar 2015 09:38:07 +0000
Subject: [R] R Help
Message-ID: <28315EE2E6C18C4EAF42C7EFEC72DD8C1997A273@mike.isis.unige.ch>

Dear Sir,

I start using (R) 3 months ago, and I am still learning, I have a project and I am using R in this project, my friend helped me to build a code for this project and it's working perfect, but I need to make a small change in, it looks very simple but for me it's very complicated. I insert the code and I hope if you can help me this problem. I highlighted what exactly I need to change. This project is calculating the market and industry weighted returns for each based on the date levels.

sync = read.csv("country-14.csv",header=T)
id.country = 14

sync = sync[sync$country!="country" & sync$country==id.country,-c(2,5)]
sync$price=as.numeric(as.character(sync$price))
sync$mv=as.numeric(as.character(sync$mv))
attach(sync)

#### Calculate returns and add to the dataset
n.comp = nlevels(as.factor(as.character(sync$company_name)))
comp.names = levels(as.factor(as.character(sync$company_name)))
data = vector("list",n.comp)
for(i in 1:n.comp){
  temp = sync[sync$company_name==comp.names[i],]
  data[[i]] = cbind(temp,c(NA,diff(temp$price)/temp$price[1:(length(temp$price)-1)]))
}
sync = do.call(rbind,data)
names(sync)[7] = "returns"
detach(sync)
attach(sync)

#### Fill industry_code column
industry_code=rep(NA,dim(sync)[1])
for(i in 1:dim(sync)[1]){
  if(nchar(as.character(company_code[i])) == 3){
    industry_code[i] = as.numeric(substr(as.character(company_code[i]),1,1))
  } else {
    industry_code[i] = as.numeric(substr(as.character(company_code[i]),1,2))
  }
  print((i/dim(sync)[1])*100)
}
sync = cbind(sync,as.factor(industry_code))
names(sync)[8] = "industry_code"
detach(sync)
attach(sync)

#### Calculate market weighted returns and add to the dataset
market_returns = rep(NA,dim(sync)[1])
industry_returns = rep(NA,dim(sync)[1])
for(i in 1:nlevels(date)){
    data = sync[date==levels(date)[i],]
    data$company_name = as.factor(as.character(data$company_name))
    for(m in 1:nlevels(data$company_name)){
      index1 = data$company_name == levels(data$company_name)[m]
      index2 = date==levels(date)[i] & company_name==levels(data$company_name)[m]
      market_returns[index2] = (sum(data$returns*(data$mv/sum(data$mv,na.rm=TRUE)),na.rm=TRUE) -
        (data$returns[index1]*(data$mv[index1]/sum(data$mv,na.rm=TRUE))))/(nlevels(data$company_name)-1) ## this what I need to change, instead of using the number of levels companies in the dataset (nlevels(data$company_name) , I need to put the number of returns values(data$returns) without NA (by the way this code is calculating returns at the date level as you can see from above)
    }
  print(i/nlevels(date))
}

sync = cbind(sync,market_returns)
names(sync)[9] = "market_returns"
detach(sync)
attach(sync)

#### Calculate industry weighted returns and add to the dataset
for(i in 1:nlevels(date)){
    for(k in 1:nlevels(as.factor(as.character(industry_code)))){
      data1 = sync[date==levels(date)[i] & industry_code==levels(as.factor(as.character(industry_code)))[k],]
      data1$company_name = as.factor(as.character(data1$company_name))
      for(l in 1:nlevels(data1$company_name)){
        index3 = data1$company_name == levels(data1$company_name)[l]
        index4 = date==levels(date)[i] & company_name==levels(data1$company_name)[l]
        industry_returns[index4] = (sum(data1$returns*(data1$mv/sum(data1$mv,na.rm=TRUE)),na.rm=TRUE) -
          (data1$returns[index3]*(data1$mv[index3]/sum(data1$mv,na.rm=TRUE))))/(nlevels(data1$company_name)-1) ## also here I need to change, instead of using the number of levels companies in the dataset (nlevels(data1$company_name) , I need to put the number of returns values(data1$returns) without NA (by the way this code is calculating returns at the date level and industry level as you can see from above)

      }
    }
  print(i/nlevels(date))
}

sync = cbind(sync,industry_returns)
names(sync)[10] = "industry_returns"
detach(sync)
attach(sync)

year = apply(as.matrix(sync$date),1,function(x) as.factor(substr(as.character(x),7,10)))
sync = cbind(sync,as.factor(year))
names(sync)[11] = "year"
sync = sync[sync$year!="1999",]
sync$year = as.factor(as.character(sync$year))
detach(sync)
attach(sync)

year = as.factor(as.character(year))
industry_code = as.factor(as.character(industry_code))
comp.per.ind = rep(NA, dim(sync)[1])
for(i in 1:nlevels(year)){
  for(j in 1:nlevels(industry_code)){
    index = year==levels(year)[i] & industry_code==levels(industry_code)[j]
    data = sync[index,]
    comp.per.ind[index] = nlevels(as.factor(as.character(data$company_name)))
  }
}

sync = cbind(sync,as.factor(comp.per.ind))
names(sync)[12] = "comp.per.ind"
detach(sync)
attach(sync)

write.csv(sync,paste("Returns_data",id.country,".csv",sep=""))




Thank you for your help

Rami Alzebdieh



	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Mon Mar  2 23:35:51 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 2 Mar 2015 14:35:51 -0800
Subject: [R] How to decide " weight" in WLS model in R ?
In-Reply-To: <CAKq6KjQfwvUsj7qDq5-soN5Nk01_PN_9ukQXezuT0cdgFNcgTw@mail.gmail.com>
References: <CAKq6KjQfwvUsj7qDq5-soN5Nk01_PN_9ukQXezuT0cdgFNcgTw@mail.gmail.com>
Message-ID: <CACk-te1E+gEEJtzwPfT4cEkEE0VKVTmaBypQCykpFnnoyX-skg@mail.gmail.com>

Angela:

These are statistical, not R, issues I believe, and you appear to be
out of your depth statistically here. I suggest you talk to a local
statistical resource or, if you can't find such help, post on a
statistical site like stats.stackexchange.com.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Mar 2, 2015 at 12:13 PM, Yan Wu <yanwu1205 at gmail.com> wrote:
> Hi,
>
> I would like to know how to decide the "weight" in a WLS model in R?
>
> For example, In the" pipeline " data from faraway, I try to fit a
> regression model Lab ~ Field (non-constant variance). I wish to use weights
> to account for the non-constant variance. So how to decide the weight in
> the WLS model?
>
> For the "pipeline" data, they split the range of Field into 12 groups of
> size 9. within each group, and they compute the variance of Lab as "varlab"
> and the mean of Field as "meanfield". In addition, they suppose that the
> variance in the response is linked to the predictor in the following way:
> var(Lab)=a*(Field^b).
>
> So we could get a estimate of a and b by regress log(varlab) on
> log(meanfield). But how to determine weights in a WLS fit of Lab on Field
> in R?
>
> I guess that it may require the function of 'VarConstPower' in R in the
> example above. So could you please explain how to use 'VarConstPower' in R?
>
> I will appreciate it if you could please answer the two questions above.
>
> Thanks!
> Angela
> -
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Tue Mar  3 00:03:30 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 03 Mar 2015 00:03:30 +0100
Subject: [R] R Help
In-Reply-To: <28315EE2E6C18C4EAF42C7EFEC72DD8C1997A273@mike.isis.unige.ch>
References: <28315EE2E6C18C4EAF42C7EFEC72DD8C1997A273@mike.isis.unige.ch>
Message-ID: <54F4EC42.1000802@statistik.tu-dortmund.de>

Better ask for local help if you can't reduce your code to some minimal 
examples so that we can understand easily what you are looking for.


On 02.03.2015 10:38, Rami Alzebdieh wrote:
> Dear Sir,
>
> I start using (R) 3 months ago,  and I am still learning,

Same for me .... after more than 16 years.

Best,
Uwe Ligges




 > I have a project and I am using R in this project, my friend helped 
me to build a code for this project and it's working perfect, but I need 
to make a small change in, it looks very simple but for me it's very 
complicated. I insert the code and I hope if you can help me this 
problem. I highlighted what exactly I need to change. This project is 
calculating the market and industry weighted returns for each based on 
the date levels.
>
> sync = read.csv("country-14.csv",header=T)
> id.country = 14
>
> sync = sync[sync$country!="country" & sync$country==id.country,-c(2,5)]
> sync$price=as.numeric(as.character(sync$price))
> sync$mv=as.numeric(as.character(sync$mv))
> attach(sync)
>
> #### Calculate returns and add to the dataset
> n.comp = nlevels(as.factor(as.character(sync$company_name)))
> comp.names = levels(as.factor(as.character(sync$company_name)))
> data = vector("list",n.comp)
> for(i in 1:n.comp){
>    temp = sync[sync$company_name==comp.names[i],]
>    data[[i]] = cbind(temp,c(NA,diff(temp$price)/temp$price[1:(length(temp$price)-1)]))
> }
> sync = do.call(rbind,data)
> names(sync)[7] = "returns"
> detach(sync)
> attach(sync)
>
> #### Fill industry_code column
> industry_code=rep(NA,dim(sync)[1])
> for(i in 1:dim(sync)[1]){
>    if(nchar(as.character(company_code[i])) == 3){
>      industry_code[i] = as.numeric(substr(as.character(company_code[i]),1,1))
>    } else {
>      industry_code[i] = as.numeric(substr(as.character(company_code[i]),1,2))
>    }
>    print((i/dim(sync)[1])*100)
> }
> sync = cbind(sync,as.factor(industry_code))
> names(sync)[8] = "industry_code"
> detach(sync)
> attach(sync)
>
> #### Calculate market weighted returns and add to the dataset
> market_returns = rep(NA,dim(sync)[1])
> industry_returns = rep(NA,dim(sync)[1])
> for(i in 1:nlevels(date)){
>      data = sync[date==levels(date)[i],]
>      data$company_name = as.factor(as.character(data$company_name))
>      for(m in 1:nlevels(data$company_name)){
>        index1 = data$company_name == levels(data$company_name)[m]
>        index2 = date==levels(date)[i] & company_name==levels(data$company_name)[m]
>        market_returns[index2] = (sum(data$returns*(data$mv/sum(data$mv,na.rm=TRUE)),na.rm=TRUE) -
>          (data$returns[index1]*(data$mv[index1]/sum(data$mv,na.rm=TRUE))))/(nlevels(data$company_name)-1) ## this what I need to change, instead of using the number of levels companies in the dataset (nlevels(data$company_name) , I need to put the number of returns values(data$returns) without NA (by the way this code is calculating returns at the date level as you can see from above)
>      }
>    print(i/nlevels(date))
> }
>
> sync = cbind(sync,market_returns)
> names(sync)[9] = "market_returns"
> detach(sync)
> attach(sync)
>
> #### Calculate industry weighted returns and add to the dataset
> for(i in 1:nlevels(date)){
>      for(k in 1:nlevels(as.factor(as.character(industry_code)))){
>        data1 = sync[date==levels(date)[i] & industry_code==levels(as.factor(as.character(industry_code)))[k],]
>        data1$company_name = as.factor(as.character(data1$company_name))
>        for(l in 1:nlevels(data1$company_name)){
>          index3 = data1$company_name == levels(data1$company_name)[l]
>          index4 = date==levels(date)[i] & company_name==levels(data1$company_name)[l]
>          industry_returns[index4] = (sum(data1$returns*(data1$mv/sum(data1$mv,na.rm=TRUE)),na.rm=TRUE) -
>            (data1$returns[index3]*(data1$mv[index3]/sum(data1$mv,na.rm=TRUE))))/(nlevels(data1$company_name)-1) ## also here I need to change, instead of using the number of levels companies in the dataset (nlevels(data1$company_name) , I need to put the number of returns values(data1$returns) without NA (by the way this code is calculating returns at the date level and industry level as you can see from above)
>
>        }
>      }
>    print(i/nlevels(date))
> }
>
> sync = cbind(sync,industry_returns)
> names(sync)[10] = "industry_returns"
> detach(sync)
> attach(sync)
>
> year = apply(as.matrix(sync$date),1,function(x) as.factor(substr(as.character(x),7,10)))
> sync = cbind(sync,as.factor(year))
> names(sync)[11] = "year"
> sync = sync[sync$year!="1999",]
> sync$year = as.factor(as.character(sync$year))
> detach(sync)
> attach(sync)
>
> year = as.factor(as.character(year))
> industry_code = as.factor(as.character(industry_code))
> comp.per.ind = rep(NA, dim(sync)[1])
> for(i in 1:nlevels(year)){
>    for(j in 1:nlevels(industry_code)){
>      index = year==levels(year)[i] & industry_code==levels(industry_code)[j]
>      data = sync[index,]
>      comp.per.ind[index] = nlevels(as.factor(as.character(data$company_name)))
>    }
> }
>
> sync = cbind(sync,as.factor(comp.per.ind))
> names(sync)[12] = "comp.per.ind"
> detach(sync)
> attach(sync)
>
> write.csv(sync,paste("Returns_data",id.country,".csv",sep=""))
>
>
>
>
> Thank you for your help
>
> Rami Alzebdieh
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From js.huang at protective.com  Mon Mar  2 23:40:29 2015
From: js.huang at protective.com (JS Huang)
Date: Mon, 2 Mar 2015 14:40:29 -0800 (PST)
Subject: [R] Sum upto every twelth cell in a column
In-Reply-To: <1425182022055-4704007.post@n4.nabble.com>
References: <1425182022055-4704007.post@n4.nabble.com>
Message-ID: <1425336029309-4704087.post@n4.nabble.com>

Here is an implementation.

> (x <-
> c(23,35,22,11,10,1,14,15,13,15,17,16,154,13,24,25,25,25,25,25,22,11,15,15))
 [1]  23  35  22  11  10   1  14  15  13  15  17  16 154  13  24  25  25  25 
25  25  22  11  15  15
> (y <- c(0,cumsum(x)))
 [1]   0  23  58  80  91 101 102 116 131 144 159 176 192 346 359 383 408 433
458 483 508 530 541 556
[25] 571
> (y[seq(13,length(y),12)] - y[seq(1,length(y)-12,12)])
[1] 192 379



--
View this message in context: http://r.789695.n4.nabble.com/Sum-upto-every-twelth-cell-in-a-column-tp4704007p4704087.html
Sent from the R help mailing list archive at Nabble.com.


From scolwell at uoguelph.ca  Tue Mar  3 01:11:21 2015
From: scolwell at uoguelph.ca (Scott Colwell)
Date: Mon, 2 Mar 2015 16:11:21 -0800 (PST)
Subject: [R] Looping and break
Message-ID: <1425341481646-4704093.post@n4.nabble.com>

Hello,

I apologies for bringing up next and break in loops given that there is so
much on the net about it, but I've tried numerous examples found using
Google and just can't seem to get this to work.

This is a simple version of what I am doing with matrices but it shows the
issue. I need to have the loop indexed as n to perform a calculation on the
variable total. But if "total" is greater than 8, it goes to the next loop
indexed "a".  For example, it does condition a = 1 for n = 1 to 50 but
within n if total is greater than 8 it goes to the next condition of a which
would be a = 2, and so on.

for (a in 1:3){
  
  if (a == 1) { b <- c(1:5) }
  if (a == 2) { b <- c(1:5) }
  if (a == 3) { b <- c(1:5) }
  
  for (n in 1:50){
  
     if (n > 15) next
    
     total <- 2*b
  
     if (total > 8) next
    
  }
}

Any help would be greatly appreciated.

Thanks,

Scott



--
View this message in context: http://r.789695.n4.nabble.com/Looping-and-break-tp4704093.html
Sent from the R help mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Tue Mar  3 01:49:23 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 02 Mar 2015 19:49:23 -0500
Subject: [R] Installed R to Windows, but having trouble with read.csv
In-Reply-To: <8CFBF20CB9E9C348A283BAB1A16869A547F98592@exmbx1>
References: <8CFBF20CB9E9C348A283BAB1A16869A547F98592@exmbx1>
Message-ID: <54F50513.2010207@gmail.com>

On 02/03/2015 11:53 AM, Mello Cavallo, Alice wrote:
> I copied the file into the bin folder of R ...
> 
> 
> 
>> perf_data <- read.csv("PerfResultsCSv.csv")
> Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>   cannot open file 'PerfResultsCSv.csv': No such file or directory
> 
> I also installed and load RWeka package, but canot open.
> 
> 
> 
> It seems like I am having some issue of directories...
> 
> I am new to R, any help appreciated.

Setting the filename using the file.choose() function is usually
easiest.  I.e.

f <- file.choose()
perf_data <- read.csv(f)

You'll get the usual file choose dialog (at least in Windows and OSX;
not sure about Linux) when file.choose() runs and can navigate to the
file.  The full name including path will be saved in f.

Duncan Murdoch


From jdnewmil at dcn.davis.CA.us  Tue Mar  3 03:04:46 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 02 Mar 2015 18:04:46 -0800
Subject: [R] Looping and break
In-Reply-To: <1425341481646-4704093.post@n4.nabble.com>
References: <1425341481646-4704093.post@n4.nabble.com>
Message-ID: <DBCAA1BB-B745-411B-98AD-C560DDD93D9B@dcn.davis.CA.us>

Your example is decidedly not expressed in R, though it looks like you tried. Can you provide the hand-computed result that you are trying to obtain?

Note that the reason you cannot find anything about next or break in R is that they don't exist. There are generally alternative ways to accomplish the kinds of things you might want to accomplish without them, and those alternatives often don't involve explicit loops at all.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 2, 2015 4:11:21 PM PST, Scott Colwell <scolwell at uoguelph.ca> wrote:
>Hello,
>
>I apologies for bringing up next and break in loops given that there is
>so
>much on the net about it, but I've tried numerous examples found using
>Google and just can't seem to get this to work.
>
>This is a simple version of what I am doing with matrices but it shows
>the
>issue. I need to have the loop indexed as n to perform a calculation on
>the
>variable total. But if "total" is greater than 8, it goes to the next
>loop
>indexed "a".  For example, it does condition a = 1 for n = 1 to 50 but
>within n if total is greater than 8 it goes to the next condition of a
>which
>would be a = 2, and so on.
>
>for (a in 1:3){
>  
>  if (a == 1) { b <- c(1:5) }
>  if (a == 2) { b <- c(1:5) }
>  if (a == 3) { b <- c(1:5) }
>  
>  for (n in 1:50){
>  
>     if (n > 15) next
>    
>     total <- 2*b
>  
>     if (total > 8) next
>    
>  }
>}
>
>Any help would be greatly appreciated.
>
>Thanks,
>
>Scott
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Looping-and-break-tp4704093.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Tue Mar  3 03:23:57 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 03 Mar 2015 15:23:57 +1300
Subject: [R] Looping and break
In-Reply-To: <DBCAA1BB-B745-411B-98AD-C560DDD93D9B@dcn.davis.CA.us>
References: <1425341481646-4704093.post@n4.nabble.com>
	<DBCAA1BB-B745-411B-98AD-C560DDD93D9B@dcn.davis.CA.us>
Message-ID: <54F51B3D.30604@auckland.ac.nz>

On 03/03/15 15:04, Jeff Newmiller wrote:
> Your example is decidedly not expressed in R, though it looks like
> you tried. Can you provide the hand-computed result that you are
> trying to obtain?
>
> Note that the reason you cannot find anything about next or break in
> R is that they don't exist.

Point of order, Mr. Chairman, but they ***do*** exist.  See e.g ?"next" 
(which actually takes you to the help for "Control Flow").

> There are generally alternative ways to
> accomplish the kinds of things you might want to accomplish without
> them, and those alternatives often don't involve explicit loops at
> all.

Otherwise I concur with everything you say.

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From jdnewmil at dcn.davis.CA.us  Tue Mar  3 04:08:12 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 02 Mar 2015 19:08:12 -0800
Subject: [R] Looping and break
In-Reply-To: <54F51B3D.30604@auckland.ac.nz>
References: <1425341481646-4704093.post@n4.nabble.com>
	<DBCAA1BB-B745-411B-98AD-C560DDD93D9B@dcn.davis.CA.us>
	<54F51B3D.30604@auckland.ac.nz>
Message-ID: <6AD99ECB-C60C-4A9B-A4A5-23C105F93668@dcn.davis.CA.us>

Sigh. To be positive is to be wrong at the top of one's lungs. Next I will be told R has a goto statement.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 2, 2015 6:23:57 PM PST, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>On 03/03/15 15:04, Jeff Newmiller wrote:
>> Your example is decidedly not expressed in R, though it looks like
>> you tried. Can you provide the hand-computed result that you are
>> trying to obtain?
>>
>> Note that the reason you cannot find anything about next or break in
>> R is that they don't exist.
>
>Point of order, Mr. Chairman, but they ***do*** exist.  See e.g ?"next"
>
>(which actually takes you to the help for "Control Flow").
>
>> There are generally alternative ways to
>> accomplish the kinds of things you might want to accomplish without
>> them, and those alternatives often don't involve explicit loops at
>> all.
>
>Otherwise I concur with everything you say.
>
>cheers,
>
>Rolf


From r.turner at auckland.ac.nz  Tue Mar  3 04:23:01 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 03 Mar 2015 16:23:01 +1300
Subject: [R] Looping and break
In-Reply-To: <6AD99ECB-C60C-4A9B-A4A5-23C105F93668@dcn.davis.CA.us>
References: <1425341481646-4704093.post@n4.nabble.com>
	<DBCAA1BB-B745-411B-98AD-C560DDD93D9B@dcn.davis.CA.us>
	<54F51B3D.30604@auckland.ac.nz>
	<6AD99ECB-C60C-4A9B-A4A5-23C105F93668@dcn.davis.CA.us>
Message-ID: <54F52915.40200@auckland.ac.nz>


On 03/03/15 16:08, Jeff Newmiller wrote:

> Sigh. To be positive is to be wrong at the top of one's lungs. Next I
> will be told R has a goto statement.

I am ***positive*** that it hasn't! :-)  Well, 99.999% confident. 
Although I guess it's not inconceivable that some misguided nerd might 
construct one.  In R all things are possible.  It'd be tough, but, in 
view of the fact that "statements" are not identified/identifiable in R 
so it would be hard to tell the code, uh, where to go.

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From glennmschultz at me.com  Tue Mar  3 04:01:02 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Tue, 03 Mar 2015 03:01:02 +0000 (GMT)
Subject: [R] vectorize data string analysis
Message-ID: <77eec0ce-e9d3-496d-b9ff-5a84303c7566@me.com>

Hello All,

I have to admit that I am not that good when it comes to vectorizing a function. ?I need some insight. ?Is the below a case where vectorization can be accomplished to improve speed?

Below the function a sample data - as you can see it is not delimited. ?However, the record length is 220 characters. ?So I wrote the following code to delimit the data set "/r". ?The function works and I have a dataset that can then be inserted into a MySql data table. ?However, the actual data set is 518,000 records so the number of characters is 518000 * 220. ?It takes R hours to parse this using the function I have written. ?Can this be vectorized or is this a loop deal?

Best Regards,
Glenn ?

#' FNMA Factor
? #'?
? #' This function parses the FNMA factor file for load into
? #' into a database table the FNMA factor file is non-delimited
? #' @param filepath A character vector specifying a data director
? #' @param lenght of the line A numeric value equal to the length of a line
? #' @export
? FNMAFactor <- function(filepath = character){
? callpath <- paste(filepath,"mbsfact.txt", sep = "")
? returnpath <- paste(filepath,"factor.txt", sep = "")
? data <- readLines(con = callpath)
? numchar <- nchar(data, type = "chars")
? start <- c(seq(1, numchar, 220))
? end <- c(seq(220, numchar, 220))
? for(i in 1 : length(start)){
? write(str_sub(data, start[i], end[i]), file = returnpath, append = TRUE)}
? }



31365EJ46 CI125483 ?00002003473100OCT03000003103340610.1548980406.500030197040112180MULTIPLE POOL ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?00000070147FNMS 06.500 CI12548307017009600000000031371KMA6 CL254253 ?00001304570700OCT03000010156865640.7785600006.000030102030132357MULTIPLE POOL ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?00000067230FNMS 06.000 CL25425306715033300000000031371RE44 CL259455 ?00000983651400OCT03000003447615880.3504916406.500050102050132357MULTIPLE POOL ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?00000070200FNMS 06.500 CL25945507045034000000000031376KBB1 CL357434 ?00002505145900OCT03000025021294240.9987958905.000090103090133359MULTIPLE POOL ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?00000055000FNMS 05.000 CL35743405500035800000000031385XE52 WS555556 ?00003651248300OCT03000033344198060.9132273504.575050103050133356MEGA POOL ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ** NOT AN ACTIVE SERVICER ** ? ? ? ? ? ? ? ? ? 00000052440FNAR 04.595 WS55555600000000000000000031385XLL9 WS555731 ?00013439369600OCT03000129242191330.9616685505.360080103040133352MEGA POOL ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ** NOT AN ACTIVE SERVICER ** ? ? ? ? ? ? ? ? ? 00000075160FNAR 05.368 WS55573100000000000000000031390XG87 CI659123 ?00000208856500OCT03000001136251660.5440346206.000080102080117179WASHINGTON MUTUAL BANK, FA ? ? ? ? ? ? ?19850 PLUMMER STREET ? ? ? ? ?CHATSWORTH ? ? CA91311069210FNMS 06.000 CI65912306909016500000000031403BTR4 CL744060 ?00000770371700OCT03000007694084860.9987496805.000090103080133356MULTIPLE POOL ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?00000053920FNMS 05.000 CL74406000000000000000000031403GND0 LB748388 ?00000952312900OCT03000009512089400.9988407604.525090103080133358DLJ MORTGAGE CAPITAL INC. ? ? ? ? ? ? ? ELEVEN MADISON AVENUE ? ? ? ? NEW YORK ? ? ? NY10010058430FNAR XX.XXX LB74838800000000000000000031403GNG3 LB748391 ?00000715661500OCT03000007007212290.9791238304.379090103080133358DLJ MORTGAGE CAPITAL INC. ? ? ? ? ? ? ? ELEVEN MADISON AVENUE ? ? ? ? NEW YORK ? ? ? NY10010056530FNAR XX.XXX LB748391000000000000000000

From js.huang at protective.com  Tue Mar  3 01:07:22 2015
From: js.huang at protective.com (JS Huang)
Date: Mon, 2 Mar 2015 16:07:22 -0800 (PST)
Subject: [R] Sorting data frame by prepared order
In-Reply-To: <1425247108502-4704038.post@n4.nabble.com>
References: <1425247108502-4704038.post@n4.nabble.com>
Message-ID: <1425341242772-4704092.post@n4.nabble.com>

Here is an implementation.

> t <-
> data.frame(x=c(1,1,1,1,1,2,2,2,2,2),y=c("a","a","a","b","b","a","a","b","b","b"))
> t
   x y
1  1 a
2  1 a
3  1 a
4  1 b
5  1 b
6  2 a
7  2 a
8  2 b
9  2 b
10 2 b
> assignSeq
function(test)
{
  temp <- test[order(test$x),]
  InC <- numeric(length(test))
  inD <- unique(test$x)
  countAll <- 0
  for (i in 1:length(inD))
  {
    countA <- 0
    countB <- 0
    for (j in 1:dim(temp[temp$x==inD[i],])[1])
    {
      countAll <- countAll + 1
      if (temp$y[countAll] == "a")
      {
        InC[countAll] <- 2*countA
        countA <- countA + 1
      }
      else
      {
        InC[countAll] <- 2*countB + 1
        countB <- countB + 1
      }
    }
  }
  temp$seq <- InC
  return(temp)
}
> d <- assignSeq(t)
> d[order(d$x,d$seq),-3]
   x y
1  1 a
4  1 b
2  1 a
5  1 b
3  1 a
6  2 a
8  2 b
7  2 a
9  2 b
10 2 b



--
View this message in context: http://r.789695.n4.nabble.com/Sorting-data-frame-by-prepared-order-tp4704038p4704092.html
Sent from the R help mailing list archive at Nabble.com.


From drjimlemon at gmail.com  Tue Mar  3 09:06:47 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 3 Mar 2015 19:06:47 +1100
Subject: [R] table
In-Reply-To: <20150302153150.65894iss8h5tsxbq@webmail.sld.cu>
References: <20150302153150.65894iss8h5tsxbq@webmail.sld.cu>
Message-ID: <CA+8X3fXMGzpgZWPmQkOTFHEhz4BZ0+vsza-+PKxedsEWGLpukg@mail.gmail.com>

Hi maicel,
This may be completely off the mark, but the brkdnNest function in the
plotrix package can produce a nested list of counts which can be
transformed into percents (100*count/total).

require(plotrix)
data$dummy<-1
brkdnNest(dummy~Provincial+Municipios+unit,data,FUN="sum")

The counts in your example are mostly NA as most cells are empty.

Jim

On Tue, Mar 3, 2015 at 7:31 AM, <maicel at infomed.sld.cu> wrote:

> Hello List,
>
> I am trying to obtain a table containing absolute and relative frequencies
> but it must be done by strata. Each strata have to contain totals and
> subtotals being the sum of the subtotals equal to the total in upper strata
> in same column. As this could be some vague I am including an example of
> such table:
>
>
> data<-data.frame(Provincial=rep(c("Prov1","Prov2","Prov1","Prov3"),10),
> Municipios=rep(c("Mun1","Mun2","Mun3","Mun4"),10),unit=rep(
> c("unit1","unit2","unit3","unit4"),10))
>
> Variable        N       %
> Province (i)
> Municipalities (j)
> Health units (k)
> &#8721;i,  &#8721;j, &#8721;k
> And so on ? i = 1 to 16
>
> &#8721;i,  &#8721;j, &#8721;k
>
> If you could help me to obtain a function to get such table I would
> appreciate very much.
>
> Best and thank you?.
> maicel monzon MD. MSc.
>
>
>
> ----------------------------------------------------------------
>
>
>
>
> --
> Este mensaje le ha llegado mediante el servicio de correo electronico que
> ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema
> Nacional de Salud. La persona que envia este correo asume el compromiso de
> usar el servicio a tales fines y cumplir con las regulaciones establecidas
>
> Infomed: http://www.sld.cu/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Mar  3 09:20:11 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 03 Mar 2015 00:20:11 -0800
Subject: [R] How to speed up a double loop?
In-Reply-To: <1425305564921-4704061.post@n4.nabble.com>
References: <1425294674325-4704054.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C22250@SRVEXCHMBX.precheza.cz>
	<1425305564921-4704061.post@n4.nabble.com>
Message-ID: <8445A742-9DB1-4D49-8D52-820869E92AE4@dcn.davis.CA.us>

Usually there is some trick with diff or role or cumsum that can make something like this work, but all I can come up with is using Rcpp to brute force it. That works best if you create a package, but it can work okay without it if this is a one-off analysis.

Note that demolishing data as in your example makes most statisticians uncomfortable.. particularly in the name of removing outliers. I would recommend creating a quality check column and then perhaps subsetting into a new data frame if you felt it was necessary.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 2, 2015 6:12:44 AM PST, jeff6868 <geoffrey_klein at etu.u-bourgogne.fr> wrote:
>Hi Petr,
>
>Thanks for your reply,
>
>Actually it's not what I'm looking for. The aim is not simply to remove
>each
>value > 15. 
>
>In my loop, I consider the first numeric value of my column as
>"correct".
>Then, I want to test the second value. If the absolute difference with
>the
>previous correct one is <15, it's a new correct one, but if it's >15,
>then
>it's a wrong one. 
>If it's a wrong one, it has to test the third one to check if it's
>still >15
>from the last correct value (first one).
>The value becomes correct again when the difference with the last
>correct
>one goes under 15 (and so, this value is the new "correct" one, and so
>one
>for the rest of the column).
>
>My loop is already doing the trick, but I just want to speed it up (or
>maybe
>another faster way to do the job).
>Hope it's more understandable right now! 
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/How-to-speed-up-a-double-loop-tp4704054p4704061.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Mar  3 09:26:51 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 03 Mar 2015 00:26:51 -0800
Subject: [R] table
In-Reply-To: <20150302153150.65894iss8h5tsxbq@webmail.sld.cu>
References: <20150302153150.65894iss8h5tsxbq@webmail.sld.cu>
Message-ID: <35C6F6EB-6C30-4A3A-B0FD-65E287CD51AF@dcn.davis.CA.us>

I suspect that the tabular function in the tables package would handle this task.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 2, 2015 12:31:50 PM PST, maicel at infomed.sld.cu wrote:
>Hello List,
>
>I am trying to obtain a table containing absolute and relative  
>frequencies but it must be done by strata. Each strata have to contain 
>
>totals and subtotals being the sum of the subtotals equal to the total 
>
>in upper strata in same column. As this could be some vague I am  
>including an example of such table:
>
>
>data<-data.frame(Provincial=rep(c("Prov1","Prov2","Prov1","Prov3"),10),
> 
>Municipios=rep(c("Mun1","Mun2","Mun3","Mun4"),10),unit=rep(c("unit1","unit2","unit3","unit4"),10))
>
>Variable 	N	%
>Province (i)
>Municipalities (j)
>Health units (k)
>&#8721;i,  &#8721;j, &#8721;k
>And so on 
> i = 1 to 16
>
>&#8721;i,  &#8721;j, &#8721;k
>
>If you could help me to obtain a function to get such table I would  
>appreciate very much.
>
>Best and thank you
>.
>maicel monzon MD. MSc.
>
>
>
>----------------------------------------------------------------
>
>
>
>
>--
>Este mensaje le ha llegado mediante el servicio de correo electronico
>que ofrece Infomed para respaldar el cumplimiento de las misiones del
>Sistema Nacional de Salud. La persona que envia este correo asume el
>compromiso de usar el servicio a tales fines y cumplir con las
>regulaciones establecidas
>
>Infomed: http://www.sld.cu/
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From alaios at yahoo.com  Tue Mar  3 11:03:11 2015
From: alaios at yahoo.com (Alaios)
Date: Tue, 3 Mar 2015 10:03:11 +0000 (UTC)
Subject: [R] check a list that a sublist exists
Message-ID: <634849620.1742503.1425376991210.JavaMail.yahoo@mail.yahoo.com>

Hi all,I have a list that has the following fields.
$`80`
[1] "Error in if (fitcass1[[2]] == \"Error\") { : \n? Fehlender Wert, wo TRUE/FALSE n?tig ist\n"
attr(,"class")
[1] "try-error"
attr(,"condition")
<simpleError in if (fitcass1[[2]] == "Error") {??? print(sprintf("error at fitting gamma distribution with %s periods. Mean %f %f Sd %f %f",???????? flag, mean1, mean2, sd1, sd2))} else {??? return(fitcass1)}: Fehlender Wert, wo TRUE/FALSE n?tig ist>


$`81`
[1] 0

$`9`
[1] 0

$`79`
$parameters
??????????? pi?????????? mu??? sigma
1 0.9996796725???? 1.654832 127.6542
2 0.0003203275 17183.001125 302.8063

$se
???????? pi.se????? mu.se sigma.se
1 2.113882e-05? 0.1439152 14.22274
2 2.113882e-05 38.3582148????? NaN

$distribution
[1] "gamma"



and so one. The content of each first level sublist are never the same. I want for each first-level sublist my list has to check fast that the current element , lets say the 79th has the $parameters.then I would keep only the numbers from the sublists that have this $parameters inside them and skip all the rest.
I tried something like exists(Mylist[[i]]$parameters) but it does not workI also tried the is.numeric(Mylist[[i]]$parameters)) but this line fails when the current sublist does not contain the $parameters field.
Can you please help me sort this out?
RegardsAlex


	[[alternative HTML version deleted]]


From Gerrit.Eichner at math.uni-giessen.de  Tue Mar  3 11:44:25 2015
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 3 Mar 2015 11:44:25 +0100 (MET)
Subject: [R] check a list that a sublist exists
In-Reply-To: <634849620.1742503.1425376991210.JavaMail.yahoo@mail.yahoo.com>
References: <634849620.1742503.1425376991210.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <Pine.SOC.4.64.1503031141260.18091@solcom.hrz.uni-giessen.de>

Hello, Alaios,

try

is.null( Mylist[[i]]$parameters)

It returns TRUE if your list doesn't have a component named "parameters" 
or if that component contains NULL.

  HtH  --  Gerrit


On Tue, 3 Mar 2015, Alaios via R-help wrote:

> Hi all,I have a list that has the following fields.
> $`80`
> [1] "Error in if (fitcass1[[2]] == \"Error\") { : \n? Fehlender Wert, wo TRUE/FALSE n?tig ist\n"
> attr(,"class")
> [1] "try-error"
> attr(,"condition")
> <simpleError in if (fitcass1[[2]] == "Error") {??? print(sprintf("error at fitting gamma distribution with %s periods. Mean %f %f Sd %f %f",???????? flag, mean1, mean2, sd1, sd2))} else {??? return(fitcass1)}: Fehlender Wert, wo TRUE/FALSE n?tig ist>
>
>
> $`81`
> [1] 0
>
> $`9`
> [1] 0
>
> $`79`
> $parameters
> ??????????? pi?????????? mu??? sigma
> 1 0.9996796725???? 1.654832 127.6542
> 2 0.0003203275 17183.001125 302.8063
>
> $se
> ???????? pi.se????? mu.se sigma.se
> 1 2.113882e-05? 0.1439152 14.22274
> 2 2.113882e-05 38.3582148????? NaN
>
> $distribution
> [1] "gamma"
>
>
>
> and so one. The content of each first level sublist are never the same. I want for each first-level sublist my list has to check fast that the current element , lets say the 79th has the $parameters.then I would keep only the numbers from the sublists that have this $parameters inside them and skip all the rest.
> I tried something like exists(Mylist[[i]]$parameters) but it does not workI also tried the is.numeric(Mylist[[i]]$parameters)) but this line fails when the current sublist does not contain the $parameters field.
> Can you please help me sort this out?
> RegardsAlex
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From drjimlemon at gmail.com  Tue Mar  3 11:46:00 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 3 Mar 2015 21:46:00 +1100
Subject: [R] table
In-Reply-To: <35C6F6EB-6C30-4A3A-B0FD-65E287CD51AF@dcn.davis.CA.us>
References: <20150302153150.65894iss8h5tsxbq@webmail.sld.cu>
	<35C6F6EB-6C30-4A3A-B0FD-65E287CD51AF@dcn.davis.CA.us>
Message-ID: <CA+8X3fWgA2-guEnHgNLW11pAbM0UrS7Zb6iBo5aOWtVfwP2MhA@mail.gmail.com>

Hi Jeff,
I don't have that package, but reading the documentation, I think you are
right. Plus the tabular function already has the formatting worked out.

Jim


On Tue, Mar 3, 2015 at 7:26 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I suspect that the tabular function in the tables package would handle
> this task.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On March 2, 2015 12:31:50 PM PST, maicel at infomed.sld.cu wrote:
> >Hello List,
> >
> >I am trying to obtain a table containing absolute and relative
> >frequencies but it must be done by strata. Each strata have to contain
> >
> >totals and subtotals being the sum of the subtotals equal to the total
> >
> >in upper strata in same column. As this could be some vague I am
> >including an example of such table:
> >
> >
> >data<-data.frame(Provincial=rep(c("Prov1","Prov2","Prov1","Prov3"),10),
> >
>
> >Municipios=rep(c("Mun1","Mun2","Mun3","Mun4"),10),unit=rep(c("unit1","unit2","unit3","unit4"),10))
> >
> >Variable       N       %
> >Province (i)
> >Municipalities (j)
> >Health units (k)
> >&#8721;i,  &#8721;j, &#8721;k
> >And so on ?> i = 1 to 16
> >
> >&#8721;i,  &#8721;j, &#8721;k
> >
> >If you could help me to obtain a function to get such table I would
> >appreciate very much.
> >
> >Best and thank you?>.
> >maicel monzon MD. MSc.
> >
> >
> >
> >----------------------------------------------------------------
> >
> >
> >
> >
> >--
> >Este mensaje le ha llegado mediante el servicio de correo electronico
> >que ofrece Infomed para respaldar el cumplimiento de las misiones del
> >Sistema Nacional de Salud. La persona que envia este correo asume el
> >compromiso de usar el servicio a tales fines y cumplir con las
> >regulaciones establecidas
> >
> >Infomed: http://www.sld.cu/
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Mar  3 12:16:45 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 3 Mar 2015 11:16:45 +0000
Subject: [R] How to speed up a double loop?
In-Reply-To: <1425305564921-4704061.post@n4.nabble.com>
References: <1425294674325-4704054.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C22250@SRVEXCHMBX.precheza.cz>
	<1425305564921-4704061.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C223FA@SRVEXCHMBX.precheza.cz>

Hi

Removal outliers is quite tricky business and especially automatic removal of outliers. I have in some cases different approach.

If I know that some series is stationary and there are some dropouts in measurement (somebody disconnected it, process stopped for whatever reasons) I take large enough sequence, compute median (which shall be close to most of the points, set some arbitrary value for threshold and remove measurements which are behind this threshold. I then check my choice by visual inspection of plot.

So in your case

myts <- data.frame(x=c(1,2,50,40,30,40,100,1,50,1,2,3,3,5,4),y=NA)
selec <- abs(myts$x-median(myts$x))>15
myts$y[selec] <- myts$x[selec]
myts$x[selec] <- NA
> myts
    x   y
1   1  NA
2   2  NA
3  NA  50
4  NA  40
5  NA  30
6  NA  40
7  NA 100
8   1  NA
9  NA  50
10  1  NA
11  2  NA
12  3  NA
13  3  NA
14  5  NA
15  4  NA

So you either reconsider your outlier definition or you has to stick with Jeff's solution.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> jeff6868
> Sent: Monday, March 02, 2015 3:13 PM
> To: r-help at r-project.org
> Subject: Re: [R] How to speed up a double loop?
>
> Hi Petr,
>
> Thanks for your reply,
>
> Actually it's not what I'm looking for. The aim is not simply to remove
> each value > 15.
>
> In my loop, I consider the first numeric value of my column as
> "correct".
> Then, I want to test the second value. If the absolute difference with
> the previous correct one is <15, it's a new correct one, but if it's
> >15, then it's a wrong one.
> If it's a wrong one, it has to test the third one to check if it's
> still >15 from the last correct value (first one).
> The value becomes correct again when the difference with the last
> correct one goes under 15 (and so, this value is the new "correct" one,
> and so one for the rest of the column).
>
> My loop is already doing the trick, but I just want to speed it up (or
> maybe another faster way to do the job).
> Hope it's more understandable right now!
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-
> speed-up-a-double-loop-tp4704054p4704061.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From john.archie.mckown at gmail.com  Tue Mar  3 14:32:59 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 3 Mar 2015 07:32:59 -0600
Subject: [R] vectorize data string analysis
In-Reply-To: <77eec0ce-e9d3-496d-b9ff-5a84303c7566@me.com>
References: <77eec0ce-e9d3-496d-b9ff-5a84303c7566@me.com>
Message-ID: <CAAJSdji7-b33H5D6pDjWtVfQ84Ksb9o6HtSuU26ZiqkZmF+NMA@mail.gmail.com>

Have you looked at readChar() ? You can use it to read your input file
in undelimited chunks of 220 bytes, and at the same time, parse into
variable. Look at the example in the help ?readChar. Unfortunately I
can't really see exactly how the columns break, but I have your data
in a file: x.data in my case. And I accessed it as follows in R

> lengths<-c(9,9,66,40,30,15,2,5,6,4,8,26)
> close(zz)
> lengths<-c(9,9,66,40,30,15,2,5,6,4,8,26)
> sum(lengths)
[1] 220
> zz=file("x.data","rb")
> readChar(zz,lengths)
 [1] "31365EJ46"
 [2] " CI125483"
 [3] "  00002003473100OCT03000003103340610.1548980406.500030197040112180"
 [4] "MULTIPLE POOL                           "
 [5] "                              "
 [6] "               "
 [7] "  "
 [8] "00000"
 [9] "070147"
[10] "FNMS"
[11] " 06.500 "
[12] "CI125483070170096000000000"
> readChar(zz,lengths)
 [1] "31371KMA6"
 [2] " CL254253"
 [3] "  00001304570700OCT03000010156865640.7785600006.000030102030132357"
 [4] "MULTIPLE POOL                           "
 [5] "                              "
 [6] "               "
 [7] "  "
 [8] "00000"
 [9] "067230"
[10] "FNMS"
[11] " 06.000 "
[12] "CL254253067150333000000000"
> # a lot more of the above, and finally
> readChar(zz,lengths)
 [1] "31403GNG3"
 [2] " LB748391"
 [3] "  00000715661500OCT03000007007212290.9791238304.379090103080133358"
 [4] "DLJ MORTGAGE CAPITAL INC.               "
 [5] "ELEVEN MADISON AVENUE         "
 [6] "NEW YORK       "
 [7] "NY"
 [8] "10010"
 [9] "056530"
[10] "FNAR"
[11] " XX.XXX "
[12] "LB748391000000000000000000"
> readChar(zz,lengths)
[1] "\n"
> readChar(zz,lengths)
character(0)

Note that the next to last readChar got a "\n" simply because my
editor puts that at the end of the file. So it likely won't be there
in your file.

On Mon, Mar 2, 2015 at 9:01 PM, Glenn Schultz <glennmschultz at me.com> wrote:
> Hello All,
>
> I have to admit that I am not that good when it comes to vectorizing a
> function.  I need some insight.  Is the below a case where vectorization can
> be accomplished to improve speed?
>
> Below the function a sample data - as you can see it is not delimited.
> However, the record length is 220 characters.  So I wrote the following code
> to delimit the data set "/r".  The function works and I have a dataset that
> can then be inserted into a MySql data table.  However, the actual data set
> is 518,000 records so the number of characters is 518000 * 220.  It takes R
> hours to parse this using the function I have written.  Can this be
> vectorized or is this a loop deal?
>
> Best Regards,
> Glenn
>
> #' FNMA Factor
>   #'
>   #' This function parses the FNMA factor file for load into
>   #' into a database table the FNMA factor file is non-delimited
>   #' @param filepath A character vector specifying a data director
>   #' @param lenght of the line A numeric value equal to the length of a line
>   #' @export
>   FNMAFactor <- function(filepath = character){
>   callpath <- paste(filepath,"mbsfact.txt", sep = "")
>   returnpath <- paste(filepath,"factor.txt", sep = "")
>   data <- readLines(con = callpath)
>   numchar <- nchar(data, type = "chars")
>   start <- c(seq(1, numchar, 220))
>   end <- c(seq(220, numchar, 220))
>   for(i in 1 : length(start)){
>   write(str_sub(data, start[i], end[i]), file = returnpath, append = TRUE)}
>   }
>
>
>
> 31365EJ46 CI125483
> 00002003473100OCT03000003103340610.1548980406.500030197040112180MULTIPLE
> POOL
> 00000070147FNMS 06.500 CI12548307017009600000000031371KMA6 CL254253
> 00001304570700OCT03000010156865640.7785600006.000030102030132357MULTIPLE
> POOL
> 00000067230FNMS 06.000 CL25425306715033300000000031371RE44 CL259455
> 00000983651400OCT03000003447615880.3504916406.500050102050132357MULTIPLE
> POOL
> 00000070200FNMS 06.500 CL25945507045034000000000031376KBB1 CL357434
> 00002505145900OCT03000025021294240.9987958905.000090103090133359MULTIPLE
> POOL
> 00000055000FNMS 05.000 CL35743405500035800000000031385XE52 WS555556
> 00003651248300OCT03000033344198060.9132273504.575050103050133356MEGA POOL
> ** NOT AN ACTIVE SERVICER **                   00000052440FNAR 04.595
> WS55555600000000000000000031385XLL9 WS555731
> 00013439369600OCT03000129242191330.9616685505.360080103040133352MEGA POOL
> ** NOT AN ACTIVE SERVICER **                   00000075160FNAR 05.368
> WS55573100000000000000000031390XG87 CI659123
> 00000208856500OCT03000001136251660.5440346206.000080102080117179WASHINGTON
> MUTUAL BANK, FA              19850 PLUMMER STREET          CHATSWORTH
> CA91311069210FNMS 06.000 CI65912306909016500000000031403BTR4 CL744060
> 00000770371700OCT03000007694084860.9987496805.000090103080133356MULTIPLE
> POOL
> 00000053920FNMS 05.000 CL74406000000000000000000031403GND0 LB748388
> 00000952312900OCT03000009512089400.9988407604.525090103080133358DLJ MORTGAGE
> CAPITAL INC.               ELEVEN MADISON AVENUE         NEW YORK
> NY10010058430FNAR XX.XXX LB74838800000000000000000031403GNG3 LB748391
> 00000715661500OCT03000007007212290.9791238304.379090103080133358DLJ MORTGAGE
> CAPITAL INC.               ELEVEN MADISON AVENUE         NEW YORK
> NY10010056530FNAR XX.XXX LB748391000000000000000000
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown


From Roger.Bivand at nhh.no  Tue Mar  3 15:07:00 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 3 Mar 2015 14:07:00 +0000
Subject: [R] R crashes when I run rgeos::gDistance
References: <CAMBOG9MOceipr5YAWnQoKRjh2PZR5b8zEH9izsqLJqRDwZXHhw@mail.gmail.com>
Message-ID: <loom.20150303T145727-338@post.gmane.org>

Adrian Torchiana <adrian.torchiana <at> gmail.com> writes:

> 
> Hi,
> 
> This is my first post to R-help.  I'm having trouble getting rgeos to work.

R-help is arguably too general to help, please ask questions of this kind on
R-sig-geo.

> 
> Info on the server and packages I'm using:
> 
...
> $ *rpm -qa | grep geos*
> geos-devel-3.4.2-1.rhel6.x86_64
> geos-3.4.2-1.rhel6.x86_64
> 

How did you install rgeos (from source)? Are other versions of GEOS present
not installed as RPMs?

...
> $ *R -q*
> > *library(rgeos)*
> rgeos version: 0.3-8, (SVN revision 460)
>  GEOS runtime version: 3.4.2-CAPI-1.8.2 r3921
>  Polygon checking: TRUE
> 
> > *example(gDistance)*
> 
> gDstnc> pt1 = readWKT("POINT(0.5 0.5)")
> 
> gDstnc> pt2 = readWKT("POINT(2 2)")
> 
> gDstnc> p1 = readWKT("POLYGON((0 0,1 0,1 1,0 1,0 0))")
> 
> gDstnc> p2 = readWKT("POLYGON((2 0,3 1,4 0,2 0))")
> 
> gDstnc> gDistance(pt1,pt2)
> R: GeometryComponentFilter.cpp:34: virtual void
> geos::geom::GeometryComponentFilter::filter_ro(const
> geos::geom::Geometry*): Assertion `0' failed.
> Aborted (core dumped)

rgeos is tested regularly and frequently, so the issue here is on your
platform, I'm afraid.

> 
> I'd like to be able to use the gDistance function.  What should I do to fix
> this?

The simplest way is to install GEOS from source, because you avoid relying
on upstream packaging. This will however interfere with other software that
may depend on your existing GEOS. 

> 
> Please let me know if any additional information would be helpful.
> 
> Thank you for your time,
> 
> Adrian
> 
> 	[[alternative HTML version deleted]]
> 

Please do not post HTML.

Roger

>


From mukesh0290 at gmail.com  Tue Mar  3 07:34:17 2015
From: mukesh0290 at gmail.com (mukesh surywanshi)
Date: Tue, 3 Mar 2015 12:04:17 +0530
Subject: [R] Frontier efficient using black litterman model In R
Message-ID: <CAC2J0hrNwCrzXabr_+A6dBC8fo9OqGMVeQGeF-obDc6qfviaSg@mail.gmail.com>

Hi
I'm working on getting frontier efficient plot using Black Litterman model.

I have used Blcop package and its function

optimalPortfolio.optim()

using this i have got optimal risk and return with weights

If i want to get 10 portfolio risk and return with corresponding weights,,,
how to do it>?
 can anyone help me....


my code goes like this
posterior <- posteriorEst(views, tau = 0.025, meanret, covar)

cons <- c("minW[1:numtk] = rep(0, times = numtk)", "maxW[1:numtk] =
rep(0.50, times = numtk)","minsumW[1:numtk] = 0","maxsumW[1:numtk] = 1")
#"listF = list(lowerExtension, upperExtension)")

res1<-optimalPortfolios.fPort(posterior,
spec=portfolioSpec(),constraints=cons,optimizer =
"minriskPortfolio",numSimulations  = 10)



Thanks
MUKESH

	[[alternative HTML version deleted]]


From pilar.serrano at sacapacitacion.com  Tue Mar  3 07:01:15 2015
From: pilar.serrano at sacapacitacion.com (Pilar Serrano)
Date: Tue, 3 Mar 2015 00:01:15 -0600
Subject: [R] =?windows-1252?q?Reglamento_IMSS_Construcci=F3n_y_SATIC=92s?=
	=?windows-1252?q?=2E_11_marzo2015?=
Message-ID: <055bc6b5598fcb96b3c64b7b00230a7a@sacapacitacion.com>

?HARTO DE COBROS ESTIMATIVOS DE CUOTAS POR PARTE DEL IMSS AL FINALIZAR CADA OBRA DE CONSTRUCCI?N? 
  
Asista al Curso: 
  
APLICACI?N PR?CTICA DEL REGLAMENTO DEL SEGURO SOCIAL PARA CONSTRUCTORAS Y SUBCONTRATISTAS Y LOS FORMATOS SATIC 
  
??Qu? hacer ante los constantes cobros estimativos de cuotas que el Seguro Social pretende por cada obra de construcci?n?
?C?mo manejar adecuadamente los Formatos SATIC.
?Qu? hacer con subcontratistas y maestros de obra.
?Cu?l es el mejor procedimiento a seguir a la terminaci?n de cada obra.
?Y muchos otros temas adicionales.

 
  
Mi?rcoles 11 de Marzo del 2015, de 09:00 a 15:00 horas. 
  
MAYOR INFORMACI?N E INSCRIPCIONES:
Pilar Serrano
Tel. 2871.2174 y 5364.2319 
  
S?nchez Arellano Abogados.
Divisi?n Capacitaci?n.
Quer?taro No. 226, Desp. 4-B.
Col. Roma. Deleg. Cuauht?moc.
06700 M?xico, D.F. 
  
Consulte m?s detalles de ?ste y otros eventos en:
www sanchezarellanocapacitacion . com 
  
S?nchez Arellano Capacitaci?n posee una r?gida pol?tica contra el SPAMming, por lo que respetamos su privacidad. Por favor, si usted no desea recibir m?s informaci?n y comunicados sobre S?nchez Arellano Capacitaci?n o considera que recibi? por error este e-mail, le suplicamos enviarnos un correo electr?nico a la direcci?n de donde provino el presente correo, poniendo en el asunto la palabra "Borrar" y lo daremos de baja inmediatamente de nuestra base de datos.



	[[alternative HTML version deleted]]


From Pascal.Niklaus at ieu.uzh.ch  Tue Mar  3 11:45:38 2015
From: Pascal.Niklaus at ieu.uzh.ch (Pascal A. Niklaus)
Date: Tue, 03 Mar 2015 11:45:38 +0100
Subject: [R] Rcpp module / class access
Message-ID: <54F590D2.2080601@ieu.uzh.ch>

Dear all,

I am struggling accessing a class created in an Rcpp module.

The structure of the package is essentially the one created using:

Rcpp.package.skeleton(name="testPackage",module=TRUE)


Now, after loadiong the package with library(testPackage), I can create 
instances of the "World" class as follows:

library(testPackage)
mod_yada<-Rcpp::Module("yada",PACKAGE="testPackage",mustStart=TRUE)
w <- new(mod_yada$World);

So far so good.


However, I fail defining a S4 wrapper class within the same package. As 
part of that, I would like to define a generator function that returns 
an instance of mod_yada$World, as in the code above:

However, "yada$World" is not accessible.

I then tried inserting the following line in the respective R file 
(although I thought this was already taken care by the 
"loadModule("yada", TRUE)" that was places in zzz.R by the skeleton 
generator:

mod_yada<-Rcpp::Module("yada",PACKAGE="testPackage",mustStart=TRUE)

But again, this fails with:

  Failed to initialize module pointer: Error in 
FUN("_rcpp_module_boot_mod_yada"[[1L]], ...): no such symbol 
_rcpp_module_boot_mod_yada in package testPackage


Putting this file after zzz.R in the Collate: list in the DESCRIPTION 
file also does not help.


How can I define this in the Rcpp package itself?


Thanks for any hint

Pascal Niklaus


From geoffrey_klein at etu.u-bourgogne.fr  Tue Mar  3 11:49:20 2015
From: geoffrey_klein at etu.u-bourgogne.fr (jeff6868)
Date: Tue, 3 Mar 2015 02:49:20 -0800 (PST)
Subject: [R] How to speed up a double loop?
In-Reply-To: <8445A742-9DB1-4D49-8D52-820869E92AE4@dcn.davis.CA.us>
References: <1425294674325-4704054.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C22250@SRVEXCHMBX.precheza.cz>
	<1425305564921-4704061.post@n4.nabble.com>
	<8445A742-9DB1-4D49-8D52-820869E92AE4@dcn.davis.CA.us>
Message-ID: <1425379760241-4704112.post@n4.nabble.com>

I tried another faster way which seems to do the trick right now:

    myts
<-data.frame(x=c(10,2,50,40,NA,NA,0,50,1,2,0,0,NA,50,0,15,3,5,4,20,0,0,25,22,0,1,100),z=NA) 
    
    test <- function(x){
    st1 <- numeric(length(x))
    temp <- st1[1]
    for (i in 2:(length(x))){ 
        if((!is.na(x[i])) & (!is.na(x[i-1]))& (abs((x[i])-(temp)) >= 15)){
    st1[i] <- 1
    } } 
    return(st1)
    }

    myts[,2] <- apply(as.data.frame(myts[,1]),2,test)  
    myts[,2] <- as.numeric(myts[,2])

Thanks anyway for your help!



--
View this message in context: http://r.789695.n4.nabble.com/How-to-speed-up-a-double-loop-tp4704054p4704112.html
Sent from the R help mailing list archive at Nabble.com.


From HDoran at air.org  Tue Mar  3 15:34:03 2015
From: HDoran at air.org (Doran, Harold)
Date: Tue, 3 Mar 2015 14:34:03 +0000
Subject: [R] readHTMLTable() in XML package
In-Reply-To: <CABdHhvFoo0C5N-yE4P-g3WdBx3FC33HWvw=cbrCg8e2bkPuJFg@mail.gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686CF3B78DB@DC1VEX10MB001.air.org>
	<CABdHhvFoo0C5N-yE4P-g3WdBx3FC33HWvw=cbrCg8e2bkPuJFg@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686CF3B96C8@DC1VEX10MB001.air.org>

Hadley

Thanks. I ran into the same roadblock when I use your code below by increasing i to loop over all pages. I think the problem is related to the fact that the website I'm scraping is getting hammered with users and the error is just related to a timeout.

I have provisionally solved my problem by wrapping in some try() statements in appropriate places and some conditional if/else statements to skip over steps if a timeout occurs. Not sure if this is elegant, but my sledgehammer approach is "working" now.



-----Original Message-----
From: Hadley Wickham [mailto:h.wickham at gmail.com] 
Sent: Monday, March 02, 2015 2:05 PM
To: Doran, Harold
Cc: r-help at r-project.org
Subject: Re: [R] readHTMLTable() in XML package

This somewhat simpler rvest code does the trick for me:

library(rvest)
library(dplyr)

i <- 1:10
urls <- paste0('http://games.crossfit.com/scores/leaderboard.php?stage=5',
  '&sort=0&division=1&region=0&numberperpage=100&competition=0&frontpage=0',
  '&expanded=1&year=15&full=1&showtoggles=0&hidedropdowns=0&showathleteac=1',
  '&is_mobile=0&page=', i)

results_table <- function(url) {
  url %>% html %>% html_table(fill = TRUE) %>% .[[1]] }

results <- lapply(urls, results_table)
out <- results %>% bind_rows()

Hadley

On Mon, Mar 2, 2015 at 10:00 AM, Doran, Harold <HDoran at air.org> wrote:
> I'm having trouble pulling down data from a website with my code below as I keep encountering the same error, but the error occurs on different pages.
>
> My code below loops through a wensite and grabs data from the html table. The error appears on different pages at different times and I'm not sure of the root cause.
>
> Error in readHTMLTable(readLines(url), which = 1, header = TRUE) :
>   error in evaluating the argument 'doc' in selecting a method for function 'readHTMLTable': Error in readHTMLTable(readLines(url), which = 1, header = TRUE) :
>   error in evaluating the argument 'doc' in selecting a method for function 'readHTMLTable':
>
> library(XML)
> for(i in 1:1000){
>                 url <- paste(paste('http://games.crossfit.com/scores/leaderboard.php?stage=5&sort=0&page=', i, sep=''), '&division=1&region=0&numberperpage=100&competition=0&frontpage=0&expanded=1&year=15&full=1&showtoggles=0&hidedropdowns=0&showathleteac=1&=&is_mobile=0', sep='')
>     tmp <- readHTMLTable(readLines(url), which=1, header=TRUE)
>                 names(tmp) <- gsub("\\n", "", names(tmp))
>                 names(tmp) <- gsub(" +", "", names(tmp))
>     tmp[] <- lapply(tmp, function(x) gsub("\\n", "", x))
>
>     if(i == 1){
>                 dat <- tmp
>                 } else {
>                 dat <- rbind(dat, tmp)
>                 }
>                 cat('Grabbing data from page', i, '\n')
>                 }
>
> Thanks,
> Harold
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
http://had.co.nz/

From phaedrusv at gmail.com  Tue Mar  3 15:43:39 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Tue, 03 Mar 2015 14:43:39 +0000
Subject: [R] Using a text file as a removeWord dictionary in tm_map
In-Reply-To: <54F41312.6000707@gmail.com>
References: <54F1C6BD.5000401@gmail.com>
	<CAAxdm-5zK167OtGg7ZE_zOr-V-7EM-Ys2hE5mMDeTd2CxHCrug@mail.gmail.com>
	<54F41312.6000707@gmail.com>
Message-ID: <54F5C89B.90308@gmail.com>

Hi again

I've now had the chance to try this out, and using scan() doesn't seem 
to work either.

This is what I used:

1) I generated a plain text file called stopDict.txt. This file is of 
the format: "a, bunch, of, words, to, use"

2) I invoked scan(), like this:
 > userStopList <- scan(text = '~/path/to/stopDict.txt', what = " ", sep 
= ",")

3) Then I used the externally generated list as stop words:
 > docs <- tm_map(docs, removeWords, userStopList)

3) When I go to inspect the document, at least two of the user-defined 
stop words are in the text

Is there a further argument I should be passing to scan(), or is the 
stopDict.txt file not set up the correct way? I tried each term 
separated by ' ' and ',', (e.g. 'all', 'the', 'text') but that didn't 
work, neither does it seem to work when the whole list is enclosed 
within quotes (e.g. "all, the, text").

While not critical to have the capacity to read in an externally 
generated list, it sure would be helpful.

Thanks.

Sun


On 02/03/15 07:36, Sun Shine wrote:
> Thanks Jim.
>
> I thought that I was passing a vector, not realising I had converted 
> this to a list object.
>
> I haven't come across the scan() function so far, so this is good to 
> know.
>
> Good explanation - I'll give this a go when I can get back to that 
> piece of work later today.
>
> Thanks again.
>
> Regards,
>
> Sun
>
>
> On 01/03/15 21:13, jim holtman wrote:
>> The 'read.table' was creating a data.frame (not a vector) and applying
>> 'c' to it converted it to a list.  You should alway look at the object
>> you are creating.  You probably want to use 'scan'.
>>
>> ======================
>>> testFile <- 
>>> "Although,this,query,applies,specifically,to,the,tm,package"
>>> # read in with read.table create a data.frame
>>> df_words <- read.table(text = testFile, sep = ',')
>>> df_words  # not a vector
>>          V1   V2    V3      V4           V5 V6  V7 V8      V9
>> 1 Although this query applies specifically to the tm package
>>> c(df_words)  # this results in a list
>> $V1
>> [1] Although
>> Levels: Although
>> $V2
>> [1] this
>> Levels: this
>> $V3
>> [1] query
>> Levels: query
>> $V4
>> [1] applies
>> Levels: applies
>> $V5
>> [1] specifically
>> Levels: specifically
>> $V6
>> [1] to
>> Levels: to
>> $V7
>> [1] the
>> Levels: the
>> $V8
>> [1] tm
>> Levels: tm
>> $V9
>> [1] package
>> Levels: package
>>> # now read with 'scan'
>>> scan_words <- scan(text = testFile, what = '', sep = ',')
>> Read 9 items
>>> scan_words
>> [1] "Although"     "this"         "query"        "applies"
>> "specifically" "to"
>> [7] "the"          "tm"           "package"
>>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>>
>> On Sat, Feb 28, 2015 at 8:46 AM, Sun Shine <phaedrusv at gmail.com> wrote:
>>> Hi list
>>>
>>> Although this query applies specifically to the tm package, perhaps 
>>> it's
>>> something that others might be able to lend a thought to.
>>>
>>> Using tm to do some initial text mining, I want to include an 
>>> external (to
>>> R) generated dictionary of words that I want removed from the corpus.
>>>
>>> I have created a comma separated list of terms in " " marks in a
>>> stopList.txt plain UTF-8 file. I want to read this into R, so do:
>>>
>>>> stopDict <- read.table('~/path/to/file/stopList.txt', sep=',')
>>> When I want to load it as part of the removeWords function in tm, I do:
>>>
>>>> docs <- tm_map(docs, removeWords, stopDict)
>>> which has no effect. Neither does:
>>>
>>>> docs <- tm_map(docs, removeWords, c(stopDict))
>>> What am I not seeing/ doing?
>>>
>>> How do I pass a text file with pre-defined terms to the removeWords
>>> transform of tm?
>>>
>>> Thanks for any ideas.
>>>
>>> Cheers
>>>
>>> Sun
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From ajaytalati at googlemail.com  Tue Mar  3 15:59:25 2015
From: ajaytalati at googlemail.com (AjayT)
Date: Tue, 3 Mar 2015 06:59:25 -0800 (PST)
Subject: [R] 2D Timeseries trace plot
Message-ID: <1425394765420-4704127.post@n4.nabble.com>

Hi,

I've got a 2D timeseries of handwriting samples, 

      x    y   time
1  1073 1058 769.05
2  1072 1085 769.07
3  1066 1117 769.08
4  1052 1152 769.10
5  1030 1196 769.12
6  1009 1242 769.13
7   994 1286 769.14

upto 500

I was just wondering how to plot this as an animation, so that the points
join up as they are rendered in time. Basically showing how the person who
generated the data writes. 

The time index is not regular and if possible I'd like to avoid padding the
data with duplicate entries if this is avoidable. For example adding a
duplicate of the first row, for a 'padded' time 769.06.

Thanks alot for your help :)  



--
View this message in context: http://r.789695.n4.nabble.com/2D-Timeseries-trace-plot-tp4704127.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Tue Mar  3 16:47:47 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 03 Mar 2015 07:47:47 -0800
Subject: [R] Using a text file as a removeWord dictionary in tm_map
In-Reply-To: <54F5C89B.90308@gmail.com>
References: <54F1C6BD.5000401@gmail.com>
	<CAAxdm-5zK167OtGg7ZE_zOr-V-7EM-Ys2hE5mMDeTd2CxHCrug@mail.gmail.com>
	<54F41312.6000707@gmail.com> <54F5C89B.90308@gmail.com>
Message-ID: <5A3B1859-AEFA-4CFC-A37D-C89FE07ECDEC@dcn.davis.CA.us>

You seem to be conflating the data input operation with your data processing. You need to stop and examine the in-memory representation of your data {"userStopList"), and compare it with the expectations of your data processing operation ("tm_map"). Then adjust your input data by choosing a different input function or change the parameters you are using, or add some manipulation step in between that "fixes" the data so it is suitable to the task.
Real world data analysis is rarely handled cleanly by one or two function calls. Take responsibility for insuring the quality of your data by looking at it.
I am not familiar with tm_map, but scan tends to be quite literal with your specification. I suspect that the elements in your userStopList have spaces in them because scan is not removing them, and tm_map is then only looking for instances in your text where spaces are present.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 3, 2015 6:43:39 AM PST, Sun Shine <phaedrusv at gmail.com> wrote:
>Hi again
>
>I've now had the chance to try this out, and using scan() doesn't seem 
>to work either.
>
>This is what I used:
>
>1) I generated a plain text file called stopDict.txt. This file is of 
>the format: "a, bunch, of, words, to, use"
>
>2) I invoked scan(), like this:
>> userStopList <- scan(text = '~/path/to/stopDict.txt', what = " ", sep
>
>= ",")
>
>3) Then I used the externally generated list as stop words:
> > docs <- tm_map (docs, removeWords, userStopList)
>
>3) When I go to inspect the document, at least two of the user-defined 
>stop words are in the text
>
>Is there a further argument I should be passing to scan(), or is the 
>stopDict.txt file not set up the correct way? I tried each term 
>separated by ' ' and ',', (e.g. 'all', 'the', 'text') but that didn't 
>work, neither does it seem to work when the whole list is enclosed 
>within quotes (e.g. "all, the, text").
>
>While not critical to have the capacity to read in an externally 
>generated list, it sure would be helpful.
>
>Thanks.
>
>Sun
>
>
>On 02/03/15 07:36, Sun Shine wrote:
>> Thanks Jim.
>>
>> I thought that I was passing a vector, not realising I had converted 
>> this to a list object.
>>
>> I haven't come across the scan() function so far, so this is good to 
>> know.
>>
>> Good explanation - I'll give this a go when I can get back to that 
>> piece of work later today.
>>
>> Thanks again.
>>
>> Regards,
>>
>> Sun
>>
>>
>> On 01/03/15 21:13, jim holtman wrote:
>>> The 'read.table' was creating a data.frame (not a vector) and
>applying
>>> 'c' to it converted it to a list.  You should alway look at the
>object
>>> you are creating.  You probably want to use 'scan'.
>>>
>>> ======================
>>>> testFile <- 
>>>> "Although,this,query,applies,specifically,to,the,tm,package"
>>>> # read in with read.table create a data.frame
>>>> df_words <- read.table(text = testFile, sep = ',')
>>>> df_words  # not a vector
>>>          V1   V2    V3      V4           V5 V6  V7 V8      V9
>>> 1 Although this query applies specifically to the tm package
>>>> c(df_words)  # this results in a list
>>> $V1
>>> [1] Although
>>> Levels: Although
>>> $V2
>>> [1] this
>>> Levels: this
>>> $V3
>>> [1] query
>>> Levels: query
>>> $V4
>>> [1] applies
>>> Levels: applies
>>> $V5
>>> [1] specifically
>>> Levels: specifically
>>> $V6
>>> [1] to
>>> Levels: to
>>> $V7
>>> [1] the
>>> Levels: the
>>> $V8
>>> [1] tm
>>> Levels: tm
>>> $V9
>>> [1] package
>>> Levels: package
>>>> # now read with 'scan'
>>>> scan_words <- scan(text = testFile, what = '', sep = ',')
>>> Read 9 items
>>>> scan_words
>>> [1] "Although"     "this"         "query"        "applies"
>>> "specifically" "to"
>>> [7] "the"          "tm"           "package"
>>>>
>>> Jim Holtman
>>> Data Munger Guru
>>>
>>> What is the problem that you are trying to solve?
>>> Tell me what you want to do, not how you want to do it.
>>>
>>>
>>> On Sat, Feb 28, 2015 at 8:46 AM, Sun Shine <phaedrusv at gmail.com>
>wrote:
>>>> Hi list
>>>>
>>>> Although this query applies specifically to the tm package, perhaps
>
>>>> it's
>>>> something that others might be able to lend a thought to.
>>>>
>>>> Using tm to do some initial text mining, I want to include an 
>>>> external (to
>>>> R) generated dictionary of words that I want removed from the
>corpus.
>>>>
>>>> I have created a comma separated list of terms in " " marks in a
>>>> stopList.txt plain UTF-8 file. I want to read this into R, so do:
>>>>
>>>>> stopDict <- read.table('~/path/to/file/stopList.txt', sep=',')
>>>> When I want to load it as part of the removeWords function in tm, I
>do:
>>>>
>>>>> docs <- tm_map(docs, removeWords, stopDict)
>>>> which has no effect. Neither does:
>>>>
>>>>> docs <- tm_map(docs, removeWords, c(stopDict))
>>>> What am I not seeing/ doing?
>>>>
>>>> How do I pass a text file with pre-defined terms to the removeWords
>>>> transform of tm?
>>>>
>>>> Thanks for any ideas.
>>>>
>>>> Cheers
>>>>
>>>> Sun
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Tue Mar  3 18:04:37 2015
From: jholtman at gmail.com (Jim Holtman)
Date: Tue, 03 Mar 2015 12:04:37 -0500
Subject: [R] Using a text file as a removeWord dictionary in tm_map
Message-ID: <j876ty8yjvcjxagq7jh4kr6c.1425402277564@email.android.com>

Send me a copy of your file so I can see what it looks like and what the output should be.


Sent from my Verizon Wireless 4G LTE Smartphone

<div>-------- Original message --------</div><div>From: Sun Shine <phaedrusv at gmail.com> </div><div>Date:03/03/2015  09:43  (GMT-05:00) </div><div>To: jim holtman <jholtman at gmail.com> </div><div>Cc: r-help <r-help at r-project.org> </div><div>Subject: Re: [R] Using a text file as a removeWord dictionary in tm_map </div><div>
</div>Hi again

I've now had the chance to try this out, and using scan() doesn't seem 
to work either.

This is what I used:

1) I generated a plain text file called stopDict.txt. This file is of 
the format: "a, bunch, of, words, to, use"

2) I invoked scan(), like this:
> userStopList <- scan(text = '~/path/to/stopDict.txt', what = " ", sep 
= ",")

3) Then I used the externally generated list as stop words:
> docs <- tm_map(docs, removeWords, userStopList)

3) When I go to inspect the document, at least two of the user-defined 
stop words are in the text

Is there a further argument I should be passing to scan(), or is the 
stopDict.txt file not set up the correct way? I tried each term 
separated by ' ' and ',', (e.g. 'all', 'the', 'text') but that didn't 
work, neither does it seem to work when the whole list is enclosed 
within quotes (e.g. "all, the, text").

While not critical to have the capacity to read in an externally 
generated list, it sure would be helpful.

Thanks.

Sun


On 02/03/15 07:36, Sun Shine wrote:
> Thanks Jim.
>
> I thought that I was passing a vector, not realising I had converted 
> this to a list object.
>
> I haven't come across the scan() function so far, so this is good to 
> know.
>
> Good explanation - I'll give this a go when I can get back to that 
> piece of work later today.
>
> Thanks again.
>
> Regards,
>
> Sun
>
>
> On 01/03/15 21:13, jim holtman wrote:
>> The 'read.table' was creating a data.frame (not a vector) and applying
>> 'c' to it converted it to a list.  You should alway look at the object
>> you are creating.  You probably want to use 'scan'.
>>
>> ======================
>>> testFile <- 
>>> "Although,this,query,applies,specifically,to,the,tm,package"
>>> # read in with read.table create a data.frame
>>> df_words <- read.table(text = testFile, sep = ',')
>>> df_words  # not a vector
>>          V1   V2    V3      V4           V5 V6  V7 V8      V9
>> 1 Although this query applies specifically to the tm package
>>> c(df_words)  # this results in a list
>> $V1
>> [1] Although
>> Levels: Although
>> $V2
>> [1] this
>> Levels: this
>> $V3
>> [1] query
>> Levels: query
>> $V4
>> [1] applies
>> Levels: applies
>> $V5
>> [1] specifically
>> Levels: specifically
>> $V6
>> [1] to
>> Levels: to
>> $V7
>> [1] the
>> Levels: the
>> $V8
>> [1] tm
>> Levels: tm
>> $V9
>> [1] package
>> Levels: package
>>> # now read with 'scan'
>>> scan_words <- scan(text = testFile, what = '', sep = ',')
>> Read 9 items
>>> scan_words
>> [1] "Although"     "this"         "query"        "applies"
>> "specifically" "to"
>> [7] "the"          "tm"           "package"
>>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>>
>> On Sat, Feb 28, 2015 at 8:46 AM, Sun Shine <phaedrusv at gmail.com> wrote:
>>> Hi list
>>>
>>> Although this query applies specifically to the tm package, perhaps 
>>> it's
>>> something that others might be able to lend a thought to.
>>>
>>> Using tm to do some initial text mining, I want to include an 
>>> external (to
>>> R) generated dictionary of words that I want removed from the corpus.
>>>
>>> I have created a comma separated list of terms in " " marks in a
>>> stopList.txt plain UTF-8 file. I want to read this into R, so do:
>>>
>>>> stopDict <- read.table('~/path/to/file/stopList.txt', sep=',')
>>> When I want to load it as part of the removeWords function in tm, I do:
>>>
>>>> docs <- tm_map(docs, removeWords, stopDict)
>>> which has no effect. Neither does:
>>>
>>>> docs <- tm_map(docs, removeWords, c(stopDict))
>>> What am I not seeing/ doing?
>>>
>>> How do I pass a text file with pre-defined terms to the removeWords
>>> transform of tm?
>>>
>>> Thanks for any ideas.
>>>
>>> Cheers
>>>
>>> Sun
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Mar  3 18:12:32 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 3 Mar 2015 17:12:32 +0000
Subject: [R] 2D Timeseries trace plot
In-Reply-To: <1425394765420-4704127.post@n4.nabble.com>
References: <1425394765420-4704127.post@n4.nabble.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D660ADC@mb02.ads.tamu.edu>

You can do this with the animation package. Install the package and then

# Load the package
library(animation)
# This representation makes your data more portable using the dput() function:
pen <- structure(list(x = c(1073L, 1072L, 1066L, 1052L, 1030L, 1009L, 
    994L), y = c(1058L, 1085L, 1117L, 1152L, 1196L, 1242L, 1286L), 
    time = c(769.05, 769.07, 769.08, 769.1, 769.12, 769.13, 769.14
    )), .Names = c("x", "y", "time"), class = "data.frame", row.names = c("1", 
    "2", "3", "4", "5", "6", "7"))
# Compute the time between each step
diftime <- diff(pen$time)
# Draw a blank plot window using the ranges for x and y
with(pen, plot(NA, xlim=c(min(x), max(x)), ylim=c(min(y), max(y)),
    xlab="", ylab="", axes=FALSE))
# Pause for a second
ani.pause(1)
# Draw the curve pausing between points.
for(i in 1:6) {
	ani.pause(diftime[i]*10) # Multiply by ten to slow things down
	segments(pen$x[i], pen$y[i], pen$x[i+1], pen$y[i+1])
}

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of AjayT
Sent: Tuesday, March 3, 2015 8:59 AM
To: r-help at r-project.org
Subject: [R] 2D Timeseries trace plot

Hi,

I've got a 2D timeseries of handwriting samples, 

      x    y   time
1  1073 1058 769.05
2  1072 1085 769.07
3  1066 1117 769.08
4  1052 1152 769.10
5  1030 1196 769.12
6  1009 1242 769.13
7   994 1286 769.14

upto 500

I was just wondering how to plot this as an animation, so that the points
join up as they are rendered in time. Basically showing how the person who
generated the data writes. 

The time index is not regular and if possible I'd like to avoid padding the
data with duplicate entries if this is avoidable. For example adding a
duplicate of the first row, for a 'padded' time 769.06.

Thanks alot for your help :)  



--
View this message in context: http://r.789695.n4.nabble.com/2D-Timeseries-trace-plot-tp4704127.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mtb954 at gmail.com  Tue Mar  3 20:01:14 2015
From: mtb954 at gmail.com (mtb954 at gmail.com)
Date: Tue, 3 Mar 2015 13:01:14 -0600
Subject: [R] Sorting list elements according to their mean value
Message-ID: <CAOF_sWRWg4_2FZkSzQTzT3psZ95TjseRA4VEEGmKsqjKDZWRNw@mail.gmail.com>

Hello R-helpers,

I have a list of 999 dataframes and I would like to sort the list by the
mean value of one of the columns in the data frames.

Here is a small, self-contained example:


#begin example

iterations<-999

d<-list() #resampled data

f<-list() #fitted values

r<-list() #residuals

l<-list()

for (i in 1:iterations){

iboot<-sample(1:nrow(cars),replace=TRUE)

bootdata<-cars[iboot,]

d[[i]]<-bootdata

f[[i]]<-fitted(lm(bootdata$dist~bootdata$speed))

r[[i]]<-resid(lm(bootdata$dist~bootdata$speed))

 t<-data.frame(d[i],f[i],r[i]);names(t)<-c("speed","dist","fitted","resid")

l[[i]]<-t

} #end loop

#end example


Now, I would like to sort the 999 elements in this list by the mean value
of the column named "fitted".


In other words, the list element with the smallest mean value of "fitted"
would be the new first list element, the list element with the second
smallest mean value of "fitted" would be second new list element, etc....up
to the list element with the largest mean value of "fitted".


Thank you for any help you can provide!


Best wishes, Mark

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Mar  3 20:12:24 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 3 Mar 2015 11:12:24 -0800
Subject: [R] Sorting list elements according to their mean value
In-Reply-To: <CAOF_sWRWg4_2FZkSzQTzT3psZ95TjseRA4VEEGmKsqjKDZWRNw@mail.gmail.com>
References: <CAOF_sWRWg4_2FZkSzQTzT3psZ95TjseRA4VEEGmKsqjKDZWRNw@mail.gmail.com>
Message-ID: <CAF8bMcZ0fDRGi4xTwTrTc2oi-+Nzks+=Ry3QkKFthcD2mvWB0w@mail.gmail.com>

Use order(), as in
  sortListByMean <- function(List) {
      List[order(vapply(List, mean, 0))]
  }
  sortedL <- sortListByMean(l)



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Mar 3, 2015 at 11:01 AM, <mtb954 at gmail.com> wrote:

> Hello R-helpers,
>
> I have a list of 999 dataframes and I would like to sort the list by the
> mean value of one of the columns in the data frames.
>
> Here is a small, self-contained example:
>
>
> #begin example
>
> iterations<-999
>
> d<-list() #resampled data
>
> f<-list() #fitted values
>
> r<-list() #residuals
>
> l<-list()
>
> for (i in 1:iterations){
>
> iboot<-sample(1:nrow(cars),replace=TRUE)
>
> bootdata<-cars[iboot,]
>
> d[[i]]<-bootdata
>
> f[[i]]<-fitted(lm(bootdata$dist~bootdata$speed))
>
> r[[i]]<-resid(lm(bootdata$dist~bootdata$speed))
>
>  t<-data.frame(d[i],f[i],r[i]);names(t)<-c("speed","dist","fitted","resid")
>
> l[[i]]<-t
>
> } #end loop
>
> #end example
>
>
> Now, I would like to sort the 999 elements in this list by the mean value
> of the column named "fitted".
>
>
> In other words, the list element with the smallest mean value of "fitted"
> would be the new first list element, the list element with the second
> smallest mean value of "fitted" would be second new list element, etc....up
> to the list element with the largest mean value of "fitted".
>
>
> Thank you for any help you can provide!
>
>
> Best wishes, Mark
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pagli005 at umn.edu  Tue Mar  3 19:07:44 2015
From: pagli005 at umn.edu (Paulo Pagliari)
Date: Tue, 3 Mar 2015 12:07:44 -0600
Subject: [R] help with plotting error bars on xyplot!
Message-ID: <853D8BC7-CEF3-4A94-B8CA-5CAFA18857DB@umn.edu>

Dear R helpers,

I am trying to create a xyplot similar to this one:

https://stat.ethz.ch/pipermail/r-help/2008-June/164968.html

I can plot the data correctly when I only have one Y. However, I need to add another Y (Y2) to the plot and each Y must have their own error bars and also different symbols.  You will see that in this plot symbol changes based on X and not Y. The symbols should change by Y category, for example in the example below, the symbols with the errors bars sould be one symbol while the symbols without errors bars should have a different symbol and also should have error bars. Any help will be much appreciated.



Hr = c(0,1,2,3,4,5,0,1,2,3,4,5)
DRUG = rep(c("D", "P"), each=6)
Y = c(1,2,2,2,2,1,3, 4, 4,4, 4, 3)
Y2 = c(2,3,3,3,3,2,4, 5, 5,5, 5, 4)
data = data.frame(Hr, DRUG, Y, Y2)
data$lower1 = data$Y - .5
data$upper1 = data$Y + .5
data$lower2 = data$Y2 - .5
data$upper2 = data$Y2 + .5


prepanel.ci <- function(x, y, ly, uy, subscripts, ...) {
    x <- as.numeric(x)
    ly <- as.numeric(ly[subscripts])
    uy <- as.numeric(uy[subscripts])
    list(ylim = range(y, uy, ly, finite = TRUE)) }

panel.ci <- function(x, y, ly, uy, subscripts, pch = c(1, 16), ...) {
    x <- as.numeric(x)
    y <- as.numeric(y)
    ly <- as.numeric(ly[subscripts])
    uy <- as.numeric(uy[subscripts])
     panel.arrows(x, ly, x, uy, col = "black",
                 length = 0.25, unit = "native",
                 angle = 90, code = 3)
    panel.xyplot(x, y, pch = c(1, 16), ...)}

xyplot(Y+Y2 ~ Hr,
        data=data, 
        ly = data$lower1,
        uy = data$upper1,
        prepanel = prepanel.ci,
        panel = panel.superpose,
        panel.groups = panel.ci,
        auto.key = list(space = "top",  text = c( "D","P"), points = FALSE,
lines = TRUE, columns=2))




Paulo H. Pagliari, PhD. 
Assistant Professor Extension Soil Scientist 
University of Minnesota 
Southwest Research and Outreach Center 
23669 130th St. 
Lamberton, MN 56152 
Tel. 507-752-5065 
FAX 507-752-5097
email: pagli005 at umn.edu




	[[alternative HTML version deleted]]


From Pascal.Niklaus at ieu.uzh.ch  Tue Mar  3 16:35:47 2015
From: Pascal.Niklaus at ieu.uzh.ch (Pascal A. Niklaus)
Date: Tue, 03 Mar 2015 16:35:47 +0100
Subject: [R] Rcpp module / class access -- answer
Message-ID: <54F5D4D3.4000300@ieu.uzh.ch>

Hi all,

I am trying to answer my own question (although it probably does not end 
up in the thread because I am not a subscribed and thus have to send a 
new mail).


The way I finally got the code working was:


In NAMESPACE, comment out the following lines

# importFrom(Rcpp, loadModule)
# importFrom(Rcpp, evalCpp)



In zzz.R:

# loadModule("mod_yada",TRUE);

.pkgNamespace <- environment()

.onLoad <- function(libname, pkgname) {
   assign("mod_yada",
   Module("mod_yada",PACKAGE="testPackage",mustStart=TRUE),
   envir=.pkgNamespace);
}


The object generation then works as expected in the S4 class code.

Not sure whether this is the best way to achieve this, though.

Pascal


From putta.saikiran1994 at gmail.com  Tue Mar  3 18:08:50 2015
From: putta.saikiran1994 at gmail.com (saikiran putta)
Date: Tue, 3 Mar 2015 22:38:50 +0530
Subject: [R] Mining non-english text
Message-ID: <CAOO7hN+fjr=HUEvwo7h9eHatqq5cMLgG80AMEzvLZ0pg_grm7g@mail.gmail.com>

I am new to R programming and trying to mine this pdf file
http://164.100.180.82/Rollpdf/AC276/S24A276P001.pdf. This pdf file is in
non-English language and I'm not able to figure out how to proceed. And,
I'm not even sure how to extract information from a PDF file, so please
help!

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Tue Mar  3 21:02:29 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Tue, 03 Mar 2015 20:02:29 +0000 (GMT)
Subject: [R] bigglm connected to a database
Message-ID: <5c5dd738-1b29-4278-8679-6bd9e8c3395d@me.com>

I can get bigglm working with the following code.

ModelFit <- bigglm(SMM ~?
? ? ? ? ? ? ? ? ? ? I(1-.88 * exp(-.192 * LoanAge))+?
? ? ? ? ? ? ? ? ? ? ns(Incentive, df = 5)+?
? ? ? ? ? ? ? ? ? ? Purpose +
? ? ? ? ? ? ? ? ? ? Occupancy +
? ? ? ? ? ? ? ? ? ? TPO +
? ? ? ? ? ? ? ? ? ? Servicer,
? ? ? ? ? ? ? ? ? ? data = sqlQuery(Train.Data, ModelData),
? ? ? ? ? ? ? ? ? ? family = binomial(link = "logit"),
? ? ? ? ? ? ? ? ? ? chuncksize = 10000,
? ? ? ? ? ? ? ? ? ? maxit = 100)

However, I would like to order the factors so I wrote the following code to make data. ?However, it is not working. ?I have read through the manual as well as some examples provided and I am not having much success with the revised code below. ?I think I need to make data and provide ordering of the factors in the make data but so far this scheme has not worked. ?I think I am missing somethin any insights are appreciated.

Best Regards,
Glenn

make.data <- function(connection, query, chunksize,...){
?
? ? function(reset = FALSE) {
? ? ? if (reset) {
? ? ? ? if (got > 0) {
? ? ? ? ? ? dbClearResult(result)
? ? ? ? ? ? result <<- dbSendQuery(Train.Data, ModelData)
? ? ? ? ? ? got <<- 0
? ? ? ? }
? ? ? ? return(TRUE)
? ? }
? ? rval <- fetch(result, n = chunksize)
? ? got <<- got + nrow(rval)
? ? if (nrow(rval) == 0)
? ? ? ? return(NULL)
? ? return(rval)
}
}

data <- make.data(connection = Train.Data, query = ModelData, chunksize = 10000)

ModelFit <- bigglm(SMM ~?
? ? ? ? ? ? ? ? ? ? I(1-.88 * exp(-.192 * LoanAge))+?
? ? ? ? ? ? ? ? ? ? ns(Incentive, df = 5)+?
? ? ? ? ? ? ? ? ? ? Purpose +
? ? ? ? ? ? ? ? ? ? Occupancy +
? ? ? ? ? ? ? ? ? ? TPO +
? ? ? ? ? ? ? ? ? ? Servicer,
? ? ? ? ? ? ? ? ? ? data = data,
? ? ? ? ? ? ? ? ? ? family = binomial(link = "logit"),
? ? ? ? ? ? ? ? ? ? maxit = 100)



?

From curtisburkhalter at gmail.com  Tue Mar  3 22:22:33 2015
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Tue, 3 Mar 2015 14:22:33 -0700
Subject: [R] sampling dataframe based upon number of record occurrences
Message-ID: <CAJmwvUak+=Ge2QD=kRjAK+fXWus=rsaLhTw33fa58M+1oz1u7w@mail.gmail.com>

Hello everyone,

I'm having trouble performing a task that is probably very simple, but
can't seem to figure out how to get my code to work. What I want to do is
use the sample function to pick records within in a dataframe, but only if
a column attribute value is repeated more than 3 times. So if you look at
the data below I have created a unique attribute value that corresponds to
every site by year combination (i.e. IDxYear). So you can see that for the
site called "A-Airport" it was sampled 6 times in 2006, "A-Bank Corral
East" was sampled twice in 2008. So what I want to do is randomly select 3
records for "A-Airport" in 2006 for the existing 6 records, but for "A-Bark
Corral East" in 2008 I just want to leave these records as they currently
are.

I've used the following code to try and  accomplish this, but like I said I
can't get it to work so I'm clearly doing something wrong. If you could
check out the code and provide any suggestions that would be great. It
should be noted that there are 5589 unique IDxYear combinations so that's
why that number is in the code. If any further clarification is needed also
let me know.

boom=data.frame()
for (i in 1:5589){

boom[i,]=ifelse(length(fitting_set$IDbyYear[i]>3),fitting_set[sample(nrow(fitting_set),3),],fitting_set)

}
boom


              *IDbyYear*           *SiteID *                  *Year*
 *6 other column attributes*
              42.24               A-Airport                 2006
             42.24               A-Airport                 2006
              42.24               A-Airport                 2006
             42.24               A-Airport                 2006
              42.24               A-Airport                 2006
             42.24               A-Airport                 2006
             45.32              A-Bark Corral East    2008
             45.32              A-Bark Corral East    2008
             45.36              A-Bark Corral East    2009
             45.40              A-Bark Corral East    2010
             45.40               A-Bark Corral East   2010

 Thanks


-- 
Curtis Burkhalter

https://sites.google.com/site/curtisburkhalter/

	[[alternative HTML version deleted]]


From luca.cerone at gmail.com  Tue Mar  3 22:30:04 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Tue, 3 Mar 2015 22:30:04 +0100
Subject: [R] devtools: install_git hangs on Windows
Message-ID: <CAFnz2-9GPe0L3mDbBUfMq8wBgA_6=NsgEvqZnWRJyLv2xZxEMQ@mail.gmail.com>

Hi,
I am trying to setup R on a Windows 7 64b machine, but despite I have
followed the instructions for Windows (installing Rtools, building the package
etc), whenever I try to use install_git and install_url, RStudio (and R) hangs.

I have identified the issues being with:
system("git clone .......")
It creates a local repository, but then the download hangs.
(the same issues apply if I use shell or system2)

git works fine in both the cmd and git-bash shells, but whenever git
clone is called from within R, the command hangs while downloading.

Does any of you have the same issue? Has any of you been able to solve it?

Thanks in advance for the help,

Best wishes,
Luca


From 538280 at gmail.com  Tue Mar  3 22:47:44 2015
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 3 Mar 2015 14:47:44 -0700
Subject: [R] bigglm connected to a database
In-Reply-To: <5c5dd738-1b29-4278-8679-6bd9e8c3395d@me.com>
References: <5c5dd738-1b29-4278-8679-6bd9e8c3395d@me.com>
Message-ID: <CAFEqCdzgCPzHNGF8VEHF5Cgr3KXkd8Lm3YeoQ-CH8FcKh8jrzA@mail.gmail.com>

It may be simpler to specify the order in the contrasts rather than trying
to order the data.  See the C function (notice capitol C).  I have never
tried this with the bigglm function, so I don't know if it will work the
same way or not.  But if it works, then that may be a simpler approach.

On Tue, Mar 3, 2015 at 1:02 PM, Glenn Schultz <glennmschultz at me.com> wrote:

> I can get bigglm working with the following code.
>
> ModelFit <- bigglm(SMM ~
>                     I(1-.88 * exp(-.192 * LoanAge))+
>                     ns(Incentive, df = 5)+
>                     Purpose +
>                     Occupancy +
>                     TPO +
>                     Servicer,
>                     data = sqlQuery(Train.Data, ModelData),
>                     family = binomial(link = "logit"),
>                     chuncksize = 10000,
>                     maxit = 100)
>
> However, I would like to order the factors so I wrote the following code
> to make data.  However, it is not working.  I have read through the manual
> as well as some examples provided and I am not having much success with the
> revised code below.  I think I need to make data and provide ordering of
> the factors in the make data but so far this scheme has not worked.  I
> think I am missing somethin any insights are appreciated.
>
> Best Regards,
> Glenn
>
> make.data <- function(connection, query, chunksize,...){
>
>     function(reset = FALSE) {
>       if (reset) {
>         if (got > 0) {
>             dbClearResult(result)
>             result <<- dbSendQuery(Train.Data, ModelData)
>             got <<- 0
>         }
>         return(TRUE)
>     }
>     rval <- fetch(result, n = chunksize)
>     got <<- got + nrow(rval)
>     if (nrow(rval) == 0)
>         return(NULL)
>     return(rval)
> }
> }
>
> data <- make.data(connection = Train.Data, query = ModelData, chunksize =
> 10000)
>
> ModelFit <- bigglm(SMM ~
>                     I(1-.88 * exp(-.192 * LoanAge))+
>                     ns(Incentive, df = 5)+
>                     Purpose +
>                     Occupancy +
>                     TPO +
>                     Servicer,
>                     data = data,
>                     family = binomial(link = "logit"),
>                     maxit = 100)
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Mar  4 16:23:44 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 4 Mar 2015 15:23:44 +0000
Subject: [R] sampling dataframe based upon number of record occurrences
In-Reply-To: <CAJmwvUak+=Ge2QD=kRjAK+fXWus=rsaLhTw33fa58M+1oz1u7w@mail.gmail.com>
References: <CAJmwvUak+=Ge2QD=kRjAK+fXWus=rsaLhTw33fa58M+1oz1u7w@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D664E04@mb04.ads.tamu.edu>

I'm not sure I understand, but I think you have a large data frame with records and you want to construct a sample of that data frame that includes no more than 3 records for each IDbyYear combination? You say there are 5589 unique combinations and your code uses a data frame called fitting_set. Assuming this is the data frame you are describing, your code will select all of the lines since fitting_set$IDbyYear[i] is always a vector of length 1.

We need a reproducible example. The best way for you to give us that would be to copy the result of dput(head(fitting_set, 10)). It would look something like this plus the 6 other columns you mention except that I've added dta <- in front of structure() to create a data frame:

dta <- structure(list(IDbyYear = c(42.24, 42.24, 42.24, 42.24, 42.24, 
42.24, 45.32, 45.32, 45.36, 45.4, 45.4), SiteID = structure(c(1L, 
1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L), .Label = c("A-Airport", 
"A-Bark Corral East"), class = "factor"), Year = c(2006L, 2006L, 
2006L, 2006L, 2006L, 2006L, 2008L, 2008L, 2009L, 2010L, 2010L
)), .Names = c("IDbyYear", "SiteID", "Year"), class = "data.frame", row.names = c(NA, 
-11L))

Now create a list of data frames, one for each IDbyYear:

dta.list <- split(dta, dta$IDbyYear)

Now a function that will select 3 rows or all of them if there are fewer:

smp <- function(dframe) {
	ind <- seq_len(nrow(dframe))
	dframe[sample(ind, ifelse(length(ind)>2, 3, length(ind))),]
}

Now take the samples and combine them into a single data frame:

sample <- do.call(rbind, lapply(dta.list, smp))
sample

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Curtis Burkhalter
Sent: Tuesday, March 3, 2015 3:23 PM
To: r-help at r-project.org
Subject: [R] sampling dataframe based upon number of record occurrences

Hello everyone,

I'm having trouble performing a task that is probably very simple, but
can't seem to figure out how to get my code to work. What I want to do is
use the sample function to pick records within in a dataframe, but only if
a column attribute value is repeated more than 3 times. So if you look at
the data below I have created a unique attribute value that corresponds to
every site by year combination (i.e. IDxYear). So you can see that for the
site called "A-Airport" it was sampled 6 times in 2006, "A-Bank Corral
East" was sampled twice in 2008. So what I want to do is randomly select 3
records for "A-Airport" in 2006 for the existing 6 records, but for "A-Bark
Corral East" in 2008 I just want to leave these records as they currently
are.

I've used the following code to try and  accomplish this, but like I said I
can't get it to work so I'm clearly doing something wrong. If you could
check out the code and provide any suggestions that would be great. It
should be noted that there are 5589 unique IDxYear combinations so that's
why that number is in the code. If any further clarification is needed also
let me know.

boom=data.frame()
for (i in 1:5589){

boom[i,]=ifelse(length(fitting_set$IDbyYear[i]>3),fitting_set[sample(nrow(fitting_set),3),],fitting_set)

}
boom


              *IDbyYear*           *SiteID *                  *Year*
 *6 other column attributes*
              42.24               A-Airport                 2006
             42.24               A-Airport                 2006
              42.24               A-Airport                 2006
             42.24               A-Airport                 2006
              42.24               A-Airport                 2006
             42.24               A-Airport                 2006
             45.32              A-Bark Corral East    2008
             45.32              A-Bark Corral East    2008
             45.36              A-Bark Corral East    2009
             45.40              A-Bark Corral East    2010
             45.40               A-Bark Corral East   2010

 Thanks


-- 
Curtis Burkhalter

https://sites.google.com/site/curtisburkhalter/

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From kmezhoud at gmail.com  Wed Mar  4 19:09:54 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 4 Mar 2015 18:09:54 +0000
Subject: [R] remove repeated string in list
Message-ID: <CALJKBv9yi78ZHPxk_8ohagMD3psUBD71irHqhpotrueFUz8cSA@mail.gmail.com>

Dear All,
here an example
temp <- list(set1=c("a","b","d","x"), set2=c("b","c","q","m"),
set3=c("b","f","e","k","q","h"))

preserve only the first one string

>temp
set1 a b d x
set2 c q m
set3 f e k h

OR

remove repeated string

>temp
set1 a d x
set2 c m
set3 f e k h

Thanks

	[[alternative HTML version deleted]]


From bh1605a at student.american.edu  Wed Mar  4 15:54:52 2015
From: bh1605a at student.american.edu (Brian Hamel)
Date: Wed, 4 Mar 2015 09:54:52 -0500
Subject: [R] Using dates in R
Message-ID: <CAE8v7Z2GOFR8aWP9+dSW1Op7Zc96b-Kp67zxssNOLkCgxM6Cog@mail.gmail.com>

Hi all,

I have a dataset that includes a "date" variable. Each observation includes
a date in the form of 2/15/15, for example. I'm looking to create a new
indicator variable that is based on the date variable. So, for example, if
the date is earlier than today, I would need a "0" in the new column, and a
"1" otherwise. Note that my dataset includes dates from 1979-2012, so it is
not one-year (this means I can't easily create a new variable 1-365).

How does R handle dates? My hunch is "not well," but perhaps there is a
package that can help me with this. Let me know if you have any
recommendations as to how this can be done relatively easily.

Thanks! Appreciate it.

Best,
Brian

	[[alternative HTML version deleted]]


From dickliang911 at gmail.com  Wed Mar  4 15:45:34 2015
From: dickliang911 at gmail.com (Hua Liang)
Date: Wed, 4 Mar 2015 09:45:34 -0500
Subject: [R] summary.formula()
Message-ID: <69CBB581-C1B8-4F0C-913D-1AC453236CAD@gmail.com>

I try to use t.test  instead of Wilcox.test in summary.formula() , a very decent function developed by Frank, as follows. But I got error messages. Can someone help me out?
 
Dick
 
 
uT<-function(a,b){
        j<-t.test(a)
        p<-list(P=j$p.value,stat=j$statistic,
            df=j$parameter,testname=j$method,statname="")
        return(p)
        }
 
pbcset<- na.omit(pbc[,c("trt","chol","copper","platelet")])
 
sf2 <- summary(trt~chol+platelet,data=pbc,test=T,method="reverse",conTest=uT)
print(sf2, prtest = "P")

From ii54250 at msn.com  Wed Mar  4 09:31:57 2015
From: ii54250 at msn.com (IOANNA IOANNOU)
Date: Wed, 4 Mar 2015 08:31:57 +0000
Subject: [R] FW: FW: confidence intervals values in locpol
In-Reply-To: <XFMail.20150303232825.Ted.Harding@wlandres.net>
References: <DUB129-DS15DD3826069DED70C22C02F3110@phx.gbl>
	<XFMail.20150303232825.Ted.Harding@wlandres.net>
Message-ID: <DUB129-DS181224B36FD9B7FA18C429F31E0@phx.gbl>


 Hello all,
 
 A straightforward question. How can I get a the values of the 90% 
 confidence intervals of a locpol in R? I can see how you can plot the 
 mean as well as the confidence intervals. I would like the matrix of 
 the values corresponding to the 95% and 5% exceedance probability.
 
 Any ideas?
 
 For example
 
 N <- 250
     xeval <- 0:100/100
     ##  ex1
     d <- data.frame(x = runif(N))
     d$y <- d$x^2 - d$x + 1 + rnorm(N, sd = 0.1)
     r <- locpol(y~x,d)
     plot(r)
 
 Best,
 Ioanna
 

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 03-Mar-2015  Time: 23:28:20
This message was sent by XFMail


From loris.bennett at fu-berlin.de  Wed Mar  4 08:52:05 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Wed, 4 Mar 2015 08:52:05 +0100
Subject: [R] Mining non-english text
References: <CAOO7hN+fjr=HUEvwo7h9eHatqq5cMLgG80AMEzvLZ0pg_grm7g@mail.gmail.com>
Message-ID: <877fux5hei.fsf@hornfels.zedat.fu-berlin.de>

saikiran putta <putta.saikiran1994 at gmail.com> writes:

> I am new to R programming and trying to mine this pdf file
> http://164.100.180.82/Rollpdf/AC276/S24A276P001.pdf. This pdf file is in
> non-English language and I'm not able to figure out how to proceed. And,
> I'm not even sure how to extract information from a PDF file, so please
> help!
>
> 	[[alternative HTML version deleted]]
>

Nothing to do with R, but the command-line program pdftotxt might help
you to get going and is available for Linux and, apparently, for
Windows.  It can deal with various encodings.

Cheers,

Loris

-- 
This signature is currently under construction.


From js.huang at protective.com  Wed Mar  4 02:13:28 2015
From: js.huang at protective.com (JS Huang)
Date: Tue, 3 Mar 2015 17:13:28 -0800 (PST)
Subject: [R] sampling dataframe based upon number of record occurrences
In-Reply-To: <CAJmwvUak+=Ge2QD=kRjAK+fXWus=rsaLhTw33fa58M+1oz1u7w@mail.gmail.com>
References: <CAJmwvUak+=Ge2QD=kRjAK+fXWus=rsaLhTw33fa58M+1oz1u7w@mail.gmail.com>
Message-ID: <1425431608505-4704154.post@n4.nabble.com>

Here is an implementation with function named getSample. Some modification to
the data was made so that it can be read as a table.

> fitting.set
   IDbyYear             SiteID Year
1     42.24          A-Airport 2006
2     42.24          A-Airport 2006
3     42.24          A-Airport 2006
4     42.24          A-Airport 2006
5     42.24          A-Airport 2006
6     42.24          A-Airport 2006
7     45.32 A-Bark.Corral.East 2008
8     45.32 A-Bark.Corral.East 2008
9     45.36 A-Bark.Corral.East 2009
10    45.40 A-Bark.Corral.East 2010
11    45.40 A-Bark.Corral.East 2010
> getSample
function(x)
{
  sites <- unique(x$SiteID)
  years <- unique(x$Year)
  result <- data.frame()
  x$ID <- seq(1,nrow(x))
  for (i in 1:length(sites))
  {
    for (j in 1:length(years))
    {
      if (nrow(x[as.character(x$SiteID)==as.character(sites[i]) &
x$Year==years[j],]) > 3)
      {
        sampledID <- sample(x[as.character(x$SiteID)==as.character(sites[i])
& x$Year==years[j],]$ID,3,replace=FALSE)
        for (k in 1:length(sampledID))
        {
          result <- rbind(result,x[x$ID==sampledID[k],-4])
        }          
      }
    }
  }
  names(result) <- c("IDbyYear","SiteID","Year")
  rownames(result) <- NULL
  return(result)
}
> getSample(fitting.set)
  IDbyYear    SiteID Year
1    42.24 A-Airport 2006
2    42.24 A-Airport 2006
3    42.24 A-Airport 2006



--
View this message in context: http://r.789695.n4.nabble.com/sampling-dataframe-based-upon-number-of-record-occurrences-tp4704144p4704154.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Wed Mar  4 02:25:52 2015
From: js.huang at protective.com (JS Huang)
Date: Tue, 3 Mar 2015 17:25:52 -0800 (PST)
Subject: [R] sampling dataframe based upon number of record occurrences
In-Reply-To: <CAJmwvUak+=Ge2QD=kRjAK+fXWus=rsaLhTw33fa58M+1oz1u7w@mail.gmail.com>
References: <CAJmwvUak+=Ge2QD=kRjAK+fXWus=rsaLhTw33fa58M+1oz1u7w@mail.gmail.com>
Message-ID: <1425432352084-4704155.post@n4.nabble.com>

Since you indicated there are six more columns in the data.frame, getSample
modified below to take care of it.

> getSample
function(x)
{
  sites <- unique(x$SiteID)
  years <- unique(x$Year)
  result <- data.frame()
  x$ID <- seq(1,nrow(x))
  for (i in 1:length(sites))
  {
    for (j in 1:length(years))
    {
      if (nrow(x[as.character(x$SiteID)==as.character(sites[i]) &
x$Year==years[j],]) > 3)
      {
        sampledID <- sample(x[as.character(x$SiteID)==as.character(sites[i])
& x$Year==years[j],]$ID,3,replace=FALSE)
        for (k in 1:length(sampledID))
        {
          result <- rbind(result,x[x$ID==sampledID[k],-ncol(x)])
        }          
      }
    }
  }
  names(result) <- names(x)[-ncol(x)]
  rownames(result) <- NULL
  return(result)
}
> getSample(fitting.set)
  IDbyYear    SiteID Year
1    42.24 A-Airport 2006
2    42.24 A-Airport 2006
3    42.24 A-Airport 2006




--
View this message in context: http://r.789695.n4.nabble.com/sampling-dataframe-based-upon-number-of-record-occurrences-tp4704144p4704155.html
Sent from the R help mailing list archive at Nabble.com.


From wdunlap at tibco.com  Wed Mar  4 19:47:25 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 4 Mar 2015 10:47:25 -0800
Subject: [R] Using dates in R
In-Reply-To: <CAE8v7Z2GOFR8aWP9+dSW1Op7Zc96b-Kp67zxssNOLkCgxM6Cog@mail.gmail.com>
References: <CAE8v7Z2GOFR8aWP9+dSW1Op7Zc96b-Kp67zxssNOLkCgxM6Cog@mail.gmail.com>
Message-ID: <CAF8bMcYX5A6=cmMLizwS_AiRyEHinmNNaMEtwX7_pLAYApt0Mg@mail.gmail.com>

You will need to convert strings like "2/15/15" into one of the time/date
classes available in R and then it is easy to do comparisons.  E.g., if you
have no interest in the time of day you can use the Date class:

> d <- as.Date(c("12/2/79", "4/15/15"), format="%m/%d/%y")
> today <- as.Date("2015-03-04") # default format
> d
[1] "1979-12-02" "2015-04-15"
> today
[1] "2015-03-04"
> d < today
[1]  TRUE FALSE

The lubridate package contains a bunch of handy functions for manipulating
dates and times.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Mar 4, 2015 at 6:54 AM, Brian Hamel <bh1605a at student.american.edu>
wrote:

> Hi all,
>
> I have a dataset that includes a "date" variable. Each observation includes
> a date in the form of 2/15/15, for example. I'm looking to create a new
> indicator variable that is based on the date variable. So, for example, if
> the date is earlier than today, I would need a "0" in the new column, and a
> "1" otherwise. Note that my dataset includes dates from 1979-2012, so it is
> not one-year (this means I can't easily create a new variable 1-365).
>
> How does R handle dates? My hunch is "not well," but perhaps there is a
> package that can help me with this. Let me know if you have any
> recommendations as to how this can be done relatively easily.
>
> Thanks! Appreciate it.
>
> Best,
> Brian
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Wed Mar  4 19:39:59 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 4 Mar 2015 18:39:59 +0000
Subject: [R] Using dates in R
In-Reply-To: <CAE8v7Z2GOFR8aWP9+dSW1Op7Zc96b-Kp67zxssNOLkCgxM6Cog@mail.gmail.com>
References: <CAE8v7Z2GOFR8aWP9+dSW1Op7Zc96b-Kp67zxssNOLkCgxM6Cog@mail.gmail.com>
Message-ID: <D11C8FF8.12107F%macqueen1@llnl.gov>

Your hunch is wrong.

Start by typing
  ?Date
at the R prompt. Continue with
  ?as.Date

Then to find out if the date is earlier than today
  delta <- thedate - Sys.Date()
(of course, that will change if you use it tomorrow)
  
Getting your indicator variable can be done very easily with base R; no
packages needed.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/4/15, 6:54 AM, "Brian Hamel" <bh1605a at student.american.edu> wrote:

>Hi all,
>
>I have a dataset that includes a "date" variable. Each observation
>includes
>a date in the form of 2/15/15, for example. I'm looking to create a new
>indicator variable that is based on the date variable. So, for example, if
>the date is earlier than today, I would need a "0" in the new column, and
>a
>"1" otherwise. Note that my dataset includes dates from 1979-2012, so it
>is
>not one-year (this means I can't easily create a new variable 1-365).
>
>How does R handle dates? My hunch is "not well," but perhaps there is a
>package that can help me with this. Let me know if you have any
>recommendations as to how this can be done relatively easily.
>
>Thanks! Appreciate it.
>
>Best,
>Brian
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From curtisburkhalter at gmail.com  Wed Mar  4 19:56:55 2015
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Wed, 4 Mar 2015 11:56:55 -0700
Subject: [R] sampling dataframe based upon number of record occurrences
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D664E04@mb04.ads.tamu.edu>
References: <CAJmwvUak+=Ge2QD=kRjAK+fXWus=rsaLhTw33fa58M+1oz1u7w@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D664E04@mb04.ads.tamu.edu>
Message-ID: <CAJmwvUaBGiZYHzz+ZEDmWoNtMT_gjtsKOMyAF1wZ4P1xpnH=Gw@mail.gmail.com>

That worked great, thanks so much David!

On Wed, Mar 4, 2015 at 8:23 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> I'm not sure I understand, but I think you have a large data frame with
> records and you want to construct a sample of that data frame that includes
> no more than 3 records for each IDbyYear combination? You say there are
> 5589 unique combinations and your code uses a data frame called
> fitting_set. Assuming this is the data frame you are describing, your code
> will select all of the lines since fitting_set$IDbyYear[i] is always a
> vector of length 1.
>
> We need a reproducible example. The best way for you to give us that would
> be to copy the result of dput(head(fitting_set, 10)). It would look
> something like this plus the 6 other columns you mention except that I've
> added dta <- in front of structure() to create a data frame:
>
> dta <- structure(list(IDbyYear = c(42.24, 42.24, 42.24, 42.24, 42.24,
> 42.24, 45.32, 45.32, 45.36, 45.4, 45.4), SiteID = structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L), .Label = c("A-Airport",
> "A-Bark Corral East"), class = "factor"), Year = c(2006L, 2006L,
> 2006L, 2006L, 2006L, 2006L, 2008L, 2008L, 2009L, 2010L, 2010L
> )), .Names = c("IDbyYear", "SiteID", "Year"), class = "data.frame",
> row.names = c(NA,
> -11L))
>
> Now create a list of data frames, one for each IDbyYear:
>
> dta.list <- split(dta, dta$IDbyYear)
>
> Now a function that will select 3 rows or all of them if there are fewer:
>
> smp <- function(dframe) {
>         ind <- seq_len(nrow(dframe))
>         dframe[sample(ind, ifelse(length(ind)>2, 3, length(ind))),]
> }
>
> Now take the samples and combine them into a single data frame:
>
> sample <- do.call(rbind, lapply(dta.list, smp))
> sample
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Curtis
> Burkhalter
> Sent: Tuesday, March 3, 2015 3:23 PM
> To: r-help at r-project.org
> Subject: [R] sampling dataframe based upon number of record occurrences
>
> Hello everyone,
>
> I'm having trouble performing a task that is probably very simple, but
> can't seem to figure out how to get my code to work. What I want to do is
> use the sample function to pick records within in a dataframe, but only if
> a column attribute value is repeated more than 3 times. So if you look at
> the data below I have created a unique attribute value that corresponds to
> every site by year combination (i.e. IDxYear). So you can see that for the
> site called "A-Airport" it was sampled 6 times in 2006, "A-Bank Corral
> East" was sampled twice in 2008. So what I want to do is randomly select 3
> records for "A-Airport" in 2006 for the existing 6 records, but for "A-Bark
> Corral East" in 2008 I just want to leave these records as they currently
> are.
>
> I've used the following code to try and  accomplish this, but like I said I
> can't get it to work so I'm clearly doing something wrong. If you could
> check out the code and provide any suggestions that would be great. It
> should be noted that there are 5589 unique IDxYear combinations so that's
> why that number is in the code. If any further clarification is needed also
> let me know.
>
> boom=data.frame()
> for (i in 1:5589){
>
>
> boom[i,]=ifelse(length(fitting_set$IDbyYear[i]>3),fitting_set[sample(nrow(fitting_set),3),],fitting_set)
>
> }
> boom
>
>
>               *IDbyYear*           *SiteID *                  *Year*
>  *6 other column attributes*
>               42.24               A-Airport                 2006
>              42.24               A-Airport                 2006
>               42.24               A-Airport                 2006
>              42.24               A-Airport                 2006
>               42.24               A-Airport                 2006
>              42.24               A-Airport                 2006
>              45.32              A-Bark Corral East    2008
>              45.32              A-Bark Corral East    2008
>              45.36              A-Bark Corral East    2009
>              45.40              A-Bark Corral East    2010
>              45.40               A-Bark Corral East   2010
>
>  Thanks
>
>
> --
> Curtis Burkhalter
>
> https://sites.google.com/site/curtisburkhalter/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Curtis Burkhalter

https://sites.google.com/site/curtisburkhalter/

	[[alternative HTML version deleted]]


From Peter.Alspach at plantandfood.co.nz  Wed Mar  4 19:59:05 2015
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Thu, 5 Mar 2015 07:59:05 +1300
Subject: [R] Using dates in R
In-Reply-To: <CAE8v7Z2GOFR8aWP9+dSW1Op7Zc96b-Kp67zxssNOLkCgxM6Cog@mail.gmail.com>
References: <CAE8v7Z2GOFR8aWP9+dSW1Op7Zc96b-Kp67zxssNOLkCgxM6Cog@mail.gmail.com>
Message-ID: <E41B375B7520DE4A8C60781AC60B754501BD429F6E@AKLEXM01.PFR.CO.NZ>

Tena koe Brian

See ?as.Date and ?strptime (and, maybe, ?locales).  For example:

as.Date('2/15/15', '%m/%d/%y')
[1] "2015-02-15"

as.Date('12/15/14', '%m/%d/%y') < as.Date('2/15/15', '%m/%d/%y')
[1] TRUE
> as.Date('12/15/16', '%m/%d/%y') < as.Date('2/15/15', '%m/%d/%y')
[1] FALSE

You might have problems across the century boundary with only two digits in the year, but ...

> as.Date('12/15/79', '%m/%d/%y') < as.Date('2/15/15', '%m/%d/%y')
[1] TRUE

HTH ...

P

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Brian Hamel
Sent: Thursday, 5 March 2015 3:55 a.m.
To: r-help at r-project.org
Subject: [R] Using dates in R

Hi all,

I have a dataset that includes a "date" variable. Each observation includes a date in the form of 2/15/15, for example. I'm looking to create a new indicator variable that is based on the date variable. So, for example, if the date is earlier than today, I would need a "0" in the new column, and a "1" otherwise. Note that my dataset includes dates from 1979-2012, so it is not one-year (this means I can't easily create a new variable 1-365).

How does R handle dates? My hunch is "not well," but perhaps there is a package that can help me with this. Let me know if you have any recommendations as to how this can be done relatively easily.

Thanks! Appreciate it.

Best,
Brian

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From dcarlson at tamu.edu  Wed Mar  4 20:08:30 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 4 Mar 2015 19:08:30 +0000
Subject: [R] Using dates in R
In-Reply-To: <CAE8v7Z2GOFR8aWP9+dSW1Op7Zc96b-Kp67zxssNOLkCgxM6Cog@mail.gmail.com>
References: <CAE8v7Z2GOFR8aWP9+dSW1Op7Zc96b-Kp67zxssNOLkCgxM6Cog@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D666F0D@mb04.ads.tamu.edu>

Wow! A bold prediction from someone who has done exactly zero investigation of the basic, built-in date/time features in R. Since your example did not include the first two digits of the year, I've used %y instead of %Y. That will assume "19" precedes values from 69-99 and "20" precedes values from 00 to 68. If you decide to implement this with a for loop, it means you have much more to learn.

> today <- "3/4/15"
> d1 <- "2/15/80"
> d2 <- "2/15/16"
> # Is d before today, if so 0, otherwise 1
> as.integer(strptime(today, "%m/%d/%y") < strptime(d1, "%m/%d/%y"))
[1] 0
> as.integer(strptime(today, "%m/%d/%y") < strptime(d2, "%m/%d/%y"))
[1] 1

?strptime for details

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Brian Hamel
Sent: Wednesday, March 4, 2015 8:55 AM
To: r-help at r-project.org
Subject: [R] Using dates in R

Hi all,

I have a dataset that includes a "date" variable. Each observation includes
a date in the form of 2/15/15, for example. I'm looking to create a new
indicator variable that is based on the date variable. So, for example, if
the date is earlier than today, I would need a "0" in the new column, and a
"1" otherwise. Note that my dataset includes dates from 1979-2012, so it is
not one-year (this means I can't easily create a new variable 1-365).

How does R handle dates? My hunch is "not well," but perhaps there is a
package that can help me with this. Let me know if you have any
recommendations as to how this can be done relatively easily.

Thanks! Appreciate it.

Best,
Brian

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From leandromarino at leandromarino.com.br  Wed Mar  4 20:53:42 2015
From: leandromarino at leandromarino.com.br (Leandro Marino)
Date: Wed, 4 Mar 2015 16:53:42 -0300
Subject: [R] Suggestion in justify in write.fwf {gdata}
Message-ID: <CAKSaaFmAOmH2d_cdMfXXspV19XLbTq7XqsqFi=yXkbQ_5dotcQ@mail.gmail.com>

Hi,

Sometimes, I need to do some hard work when exporting files using gdata
package.

It will be very useful if the justify parameter of write.fwf can receive
vectors. In some jobs I need to left and right justify in different columns
of the same file.

Nowadays, I do a lot ow this working in preparing manually each file.

I was wondering something like


justify=c(rep('right',3),'left',rep('right',2),rep('left',10))

in a file that has 15 columns.


Best,
Leandro

	[[alternative HTML version deleted]]


From Douglas.Federman at utoledo.edu  Wed Mar  4 21:08:35 2015
From: Douglas.Federman at utoledo.edu (Federman, Douglas)
Date: Wed, 4 Mar 2015 20:08:35 +0000
Subject: [R] Suggestion in justify in write.fwf {gdata}
In-Reply-To: <CAKSaaFmAOmH2d_cdMfXXspV19XLbTq7XqsqFi=yXkbQ_5dotcQ@mail.gmail.com>
References: <CAKSaaFmAOmH2d_cdMfXXspV19XLbTq7XqsqFi=yXkbQ_5dotcQ@mail.gmail.com>
Message-ID: <F1065E5D886F4D429259CDEAE3F83CB61AEC18E7@msgdb20.utad.utoledo.edu>

Perhaps you should contact the package maintainer regarding this request.

Who is wise? One who learns from every person.
Who is strong? One who overpowers his evil inclinations.
Who is rich? One who is satisfied with his lot.
Who is honorable? One who honors his fellows.
- Pirkei Avot [excerpt]


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Leandro Marino
Sent: Wednesday, March 04, 2015 2:54 PM
To: r-help at r-project.org
Subject: [R] Suggestion in justify in write.fwf {gdata}

Hi,

Sometimes, I need to do some hard work when exporting files using gdata package.

It will be very useful if the justify parameter of write.fwf can receive vectors. In some jobs I need to left and right justify in different columns of the same file.

Nowadays, I do a lot ow this working in preparing manually each file.

I was wondering something like


justify=c(rep('right',3),'left',rep('right',2),rep('left',10))

in a file that has 15 columns.


Best,
Leandro

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From chrisdv82 at gmail.com  Wed Mar  4 21:32:30 2015
From: chrisdv82 at gmail.com (Chris Vanlangenberg)
Date: Wed, 4 Mar 2015 15:32:30 -0500
Subject: [R] Second order bessel function
Message-ID: <CAGgSdZVg01DcDpVaEF6SSzd+8RVHf_QOZPhzTZwxJfGjn+R0zQ@mail.gmail.com>

Hi all,

I want to compute the numerical values for modified second order bessel
function given x and other parameters, currently base R has a bessel
function for 1st order and I have tried to use the relationship between 1st
and 2nd order to compute the 2nd order bessel function, but I ended up
getting a zero.

Any suggestions how to proceed on this? or any alternative methods?

-- 
Regards,
Chris Vanlangenberg

	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Wed Mar  4 22:39:05 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 4 Mar 2015 13:39:05 -0800 (PST)
Subject: [R] Fitting Legend to Matrix Plot
Message-ID: <alpine.LNX.2.11.1503041332020.26347@localhost>

   I have a matrix plot of ternary diagrams (pdf attached) generated with
these commands:

opar <- par(xpd=NA,no.readonly=T)

plot(WintersY, pch=as.numeric(WintersX4),
 	col=c("black","red","green","blue","yellow","orange")[WintersX4])

legend(x=0.75, y=0.0, abbreviate(levels(WintersX4),
 	minlength=1),pch=as.numeric(WintersX4),
 	col=c("black","red","green","blue","yellow","orange"), yjust=0)

par(opar)

   I have read ?legend but am uncertain what to adjust so the legend is
readable yet not overlapping any of the plots. One of this series of plots
has data from 8 years which would be a worse looking fit.

   How should I specify the legend (or the plots themselves) in a figure that
occupies the full display?

Rich
-------------- next part --------------
A non-text attachment was scrubbed...
Name: winters-ternary-2.pdf
Type: application/pdf
Size: 7997 bytes
Desc: 
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150304/69b3c66d/attachment.pdf>

From ecervera at uji.es  Wed Mar  4 13:19:01 2015
From: ecervera at uji.es (Enric Cervera Mateu)
Date: Wed, 4 Mar 2015 13:19:01 +0100
Subject: [R] Online R server with instant messaging access
Message-ID: <CAH+5udegoC8czWcf2eoxVYBtfUFxWCsjjzHH_OtHr99a_WVXHg@mail.gmail.com>

Dear all,

I have set up a dedicated R server, which can be used by anyone with an
instant messaging application (Telegram).

See instructions at:

http://telemath.altervista.org/TeleR.html

It's still experimental, and not heavily tested. Any feedback or comment is
absolutely welcome.

Hope you like it.

Best,

Enric

	[[alternative HTML version deleted]]


From mrowlan1 at gmail.com  Wed Mar  4 22:19:38 2015
From: mrowlan1 at gmail.com (Myfanwy Johnston)
Date: Wed, 4 Mar 2015 13:19:38 -0800
Subject: [R] Using dates in R
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D666F0D@mb04.ads.tamu.edu>
References: <CAE8v7Z2GOFR8aWP9+dSW1Op7Zc96b-Kp67zxssNOLkCgxM6Cog@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D666F0D@mb04.ads.tamu.edu>
Message-ID: <CAFYAvB4VpupJiX8D5B18_ASwLzrrMtyC_939+C=2p1oOQbfu3g@mail.gmail.com>

Our R-user's group (UC Davis) has a good post on working with dates/times
in R:
http://www.noamross.net/blog/2014/2/10/using-times-and-dates-in-r---presentation-code.html



On Wed, Mar 4, 2015 at 11:08 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> Wow! A bold prediction from someone who has done exactly zero
> investigation of the basic, built-in date/time features in R. Since your
> example did not include the first two digits of the year, I've used %y
> instead of %Y. That will assume "19" precedes values from 69-99 and "20"
> precedes values from 00 to 68. If you decide to implement this with a for
> loop, it means you have much more to learn.
>
> > today <- "3/4/15"
> > d1 <- "2/15/80"
> > d2 <- "2/15/16"
> > # Is d before today, if so 0, otherwise 1
> > as.integer(strptime(today, "%m/%d/%y") < strptime(d1, "%m/%d/%y"))
> [1] 0
> > as.integer(strptime(today, "%m/%d/%y") < strptime(d2, "%m/%d/%y"))
> [1] 1
>
> ?strptime for details
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Brian
> Hamel
> Sent: Wednesday, March 4, 2015 8:55 AM
> To: r-help at r-project.org
> Subject: [R] Using dates in R
>
> Hi all,
>
> I have a dataset that includes a "date" variable. Each observation includes
> a date in the form of 2/15/15, for example. I'm looking to create a new
> indicator variable that is based on the date variable. So, for example, if
> the date is earlier than today, I would need a "0" in the new column, and a
> "1" otherwise. Note that my dataset includes dates from 1979-2012, so it is
> not one-year (this means I can't easily create a new variable 1-365).
>
> How does R handle dates? My hunch is "not well," but perhaps there is a
> package that can help me with this. Let me know if you have any
> recommendations as to how this can be done relatively easily.
>
> Thanks! Appreciate it.
>
> Best,
> Brian
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Myfanwy Johnston
Ph.D Candidate, Animal Behavior
University of California at Davis
Biotelemetry Lab
+1.530.205.5243

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Wed Mar  4 23:13:14 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 4 Mar 2015 23:13:14 +0100
Subject: [R] format( "www.R-project.org" , year = 2015)
Message-ID: <CAPRP4-e0OjY9EFJdmSp99amsSy8NYewwimo5QUeseYNY+Aq_Eg@mail.gmail.com>

 The R Foundation is pleased to announce that our website
 http://www.r-project.org/ has under gone a nice retouch (and
 thus arrived in the 21st century :-)

 Thanks to a working group of Dirk Eddelbuettel, Simon Urbanek and
Hadley Wickham.,
 the current page sources are in markdown, and the html is auto
produced using pandoc
 (and IT infrastructure in Vienna and Zurich).

Martin Maechler,
as secretary of the R Foundation

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From steve.taylor at aut.ac.nz  Wed Mar  4 23:42:42 2015
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Wed, 4 Mar 2015 22:42:42 +0000
Subject: [R] Using dates in R
In-Reply-To: <CAF8bMcYX5A6=cmMLizwS_AiRyEHinmNNaMEtwX7_pLAYApt0Mg@mail.gmail.com>
References: <CAE8v7Z2GOFR8aWP9+dSW1Op7Zc96b-Kp67zxssNOLkCgxM6Cog@mail.gmail.com>
	<CAF8bMcYX5A6=cmMLizwS_AiRyEHinmNNaMEtwX7_pLAYApt0Mg@mail.gmail.com>
Message-ID: <CCE952776B6679469977532BD863C39C9A67A144@Lewis.autuni.aut.ac.nz>

> today <- as.Date("2015-03-04") # default format

Better is:

today <- Sys.Date() 

S

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of William Dunlap
Sent: Thursday, 5 March 2015 7:47a
To: Brian Hamel
Cc: r-help at r-project.org
Subject: Re: [R] Using dates in R

You will need to convert strings like "2/15/15" into one of the time/date
classes available in R and then it is easy to do comparisons.  E.g., if you
have no interest in the time of day you can use the Date class:

> d <- as.Date(c("12/2/79", "4/15/15"), format="%m/%d/%y")
> today <- as.Date("2015-03-04") # default format
> d
[1] "1979-12-02" "2015-04-15"
> today
[1] "2015-03-04"
> d < today
[1]  TRUE FALSE

The lubridate package contains a bunch of handy functions for manipulating
dates and times.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Mar 4, 2015 at 6:54 AM, Brian Hamel <bh1605a at student.american.edu>
wrote:

> Hi all,
>
> I have a dataset that includes a "date" variable. Each observation includes
> a date in the form of 2/15/15, for example. I'm looking to create a new
> indicator variable that is based on the date variable. So, for example, if
> the date is earlier than today, I would need a "0" in the new column, and a
> "1" otherwise. Note that my dataset includes dates from 1979-2012, so it is
> not one-year (this means I can't easily create a new variable 1-365).
>
> How does R handle dates? My hunch is "not well," but perhaps there is a
> package that can help me with this. Let me know if you have any
> recommendations as to how this can be done relatively easily.
>
> Thanks! Appreciate it.
>
> Best,
> Brian
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dupouey at nancy.inra.fr  Thu Mar  5 00:42:32 2015
From: dupouey at nancy.inra.fr (Jean-Luc Dupouey)
Date: Thu, 05 Mar 2015 00:42:32 +0100
Subject: [R] .SavedPlots and replayPlot
Message-ID: <54F79868.1010109@nancy.inra.fr>

I would like to redraw a plot from the .SavedPlots object (list), using 
R code (not arrows on the keyboard).

 > windows(record=TRUE)
 >
 > x=runif(100)
 > plot(x,col="blue")
 > hist(x,col="red")
 > plot(x,col="green")

 > #When I try to replay any of the recorded plots (here, the second 
one), I get the following error message:

 > .SavedPlots[2]
Error in replayPlot(x) : loading snapshot from a different session

But I am in the same session! A quick look at function replayPlot shows 
that it is because the plots recorded in .SavedPlot do not have any pid 
value, whereas they should have one, equal to the current session pid.

Thus, assignation of the current session pid to the pid attribute of the 
recorded plots works:

 > for (i in 1:.SavedPlots[[2]]) 
attr(.SavedPlots[[5]][[i]],"pid")=Sys.getpid()
 > #correctly gives the second plot:
 > .SavedPlots[2]

Is it the right way to replay a plot in an R script, using .SavedPlots? 
Is there a simpler or better way?

I would prefer not to use recordPlot, which works, but requires an 
additional line of code and a new variable for each created plot:

 > plot(x,col="blue")
 > plot1=recordPlot()
 >
 > hist(x,col="red")
 > plot2=recordPlot()
 >
 > plot(x,col="green")
 > plot3=recordPlot()
 >
 > replayPlot(plot2)

I use R version 3.1.2.

Thanks in advance,

Jean-Luc Dupouey

-- 
INRA
Forest Ecology and Ecophysiology Unit
F-54280 Champenoux
France


From typhenn at yahoo.com  Wed Mar  4 23:02:06 2015
From: typhenn at yahoo.com (Typhenn Brichieri-Colombi)
Date: Wed, 4 Mar 2015 22:02:06 +0000 (UTC)
Subject: [R] R 3.1.2 using a custom function in aggregate() function on
 Windows 7 OS 64bit
Message-ID: <246549524.4368320.1425506526988.JavaMail.yahoo@mail.yahoo.com>

Hello,

I am trying to use the following custom function in an aggregatefunction, but cannot get R to recognize my data. I?ve read the help on function()and on aggregate() but am unable to solve my problem. How can I get R torecognize the data inputs for the custom function nested within aggregate()?

My custom function is found below, as well as the errormessage I get when I run it on a test data set (I will be using this functionon a much larger dataset (over 600,000 rows)) 

Thank you for your time and your help!


?
d_rule<-function(a,x){?

i<-which(a==max(a))

out<-ifelse(length(i)==1, x[i], min(x))

return(out)

}


?
a<-c(2,2,1,4,2,5,2,3,4,4)

x<-c(1:10)

g<-c(1,1,2,2,3,3,4,4,5,5)

dat<-as.data.frame(cbind(x,g))


?
test<-aggregate(dat, by=list(g), FUN=d_rule,dat$a, dat$x)

Error in dat$x : $ operator is invalid for atomic vectors



	[[alternative HTML version deleted]]


From alemu.tadesse at gmail.com  Thu Mar  5 02:46:23 2015
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Wed, 4 Mar 2015 18:46:23 -0700
Subject: [R] help with RODBC
Message-ID: <CACGkHRMUjXDfdH8qHLoYpeLVz-LOM4=dmFot7y5gPSG0E=Tq-Q@mail.gmail.com>

I want to apply  the following query to my database.

P2<-sqlQuery(ch1,'select *,
      TimeStamp_Local,
      ref_density,
      ref_dewpoint,
      ref_dir,
      ref_precip,
      ref_press,
      ref_rh,
      ref_snowfall,
      ref_snowdepth,
      ref_temperature_avg,
      ref_temperature_max,
      ref_temperature_min,
      ref_ws_avg,
      ref_ws_max,
      ref_wetbulb
  FROM ASOS.dbo.DailyData DD
  left outer join ASOS.dbo.ASOS_MetaData MD on MD.WBAN = DD.WBAN
where CallSign = 'BOS' order by TimeStamp_Local ASC')

where ch1 <- odbcConnect(dsn="SQLBI01", uid="DataPull", pwd="PullData")

in R (RODBC). I am running into the following error

Error: unexpected symbol in:
"  left outer join ASOS.dbo.ASOS_MetaData MD on MD.WBAN = DD.WBAN,
where CallSign = 'BOS"

I don't know why

Thanks,

Alemu

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Mar  5 03:23:07 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 04 Mar 2015 18:23:07 -0800
Subject: [R] help with RODBC
In-Reply-To: <CACGkHRMUjXDfdH8qHLoYpeLVz-LOM4=dmFot7y5gPSG0E=Tq-Q@mail.gmail.com>
References: <CACGkHRMUjXDfdH8qHLoYpeLVz-LOM4=dmFot7y5gPSG0E=Tq-Q@mail.gmail.com>
Message-ID: <D563F1EA-9D0C-457F-9660-99425C9DC914@dcn.davis.CA.us>

Why do you have single quotes inside your single quotes?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 4, 2015 5:46:23 PM PST, Alemu Tadesse <alemu.tadesse at gmail.com> wrote:
>I want to apply  the following query to my database.
>
>P2<-sqlQuery(ch1,'select *,
>      TimeStamp_Local,
>      ref_density,
>      ref_dewpoint,
>      ref_dir,
>      ref_precip,
>      ref_press,
>      ref_rh,
>      ref_snowfall,
>      ref_snowdepth,
>      ref_temperature_avg,
>      ref_temperature_max,
>      ref_temperature_min,
>      ref_ws_avg,
>      ref_ws_max,
>      ref_wetbulb
>  FROM ASOS.dbo.DailyData DD
>  left outer join ASOS.dbo.ASOS_MetaData MD on MD.WBAN = DD.WBAN
>where CallSign = 'BOS' order by TimeStamp_Local ASC')
>
>where ch1 <- odbcConnect(dsn="SQLBI01", uid="DataPull", pwd="PullData")
>
>in R (RODBC). I am running into the following error
>
>Error: unexpected symbol in:
>"  left outer join ASOS.dbo.ASOS_MetaData MD on MD.WBAN = DD.WBAN,
>where CallSign = 'BOS"
>
>I don't know why
>
>Thanks,
>
>Alemu
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Thu Mar  5 06:15:27 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 4 Mar 2015 21:15:27 -0800
Subject: [R] R 3.1.2 using a custom function in aggregate() function on
 Windows 7 OS 64bit
In-Reply-To: <246549524.4368320.1425506526988.JavaMail.yahoo@mail.yahoo.com>
References: <246549524.4368320.1425506526988.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CACk-te04TG-EWm3SoVcQ98TvQUiRajQg+SLmG-Jnr-2BH2_rwQ@mail.gmail.com>

What do you think dat$a is?

I recommend that you spend some time with an R tutorial if you plan to
use R. Your code is pretty bad. Examples: use of the ifelse
construction instead of if ... else; return()

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Mar 4, 2015 at 2:02 PM, Typhenn Brichieri-Colombi via R-help
<r-help at r-project.org> wrote:
> Hello,
>
> I am trying to use the following custom function in an aggregatefunction, but cannot get R to recognize my data. I?ve read the help on function()and on aggregate() but am unable to solve my problem. How can I get R torecognize the data inputs for the custom function nested within aggregate()?
>
> My custom function is found below, as well as the errormessage I get when I run it on a test data set (I will be using this functionon a much larger dataset (over 600,000 rows))
>
> Thank you for your time and your help!
>
>
>
> d_rule<-function(a,x){
>
> i<-which(a==max(a))
>
> out<-ifelse(length(i)==1, x[i], min(x))
>
> return(out)
>
> }
>
>
>
> a<-c(2,2,1,4,2,5,2,3,4,4)
>
> x<-c(1:10)
>
> g<-c(1,1,2,2,3,3,4,4,5,5)
>
> dat<-as.data.frame(cbind(x,g))
>
>
>
> test<-aggregate(dat, by=list(g), FUN=d_rule,dat$a, dat$x)
>
> Error in dat$x : $ operator is invalid for atomic vectors
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From js.huang at protective.com  Thu Mar  5 04:51:00 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 4 Mar 2015 19:51:00 -0800 (PST)
Subject: [R] remove repeated string in list
In-Reply-To: <CALJKBv9yi78ZHPxk_8ohagMD3psUBD71irHqhpotrueFUz8cSA@mail.gmail.com>
References: <CALJKBv9yi78ZHPxk_8ohagMD3psUBD71irHqhpotrueFUz8cSA@mail.gmail.com>
Message-ID: <1425527460857-4704189.post@n4.nabble.com>

Hi,

  Here is one for removing repeated strings.

> temp
$set1
[1] "a" "b" "d" "x"

$set2
[1] "b" "c" "q" "m"

$set3
[1] "b" "f" "e" "k" "q" "h"

> sapply(1:3,function(x){temp[[x]][as.numeric(table(unlist(temp))[temp[[x]]])==1]})
[[1]]
[1] "a" "d" "x"

[[2]]
[1] "c" "m"

[[3]]
[1] "f" "e" "k" "h"




--
View this message in context: http://r.789695.n4.nabble.com/remove-repeated-string-in-list-tp4704166p4704189.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Thu Mar  5 04:56:01 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 4 Mar 2015 19:56:01 -0800 (PST)
Subject: [R] remove repeated string in list
In-Reply-To: <1425527460857-4704189.post@n4.nabble.com>
References: <CALJKBv9yi78ZHPxk_8ohagMD3psUBD71irHqhpotrueFUz8cSA@mail.gmail.com>
	<1425527460857-4704189.post@n4.nabble.com>
Message-ID: <1425527761492-4704190.post@n4.nabble.com>

Hi,

  To avoid hardcoded 1:3, here is some revision.

> temp
$set1
[1] "a" "b" "d" "x"

$set2
[1] "b" "c" "q" "m"

$set3
[1] "b" "f" "e" "k" "q" "h"

> sapply(1:*length(temp)*,function(x){temp[[x]][as.numeric(table(unlist(temp))[temp[[x]]])==1]})
[[1]]
[1] "a" "d" "x"

[[2]]
[1] "c" "m"

[[3]]
[1] "f" "e" "k" "h"



--
View this message in context: http://r.789695.n4.nabble.com/remove-repeated-string-in-list-tp4704166p4704190.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Thu Mar  5 05:08:57 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 4 Mar 2015 20:08:57 -0800 (PST)
Subject: [R] remove repeated string in list
In-Reply-To: <CALJKBv9yi78ZHPxk_8ohagMD3psUBD71irHqhpotrueFUz8cSA@mail.gmail.com>
References: <CALJKBv9yi78ZHPxk_8ohagMD3psUBD71irHqhpotrueFUz8cSA@mail.gmail.com>
Message-ID: <1425528537678-4704191.post@n4.nabble.com>

Hi,

  Here is one for preserving the first strings.  as.numeric in the previous
posting is not necessary.

> temp
$set1
[1] "a" "b" "d" "x"

$set2
[1] "b" "c" "q" "m"

$set3
[1] "b" "f" "e" "k" "q" "h"

> sapply(1:length(temp),function(x){c <- list(); for (j in 1:x){c <-
> c(c,temp[[j]])}; temp[[x]][table(unlist(c))[temp[[x]]]==1]})
[[1]]
[1] "a" "b" "d" "x"

[[2]]
[1] "c" "q" "m"

[[3]]
[1] "f" "e" "k" "h"




--
View this message in context: http://r.789695.n4.nabble.com/remove-repeated-string-in-list-tp4704166p4704191.html
Sent from the R help mailing list archive at Nabble.com.


From ayang at mango-solutions.com  Thu Mar  5 07:49:45 2015
From: ayang at mango-solutions.com (Ava Yang)
Date: Thu, 5 Mar 2015 06:49:45 +0000
Subject: [R] FW:  Frontier efficient using black litterman model In R
In-Reply-To: <45924EF5E56C614F9942C1E70216397AA17F12E4@mexchange.Mango.local>
References: <CAC2J0hrNwCrzXabr_+A6dBC8fo9OqGMVeQGeF-obDc6qfviaSg@mail.gmail.com>
	<45924EF5E56C614F9942C1E70216397AA17F12E4@mexchange.Mango.local>
Message-ID: <3E4B52132CC2C741815B775259E998ED13D0CAB9@mexchange.Mango.local>

Hi Mukesh,

Glad to see someone using BLCOP.

You didn't provide a reproducible example so I assume you got a result list complete from optimalPortfolios.fPort() and wanted to obtain details of all the 10 simulations.

Short answer to your question: the function only renders the optimal value which is the mean of simulations. It is a wrapper of efficientPortfolio functions(minriskPortfolio in your example) from package fPortfolio. I believe looking deep at the source of optimalPortfolios.fPort, structure of result and slot details would help.

Best regards,

Ava

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of mukesh surywanshi
Sent: 03 March 2015 06:34
To: r-help at r-project.org
Subject: [R] Frontier efficient using black litterman model In R

Hi
I'm working on getting frontier efficient plot using Black Litterman model.

I have used Blcop package and its function

optimalPortfolio.optim()

using this i have got optimal risk and return with weights

If i want to get 10 portfolio risk and return with corresponding weights,,, how to do it>?
 can anyone help me....


my code goes like this
posterior <- posteriorEst(views, tau = 0.025, meanret, covar)

cons <- c("minW[1:numtk] = rep(0, times = numtk)", "maxW[1:numtk] = rep(0.50, times = numtk)","minsumW[1:numtk] = 0","maxsumW[1:numtk] = 1") #"listF = list(lowerExtension, upperExtension)")

res1<-optimalPortfolios.fPort(posterior,
spec=portfolioSpec(),constraints=cons,optimizer = "minriskPortfolio",numSimulations  = 10)



Thanks
MUKESH

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

--

LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}


From kmezhoud at gmail.com  Thu Mar  5 08:38:18 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Thu, 5 Mar 2015 07:38:18 +0000
Subject: [R] remove repeated string in list
In-Reply-To: <1425528537678-4704191.post@n4.nabble.com>
References: <CALJKBv9yi78ZHPxk_8ohagMD3psUBD71irHqhpotrueFUz8cSA@mail.gmail.com>
	<1425528537678-4704191.post@n4.nabble.com>
Message-ID: <CALJKBv9o6znVh3W5REwHeJ-VyjP3ni1gqjCR-=GY76bSyc-kiA@mail.gmail.com>

Many Thanks JS
karim

On Thu, Mar 5, 2015 at 4:08 AM, JS Huang <js.huang at protective.com> wrote:

> Hi,
>
>   Here is one for preserving the first strings.  as.numeric in the previous
> posting is not necessary.
>
> > temp
> $set1
> [1] "a" "b" "d" "x"
>
> $set2
> [1] "b" "c" "q" "m"
>
> $set3
> [1] "b" "f" "e" "k" "q" "h"
>
> > sapply(1:length(temp),function(x){c <- list(); for (j in 1:x){c <-
> > c(c,temp[[j]])}; temp[[x]][table(unlist(c))[temp[[x]]]==1]})
> [[1]]
> [1] "a" "b" "d" "x"
>
> [[2]]
> [1] "c" "q" "m"
>
> [[3]]
> [1] "f" "e" "k" "h"
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/remove-repeated-string-in-list-tp4704166p4704191.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Mar  5 11:24:38 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 5 Mar 2015 11:24:38 +0100
Subject: [R] Find the name of the package with called the function
Message-ID: <CAJuCY5wb7j2v_MnKUXq-kqhLv11e7OfOXaLS8YXHnZtUR_=wOw@mail.gmail.com>

Dear all,

I have several pacakges which all use some generic functions stored in
package. Let's call the package with generic functions 'auxiliary', a
package which uses those functions 'main'.

'auxiliary' has a function that needs the name of the package it is called
by. Currently I solve this by passing the name of the package as an
argument.

auxiliary::a <- function(package){
  cat("do something with", package)
}

#'@importFrom auxiliary a
main::use_a <- function(){
   a(package = "main")
}

I was wondering how I can rewrite this so I don't have to pass the package
name as an argument.

auxiliary::a <- function(){
  package <- the_thing_I_am_looking_for()
  cat("do something with", package)
}

#'@importFrom auxiliary a
main::use_a <- function(){
   a()
}

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Thu Mar  5 13:55:45 2015
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 05 Mar 2015 07:55:45 -0500
Subject: [R] Fitting Legend to Matrix Plot
In-Reply-To: <alpine.LNX.2.11.1503041332020.26347@localhost>
References: <alpine.LNX.2.11.1503041332020.26347@localhost>
Message-ID: <54F85251.6030409@yorku.ca>

Why not make the legend fit on one line above or below the plot matrix?

?legend
-- look at ncol=, horiz= and xpd= args

On 3/4/2015 4:39 PM, Rich Shepard wrote:
>    I have a matrix plot of ternary diagrams (pdf attached) generated with
> these commands:
>
> opar <- par(xpd=NA,no.readonly=T)
>
> plot(WintersY, pch=as.numeric(WintersX4),
>      col=c("black","red","green","blue","yellow","orange")[WintersX4])
>
> legend(x=0.75, y=0.0, abbreviate(levels(WintersX4),
>      minlength=1),pch=as.numeric(WintersX4),
>      col=c("black","red","green","blue","yellow","orange"), yjust=0)
>
> par(opar)
>
>    I have read ?legend but am uncertain what to adjust so the legend is
> readable yet not overlapping any of the plots. One of this series of plots
> has data from 8 years which would be a worse looking fit.
>
>    How should I specify the legend (or the plots themselves) in a figure
> that
> occupies the full display?
>
> Rich
>
>


From rshepard at appl-ecosys.com  Thu Mar  5 14:54:08 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 5 Mar 2015 05:54:08 -0800 (PST)
Subject: [R] Fitting Legend to Matrix Plot
In-Reply-To: <54F85251.6030409@yorku.ca>
References: <alpine.LNX.2.11.1503041332020.26347@localhost>
	<54F85251.6030409@yorku.ca>
Message-ID: <alpine.LNX.2.11.1503050551280.5862@localhost>

On Thu, 5 Mar 2015, Michael Friendly wrote:

> Why not make the legend fit on one line above or below the plot matrix?
> ?legend
> -- look at ncol=, horiz= and xpd= args

Michael,

   That's just the pointer I was hoping to see. There's no reason not to have
the legend outside the plot matrix and now I know where to experiment.

Much appreciated,

Rich


From jdnewmil at dcn.davis.CA.us  Thu Mar  5 16:03:23 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 05 Mar 2015 07:03:23 -0800
Subject: [R] Find the name of the package with called the function
In-Reply-To: <CAJuCY5wb7j2v_MnKUXq-kqhLv11e7OfOXaLS8YXHnZtUR_=wOw@mail.gmail.com>
References: <CAJuCY5wb7j2v_MnKUXq-kqhLv11e7OfOXaLS8YXHnZtUR_=wOw@mail.gmail.com>
Message-ID: <B4D50647-39AA-4B45-B171-F60EF8B4EE5E@dcn.davis.CA.us>

Please don't. This violates basic principles of functional design for a very minor degree of convenience. In fact, the whole concept of a function interface that accepts a caller's package name strikes me as brittle design. If your function needs to do callbacks, give it a function to call. If you need to manipulate an object, use some form of method dispatching (I like S3, but you have alternatives) on an object you pass in.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 5, 2015 2:24:38 AM PST, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>Dear all,
>
>I have several pacakges which all use some generic functions stored in
>package. Let's call the package with generic functions 'auxiliary', a
>package which uses those functions 'main'.
>
>'auxiliary' has a function that needs the name of the package it is
>called
>by. Currently I solve this by passing the name of the package as an
>argument.
>
>auxiliary::a <- function(package){
>  cat("do something with", package)
>}
>
>#'@importFrom auxiliary a
>main::use_a <- function(){
>   a(package = "main")
>}
>
>I was wondering how I can rewrite this so I don't have to pass the
>package
>name as an argument.
>
>auxiliary::a <- function(){
>  package <- the_thing_I_am_looking_for()
>  cat("do something with", package)
>}
>
>#'@importFrom auxiliary a
>main::use_a <- function(){
>   a()
>}
>
>Best regards,
>
>ir. Thierry Onkelinx
>Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>and
>Forest
>team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>Kliniekstraat 25
>1070 Anderlecht
>Belgium
>
>To call in the statistician after the experiment is done may be no more
>than asking him to perform a post-mortem examination: he may be able to
>say
>what the experiment died of. ~ Sir Ronald Aylmer Fisher
>The plural of anecdote is not data. ~ Roger Brinner
>The combination of some data and an aching desire for an answer does
>not
>ensure that a reasonable answer can be extracted from a given body of
>data.
>~ John Tukey
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Thu Mar  5 16:54:16 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 05 Mar 2015 07:54:16 -0800
Subject: [R] R 3.1.2 using a custom function in aggregate() function on
	Windows 7 OS 64bit
In-Reply-To: <246549524.4368320.1425506526988.JavaMail.yahoo@mail.yahoo.com>
References: <246549524.4368320.1425506526988.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <911ACBEC-6B9D-4C21-B78C-CA7689C03DA5@dcn.davis.CA.us>

The aggregate function applies FUN to vectors, not data frames. For example, the default "mean" function accepts a vector such as a column in a data frame and returns a scalar (well, a vector of length 1). Aggregate then calls this function once for each piece of the column(s) you give it. Your function wants two vectors, but aggregate does not understand how to give two inputs.

(In the future, please follow R-help mailing list guidelines and post using plain text so your code does not get messed up.)

You could use split to break your data frame into a list of data frames, and then sapply to extract the results you are looking for. I prefer to use the plyr or dplyr or data.table packages to do all this for me.

d_rule <- function( DF ) {
  i <- which( DF$a==max( DF$a ) )
  if ( length( i ) == 1 ){
    DF[ i, "x" ] 
  } else {
    min( DF[ , "x" ] ) # did you mean min( DF$x[i] ) ?
  }
}

dat <- data.frame( a=c(2,2,1,4,2,5,2,3,4,4)
    , x = c(1:10)
    , g = c(1,1,2,2,3,3,4,4,5,5)
    )
# note that cbind on vectors creates a matrix
# in a matrix all columns must be of the same type
# but data frames generally have a variety of types
# so don't use cbind when making a data frame

library( dplyr )

result <- dat %>% group_by( g ) %>% do( answer = d_rule( . ) ) %>% as.data.frame

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 4, 2015 2:02:06 PM PST, Typhenn Brichieri-Colombi via R-help <r-help at r-project.org> wrote:
>Hello,
>
>I am trying to use the following custom function in an
>aggregatefunction, but cannot get R to recognize my data. I?ve read the
>help on function()and on aggregate() but am unable to solve my problem.
>How can I get R torecognize the data inputs for the custom function
>nested within aggregate()?
>
>My custom function is found below, as well as the errormessage I get
>when I run it on a test data set (I will be using this functionon a
>much larger dataset (over 600,000 rows)) 
>
>Thank you for your time and your help!
>
>
>?
>d_rule<-function(a,x){?
>
>i<-which(a==max(a))
>
>out<-ifelse(length(i)==1, x[i], min(x))
>
>return(out)
>
>}
>
>
>?
>a<-c(2,2,1,4,2,5,2,3,4,4)
>
>x<-c(1:10)
>
>g<-c(1,1,2,2,3,3,4,4,5,5)
>
>dat<-as.data.frame(cbind(x,g))
>
>
>?
>test<-aggregate(dat, by=list(g), FUN=d_rule,dat$a, dat$x)
>
>Error in dat$x : $ operator is invalid for atomic vectors
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Thu Mar  5 17:12:39 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 5 Mar 2015 08:12:39 -0800
Subject: [R] R 3.1.2 using a custom function in aggregate() function on
 Windows 7 OS 64bit
In-Reply-To: <911ACBEC-6B9D-4C21-B78C-CA7689C03DA5@dcn.davis.CA.us>
References: <246549524.4368320.1425506526988.JavaMail.yahoo@mail.yahoo.com>
	<911ACBEC-6B9D-4C21-B78C-CA7689C03DA5@dcn.davis.CA.us>
Message-ID: <CACk-te1ryRxe+XqWgmmOaQyNAjMGiST4YpRWfksB0bVU4AGvig@mail.gmail.com>

Sorry, Jeff. aggregate() is generic.

>From ?aggregate:

"## S3 method for class 'data.frame'
aggregate(x, by, FUN, ..., simplify = TRUE)"

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Mar 5, 2015 at 7:54 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> The aggregate function applies FUN to vectors, not data frames. For example, the default "mean" function accepts a vector such as a column in a data frame and returns a scalar (well, a vector of length 1). Aggregate then calls this function once for each piece of the column(s) you give it. Your function wants two vectors, but aggregate does not understand how to give two inputs.
>
> (In the future, please follow R-help mailing list guidelines and post using plain text so your code does not get messed up.)
>
> You could use split to break your data frame into a list of data frames, and then sapply to extract the results you are looking for. I prefer to use the plyr or dplyr or data.table packages to do all this for me.
>
> d_rule <- function( DF ) {
>   i <- which( DF$a==max( DF$a ) )
>   if ( length( i ) == 1 ){
>     DF[ i, "x" ]
>   } else {
>     min( DF[ , "x" ] ) # did you mean min( DF$x[i] ) ?
>   }
> }
>
> dat <- data.frame( a=c(2,2,1,4,2,5,2,3,4,4)
>     , x = c(1:10)
>     , g = c(1,1,2,2,3,3,4,4,5,5)
>     )
> # note that cbind on vectors creates a matrix
> # in a matrix all columns must be of the same type
> # but data frames generally have a variety of types
> # so don't use cbind when making a data frame
>
> library( dplyr )
>
> result <- dat %>% group_by( g ) %>% do( answer = d_rule( . ) ) %>% as.data.frame
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On March 4, 2015 2:02:06 PM PST, Typhenn Brichieri-Colombi via R-help <r-help at r-project.org> wrote:
>>Hello,
>>
>>I am trying to use the following custom function in an
>>aggregatefunction, but cannot get R to recognize my data. I?ve read the
>>help on function()and on aggregate() but am unable to solve my problem.
>>How can I get R torecognize the data inputs for the custom function
>>nested within aggregate()?
>>
>>My custom function is found below, as well as the errormessage I get
>>when I run it on a test data set (I will be using this functionon a
>>much larger dataset (over 600,000 rows))
>>
>>Thank you for your time and your help!
>>
>>
>>
>>d_rule<-function(a,x){
>>
>>i<-which(a==max(a))
>>
>>out<-ifelse(length(i)==1, x[i], min(x))
>>
>>return(out)
>>
>>}
>>
>>
>>
>>a<-c(2,2,1,4,2,5,2,3,4,4)
>>
>>x<-c(1:10)
>>
>>g<-c(1,1,2,2,3,3,4,4,5,5)
>>
>>dat<-as.data.frame(cbind(x,g))
>>
>>
>>
>>test<-aggregate(dat, by=list(g), FUN=d_rule,dat$a, dat$x)
>>
>>Error in dat$x : $ operator is invalid for atomic vectors
>>
>>
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Thu Mar  5 17:27:22 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 05 Mar 2015 08:27:22 -0800
Subject: [R] help with RODBC
In-Reply-To: <CACGkHRO+m3b+-xUYKH9CXKgBQG3uMQKpCdPPgz9ADx3CWtN6nw@mail.gmail.com>
References: <CACGkHRMUjXDfdH8qHLoYpeLVz-LOM4=dmFot7y5gPSG0E=Tq-Q@mail.gmail.com>
	<D563F1EA-9D0C-457F-9660-99425C9DC914@dcn.davis.CA.us>
	<CACGkHRO+m3b+-xUYKH9CXKgBQG3uMQKpCdPPgz9ADx3CWtN6nw@mail.gmail.com>
Message-ID: <52C0F98E-823C-4E3C-8B16-DF915717FD69@dcn.davis.CA.us>

Using HTML email is, as usual, obscuring what you are doing on this end of the communication. The error message indicates that you have single quotes around the BOS term, but they are not visible in the code you have presented. In addition, there is a syntax error in having the word 'from' before the keyword 'select' in your code. It is hard to believe the error and presented code are related.

The actual error given below is different than the one you originally posted. This one suggests that you cannot see a table. This is not an R problem. It could be that that table name is misspelled, or it could mean that the login permissions you are using from R don't allow access to that data table. Or something else... but not related to R. 

Note that there is a mailing list where database use with R is on topic... R-sig-db.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 5, 2015 7:57:51 AM PST, Alemu Tadesse <alemu.tadesse at gmail.com> wrote:
>Hi Jeff,
>
>Thank you very much for your prompt reply and help.
>
>I have also tried without quote and it did not work for me. I was told
>that
>the query works on the  microsoft sql management studio as shown below.
>[image: Inline image 1]
>
>in my R script what I did is :
>
>ch1 <- odbcConnect(dsn="COLOMSQLQC01", uid="Data_Pull",
>pwd="Pull_Data")
>> ch1
>RODBC Connection 8
>Details:
>  case=nochange
>  DSN=COLOMSQLQC01
>  Description=COLOMSQLQC01
>  UID=DataPull
>  PWD=******
>  APP=RStudio
>  WSID=R9V7LFH
>
>P<-sqlQuery(ch1,'from select DD.WBAN,
>      TimeStamp_Local,
>      ref_density,
>      ref_dewpoint,
>      ref_dir,
>      ref_precip,
>      ref_press,
>      ref_rh,
>      ref_snowfall,
>      ref_snowdepth,
>      ref_temperature_avg,
>      ref_temperature_max,
>      ref_temperature_min,
>      ref_ws_avg,
>      ref_ws_max,
>      ref_wetbulb
>  FROM ASOS.dbo.DailyData DD
>  left outer join ASOS.dbo.ASOS_MetaData MD on MD.WBAN = DD.WBAN
>where CallSign = BOS order by TimeStamp_Local ASC')
>
>As you can see below, there is no data in P
>
>
>> P
>[1] "42S02 208 [Microsoft][ODBC SQL Server Driver][SQL Server]Invalid
>object name 'ASOS.dbo.DailyData'."
>
>
>
>
>
>
>[2] "[RODBC] ERROR: Could not SQLExecDirect 'SELECT DD.WBAN\n
> ,TimeStamp_Local\n      ,ref_density\n      ,ref_dewpoint\n
> ,ref_dir\n      ,ref_precip\n      ,ref_press\n      ,ref_rh\n
> ,ref_snowfall\n      ,ref_snowdepth\n      ,ref_temperature_avg\n
> ,ref_temperature_max\n      ,ref_temperature_min\n      ,ref_ws_avg\n
> ,ref_ws_max\n      ,ref_wetbulb\n  FROM ASOS.dbo.DailyData DD\n  left
>outer join ASOS.dbo.ASOS_MetaData MD on MD.WBAN = DD.WBAN\nwhere
>CallSign =
>'BOS' order by TimeStamp_Local ASC'"
>
>I did not understand my problem.
>
>Cheers,
>
>Alemu
>
>
>
>
>On Wed, Mar 4, 2015 at 7:23 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Why do you have single quotes inside your single quotes?
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 4, 2015 5:46:23 PM PST, Alemu Tadesse
><alemu.tadesse at gmail.com>
>> wrote:
>> >I want to apply  the following query to my database.
>> >
>> >P2<-sqlQuery(ch1,'select *,
>> >      TimeStamp_Local,
>> >      ref_density,
>> >      ref_dewpoint,
>> >      ref_dir,
>> >      ref_precip,
>> >      ref_press,
>> >      ref_rh,
>> >      ref_snowfall,
>> >      ref_snowdepth,
>> >      ref_temperature_avg,
>> >      ref_temperature_max,
>> >      ref_temperature_min,
>> >      ref_ws_avg,
>> >      ref_ws_max,
>> >      ref_wetbulb
>> >  FROM ASOS.dbo.DailyData DD
>> >  left outer join ASOS.dbo.ASOS_MetaData MD on MD.WBAN = DD.WBAN
>> >where CallSign = 'BOS' order by TimeStamp_Local ASC')
>> >
>> >where ch1 <- odbcConnect(dsn="SQLBI01", uid="DataPull",
>pwd="PullData")
>> >
>> >in R (RODBC). I am running into the following error
>> >
>> >Error: unexpected symbol in:
>> >"  left outer join ASOS.dbo.ASOS_MetaData MD on MD.WBAN = DD.WBAN,
>> >where CallSign = 'BOS"
>> >
>> >I don't know why
>> >
>> >Thanks,
>> >
>> >Alemu
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From jdnewmil at dcn.davis.CA.us  Thu Mar  5 17:55:07 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 05 Mar 2015 08:55:07 -0800
Subject: [R] R 3.1.2 using a custom function in aggregate() function on
	Windows 7 OS 64bit
In-Reply-To: <CACk-te1ryRxe+XqWgmmOaQyNAjMGiST4YpRWfksB0bVU4AGvig@mail.gmail.com>
References: <246549524.4368320.1425506526988.JavaMail.yahoo@mail.yahoo.com>
	<911ACBEC-6B9D-4C21-B78C-CA7689C03DA5@dcn.davis.CA.us>
	<CACk-te1ryRxe+XqWgmmOaQyNAjMGiST4YpRWfksB0bVU4AGvig@mail.gmail.com>
Message-ID: <B74A33D0-BB19-4C07-B387-18D79DD6DBBE@dcn.davis.CA.us>

I don't see your point. No matter which version of aggregate you use, FUN is applied to vectors. Those vectors may be columns in a data frame or not, but FUN is always given one vector at a time by aggregate.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 5, 2015 8:12:39 AM PST, Bert Gunter <gunter.berton at gene.com> wrote:
>Sorry, Jeff. aggregate() is generic.
>
>>From ?aggregate:
>
>"## S3 method for class 'data.frame'
>aggregate(x, by, FUN, ..., simplify = TRUE)"
>
>Cheers,
>Bert
>
>Bert Gunter
>Genentech Nonclinical Biostatistics
>(650) 467-7374
>
>"Data is not information. Information is not knowledge. And knowledge
>is certainly not wisdom."
>Clifford Stoll
>
>
>
>
>On Thu, Mar 5, 2015 at 7:54 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> The aggregate function applies FUN to vectors, not data frames. For
>example, the default "mean" function accepts a vector such as a column
>in a data frame and returns a scalar (well, a vector of length 1).
>Aggregate then calls this function once for each piece of the column(s)
>you give it. Your function wants two vectors, but aggregate does not
>understand how to give two inputs.
>>
>> (In the future, please follow R-help mailing list guidelines and post
>using plain text so your code does not get messed up.)
>>
>> You could use split to break your data frame into a list of data
>frames, and then sapply to extract the results you are looking for. I
>prefer to use the plyr or dplyr or data.table packages to do all this
>for me.
>>
>> d_rule <- function( DF ) {
>>   i <- which( DF$a==max( DF$a ) )
>>   if ( length( i ) == 1 ){
>>     DF[ i, "x" ]
>>   } else {
>>     min( DF[ , "x" ] ) # did you mean min( DF$x[i] ) ?
>>   }
>> }
>>
>> dat <- data.frame( a=c(2,2,1,4,2,5,2,3,4,4)
>>     , x = c(1:10)
>>     , g = c(1,1,2,2,3,3,4,4,5,5)
>>     )
>> # note that cbind on vectors creates a matrix
>> # in a matrix all columns must be of the same type
>> # but data frames generally have a variety of types
>> # so don't use cbind when making a data frame
>>
>> library( dplyr )
>>
>> result <- dat %>% group_by( g ) %>% do( answer = d_rule( . ) ) %>%
>as.data.frame
>>
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 4, 2015 2:02:06 PM PST, Typhenn Brichieri-Colombi via R-help
><r-help at r-project.org> wrote:
>>>Hello,
>>>
>>>I am trying to use the following custom function in an
>>>aggregatefunction, but cannot get R to recognize my data. I?ve read
>the
>>>help on function()and on aggregate() but am unable to solve my
>problem.
>>>How can I get R torecognize the data inputs for the custom function
>>>nested within aggregate()?
>>>
>>>My custom function is found below, as well as the errormessage I get
>>>when I run it on a test data set (I will be using this functionon a
>>>much larger dataset (over 600,000 rows))
>>>
>>>Thank you for your time and your help!
>>>
>>>
>>>
>>>d_rule<-function(a,x){
>>>
>>>i<-which(a==max(a))
>>>
>>>out<-ifelse(length(i)==1, x[i], min(x))
>>>
>>>return(out)
>>>
>>>}
>>>
>>>
>>>
>>>a<-c(2,2,1,4,2,5,2,3,4,4)
>>>
>>>x<-c(1:10)
>>>
>>>g<-c(1,1,2,2,3,3,4,4,5,5)
>>>
>>>dat<-as.data.frame(cbind(x,g))
>>>
>>>
>>>
>>>test<-aggregate(dat, by=list(g), FUN=d_rule,dat$a, dat$x)
>>>
>>>Error in dat$x : $ operator is invalid for atomic vectors
>>>
>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Thu Mar  5 17:59:55 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 5 Mar 2015 08:59:55 -0800
Subject: [R] R 3.1.2 using a custom function in aggregate() function on
 Windows 7 OS 64bit
In-Reply-To: <B74A33D0-BB19-4C07-B387-18D79DD6DBBE@dcn.davis.CA.us>
References: <246549524.4368320.1425506526988.JavaMail.yahoo@mail.yahoo.com>
	<911ACBEC-6B9D-4C21-B78C-CA7689C03DA5@dcn.davis.CA.us>
	<CACk-te1ryRxe+XqWgmmOaQyNAjMGiST4YpRWfksB0bVU4AGvig@mail.gmail.com>
	<B74A33D0-BB19-4C07-B387-18D79DD6DBBE@dcn.davis.CA.us>
Message-ID: <CACk-te2jNcFJF5ke+YF07dHxswTDQ1UoJee7Wh5siLnyJbfTBg@mail.gmail.com>

That's not what ?aggregate says:

"aggregate.data.frame is the data frame method. If x is not a data
frame, it is coerced to one, which must have a non-zero number of
rows. Then, each of the variables (columns) in x is split into subsets
of cases (rows) of identical combinations of the components of by, and
FUN is applied to each such subset with further arguments in ...
passed to it."


As I read this, the argument of FUN is a data frame that is a subset
of the original frame, defined by the by variable values.


No?


-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Mar 5, 2015 at 8:55 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> I don't see your point. No matter which version of aggregate you use, FUN is applied to vectors. Those vectors may be columns in a data frame or not, but FUN is always given one vector at a time by aggregate.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On March 5, 2015 8:12:39 AM PST, Bert Gunter <gunter.berton at gene.com> wrote:
>>Sorry, Jeff. aggregate() is generic.
>>
>>>From ?aggregate:
>>
>>"## S3 method for class 'data.frame'
>>aggregate(x, by, FUN, ..., simplify = TRUE)"
>>
>>Cheers,
>>Bert
>>
>>Bert Gunter
>>Genentech Nonclinical Biostatistics
>>(650) 467-7374
>>
>>"Data is not information. Information is not knowledge. And knowledge
>>is certainly not wisdom."
>>Clifford Stoll
>>
>>
>>
>>
>>On Thu, Mar 5, 2015 at 7:54 AM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us> wrote:
>>> The aggregate function applies FUN to vectors, not data frames. For
>>example, the default "mean" function accepts a vector such as a column
>>in a data frame and returns a scalar (well, a vector of length 1).
>>Aggregate then calls this function once for each piece of the column(s)
>>you give it. Your function wants two vectors, but aggregate does not
>>understand how to give two inputs.
>>>
>>> (In the future, please follow R-help mailing list guidelines and post
>>using plain text so your code does not get messed up.)
>>>
>>> You could use split to break your data frame into a list of data
>>frames, and then sapply to extract the results you are looking for. I
>>prefer to use the plyr or dplyr or data.table packages to do all this
>>for me.
>>>
>>> d_rule <- function( DF ) {
>>>   i <- which( DF$a==max( DF$a ) )
>>>   if ( length( i ) == 1 ){
>>>     DF[ i, "x" ]
>>>   } else {
>>>     min( DF[ , "x" ] ) # did you mean min( DF$x[i] ) ?
>>>   }
>>> }
>>>
>>> dat <- data.frame( a=c(2,2,1,4,2,5,2,3,4,4)
>>>     , x = c(1:10)
>>>     , g = c(1,1,2,2,3,3,4,4,5,5)
>>>     )
>>> # note that cbind on vectors creates a matrix
>>> # in a matrix all columns must be of the same type
>>> # but data frames generally have a variety of types
>>> # so don't use cbind when making a data frame
>>>
>>> library( dplyr )
>>>
>>> result <- dat %>% group_by( g ) %>% do( answer = d_rule( . ) ) %>%
>>as.data.frame
>>>
>>>
>>---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>Go...
>>>                                       Live:   OO#.. Dead: OO#..
>>Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>rocks...1k
>>>
>>---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 4, 2015 2:02:06 PM PST, Typhenn Brichieri-Colombi via R-help
>><r-help at r-project.org> wrote:
>>>>Hello,
>>>>
>>>>I am trying to use the following custom function in an
>>>>aggregatefunction, but cannot get R to recognize my data. I?ve read
>>the
>>>>help on function()and on aggregate() but am unable to solve my
>>problem.
>>>>How can I get R torecognize the data inputs for the custom function
>>>>nested within aggregate()?
>>>>
>>>>My custom function is found below, as well as the errormessage I get
>>>>when I run it on a test data set (I will be using this functionon a
>>>>much larger dataset (over 600,000 rows))
>>>>
>>>>Thank you for your time and your help!
>>>>
>>>>
>>>>
>>>>d_rule<-function(a,x){
>>>>
>>>>i<-which(a==max(a))
>>>>
>>>>out<-ifelse(length(i)==1, x[i], min(x))
>>>>
>>>>return(out)
>>>>
>>>>}
>>>>
>>>>
>>>>
>>>>a<-c(2,2,1,4,2,5,2,3,4,4)
>>>>
>>>>x<-c(1:10)
>>>>
>>>>g<-c(1,1,2,2,3,3,4,4,5,5)
>>>>
>>>>dat<-as.data.frame(cbind(x,g))
>>>>
>>>>
>>>>
>>>>test<-aggregate(dat, by=list(g), FUN=d_rule,dat$a, dat$x)
>>>>
>>>>Error in dat$x : $ operator is invalid for atomic vectors
>>>>
>>>>
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From jim.silverton at gmail.com  Thu Mar  5 18:07:32 2015
From: jim.silverton at gmail.com (Jim Silverton)
Date: Thu, 5 Mar 2015 13:07:32 -0400
Subject: [R] Help with Boxplot
Message-ID: <CAGPwjHzhZ0cOtBeyOCMWebDdo0u_J7OXBzop2PL59Pm91uXRsA@mail.gmail.com>

I have the following R code for a boxplot. But I keep getting 4 1's, 4 2's
and 4 3's on the x asis for which I reall want to relace the 1's by
agegroup 1 the 2's by age group 2 etc. And I don't want to replce it 4
times just once. Can anyone help.


boxplot(data.all ~ age.group, data = data.plots,
        boxwex = 0.5, at = c(1, 4, 7, 10),
        subset = model.type == 1, col = "yellow",
        main = "Deviation of Predicted from Actual",
        xlab = "Age Groups",
        ylab = "Deviations",
        xlim = c(0.5, 12), ylim = c(-25, 35))
boxplot(data.all ~ age.group, data = data.plots, add = TRUE,
        boxwex = 0.5, at = c(1.7, 4.7, 7.7, 10.7),
        subset = model.type == 2, col = "orange")
boxplot(data.all ~ age.group, data = data.plots, add = TRUE,
        boxwex = 0.5, at = c(2.4, 5.4, 8.4, 11.4),
        subset = model.type == 3, col = "blue")
legend(1, 30, c("regression", "glm", "gam"),fill = c("yellow", "orange",
"blue"))



-- 
Thanks,
Jim.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Mar  5 19:09:28 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Mar 2015 10:09:28 -0800
Subject: [R] R 3.1.2 using a custom function in aggregate() function on
	Windows 7 OS 64bit
In-Reply-To: <246549524.4368320.1425506526988.JavaMail.yahoo@mail.yahoo.com>
References: <246549524.4368320.1425506526988.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CB82DFDF-C7E4-4576-A09B-5673ACAB8829@comcast.net>


On Mar 4, 2015, at 2:02 PM, Typhenn Brichieri-Colombi via R-help wrote:

> Hello,
> 
> I am trying to use the following custom function in an aggregatefunction, but cannot get R to recognize my data. I?ve read the help on function()and on aggregate() but am unable to solve my problem. How can I get R torecognize the data inputs for the custom function nested within aggregate()?
> 
> My custom function is found below, as well as the errormessage I get when I run it on a test data set (I will be using this functionon a much larger dataset (over 600,000 rows)) 
> 
> Thank you for your time and your help!
>  
> d_rule<-function(a,x){ 
> i<-which(a==max(a))
> out<-ifelse(length(i)==1, x[i], min(x))
> return(out)
> }
>  
> a<-c(2,2,1,4,2,5,2,3,4,4)
> x<-c(1:10)
> g<-c(1,1,2,2,3,3,4,4,5,5)
> dat<-as.data.frame(cbind(x,g))
>  
> test<-aggregate(dat, by=list(g), FUN=d_rule,dat$a, dat$x)
> 
> Error in dat$x : $ operator is invalid for atomic vectors

That message makes no sense to me because it suggests that the 'dat'-object was not a dataframe.

I get a different error which I think I can explain:

> test<-aggregate(dat, by=list(g), FUN=d_rule,dat$a, dat$x)
Error in FUN(X[[1L]], ...) : 
  unused argument (c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))

The aggregate.data.frame function is I believe one by one positionally matching  the x and g columns to the a-parameter of the d_rule-function and would be attempting to use dat$a (which as far as I can tell doesn't exist and would throw an error if the interpreter ever got to that step)  as the match to the d_rule x-parameter, but before it does that, it tries to match dat$x to some parameter in d_rule but because both parameters already have candidate objects matched up, it fails producing the error message I see.

(It's also very bad practice to use the construction as.data.frame(cbind(x,g)). It will mangle the results if there are either factor or character variables inside the cbind().

-- 
David.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From clint at ecy.wa.gov  Thu Mar  5 19:26:24 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Thu, 5 Mar 2015 10:26:24 -0800 (PST)
Subject: [R] Help with Boxplot
In-Reply-To: <CAGPwjHzhZ0cOtBeyOCMWebDdo0u_J7OXBzop2PL59Pm91uXRsA@mail.gmail.com>
References: <CAGPwjHzhZ0cOtBeyOCMWebDdo0u_J7OXBzop2PL59Pm91uXRsA@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1503051023480.18806@aeolus.ecy.wa.gov>

Jim,

Have you looked at:

names: group labels which will be printed under each boxplot.  Can
           be a character vector or an expression (see plotmath).

You could use "" where you want a blank.  I believe that "at" may work 
here also.

Clint

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Thu, 5 Mar 2015, Jim Silverton wrote:

> I have the following R code for a boxplot. But I keep getting 4 1's, 4 2's
> and 4 3's on the x asis for which I reall want to relace the 1's by
> agegroup 1 the 2's by age group 2 etc. And I don't want to replce it 4
> times just once. Can anyone help.
>
>
> boxplot(data.all ~ age.group, data = data.plots,
>        boxwex = 0.5, at = c(1, 4, 7, 10),
>        subset = model.type == 1, col = "yellow",
>        main = "Deviation of Predicted from Actual",
>        xlab = "Age Groups",
>        ylab = "Deviations",
>        xlim = c(0.5, 12), ylim = c(-25, 35))
> boxplot(data.all ~ age.group, data = data.plots, add = TRUE,
>        boxwex = 0.5, at = c(1.7, 4.7, 7.7, 10.7),
>        subset = model.type == 2, col = "orange")
> boxplot(data.all ~ age.group, data = data.plots, add = TRUE,
>        boxwex = 0.5, at = c(2.4, 5.4, 8.4, 11.4),
>        subset = model.type == 3, col = "blue")
> legend(1, 30, c("regression", "glm", "gam"),fill = c("yellow", "orange",
> "blue"))
>
>
>
> -- 
> Thanks,
> Jim.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From n.l.pace at utah.edu  Thu Mar  5 19:36:38 2015
From: n.l.pace at utah.edu (Nathan Pace)
Date: Thu, 5 Mar 2015 18:36:38 +0000
Subject: [R] deming package error message
Message-ID: <D11DF044.50988%n.l.pace@utah.edu>

I don?t understand an error message from a thielsen function call within a
dplyr do function call.

by.CaseNo <- group_by(as.data.frame(MAP.dt), CaseNo)
> MAP.thielsen <- by.CaseNo %>%
+   do(model = thielsen(noninvMAP ~ invMAP, symmetric = T, data = .,
+                       x = T, y = T, model = T, nboot = 1000))
|                                                   |  1% ~40 m remaining
  

Error in if (any(tied)) { : missing value where TRUE/FALSE needed



This error does not occur and the function call completes if nboot = 0.


Nathan


> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] boot_1.3-15      deming_1.0-1     dplyr_0.4.1      data.table_1.9.4
[5] lme4_1.1-7       Rcpp_0.11.4      Matrix_1.1-5

loaded via a namespace (and not attached):
 [1] assertthat_0.1  chron_2.3-45    DBI_0.3.1       grid_3.1.2
 [5] lattice_0.20-30 lazyeval_0.1.10 magrittr_1.5    MASS_7.3-39
 [9] minqa_1.2.4     nlme_3.1-120    nloptr_1.0.4    parallel_3.1.2
[13] plyr_1.8.1      R6_2.0.1        reshape2_1.4.1  splines_3.1.2
[17] stringr_0.6.2   tools_3.1.2  


From friendly at yorku.ca  Thu Mar  5 19:45:11 2015
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 05 Mar 2015 13:45:11 -0500
Subject: [R] subset a data frame by largest frequencies of factors
Message-ID: <54F8A437.90404@yorku.ca>

A consulting client has a large data set with a binary response 
(negative) and two factors (ctry and member) which have many levels,
but many occur with very small frequencies.  It is far too sparse with a 
model like glm(negative ~ ctry+member, family=binomial).

 > str(Dataset)
'data.frame':   10672 obs. of  5 variables:
  $ ctry    : Factor w/ 31 levels "Barbados","Belize",..: 21 21 5 22 18 
18 18 18 26 18 ...
  $ member  : Factor w/ 163 levels "","ADHOPIA, PREETI ",..: 150 19 19 
111 120 1 1 4 55 18 ...
  $ negative: int  0 1 0 1 1 1 1 0 0 0 ...
 >

For analysis, we'd like to subset the data to include only those that 
occur with frequency greater than a given
value, or the top 10 (say) in frequency, or the highest frequency 
categories accounting for 80% (say) of the
total.  I'm not sure how to do any of these in R.  Can anyone help?

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From jdnewmil at dcn.davis.CA.us  Thu Mar  5 19:47:18 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 05 Mar 2015 10:47:18 -0800
Subject: [R] R 3.1.2 using a custom function in aggregate() function on
	Windows 7 OS 64bit
In-Reply-To: <CACk-te2jNcFJF5ke+YF07dHxswTDQ1UoJee7Wh5siLnyJbfTBg@mail.gmail.com>
References: <246549524.4368320.1425506526988.JavaMail.yahoo@mail.yahoo.com>
	<911ACBEC-6B9D-4C21-B78C-CA7689C03DA5@dcn.davis.CA.us>
	<CACk-te1ryRxe+XqWgmmOaQyNAjMGiST4YpRWfksB0bVU4AGvig@mail.gmail.com>
	<B74A33D0-BB19-4C07-B387-18D79DD6DBBE@dcn.davis.CA.us>
	<CACk-te2jNcFJF5ke+YF07dHxswTDQ1UoJee7Wh5siLnyJbfTBg@mail.gmail.com>
Message-ID: <81B768C1-2D02-4D4F-BED1-94224AF394A3@dcn.davis.CA.us>

Bert: using the sample data frame from below, try to interpret the output of this:

aggregate( dat[,1:2], dat[,"g",drop=FALSE, FUN=function(x){print(x);class(x)})

The help text you quote is probably not as clear as it should be. Would the following be better?

"... and FUN is applied to each column in each such subset with further arguments in ... passed to it."

I became aware of this "feature" because this application of exactly the same aggregation function to all of my data columns is not convenient for my day-to-day work. Thus, I don't use "aggregate" very often.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 5, 2015 8:59:55 AM PST, Bert Gunter <gunter.berton at gene.com> wrote:
>That's not what ?aggregate says:
>
>"aggregate.data.frame is the data frame method. If x is not a data
>frame, it is coerced to one, which must have a non-zero number of
>rows. Then, each of the variables (columns) in x is split into subsets
>of cases (rows) of identical combinations of the components of by, and
>FUN is applied to each such subset with further arguments in ...
>passed to it."
>
>
>As I read this, the argument of FUN is a data frame that is a subset
>of the original frame, defined by the by variable values.
>
>
>No?
>
>
>-- Bert
>
>Bert Gunter
>Genentech Nonclinical Biostatistics
>(650) 467-7374
>
>"Data is not information. Information is not knowledge. And knowledge
>is certainly not wisdom."
>Clifford Stoll
>
>
>
>
>On Thu, Mar 5, 2015 at 8:55 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> I don't see your point. No matter which version of aggregate you use,
>FUN is applied to vectors. Those vectors may be columns in a data frame
>or not, but FUN is always given one vector at a time by aggregate.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 5, 2015 8:12:39 AM PST, Bert Gunter <gunter.berton at gene.com>
>wrote:
>>>Sorry, Jeff. aggregate() is generic.
>>>
>>>>From ?aggregate:
>>>
>>>"## S3 method for class 'data.frame'
>>>aggregate(x, by, FUN, ..., simplify = TRUE)"
>>>
>>>Cheers,
>>>Bert
>>>
>>>Bert Gunter
>>>Genentech Nonclinical Biostatistics
>>>(650) 467-7374
>>>
>>>"Data is not information. Information is not knowledge. And knowledge
>>>is certainly not wisdom."
>>>Clifford Stoll
>>>
>>>
>>>
>>>
>>>On Thu, Mar 5, 2015 at 7:54 AM, Jeff Newmiller
>>><jdnewmil at dcn.davis.ca.us> wrote:
>>>> The aggregate function applies FUN to vectors, not data frames. For
>>>example, the default "mean" function accepts a vector such as a
>column
>>>in a data frame and returns a scalar (well, a vector of length 1).
>>>Aggregate then calls this function once for each piece of the
>column(s)
>>>you give it. Your function wants two vectors, but aggregate does not
>>>understand how to give two inputs.
>>>>
>>>> (In the future, please follow R-help mailing list guidelines and
>post
>>>using plain text so your code does not get messed up.)
>>>>
>>>> You could use split to break your data frame into a list of data
>>>frames, and then sapply to extract the results you are looking for. I
>>>prefer to use the plyr or dplyr or data.table packages to do all this
>>>for me.
>>>>
>>>> d_rule <- function( DF ) {
>>>>   i <- which( DF$a==max( DF$a ) )
>>>>   if ( length( i ) == 1 ){
>>>>     DF[ i, "x" ]
>>>>   } else {
>>>>     min( DF[ , "x" ] ) # did you mean min( DF$x[i] ) ?
>>>>   }
>>>> }
>>>>
>>>> dat <- data.frame( a=c(2,2,1,4,2,5,2,3,4,4)
>>>>     , x = c(1:10)
>>>>     , g = c(1,1,2,2,3,3,4,4,5,5)
>>>>     )
>>>> # note that cbind on vectors creates a matrix
>>>> # in a matrix all columns must be of the same type
>>>> # but data frames generally have a variety of types
>>>> # so don't use cbind when making a data frame
>>>>
>>>> library( dplyr )
>>>>
>>>> result <- dat %>% group_by( g ) %>% do( answer = d_rule( . ) ) %>%
>>>as.data.frame
>>>>
>>>>
>>>---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>>Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live
>>>Go...
>>>>                                       Live:   OO#.. Dead: OO#..
>>>Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>rocks...1k
>>>>
>>>---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On March 4, 2015 2:02:06 PM PST, Typhenn Brichieri-Colombi via
>R-help
>>><r-help at r-project.org> wrote:
>>>>>Hello,
>>>>>
>>>>>I am trying to use the following custom function in an
>>>>>aggregatefunction, but cannot get R to recognize my data. I?ve read
>>>the
>>>>>help on function()and on aggregate() but am unable to solve my
>>>problem.
>>>>>How can I get R torecognize the data inputs for the custom function
>>>>>nested within aggregate()?
>>>>>
>>>>>My custom function is found below, as well as the errormessage I
>get
>>>>>when I run it on a test data set (I will be using this functionon a
>>>>>much larger dataset (over 600,000 rows))
>>>>>
>>>>>Thank you for your time and your help!
>>>>>
>>>>>
>>>>>
>>>>>d_rule<-function(a,x){
>>>>>
>>>>>i<-which(a==max(a))
>>>>>
>>>>>out<-ifelse(length(i)==1, x[i], min(x))
>>>>>
>>>>>return(out)
>>>>>
>>>>>}
>>>>>
>>>>>
>>>>>
>>>>>a<-c(2,2,1,4,2,5,2,3,4,4)
>>>>>
>>>>>x<-c(1:10)
>>>>>
>>>>>g<-c(1,1,2,2,3,3,4,4,5,5)
>>>>>
>>>>>dat<-as.data.frame(cbind(x,g))
>>>>>
>>>>>
>>>>>
>>>>>test<-aggregate(dat, by=list(g), FUN=d_rule,dat$a, dat$x)
>>>>>
>>>>>Error in dat$x : $ operator is invalid for atomic vectors
>>>>>
>>>>>
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>>______________________________________________
>>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>PLEASE do read the posting guide
>>>>>http://www.R-project.org/posting-guide.html
>>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>


From gunter.berton at gene.com  Thu Mar  5 20:19:53 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 5 Mar 2015 11:19:53 -0800
Subject: [R] R 3.1.2 using a custom function in aggregate() function on
 Windows 7 OS 64bit
In-Reply-To: <81B768C1-2D02-4D4F-BED1-94224AF394A3@dcn.davis.CA.us>
References: <246549524.4368320.1425506526988.JavaMail.yahoo@mail.yahoo.com>
	<911ACBEC-6B9D-4C21-B78C-CA7689C03DA5@dcn.davis.CA.us>
	<CACk-te1ryRxe+XqWgmmOaQyNAjMGiST4YpRWfksB0bVU4AGvig@mail.gmail.com>
	<B74A33D0-BB19-4C07-B387-18D79DD6DBBE@dcn.davis.CA.us>
	<CACk-te2jNcFJF5ke+YF07dHxswTDQ1UoJee7Wh5siLnyJbfTBg@mail.gmail.com>
	<81B768C1-2D02-4D4F-BED1-94224AF394A3@dcn.davis.CA.us>
Message-ID: <CACk-te18M903Qvjz0O01jHraaA=THpRegSKc0-T+L3O8HjA-Bw@mail.gmail.com>

Well, I obviously don't use it either, as I'm just quoting the docs.

I either use by(), or tapply().

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Mar 5, 2015 at 10:47 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Bert: using the sample data frame from below, try to interpret the output of this:
>
> aggregate( dat[,1:2], dat[,"g",drop=FALSE, FUN=function(x){print(x);class(x)})
>
> The help text you quote is probably not as clear as it should be. Would the following be better?
>
> "... and FUN is applied to each column in each such subset with further arguments in ... passed to it."
>
> I became aware of this "feature" because this application of exactly the same aggregation function to all of my data columns is not convenient for my day-to-day work. Thus, I don't use "aggregate" very often.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On March 5, 2015 8:59:55 AM PST, Bert Gunter <gunter.berton at gene.com> wrote:
>>That's not what ?aggregate says:
>>
>>"aggregate.data.frame is the data frame method. If x is not a data
>>frame, it is coerced to one, which must have a non-zero number of
>>rows. Then, each of the variables (columns) in x is split into subsets
>>of cases (rows) of identical combinations of the components of by, and
>>FUN is applied to each such subset with further arguments in ...
>>passed to it."
>>
>>
>>As I read this, the argument of FUN is a data frame that is a subset
>>of the original frame, defined by the by variable values.
>>
>>
>>No?
>>
>>
>>-- Bert
>>
>>Bert Gunter
>>Genentech Nonclinical Biostatistics
>>(650) 467-7374
>>
>>"Data is not information. Information is not knowledge. And knowledge
>>is certainly not wisdom."
>>Clifford Stoll
>>
>>
>>
>>
>>On Thu, Mar 5, 2015 at 8:55 AM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us> wrote:
>>> I don't see your point. No matter which version of aggregate you use,
>>FUN is applied to vectors. Those vectors may be columns in a data frame
>>or not, but FUN is always given one vector at a time by aggregate.
>>>
>>---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>Go...
>>>                                       Live:   OO#.. Dead: OO#..
>>Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>rocks...1k
>>>
>>---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 5, 2015 8:12:39 AM PST, Bert Gunter <gunter.berton at gene.com>
>>wrote:
>>>>Sorry, Jeff. aggregate() is generic.
>>>>
>>>>>From ?aggregate:
>>>>
>>>>"## S3 method for class 'data.frame'
>>>>aggregate(x, by, FUN, ..., simplify = TRUE)"
>>>>
>>>>Cheers,
>>>>Bert
>>>>
>>>>Bert Gunter
>>>>Genentech Nonclinical Biostatistics
>>>>(650) 467-7374
>>>>
>>>>"Data is not information. Information is not knowledge. And knowledge
>>>>is certainly not wisdom."
>>>>Clifford Stoll
>>>>
>>>>
>>>>
>>>>
>>>>On Thu, Mar 5, 2015 at 7:54 AM, Jeff Newmiller
>>>><jdnewmil at dcn.davis.ca.us> wrote:
>>>>> The aggregate function applies FUN to vectors, not data frames. For
>>>>example, the default "mean" function accepts a vector such as a
>>column
>>>>in a data frame and returns a scalar (well, a vector of length 1).
>>>>Aggregate then calls this function once for each piece of the
>>column(s)
>>>>you give it. Your function wants two vectors, but aggregate does not
>>>>understand how to give two inputs.
>>>>>
>>>>> (In the future, please follow R-help mailing list guidelines and
>>post
>>>>using plain text so your code does not get messed up.)
>>>>>
>>>>> You could use split to break your data frame into a list of data
>>>>frames, and then sapply to extract the results you are looking for. I
>>>>prefer to use the plyr or dplyr or data.table packages to do all this
>>>>for me.
>>>>>
>>>>> d_rule <- function( DF ) {
>>>>>   i <- which( DF$a==max( DF$a ) )
>>>>>   if ( length( i ) == 1 ){
>>>>>     DF[ i, "x" ]
>>>>>   } else {
>>>>>     min( DF[ , "x" ] ) # did you mean min( DF$x[i] ) ?
>>>>>   }
>>>>> }
>>>>>
>>>>> dat <- data.frame( a=c(2,2,1,4,2,5,2,3,4,4)
>>>>>     , x = c(1:10)
>>>>>     , g = c(1,1,2,2,3,3,4,4,5,5)
>>>>>     )
>>>>> # note that cbind on vectors creates a matrix
>>>>> # in a matrix all columns must be of the same type
>>>>> # but data frames generally have a variety of types
>>>>> # so don't use cbind when making a data frame
>>>>>
>>>>> library( dplyr )
>>>>>
>>>>> result <- dat %>% group_by( g ) %>% do( answer = d_rule( . ) ) %>%
>>>>as.data.frame
>>>>>
>>>>>
>>>>---------------------------------------------------------------------------
>>>>> Jeff Newmiller                        The     .....       .....  Go
>>>>Live...
>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
>>Live
>>>>Go...
>>>>>                                       Live:   OO#.. Dead: OO#..
>>>>Playing
>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.
>>with
>>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>>rocks...1k
>>>>>
>>>>---------------------------------------------------------------------------
>>>>> Sent from my phone. Please excuse my brevity.
>>>>>
>>>>> On March 4, 2015 2:02:06 PM PST, Typhenn Brichieri-Colombi via
>>R-help
>>>><r-help at r-project.org> wrote:
>>>>>>Hello,
>>>>>>
>>>>>>I am trying to use the following custom function in an
>>>>>>aggregatefunction, but cannot get R to recognize my data. I?ve read
>>>>the
>>>>>>help on function()and on aggregate() but am unable to solve my
>>>>problem.
>>>>>>How can I get R torecognize the data inputs for the custom function
>>>>>>nested within aggregate()?
>>>>>>
>>>>>>My custom function is found below, as well as the errormessage I
>>get
>>>>>>when I run it on a test data set (I will be using this functionon a
>>>>>>much larger dataset (over 600,000 rows))
>>>>>>
>>>>>>Thank you for your time and your help!
>>>>>>
>>>>>>
>>>>>>
>>>>>>d_rule<-function(a,x){
>>>>>>
>>>>>>i<-which(a==max(a))
>>>>>>
>>>>>>out<-ifelse(length(i)==1, x[i], min(x))
>>>>>>
>>>>>>return(out)
>>>>>>
>>>>>>}
>>>>>>
>>>>>>
>>>>>>
>>>>>>a<-c(2,2,1,4,2,5,2,3,4,4)
>>>>>>
>>>>>>x<-c(1:10)
>>>>>>
>>>>>>g<-c(1,1,2,2,3,3,4,4,5,5)
>>>>>>
>>>>>>dat<-as.data.frame(cbind(x,g))
>>>>>>
>>>>>>
>>>>>>
>>>>>>test<-aggregate(dat, by=list(g), FUN=d_rule,dat$a, dat$x)
>>>>>>
>>>>>>Error in dat$x : $ operator is invalid for atomic vectors
>>>>>>
>>>>>>
>>>>>>
>>>>>>       [[alternative HTML version deleted]]
>>>>>>
>>>>>>______________________________________________
>>>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>PLEASE do read the posting guide
>>>>>>http://www.R-project.org/posting-guide.html
>>>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>


From dcarlson at tamu.edu  Thu Mar  5 21:15:49 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 5 Mar 2015 20:15:49 +0000
Subject: [R] subset a data frame by largest frequencies of factors
In-Reply-To: <54F8A437.90404@yorku.ca>
References: <54F8A437.90404@yorku.ca>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D66C480@mb02.ads.tamu.edu>

These two commands will compute the cell frequencies and then sort them:

e <- as.data.frame(xtabs(~ctry+member, Dataset))
f <- e[order(e$Freq, decreasing=TRUE),]

Then draw your subset

g <- head(f, 10)

or

g <- f[cumsum(f$Freq)/sum(f$Freq) >.8,]

Finally merge the sample with the original data and delete the unused factor levels:

sample <- merge(Dataset, g[,-3])
sample$ctry <- factor(sample$ctry)
sample$member <- factor(sample$member)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael Friendly
Sent: Thursday, March 5, 2015 12:45 PM
To: R-help
Subject: [R] subset a data frame by largest frequencies of factors

A consulting client has a large data set with a binary response 
(negative) and two factors (ctry and member) which have many levels,
but many occur with very small frequencies.  It is far too sparse with a 
model like glm(negative ~ ctry+member, family=binomial).

 > str(Dataset)
'data.frame':   10672 obs. of  5 variables:
  $ ctry    : Factor w/ 31 levels "Barbados","Belize",..: 21 21 5 22 18 
18 18 18 26 18 ...
  $ member  : Factor w/ 163 levels "","ADHOPIA, PREETI ",..: 150 19 19 
111 120 1 1 4 55 18 ...
  $ negative: int  0 1 0 1 1 1 1 0 0 0 ...
 >

For analysis, we'd like to subset the data to include only those that 
occur with frequency greater than a given
value, or the top 10 (say) in frequency, or the highest frequency 
categories accounting for 80% (say) of the
total.  I'm not sure how to do any of these in R.  Can anyone help?

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From hwborchers at gmail.com  Thu Mar  5 21:23:11 2015
From: hwborchers at gmail.com (Hans W Borchers)
Date: Thu, 5 Mar 2015 21:23:11 +0100
Subject: [R] Second order bessel function
Message-ID: <CAML4n3ODV3aPA47okNE6J12hyyYpO+4sp=Psgqe-P9LdPAJsbg@mail.gmail.com>

On Wed Mar 4 21:32:30 CET 2015 Chris Vanlangenberg writes:
>
> I want to compute the numerical values for modified second order bessel
> function given x and other parameters, currently base R has a bessel
> function for 1st order and I have tried to use the relationship between 1st
> and 2nd order to compute the 2nd order bessel function, but I ended up
> getting a zero.
>
> Any suggestions how to proceed on this? or any alternative methods?

R has the Bessel and modified Bessel functions of first and second kind, of
integer and fractional order. Package 'Bessel' contains Bessel functions for
real and complex numbers. Package 'gsl' provides access to lots of special
Bessel functions.

What exactly are you looking for?

>
> Regards,
> Chris Vanlangenberg


From evelyne.brie.1 at ulaval.ca  Thu Mar  5 19:09:54 2015
From: evelyne.brie.1 at ulaval.ca (Evelyne1991)
Date: Thu, 5 Mar 2015 10:09:54 -0800 (PST)
Subject: [R] Dividing a map by electoral results with R?
Message-ID: <1425578994536-4704211.post@n4.nabble.com>

Hi everyone,

I would like to divide a map of Germany vertically by the electoral results
of 2013:

> VoteGermany2013
    Party Result
1 CDU/CSU   49.4
2     SPD   30.5
3   LINKE   10.2
4  GRUENE   10.0

What I'm looking for is very simple: a map divided like a one-bar graph,
with 49.4% of the lenght for CDU/CSU, 30.5% for SPD and so on. It would be
like a single bar divided in parts, but with the form of a country (quite
simple in fact).

For the map, I'm using:

library(maps)
library(mapdata)
map("worldHires","Germany")

Would someone be able to help me?




--
View this message in context: http://r.789695.n4.nabble.com/Dividing-a-map-by-electoral-results-with-R-tp4704211.html
Sent from the R help mailing list archive at Nabble.com.


From ii54250 at msn.com  Thu Mar  5 11:46:22 2015
From: ii54250 at msn.com (IOANNA IOANNOU)
Date: Thu, 5 Mar 2015 10:46:22 +0000
Subject: [R] gaussian Kernel smoothing using Nadaraya-Watson estimator and
	confidence bands
Message-ID: <DUB129-DS100AD68708239516DB77A6F31F0@phx.gbl>

Hello, 

I have a database and I would like to fit a Nadaraya-Watson Gaussian kernel
estimator and produce the confidence bands around the  mean estimate. Any
ideas how to do this with R? I cannot find a way to produce the confidence
bands. I will use a fixed bandwidth. 


Lets use this database for illustration purposes:

d <- data.frame(x = runif(N))
d$y <- d$x^2 - d$x + 1 + (1+d$x)*rnorm(N, sd = 0.1)


Any help much appreciated. 


Best, 
Ioanna


From zaynabmousavian at gmail.com  Thu Mar  5 10:21:19 2015
From: zaynabmousavian at gmail.com (Zaynab Mousavian)
Date: Thu, 5 Mar 2015 12:51:19 +0330
Subject: [R] Installing GO.db Package in R
Message-ID: <CADVVYs34GvMGCrPAikFODhH0wA5td8VYcfkn0+DCF9TdXmi_Dg@mail.gmail.com>

Hi all,

I have tried to install GO.db package in R, but the following error is
given to me:

biocLite(c("GO.db"))
BioC_mirror: http://bioconductor.org
Using Bioconductor version 2.13 (BiocInstaller 1.12.1), R version 3.0.2.
Installing package(s) 'GO.db'
trying URL
    'http://bioconductor.org/packages/2.13/data/annotation/src/contrib/GO.db_2.10.1.tar.gz'
Content type 'application/x-gzip' length 26094175 bytes (24.9 Mb)
opened URL==================================================
downloaded 24.9 Mb
* installing *source* package ?GO.db? ...** R** inst** preparing
package for lazy loading** help*** installing help indices** building
package indices** testing if installed package can be loaded
Error : .onLoad failed in loadNamespace() for 'GO.db', details:
call: match.arg(synchronous, c("off", "normal", "full"))
error: 'arg' must be NULL or a character vector
Error: loading failed
Execution halted
ERROR: loading failed* removing
?/home/zmousavian/R/x86_64-pc-linux-gnu-library/3.0/GO.db?

The downloaded source packages are in
    ?/tmp/RtmpBDs1Tq/downloaded_packages?
Warning messages:1: In install.packages(pkgs = pkgs, lib = lib, repos
= repos, ...) :
installation of package ?GO.db? had non-zero exit status2: installed
directory not writable, cannot update packages 'colorspace','lattice',
'mgcv', 'survival'


Can anyone help me to install it?

Regards
-- 
Zaynab Mousavian, Ph.D. student

Laboratory of Systems Biology and Bioinformatics
(LBB)
Institute of Biochemistry and Biophysics, University of
Tehran
Tehran, Iran
Web: *http://LBB.ut.ac.ir <http://LBB.ut.ac.ir>*
Email: zmousavian at ut.ac.ir

	[[alternative HTML version deleted]]


From harini.v at positiveintegers.com  Thu Mar  5 10:53:56 2015
From: harini.v at positiveintegers.com (harini_v)
Date: Thu, 5 Mar 2015 01:53:56 -0800 (PST)
Subject: [R] Want to convert list with vectore of dis similar lengths to
 data frame
Message-ID: <1425549236521-4704196.post@n4.nabble.com>

Hi there

I am Ms. Harini and I am trying to solve a problem with the function
data.frame. The problem I am trying to solve is similar to the one listed
under the title Example Four in this website: 
http://www.r-bloggers.com/converting-a-list-to-a-data-frame/

For some reason when I try to replicate the results in my R console, I get
this error:
test4 <- list('Row1'=letters[1:5], 'Row2'=letters[1:7],
'Row3'=letters[8:14])

as.data.frame(test4)

Error in data.frame(Row1 = c("a", "b", "c", "d", "e"), Row2 = c("a", "b",  : 
  arguments imply differing number of rows: 5, 7

It says that it can?t do what I am asking it to do because the lengths of
the rows are different. But somehow it has worked on the above website.

This is an old article (written in 2013). My question is this: Would you
know if the way data.frame handles lists has been re written in some way? I
couldn?t find anything to answer my question on the web, so I thought I
should email you.

Thank you for the time you are taking to read my email and trying to help
me.
Sincerely,
Harini




--
View this message in context: http://r.789695.n4.nabble.com/Want-to-convert-list-with-vectore-of-dis-similar-lengths-to-data-frame-tp4704196.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Thu Mar  5 15:04:35 2015
From: js.huang at protective.com (JS Huang)
Date: Thu, 5 Mar 2015 06:04:35 -0800 (PST)
Subject: [R] Want to convert list with vectore of dis similar lengths to
 data frame
In-Reply-To: <1425549236521-4704196.post@n4.nabble.com>
References: <1425549236521-4704196.post@n4.nabble.com>
Message-ID: <1425564275902-4704200.post@n4.nabble.com>

Hi,
  
  The following works by appending NA to make up the maximum length of the
list.

> test4
$Row1
[1] "a" "b" "c" "d" "e"

$Row2
[1] "a" "b" "c" "d" "e" "f" "g"

$Row3
[1] "h" "i" "j" "k" "l" "m" "n"

> as.data.frame(t(sapply(1:length(test4),
> function(x){c(test4[[x]],rep(NA,max(sapply(1:length(test4),function(x)length(test4[[x]])))-length(test4[[x]])))})))
  V1 V2 V3 V4 V5   V6   V7
1  a  b  c  d  e <NA> <NA>
2  a  b  c  d  e    f    g
3  h  i  j  k  l    m    n



--
View this message in context: http://r.789695.n4.nabble.com/Want-to-convert-list-with-vectore-of-dis-similar-lengths-to-data-frame-tp4704196p4704200.html
Sent from the R help mailing list archive at Nabble.com.


From laurent.franckx at vito.be  Thu Mar  5 21:34:09 2015
From: laurent.franckx at vito.be (Franckx Laurent)
Date: Thu, 5 Mar 2015 20:34:09 +0000
Subject: [R] error message: ReadItem: unknown type 64,
 perhaps written by later version of R
Message-ID: <3FA7C532AA08284AB2ACA7B0AB56EF8715928D14@vitomail4.vito.local>

Dear all

I get the following error message when I try to load one  specific RData object in R:

        Error: ReadItem: unknown type 64, perhaps written by later version of R


The error message is odd because (a) this RData object was created just one hour berfore in a  previous script (in a series of R scripts called in batch mode), so it would seem to me that it has been created by the same version of R that is now calling it (b) this script is "looping" over several scenarios and years, and the error only occurs for one very specific combination of scenarios and years. This object is about 6 Gb large, which is the same  size as the other objects that were called in previous instances.

I load the RData with the following command (where pathsony[[rdata]] is the folder with the RData and skimlistrdata is the file I try to load):

        load( file.path(pathsony[[rdata]],skimlistrdata))


The problem occurs both when I run the script in batch mode or when I run it interactively.

I use a  "x86_64-pc-linux-gnu" and  "R version 3.1.2 (2014-10-31)".


Laurent Franckx, PhD
Senior researcher sustainable mobility
VITO NV | Boeretang 200 | 2400 Mol
Tel. ++ 32 14 33 58 22| mob. +32 479 25 59 07 | Skype: laurent.franckx | laurent.franckx at vito.be | Twitter @LaurentFranckx




VITO Disclaimer: http://www.vito.be/e-maildisclaimer


From curtisburkhalter at gmail.com  Thu Mar  5 21:41:38 2015
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Thu, 5 Mar 2015 13:41:38 -0700
Subject: [R] problem with function that adds rows to dataframe based on
 conditional statement
Message-ID: <CAJmwvUadtpFODfCV3Qh+xHuiGvLH0DUSvehuMb_S-_dF6Rck5g@mail.gmail.com>

Hello everyone,

I'm having a problem with a function that I wrote that is supposed to add a
row to dataframe based upon a conditional statement. To explain I've used
an example below:

#create data frame
animals=c("bird","dog","cat")
animals=rep(animals,each=4)
animals=animals[1:11]
animalYears=c(1,1,2,2,1,1,2,2,1,1,2)
animalMass=round(runif(11,min=10,max=50),0)

comAn=as.data.frame(cbind(animals,animalYears,animalMass))
comAn

  * animals* *animalYears* *animalMass*
1     bird           1         30
2     bird           1         32
3     bird           2         27
4     bird           2         16
5      dog           1         22
6      dog           1         25
7      dog           2         41
8      dog           2         22
9      cat           1         30
10     cat           1         37
11     cat           2         49

We can see here that for every type of animal I have two years of mass
measurements, except for the cat in year 2. What I want to do is add an
additional row to the end of the dataframe that consists strictly of NAs
and then I can substitute those out later.

So what I first did was split the 'comAn' dataframe into the different
Animal by Year combos.

#This line splits 'com_An' into a list ordered by the Animal by Year combos
comAn_split=split(comAn, paste(comAn$animals,comAn$animalYear))

Then I wrote the function that identifies whether a particular Animal by
Year combo is less than two rows in length and if so it should add another
row that consists only of NAs using the vector 'NAs':

#This function identifies the length of each Animal by Year combo and then
#uses the rbind function built in R to add a row
#to each animal by year combo if they have less than 2 samples

addNA <- function(comAn) {
  NAs=c(NA,NA,NA)
        ind <- seq_len(nrow(comAn))
        comAn[ifelse(length(ind)<2,rbind(NAs),length(ind)),]
}

#This applies the function addNs to the animals data organized in list
format
addedNAcomAn <- do.call(rbind, lapply(comAn_split, addNA))
addedNAcomAn

When I apply the function to the list of the different Animal by Year
combos this is what I get:
       animals animalYears animalMass
bird 1    bird           1         23
bird 2    bird           2         50
cat 1      cat           1         15
cat 2     <NA>        <NA>       <NA>
dog 1      dog           1         23
dog 2      dog           2         38

What I expect is this:

   animals animalYears animalMass
1     bird           1         41
2     bird           1         23
3     bird           2         23
4     bird           2         50
5      dog           1         49
6      dog           1         23
7      dog           2         13
8      dog           2         38
9      cat           1         42
10     cat           1         15
11     cat           2         33
12     NA           NA      NA

Am I conditioning improperly within the function or am I missing something
else. Any help would be greatly appreciated.

Best

-- 
Curtis Burkhalter

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Mar  5 22:03:08 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 5 Mar 2015 13:03:08 -0800
Subject: [R] Want to convert list with vectore of dis similar lengths to
 data frame
In-Reply-To: <1425549236521-4704196.post@n4.nabble.com>
References: <1425549236521-4704196.post@n4.nabble.com>
Message-ID: <CAF8bMcYw+KCXQMjSQ27=amx99r70v1knqRwRr5UN_Qv9ugyo+A@mail.gmail.com>

That blog post refers to the authors own function, as.data.frame.list,
that you would have to download from github.  It makes data.frame()
act quite differently than the usual way.  I would not recommend it.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Mar 5, 2015 at 1:53 AM, harini_v <harini.v at positiveintegers.com>
wrote:

> Hi there
>
> I am Ms. Harini and I am trying to solve a problem with the function
> data.frame. The problem I am trying to solve is similar to the one listed
> under the title Example Four in this website:
> http://www.r-bloggers.com/converting-a-list-to-a-data-frame/
>
> For some reason when I try to replicate the results in my R console, I get
> this error:
> test4 <- list('Row1'=letters[1:5], 'Row2'=letters[1:7],
> 'Row3'=letters[8:14])
>
> as.data.frame(test4)
>
> Error in data.frame(Row1 = c("a", "b", "c", "d", "e"), Row2 = c("a", "b",
> :
>   arguments imply differing number of rows: 5, 7
>
> It says that it can?t do what I am asking it to do because the lengths of
> the rows are different. But somehow it has worked on the above website.
>
> This is an old article (written in 2013). My question is this: Would you
> know if the way data.frame handles lists has been re written in some way? I
> couldn?t find anything to answer my question on the web, so I thought I
> should email you.
>
> Thank you for the time you are taking to read my email and trying to help
> me.
> Sincerely,
> Harini
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Want-to-convert-list-with-vectore-of-dis-similar-lengths-to-data-frame-tp4704196.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Mar  5 22:12:04 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Mar 2015 13:12:04 -0800
Subject: [R] Dividing a map by electoral results with R?
In-Reply-To: <1425578994536-4704211.post@n4.nabble.com>
References: <1425578994536-4704211.post@n4.nabble.com>
Message-ID: <AF1EF914-C612-481F-9E5B-1F090FD44E24@comcast.net>


On Mar 5, 2015, at 10:09 AM, Evelyne1991 wrote:

> Hi everyone,
> 
> I would like to divide a map of Germany vertically by the electoral results
> of 2013:
> 
>> VoteGermany2013
>    Party Result
> 1 CDU/CSU   49.4
> 2     SPD   30.5
> 3   LINKE   10.2
> 4  GRUENE   10.0
> 
> What I'm looking for is very simple: a map divided like a one-bar graph,
> with 49.4% of the lenght for CDU/CSU, 30.5% for SPD and so on. It would be
> like a single bar divided in parts, but with the form of a country (quite
> simple in fact).
> 
> For the map, I'm using:
> 
> library(maps)
> library(mapdata)
> map("worldHires","Germany")
> 
> Would someone be able to help me?

Please do not crosspost to Rhelp and StackOverflow.
> 
> View this message in context: http://r.789695.n4.nabble.com/Dividing-a-map-by-electoral-results-with-R-tp4704211.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ####
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mtmorgan at fredhutch.org  Thu Mar  5 23:12:16 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Thu, 05 Mar 2015 14:12:16 -0800
Subject: [R] Installing GO.db Package in R
In-Reply-To: <CADVVYs34GvMGCrPAikFODhH0wA5td8VYcfkn0+DCF9TdXmi_Dg@mail.gmail.com>
References: <CADVVYs34GvMGCrPAikFODhH0wA5td8VYcfkn0+DCF9TdXmi_Dg@mail.gmail.com>
Message-ID: <54F8D4C0.2080201@fredhutch.org>

On 03/05/2015 01:21 AM, Zaynab Mousavian wrote:
> Hi all,
>
> I have tried to install GO.db package in R, but the following error is

please ask questions about Bioconductor packages on the Bioconductor support 
forum https://support.bioconductor.org. Please also review answers to your 
question on Biostars first.

You are using an old version of R / Bioconductor but a new version of RSQLite. 
Use either a current version of R / Bioconductor or an old version of RSQLite, 
as explained here https://support.bioconductor.org/p/63555.

If you are having trouble installing a current version of R on linux, indicate 
your OS and how you are currently installing R. Be sure to follow the relevant 
directions from, e.g., http://cran.r-project.org/. Perhaps the R-SIG-Debian 
archives and mailing list have additional hints 
https://stat.ethz.ch/pipermail/r-sig-debian/.

Martin

> given to me:
>
> biocLite(c("GO.db"))
> BioC_mirror: http://bioconductor.org
> Using Bioconductor version 2.13 (BiocInstaller 1.12.1), R version 3.0.2.
> Installing package(s) 'GO.db'
> trying URL
>      'http://bioconductor.org/packages/2.13/data/annotation/src/contrib/GO.db_2.10.1.tar.gz'
> Content type 'application/x-gzip' length 26094175 bytes (24.9 Mb)
> opened URL==================================================
> downloaded 24.9 Mb
> * installing *source* package ?GO.db? ...** R** inst** preparing
> package for lazy loading** help*** installing help indices** building
> package indices** testing if installed package can be loaded
> Error : .onLoad failed in loadNamespace() for 'GO.db', details:
> call: match.arg(synchronous, c("off", "normal", "full"))
> error: 'arg' must be NULL or a character vector
> Error: loading failed
> Execution halted
> ERROR: loading failed* removing
> ?/home/zmousavian/R/x86_64-pc-linux-gnu-library/3.0/GO.db?
>
> The downloaded source packages are in
>      ?/tmp/RtmpBDs1Tq/downloaded_packages?
> Warning messages:1: In install.packages(pkgs = pkgs, lib = lib, repos
> = repos, ...) :
> installation of package ?GO.db? had non-zero exit status2: installed
> directory not writable, cannot update packages 'colorspace','lattice',
> 'mgcv', 'survival'
>
>
> Can anyone help me to install it?
>
> Regards
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From js.huang at protective.com  Fri Mar  6 00:29:46 2015
From: js.huang at protective.com (JS Huang)
Date: Thu, 5 Mar 2015 15:29:46 -0800 (PST)
Subject: [R] problem with function that adds rows to dataframe based on
 conditional statement
In-Reply-To: <CAJmwvUadtpFODfCV3Qh+xHuiGvLH0DUSvehuMb_S-_dF6Rck5g@mail.gmail.com>
References: <CAJmwvUadtpFODfCV3Qh+xHuiGvLH0DUSvehuMb_S-_dF6Rck5g@mail.gmail.com>
Message-ID: <1425598186197-4704237.post@n4.nabble.com>

Hi Curtis,

  Maybe you forgot to tell us how the function seq_len is defined.



-----
JS Huang
--
View this message in context: http://r.789695.n4.nabble.com/problem-with-function-that-adds-rows-to-dataframe-based-on-conditional-statement-tp4704228p4704237.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Fri Mar  6 02:28:04 2015
From: js.huang at protective.com (JS Huang)
Date: Thu, 5 Mar 2015 17:28:04 -0800 (PST)
Subject: [R] help on output my own function result in ddply
In-Reply-To: <1425601442201-4704238.post@n4.nabble.com>
References: <1425601442201-4704238.post@n4.nabble.com>
Message-ID: <1425605284561-4704240.post@n4.nabble.com>

Hi, 

  There is a lot of if-else statement.  r syntax rejects them.  Here is an
example of if-else example.  In r we can code *ifelse(x>2,y <-
1,ifelse(x>1,y <- 0.5, y <- 0))* for the following.

if (x > 2) 
{
  y = 1
}
else
{
  if (x > 1)
  { 
     y = 0.5
  }
  else 
  {
     y = 0
  }
}




-----
JS Huang
--
View this message in context: http://r.789695.n4.nabble.com/help-on-output-my-own-function-result-in-ddply-tp4704238p4704240.html
Sent from the R help mailing list archive at Nabble.com.


From zilefacelvis at yahoo.com  Fri Mar  6 02:49:48 2015
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Fri, 6 Mar 2015 01:49:48 +0000 (UTC)
Subject: [R] Fit an Extreme Value Distribution to List of dataframes R
Message-ID: <1745460694.5536797.1425606588075.JavaMail.yahoo@mail.yahoo.com>

Hello, I have a list object with many dataframes (example provided below). Each coulmn in a dataframe represents a simluation and each dataframe represents a clmate station. I want to fit an extreme value distribution on each coulmn of a dataframe and then average the confidence intervals and estimates of retruen values from all simulations in a dataframe.

1) I would like to apply the following code to each dataframe in the list. So far, I can apply 'fevd' to each column in a dataframe, NOT list. 

library(extRemes) 

out.lst <- lapply(lst, fevd,type="GEV",method = c("MLE"))# fit GEv to each column of dataframe 
#lapply(out.lst,plot) # make plots for all columns 
rlcis<-lapply(out.lst,return.level, do.ci=TRUE,method="normal",return.period=c(2,5,10,20,50,100))# calc return and CIs for all columns 

lst=list(df,df,df,df) 

df=structure(list(Sim001 = c(120.79, 59.35, 51.14, 104.85, 51.09, 
138.91, 254.94, 56.44, 68.3, 51.69, 51.31, 51.08, 37.17, 38.02, 
62.13, 111.48, 118.38, 45.54, 44.87, 49.59), Sim002 = c(50.25, 
31.17, 67.48, 104.56, 59.82, 38.09, 50.76, 70.25, 35.8, 59.2, 
47.89, 55.21, 74.38, 51.88, 124.09, 91.86, 109.28, 65.61, 69.54, 
55.89), Sim003 = c(30.22, 50.07, 57.66, 57.97, 62.73, 43.84, 
103.61, 53.05, 60.71, 46.57, 65.87, 33.27, 60.24, 43.63, 115.68, 
37.24, 43.27, 46.38, 122.97, 86.02), Sim004 = c(38.6, 39.02, 
45.74, 201.55, 110.78, 49.91, 63.5, 48.65, 94.43, 37.01, 32.61, 
46.39, 120.25, 45.38, 70.26, 94.02, 67.35, 55.62, 59.3, 33.96 
), Sim005 = c(43.54, 68.42, 86.02, 78.9, 40.68, 59.97, 34.5, 
48.47, 68.81, 32, 49.53, 51.23, 51.42, 61.17, 38.02, 52.96, 45.25, 
39.18, 42.33, 97.15), Sim006 = c(45.96, 65.21, 94.81, 106.71, 
46.95, 26.93, 39.45, 33.79, 50.36, 31.22, 128.37, 177.03, 82.07, 
58.02, 32.5, 96.37, 73.77, 48.96, 143.52, 50.14), Sim007 = c(66.3, 
53.99, 162.7, 100.22, 48.76, 74.06, 49.3, 62.66, 158, 82.57, 
94.07, 93.01, 53.88, 160.91, 63.71, 44.93, 63.82, 56.7, 58.92, 
101.52), Sim008 = c(130.62, 75.48, 126.46, 49.97, 71.69, 66.81, 
89.33, 52.68, 29.19, 75.88, 89.69, 59.41, 84.16, 104.49, 65.04, 
66.41, 88.5, 56.64, 62.48, 77.08), Sim009 = c(60.58, 71.85, 62.08, 
57.4, 63.08, 45.38, 50.97, 59.42, 159.44, 120.94, 58.66, 54.57, 
77.45, 49.63, 48.88, 91.03, 103.42, 56.9, 97.04, 69.89), Sim010 = c(48.63, 
51.07, 65.13, 47.59, 94.73, 42.43, 68.77, 95.83, 42.16, 133.1, 
67.2, 56.91, 138.57, 39.26, 79.75, 123.67, 64.27, 64.83, 78.88, 
89.74), Sim011 = c(59.85, 53.73, 116.88, 95.06, 113.44, 87.64, 
47.37, 42.42, 36.69, 39.11, 76.91, 59.85, 76.29, 118.37, 39.14, 
50.76, 98.06, 40.71, 53.03, 42.93), Sim012 = c(128.35, 60.21, 
60.19, 51.69, 51.47, 35.44, 101.72, 82.83, 50.72, 68.66, 80.84, 
59.98, 79.84, 35.52, 128.69, 53.35, 84.77, 18.38, 28.98, 48), 
Sim013 = c(52.88, 117.11, 103.3, 103.59, 119.06, 62.66, 65.64, 
75.91, 81.78, 80.31, 22.83, 79.22, 51.33, 79.63, 86.26, 54.44, 
42.86, 63.95, 166.87, 58.48), Sim014 = c(50.28, 123.9, 35.87, 
133.52, 94.28, 62.35, 58.54, 42.08, 67.7, 101.44, 34.68, 
45.98, 60.99, 60.06, 79.76, 61.93, 59.4, 42.02, 56.45, 81.41 
), Sim015 = c(50.32, 39.01, 100.3, 105.38, 55.49, 36.36, 
56.49, 107.52, 38.7, 73.09, 98.22, 44.19, 50.17, 56.69, 44.82, 
44.09, 57.57, 52.55, 90.37, 78.62), Sim016 = c(35.2, 62.77, 
35.25, 52.05, 93.51, 65.84, 43.85, 54.52, 39.17, 62.02, 47.6, 
34.42, 190.57, 38.46, 94.9, 73.34, 78.5, 52.84, 103.7, 51.48 
), Sim017 = c(69.03, 58.19, 130.37, 80.04, 52.96, 65.14, 
65.08, 45.95, 65.35, 41.95, 78.67, 78.41, 56.51, 63.52, 52.93, 
52.32, 70.14, 81.59, 70.99, 105.02), Sim018 = c(55.98, 44.37, 
59.07, 36.65, 44.16, 26.62, 125.38, 75.54, 75.46, 25.62, 
22.95, 65.74, 72.86, 53.5, 32.05, 58.98, 70.87, 30.95, 78.25, 
54.75), Sim019 = c(147.82, 37.48, 161.91, 46.28, 95.4, 74.79, 
53.51, 58.73, 50.96, 32.03, 50.08, 60.03, 76.75, 45.31, 58.29, 
52.91, 42.84, 74.52, 83.19, 43.8), Sim020 = c(59.33, 218.52, 
64.55, 73.07, 59.9, 39.09, 129.88, 61.53, 56.7, 38.55, 62.2, 
29.25, 52.74, 57.86, 46.04, 80.03, 44.61, 88.52, 45.36, 93.97 
), Sim021 = c(93.44, 41.32, 67.08, 99.15, 89.43, 31.64, 38.59, 
65.08, 58.9, 52.7, 47.39, 47.91, 90.93, 54.57, 51.26, 44.59, 
33.52, 38.69, 44.92, 50.46), Sim022 = c(43.37, 43.47, 63.15, 
77.19, 117.13, 77.32, 65.36, 67.49, 49.18, 87.66, 70.09, 
110.66, 70.85, 46.71, 55.36, 45.53, 30.55, 51.7, 46.08, 65.91 
), Sim023 = c(65.76, 42.75, 50.2, 58.23, 69.27, 75.63, 46.72, 
72.47, 62.53, 50.87, 58.8, 63.61, 39.99, 91.36, 66.07, 100.32, 
55.34, 32.59, 59.8, 43.96), Sim024 = c(174.2, 70.17, 47.86, 
71.24, 91.39, 40.5, 28.66, 64.57, 33.02, 46.27, 68.56, 56.68, 
97.28, 46.24, 65.76, 72.53, 60.26, 128.26, 85.63, 107.29), 
Sim025 = c(84.66, 38.95, 43.63, 41.33, 108.67, 62.94, 64.73, 
57.26, 42.11, 100.24, 28, 35.95, 175.8, 61.64, 81.42, 67.55, 
68.12, 35.1, 46.63, 105.43), Sim026 = c(64.17, 55.25, 59.21, 
49.21, 104.75, 129.05, 76.05, 69.88, 110.19, 40.71, 103.17, 
74.32, 64.18, 55.66, 105.93, 36.25, 81.08, 75.96, 81.67, 
99.22), Sim027 = c(55.07, 53.32, 71.68, 37.51, 96.35, 42.25, 
41.22, 41.09, 67.46, 69.64, 54.6, 37.63, 106.3, 121.53, 67, 
24.6, 64.82, 64.82, 68.65, 98.26), Sim028 = c(56.44, 27.16, 
45.64, 59.74, 55.09, 28.91, 94.48, 42.9, 91.21, 79.34, 41.06, 
42.36, 57.21, 38.13, 46.28, 75.48, 83.1, 72.94, 98.49, 66.73 
), Sim029 = c(49.77, 49.29, 54.16, 83.52, 48.06, 61.06, 26.69, 
68.11, 51.43, 56.84, 35.05, 87.57, 160.17, 48.4, 95.22, 74.41, 
69.18, 43.84, 65.14, 65.05), Sim030 = c(63.45, 62.12, 81.56, 
66.5, 53.21, 49.33, 44.95, 50.49, 81.7, 59.45, 46.68, 100.52, 
128.92, 75.38, 74.2, 46.92, 96.02, 42.79, 73.97, 35.67), 
Sim031 = c(42.32, 44.08, 63.43, 74.42, 78.09, 59.41, 54.34, 
103.51, 74.34, 42.34, 32.86, 76.19, 56.32, 79, 79.11, 37.75, 
46.15, 43.67, 78.34, 115.33), Sim032 = c(60.6, 46.4, 179.78, 
102.86, 57.86, 34.29, 68.26, 56.88, 103.82, 97.29, 56.46, 
104.64, 58.03, 70.71, 53.61, 111.52, 77.73, 49.03, 48.64, 
69.16), Sim033 = c(35.23, 42.14, 64.93, 74.66, 183.2, 26.87, 
59.4, 73.74, 63.13, 37.65, 64.59, 45, 75.46, 78.81, 66.73, 
56.63, 50.68, 56.87, 69.41, 86.37), Sim034 = c(51.52, 108.22, 
47.16, 41.77, 62.01, 85.64, 66.62, 58.47, 167.55, 34.71, 
73.55, 43.42, 122.87, 53.81, 48.08, 59.5, 83.6, 46.33, 55.82, 
76.99), Sim035 = c(37.25, 41.93, 74.69, 61.38, 78.29, 70.13, 
56.44, 36.66, 94.21, 97.32, 46, 45.78, 32.85, 57.05, 61.26, 
69.1, 43.26, 41.41, 69.67, 147.57), Sim036 = c(67.96, 59.22, 
65.29, 64.49, 41.23, 39.53, 46.21, 32.87, 88.47, 59.53, 44.28, 
73.41, 38.3, 72.1, 77.33, 43.23, 99.6, 49.46, 63.7, 54.96 
), Sim037 = c(73.31, 60.02, 46.72, 69.75, 39.97, 42.39, 69, 
70.86, 86.68, 79.96, 46.88, 43.91, 70.03, 53.46, 59.72, 112.63, 
44.71, 91.34, 80.78, 58.28), Sim038 = c(66.82, 67.99, 72.85, 
108.32, 45.14, 54.1, 68.67, 68.01, 51.8, 43.09, 43.94, 46.68, 
61.19, 75.64, 74.25, 43.64, 114.62, 43.71, 43.1, 66.72), 
Sim039 = c(41.57, 39.89, 172.91, 45.93, 146.08, 64.04, 51.16, 
60.84, 63.01, 59.85, 43.72, 118.3, 57.85, 64.73, 141.46, 
48.84, 109.66, 53.85, 49.28, 33.75), Sim040 = c(41.66, 203.26, 
29.55, 64.55, 43.06, 85.98, 89.09, 80.92, 83.08, 40.77, 47.7, 
120.21, 88.37, 71.86, 86.6, 122.06, 59.61, 73.06, 67.51, 
165.09), Sim041 = c(43.02, 33.99, 32.19, 60.84, 34.49, 31.81, 
46.81, 56.2, 74.42, 59.62, 48.4, 53.33, 78.04, 100.36, 92.8, 
147.88, 89.32, 38.73, 76.25, 93.83), Sim042 = c(64.27, 49.35, 
99.48, 86.88, 24.19, 54.45, 111.73, 72.6, 57.73, 75.14, 42.85, 
96.38, 55.17, 82.13, 72.9, 68.29, 76.44, 41.64, 83.17, 89.69 
), Sim043 = c(92.51, 127.4, 68.69, 45.07, 65.78, 40.81, 35.22, 
41.47, 50.94, 73.3, 55.48, 91.55, 60.15, 39.31, 110.71, 73.27, 
92.3, 64.83, 74.21, 57.68), Sim044 = c(46.86, 68.48, 51.29, 
83.66, 87.2, 79.22, 62.5, 25.17, 44.04, 55.36, 69.23, 23.23, 
43.22, 43.38, 34.28, 96.67, 42.1, 52, 95.03, 43.73), Sim045 = c(111.78, 
63.81, 126.77, 49.3, 60.11, 42.84, 47, 22.98, 48.41, 144.18, 
42.21, 85.14, 105.72, 86.97, 55.17, 73.22, 122.86, 60.04, 
31.13, 95.21), Sim046 = c(43.29, 40.17, 53.99, 29.43, 87.25, 
58.74, 81.31, 74.3, 48.47, 91.82, 60.84, 74.5, 94.22, 43.77, 
55.42, 71.17, 54.49, 76.96, 58.04, 57.95), Sim047 = c(51.58, 
50.48, 51.44, 38.82, 49.5, 59.16, 46.11, 43.95, 109.03, 57.92, 
62.12, 68.25, 42.59, 82.52, 63.36, 84.1, 77.16, 183.01, 80.42, 
57.06), Sim048 = c(39.95, 57.88, 33.13, 57.07, 123.89, 39.91, 
94.86, 80.16, 104.46, 86.94, 87.65, 82.74, 69.6, 79.83, 32.9, 
34.05, 45.11, 83.16, 78.13, 56.18), Sim049 = c(15.68, 65.54, 
71.53, 148.3, 79.93, 49.64, 82.59, 34, 77.56, 92.19, 158.28, 
82.13, 46.34, 93.22, 93.89, 59.37, 47.72, 40.11, 128.32, 
67.29), Sim050 = c(37.63, 43.41, 143.61, 157.48, 39.44, 73.62, 
75.41, 86.69, 58.29, 66.7, 45.95, 34.3, 61.8, 78.35, 58.18, 
60.04, 84.08, 76.19, 70.58, 73.57), Sim051 = c(68.28, 50.97, 
62.66, 45.23, 92.23, 93.46, 53.17, 108.31, 45.67, 121.95, 
46.52, 66.13, 75.3, 42.31, 85.94, 77.72, 111.41, 57.23, 203.79, 
68.42), Sim052 = c(86.42, 75.88, 57.99, 72.95, 129.47, 78.71, 
63.86, 66.31, 69.14, 84.81, 118.46, 67.52, 40.33, 87.73, 
46.34, 55.88, 66.93, 85.46, 130.03, 85.77), Sim053 = c(69.54, 
94.8, 158.78, 47.58, 45.09, 29.65, 69.53, 36.24, 101.68, 
63.58, 54.03, 157.1, 52.78, 72.2, 45.35, 103.47, 53.52, 43.74, 
60.9, 85.14), Sim054 = c(39.92, 48.19, 36.69, 49.01, 46.39, 
95.15, 139.94, 109.69, 72.34, 45.89, 72.94, 64.4, 61.13, 
28.13, 95.76, 133.6, 121.57, 40.21, 118.29, 33.56), Sim055 = c(80.18, 
64.11, 73.13, 43.64, 72.62, 93.36, 55.58, 72.2, 44.95, 176.77, 
33.08, 87.33, 50.86, 75.27, 74.68, 110.55, 34.23, 58.23, 
73.04, 77.96), Sim056 = c(51.11, 48.25, 68.3, 34.38, 41.18, 
45.43, 51.55, 72.79, 77.97, 170.95, 79.26, 43.51, 53.14, 
38.4, 65.34, 68.69, 71.58, 109.44, 35.29, 95.03), Sim057 = c(117.02, 
35.8, 49.18, 53.25, 61.22, 49.9, 78.82, 26.87, 113.83, 41.02, 
78.64, 48.17, 47.2, 28.92, 69.97, 56.97, 41.39, 43.83, 148.6, 
68.75), Sim058 = c(66.01, 62.38, 61.91, 100.88, 75.68, 70.96, 
119.97, 40.18, 84.75, 42.18, 81.37, 74.45, 62.03, 39.8, 63.51, 
35.9, 60.29, 51.93, 71.17, 113.18), Sim059 = c(50.1, 49.47, 
29.68, 43.19, 35.17, 95.79, 50.49, 46.12, 41.36, 55.78, 27.66, 
40.3, 47.85, 81.82, 37.56, 71, 56.49, 54.95, 49.76, 58.16 
), Sim060 = c(59.82, 36.35, 88.85, 116.35, 45.49, 133.77, 
41.36, 44.67, 34.49, 78.62, 57.15, 88.35, 28.35, 60.38, 68.16, 
150.2, 68.82, 68.36, 68.9, 35.27), Sim061 = c(78.89, 94.1, 
46.84, 70.41, 82.07, 63.92, 74.85, 45.1, 65.33, 52.73, 66.52, 
37.47, 67.55, 137.72, 82.13, 85.19, 66.18, 73.32, 67.15, 
57.61), Sim062 = c(81.25, 93.78, 43.91, 34.15, 97.4, 109.88, 
91.72, 62.36, 70.51, 59.99, 48.28, 62.83, 41.18, 50.3, 42.9, 
51.33, 39.26, 83.69, 42.38, 129.54), Sim063 = c(92.2, 53.54, 
78.81, 62.42, 83.9, 48.32, 36.29, 57.05, 46.86, 51.3, 69.92, 
58.82, 41.7, 80.2, 82.66, 78.44, 113.14, 72.73, 55.48, 78.88 
), Sim064 = c(68.46, 92.47, 40.15, 49.84, 38.22, 25.36, 77.04, 
80.5, 68.33, 42.91, 74.06, 74.03, 71.53, 91.14, 55.99, 41.71, 
45.23, 48.98, 65.36, 65.36), Sim065 = c(52.28, 120.72, 50.94, 
46.4, 59.19, 55.21, 134.89, 58.24, 54.64, 39.89, 77.4, 57.98, 
48.69, 43.63, 63.83, 113.99, 39.76, 62.65, 58.85, 63.1), 
Sim066 = c(78.03, 66.85, 27.91, 90.69, 28.72, 71.36, 73.96, 
103.19, 74.18, 43.95, 75.8, 140.66, 112.48, 59.78, 109.98, 
66.22, 123.03, 72.69, 76.89, 66.23), Sim067 = c(30.57, 61.86, 
81.85, 59.19, 57.64, 42.83, 39.97, 73.42, 66.35, 62.56, 77.06, 
60.96, 61.36, 90.85, 61.42, 121.89, 33.37, 38.83, 39.13, 
70.39), Sim068 = c(48.16, 63.75, 76.4, 17.38, 52.2, 61.95, 
73.14, 82.07, 33.54, 52.51, 61.77, 43.03, 68.15, 99, 41.97, 
94.21, 63.38, 72.88, 84.45, 77.36), Sim069 = c(199.92, 50.89, 
82.86, 30.25, 73.31, 51.05, 85.51, 52.66, 111.93, 43.89, 
114.57, 36, 46.55, 118.81, 83.79, 87.48, 76.51, 36.57, 63.2, 
55.37), Sim070 = c(77.63, 69.78, 41.28, 99.35, 80.91, 50.35, 
63.28, 86.09, 41.5, 77.95, 49.99, 64.87, 80.73, 44.15, 59.28, 
64.36, 95.07, 40.8, 103.74, 68.12), Sim071 = c(73.13, 90.19, 
39.37, 92.21, 38.72, 59.3, 59.63, 38.1, 77.38, 34.77, 74.84, 
43.84, 48.66, 69.32, 78.65, 89.51, 112.98, 83.36, 79.77, 
69.33), Sim072 = c(48.94, 79.94, 56.45, 71.4, 114.35, 61.25, 
88.91, 40.43, 71.21, 36.4, 53.34, 31.73, 70.45, 70.68, 26.03, 
77.17, 139.23, 30.64, 54.62, 45.7), Sim073 = c(90.61, 42.67, 
47.8, 62.26, 61.79, 78.01, 120.58, 61.89, 66.23, 69.28, 84.8, 
117.08, 70.77, 49, 65.52, 56.2, 124.19, 86.22, 104.7, 59.75 
), Sim074 = c(108.82, 74.84, 52.64, 61.65, 95.5, 100.88, 
61.06, 66.21, 134.45, 67.34, 67.65, 184.28, 82.28, 63.28, 
80.68, 58.1, 69.79, 114.61, 114.38, 60.15), Sim075 = c(56.4, 
71.83, 52.8, 46.04, 57.72, 78.28, 37.17, 54.41, 149.06, 35.09, 
70.95, 60.31, 107.83, 62.06, 36.78, 119.39, 54.17, 39.29, 
52.15, 91.5), Sim076 = c(73.24, 79.73, 58.04, 75.6, 99.1, 
59.95, 91.25, 55.96, 89.8, 103.72, 128.09, 56.35, 70.41, 
63.03, 67.42, 33.68, 52.25, 55.44, 40.41, 43.04), Sim077 = c(62.17, 
71.66, 51.93, 38.59, 104.54, 70.61, 69.26, 85.57, 56.65, 
56.74, 53.78, 73.24, 87.02, 63.44, 23.16, 31.31, 73.08, 24.96, 
74.46, 65.09), Sim078 = c(82.22, 44.23, 111.1, 43.37, 27.78, 
59.32, 60.79, 44.29, 34.12, 127.79, 43.09, 89.62, 59.46, 
54.22, 33.99, 85.2, 59.62, 38.53, 56.52, 45.58), Sim079 = c(74.24, 
40.5, 50.01, 62.35, 72.25, 86.32, 64.82, 94.35, 84.82, 73.1, 
34.69, 24.8, 59.56, 121.09, 73.31, 31.34, 90.42, 36.34, 69.64, 
78.18), Sim080 = c(55.04, 82.85, 19.32, 89.09, 66.21, 47.31, 
76.09, 75.88, 51.53, 103.09, 39.1, 61.51, 49.17, 78.87, 56.77, 
36.57, 91.1, 58.45, 46.61, 72.83), Sim081 = c(64.36, 99.43, 
55.1, 69.66, 54.11, 47.28, 59.61, 86.49, 81.46, 60.81, 51.63, 
69.41, 75.07, 73.5, 45.67, 36.28, 62.59, 52.71, 85.94, 83.04 
), Sim082 = c(52.98, 82.61, 54.28, 53.08, 57.04, 47.4, 64.55, 
72.55, 80.88, 61.19, 49.76, 36.32, 60.83, 80.69, 52.83, 72.73, 
76.1, 46.38, 65.93, 71.06), Sim083 = c(69.07, 81.13, 53.04, 
39.36, 28.55, 41.81, 36.99, 81.61, 109.19, 54.24, 60, 57.54, 
136.52, 93.04, 58.7, 73.08, 35.66, 34.86, 45.09, 76.62), 
Sim084 = c(90.19, 43.42, 75.16, 75.16, 33.06, 48.17, 71.74, 
29.67, 56.77, 26.87, 87.69, 81.29, 58.08, 65.15, 101.91, 
87.23, 42.49, 33.56, 77.63, 54.36), Sim085 = c(63.49, 82.74, 
59.87, 77.88, 40.73, 71.23, 120.13, 64.18, 87.58, 121.86, 
64.96, 62.73, 38.4, 85.41, 79.58, 49.38, 49, 62.84, 90.14, 
49.72), Sim086 = c(88.33, 80.44, 132.63, 107.53, 64.24, 43.19, 
130.09, 107.91, 60.15, 58.14, 53.03, 90.76, 78.17, 139.56, 
71.73, 82.55, 53.2, 68.94, 55, 59.18), Sim087 = c(49.11, 
62.7, 48.76, 99.97, 75.04, 34.77, 60.68, 68.9, 36.76, 112.95, 
34.86, 73.13, 52.06, 152.08, 104.78, 119.68, 42.02, 45.43, 
63.73, 125.19), Sim088 = c(67.52, 91.09, 91.14, 66.95, 60.57, 
45.83, 61, 35.04, 63.79, 111.8, 87.27, 53.01, 56.64, 60.25, 
31.08, 96.81, 113.34, 37.46, 73.03, 83.45), Sim089 = c(42.77, 
75.16, 114, 154.67, 56.7, 79.89, 81.79, 42.84, 109.66, 41.33, 
28.78, 31.88, 118.83, 59.86, 91.98, 71.25, 32.23, 44.86, 
81.37, 50.76), Sim090 = c(48.1, 80.97, 50.54, 63.82, 59.58, 
57.5, 63.89, 35.23, 47.96, 72.27, 36.25, 64.75, 89.16, 70.78, 
51.19, 59.98, 46.58, 42.59, 58.91, 55.28), Sim091 = c(63.06, 
68.09, 130.1, 57.53, 109.23, 32.15, 67.64, 56.55, 60.23, 
53.15, 120.2, 40.62, 89.09, 85.86, 58.44, 44.27, 77.34, 38.93, 
50.17, 69.32), Sim092 = c(38.79, 43.18, 123.18, 59.46, 48.14, 
72.46, 69.64, 45.79, 51.93, 38.79, 53.44, 46.58, 41.82, 49.96, 
72.31, 123.45, 66.02, 46.77, 37.24, 41.9), Sim093 = c(79.67, 
47.85, 72, 66.98, 76.16, 58.75, 52.11, 60.08, 44, 61.48, 
59.37, 55.79, 85.44, 43.41, 58.68, 98.53, 96.74, 61.61, 65.88, 
65.4), Sim094 = c(43.82, 36.17, 50.2, 75.13, 48.34, 35.14, 
71.98, 40.37, 84.7, 76.9, 104.48, 49.85, 100.88, 105.98, 
187.59, 46.83, 52.21, 43.24, 54.13, 81.76), Sim095 = c(93, 
60.84, 37.51, 101.75, 53.11, 53.08, 62.82, 111.24, 30.74, 
49.81, 42.1, 66.54, 71.24, 67.26, 64.89, 48.8, 63.78, 51.24, 
81.58, 60.91), Sim096 = c(73.68, 51.34, 148.38, 44.37, 85.09, 
24.63, 85.84, 80.44, 93.39, 196.38, 42.76, 62.17, 42.13, 
56.12, 56.71, 39.55, 81.37, 40.32, 72.2, 40.77), Sim097 = c(48.89, 
97.01, 29.05, 112.77, 28.27, 57.75, 85.94, 51.69, 58.61, 
32.72, 35.08, 44.03, 121.13, 88.94, 69.46, 75.61, 55.79, 
70.04, 47.91, 217.15), Sim098 = c(110.83, 53.7, 115.46, 50.46, 
92.72, 43.66, 88.45, 63.93, 54.36, 74.44, 54.67, 56.96, 46.54, 
86.65, 60.91, 61.26, 47.6, 55.04, 59.69, 49.21), Sim099 = c(31.68, 
47.26, 94.13, 66.91, 122.04, 55.12, 65.5, 113.39, 84.46, 
79.77, 51.33, 56.98, 72.55, 55.98, 89.94, 56.12, 57.61, 47.81, 
74.62, 72.74), Sim100 = c(57.1, 46.75, 32.57, 44.22, 67.5, 
64.69, 46.55, 99.27, 71.21, 90.31, 68.15, 58.36, 46.42, 44.41, 
80.41, 35.38, 95.21, 52.11, 55.61, 41.38)), .Names = c("Sim001", 
"Sim002", "Sim003", "Sim004", "Sim005", "Sim006", "Sim007", "Sim008", 
"Sim009", "Sim010", "Sim011", "Sim012", "Sim013", "Sim014", "Sim015", 
"Sim016", "Sim017", "Sim018", "Sim019", "Sim020", "Sim021", "Sim022", 
"Sim023", "Sim024", "Sim025", "Sim026", "Sim027", "Sim028", "Sim029", 
"Sim030", "Sim031", "Sim032", "Sim033", "Sim034", "Sim035", "Sim036", 
"Sim037", "Sim038", "Sim039", "Sim040", "Sim041", "Sim042", "Sim043", 
"Sim044", "Sim045", "Sim046", "Sim047", "Sim048", "Sim049", "Sim050", 
"Sim051", "Sim052", "Sim053", "Sim054", "Sim055", "Sim056", "Sim057", 
"Sim058", "Sim059", "Sim060", "Sim061", "Sim062", "Sim063", "Sim064", 
"Sim065", "Sim066", "Sim067", "Sim068", "Sim069", "Sim070", "Sim071", 
"Sim072", "Sim073", "Sim074", "Sim075", "Sim076", "Sim077", "Sim078", 
"Sim079", "Sim080", "Sim081", "Sim082", "Sim083", "Sim084", "Sim085", 
"Sim086", "Sim087", "Sim088", "Sim089", "Sim090", "Sim091", "Sim092", 
"Sim093", "Sim094", "Sim095", "Sim096", "Sim097", "Sim098", "Sim099", 
"Sim100"), row.names = c(NA, 20L), class = "data.frame") 

2) The ouput for the last column looks like: 

$Sim100 
FUN(x = X[[100L]], type = "GEV", method = ..2) 

[1] "Normal Approx." 

95% lower CI  Estimate 95% upper CI 
2-year return level       47.45112  56.12244     64.79377 
5-year return level       60.89166  73.38495     85.87825 
10-year return level      66.75437  85.28832    103.82226 
20-year return level      68.03104  97.07476    126.11849 
50-year return level      62.95423 112.88572    162.81720 
100-year return level     54.12096 125.15808    196.19519 

For each df in lst, I would like to get the `mean` of all variables in all columns. So, make an avearge of 

                        95% lower CI  Estimate 95% upper CI 
2-year return level  47.45112        56.12244         64.79377 
5-year return level  60.89166  7      3.38495         85.87825 
10-year return level  66.75437       85.28832        103.82226 
20-year return level  68.03104       97.07476        126.11849 
50-year return level  62.95423       112.88572       162.81720 
100-year return level  54.12096      125.15808       196.19519 

in each df. For example, 47.45112 is the mean of 95% lower CIs for 2-year return level for all columns in df1.The final format for each dataframe in lst is as shown here with rownames, and colnames. So,if lst has 4 dfs, then lst.final should have 4 dfs with the above format.

Thanks for helping.
AT.


From sarah.goslee at gmail.com  Fri Mar  6 05:24:25 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 5 Mar 2015 23:24:25 -0500
Subject: [R] problem with function that adds rows to dataframe based on
 conditional statement
In-Reply-To: <1425598186197-4704237.post@n4.nabble.com>
References: <CAJmwvUadtpFODfCV3Qh+xHuiGvLH0DUSvehuMb_S-_dF6Rck5g@mail.gmail.com>
	<1425598186197-4704237.post@n4.nabble.com>
Message-ID: <CAM_vjukRo4HZ=E_nL_aQJ7-qLbK_tw9UsBjwCZUqtyEko=tvfw@mail.gmail.com>

Why should he? seq_len() is part of base R.

On Thursday, March 5, 2015, JS Huang <js.huang at protective.com> wrote:

> Hi Curtis,
>
>   Maybe you forgot to tell us how the function seq_len is defined.
>
>
>
> -----
> JS Huang
> --
> View this message in context:
> http://r.789695.n4.nabble.com/problem-with-function-that-adds-rows-to-dataframe-based-on-conditional-statement-tp4704228p4704237.html
> Sent from the R help mailing list archive at Nabble.com.
>

Nabble is not either the R help mailing list archive, and if you don't
include context in your post the real R help list will have little idea
what you're talking about.

Sarah




-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Mar  6 05:32:18 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 5 Mar 2015 23:32:18 -0500
Subject: [R] help on output my own function result in ddply
In-Reply-To: <1425605284561-4704240.post@n4.nabble.com>
References: <1425601442201-4704238.post@n4.nabble.com>
	<1425605284561-4704240.post@n4.nabble.com>
Message-ID: <CAM_vju=peze5pLbkfVTOPAhLiqkmZsrer8+UughWaQXAzNf8og@mail.gmail.com>

 Hi,

On Thursday, March 5, 2015, JS Huang <js.huang at protective.com> wrote:

> Hi,
>
>   There is a lot of if-else statement.  r syntax rejects them.  Here is an
> example of if-else example.  In r we can code *ifelse(x>2,y <-
> 1,ifelse(x>1,y <- 0.5, y <- 0))* for the following.


I'm not sure what you are talking about: if-else is a valid construct in R,
and NOT synonymous with ifelse().

Your construct below is wrong, though, because the curly brace on a line
alne tells R that you're done. Instead you need

if(x > 2) {
   y <- 1
} else {
   y <- 0
}

and these can be nested at will. Note that else is on the same line as the
curly brace ending the if statement.

http://cran.r-project.org/doc/manuals/R-lang.html#if


>
> if (x > 2)
> {
>   y = 1
> }
> else
> {
>   if (x > 1)
>   {
>      y = 0.5
>   }
>   else
>   {
>      y = 0
>   }
> }
>
>
>
>
> -----
> JS Huang
> --
> View this message in context:
> http://r.789695.n4.nabble.com/help-on-output-my-own-function-result-in-ddply-tp4704238p4704240.html
> Sent from the R help mailing list archive at Nabble.com.


Nabble is not the R help mailing list archive, and if you don't include
context in your post the real R help list will have little idea what you're
talking about.


>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Instead, you could actually sign up for the mailing list.

Sarah



-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From henrik.bengtsson at ucsf.edu  Fri Mar  6 06:57:59 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Thu, 5 Mar 2015 21:57:59 -0800
Subject: [R] help on output my own function result in ddply
In-Reply-To: <CAM_vju=peze5pLbkfVTOPAhLiqkmZsrer8+UughWaQXAzNf8og@mail.gmail.com>
References: <1425601442201-4704238.post@n4.nabble.com>
	<1425605284561-4704240.post@n4.nabble.com>
	<CAM_vju=peze5pLbkfVTOPAhLiqkmZsrer8+UughWaQXAzNf8og@mail.gmail.com>
Message-ID: <CAFDcVCRX_1_0W6_9gD_5mXuzkbKL_QH1jXDj93fFJvKjt9wMGg@mail.gmail.com>

On Mar 5, 2015 8:32 PM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:
>
>  Hi,
>
> On Thursday, March 5, 2015, JS Huang <js.huang at protective.com> wrote:
>
> > Hi,
> >
> >   There is a lot of if-else statement.  r syntax rejects them.  Here is
an
> > example of if-else example.  In r we can code *ifelse(x>2,y <-
> > 1,ifelse(x>1,y <- 0.5, y <- 0))* for the following.
>
>
> I'm not sure what you are talking about: if-else is a valid construct in
R,
> and NOT synonymous with ifelse().
>
> Your construct below is wrong, though, because the curly brace on a line
> alne tells R that you're done. Instead you need
>
> if(x > 2) {
>    y <- 1
> } else {
>    y <- 0
> }
>
> and these can be nested at will. Note that else is on the same line as the
> curly brace ending the if statement.
>
> http://cran.r-project.org/doc/manuals/R-lang.html#if
>
>
> >
> > if (x > 2)
> > {
> >   y = 1
> > }
> > else
> > {
> >   if (x > 1)
> >   {
> >      y = 0.5
> >   }
> >   else
> >   {
> >      y = 0
> >   }
> > }
> >
> >
> >
> >
> > -----
> > JS Huang
> > --
> > View this message in context:
> >
http://r.789695.n4.nabble.com/help-on-output-my-own-function-result-in-ddply-tp4704238p4704240.html
> > Sent from the R help mailing list archive at Nabble.com.
>
>
> Nabble is not the R help mailing list archive, and if you don't include
> context in your post the real R help list will have little idea what
you're
> talking about.

Yes, it has happened before and is really confusing to the r-help list.  It
occurs when the original message is posted by a user on Nabble who is not
on the r-help list - then that message is held for moderation/discarded.
Then another Nabble user, who is on also the r-help list, respond via
Nabble and then we only see that reply over here at r-help.  Second user
who reply is probably unaware of this (though the Nabble interface says
"This post has NOT been accepted by the mailing list yet.") and makes it
look like s/he is posting random text/code.

It would be useful if our mailing list server could filter out/block such
threads, but that is probably not that easy to do.

Henrik

>
>
> >
> > ______________________________________________
> > R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> > more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> Instead, you could actually sign up for the mailing list.
>
> Sarah
>
>
>
> --
> Sarah Goslee
> http://www.stringpage.com
> http://www.sarahgoslee.com
> http://www.functionaldiversity.org
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Fri Mar  6 10:23:25 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 06 Mar 2015 09:23:25 +0000
Subject: [R] error message: ReadItem: unknown type 64,
 perhaps written by later version of R
In-Reply-To: <3FA7C532AA08284AB2ACA7B0AB56EF8715928D14@vitomail4.vito.local>
References: <3FA7C532AA08284AB2ACA7B0AB56EF8715928D14@vitomail4.vito.local>
Message-ID: <54F9720D.6030809@stats.ox.ac.uk>

On 05/03/2015 20:34, Franckx Laurent wrote:
> Dear all
>
> I get the following error message when I try to load one  specific RData object in R:
>
>          Error: ReadItem: unknown type 64, perhaps written by later version of R
>
>
> The error message is odd because (a) this RData object was created just one hour berfore in a  previous script (in a series of R scripts called in batch mode), so it would seem to me that it has been created by the same version of R that is now calling it (b) this script is "looping" over several scenarios and years, and the error only occurs for one very specific combination of scenarios and years. This object is about 6 Gb large, which is the same  size as the other objects that were called in previous instances.

What is 'odd' is that you missed the 'perhaps'.

The most likely explanation is an I/O error when the file was written: 
it is 'perhaps' corrupted.


> I load the RData with the following command (where pathsony[[rdata]] is the folder with the RData and skimlistrdata is the file I try to load):
>
>          load( file.path(pathsony[[rdata]],skimlistrdata))
>
>
> The problem occurs both when I run the script in batch mode or when I run it interactively.
>
> I use a  "x86_64-pc-linux-gnu" and  "R version 3.1.2 (2014-10-31)".
>
>
> Laurent Franckx, PhD
> Senior researcher sustainable mobility
> VITO NV | Boeretang 200 | 2400 Mol
> Tel. ++ 32 14 33 58 22| mob. +32 479 25 59 07 | Skype: laurent.franckx | laurent.franckx at vito.be | Twitter @LaurentFranckx


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From laurent.franckx at vito.be  Fri Mar  6 10:41:06 2015
From: laurent.franckx at vito.be (Franckx Laurent)
Date: Fri, 6 Mar 2015 09:41:06 +0000
Subject: [R] error message: ReadItem: unknown type 64,
 perhaps written by later version of R
In-Reply-To: <54F9720D.6030809@stats.ox.ac.uk>
References: <3FA7C532AA08284AB2ACA7B0AB56EF8715928D14@vitomail4.vito.local>
	<54F9720D.6030809@stats.ox.ac.uk>
Message-ID: <3FA7C532AA08284AB2ACA7B0AB56EF87159290B9@vitomail4.vito.local>



> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: vrijdag 6 maart 2015 10:23
> To: Franckx Laurent; r-help at r-project.org
> Subject: Re: [R] error message: ReadItem: unknown type 64, perhaps written
> by later version of R
>
> On 05/03/2015 20:34, Franckx Laurent wrote:
> > Dear all
> >
> > I get the following error message when I try to load one  specific RData
> object in R:
> >
> >          Error: ReadItem: unknown type 64, perhaps written by later
> > version of R
> >
> >
> > The error message is odd because (a) this RData object was created just
> one hour berfore in a  previous script (in a series of R scripts called in batch
> mode), so it would seem to me that it has been created by the same version
> of R that is now calling it (b) this script is "looping" over several scenarios and
> years, and the error only occurs for one very specific combination of
> scenarios and years. This object is about 6 Gb large, which is the same  size as
> the other objects that were called in previous instances.
>
> What is 'odd' is that you missed the 'perhaps'.
>
> The most likely explanation is an I/O error when the file was written:
> it is 'perhaps' corrupted.
>
>

Dear Professor Riply,

Thank you for your suggestion.

The possibility of an I/O error in the writing of the file is actually something I had anticipated. The saving of the file is immediately followed by a test - see the code below.

        save(list = skimlistname, file = file.path(pathsony[[rdata]],skimlistnamerdata))
        if(file.exists(file.path(pathsony[[rdata]],skimlistnamerdata))) {
                cat(skimlistnamerdata, " has been created. \n ", file = warningfile, sep = "", append = TRUE)
                } else {
                stop(skimlistnamerdata, " has not been created correctly. \n ")
                }

My understanding was that this test code would stop the execution of the program if the file had not been saved correctly.
Moreover, each of my script starts with a verification whether any error message is contained in the Rout of the preceding scripts, and stops execution immediately if this is indeed the case.
Therefore, I should not even have reached the point where R tries to load the file in memory.
Is there any alternative to verifying whether a file has been created correctly without actually loading it?
Sincerely,
Laurent Franckx



> > I load the RData with the following command (where pathsony[[rdata]] is
> the folder with the RData and skimlistrdata is the file I try to load):
> >
> >          load( file.path(pathsony[[rdata]],skimlistrdata))
> >
> >
> > The problem occurs both when I run the script in batch mode or when I run
> it interactively.
> >
> > I use a  "x86_64-pc-linux-gnu" and  "R version 3.1.2 (2014-10-31)".
> >
> >
> > Laurent Franckx, PhD
> > Senior researcher sustainable mobility VITO NV | Boeretang 200 | 2400
> > Mol Tel. ++ 32 14 33 58 22| mob. +32 479 25 59 07 | Skype:
> > laurent.franckx | laurent.franckx at vito.be | Twitter @LaurentFranckx
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
VITO Disclaimer: http://www.vito.be/e-maildisclaimer

From petr.pikal at precheza.cz  Fri Mar  6 11:04:13 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 6 Mar 2015 10:04:13 +0000
Subject: [R] problem with function that adds rows to dataframe based on
 conditional statement
In-Reply-To: <CAJmwvUadtpFODfCV3Qh+xHuiGvLH0DUSvehuMb_S-_dF6Rck5g@mail.gmail.com>
References: <CAJmwvUadtpFODfCV3Qh+xHuiGvLH0DUSvehuMb_S-_dF6Rck5g@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C22CDD@SRVEXCHMBX.precheza.cz>

Hi

May I ask you why do you need such operation. I cannot imagine a situation where I would need to do this. The only imaginable procedure is to merge NA enhanced object with another object but for that situation usually

?merge

is used

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Curtis
> Burkhalter
> Sent: Thursday, March 05, 2015 9:42 PM
> To: r-help at r-project.org
> Subject: [R] problem with function that adds rows to dataframe based on
> conditional statement
>
> Hello everyone,
>
> I'm having a problem with a function that I wrote that is supposed to
> add a
> row to dataframe based upon a conditional statement. To explain I've
> used
> an example below:
>
> #create data frame
> animals=c("bird","dog","cat")
> animals=rep(animals,each=4)
> animals=animals[1:11]
> animalYears=c(1,1,2,2,1,1,2,2,1,1,2)
> animalMass=round(runif(11,min=10,max=50),0)
>
> comAn=as.data.frame(cbind(animals,animalYears,animalMass))
> comAn
>
>   * animals* *animalYears* *animalMass*
> 1     bird           1         30
> 2     bird           1         32
> 3     bird           2         27
> 4     bird           2         16
> 5      dog           1         22
> 6      dog           1         25
> 7      dog           2         41
> 8      dog           2         22
> 9      cat           1         30
> 10     cat           1         37
> 11     cat           2         49
>
> We can see here that for every type of animal I have two years of mass
> measurements, except for the cat in year 2. What I want to do is add an
> additional row to the end of the dataframe that consists strictly of
> NAs
> and then I can substitute those out later.
>
> So what I first did was split the 'comAn' dataframe into the different
> Animal by Year combos.
>
> #This line splits 'com_An' into a list ordered by the Animal by Year
> combos
> comAn_split=split(comAn, paste(comAn$animals,comAn$animalYear))
>
> Then I wrote the function that identifies whether a particular Animal
> by
> Year combo is less than two rows in length and if so it should add
> another
> row that consists only of NAs using the vector 'NAs':
>
> #This function identifies the length of each Animal by Year combo and
> then
> #uses the rbind function built in R to add a row
> #to each animal by year combo if they have less than 2 samples
>
> addNA <- function(comAn) {
>   NAs=c(NA,NA,NA)
>         ind <- seq_len(nrow(comAn))
>         comAn[ifelse(length(ind)<2,rbind(NAs),length(ind)),]
> }
>
> #This applies the function addNs to the animals data organized in list
> format
> addedNAcomAn <- do.call(rbind, lapply(comAn_split, addNA))
> addedNAcomAn
>
> When I apply the function to the list of the different Animal by Year
> combos this is what I get:
>        animals animalYears animalMass
> bird 1    bird           1         23
> bird 2    bird           2         50
> cat 1      cat           1         15
> cat 2     <NA>        <NA>       <NA>
> dog 1      dog           1         23
> dog 2      dog           2         38
>
> What I expect is this:
>
>    animals animalYears animalMass
> 1     bird           1         41
> 2     bird           1         23
> 3     bird           2         23
> 4     bird           2         50
> 5      dog           1         49
> 6      dog           1         23
> 7      dog           2         13
> 8      dog           2         38
> 9      cat           1         42
> 10     cat           1         15
> 11     cat           2         33
> 12     NA           NA      NA
>
> Am I conditioning improperly within the function or am I missing
> something
> else. Any help would be greatly appreciated.
>
> Best
>
> --
> Curtis Burkhalter
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From alrik.thiem at gmail.com  Fri Mar  6 11:07:11 2015
From: alrik.thiem at gmail.com (Alrik Thiem)
Date: Fri, 6 Mar 2015 11:07:11 +0100
Subject: [R] Concatenating elements from lists via combinations
Message-ID: <001501d057f5$50db7cb0$f2927610$@gmail.com>

Dear R-help list,

I have a problem in which I would like to concatenate elements from lists in
a combinational order. For example, I have a list of n character vectors
(here 3), each with m elements (here 7,3,1):

lst <- list(c("a","aB","aBC","aC","B","BC","C"), c("B","Bc","c"), c("D"))

[[1]]
[1] "a"   "aB"  "aBC" "aC"  "B"   "BC"  "C"  
[[2]]
[1] "B"  "Bc" "c" 
[[3]]
[1] "D"

As the first list element has seven, the second has three and the third has
one element, there are 21 different combinations of the individual vector
elements: 

idx <- expand.grid(1:7,1:3,1:1)

   Var1 Var2 Var3
1     1    1    1
2     2    1    1
.     .    .    .
6     6    1    1
7     7    1    1
8     1    2    1
9     2    2    1
.     .    .    .
20    6    3    1
21    7    3    1

How could I create an exhaustive list of length 21 now, each of whose
elements contains a unique combination of vector elements? I.e., the final
list should look like this

[[1]]
[1] "a" "B" "D"  
[[2]]
[1] "aB" "B" "D" 
[[3]]
[1] "aBC" "B" "D"
[[4]]
[1] "aC" "B" "D"
.....
[[21]]
[1] "C" "c" "D"

Many thanks for help,
Alrik


********************************
Alrik Thiem
Post-Doctoral Researcher

Department of Philosophy
University of Geneva
Rue de Candolle 2
CH-1211 Geneva

+41 76 527 80 83

http://www.alrik-thiem.net
http://www.compasss.org


From S.Ellison at LGCGroup.com  Fri Mar  6 11:15:32 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 6 Mar 2015 10:15:32 +0000
Subject: [R] subset a data frame by largest frequencies of factors
In-Reply-To: <54F8A437.90404@yorku.ca>
References: <54F8A437.90404@yorku.ca>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED66A596A0C5@GOLD.corp.lgc-group.com>



> -----Original Message-----
> A consulting client has a large data set with a binary response
> (negative) and two factors (ctry and member) which have many levels, but
> many occur with very small frequencies.  It is far too sparse with a model like
> glm(negative ~ ctry+member, family=binomial).
> 
> For analysis, we'd like to subset the data to include only those that occur with
> frequency greater than a given value

ave() helps with this kind of thing. 

Something like

freq <- ave(1:length(ctry), factor(ctry:member), FUN=length)

gives the count for each ctry:member call. Then you can subset a data frame using, for example

dfr.subset <- dfr[freq>10, ]

The 1:length(ctry) in the ave call is simply because ave wants a numeric there. If all we're doing with it is counting the number, it just has to be a numeric of the same length as your data. in a data frame it can be 1:nrow(dfr) etc.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at LGCGroup.com  Fri Mar  6 11:18:55 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 6 Mar 2015 10:18:55 +0000
Subject: [R] Concatenating elements from lists via combinations
In-Reply-To: <001501d057f5$50db7cb0$f2927610$@gmail.com>
References: <001501d057f5$50db7cb0$f2927610$@gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED66A596A0C9@GOLD.corp.lgc-group.com>



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alrik Thiem
> 
> lst <- list(c("a","aB","aBC","aC","B","BC","C"), c("B","Bc","c"), c("D"))
> 
 > How could I create an exhaustive list of length 21 now, each of whose elements
> contains a unique combination of vector elements? 

do.call(expand.grid, lst)

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From therneau at mayo.edu  Fri Mar  6 14:04:19 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 06 Mar 2015 07:04:19 -0600
Subject: [R] Error in thielsen
In-Reply-To: <mailman.1.1425639601.1866.r-help@r-project.org>
References: <mailman.1.1425639601.1866.r-help@r-project.org>
Message-ID: <1e7ee5$6chd4@ironport10.mayo.edu>

I have no idea.  A data set that generates the error would be very helpful to me.  What is 
the role of the last line BTW, the one with "1%" on it?
  Looking at the code I would guess that the vector "tied" has an NA in it, but how that 
would happen I can't see.  There is a reasonable chance that it will become obvious once I 
have an example.

Terry Therneau


On 03/06/2015 05:00 AM, r-help-request at r-project.org wrote:
> I don?t understand an error message from a thielsen function call within a
> dplyr do function call.
>
> by.CaseNo <- group_by(as.data.frame(MAP.dt), CaseNo)
>> >MAP.thielsen <- by.CaseNo %>%
> +   do(model = thielsen(noninvMAP ~ invMAP, symmetric = T, data = .,
> +                       x = T, y = T, model = T, nboot = 1000))
> |                                                   |  1% ~40 m remaining
>
>
> Error in if (any(tied)) { : missing value where TRUE/FALSE needed
>


From S.Ellison at LGCGroup.com  Fri Mar  6 15:24:37 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 6 Mar 2015 14:24:37 +0000
Subject: [R] Error in thielsen
In-Reply-To: <1e7ee5$6chd4@ironport10.mayo.edu>
References: <mailman.1.1425639601.1866.r-help@r-project.org>
	<1e7ee5$6chd4@ironport10.mayo.edu>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED66A596A317@GOLD.corp.lgc-group.com>

> I have no idea.  A data set that generates the error would be very helpful to
> me.  What is the role of the last line BTW, the one with "1%" on it?
>   Looking at the code I would guess that the vector "tied" has an NA in it, but
> how that would happen I can't see.  There is a reasonable chance that it will
> become obvious once I have an example.


In a small bootstrap or other simulation one can end up by chance with a vector that doesn't behave; for example one with all values the same or with the one NA substituted into the whole vector. A common symptom is that the bootstrap sometimes works and sometimes doesn't, or only seems to work for small numbers of bootstrap replicates.

But you're right; with no data, one can only guess.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From Brian.Davis at uth.tmc.edu  Fri Mar  6 17:22:46 2015
From: Brian.Davis at uth.tmc.edu (Davis, Brian)
Date: Fri, 6 Mar 2015 16:22:46 +0000
Subject: [R] Tracing a variable name back
Message-ID: <FDC71085EDA9A946B66619E7EAD402A004352CA6@UTHMAIL2.uthouston.edu>

I'm looking to find a way to trace back the original variable name after a being passed through a series of functions.

I can get the variables names for the current call easy enough with match.call, but I'd like to go back further if the function was called from another function.

Say I have.

df <- data.frame(x=1:3, y=c("A", "B", "C"))

check_stuff <- function(x, cn) {
  cl <- match.call()
  df_name <- as.character(as.list(cl)$x)
  cn_name <- as.character(as.list(cl)$cn)
  
  print(df_name)
  print(cn_name)
}


foo <- function(p1, p2) {
  check_stuff(p1, p2)
}

bar <- function(x1, x2) {
  foo(x1, x2)
}

> check_stuff(df, "y")
[1] "df"
[1] "y"

> foo(df, "y")
[1] "p1"
[1] "p2"

> bar(df, "y")
[1] "p1"
[1] "p2"


I'd like foo(df, "y")  and bar(df, "y") to print "df" and "y" from check_type

Any advice on how to achieve this?

Thanks in advance,


Brian Davis


From curtisburkhalter at gmail.com  Fri Mar  6 18:27:20 2015
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Fri, 6 Mar 2015 10:27:20 -0700
Subject: [R] problem with function that adds rows to dataframe based on
 conditional statement
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C22CDD@SRVEXCHMBX.precheza.cz>
References: <CAJmwvUadtpFODfCV3Qh+xHuiGvLH0DUSvehuMb_S-_dF6Rck5g@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C22CDD@SRVEXCHMBX.precheza.cz>
Message-ID: <CAJmwvUaCMTY1Wze5Z0Q+oE07yz4La=Ent=kTs9=m6O0CnyDkeA@mail.gmail.com>

Petr,

The reason I need to do this is that I'm going to be using some large
datasets in WinBUGS, but there is some missing data for the files I'm
using. In order to make the data files readable in WinBUGS there have to be
NAs in place of missing data so I'm trying to add in NAs where there are
missing sampling occasions for a site in a given year. I tried using
'merge' within my function, but that didn't seem to work either. Thanks for
the suggestion, but I've got to try something else.

Best

On Fri, Mar 6, 2015 at 3:04 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> May I ask you why do you need such operation. I cannot imagine a situation
> where I would need to do this. The only imaginable procedure is to merge NA
> enhanced object with another object but for that situation usually
>
> ?merge
>
> is used
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Curtis
> > Burkhalter
> > Sent: Thursday, March 05, 2015 9:42 PM
> > To: r-help at r-project.org
> > Subject: [R] problem with function that adds rows to dataframe based on
> > conditional statement
> >
> > Hello everyone,
> >
> > I'm having a problem with a function that I wrote that is supposed to
> > add a
> > row to dataframe based upon a conditional statement. To explain I've
> > used
> > an example below:
> >
> > #create data frame
> > animals=c("bird","dog","cat")
> > animals=rep(animals,each=4)
> > animals=animals[1:11]
> > animalYears=c(1,1,2,2,1,1,2,2,1,1,2)
> > animalMass=round(runif(11,min=10,max=50),0)
> >
> > comAn=as.data.frame(cbind(animals,animalYears,animalMass))
> > comAn
> >
> >   * animals* *animalYears* *animalMass*
> > 1     bird           1         30
> > 2     bird           1         32
> > 3     bird           2         27
> > 4     bird           2         16
> > 5      dog           1         22
> > 6      dog           1         25
> > 7      dog           2         41
> > 8      dog           2         22
> > 9      cat           1         30
> > 10     cat           1         37
> > 11     cat           2         49
> >
> > We can see here that for every type of animal I have two years of mass
> > measurements, except for the cat in year 2. What I want to do is add an
> > additional row to the end of the dataframe that consists strictly of
> > NAs
> > and then I can substitute those out later.
> >
> > So what I first did was split the 'comAn' dataframe into the different
> > Animal by Year combos.
> >
> > #This line splits 'com_An' into a list ordered by the Animal by Year
> > combos
> > comAn_split=split(comAn, paste(comAn$animals,comAn$animalYear))
> >
> > Then I wrote the function that identifies whether a particular Animal
> > by
> > Year combo is less than two rows in length and if so it should add
> > another
> > row that consists only of NAs using the vector 'NAs':
> >
> > #This function identifies the length of each Animal by Year combo and
> > then
> > #uses the rbind function built in R to add a row
> > #to each animal by year combo if they have less than 2 samples
> >
> > addNA <- function(comAn) {
> >   NAs=c(NA,NA,NA)
> >         ind <- seq_len(nrow(comAn))
> >         comAn[ifelse(length(ind)<2,rbind(NAs),length(ind)),]
> > }
> >
> > #This applies the function addNs to the animals data organized in list
> > format
> > addedNAcomAn <- do.call(rbind, lapply(comAn_split, addNA))
> > addedNAcomAn
> >
> > When I apply the function to the list of the different Animal by Year
> > combos this is what I get:
> >        animals animalYears animalMass
> > bird 1    bird           1         23
> > bird 2    bird           2         50
> > cat 1      cat           1         15
> > cat 2     <NA>        <NA>       <NA>
> > dog 1      dog           1         23
> > dog 2      dog           2         38
> >
> > What I expect is this:
> >
> >    animals animalYears animalMass
> > 1     bird           1         41
> > 2     bird           1         23
> > 3     bird           2         23
> > 4     bird           2         50
> > 5      dog           1         49
> > 6      dog           1         23
> > 7      dog           2         13
> > 8      dog           2         38
> > 9      cat           1         42
> > 10     cat           1         15
> > 11     cat           2         33
> > 12     NA           NA      NA
> >
> > Am I conditioning improperly within the function or am I missing
> > something
> > else. Any help would be greatly appreciated.
> >
> > Best
> >
> > --
> > Curtis Burkhalter
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>



-- 
Curtis Burkhalter

https://sites.google.com/site/curtisburkhalter/

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Mar  6 10:21:00 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 6 Mar 2015 20:21:00 +1100
Subject: [R] Dividing a map by electoral results with R?
In-Reply-To: <AF1EF914-C612-481F-9E5B-1F090FD44E24@comcast.net>
References: <1425578994536-4704211.post@n4.nabble.com>
	<AF1EF914-C612-481F-9E5B-1F090FD44E24@comcast.net>
Message-ID: <CA+8X3fWp7x5gD6KqTOxFRpQJ+RAozXFy6LZUDCnz57PwPa20Ow@mail.gmail.com>

Hi Evelyne,
Not really easy, as you have to work out the upper (55) and lower (47.27)
latitudes of Germany, but try this:

DEylim<-c(47.27,55)
DENS<-diff(DEylim)
clip(5.8,15.1,DEylim[2]-0.494*DENS,DEylim[2])
abline(h=60)
map("worldHires","Germany",fill=TRUE,col="blue")
text(10.3,52.5,"CDU/CSU",col="white")
clip(5.8,15.1,DEylim[2]-0.799*DENS,DEylim[2]-0.494*DENS)
abline(h=60)
map("worldHires","Germany",fill=TRUE,col="red",add=TRUE)
text(10.3,50,"SPD",col="white")
clip(5.8,15.1,DEylim[2]-0.9*DENS,DEylim[2]-0.799*DENS)
abline(h=60)
map("worldHires","Germany",fill=TRUE,col="orange",add=TRUE)
text(10.3,48.5,"LINKE",col="white")
clip(5.8,15.1,DEylim[1],DEylim[2]-0.9*DENS)
abline(h=60)
map("worldHires","Germany",fill=TRUE,col="green",add=TRUE)
text(10.3,47.8,"GRUENE",col="white")

Jim


On Fri, Mar 6, 2015 at 8:12 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Mar 5, 2015, at 10:09 AM, Evelyne1991 wrote:
>
> > Hi everyone,
> >
> > I would like to divide a map of Germany vertically by the electoral
> results
> > of 2013:
> >
> >> VoteGermany2013
> >    Party Result
> > 1 CDU/CSU   49.4
> > 2     SPD   30.5
> > 3   LINKE   10.2
> > 4  GRUENE   10.0
> >
> > What I'm looking for is very simple: a map divided like a one-bar graph,
> > with 49.4% of the lenght for CDU/CSU, 30.5% for SPD and so on. It would
> be
> > like a single bar divided in parts, but with the form of a country (quite
> > simple in fact).
> >
> > For the map, I'm using:
> >
> > library(maps)
> > library(mapdata)
> > map("worldHires","Germany")
> >
> > Would someone be able to help me?
>
> Please do not crosspost to Rhelp and StackOverflow.
> >
> > View this message in context:
> http://r.789695.n4.nabble.com/Dividing-a-map-by-electoral-results-with-R-tp4704211.html
> > Sent from the R help mailing list archive at Nabble.com.
> >
> > ####
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From js.huang at protective.com  Fri Mar  6 03:50:39 2015
From: js.huang at protective.com (JS Huang)
Date: Thu, 5 Mar 2015 18:50:39 -0800 (PST)
Subject: [R] Using R to Calculate Coefficients of Relatedness and
 Kinship for Family Members
In-Reply-To: <1425594759432-4704232.post@n4.nabble.com>
References: <1425594759432-4704232.post@n4.nabble.com>
Message-ID: <1425610239886-4704243.post@n4.nabble.com>

Hi,

  I don't quite understand the logic since some later assignment will
overwrite the previous one.  I simply assign for the current index and
ignore the index after it.  In addition, the column Dads.Renamed is not in
the data.frame you defined in the post and I used Father_ID to substitute
for it.  Here is an implementation.  Write back if this is not what you
expect.

> pedigree.data
   Subject Twin_Stat Zygosity Father_ID Mother_ID
1   100307      Twin    NotMZ     81352     51488
2   100408      Twin       MZ     81594     51730
3   101006      Twin       MZ     81149     51283
4   101107   NotTwin  NotTwin     81833     51969
5   101309   NotTwin  NotTwin     82248     52385
6   101410      Twin    NotMZ     82061     52198
7   101915   NotTwin  NotTwin     81841     51977
8   102008   NotTwin  NotTwin     81882     52018
9   102311      Twin       MZ     81543     51679
10  102816      Twin       MZ     81283     51418
> assignKinScore
function(Input)
{
  result <- rep(0,dim(Input)[1] - 1)
  for (i in 1:(dim(Input)[1] - 1))
  {
    if (as.character(Input$Twin_Stat[i]) == "Twin" &
as.character(Input$Twin_Stat[i + 1]) == "Twin")
    {
      if (as.character(Input$Zygosity[i]) == "MZ" &
as.character(Input$Zygosity[i + 1]) == "MZ")
      {
        result[i] <- 0.5
      }
      else
      {
        if (as.character(Input$Zygosity[i]) == "DZ" &
as.character(Input$Zygosity[i + 1]) == "DZ")
        {
          result[i] <- 0.25
        }        
      }
    }
    else
    {
      if (as.character(Input$Twin_Stat[i])=="NotTwin" &
as.character(Input$Twin_Stat[i + 1])=="NotTwin")
      {
        if (Input$Mother_ID[i] == Input$Mother_ID[i + 1] &
Input$Father_ID[i] == Input$Father_ID[i + 1])
        {
          result[i] <- 0.25
        }
        else
        {
          if (Input$Mother_ID[i] == Input$Mother_ID[i + 1] &
Input$Father_ID[i] != Input$Father_ID[i + 1])
          {
            result[i] <- 0.125
          }        
        }
      }
    }
  }
  return(result)
}
> assignKinScore(pedigree.data)
[1] 0.0 0.5 0.0 0.0 0.0 0.0 0.0 0.0 0.5



-----
JS Huang
--
View this message in context: http://r.789695.n4.nabble.com/Using-R-to-Calculate-Coefficients-of-Relatedness-and-Kinship-for-Family-Members-tp4704232p4704243.html
Sent from the R help mailing list archive at Nabble.com.


From namrathakmurthy.05 at gmail.com  Fri Mar  6 10:34:29 2015
From: namrathakmurthy.05 at gmail.com (Namratha K)
Date: Fri, 6 Mar 2015 15:04:29 +0530
Subject: [R] Requesting function for A/B testing
Message-ID: <CAAZhZma3rwont0vb6x35-KY6QSBA+XjR-fo0trFW_zb_ROkEjw@mail.gmail.com>

Dear Sir/Madam,
I am a student pursuing MCA .As i am doing an project using R language .I
want to implement A/B testing using R language.I am searching in google
from past few days and not able to implement .So i request u to kindly help
me by sending function or code on A/B testing method using R language.



talk soon


Thanking you


Regards
Namratha K

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Fri Mar  6 19:25:19 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 6 Mar 2015 13:25:19 -0500
Subject: [R]  vignette advice
Message-ID: <CACxE24ntb10=RKKAM0vqy6FFJ6fhUxyaXB_3tK-Fg2N96oAuhQ@mail.gmail.com>

Hello!

I've built several packages before, but am now building a new package and
would like to have a vignette to go with it.  I will be using knitr for it.

My question, please:  could someone recommend a good reference on the
content-type material itself for the vignette, please?

Thanks,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From tom at maladmin.com  Fri Mar  6 21:48:27 2015
From: tom at maladmin.com (Tom Wright)
Date: Fri, 06 Mar 2015 15:48:27 -0500
Subject: [R] problem with function that adds rows to dataframe based on
 conditional statement
In-Reply-To: <CAJmwvUadtpFODfCV3Qh+xHuiGvLH0DUSvehuMb_S-_dF6Rck5g@mail.gmail.com>
References: <CAJmwvUadtpFODfCV3Qh+xHuiGvLH0DUSvehuMb_S-_dF6Rck5g@mail.gmail.com>
Message-ID: <1425674907.11962.13.camel@maladmin.com>

If all you want is to add a row of na's could you just do something
like:

nExpectedRows<-length(unique(animals)) * length(unique(animalYears)) * 2

newDf<-data.frame(animals=rep(NA,nExpectedRows-nrow(comAn)),
		  animalYears=rep(NA,nExpectedRows-nrow(comAn)),
		  animalMass=rep(NA,nExpectedRows-nrow(comAn)))

comAn = rbind(comAn,newDf)



On Thu, 2015-03-05 at 13:41 -0700, Curtis Burkhalter wrote:
> Hello everyone,
> 
> I'm having a problem with a function that I wrote that is supposed to add a
> row to dataframe based upon a conditional statement. To explain I've used
> an example below:
> 
> #create data frame
> animals=c("bird","dog","cat")
> animals=rep(animals,each=4)
> animals=animals[1:11]
> animalYears=c(1,1,2,2,1,1,2,2,1,1,2)
> animalMass=round(runif(11,min=10,max=50),0)
> 
> comAn=as.data.frame(cbind(animals,animalYears,animalMass))
> comAn
> 
>   * animals* *animalYears* *animalMass*
> 1     bird           1         30
> 2     bird           1         32
> 3     bird           2         27
> 4     bird           2         16
> 5      dog           1         22
> 6      dog           1         25
> 7      dog           2         41
> 8      dog           2         22
> 9      cat           1         30
> 10     cat           1         37
> 11     cat           2         49
> 
> We can see here that for every type of animal I have two years of mass
> measurements, except for the cat in year 2. What I want to do is add an
> additional row to the end of the dataframe that consists strictly of NAs
> and then I can substitute those out later.
> 
> So what I first did was split the 'comAn' dataframe into the different
> Animal by Year combos.
> 
> #This line splits 'com_An' into a list ordered by the Animal by Year combos
> comAn_split=split(comAn, paste(comAn$animals,comAn$animalYear))
> 
> Then I wrote the function that identifies whether a particular Animal by
> Year combo is less than two rows in length and if so it should add another
> row that consists only of NAs using the vector 'NAs':
> 
> #This function identifies the length of each Animal by Year combo and then
> #uses the rbind function built in R to add a row
> #to each animal by year combo if they have less than 2 samples
> 
> addNA <- function(comAn) {
>   NAs=c(NA,NA,NA)
>         ind <- seq_len(nrow(comAn))
>         comAn[ifelse(length(ind)<2,rbind(NAs),length(ind)),]
> }
> 
> #This applies the function addNs to the animals data organized in list
> format
> addedNAcomAn <- do.call(rbind, lapply(comAn_split, addNA))
> addedNAcomAn
> 
> When I apply the function to the list of the different Animal by Year
> combos this is what I get:
>        animals animalYears animalMass
> bird 1    bird           1         23
> bird 2    bird           2         50
> cat 1      cat           1         15
> cat 2     <NA>        <NA>       <NA>
> dog 1      dog           1         23
> dog 2      dog           2         38
> 
> What I expect is this:
> 
>    animals animalYears animalMass
> 1     bird           1         41
> 2     bird           1         23
> 3     bird           2         23
> 4     bird           2         50
> 5      dog           1         49
> 6      dog           1         23
> 7      dog           2         13
> 8      dog           2         38
> 9      cat           1         42
> 10     cat           1         15
> 11     cat           2         33
> 12     NA           NA      NA
> 
> Am I conditioning improperly within the function or am I missing something
> else. Any help would be greatly appreciated.
> 
> Best
>


From murdoch.duncan at gmail.com  Fri Mar  6 21:50:20 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 6 Mar 2015 15:50:20 -0500
Subject: [R] vignette advice
In-Reply-To: <CACxE24ntb10=RKKAM0vqy6FFJ6fhUxyaXB_3tK-Fg2N96oAuhQ@mail.gmail.com>
References: <CACxE24ntb10=RKKAM0vqy6FFJ6fhUxyaXB_3tK-Fg2N96oAuhQ@mail.gmail.com>
Message-ID: <54FA130C.2010006@gmail.com>

On 06/03/2015 1:25 PM, Erin Hodgess wrote:
> Hello!
> 
> I've built several packages before, but am now building a new package and
> would like to have a vignette to go with it.  I will be using knitr for it.
> 
> My question, please:  could someone recommend a good reference on the
> content-type material itself for the vignette, please?

I don't know a reference to recommend, but when I am trying out a new
package, the first thing I look for is a vignette to give a package
overview.  It should say what the package is for, and demonstrate (at
least) the major functions.  If I don't find a vignette, I deduct 5
points ;-).

After the package overview, you might also have vignettes that discuss
particular technical issues.

If you have published a paper about your package in the R Journal or
JSS, including a copy as a vignette is a reasonable thing to do.  (Of
course, as the package evolves, the paper might become obsolete; then
you have a problem:  update it, or just declare it of historical interest?)

Duncan Murdoch


From erinm.hodgess at gmail.com  Fri Mar  6 21:57:12 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 6 Mar 2015 15:57:12 -0500
Subject: [R] vignette advice
In-Reply-To: <54FA130C.2010006@gmail.com>
References: <CACxE24ntb10=RKKAM0vqy6FFJ6fhUxyaXB_3tK-Fg2N96oAuhQ@mail.gmail.com>
	<54FA130C.2010006@gmail.com>
Message-ID: <CACxE24mkJY78KexVHNxikY5RyA+3PmFQ8ae8wKsnoNmsA_Ancw@mail.gmail.com>

This is exactly what I was looking for.  Thanks so much!

Sincerely,
Erin


On Fri, Mar 6, 2015 at 3:50 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 06/03/2015 1:25 PM, Erin Hodgess wrote:
> > Hello!
> >
> > I've built several packages before, but am now building a new package and
> > would like to have a vignette to go with it.  I will be using knitr for
> it.
> >
> > My question, please:  could someone recommend a good reference on the
> > content-type material itself for the vignette, please?
>
> I don't know a reference to recommend, but when I am trying out a new
> package, the first thing I look for is a vignette to give a package
> overview.  It should say what the package is for, and demonstrate (at
> least) the major functions.  If I don't find a vignette, I deduct 5
> points ;-).
>
> After the package overview, you might also have vignettes that discuss
> particular technical issues.
>
> If you have published a paper about your package in the R Journal or
> JSS, including a copy as a vignette is a reasonable thing to do.  (Of
> course, as the package evolves, the paper might become obsolete; then
> you have a problem:  update it, or just declare it of historical interest?)
>
> Duncan Murdoch
>
>


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From curtisburkhalter at gmail.com  Fri Mar  6 22:00:32 2015
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Fri, 6 Mar 2015 14:00:32 -0700
Subject: [R] problem with function that adds rows to dataframe based on
 conditional statement
In-Reply-To: <1425674907.11962.13.camel@maladmin.com>
References: <CAJmwvUadtpFODfCV3Qh+xHuiGvLH0DUSvehuMb_S-_dF6Rck5g@mail.gmail.com>
	<1425674907.11962.13.camel@maladmin.com>
Message-ID: <CAJmwvUYRn4F8vmddAEReK+Fx-O-qfbuzKNNNw_b77zTApDsmHw@mail.gmail.com>

Hey Tom,

This solution works great, but if I try to then insert it in my function
that I've displayed above and apply it to my split dataframe I get the
error message:

Error in `[.default`(xj, i) : invalid subscript type 'list'

The reason why I need to try and get this to work within the function is
that I'm trying to apply it to a much larger dataframe
(nrow=12000,ncol=14). The actual data I'm working with consists of a
sampling year, a site, and a bunch of response variables. For each sampling
year by site combination I have 3 within year sampling occasions. For the
sampling year by site combinations that don't have 3 sampling events I need
to fill in the missing occasions with the NAs.

Can you see why I might be getting this error message?

Thanks



On Fri, Mar 6, 2015 at 1:48 PM, Tom Wright <tom at maladmin.com> wrote:

> If all you want is to add a row of na's could you just do something
> like:
>
> nExpectedRows<-length(unique(animals)) * length(unique(animalYears)) * 2
>
> newDf<-data.frame(animals=rep(NA,nExpectedRows-nrow(comAn)),
>                   animalYears=rep(NA,nExpectedRows-nrow(comAn)),
>                   animalMass=rep(NA,nExpectedRows-nrow(comAn)))
>
> comAn = rbind(comAn,newDf)
>
>
>
> On Thu, 2015-03-05 at 13:41 -0700, Curtis Burkhalter wrote:
> > Hello everyone,
> >
> > I'm having a problem with a function that I wrote that is supposed to
> add a
> > row to dataframe based upon a conditional statement. To explain I've used
> > an example below:
> >
> > #create data frame
> > animals=c("bird","dog","cat")
> > animals=rep(animals,each=4)
> > animals=animals[1:11]
> > animalYears=c(1,1,2,2,1,1,2,2,1,1,2)
> > animalMass=round(runif(11,min=10,max=50),0)
> >
> > comAn=as.data.frame(cbind(animals,animalYears,animalMass))
> > comAn
> >
> >   * animals* *animalYears* *animalMass*
> > 1     bird           1         30
> > 2     bird           1         32
> > 3     bird           2         27
> > 4     bird           2         16
> > 5      dog           1         22
> > 6      dog           1         25
> > 7      dog           2         41
> > 8      dog           2         22
> > 9      cat           1         30
> > 10     cat           1         37
> > 11     cat           2         49
> >
> > We can see here that for every type of animal I have two years of mass
> > measurements, except for the cat in year 2. What I want to do is add an
> > additional row to the end of the dataframe that consists strictly of NAs
> > and then I can substitute those out later.
> >
> > So what I first did was split the 'comAn' dataframe into the different
> > Animal by Year combos.
> >
> > #This line splits 'com_An' into a list ordered by the Animal by Year
> combos
> > comAn_split=split(comAn, paste(comAn$animals,comAn$animalYear))
> >
> > Then I wrote the function that identifies whether a particular Animal by
> > Year combo is less than two rows in length and if so it should add
> another
> > row that consists only of NAs using the vector 'NAs':
> >
> > #This function identifies the length of each Animal by Year combo and
> then
> > #uses the rbind function built in R to add a row
> > #to each animal by year combo if they have less than 2 samples
> >
> > addNA <- function(comAn) {
> >   NAs=c(NA,NA,NA)
> >         ind <- seq_len(nrow(comAn))
> >         comAn[ifelse(length(ind)<2,rbind(NAs),length(ind)),]
> > }
> >
> > #This applies the function addNs to the animals data organized in list
> > format
> > addedNAcomAn <- do.call(rbind, lapply(comAn_split, addNA))
> > addedNAcomAn
> >
> > When I apply the function to the list of the different Animal by Year
> > combos this is what I get:
> >        animals animalYears animalMass
> > bird 1    bird           1         23
> > bird 2    bird           2         50
> > cat 1      cat           1         15
> > cat 2     <NA>        <NA>       <NA>
> > dog 1      dog           1         23
> > dog 2      dog           2         38
> >
> > What I expect is this:
> >
> >    animals animalYears animalMass
> > 1     bird           1         41
> > 2     bird           1         23
> > 3     bird           2         23
> > 4     bird           2         50
> > 5      dog           1         49
> > 6      dog           1         23
> > 7      dog           2         13
> > 8      dog           2         38
> > 9      cat           1         42
> > 10     cat           1         15
> > 11     cat           2         33
> > 12     NA           NA      NA
> >
> > Am I conditioning improperly within the function or am I missing
> something
> > else. Any help would be greatly appreciated.
> >
> > Best
> >
>
>
>


-- 
Curtis Burkhalter

https://sites.google.com/site/curtisburkhalter/

	[[alternative HTML version deleted]]


From cryan at binghamton.edu  Fri Mar  6 22:03:48 2015
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Fri, 06 Mar 2015 16:03:48 -0500
Subject: [R] plotting the one-dimensional density of events in time
Message-ID: <54FA1634.3030804@binghamton.edu>

I have the dates of occurence of a repetitive event. I would like to
plot the density of these events, as well as their specific temporal
location.  This is as far as I have gotten:

# generate some sample data: dates in 2014
random.dates <- sample(1:31, 100, replace=TRUE)
random.months <- sample(1:12, 100, replace=TRUE)
dd <- as.Date(as.character((paste(random.dates, random.months, "2014",
sep="-"))), format="%d-%m-%Y")
dd <- dd[!is.na(dd)]

# plot density with a "rug".
density(as.numeric(dd))
plot(density(as.numeric(dd)))
rug(as.numeric(dd))

# But horizontal axis label is not very informative
# would prefer labeling the start of each month
plot(density(as.numeric(dd)), axes=FALSE)
library(zoo)
new.axis <- as.yearmon(dd)

# but then what? This is where I get stuck--adding back a sensible axis

Grateful for any guidance.

Thanks.

--Chris
-- 
Christopher W. Ryan, MD, MS
cryanatbinghamtondotedu

Early success is a terrible teacher. You?re essentially being rewarded
for a lack of preparation, so when you find yourself in a situation
where you must prepare, you can?t do it. You don?t know how.
--Chris Hadfield, An Astronaut's Guide to Life on Earth


---


From r.turner at auckland.ac.nz  Fri Mar  6 22:22:56 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 07 Mar 2015 10:22:56 +1300
Subject: [R] Requesting function for A/B testing
In-Reply-To: <CAAZhZma3rwont0vb6x35-KY6QSBA+XjR-fo0trFW_zb_ROkEjw@mail.gmail.com>
References: <CAAZhZma3rwont0vb6x35-KY6QSBA+XjR-fo0trFW_zb_ROkEjw@mail.gmail.com>
Message-ID: <54FA1AB0.2030009@auckland.ac.nz>


On 06/03/15 22:34, Namratha K wrote:

> Dear Sir/Madam,
> I am a student pursuing MCA .As i am doing an project using R language .I
> want to implement A/B testing using R language.I am searching in google
> from past few days and not able to implement .So i request u to kindly help
> me by sending function or code on A/B testing method using R language.
>
>
>
> talk soon

Huh?  Or, to put it another way, WTF?

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From tom at maladmin.com  Fri Mar  6 22:48:58 2015
From: tom at maladmin.com (Tom Wright)
Date: Fri, 06 Mar 2015 16:48:58 -0500
Subject: [R] plotting the one-dimensional density of events in time
In-Reply-To: <54FA1634.3030804@binghamton.edu>
References: <54FA1634.3030804@binghamton.edu>
Message-ID: <1425678538.11962.30.camel@maladmin.com>

plot(density(as.numeric(dd)), 
	axes=FALSE, 
	xlim=c(as.numeric(as.Date("2014-01-01")),
	as.numeric(as.Date("2014-12-30")))
rug(as.numeric(dd))
axis(side=1,
    at=seq(from=as.numeric(as.Date('2014-01-01')),
           to=as.numeric(as.Date('2014-12-1')),length.out=12),
    labels=month.abb,
    las=2)




On Fri, 2015-03-06 at 16:03 -0500, Christopher W. Ryan wrote:
> I have the dates of occurence of a repetitive event. I would like to
> plot the density of these events, as well as their specific temporal
> location.  This is as far as I have gotten:
> 
> # generate some sample data: dates in 2014
> random.dates <- sample(1:31, 100, replace=TRUE)
> random.months <- sample(1:12, 100, replace=TRUE)
> dd <- as.Date(as.character((paste(random.dates, random.months, "2014",
> sep="-"))), format="%d-%m-%Y")
> dd <- dd[!is.na(dd)]
> 
> # plot density with a "rug".
> density(as.numeric(dd))
> plot(density(as.numeric(dd)))
> rug(as.numeric(dd))
> 
> # But horizontal axis label is not very informative
> # would prefer labeling the start of each month

> library(zoo)
> new.axis <- as.yearmon(dd)
> 
> # but then what? This is where I get stuck--adding back a sensible axis
> 
> Grateful for any guidance.
> 
> Thanks.
> 
> --Chris


From tom at maladmin.com  Fri Mar  6 22:50:47 2015
From: tom at maladmin.com (Tom Wright)
Date: Fri, 06 Mar 2015 16:50:47 -0500
Subject: [R] Requesting function for A/B testing
In-Reply-To: <CAAZhZma3rwont0vb6x35-KY6QSBA+XjR-fo0trFW_zb_ROkEjw@mail.gmail.com>
References: <CAAZhZma3rwont0vb6x35-KY6QSBA+XjR-fo0trFW_zb_ROkEjw@mail.gmail.com>
Message-ID: <1425678647.11962.31.camel@maladmin.com>

I can answer this:

sample(c(0,1),1)

On Fri, 2015-03-06 at 15:04 +0530, Namratha K wrote:
> Dear Sir/Madam,
> I am a student pursuing MCA .As i am doing an project using R language .I
> want to implement A/B testing using R language.I am searching in google
> from past few days and not able to implement .So i request u to kindly help
> me by sending function or code on A/B testing method using R language.
> 
> 
> 
> talk soon
> 
> 
> Thanking you
> 
> 
> Regards
> Namratha K
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Mar  6 23:29:37 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 6 Mar 2015 14:29:37 -0800
Subject: [R] plotting the one-dimensional density of events in time
In-Reply-To: <54FA1634.3030804@binghamton.edu>
References: <54FA1634.3030804@binghamton.edu>
Message-ID: <CAF8bMcb0Oymoe6fqBHK8zwfAhaXQ8BUpV2vOYahRmZjDEM2ZMA@mail.gmail.com>

You could change the x component of density's output back into a Date object
and let plot choose a Date axis in its usual way.  E.g.,
  > den <- density(as.numeric(dd))
  > den$x <- as.Date(den$x, origin=as.Date("1970-01-01"))
  > plot(den$x, den$y)
(You probably will also want to normalize the y component to be on a
specific
per time unit, say day or year, basis.)



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Mar 6, 2015 at 1:03 PM, Christopher W. Ryan <cryan at binghamton.edu>
wrote:

> I have the dates of occurence of a repetitive event. I would like to
> plot the density of these events, as well as their specific temporal
> location.  This is as far as I have gotten:
>
> # generate some sample data: dates in 2014
> random.dates <- sample(1:31, 100, replace=TRUE)
> random.months <- sample(1:12, 100, replace=TRUE)
> dd <- as.Date(as.character((paste(random.dates, random.months, "2014",
> sep="-"))), format="%d-%m-%Y")
> dd <- dd[!is.na(dd)]
>
> # plot density with a "rug".
> density(as.numeric(dd))
> plot(density(as.numeric(dd)))
> rug(as.numeric(dd))
>
> # But horizontal axis label is not very informative
> # would prefer labeling the start of each month
> plot(density(as.numeric(dd)), axes=FALSE)
> library(zoo)
> new.axis <- as.yearmon(dd)
>
> # but then what? This is where I get stuck--adding back a sensible axis
>
> Grateful for any guidance.
>
> Thanks.
>
> --Chris
> --
> Christopher W. Ryan, MD, MS
> cryanatbinghamtondotedu
>
> Early success is a terrible teacher. You?re essentially being rewarded
> for a lack of preparation, so when you find yourself in a situation
> where you must prepare, you can?t do it. You don?t know how.
> --Chris Hadfield, An Astronaut's Guide to Life on Earth
>
>
> ---
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ccberry at ucsd.edu  Sat Mar  7 04:35:52 2015
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Fri, 6 Mar 2015 19:35:52 -0800
Subject: [R] Requesting function for A/B testing
In-Reply-To: <54FA1AB0.2030009@auckland.ac.nz>
References: <CAAZhZma3rwont0vb6x35-KY6QSBA+XjR-fo0trFW_zb_ROkEjw@mail.gmail.com>
	<54FA1AB0.2030009@auckland.ac.nz>
Message-ID: <alpine.OSX.2.00.1503061907480.1278@charles-berrys-macbook.local>

On Sat, 7 Mar 2015, Rolf Turner wrote:

>
> On 06/03/15 22:34, Namratha K wrote:
>
>> Dear Sir/Madam,
>> I am a student pursuing MCA .As i am doing an project using R language .I
>> want to implement A/B testing using R language.I am searching in google
>> from past few days and not able to implement .So i request u to kindly help
>> me by sending function or code on A/B testing method using R language.
>> 
>> 
>> 
>> talk soon
>
> Huh?  Or, to put it another way, WTF?

Rolf,

Old wine, new bottle.

According to http://en.wikipedia.org/wiki/A/B_testing,

"A/B testing has been marketed by some as a change in philosophy and
  business strategy in certain niches, though the approach is identical to
  a between-subjects design, which is commonly used in a variety of
  research traditions[refs]"

A friend who is a management consultant tells me that the core ideas in 
his discipline never change, but every five years or so a new set of 
buzzwords is introduced to describe them. It makes it seem like "a change 
in philosophy and business strategy" has occurred. And of course the 
clients will need to hire consultants who know those buzzwords to stay 
current. And the consultants will need to sign up for continuing education 
courses to learn those buzzwords.

===

Namratha,

Read R-intro. Either from your R installation or at

http://cran.r-project.org/doc/manuals/r-release/R-intro.html

Then start R and enter

 	ls("package:stats",pat="test")

at the prompt and push "ENTER". Browse the help pages for the functions 
listed. Run the examples.

That should get you started.

Chuck


From antonmorkovin at gmail.com  Sat Mar  7 09:14:28 2015
From: antonmorkovin at gmail.com (Anton Morkovin)
Date: Sat, 07 Mar 2015 11:14:28 +0300
Subject: [R] Special case of data classification
Message-ID: <4539761425716068@web7o.yandex.ru>

I have a matrix with dissimilarity coefficients for bird community composition in different monthes. I need to divide this variants of bird communities in several classes ("seasonal aspects"). Each class must include variants maximally similar with each other and maximally dissimilar with other classes. The most important thing is that each class must include only cosecutive monthes. Is there any special classification algorithm in R with such possibility?



--?
Best regards,
Anton Morkovin


From gunter.berton at gene.com  Sat Mar  7 16:39:16 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 7 Mar 2015 07:39:16 -0800
Subject: [R] Special case of data classification
In-Reply-To: <4539761425716068@web7o.yandex.ru>
References: <4539761425716068@web7o.yandex.ru>
Message-ID: <CACk-te1RFTG-+hCr=ngYXQWdxhjdXFGs9esyiHjtBHeLokNmqg@mail.gmail.com>

Have you done any homework for yourself? CRAN task views would be an
obvious first place to look:

http://cran.r-project.org/web/views/

Both the environmental and spatio-temporal views seem like possibilities.

If that doesn't suit, try searching on suitable keywords

Cheers,
Bert


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Mar 7, 2015 at 12:14 AM, Anton Morkovin <antonmorkovin at gmail.com> wrote:
> I have a matrix with dissimilarity coefficients for bird community composition in different monthes. I need to divide this variants of bird communities in several classes ("seasonal aspects"). Each class must include variants maximally similar with each other and maximally dissimilar with other classes. The most important thing is that each class must include only cosecutive monthes. Is there any special classification algorithm in R with such possibility?
>
>
>
> --
> Best regards,
> Anton Morkovin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ackovacs at millersville.edu  Sat Mar  7 15:29:34 2015
From: ackovacs at millersville.edu (annclaire)
Date: Sat, 7 Mar 2015 06:29:34 -0800 (PST)
Subject: [R] Confidence Intervals for survreg (survival)
In-Reply-To: <DUB116-W1227494124C0CA456EE1B9BBF4C0@phx.gbl>
References: <DUB116-W232EF794435F4BE392B4C7BF430@phx.gbl>
	<FF7FBE9D-E9B7-4C3E-9677-C09DF92867D2@comcast.net>
	<DUB116-W1227494124C0CA456EE1B9BBF4C0@phx.gbl>
Message-ID: <1425738574138-4704283.post@n4.nabble.com>

Hello!
I am trying to fit confidence intervals for my server object as well, but I
can only get an interval estimation for the intercept coefficient and am
getting NAs for my scale parameter.  Did you also have this issue?  
Below is a rough outline of my code

>newsurvobj <-Surv(studytimenew, censors)
> newserv <- survfit(newsurvobj~1, type="kaplan-meier")
> survreg(formula=newsurvobj~1, dist="weibull")
Call:
survreg(formula = newsurvobj ~ 1, dist = "weibull")

Coefficients:
(Intercept) 
   2.726151 

Scale= 0.4861742 

Loglik(model)= -160.8   Loglik(intercept only)= -160.8
n= 100 
> ??confint
> survival <- survreg(formula=newsurvobj~1, dist="weibull")
> confint(survival, level=.95)
               2.5 %   97.5 %
(Intercept) 2.540459 2.911843
confint(survival, "coefficients$scale",level=.95)
                   2.5 % 97.5 %
coefficients$scale    NA     NA

Thank you so much for any help you can offer!
-Ann



--
View this message in context: http://r.789695.n4.nabble.com/Confidence-Intervals-for-survreg-survival-tp4674137p4704283.html
Sent from the R help mailing list archive at Nabble.com.


From bluebarbarossa at hotmail.com  Sat Mar  7 17:05:43 2015
From: bluebarbarossa at hotmail.com (White Sky)
Date: Sat, 7 Mar 2015 16:05:43 +0000
Subject: [R] t-test: many changing groups.
Message-ID: <DUB122-W319E56EAC4B4CA67C1BA28DF1D0@phx.gbl>

I'd like to perform a t-test between groups 'A' and 'B'. The difficulty is that although there is only one response variable, there are many observations, and the grouping (A or B) differs with each observation. My code for generating the input data is shown below.
I'd like to know how to approach doing the test, ideally so that the t-test results for each observation are presented in a table. I'm not sure where to start as other searches have been futile... something along the lines of t.test(ind_vars ~ resp_vars) , maybe using rapply, and separating groups by A and B each time...
# Matrix for response variableN_samples <- 20resp_vars <- matrix(runif(n=N_samples, min=0, max=1))sample_names <- paste0("sample_", 1:N_samples )rownames(x=resp_vars) <- sample_namescolnames(x=resp_vars) <- "resp"resp_vars [1:5,]
# Matrix for independent variablesN_observations <- 100ind_vars <- matrix(NA, N_observations, N_samples)ind_vars <- apply(ind_vars, c(1,2), function(x) sample(c("A", "B"),1))ind_var_names <- paste0("obs_", 1:N_observations)rownames(x=ind_vars) <- ind_var_namescolnames(x=ind_vars) <- sample_namesind_vars[1:3,1:5]  		 	   		  
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Mar  7 19:55:24 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 7 Mar 2015 10:55:24 -0800
Subject: [R] Confidence Intervals for survreg (survival)
In-Reply-To: <1425738574138-4704283.post@n4.nabble.com>
References: <DUB116-W232EF794435F4BE392B4C7BF430@phx.gbl>
	<FF7FBE9D-E9B7-4C3E-9677-C09DF92867D2@comcast.net>
	<DUB116-W1227494124C0CA456EE1B9BBF4C0@phx.gbl>
	<1425738574138-4704283.post@n4.nabble.com>
Message-ID: <817EB668-F831-4378-B6A1-00DEE6602B06@comcast.net>


On Mar 7, 2015, at 6:29 AM, annclaire wrote:

> Hello!
> I am trying to fit confidence intervals for my server object as well, but I
> can only get an interval estimation for the intercept coefficient and am
> getting NAs for my scale parameter.  Did you also have this issue?  
> Below is a rough outline of my code

> 
>> newsurvobj <-Surv(studytimenew, censors)
>> newserv <- survfit(newsurvobj~1, type="kaplan-meier")
>> survreg(formula=newsurvobj~1, dist="weibull")
> Call:
> survreg(formula = newsurvobj ~ 1, dist = "weibull")
> 
> Coefficients:
> (Intercept) 
>   2.726151 
> 
> Scale= 0.4861742 
> 
> Loglik(model)= -160.8   Loglik(intercept only)= -160.8
> n= 100 

I'm puzzled. First you tell `survreg` that you want a model with only an intercept term and then complain about it. Then you get a confidence interval for that parameter from `confint` and then you complain about getting NA's when you give `confint` an object that doesn't match the specifications for it in the help page. 


>> ??confint
>> survival <- survreg(formula=newsurvobj~1, dist="weibull")
>> confint(survival, level=.95)
>               2.5 %   97.5 %
> (Intercept) 2.540459 2.911843
> confint(survival, "coefficients$scale",level=.95)
>                   2.5 % 97.5 %
> coefficients$scale    NA     NA



The second parameter to `confint` is supposed to be either a term name or a number. In your case the only available name (for a model term) would be `(Intercept)`. If you want the estimated scale, you would use `summary`. Read the ?summary.survreg page. The var (vcov object) includes the log(scale) parameter.


> 
> Thank you so much for any help you can offer!
> -Ann
> 

Uncommenting the Nabble link:
View this message in context: http://r.789695.n4.nabble.com/Confidence-Intervals-for-survreg-survival-tp4674137p4704283.html
Sent from the R help mailing list archive at Nabble.com.

I did go there thinking I might learn something about this question and found out that it was in followup to one of mine from two years ago. You should include context for your questions and understand that Nabble is neither the Rhelp mailing list nor does it function as its Archive. And it removes these important lines which I am now attempting to put before you (again)

https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 
David Winsemius
Alameda, CA, USA


From adel.daoud at socav.gu.se  Sat Mar  7 18:39:40 2015
From: adel.daoud at socav.gu.se (Adel)
Date: Sat, 7 Mar 2015 09:39:40 -0800 (PST)
Subject: [R] Alpha not working in geom_rect
Message-ID: <1425749980919-4704291.post@n4.nabble.com>

Hi 
I am trying to activate the alpha argument to work, but for some reason it
does not to play with me. Anybody has an idea why?


p <- ggplot(data = prediction_df, aes(x=x, y=prediction, fill=threshold)) +
geom_area(colour="black", size=.2, alpha=.4) +
scale_fill_brewer(palette="Set1",
breaks=rev(levels(prediction_df$threshold)))
p + geom_rect(aes(xmin=2, xmax=10, ymin=(0), ymax=(1)), fill="black",
alpha=0.5)


prediction_df
     x prediction  threshold
1  -10  0.5694161       noAF
2   -9  0.5700513       noAF
3   -8  0.5706863       noAF
4   -7  0.5713211       noAF
5   -6  0.5719556       noAF
6   -5  0.5725899       noAF
7   -4  0.5732240       noAF
8   -3  0.5738578       noAF
9   -2  0.5744914       noAF
10  -1  0.5751247       noAF
11   0  0.5757578       noAF
12   1  0.5763906       noAF
13   2  0.5770232       noAF
14   3  0.5776556       noAF
15   4  0.5782876       noAF
16   5  0.5789195       noAF
17   6  0.5795510       noAF
18   7  0.5801823       noAF
19   8  0.5808134       noAF
20   9  0.5814441       noAF
21  10  0.5820747       noAF
22 -10  0.2359140   singleAF
23  -9  0.2356847   singleAF
24  -8  0.2354550   singleAF
25  -7  0.2352249   singleAF
26  -6  0.2349943   singleAF
27  -5  0.2347634   singleAF
28  -4  0.2345321   singleAF
29  -3  0.2343003   singleAF
30  -2  0.2340682   singleAF
31  -1  0.2338356   singleAF
32   0  0.2336027   singleAF
33   1  0.2333694   singleAF
34   2  0.2331357   singleAF
35   3  0.2329016   singleAF
36   4  0.2326671   singleAF
37   5  0.2324322   singleAF
38   6  0.2321969   singleAF
39   7  0.2319613   singleAF
40   8  0.2317253   singleAF
41   9  0.2314889   singleAF
42  10  0.2312522   singleAF
43 -10  0.1946699 multipleAF
44  -9  0.1942640 multipleAF
45  -8  0.1938587 multipleAF
46  -7  0.1934540 multipleAF
47  -6  0.1930500 multipleAF
48  -5  0.1926467 multipleAF
49  -4  0.1922440 multipleAF
50  -3  0.1918419 multipleAF
51  -2  0.1914404 multipleAF
52  -1  0.1910397 multipleAF
53   0  0.1906395 multipleAF
54   1  0.1902400 multipleAF
55   2  0.1898411 multipleAF
56   3  0.1894429 multipleAF
57   4  0.1890453 multipleAF
58   5  0.1886483 multipleAF
59   6  0.1882520 multipleAF
60   7  0.1878564 multipleAF
61   8  0.1874613 multipleAF
62   9  0.1870669 multipleAF
63  10  0.1866732 multipleAF





--
View this message in context: http://r.789695.n4.nabble.com/Alpha-not-working-in-geom-rect-tp4704291.html
Sent from the R help mailing list archive at Nabble.com.


From mashranga at yahoo.com  Sat Mar  7 23:01:57 2015
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Sat, 7 Mar 2015 22:01:57 +0000 (UTC)
Subject: [R] Merge List element by name
Message-ID: <290517811.452952.1425765717486.JavaMail.yahoo@mail.yahoo.com>

Hi,?I have a list like below :?
> gg
[[1]]? ? ? ?assembly1 GCA_000257985
[[2]]? ? ? ?assembly1 GCA_000017125
[[3]]? ? ? ?assembly1 GCA_000016805
[[4]]? ? ? ?assembly1 GCA_000144955
[[5]]? ? ? ?assembly ? ? ? ? ? ? ? ? ? ?isolation.source1 GCA_000507725 ? ? ? ? ?missing
[[6]]? ? ? ?assembly ????????????????????isolation.source1 GCA_000507705 ? ? ? ? ? missing
[[7]]? ? ? ?assembly1 GCA_000237265
[[8]]? ? ? ?assembly ????????????location ? ????date ? ? ? ? host ? ? ? ? ? ? ? ? ? ? isolation.source1 GCA_000237125 ? Taiwan ????????Jul-02 ????Homo sapiens ? ? pus/wound##############################################################now i want merge the list element and want output as below as data frame
Expected output :?
assembly ? ? ? ? ? ? ? ? ?location ?date ? ????host ? ? ? ? ? ? ? ? ? ? ? isolation.sourceGCA_000257985 ? ?NA ? ? ? ? ?NA ? ?????NA ? ? ? ?????????????????NA
GCA_000017125 ? ?NA ? ? ? ? ?NA ? ?????NA ? ? ? ?????????????????NA
GCA_000016805 ? ?NA ? ? ? ? ?NA ? ?????NA ? ? ? ?????????????????NA
GCA_000144955 ? ?NA ? ? ? ? ?NA ? ?????NA ? ? ? ?????????????????NA
GCA_000507725 ? ?NA ? ? ? ? ?NA ? ?????NA ? ? ? ?????????????????missing
GCA_000507705????NA ? ? ? ? ?NA ? ?????NA ? ? ? ?????????????????missingGCA_000237265 ? ?NA ? ? ? ? ?NA ? ?????NA ? ? ? ?????????????????NA ? ?
GCA_000237125 ? ?Taiwan ? ?Jul-02 ? ?Homo sapiens ? ? ?pus/wound
Any help will be very much appreciated .?Thanks?
Best regards

...........................?Tanvir AhamedG?teborg, Sweden
	[[alternative HTML version deleted]]


From tommesmcpommes at gmx.net  Sat Mar  7 23:52:51 2015
From: tommesmcpommes at gmx.net (TeeJay)
Date: Sat, 7 Mar 2015 14:52:51 -0800 (PST)
Subject: [R] How to see a R function's code
In-Reply-To: <4F385E01.7050907@gmail.com>
References: <CABc7NqGumRHVg+8eaKtiEX8CbvQyxELUL5xpvHHaoE9DseEGsA@mail.gmail.com>
	<4F385E01.7050907@gmail.com>
Message-ID: <1425768771544-4704296.post@n4.nabble.com>

Hi there,

I know this is quite an old post but I am wondering if the answer still
applies!?

I would like to access the boxplot function. So, I tried to follow the
instruction of Uwe Ligges?s article  ?Accessing the Sources?
<http://cran.r-project.org/doc/Rnews/Rnews_2006-4.pdf>  . However, in
?$RHOME/src/library/? there is no graphics folder! At this location I only
have a ?windlgs? folder. I have a graphics folder in ?$RHOME/library/?
though. But I am not able to find a ?plot.R? in any of the subfolders as
mentioned in Uwe?s article.

Furthermore, if I debug into the boxplot function in RStudio, I get a
warning stating ?Debug location is approximate because the source is not
available?.

I already tried to reinstall R but that also did not add the ?graphics?
folder to the ?src? folder. Any ideas are appreciated a lot!




--
View this message in context: http://r.789695.n4.nabble.com/How-to-see-a-R-function-s-code-tp4380111p4704296.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Sun Mar  8 02:45:28 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 07 Mar 2015 17:45:28 -0800
Subject: [R] How to see a R function's code
In-Reply-To: <1425768771544-4704296.post@n4.nabble.com>
References: <CABc7NqGumRHVg+8eaKtiEX8CbvQyxELUL5xpvHHaoE9DseEGsA@mail.gmail.com>
	<4F385E01.7050907@gmail.com>
	<1425768771544-4704296.post@n4.nabble.com>
Message-ID: <C8F1078A-B496-4F5C-925A-0F0B79995E70@dcn.davis.CA.us>

Most (perhaps all) packages are byte-compiled now. You can often see decompiled code by entering the name of the function without parentheses, or using the getAnywhere function. For base R functions you should probably download the R source tar file separately and unpack it to a convenient location of your choice and dig in.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 7, 2015 2:52:51 PM PST, TeeJay <tommesmcpommes at gmx.net> wrote:
>Hi there,
>
>I know this is quite an old post but I am wondering if the answer still
>applies!?
>
>I would like to access the boxplot function. So, I tried to follow the
>instruction of Uwe Ligges?s article  ?Accessing the Sources?
><http://cran.r-project.org/doc/Rnews/Rnews_2006-4.pdf>  . However, in
>?$RHOME/src/library/? there is no graphics folder! At this location I
>only
>have a ?windlgs? folder. I have a graphics folder in ?$RHOME/library/?
>though. But I am not able to find a ?plot.R? in any of the subfolders
>as
>mentioned in Uwe?s article.
>
>Furthermore, if I debug into the boxplot function in RStudio, I get a
>warning stating ?Debug location is approximate because the source is
>not
>available?.
>
>I already tried to reinstall R but that also did not add the ?graphics?
>folder to the ?src? folder. Any ideas are appreciated a lot!
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/How-to-see-a-R-function-s-code-tp4380111p4704296.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Mar  8 02:51:35 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 07 Mar 2015 17:51:35 -0800
Subject: [R] Merge List element by name
In-Reply-To: <290517811.452952.1425765717486.JavaMail.yahoo@mail.yahoo.com>
References: <290517811.452952.1425765717486.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <B7499766-566B-48F2-8CB5-8E07282D9E5F@dcn.davis.CA.us>

This would be a perfect time for you to use best practices to convey what you have to us [1]... most specifically, posting using plain text will keep your code from getting munged up, and using dput to provide an unambiguous form we can put into our R sessions.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 7, 2015 2:01:57 PM PST, Mohammad Tanvir Ahamed via R-help <r-help at r-project.org> wrote:
>Hi,?I have a list like below :?
>> gg
>[[1]]? ? ? ?assembly1 GCA_000257985
>[[2]]? ? ? ?assembly1 GCA_000017125
>[[3]]? ? ? ?assembly1 GCA_000016805
>[[4]]? ? ? ?assembly1 GCA_000144955
>[[5]]? ? ? ?assembly ? ? ? ? ? ? ? ? ? ?isolation.source1 GCA_000507725
>? ? ? ? ?missing
>[[6]]? ? ? ?assembly ????????????????????isolation.source1
>GCA_000507705 ? ? ? ? ? missing
>[[7]]? ? ? ?assembly1 GCA_000237265
>[[8]]? ? ? ?assembly ????????????location ? ????date ? ? ? ? host ? ? ?
>? ? ? ? ? ? ? isolation.source1 GCA_000237125 ? Taiwan ????????Jul-02
>????Homo sapiens ? ?
>pus/wound##############################################################now
>i want merge the list element and want output as below as data frame
>Expected output :?
>assembly ? ? ? ? ? ? ? ? ?location ?date ? ????host ? ? ? ? ? ? ? ? ? ?
>? isolation.sourceGCA_000257985 ? ?NA ? ? ? ? ?NA ? ?????NA ? ? ?
>?????????????????NA
>GCA_000017125 ? ?NA ? ? ? ? ?NA ? ?????NA ? ? ? ?????????????????NA
>GCA_000016805 ? ?NA ? ? ? ? ?NA ? ?????NA ? ? ? ?????????????????NA
>GCA_000144955 ? ?NA ? ? ? ? ?NA ? ?????NA ? ? ? ?????????????????NA
>GCA_000507725 ? ?NA ? ? ? ? ?NA ? ?????NA ? ? ?
>?????????????????missing
>GCA_000507705????NA ? ? ? ? ?NA ? ?????NA ? ? ?
>?????????????????missingGCA_000237265 ? ?NA ? ? ? ? ?NA ? ?????NA ? ? ?
>?????????????????NA ? ?
>GCA_000237125 ? ?Taiwan ? ?Jul-02 ? ?Homo sapiens ? ? ?pus/wound
>Any help will be very much appreciated .?Thanks?
>Best regards
>
>...........................?Tanvir AhamedG?teborg, Sweden
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Mar  8 06:46:44 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 8 Mar 2015 16:46:44 +1100
Subject: [R] Alpha not working in geom_rect
In-Reply-To: <1425749980919-4704291.post@n4.nabble.com>
References: <1425749980919-4704291.post@n4.nabble.com>
Message-ID: <CA+8X3fU9mzs_JtJ9MENYQ08A-MH96soBm5ej2cEm=h9eP6pnMA@mail.gmail.com>

Hi Adel,
Almost certainly because the device you were using doesn't support
transparency.Try it with a PDF device and check the resulting file in a PDF
reader:

pdf("ad.pdf")
print(p)
dev.off()

Jim


On Sun, Mar 8, 2015 at 4:39 AM, Adel <adel.daoud at socav.gu.se> wrote:

> Hi
> I am trying to activate the alpha argument to work, but for some reason it
> does not to play with me. Anybody has an idea why?
>
>
> p <- ggplot(data = prediction_df, aes(x=x, y=prediction, fill=threshold)) +
> geom_area(colour="black", size=.2, alpha=.4) +
> scale_fill_brewer(palette="Set1",
> breaks=rev(levels(prediction_df$threshold)))
> p + geom_rect(aes(xmin=2, xmax=10, ymin=(0), ymax=(1)), fill="black",
> alpha=0.5)
>
>
> prediction_df
>      x prediction  threshold
> 1  -10  0.5694161       noAF
> 2   -9  0.5700513       noAF
> 3   -8  0.5706863       noAF
> 4   -7  0.5713211       noAF
> 5   -6  0.5719556       noAF
> 6   -5  0.5725899       noAF
> 7   -4  0.5732240       noAF
> 8   -3  0.5738578       noAF
> 9   -2  0.5744914       noAF
> 10  -1  0.5751247       noAF
> 11   0  0.5757578       noAF
> 12   1  0.5763906       noAF
> 13   2  0.5770232       noAF
> 14   3  0.5776556       noAF
> 15   4  0.5782876       noAF
> 16   5  0.5789195       noAF
> 17   6  0.5795510       noAF
> 18   7  0.5801823       noAF
> 19   8  0.5808134       noAF
> 20   9  0.5814441       noAF
> 21  10  0.5820747       noAF
> 22 -10  0.2359140   singleAF
> 23  -9  0.2356847   singleAF
> 24  -8  0.2354550   singleAF
> 25  -7  0.2352249   singleAF
> 26  -6  0.2349943   singleAF
> 27  -5  0.2347634   singleAF
> 28  -4  0.2345321   singleAF
> 29  -3  0.2343003   singleAF
> 30  -2  0.2340682   singleAF
> 31  -1  0.2338356   singleAF
> 32   0  0.2336027   singleAF
> 33   1  0.2333694   singleAF
> 34   2  0.2331357   singleAF
> 35   3  0.2329016   singleAF
> 36   4  0.2326671   singleAF
> 37   5  0.2324322   singleAF
> 38   6  0.2321969   singleAF
> 39   7  0.2319613   singleAF
> 40   8  0.2317253   singleAF
> 41   9  0.2314889   singleAF
> 42  10  0.2312522   singleAF
> 43 -10  0.1946699 multipleAF
> 44  -9  0.1942640 multipleAF
> 45  -8  0.1938587 multipleAF
> 46  -7  0.1934540 multipleAF
> 47  -6  0.1930500 multipleAF
> 48  -5  0.1926467 multipleAF
> 49  -4  0.1922440 multipleAF
> 50  -3  0.1918419 multipleAF
> 51  -2  0.1914404 multipleAF
> 52  -1  0.1910397 multipleAF
> 53   0  0.1906395 multipleAF
> 54   1  0.1902400 multipleAF
> 55   2  0.1898411 multipleAF
> 56   3  0.1894429 multipleAF
> 57   4  0.1890453 multipleAF
> 58   5  0.1886483 multipleAF
> 59   6  0.1882520 multipleAF
> 60   7  0.1878564 multipleAF
> 61   8  0.1874613 multipleAF
> 62   9  0.1870669 multipleAF
> 63  10  0.1866732 multipleAF
>
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Alpha-not-working-in-geom-rect-tp4704291.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Sun Mar  8 08:30:52 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Sun, 8 Mar 2015 07:30:52 +0000
Subject: [R] install R-devel from R 3.1 to R 3.2 kubuntu
Message-ID: <CALJKBv_Qyt6gKy2A0id2AJpogOUqAB73FHusMkUjue1GGsUYtA@mail.gmail.com>

Dear all,
I found some threads about compiling r-devel source and installing process
but I need some clarifications.
1. Is it better to uninstall R 3.1 before installing R-devel?
2. I have multiples library directories, R-devel will use these libpaths?
> .libpaths()
[1] "/home/mezhoud/R/x86_64-pc-linux-gnu-library/3.1"
[2] "/usr/local/lib/R/site-library"
[3] "/usr/lib/R/site-library"
[4] "/usr/lib/R/library

3. is there a complete tutorial for R-devel installing in GNU/Linux OS?

Thanks,
Karim

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Sun Mar  8 10:36:19 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 08 Mar 2015 10:36:19 +0100
Subject: [R] How to see a R function's code
In-Reply-To: <C8F1078A-B496-4F5C-925A-0F0B79995E70@dcn.davis.CA.us>
References: <CABc7NqGumRHVg+8eaKtiEX8CbvQyxELUL5xpvHHaoE9DseEGsA@mail.gmail.com>	<4F385E01.7050907@gmail.com>	<1425768771544-4704296.post@n4.nabble.com>
	<C8F1078A-B496-4F5C-925A-0F0B79995E70@dcn.davis.CA.us>
Message-ID: <54FC1813.30002@statistik.tu-dortmund.de>



On 08.03.2015 02:45, Jeff Newmiller wrote:
> Most (perhaps all) packages are byte-compiled now. You can often see decompiled code by entering the name of the function without parentheses, or using the getAnywhere function. For base R functions you should probably download the R source tar file separately and unpack it to a convenient location of your choice and dig in.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On March 7, 2015 2:52:51 PM PST, TeeJay <tommesmcpommes at gmx.net> wrote:
>> Hi there,
>>
>> I know this is quite an old post but I am wondering if the answer still
>> applies!?
>>
>> I would like to access the boxplot function. So, I tried to follow the
>> instruction of Uwe Ligges?s article  ?Accessing the Sources?
>> <http://cran.r-project.org/doc/Rnews/Rnews_2006-4.pdf>  . However, in
>> ?$RHOME/src/library/? there is no graphics folder!

Just unpack the R sources and it is there.

Best,
Uwe Ligges


At this location I
>> only
>> have a ?windlgs? folder. I have a graphics folder in ?$RHOME/library/?
>> though. But I am not able to find a ?plot.R? in any of the subfolders
>> as
>> mentioned in Uwe?s article.
>>
>> Furthermore, if I debug into the boxplot function in RStudio, I get a
>> warning stating ?Debug location is approximate because the source is
>> not
>> available?.
>>
>> I already tried to reinstall R but that also did not add the ?graphics?
>> folder to the ?src? folder. Any ideas are appreciated a lot!
>>
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/How-to-see-a-R-function-s-code-tp4380111p4704296.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sun Mar  8 10:38:38 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 08 Mar 2015 10:38:38 +0100
Subject: [R] install R-devel from R 3.1 to R 3.2 kubuntu
In-Reply-To: <CALJKBv_Qyt6gKy2A0id2AJpogOUqAB73FHusMkUjue1GGsUYtA@mail.gmail.com>
References: <CALJKBv_Qyt6gKy2A0id2AJpogOUqAB73FHusMkUjue1GGsUYtA@mail.gmail.com>
Message-ID: <54FC189E.4050603@statistik.tu-dortmund.de>



On 08.03.2015 08:30, Karim Mezhoud wrote:
> Dear all,
> I found some threads about compiling r-devel source and installing process
> but I need some clarifications.
> 1. Is it better to uninstall R 3.1 before installing R-devel?

No, they can be installed separately.

> 2. I have multiples library directories, R-devel will use these libpaths?
>> .libpaths()
> [1] "/home/mezhoud/R/x86_64-pc-linux-gnu-library/3.1"

Well, you should not share them among R versions.
But if you have decided whicvh youb use, you can use these and ask R to

update.packages(checkBuilt=TRUE)

> [2] "/usr/local/lib/R/site-library"
> [3] "/usr/lib/R/site-library"
> [4] "/usr/lib/R/library
>
> 3. is there a complete tutorial for R-devel installing in GNU/Linux OS?

Yes, the manual called "R Installation and Administration".

Best,
Uwe Ligges



> Thanks,
> Karim
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kmezhoud at gmail.com  Sun Mar  8 11:42:40 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Sun, 8 Mar 2015 10:42:40 +0000
Subject: [R] install R-devel from R 3.1 to R 3.2 kubuntu
In-Reply-To: <54FC189E.4050603@statistik.tu-dortmund.de>
References: <CALJKBv_Qyt6gKy2A0id2AJpogOUqAB73FHusMkUjue1GGsUYtA@mail.gmail.com>
	<54FC189E.4050603@statistik.tu-dortmund.de>
Message-ID: <CALJKBv9iM9QLcw1G__3QYWH8RohNWt+pSeQLjueQpz6UvqbfVw@mail.gmail.com>

Thanks Uwe,
yes I read it and I stopped on the last step (below). Something warning
with x11 headers/libs. What I need to do? Thanks

sudo apt-get build-dep r-base
sudo apt-get install subversion ccache
mkdir ~/svn/
cd ~/svn/
svn co https://svn.r-project.org/R/trunk r-devel/R

cd /svn/r-devel/R

LAST STEP
./configure
....
configure: error: --with-x=yes (default) and X11 headers/libs are not available

or
./configure --prefix=/usr/local/bin/
.....

configure: error: --with-x=yes (default) and X11 headers/libs are not available






On Sun, Mar 8, 2015 at 9:38 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de>
wrote:

>
>
> On 08.03.2015 08:30, Karim Mezhoud wrote:
>
>> Dear all,
>> I found some threads about compiling r-devel source and installing process
>> but I need some clarifications.
>> 1. Is it better to uninstall R 3.1 before installing R-devel?
>>
>
> No, they can be installed separately.
>
>  2. I have multiples library directories, R-devel will use these libpaths?
>>
>>> .libpaths()
>>>
>> [1] "/home/mezhoud/R/x86_64-pc-linux-gnu-library/3.1"
>>
>
> Well, you should not share them among R versions.
> But if you have decided whicvh youb use, you can use these and ask R to
>
> update.packages(checkBuilt=TRUE)
>
>  [2] "/usr/local/lib/R/site-library"
>> [3] "/usr/lib/R/site-library"
>> [4] "/usr/lib/R/library
>>
>> 3. is there a complete tutorial for R-devel installing in GNU/Linux OS?
>>
>
> Yes, the manual called "R Installation and Administration".
>
> Best,
> Uwe Ligges
>
>
>
>  Thanks,
>> Karim
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Sun Mar  8 12:30:09 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 08 Mar 2015 12:30:09 +0100
Subject: [R] install R-devel from R 3.1 to R 3.2 kubuntu
In-Reply-To: <CALJKBv9iM9QLcw1G__3QYWH8RohNWt+pSeQLjueQpz6UvqbfVw@mail.gmail.com>
References: <CALJKBv_Qyt6gKy2A0id2AJpogOUqAB73FHusMkUjue1GGsUYtA@mail.gmail.com>	<54FC189E.4050603@statistik.tu-dortmund.de>
	<CALJKBv9iM9QLcw1G__3QYWH8RohNWt+pSeQLjueQpz6UvqbfVw@mail.gmail.com>
Message-ID: <54FC32C1.4000800@statistik.tu-dortmund.de>



On 08.03.2015 11:42, Karim Mezhoud wrote:
> Thanks Uwe,
> yes I read it and I stopped on the last step (below). Something warning
> with x11 headers/libs. What I need to do? Thanks
>
> sudo apt-get build-dep r-base
> sudo apt-get install subversion ccache
> mkdir ~/svn/
> cd ~/svn/
> svn co https://svn.r-project.org/R/trunk r-devel/R
>
> cd /svn/r-devel/R
>
> LAST STEP
> ./configure
> ....
> configure: error: --with-x=yes (default) and X11 headers/libs are not available
>
> or
> ./configure --prefix=/usr/local/bin/
> .....
>
> configure: error: --with-x=yes (default) and X11 headers/libs are not available

Install them?

Best,
Uwe Ligges


From romeo.kienzler at gmail.com  Sun Mar  8 14:27:59 2015
From: romeo.kienzler at gmail.com (Romeo Kienzler)
Date: Sun, 8 Mar 2015 14:27:59 +0100
Subject: [R] Performance issue on sparse matrix object
Message-ID: <CANubczvBrFpfL4HwduO=e=9SPWHjR-Z0V3gy6Mo+fugANX687Q@mail.gmail.com>

Hi,

I'm writing to a sparse 2500x180000 matrix in a column wise random access
pattern and I'm facing very strong performance issues which I'm not facing
with the dense implementation ( where I'm facing main memory issues )

Is there another way to solve this?

Best regards

Romeo

	[[alternative HTML version deleted]]


From archstevej at gmail.com  Sun Mar  8 02:49:55 2015
From: archstevej at gmail.com (Steve Archambault)
Date: Sat, 7 Mar 2015 18:49:55 -0700
Subject: [R] Date extract Year
In-Reply-To: <1425768716075-4704295.post@n4.nabble.com>
References: <1425768716075-4704295.post@n4.nabble.com>
Message-ID: <7E82AA71-0B9D-46B3-8114-2C0E71D60C45@gmail.com>

Hi all,

I am trying in vain to create a new object "Year" in my data frame from
existing Date data. I have tried many different approaches, but can't seem
to get it to work. Here is an example of some code I tried.

date1<- as.Date(wells$Date,"%m/%d/%Y")
wells$year<-as.numeric(format(date1, "%Y"))

I am starting with data that looks like this.

        ID  Date DepthtoWater_bgs test test2
1  BC-0004 41163           260.60    3     1
2  BC-0004 41255           261.65    4     2
3  BC-0003 41345           166.58    5     3
4  BC-0002 41351           317.85    6     4
5  BC-0004 41355           262.15    7     5
6  BC-0003 41438           167.55    8     6
7  BC-0004 41438           265.45    9     7
8  BC-0002 41443           317.25   10     8
9  BC-0002 41521           321.25   11     9
10 BC-0003 41522           168.65   12    10
11 BC-0004 41522           266.15   13    11
12 BC-0003 41627           168.95   14    12
13 BC-0004 41627           265.25   15    13
14 BC-0002 41634           312.31   16    14
15 BC-0003 41703           169.25   17    15
16 BC-0004 41703           265.05   18    16
17 BC-0002 41710           313.01   19    17
18 BC-0003 41795           168.85   20    18
19 BC-0004 41795           266.95   21    19
20 BC-0002 41801           330.41   22    20
21 BC-0003 41905           169.75   23    21
22 BC-0004 41905           267.75   24    22
23 BC-0002 41906           321.01   25    23

Any help would be greatly appreciated!


-Steve


From archstevej at gmail.com  Sun Mar  8 07:50:23 2015
From: archstevej at gmail.com (Steve Archambault)
Date: Sat, 7 Mar 2015 23:50:23 -0700
Subject: [R] Extract year from date
Message-ID: <05AB7693-1D99-497F-BCEE-FD2A6344B7C1@gmail.com>

Hi all,

I am trying in vain to create a new object "Year" in my data frame from
existing Date data. I have tried many different approaches, but can't seem
to get it to work. Here is an example of some code I tried.

date1<- as.Date(wells$Date,"%m/%d/%Y")
wells$year<-as.numeric(format(date1, "%Y"))

I am starting with data that looks like this.

        ID  Date DepthtoWater_bgs test test2
1  BC-0004 41163           260.60    3     1
2  BC-0004 41255           261.65    4     2
3  BC-0003 41345           166.58    5     3
4  BC-0002 41351           317.85    6     4
5  BC-0004 41355           262.15    7     5
6  BC-0003 41438           167.55    8     6
7  BC-0004 41438           265.45    9     7
8  BC-0002 41443           317.25   10     8
9  BC-0002 41521           321.25   11     9
10 BC-0003 41522           168.65   12    10
11 BC-0004 41522           266.15   13    11
12 BC-0003 41627           168.95   14    12
13 BC-0004 41627           265.25   15    13
14 BC-0002 41634           312.31   16    14
15 BC-0003 41703           169.25   17    15
16 BC-0004 41703           265.05   18    16
17 BC-0002 41710           313.01   19    17
18 BC-0003 41795           168.85   20    18
19 BC-0004 41795           266.95   21    19
20 BC-0002 41801           330.41   22    20
21 BC-0003 41905           169.75   23    21
22 BC-0004 41905           267.75   24    22
23 BC-0002 41906           321.01   25    23

Any help would be greatly appreciated!

-Steve
Sent from my iPhone


From wouter-simons at hotmail.com  Sun Mar  8 11:16:32 2015
From: wouter-simons at hotmail.com (Wouter Simons)
Date: Sun, 8 Mar 2015 11:16:32 +0100
Subject: [R] polr: initial value in 'vmmin' is not finite
Message-ID: <DUB118-W39876B7511CA66100B018AE91A0@phx.gbl>

Hi all, I'm trying to estimate an ordered probit model using polr: polr(Rating ~ Currac + Debt + Inflation + GDPpc + GDPgr + Ratio + Levelofdev + Eurozone + Default, method ="probit") where Rating is an ordered discrete dependent variable and the independent variables are a set of economic determinants (e.g. inflation rate). However, I keep getting the same error: Error in optim(s0, fmin, gmin, method = "BFGS", ...) : initial value in 'vmmin' is not finiteI found it in the C code (src/main/optim.c), at line 523 in the procedure vmmin. An error is thrown because the result of function fminfn is not finite. In this function fminfn, at line 82, the result is calculated as result = REAL(s)[0]/(OS->fnscale). This does not make much sense to me, however. I understood it should have something to do with a function evaluating at an infinite value at the starting values. I was hoping someone could explain this in more detail, or help me overcome the problem. Exluding/omitting NA-values from the dataset does not resolve the problem. However, when I delete either Inflation or GDPpc from the set of regressors, it suddenly works fine. And when I delete everything else but keep both Inflation and GDPpc, it also still works. If you have experienced the same problem or might know how to deal with this, I would be really grateful for your response. Thanks a lot, Wouter 		 	   		  
	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Sun Mar  8 17:41:59 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Sun, 8 Mar 2015 18:41:59 +0200
Subject: [R] Date extract Year
In-Reply-To: <7E82AA71-0B9D-46B3-8114-2C0E71D60C45@gmail.com>
References: <1425768716075-4704295.post@n4.nabble.com>
	<7E82AA71-0B9D-46B3-8114-2C0E71D60C45@gmail.com>
Message-ID: <CAGh51gSuY=SPnwb2Wf1f7drF2s=FP-ykJBukqUuhxEqr-3JvUA@mail.gmail.com>

Hi Steve,

Can you please explain to us your date column? thanks.

Regards,
Fredo.
 On Mar 8, 2015 7:32 PM, "Steve Archambault" <archstevej at gmail.com> wrote:

> Hi all,
>
> I am trying in vain to create a new object "Year" in my data frame from
> existing Date data. I have tried many different approaches, but can't seem
> to get it to work. Here is an example of some code I tried.
>
> date1<- as.Date(wells$Date,"%m/%d/%Y")
> wells$year<-as.numeric(format(date1, "%Y"))
>
> I am starting with data that looks like this.
>
>         ID  Date DepthtoWater_bgs test test2
> 1  BC-0004 41163           260.60    3     1
> 2  BC-0004 41255           261.65    4     2
> 3  BC-0003 41345           166.58    5     3
> 4  BC-0002 41351           317.85    6     4
> 5  BC-0004 41355           262.15    7     5
> 6  BC-0003 41438           167.55    8     6
> 7  BC-0004 41438           265.45    9     7
> 8  BC-0002 41443           317.25   10     8
> 9  BC-0002 41521           321.25   11     9
> 10 BC-0003 41522           168.65   12    10
> 11 BC-0004 41522           266.15   13    11
> 12 BC-0003 41627           168.95   14    12
> 13 BC-0004 41627           265.25   15    13
> 14 BC-0002 41634           312.31   16    14
> 15 BC-0003 41703           169.25   17    15
> 16 BC-0004 41703           265.05   18    16
> 17 BC-0002 41710           313.01   19    17
> 18 BC-0003 41795           168.85   20    18
> 19 BC-0004 41795           266.95   21    19
> 20 BC-0002 41801           330.41   22    20
> 21 BC-0003 41905           169.75   23    21
> 22 BC-0004 41905           267.75   24    22
> 23 BC-0002 41906           321.01   25    23
>
> Any help would be greatly appreciated!
>
>
> -Steve
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pertsou at gmail.com  Sun Mar  8 17:44:06 2015
From: pertsou at gmail.com (Endy BlackEndy)
Date: Sun, 8 Mar 2015 18:44:06 +0200
Subject: [R] "survMisc" package
Message-ID: <CAGpBJKR6PKf=aJZiptw=wzsrD3WQ8vNxscfGrMA-F1-pjLZvNw@mail.gmail.com>

Hi R users. I have some problems with the package ?survMisc?. When I am
loading it I am getting the following



> library(survMisc)

Loading required package: survival

Loading required package: splines

Loading required package: km.ci

Loading required package: ggplot2

Loading required package: data.table

data.table 1.9.4  For help type: ?data.table

*** NB: by=.EACHI is now explicit. See README to restore previous behaviour.

Loading required package: gridExtra

Loading required package: grid

Loading required package: rpart



Attaching package: ?survMisc?



The following objects are masked from ?package:stats?:



    AIC, BIC, median, quantile



   In the above output I noticed the line with the three stars (*). In
order to restore the data.table in its previous behavior I tried to locate
the README file but I couldn?t.

   I ignored that NB in the previous output and I continue to run the
example given in the above mentioned package for the routine comp(). The
commands and the output are given below.

> ### 2 curves

> data(kidney,package="KMsurv")

> s1 <- survfit(Surv(time=time, event=delta) ~ type, data=kidney )

> comp(s1)

$tne

       t          n          e   n_type=1   e_type=1   n_type=2   e_type=2

 1:  1.5    86         2       43                1
43                1

 2:  3.5    80         2       40                1
40                1

 3:  4.5    72         4       36                2
36                2

 4:  5.5    66         2       33                1
33                1

 5:  8.5    60         4       30                2                  30
           2

 6:  9.5    54         2       27                1
27                1

 7: 10.5   50         2       25                1
25                1

 8: 11.5    44         2       22               1
22                1

 9: 15.5    28         4       14               2
14                2

10: 16.5   26         2       13               1
13                1

11: 18.5   22         2       11               1
  11                1

12: 23.5     8         2        4                 1
4                1

13: 26.5     6         2        3                 1
3                1



$tests

$tests$lrTests

                                                        ChiSq df p

Log-rank                                                0  1 1

Gehan-Breslow (mod~ Wilcoxon)             0  1 1

Tarone-Ware                                          0  1 1

Peto-Peto                                              0  1 1

Mod~ Peto-Peto (Andersen)                    0  1 1

Flem~-Harr~ with p=1, q=1                      0  1 1



$tests$supTests

                                                             Q p

Log-rank                                                 0 1

Gehan-Breslow (mod~ Wilcoxon)              0 1

Tarone-Ware                                           0 1

Peto-Peto                                               0 1

Mod~ Peto-Peto (Andersen)                     0 1

Renyi Flem~-Harr~ with p=1, q=1             0 1



Notice the zeros (0) that corresponds to the test statistics. (To my
opinion those zeros are strongly related to the NB above).

   Next I noticed the following strange, to my opinion, thing.  More
precisely I have written the following
routine

proc<-function(){

 rm(list=ls())

 library(survMisc)

 d<-read.table("C:\\Program
Files\\R\\Data\\Survival\\HosmLem.txt",fill=TRUE,header=TRUE)

 d4<-as.factor(d[,4])

 s<-survfit(Surv(d[,2], d[,5])~d4)

 ctest<-comp(s)$tests

 print(ctest)

}

The data used are those of Hosmer and Lemeshow book on Applied Survival
Analysis. The first rows of this data set follow.

id Time Age Drug Censor    entdate    enddate

  1    5  46    0      1   05/15/1990 10/14/1990

  2    6  35    1      0   09/19/1989 03/20/1990

  3    8  30    1      1   04/21/1991 12/20/1991

  4    3  30    1      1   01/03/1991 04/04/1991

  5   22  36    0      1   09/18/1989 07/19/1991

  6    1  32    1      0    03/18/1991 04/17/1991

When I run the function proc() I am getting the answer

> proc()

Error in Surv(d[, 2], d[, 5]) : object 'd' not found

In contrast when I run the same routine command-by-command I am getting the
following output

$lrTests

                                                         ChiSq df p

Log-rank                                                 0  1 1

Gehan-Breslow (mod~ Wilcoxon)              0  1 1

Tarone-Ware                                           0  1 1

Peto-Peto                                               0  1 1

Mod~ Peto-Peto (Andersen)                     0  1 1

Flem~-Harr~ with p=1, q=1                       0  1 1



$supTests

                                                              Q p

Log-rank                                                  0 1

Gehan-Breslow (mod~ Wilcoxon)               0 1

Tarone-Ware                                            0 1

Peto-Peto                                                0 1

Mod~ Peto-Peto (Andersen)                      0 1

Renyi Flem~-Harr~ with p=1, q=1              0 1

Any assistance will greatly appreciated.

Cheers

Endy

I am using the

R version 3.1.1 (2014-07-10) -- "Sock it to Me"

Copyright (C) 2014 The R Foundation for Statistical Computing

Platform: i386-w64-mingw32/i386 (32-bit)

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sun Mar  8 17:51:45 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 8 Mar 2015 09:51:45 -0700
Subject: [R] Date extract Year
In-Reply-To: <7E82AA71-0B9D-46B3-8114-2C0E71D60C45@gmail.com>
References: <1425768716075-4704295.post@n4.nabble.com>
	<7E82AA71-0B9D-46B3-8114-2C0E71D60C45@gmail.com>
Message-ID: <CACk-te16Ehqjdm3-9SYq7aJj5BT5-uKk-A9cS7KyK7ai3u9NNA@mail.gmail.com>

Please read ?as.Date carefully. Your argument appears to be numeric
(??)  and you do not seem to have specified an origin:

"as.Date will accept numeric data (the number of days since an epoch),
but only if origin is supplied."

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Mar 7, 2015 at 5:49 PM, Steve Archambault <archstevej at gmail.com> wrote:
> Hi all,
>
> I am trying in vain to create a new object "Year" in my data frame from
> existing Date data. I have tried many different approaches, but can't seem
> to get it to work. Here is an example of some code I tried.
>
> date1<- as.Date(wells$Date,"%m/%d/%Y")
> wells$year<-as.numeric(format(date1, "%Y"))
>
> I am starting with data that looks like this.
>
>         ID  Date DepthtoWater_bgs test test2
> 1  BC-0004 41163           260.60    3     1
> 2  BC-0004 41255           261.65    4     2
> 3  BC-0003 41345           166.58    5     3
> 4  BC-0002 41351           317.85    6     4
> 5  BC-0004 41355           262.15    7     5
> 6  BC-0003 41438           167.55    8     6
> 7  BC-0004 41438           265.45    9     7
> 8  BC-0002 41443           317.25   10     8
> 9  BC-0002 41521           321.25   11     9
> 10 BC-0003 41522           168.65   12    10
> 11 BC-0004 41522           266.15   13    11
> 12 BC-0003 41627           168.95   14    12
> 13 BC-0004 41627           265.25   15    13
> 14 BC-0002 41634           312.31   16    14
> 15 BC-0003 41703           169.25   17    15
> 16 BC-0004 41703           265.05   18    16
> 17 BC-0002 41710           313.01   19    17
> 18 BC-0003 41795           168.85   20    18
> 19 BC-0004 41795           266.95   21    19
> 20 BC-0002 41801           330.41   22    20
> 21 BC-0003 41905           169.75   23    21
> 22 BC-0004 41905           267.75   24    22
> 23 BC-0002 41906           321.01   25    23
>
> Any help would be greatly appreciated!
>
>
> -Steve
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From g.leask at aston.ac.uk  Sun Mar  8 17:58:40 2015
From: g.leask at aston.ac.uk (Leask, Graham)
Date: Sun, 8 Mar 2015 16:58:40 +0000
Subject: [R] Cluster mapping data
Message-ID: <1DF318D1-D417-4D3B-84B0-855733E5EE67@aston.ac.uk>

I am looking to cluster some data including a postcode shape file but need to ensure that the resulting groups are contiguous.

How do I accomplish this using R?

Kind Regards

Dr Graham Leask
Economics & Strategy Group
Aston University
Aston Triangle
Birmingham
B4 7ET

Tel: 0121 204 3150

From pertsou at gmail.com  Sun Mar  8 18:06:53 2015
From: pertsou at gmail.com (Endy BlackEndy)
Date: Sun, 8 Mar 2015 19:06:53 +0200
Subject: [R] "survMisc"
Message-ID: <CAGpBJKRPq0L1rx_gJ7d4=ng+i=Ru83F-5YMASJN-G+SRBDKUNQ@mail.gmail.com>

Hi R users. I have some problems with the package ?survMisc?. When I am
loading it I am getting the following



> library(survMisc)

Loading required package: survival

Loading required package: splines

Loading required package: km.ci

Loading required package: ggplot2

Loading required package: data.table

data.table 1.9.4  For help type: ?data.table

*** NB: by=.EACHI is now explicit. See README to restore previous behaviour.

Loading required package: gridExtra

Loading required package: grid

Loading required package: rpart



Attaching package: ?survMisc?



The following objects are masked from ?package:stats?:



    AIC, BIC, median, quantile



   In the above output I noticed the line with the three stars (*). In
order to restore the data.table in its previous behavior I tried to locate
the README file but I couldn?t.

   I ignored that NB in the previous output and I continue to run the
example given in the above mentioned package for the routine comp(). The
commands and the output are given below.

> ### 2 curves

> data(kidney,package="KMsurv")

> s1 <- survfit(Surv(time=time, event=delta) ~ type, data=kidney )

> comp(s1)

$tne

       t          n          e   n_type=1   e_type=1   n_type=2   e_type=2

 1:  1.5    86         2       43                1
43                1

 2:  3.5    80         2       40                1
40                1

 3:  4.5    72         4       36                2
36                2

 4:  5.5    66         2       33                1
33                1

 5:  8.5    60         4       30                2                  30
           2

 6:  9.5    54         2       27                1
27                1

 7: 10.5   50         2       25                1
25                1

 8: 11.5    44         2       22               1
22                1

 9: 15.5    28         4       14               2
14                2

10: 16.5   26         2       13               1
13                1

11: 18.5   22         2       11               1
  11                1

12: 23.5     8         2        4                 1
4                1

13: 26.5     6         2        3                 1
3                1



$tests

$tests$lrTests

                                                        ChiSq df p

Log-rank                                                0  1 1

Gehan-Breslow (mod~ Wilcoxon)             0  1 1

Tarone-Ware                                          0  1 1

Peto-Peto                                              0  1 1

Mod~ Peto-Peto (Andersen)                    0  1 1

Flem~-Harr~ with p=1, q=1                      0  1 1



$tests$supTests

                                                             Q p

Log-rank                                                 0 1

Gehan-Breslow (mod~ Wilcoxon)              0 1

Tarone-Ware                                           0 1

Peto-Peto                                               0 1

Mod~ Peto-Peto (Andersen)                     0 1

Renyi Flem~-Harr~ with p=1, q=1             0 1



Notice the zeros (0) that corresponds to the test statistics. (To my
opinion those zeros are strongly related to the NB above).

   Next I noticed the following strange, to my opinion, thing.  More
precisely I have written the following
routine

proc<-function(){

 rm(list=ls())

 library(survMisc)

 d<-read.table("C:\\Program
Files\\R\\Data\\Survival\\HosmLem.txt",fill=TRUE,header=TRUE)

 d4<-as.factor(d[,4])

 s<-survfit(Surv(d[,2], d[,5])~d4)

 ctest<-comp(s)$tests

 print(ctest)

}

The data used are those of Hosmer and Lemeshow book on Applied Survival
Analysis. The first rows of this data set follow.

id Time Age Drug Censor    entdate    enddate

  1    5  46    0      1   05/15/1990 10/14/1990

  2    6  35    1      0   09/19/1989 03/20/1990

  3    8  30    1      1   04/21/1991 12/20/1991

  4    3  30    1      1   01/03/1991 04/04/1991

  5   22  36    0      1   09/18/1989 07/19/1991

  6    1  32    1      0    03/18/1991 04/17/1991

When I run the function proc() I am getting the answer

> proc()

Error in Surv(d[, 2], d[, 5]) : object 'd' not found

In contrast when I run the same routine command-by-command I am getting the
following output

$lrTests

                                                         ChiSq df p

Log-rank                                                 0  1 1

Gehan-Breslow (mod~ Wilcoxon)              0  1 1

Tarone-Ware                                           0  1 1

Peto-Peto                                               0  1 1

Mod~ Peto-Peto (Andersen)                     0  1 1

Flem~-Harr~ with p=1, q=1                       0  1 1



$supTests

                                                              Q p

Log-rank                                                  0 1

Gehan-Breslow (mod~ Wilcoxon)               0 1

Tarone-Ware                                            0 1

Peto-Peto                                                0 1

Mod~ Peto-Peto (Andersen)                      0 1

Renyi Flem~-Harr~ with p=1, q=1              0 1

Any assistance will greatly appreciated.

Cheers

Endy

I am using the

R version 3.1.1 (2014-07-10) -- "Sock it to Me"

Copyright (C) 2014 The R Foundation for Statistical Computing

Platform: i386-w64-mingw32/i386 (32-bit)

	[[alternative HTML version deleted]]


From pertsou at gmail.com  Sun Mar  8 18:14:20 2015
From: pertsou at gmail.com (Endy BlackEndy)
Date: Sun, 8 Mar 2015 19:14:20 +0200
Subject: [R]  survMisc
Message-ID: <CAGpBJKQ5DKFozmSd_oyz1ju4xD_R9bNYv+tRUFdS6hQoG=0KbQ@mail.gmail.com>

Hi R users. I have some problems with the package ?survMisc?. When I am
loading it I am getting the following



> library(survMisc)

Loading required package: survival

Loading required package: splines

Loading required package: km.ci

Loading required package: ggplot2

Loading required package: data.table

data.table 1.9.4  For help type: ?data.table

*** NB: by=.EACHI is now explicit. See README to restore previous behaviour.

Loading required package: gridExtra

Loading required package: grid

Loading required package: rpart



Attaching package: ?survMisc?



The following objects are masked from ?package:stats?:



    AIC, BIC, median, quantile



   In the above output I noticed the line with the three stars (*). In
order to restore the data.table in its previous behavior I tried to locate
the README file but I couldn?t.

   I ignored that NB in the previous output and I continue to run the
example given in the above mentioned package for the routine comp(). The
commands and the output are given below.

> ### 2 curves

> data(kidney,package="KMsurv")

> s1 <- survfit(Surv(time=time, event=delta) ~ type, data=kidney )

> comp(s1)

$tne

       t          n          e   n_type=1   e_type=1   n_type=2   e_type=2

 1:  1.5    86         2       43                1
43                1

 2:  3.5    80         2       40                1
40                1

 3:  4.5    72         4       36                2
36                2

 4:  5.5    66         2       33                1
33                1

 5:  8.5    60         4       30                2                  30
           2

 6:  9.5    54         2       27                1
27                1

 7: 10.5   50         2       25                1
25                1

 8: 11.5    44         2       22               1
22                1

 9: 15.5    28         4       14               2
14                2

10: 16.5   26         2       13               1
13                1

11: 18.5   22         2       11               1
  11                1

12: 23.5     8         2        4                 1
4                1

13: 26.5     6         2        3                 1
3                1



$tests

$tests$lrTests

                                                        ChiSq df p

Log-rank                                                0  1 1

Gehan-Breslow (mod~ Wilcoxon)             0  1 1

Tarone-Ware                                          0  1 1

Peto-Peto                                              0  1 1

Mod~ Peto-Peto (Andersen)                    0  1 1

Flem~-Harr~ with p=1, q=1                      0  1 1



$tests$supTests

                                                             Q p

Log-rank                                                 0 1

Gehan-Breslow (mod~ Wilcoxon)              0 1

Tarone-Ware                                           0 1

Peto-Peto                                               0 1

Mod~ Peto-Peto (Andersen)                     0 1

Renyi Flem~-Harr~ with p=1, q=1             0 1



Notice the zeros (0) that corresponds to the test statistics. (To my
opinion those zeros are strongly related to the NB above).

   Next I noticed the following strange, to my opinion, thing.  More
precisely I have written the following
routine

proc<-function(){

 rm(list=ls())

 library(survMisc)

 d<-read.table("C:\\Program
Files\\R\\Data\\Survival\\HosmLem.txt",fill=TRUE,header=TRUE)

 d4<-as.factor(d[,4])

 s<-survfit(Surv(d[,2], d[,5])~d4)

 ctest<-comp(s)$tests

 print(ctest)

}

The data used are those of Hosmer and Lemeshow book on Applied Survival
Analysis. The first rows of this data set follow.

id Time Age Drug Censor    entdate    enddate

  1    5  46    0      1   05/15/1990 10/14/1990

  2    6  35    1      0   09/19/1989 03/20/1990

  3    8  30    1      1   04/21/1991 12/20/1991

  4    3  30    1      1   01/03/1991 04/04/1991

  5   22  36    0      1   09/18/1989 07/19/1991

  6    1  32    1      0    03/18/1991 04/17/1991

When I run the function proc() I am getting the answer

> proc()

Error in Surv(d[, 2], d[, 5]) : object 'd' not found

In contrast when I run the same routine command-by-command I am getting the
following output

$lrTests

                                                         ChiSq df p

Log-rank                                                 0  1 1

Gehan-Breslow (mod~ Wilcoxon)              0  1 1

Tarone-Ware                                           0  1 1

Peto-Peto                                               0  1 1

Mod~ Peto-Peto (Andersen)                     0  1 1

Flem~-Harr~ with p=1, q=1                       0  1 1



$supTests

                                                              Q p

Log-rank                                                  0 1

Gehan-Breslow (mod~ Wilcoxon)               0 1

Tarone-Ware                                            0 1

Peto-Peto                                                0 1

Mod~ Peto-Peto (Andersen)                      0 1

Renyi Flem~-Harr~ with p=1, q=1              0 1

Any assistance will greatly appreciated.

Cheers

Endy

I am using the

R version 3.1.1 (2014-07-10) -- "Sock it to Me"

Copyright (C) 2014 The R Foundation for Statistical Computing

Platform: i386-w64-mingw32/i386 (32-bit)

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sun Mar  8 18:14:33 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 8 Mar 2015 10:14:33 -0700
Subject: [R] Cluster mapping data
In-Reply-To: <1DF318D1-D417-4D3B-84B0-855733E5EE67@aston.ac.uk>
References: <1DF318D1-D417-4D3B-84B0-855733E5EE67@aston.ac.uk>
Message-ID: <CACk-te24YDrcFgUciLyZLK5h_6Onx9-X7NQeCmcxLhjmSrWEoA@mail.gmail.com>

Have you looked at the "Cluster" task view on CRAN?

http://cran.r-project.org/web/views/

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Mar 8, 2015 at 9:58 AM, Leask, Graham <g.leask at aston.ac.uk> wrote:
> I am looking to cluster some data including a postcode shape file but need to ensure that the resulting groups are contiguous.
>
> How do I accomplish this using R?
>
> Kind Regards
>
> Dr Graham Leask
> Economics & Strategy Group
> Aston University
> Aston Triangle
> Birmingham
> B4 7ET
>
> Tel: 0121 204 3150
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kmezhoud at gmail.com  Sun Mar  8 18:26:59 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Sun, 8 Mar 2015 17:26:59 +0000
Subject: [R] install R-devel from R 3.1 to R 3.2 kubuntu
In-Reply-To: <54FC32C1.4000800@statistik.tu-dortmund.de>
References: <CALJKBv_Qyt6gKy2A0id2AJpogOUqAB73FHusMkUjue1GGsUYtA@mail.gmail.com>
	<54FC189E.4050603@statistik.tu-dortmund.de>
	<CALJKBv9iM9QLcw1G__3QYWH8RohNWt+pSeQLjueQpz6UvqbfVw@mail.gmail.com>
	<54FC32C1.4000800@statistik.tu-dortmund.de>
Message-ID: <CALJKBv98kk2nY=-bpL0xzu3hJwEXgJ_gNkesgOf9nnAai4jpZQ@mail.gmail.com>

Resolved, Thanks
sudo apt-get install libxt-dev
sudo apt-get install fonts-inconsolata


On Sun, Mar 8, 2015 at 11:30 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

>
>
> On 08.03.2015 11:42, Karim Mezhoud wrote:
>
>> Thanks Uwe,
>> yes I read it and I stopped on the last step (below). Something warning
>> with x11 headers/libs. What I need to do? Thanks
>>
>> sudo apt-get build-dep r-base
>> sudo apt-get install subversion ccache
>> mkdir ~/svn/
>> cd ~/svn/
>> svn co https://svn.r-project.org/R/trunk r-devel/R
>>
>> cd /svn/r-devel/R
>>
>> LAST STEP
>> ./configure
>> ....
>> configure: error: --with-x=yes (default) and X11 headers/libs are not
>> available
>>
>> or
>> ./configure --prefix=/usr/local/bin/
>> .....
>>
>> configure: error: --with-x=yes (default) and X11 headers/libs are not
>> available
>>
>
> Install them?
>
> Best,
> Uwe Ligges
>
>

	[[alternative HTML version deleted]]


From g.leask at aston.ac.uk  Sun Mar  8 18:31:29 2015
From: g.leask at aston.ac.uk (Leask, Graham)
Date: Sun, 8 Mar 2015 17:31:29 +0000
Subject: [R] Cluster mapping data
In-Reply-To: <CACk-te24YDrcFgUciLyZLK5h_6Onx9-X7NQeCmcxLhjmSrWEoA@mail.gmail.com>
References: <1DF318D1-D417-4D3B-84B0-855733E5EE67@aston.ac.uk>,
	<CACk-te24YDrcFgUciLyZLK5h_6Onx9-X7NQeCmcxLhjmSrWEoA@mail.gmail.com>
Message-ID: <2BE99CCE-BBAD-46F9-9542-4CE5A6D0DC59@aston.ac.uk>

Bert,

Thank you for the suggestion but I am familiar with the clustering routines in R. My issue is how to carry out a grouping analysis on multi variate data that includes postcode shape file data as a variable.

Rather than obtain clusters spread across the map I am looking to limit the solution to groups that are entirely contiguous. I know how to accomplish this with SAS but I am looking to accomplish this using R.

Kind Regards

Dr Graham Leask
Economics & Strategy Group
Aston University
Aston Triangle
Birmingham
B4 7ET

Tel: 0121 204 3150

> On 8 Mar 2015, at 17:14, Bert Gunter <gunter.berton at gene.com> wrote:
> 
> Have you looked at the "Cluster" task view on CRAN?
> 
> http://cran.r-project.org/web/views/
> 
> -- Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
> 
> 
> 
> 
>> On Sun, Mar 8, 2015 at 9:58 AM, Leask, Graham <g.leask at aston.ac.uk> wrote:
>> I am looking to cluster some data including a postcode shape file but need to ensure that the resulting groups are contiguous.
>> 
>> How do I accomplish this using R?
>> 
>> Kind Regards
>> 
>> Dr Graham Leask
>> Economics & Strategy Group
>> Aston University
>> Aston Triangle
>> Birmingham
>> B4 7ET
>> 
>> Tel: 0121 204 3150
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at prodsyse.com  Sun Mar  8 18:54:30 2015
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sun, 08 Mar 2015 10:54:30 -0700
Subject: [R] Date extract Year
In-Reply-To: <CACk-te16Ehqjdm3-9SYq7aJj5BT5-uKk-A9cS7KyK7ai3u9NNA@mail.gmail.com>
References: <1425768716075-4704295.post@n4.nabble.com>	<7E82AA71-0B9D-46B3-8114-2C0E71D60C45@gmail.com>
	<CACk-te16Ehqjdm3-9SYq7aJj5BT5-uKk-A9cS7KyK7ai3u9NNA@mail.gmail.com>
Message-ID: <54FC8CD6.8030100@prodsyse.com>

       The Ecfun package includes a function "as.Date1970", that merely 
provides a default origin for "as.Date".


       This kind of thing can be found using


library(sos)
findFn('as.Date1970')


       This produced a list in my default browser showing 4 links in 3 
packages, the first 2 of which were for this.


       Hope this helps.
       Spencer


On 3/8/2015 9:51 AM, Bert Gunter wrote:
> Please read ?as.Date carefully. Your argument appears to be numeric
> (??)  and you do not seem to have specified an origin:
>
> "as.Date will accept numeric data (the number of days since an epoch),
> but only if origin is supplied."
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sat, Mar 7, 2015 at 5:49 PM, Steve Archambault <archstevej at gmail.com> wrote:
>> Hi all,
>>
>> I am trying in vain to create a new object "Year" in my data frame from
>> existing Date data. I have tried many different approaches, but can't seem
>> to get it to work. Here is an example of some code I tried.
>>
>> date1<- as.Date(wells$Date,"%m/%d/%Y")
>> wells$year<-as.numeric(format(date1, "%Y"))
>>
>> I am starting with data that looks like this.
>>
>>          ID  Date DepthtoWater_bgs test test2
>> 1  BC-0004 41163           260.60    3     1
>> 2  BC-0004 41255           261.65    4     2
>> 3  BC-0003 41345           166.58    5     3
>> 4  BC-0002 41351           317.85    6     4
>> 5  BC-0004 41355           262.15    7     5
>> 6  BC-0003 41438           167.55    8     6
>> 7  BC-0004 41438           265.45    9     7
>> 8  BC-0002 41443           317.25   10     8
>> 9  BC-0002 41521           321.25   11     9
>> 10 BC-0003 41522           168.65   12    10
>> 11 BC-0004 41522           266.15   13    11
>> 12 BC-0003 41627           168.95   14    12
>> 13 BC-0004 41627           265.25   15    13
>> 14 BC-0002 41634           312.31   16    14
>> 15 BC-0003 41703           169.25   17    15
>> 16 BC-0004 41703           265.05   18    16
>> 17 BC-0002 41710           313.01   19    17
>> 18 BC-0003 41795           168.85   20    18
>> 19 BC-0004 41795           266.95   21    19
>> 20 BC-0002 41801           330.41   22    20
>> 21 BC-0003 41905           169.75   23    21
>> 22 BC-0004 41905           267.75   24    22
>> 23 BC-0002 41906           321.01   25    23
>>
>> Any help would be greatly appreciated!
>>
>>
>> -Steve
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Sun Mar  8 19:23:24 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 08 Mar 2015 18:23:24 +0000
Subject: [R] polr: initial value in 'vmmin' is not finite
In-Reply-To: <DUB118-W39876B7511CA66100B018AE91A0@phx.gbl>
References: <DUB118-W39876B7511CA66100B018AE91A0@phx.gbl>
Message-ID: <54FC939C.8080307@stats.ox.ac.uk>

If you did as the posting guide asked and not send HTML your message 
might actually be readable.  But I see no sign of the 'commented, 
minimal, self-contained, reproducible' example.

The issue is most likely the starting values.  See ?polr for how to 
specify others (and it sounds like you can use the coefficients from a 
smaller fit to do so).

Finally, you are completely failing to credit the work you are using. 
Package MASS is not even mentioned, and its author expects civilized 
behaviour from its users.

On 08/03/2015 10:16, Wouter Simons wrote:
> Hi all, I'm trying to estimate an ordered probit model using polr: polr(Rating ~ Currac + Debt + Inflation + GDPpc + GDPgr + Ratio + Levelofdev + Eurozone + Default, method ="probit") where Rating is an ordered discrete dependent variable and the independent variables are a set of economic determinants (e.g. inflation rate). However, I keep getting the same error: Error in optim(s0, fmin, gmin, method = "BFGS", ...) : initial value in 'vmmin' is not finiteI found it in the C code (src/main/optim.c), at line 523 in the procedure vmmin. An error is thrown because the result of function fminfn is not finite. In this function fminfn, at line 82, the result is calculated as result = REAL(s)[0]/(OS->fnscale). This does not make much sense to me, however. I understood it should have something to do with a function evaluating at an infinite value at the starting values. I was hoping someone could explain this in more detail, or help me overcome the problem. Exluding/omitting NA-valu!
>   es from the dataset does not resolve the problem. However, when I delete either Inflation or GDPpc from the set of regressors, it suddenly works fine. And when I delete everything else but keep both Inflation and GDPpc, it also still works. If you have experienced the same problem or might know how to deal with this, I would be really grateful for your response. Thanks a lot, Wouter 		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From msharp at txbiomed.org  Sun Mar  8 21:45:08 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Sun, 8 Mar 2015 20:45:08 +0000
Subject: [R] Extract year from date
In-Reply-To: <05AB7693-1D99-497F-BCEE-FD2A6344B7C1@gmail.com>
References: <05AB7693-1D99-497F-BCEE-FD2A6344B7C1@gmail.com>
Message-ID: <8A8FB7BA-0235-4345-836C-53E1001A67CD@txbiomed.org>

Make the question reproducible (I used dput after getting the data into a dataframe). 
You need to provide a date of origin for the as.Date function.
Try lubridate package.

library(lubridate)
wells <- structure(list(ID = structure(c(3L, 3L, 2L, 1L, 3L, 2L, 3L, 1L, 
 1L, 2L, 3L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L), .Label = c("BC-0002", 
 "BC-0003", "BC-0004"), class = "factor"), Date = c(41163L, 41255L, 
 41345L, 41351L, 41355L, 41438L, 41438L, 41443L, 41521L, 41522L, 
 41522L, 41627L, 41627L, 41634L, 41703L, 41703L, 41710L, 41795L, 
 41795L, 41801L, 41905L, 41905L, 41906L), DepthtoWater_bgs = c(260.6, 
 261.65, 166.58, 317.85, 262.15, 167.55, 265.45, 317.25, 321.25, 
 168.65, 266.15, 168.95, 265.25, 312.31, 169.25, 265.05, 313.01, 
 168.85, 266.95, 330.41, 169.75, 267.75, 321.01), test = 3:25, 
 test2 = 1:23), .Names = c("ID", "Date", "DepthtoWater_bgs", 
 "test", "test2"), class = "data.frame", row.names = c("1", "2", 
 "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", 
 "15", "16", "17", "18", "19", "20", "21", "22", "23"))

wells$year <- year(as.Date(wells$Date, origin = '1900-1-1'))
head(wells$year)

Mark

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org



> On Mar 8, 2015, at 12:50 AM, Steve Archambault <archstevej at gmail.com> wrote:
> 
> Hi all,
> 
> I am trying in vain to create a new object "Year" in my data frame from
> existing Date data. I have tried many different approaches, but can't seem
> to get it to work. Here is an example of some code I tried.
> 
> date1<- as.Date(wells$Date,"%m/%d/%Y")
> wells$year<-as.numeric(format(date1, "%Y"))
> 
> I am starting with data that looks like this.
> 
>        ID  Date DepthtoWater_bgs test test2
> 1  BC-0004 41163           260.60    3     1
> 2  BC-0004 41255           261.65    4     2
> 3  BC-0003 41345           166.58    5     3
> 4  BC-0002 41351           317.85    6     4
> 5  BC-0004 41355           262.15    7     5
> 6  BC-0003 41438           167.55    8     6
> 7  BC-0004 41438           265.45    9     7
> 8  BC-0002 41443           317.25   10     8
> 9  BC-0002 41521           321.25   11     9
> 10 BC-0003 41522           168.65   12    10
> 11 BC-0004 41522           266.15   13    11
> 12 BC-0003 41627           168.95   14    12
> 13 BC-0004 41627           265.25   15    13
> 14 BC-0002 41634           312.31   16    14
> 15 BC-0003 41703           169.25   17    15
> 16 BC-0004 41703           265.05   18    16
> 17 BC-0002 41710           313.01   19    17
> 18 BC-0003 41795           168.85   20    18
> 19 BC-0004 41795           266.95   21    19
> 20 BC-0002 41801           330.41   22    20
> 21 BC-0003 41905           169.75   23    21
> 22 BC-0004 41905           267.75   24    22
> 23 BC-0002 41906           321.01   25    23
> 
> Any help would be greatly appreciated!
> 
> -Steve
> Sent from my iPhone
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mir.salam at uef.fi  Sun Mar  8 22:56:53 2015
From: mir.salam at uef.fi (Mir Salam)
Date: Sun, 8 Mar 2015 21:56:53 +0000
Subject: [R] graphs
Message-ID: <1425852099806.91103@uef.fi>

Dear all,

 I need help to get different 68  plots specifc fitted curves in one plot with respective field data observations (age vs dominant height).



aspdomH2<-groupedData(domH2~age|plotno,data=aspdomH2)



names(aspdomH2)

plotno, age, origin, soilcharacter, domH2,



plotno-different plot no. I have 68 plots

age- every plot have from age 5 to 30 years

origin- two, native aspen and hybrid aspen

domH2<-dominant height

soilcharacter-3, clay, silt and mold. both origin have different soil charcter



#### then I fit model

fm2cham.nlme<-nlme(domH2~cham(age,b0,b1,b2),
               data=aspdomH2,
               fixed = list(b0~1+origin+soilcharacter,b1~ 1,b2 ~ 1+origin+soilcharacter),
               random = b0+b2~1|plotno,
               start=c(b0=26.3387,0,0,0,b1=0.1065,b2=1.9453,0,0,0),
               weights=varPower(form = ~age, 0.5),
               correlation=corAR1())



#### parameter values

Fixed effects: list(b0 ~ 1 + origin + soil character, b1 ~ 1, b2 ~ 1 + origin + soil character)

                                        Value
b0.(Intercept)                 21.081124
b0.origin1                        7.735064
b0.soilcharactermold   10.689051
b0.soilcharactersilt       3.906585
b1                                      0.079035
b2.(Intercept)                  1.616360
b2.origin1                        -0.384421
b2.soilcharactermold      0.612285
b2.soilcharactersilt          0.527462



##### I can easily get the augmented plot.  I got  different 68 plots specific curves.

#######

Any body can help me how can I will get all 68 plots specific fitted curves in one plot with respective plot specific age and dominant height obervations? (x axis will represent age, y axis will represent dominant height and fitted curves of all 68 plots)









	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Sun Mar  8 23:32:04 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Sun, 8 Mar 2015 17:32:04 -0500
Subject: [R] t-test: many changing groups.
In-Reply-To: <DUB122-W319E56EAC4B4CA67C1BA28DF1D0@phx.gbl>
References: <DUB122-W319E56EAC4B4CA67C1BA28DF1D0@phx.gbl>
Message-ID: <CAN5YmCH7UEGWRhQPZy13Dy9d5kCR8vqATSKYWPu4gK18Z+C-nw@mail.gmail.com>

Hard to disentangle your code in the non-HTML world of r-help.  Please use
plain text in the future.  Below is one approach you could try.

Jean

# response variables
resp_vars <- runif(20)
names(resp_vars) <- paste0("sample_", seq(20))

# independent variables
ind_vars <- matrix(sample(c("A", "B"), 2000, TRUE), ncol=20,
  dimnames=list(paste0("obs_", seq(100)), names(resp_vars)))

# save the t-test results to a list
t_fit <- apply(ind_vars, 1, function(obs) t.test(resp_vars ~ obs))

# grab the estimates from each t-test and put it in a data frame
library(broom)
t_est <- do.call(rbind, lapply(t_fit, tidy))
names(t_est) <- c("diff", "meanA", "meanB", "t", "p.value", "df",
  "conf.low", "conf.high")

head(t_est)



On Sat, Mar 7, 2015 at 10:05 AM, White Sky <bluebarbarossa at hotmail.com>
wrote:

> I'd like to perform a t-test between groups 'A' and 'B'. The difficulty is
> that although there is only one response variable, there are many
> observations, and the grouping (A or B) differs with each observation. My
> code for generating the input data is shown below.
> I'd like to know how to approach doing the test, ideally so that the
> t-test results for each observation are presented in a table. I'm not sure
> where to start as other searches have been futile... something along the
> lines of t.test(ind_vars ~ resp_vars) , maybe using rapply, and separating
> groups by A and B each time...
> # Matrix for response variableN_samples <- 20resp_vars <-
> matrix(runif(n=N_samples, min=0, max=1))sample_names <- paste0("sample_",
> 1:N_samples )rownames(x=resp_vars) <- sample_namescolnames(x=resp_vars) <-
> "resp"resp_vars [1:5,]
> # Matrix for independent variablesN_observations <- 100ind_vars <-
> matrix(NA, N_observations, N_samples)ind_vars <- apply(ind_vars, c(1,2),
> function(x) sample(c("A", "B"),1))ind_var_names <- paste0("obs_",
> 1:N_observations)rownames(x=ind_vars) <- ind_var_namescolnames(x=ind_vars)
> <- sample_namesind_vars[1:3,1:5]
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Mar  8 23:43:52 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 09 Mar 2015 11:43:52 +1300
Subject: [R] "tile.list" method for "[" in deldir
Message-ID: <54FCD0A8.2000905@auckland.ac.nz>


I have now added a "tile.list" method for "[" so that "tile.list" 
objects can be sub-setted without losing their class or their "rw" 
attributes.

This is incorporated in version 0.1-8 of deldir which I have just 
uploaded to CRAN.  It should be available for download "soon".

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From r.turner at auckland.ac.nz  Mon Mar  9 01:30:15 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 09 Mar 2015 13:30:15 +1300
Subject: [R] Revised version of deldir.
Message-ID: <54FCE997.5020609@auckland.ac.nz>


There were some (obscure?) technical glitches in version 0.1-8.  I have
fixed these and have uploaded version 0.1-9 to CRAN.  With a bit of luck 
that version will be satisfactory.

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From pertsou at yahoo.gr  Sun Mar  8 19:05:07 2015
From: pertsou at yahoo.gr (Endy)
Date: Sun, 8 Mar 2015 18:05:07 +0000 (UTC)
Subject: [R] survMisc
Message-ID: <1469717187.1008791.1425837907546.JavaMail.yahoo@mail.yahoo.com>

Hi R users. I have some problems with the package ?survMisc?. When I am loading it I am getting the following?> library(survMisc)Loading required package: survivalLoading required package: splinesLoading required package:?km.ciLoading required package: ggplot2Loading required package: data.tabledata.table 1.9.4? For help type: ?data.table*** NB: by=.EACHI is now explicit. See README to restore previous behaviour.Loading required package: gridExtraLoading required package: gridLoading required package: rpart?Attaching package: ?survMisc??The following objects are masked from ?package:stats?:???? AIC, BIC, median, quantile??? In the above output I noticed the line with the three stars (*). In order to restore the data.table in its previous behavior I tried to locate the README file but I couldn?t.?? I ignored that NB in the previous output and I continue to run the example given in the above mentioned package for the routine comp(). The commands and the output are given below.> ### 2 curves> data(kidney,package="KMsurv")> s1 <- survfit(Surv(time=time, event=delta) ~ type, data=kidney )> comp(s1)$tne?????? t? ???? ???n ???????? e?? n_type=1?? e_type=1?? n_type=2?? e_type=2?1:? 1.5??? 86???????? 2?????? 43??????????????? 1????????????????? 43??????????????? 1?2:? 3.5??? 80???????? 2?????? 40??????????????? 1????????????????? 40???????????? ???1?3:? 4.5??? 72???????? 4?????? 36??????????????? 2????????????????? 36??????????????? 2?4:? 5.5??? 66???????? 2?????? 33??????????????? 1????????????????? 33??????????????? 1?5:? 8.5??? 60???????? 4?????? 30??????????????? 2????????????????? 30???? ???????????2?6:? 9.5??? 54???????? 2?????? 27??????????????? 1????????????????? 27??????????????? 1?7: 10.5?? 50???????? 2?????? 25??????????????? 1????????????????? 25??????????????? 1?8: 11.5??? 44???????? 2?????? 22?????????????? 1????????????????? 22??????????????? 1?9: 15.5??? 28???????? 4?????? 14?????????????? 2????????????????? 14??????????????? 210: 16.5?? 26???????? 2?????? 13?????????????? 1????????????????? 13??????????????? 111: 18.5?? 22???????? 2?????? 11?????????????? 1??????????????? ??11??????????????? 112: 23.5???? 8???????? 2??????? 4???????????????? 1??????????????????? 4??????????????? 113: 26.5???? 6???????? 2??????? 3???????????????? 1??????????????????? 3??????????????? 1?$tests$tests$lrTests????????????????????????????? ??????????????????????????ChiSq df pLog-rank????????????????????????? ??????????????????????0? 1 1Gehan-Breslow (mod~ Wilcoxon)? ? ? ? ? ? ?0? 1 1Tarone-Ware?????????????????????? ? ? ? ? ? ? ? ? ? ?0? 1 1Peto-Peto???????????????????? ????????????????????? ? ?0? 1 1Mod~ Peto-Peto (Andersen)???????? ? ? ? ? ? ?0? 1 1Flem~-Harr~ with p=1, q=1???????? ? ? ? ? ? ? ?0? 1 1?$tests$supTests?????????????????????????????? ??????????????????????????????Q pLog-rank??????????????????????? ??????????????????????? ?0 1Gehan-Breslow (mod~ Wilcoxon)? ? ? ? ? ? ??0 1Tarone-Ware???????????????????? ? ? ? ? ? ? ? ? ? ? ??0 1Peto-Peto?????????????????????? ? ? ? ? ? ? ? ? ? ? ? ??0 1Mod~ Peto-Peto (Andersen)?????? ? ? ? ? ? ? ??0 1Renyi Flem~-Harr~ with p=1, q=1 ? ? ? ? ? ??0 1?Notice the zeros (0) that corresponds to the test statistics. (To my opinion those zeros are strongly related to the NB above).?? Next I noticed the following strange, to my opinion, thing.? More precisely I have written the following routine????????????????????????????????????????????????????????????????????????????????proc<-function(){?rm(list=ls())?library(survMisc)?d<-read.table("C:\\Program Files\\R\\Data\\Survival\\HosmLem.txt",fill=TRUE,header=TRUE)?d4<-as.factor(d[,4])?s<-survfit(Surv(d[,2], d[,5])~d4)?ctest<-comp(s)$tests?print(ctest)}The data used are those of Hosmer and Lemeshow book on Applied Survival Analysis. The first rows of this data set follow.id Time Age Drug Censor??? entdate??? enddate? 1??? 5? 46??? 0????? 1?? 05/15/1990 10/14/1990? 2??? 6? 35??? 1????? 0?? 09/19/1989 03/20/1990? 3??? 8? 30??? 1????? 1?? 04/21/1991 12/20/1991? 4??? 3? 30??? 1????? 1?? 01/03/1991 04/04/1991? 5?? 22? 36??? 0????? 1?? 09/18/1989 07/19/1991? 6??? 1? 32??? 1????? 0??? 03/18/1991 04/17/1991When I run the function proc() I am getting the answer> proc()Error in Surv(d[, 2], d[, 5]) : object 'd' not foundIn contrast when I run the same routine command-by-command I am getting the following output$lrTests????????????????????? ???????????????????????????????????ChiSq df pLog-rank????????????????????????? ???????????????????????0? 1 1Gehan-Breslow (mod~ Wilcoxon)? ? ? ? ? ? ? 0? 1 1Tarone-Ware?????????????????????? ? ? ? ? ? ? ? ? ? ? 0? 1 1Peto-Peto???????????????????????? ? ? ? ? ? ? ? ? ? ? ??0? 1 1Mod~ Peto-Peto (Andersen)??????? ????? ? ? ? ?0? 1 1Flem~-Harr~ with p=1, q=1?????? ??? ? ? ? ? ? ??0? 1 1?$supTests??????????????????????????????? ??????????????????????????????Q pLog-rank?????????????????????? ???????????????????????? ??0 1Gehan-Breslow (mod~ Wilcoxon)? ? ? ? ? ? ? ?0 1Tarone-Ware???????????????????? ? ? ? ? ? ? ? ? ? ? ? ?0 1Peto-Peto?????????????????????? ? ? ? ? ? ? ? ? ? ? ? ? ?0 1Mod~ Peto-Peto (Andersen)?????? ? ? ? ? ? ? ? ?0 1Renyi Flem~-Harr~ with p=1, q=1 ? ? ? ? ? ???0 1Any assistance will greatly appreciated.CheersEndyI am using theR version 3.1.1 (2014-07-10) -- "Sock it to Me"Copyright (C) 2014 The R Foundation for Statistical ComputingPlatform: i386-w64-mingw32/i386 (32-bit)?

	[[alternative HTML version deleted]]


From tommesmcpommes at gmx.net  Sun Mar  8 19:07:00 2015
From: tommesmcpommes at gmx.net (TeeJay)
Date: Sun, 8 Mar 2015 11:07:00 -0700 (PDT)
Subject: [R] How to see a R function's code
In-Reply-To: <54FC1813.30002@statistik.tu-dortmund.de>
References: <CABc7NqGumRHVg+8eaKtiEX8CbvQyxELUL5xpvHHaoE9DseEGsA@mail.gmail.com>
	<4F385E01.7050907@gmail.com>
	<1425768771544-4704296.post@n4.nabble.com>
	<C8F1078A-B496-4F5C-925A-0F0B79995E70@dcn.davis.CA.us>
	<54FC1813.30002@statistik.tu-dortmund.de>
Message-ID: <1425838020031-4704321.post@n4.nabble.com>

@ Jeff & @ Uwe: Thanks a lot! Worked like a charm 



Uwe Ligges-3 wrote
> On 08.03.2015 02:45, Jeff Newmiller wrote:
>> Most (perhaps all) packages are byte-compiled now. You can often see
>> decompiled code by entering the name of the function without parentheses,
>> or using the getAnywhere function. For base R functions you should
>> probably download the R source tar file separately and unpack it to a
>> convenient location of your choice and dig in.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:&lt;

> jdnewmil at .ca

> &gt;        Basics: ##.#.       ##.#.  Live Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>> rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 7, 2015 2:52:51 PM PST, TeeJay &lt;

> tommesmcpommes@

> &gt; wrote:
>>> Hi there,
>>>
>>> I know this is quite an old post but I am wondering if the answer still
>>> applies!?
>>>
>>> I would like to access the boxplot function. So, I tried to follow the
>>> instruction of Uwe Ligges?s article  ?Accessing the Sources?
>>> &lt;http://cran.r-project.org/doc/Rnews/Rnews_2006-4.pdf&gt;  . However,
>>> in
>>> ?$RHOME/src/library/? there is no graphics folder!
> 
> Just unpack the R sources and it is there.
> 
> Best,
> Uwe Ligges
> 
> 
> At this location I
>>> only
>>> have a ?windlgs? folder. I have a graphics folder in ?$RHOME/library/?
>>> though. But I am not able to find a ?plot.R? in any of the subfolders
>>> as
>>> mentioned in Uwe?s article.
>>>
>>> Furthermore, if I debug into the boxplot function in RStudio, I get a
>>> warning stating ?Debug location is approximate because the source is
>>> not
>>> available?.
>>>
>>> I already tried to reinstall R but that also did not add the ?graphics?
>>> folder to the ?src? folder. Any ideas are appreciated a lot!
>>>
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>> http://r.789695.n4.nabble.com/How-to-see-a-R-function-s-code-tp4380111p4704296.html
>>> Sent from the R help mailing list archive at Nabble.com.
>>>
>>> ______________________________________________
>>> 

> R-help@

>  mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> 

> R-help@

>  mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________

> R-help@

>  mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/How-to-see-a-R-function-s-code-tp4380111p4704321.html
Sent from the R help mailing list archive at Nabble.com.


From archstevej at gmail.com  Sun Mar  8 19:27:32 2015
From: archstevej at gmail.com (Steven Archambault)
Date: Sun, 8 Mar 2015 12:27:32 -0600
Subject: [R] Date extract Year
In-Reply-To: <CAGh51gSuY=SPnwb2Wf1f7drF2s=FP-ykJBukqUuhxEqr-3JvUA@mail.gmail.com>
References: <1425768716075-4704295.post@n4.nabble.com>
	<7E82AA71-0B9D-46B3-8114-2C0E71D60C45@gmail.com>
	<CAGh51gSuY=SPnwb2Wf1f7drF2s=FP-ykJBukqUuhxEqr-3JvUA@mail.gmail.com>
Message-ID: <72750608-7D36-40E6-94B0-FC4C3CE83584@gmail.com>

My date column is the excel numeric date format. For instance, in excel, that first date is 11 September 2012.

On Mar 8, 2015, at 10:41 AM, Frederic Ntirenganya <ntfredo at gmail.com> wrote:

> Hi Steve,
> 
> Can you please explain to us your date column? thanks.
> 
> Regards,
> Fredo.
> On Mar 8, 2015 7:32 PM, "Steve Archambault" <archstevej at gmail.com> wrote:
> Hi all,
> 
> I am trying in vain to create a new object "Year" in my data frame from
> existing Date data. I have tried many different approaches, but can't seem
> to get it to work. Here is an example of some code I tried.
> 
> date1<- as.Date(wells$Date,"%m/%d/%Y")
> wells$year<-as.numeric(format(date1, "%Y"))
> 
> I am starting with data that looks like this.
> 
>         ID  Date DepthtoWater_bgs test test2
> 1  BC-0004 41163           260.60    3     1
> 2  BC-0004 41255           261.65    4     2
> 3  BC-0003 41345           166.58    5     3
> 4  BC-0002 41351           317.85    6     4
> 5  BC-0004 41355           262.15    7     5
> 6  BC-0003 41438           167.55    8     6
> 7  BC-0004 41438           265.45    9     7
> 8  BC-0002 41443           317.25   10     8
> 9  BC-0002 41521           321.25   11     9
> 10 BC-0003 41522           168.65   12    10
> 11 BC-0004 41522           266.15   13    11
> 12 BC-0003 41627           168.95   14    12
> 13 BC-0004 41627           265.25   15    13
> 14 BC-0002 41634           312.31   16    14
> 15 BC-0003 41703           169.25   17    15
> 16 BC-0004 41703           265.05   18    16
> 17 BC-0002 41710           313.01   19    17
> 18 BC-0003 41795           168.85   20    18
> 19 BC-0004 41795           266.95   21    19
> 20 BC-0002 41801           330.41   22    20
> 21 BC-0003 41905           169.75   23    21
> 22 BC-0004 41905           267.75   24    22
> 23 BC-0002 41906           321.01   25    23
> 
> Any help would be greatly appreciated!
> 
> 
> -Steve
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From pertsou at yahoo.gr  Sun Mar  8 19:29:56 2015
From: pertsou at yahoo.gr (Endy)
Date: Sun, 8 Mar 2015 18:29:56 +0000 (UTC)
Subject: [R] survMisc package
Message-ID: <1933326432.1018361.1425839396655.JavaMail.yahoo@mail.yahoo.com>

Hi R users. I have some problems with the package ?survMisc?. When I am loading it I am getting the following?> library(survMisc)Loading required package: survivalLoading required package: splinesLoading required package:?km.ciLoading required package: ggplot2Loading required package: data.tabledata.table 1.9.4? For help type: ?data.table*** NB: by=.EACHI is now explicit. See README to restore previous behaviour.Loading required package: gridExtraLoading required package: gridLoading required package: rpart?Attaching package: ?survMisc??The following objects are masked from ?package:stats?:???? AIC, BIC, median, quantile??? In the above output I noticed the line with the three stars (*). In order to restore the data.table in its previous behavior I tried to locate the README file but I couldn?t.?? I ignored that NB in the previous output and I continue to run the example given in the above mentioned package for the routine comp(). The commands and the output are given below.> ### 2 curves> data(kidney,package="KMsurv")> s1 <- survfit(Surv(time=time, event=delta) ~ type, data=kidney )> comp(s1)$tne?????? t? ???? ???n ???????? e?? n_type=1?? e_type=1?? n_type=2?? e_type=2?1:? 1.5??? 86???????? 2?????? 43??????????????? 1????????????????? 43??????????????? 1?2:? 3.5??? 80???????? 2?????? 40??????????????? 1????????????????? 40???????????? ???1?3:? 4.5??? 72???????? 4?????? 36??????????????? 2????????????????? 36??????????????? 2?4:? 5.5??? 66???????? 2?????? 33??????????????? 1????????????????? 33??????????????? 1?5:? 8.5??? 60???????? 4?????? 30??????????????? 2????????????????? 30???? ???????????2?6:? 9.5??? 54???????? 2?????? 27??????????????? 1????????????????? 27??????????????? 1?7: 10.5?? 50???????? 2?????? 25??????????????? 1????????????????? 25??????????????? 1?8: 11.5??? 44???????? 2?????? 22?????????????? 1????????????????? 22??????????????? 1?9: 15.5??? 28???????? 4?????? 14?????????????? 2????????????????? 14??????????????? 210: 16.5?? 26???????? 2?????? 13?????????????? 1????????????????? 13??????????????? 111: 18.5?? 22???????? 2?????? 11?????????????? 1??????????????? ??11??????????????? 112: 23.5???? 8???????? 2??????? 4???????????????? 1??????????????????? 4??????????????? 113: 26.5???? 6???????? 2??????? 3???????????????? 1??????????????????? 3??????????????? 1?$tests$tests$lrTests????????????????????????????? ??????????????????????????ChiSq df pLog-rank????????????????????????? ??????????????????????0? 1 1Gehan-Breslow (mod~ Wilcoxon)? ? ? ? ? ? ?0? 1 1Tarone-Ware?????????????????????? ? ? ? ? ? ? ? ? ? ?0? 1 1Peto-Peto???????????????????? ????????????????????? ? ?0? 1 1Mod~ Peto-Peto (Andersen)???????? ? ? ? ? ? ?0? 1 1Flem~-Harr~ with p=1, q=1???????? ? ? ? ? ? ? ?0? 1 1?$tests$supTests?????????????????????????????? ??????????????????????????????Q pLog-rank??????????????????????? ??????????????????????? ?0 1Gehan-Breslow (mod~ Wilcoxon)? ? ? ? ? ? ??0 1Tarone-Ware???????????????????? ? ? ? ? ? ? ? ? ? ? ??0 1Peto-Peto?????????????????????? ? ? ? ? ? ? ? ? ? ? ? ??0 1Mod~ Peto-Peto (Andersen)?????? ? ? ? ? ? ? ??0 1Renyi Flem~-Harr~ with p=1, q=1 ? ? ? ? ? ??0 1?Notice the zeros (0) that corresponds to the test statistics. (To my opinion those zeros are strongly related to the NB above).?? Next I noticed the following strange, to my opinion, thing.? More precisely I have written the following routine????????????????????????????????????????????????????????????????????????????????proc<-function(){?rm(list=ls())?library(survMisc)?d<-read.table("C:\\Program Files\\R\\Data\\Survival\\HosmLem.txt",fill=TRUE,header=TRUE)?d4<-as.factor(d[,4])?s<-survfit(Surv(d[,2], d[,5])~d4)?ctest<-comp(s)$tests?print(ctest)}The data used are those of Hosmer and Lemeshow book on Applied Survival Analysis. The first rows of this data set follow.id Time Age Drug Censor??? entdate??? enddate? 1??? 5? 46??? 0????? 1?? 05/15/1990 10/14/1990? 2??? 6? 35??? 1????? 0?? 09/19/1989 03/20/1990? 3??? 8? 30??? 1????? 1?? 04/21/1991 12/20/1991? 4??? 3? 30??? 1????? 1?? 01/03/1991 04/04/1991? 5?? 22? 36??? 0????? 1?? 09/18/1989 07/19/1991? 6??? 1? 32??? 1????? 0??? 03/18/1991 04/17/1991When I run the function proc() I am getting the answer> proc()Error in Surv(d[, 2], d[, 5]) : object 'd' not foundIn contrast when I run the same routine command-by-command I am getting the following output$lrTests????????????????????? ???????????????????????????????????ChiSq df pLog-rank????????????????????????? ???????????????????????0? 1 1Gehan-Breslow (mod~ Wilcoxon)? ? ? ? ? ? ? 0? 1 1Tarone-Ware?????????????????????? ? ? ? ? ? ? ? ? ? ? 0? 1 1Peto-Peto???????????????????????? ? ? ? ? ? ? ? ? ? ? ??0? 1 1Mod~ Peto-Peto (Andersen)??????? ????? ? ? ? ?0? 1 1Flem~-Harr~ with p=1, q=1?????? ??? ? ? ? ? ? ??0? 1 1?$supTests??????????????????????????????? ??????????????????????????????Q pLog-rank?????????????????????? ???????????????????????? ??0 1Gehan-Breslow (mod~ Wilcoxon)? ? ? ? ? ? ? ?0 1Tarone-Ware???????????????????? ? ? ? ? ? ? ? ? ? ? ? ?0 1Peto-Peto?????????????????????? ? ? ? ? ? ? ? ? ? ? ? ? ?0 1Mod~ Peto-Peto (Andersen)?????? ? ? ? ? ? ? ? ?0 1Renyi Flem~-Harr~ with p=1, q=1 ? ? ? ? ? ???0 1Any assistance will greatly appreciated.CheersEndyI am using theR version 3.1.1 (2014-07-10) -- "Sock it to Me"Copyright (C) 2014 The R Foundation for Statistical ComputingPlatform: i386-w64-mingw32/i386 (32-bit)?

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Mon Mar  9 04:00:06 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 8 Mar 2015 20:00:06 -0700
Subject: [R] Date extract Year
In-Reply-To: <72750608-7D36-40E6-94B0-FC4C3CE83584@gmail.com>
References: <1425768716075-4704295.post@n4.nabble.com>
	<7E82AA71-0B9D-46B3-8114-2C0E71D60C45@gmail.com>
	<CAGh51gSuY=SPnwb2Wf1f7drF2s=FP-ykJBukqUuhxEqr-3JvUA@mail.gmail.com>
	<72750608-7D36-40E6-94B0-FC4C3CE83584@gmail.com>
Message-ID: <CACk-te3N89JHF2+uDjG7=tOjTeBEwhCLO-AxR5qDzWc79g9ApA@mail.gmail.com>

... and that is the source of your difficulties, as I and others have told you.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Mar 8, 2015 at 11:27 AM, Steven Archambault
<archstevej at gmail.com> wrote:
> My date column is the excel numeric date format. For instance, in excel, that first date is 11 September 2012.
>
> On Mar 8, 2015, at 10:41 AM, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
>
>> Hi Steve,
>>
>> Can you please explain to us your date column? thanks.
>>
>> Regards,
>> Fredo.
>> On Mar 8, 2015 7:32 PM, "Steve Archambault" <archstevej at gmail.com> wrote:
>> Hi all,
>>
>> I am trying in vain to create a new object "Year" in my data frame from
>> existing Date data. I have tried many different approaches, but can't seem
>> to get it to work. Here is an example of some code I tried.
>>
>> date1<- as.Date(wells$Date,"%m/%d/%Y")
>> wells$year<-as.numeric(format(date1, "%Y"))
>>
>> I am starting with data that looks like this.
>>
>>         ID  Date DepthtoWater_bgs test test2
>> 1  BC-0004 41163           260.60    3     1
>> 2  BC-0004 41255           261.65    4     2
>> 3  BC-0003 41345           166.58    5     3
>> 4  BC-0002 41351           317.85    6     4
>> 5  BC-0004 41355           262.15    7     5
>> 6  BC-0003 41438           167.55    8     6
>> 7  BC-0004 41438           265.45    9     7
>> 8  BC-0002 41443           317.25   10     8
>> 9  BC-0002 41521           321.25   11     9
>> 10 BC-0003 41522           168.65   12    10
>> 11 BC-0004 41522           266.15   13    11
>> 12 BC-0003 41627           168.95   14    12
>> 13 BC-0004 41627           265.25   15    13
>> 14 BC-0002 41634           312.31   16    14
>> 15 BC-0003 41703           169.25   17    15
>> 16 BC-0004 41703           265.05   18    16
>> 17 BC-0002 41710           313.01   19    17
>> 18 BC-0003 41795           168.85   20    18
>> 19 BC-0004 41795           266.95   21    19
>> 20 BC-0002 41801           330.41   22    20
>> 21 BC-0003 41905           169.75   23    21
>> 22 BC-0004 41905           267.75   24    22
>> 23 BC-0002 41906           321.01   25    23
>>
>> Any help would be greatly appreciated!
>>
>>
>> -Steve
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Mon Mar  9 04:31:54 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 09 Mar 2015 16:31:54 +1300
Subject: [R] Date extract Year
In-Reply-To: <72750608-7D36-40E6-94B0-FC4C3CE83584@gmail.com>
References: <1425768716075-4704295.post@n4.nabble.com>	<7E82AA71-0B9D-46B3-8114-2C0E71D60C45@gmail.com>	<CAGh51gSuY=SPnwb2Wf1f7drF2s=FP-ykJBukqUuhxEqr-3JvUA@mail.gmail.com>
	<72750608-7D36-40E6-94B0-FC4C3CE83584@gmail.com>
Message-ID: <54FD142A.7050203@auckland.ac.nz>


On 09/03/15 07:27, Steven Archambault wrote:

> My date column is the excel numeric date format. For instance, in
> excel, that first date is 11 September 2012.

And we were supposed to know that?  The level of obtuseness of people
who post to this list truly knows no lower bound.

Be that as it may, you could do:

o <- as.Date("2012/09/11")-41163
date1 <- as.Date(wells$Date,origin=o)

cheers,

Rolf Turner

>
> On Mar 8, 2015, at 10:41 AM, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
>
>> Hi Steve,
>>
>> Can you please explain to us your date column? thanks.
>>
>> Regards,
>> Fredo.
>> On Mar 8, 2015 7:32 PM, "Steve Archambault" <archstevej at gmail.com> wrote:
>> Hi all,
>>
>> I am trying in vain to create a new object "Year" in my data frame from
>> existing Date data. I have tried many different approaches, but can't seem
>> to get it to work. Here is an example of some code I tried.
>>
>> date1<- as.Date(wells$Date,"%m/%d/%Y")
>> wells$year<-as.numeric(format(date1, "%Y"))
>>
>> I am starting with data that looks like this.
>>
>>          ID  Date DepthtoWater_bgs test test2
>> 1  BC-0004 41163           260.60    3     1
>> 2  BC-0004 41255           261.65    4     2
>> 3  BC-0003 41345           166.58    5     3
>> 4  BC-0002 41351           317.85    6     4
>> 5  BC-0004 41355           262.15    7     5
>> 6  BC-0003 41438           167.55    8     6
>> 7  BC-0004 41438           265.45    9     7
>> 8  BC-0002 41443           317.25   10     8
>> 9  BC-0002 41521           321.25   11     9
>> 10 BC-0003 41522           168.65   12    10
>> 11 BC-0004 41522           266.15   13    11
>> 12 BC-0003 41627           168.95   14    12
>> 13 BC-0004 41627           265.25   15    13
>> 14 BC-0002 41634           312.31   16    14
>> 15 BC-0003 41703           169.25   17    15
>> 16 BC-0004 41703           265.05   18    16
>> 17 BC-0002 41710           313.01   19    17
>> 18 BC-0003 41795           168.85   20    18
>> 19 BC-0004 41795           266.95   21    19
>> 20 BC-0002 41801           330.41   22    20
>> 21 BC-0003 41905           169.75   23    21
>> 22 BC-0004 41905           267.75   24    22
>> 23 BC-0002 41906           321.01   25    23
>>
>> Any help would be greatly appreciated!

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From bhh at xs4all.nl  Mon Mar  9 07:50:59 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 9 Mar 2015 07:50:59 +0100
Subject: [R] survMisc package
In-Reply-To: <1933326432.1018361.1425839396655.JavaMail.yahoo@mail.yahoo.com>
References: <1933326432.1018361.1425839396655.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <0FEAF095-3324-4279-B4EA-E8172AA2EE25@xs4all.nl>


> On 08-03-2015, at 19:29, Endy <pertsou at yahoo.gr> wrote:
> 
> Hi R users. I have some problems with the package ?survMisc?. When I am loading it I am getting the following > library(survMisc)Loading required package: survivalLoading required package: splinesLoading required package: km.ciLoading required package: ggplot2Loading required package: data.tabledata.table 1.9.4  For help type: ?data.table*** NB: by=.EACHI is now explicit. See README to restore previous behaviour.Loading required package: gridExtraLoading required package: gridLoading required package: rpart Attaching package: ?survMisc? The following objects are masked from ?package:stats?:     AIC, BIC, median, quantile    In the above output I noticed the line with the three stars (*). In order to restore the data.table in its previous behavior I tried to locate the README file but I couldn?t.   I ignored that NB in the previous output and I continue to run the example given in the above mentioned package for the routine comp(). The commands and the output are given below.> ### 2 curves> data(kidney,package="KMsurv")> s1 <- survfit(Surv(time=time, event=delta) ~ type, data=kidney )> comp(s1)$tne       t          n          e   n_type=1   e_type=1   n_type=2   e_type=2 1:  1.5    86         2       43                1                  43                1 2:  3.5    80         2       40                1                  40                1 3:  4.5    72         4       36                2                  36                2 4:  5.5    66         2       33                1                  33                1 5:  8.5    60         4       30                2                  30                2 6:  9.5    54         2       27                1                  27                1 7: 10.5   50         2       25                1                  25                1 8: 11.5    44         2       22               1                  22                1 9: 15.5    28         4       14               2                  14                210: 16.5   26         2       13               1                  13                111: 18.5   22         2       11               1                  11                112: 23.5     8         2        4                 1                    4                113: 26.5     6         2        3                 1                    3                1 $tests$tests$lrTests                                                        ChiSq df pLog-rank                                                0  1 1Gehan-Breslow (mod~ Wilcoxon)             0  1 1Tarone-Ware                                          0  1 1Peto-Peto                                              0  1 1Mod~ Peto-Peto (Andersen)                    0  1 1Flem~-Harr~ with p=1, q=1                      0  1 1 $tests$supTests                                                             Q pLog-rank                                                 0 1Gehan-Breslow (mod~ Wilcoxon)              0 1Tarone-Ware                                           0 1Peto-Peto                                               0 1Mod~ Peto-Peto (Andersen)                     0 1Renyi Flem~-Harr~ with p=1, q=1             0 1 Notice the zeros (0) that corresponds to the test statistics. (To my opinion those zeros are strongly related to the NB above).   Next I noticed the following strange, to my opinion, thing.  More precisely I have written the following routine                                                                                proc<-function(){ rm(list=ls()) library(survMisc) d<-read.table("C:\\Program Files\\R\\Data\\Survival\\HosmLem.txt",fill=TRUE,header=TRUE) d4<-as.factor(d[,4]) s<-survfit(Surv(d[,2], d[,5])~d4) ctest<-comp(s)$tests print(ctest)}The data used are those of Hosmer and Lemeshow book on Applied Survival Analysis. The first rows of this data set follow.id Time Age Drug Censor    entdate    enddate  1    5  46    0      1   05/15/1990 10/14/1990  2    6  35    1      0   09/19/1989 03/20/1990  3    8  30    1      1   04/21/1991 12/20/1991  4    3  30    1      1   01/03/1991 04/04/1991  5   22  36    0      1   09/18/1989 07/19/1991  6    1  32    1      0    03/18/1991 04/17/1991When I run the function proc() I am getting the answer> proc()Error in Surv(d[, 2], d[, 5]) : object 'd' not foundIn contrast when I run the same routine command-by-command I am getting the following output$lrTests                                                         ChiSq df pLog-rank                                                 0  1 1Gehan-Breslow (mod~ Wilcoxon)              0  1 1Tarone-Ware                                           0  1 1Peto-Peto                                               0  1 1Mod~ Peto-Peto (Andersen)                     0  1 1Flem~-Harr~ with p=1, q=1                       0  1 1 $supTests                                                              Q pLog-rank                                                  0 1Gehan-Breslow (mod~ Wilcoxon)               0 1Tarone-Ware                                            0 1Peto-Peto                                                0 1Mod~ Peto-Peto (Andersen)                      0 1Renyi Flem~-Harr~ with p=1, q=1              0 1Any assistance will greatly appreciated.CheersEndyI am using theR version 3.1.1 (2014-07-10) -- "Sock it to Me"Copyright (C) 2014 The R Foundation for Statistical ComputingPlatform: i386-w64-mingw32/i386 (32-bit) 
> 
> 	[[alternative HTML version deleted]]


Do not post twice in a space of 10 minutes.

Your mail is completely mangled and unreadable.
Please follow the posting guide and DO NOT post in html.

Berend


From pd.mes at cbs.dk  Mon Mar  9 10:04:28 2015
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Mon, 9 Mar 2015 10:04:28 +0100
Subject: [R] R 3.1.3 is released
Message-ID: <4EE2768D-1C4B-487F-A72C-2AA8EEE50D05@cbs.dk>

The build system rolled up R-3.1.3.tar.gz (codename "Smooth Sidewalk") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.1.3.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team

Peter Dalgaard


These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = cebbdd1eb8cd620bf2a6ac84c9e731c2
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = a699fa0eeef280b78134f0abe0b1c1b0
MD5 (INSTALL) = 3964b9119adeaab9ceb633773fc94aac
MD5 (NEWS) = 8790db3a8000910f0bf00fb1ee039634
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 8e2f4d1d5228663ae598a09bf1e2bc6b
MD5 (R-latest.tar.gz) = 53a85b884925aa6b5811dfc361d73fc4
MD5 (R.css) = 444535b9cb76ddff1bab1e1865a3fb14
MD5 (README) = aece1dfbd18c1760128c3787f5456af6
MD5 (RESOURCES) = a59076c1ac7e9bab0f0a38b3f57a3914
MD5 (THANKS) = 1989ce89fb3891420c9964dc418ab71c
MD5 (R-3/R-3.1.3.tar.gz) = 53a85b884925aa6b5811dfc361d73fc4


This is the relevant part of the NEWS file

CHANGES IN R 3.1.3:

  NEW FEATURES:

    * The internal method of download.file() can now handle files
      larger than 2GB on 32-bit builds which support such files (tested
      on 32-bit R running on 64-bit Windows).

    * kruskal.test() warns on more types of suspicious input.

    * The as.dendrogram() method for "hclust" objects gains a check
      argument protecting against memory explosion for invalid inputs.

    * capabilities() has a new item long.double which indicates if the
      build uses a long double type which is longer than double.

    * nlm() no longer modifies the callback argument in place (a new
      vector is allocated for each invocation, which mimics the
      implicit duplication that occurred in R < 3.1.0); note that this
      is a change from the previously documented behavior. (PR#15958)

    * icuSetCollate() now accepts locale = "ASCII" which uses the basic
      C function strcmp and so collates strings byte-by-byte in
      numerical order.

    * sessionInfo() tries to report the OS version in use (not just
      that compiled under, and including details of Linux
      distributions).

    * model.frame() (used by lm() and many other modelling functions)
      now warns when it drops contrasts from factors.  (Wish of
      PR#16119)

    * install.packages() and friends now accept the value type =
      "binary" as a synonym for the native binary type on the platform
      (if it has one).

    * Single source or binary files can be supplied for
      install.packages(type = "both") and the appropriate type and
      repos = NULL will be inferred.

    * New function pcre_config() to report on some of the configuration
      options of the version of PCRE in use.  In particular, this
      reports if regular expressions using \p{xx} are supported.

    * (Windows.) download.file(cacheOK = FALSE) is now supported when
      internet2.dll is used.

    * browseURL() has been updated to work with Firefox 36.0 which has
      dropped support for the -remote interface.

  INSTALLATION and INCLUDED SOFTWARE:

    * The included version of PCRE has been updated to 8.36.

    * configure accepts MAKEINFO=texi2any as another way to ensure
      texinfo 5.x is used when both 5.x and 4.x are installed.

  UTILITIES:

    * R CMD check now checks the packages used in \donttest sections of
      the examples are specified in the DESCRIPTION file.  (These are
      needed to run the examples interactively.)

    * R CMD check checks for the undeclared use of GNU extensions in
      Makefiles, and for Makefiles with a missing final linefeed.

      R CMD build will correct line endings in all Makefiles, not just
      those in the src directory.

    * R CMD check notes uses of library() and require() in package
      code: see the section 'Suggested packages' of 'Writing R
      Extensions' for good practice.

  DEPRECATED AND DEFUNCT:

    * The configure option --with-valgrind-instrumentation=3 is
      deprecated and will be removed in R 3.2.0.

  BUG FIXES:

    * (Windows.) Rscript.exe was missing a manifest specifying the
      modern style for common controls (e.g., the download progress
      bar).

    * If a package had extra documentation files but no vignette, the
      HTML help system produced an empty index page.

    * The parser now gives an error if a null character is included in
      a string using Unicode escapes. (PR#16046)

    * qr.Q() failed on complex arguments due to pre-3.0(!) typo.
      (PR#16054)

    * abs() failed with named arguments when the argument was complex.
      (PR#16047)

    * "noquote" objects may now be used as columns in dataframes.
      (PR#15997)

    * Some values with extremely long names were printed incorrectly.
      (PR#15999)

    * Extremely large exponents on zero expressed in scientific
      notation (e.g. 0.0e50000) could give NaN.  (PR#15976)

    * download.file() reported downloaded sizes as 0KB if less than
      1MB, only for R 3.1.2 and only on big-endian platforms.

    * prompt() did not escape percent signs in the automatically
      generated usage section of help files.

    * drop.terms() dropped some of the attributes of the object it was
      working with.  (PR#16029)

    * (Windows.) The command completion in Rgui.exe messed up the
      console.  (PR#15791)

    * (Windows.) The choose.files() command returned a blank string
      when the user asked for a single file but cancelled the request.
      (PR#16074)

    * Math2 S4 group generics failed to correctly dispatch "structure"-
      and "nonStructure"-derived classes.

    * loadNamespace() imposed undocumented restrictions on the
      versionCheck parameter.  (Reported by Geoff Lee.)

    * Rare over-runs detected by AddressSanitizer in substr() and its
      replacement version have been avoided.

      _Inter alia_ that fix gives the documented behaviour for
      substr(x, 1, 2) <- "" (subsequently reported as PR#16214).

    * Loading packages incorrectly defining an S4 generic followed by a
      function of the same name caused an erroneous cyclic namespace
      dependency error.

    * Declared vignette encodings are now always passed to the vignette
      engine.

    * Port Tomas Kalibera's fix from R-devel that restores the
      loadMethod() fast path, effectively doubling the speed of S4
      dispatch.

    * power.t.test() and power.prop.test() now make use of the
      extendInt option of uniroot() and hence work in more extreme
      cases.  (PR#15792)

    * If a package was updated and attached when its namespace was
      already loaded, it could end up with parts from one version and
      parts from the other.  (PR#16120)

    * tools:::.Rdconv() didn't accept --encoding= due to a typo.
      (PR#16121)

    * Unix-alike builds without a suitable makeinfo were documented to
      link the missing HTML manuals to CRAN, but did not.

    * save(*, ascii=TRUE) and load() now correctly deal with NaN's.
      (PR#16137)

    * split.Date() retains fractional representations while avoiding
      incomplete class propagation.

    * R_ext/Lapack.h had not been updated for changes made by LAPACK to
      the argument lists of its (largely internal) functions dlaed2 and
      dlaed3.  (PR#16157)

    * RShowDoc("NEWS", "txt") had not been updated for the layout
      changes of R 3.1.0.

    * The xtfrm() method for class "Surv" has been corrected and its
      description expanded.

    * mode(x) <- y would incorrectly evaluate x before changing its
      mode. (PR#16215)

    * besselJ(1, 2^64) and besselY(..) now signal a warning, returning
      NaN instead of typically segfaulting. (Issue 3 of PR#15554)

    * HTML conversion of \href markup in .Rd files did not remove the
      backslash from \% and so gave an invalid URL.  In a related
      change, the \ escape is now required in such URLs.



--
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From petr.pikal at precheza.cz  Mon Mar  9 10:53:43 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 9 Mar 2015 09:53:43 +0000
Subject: [R] problem with function that adds rows to dataframe based on
 conditional statement
In-Reply-To: <CAJmwvUYRn4F8vmddAEReK+Fx-O-qfbuzKNNNw_b77zTApDsmHw@mail.gmail.com>
References: <CAJmwvUadtpFODfCV3Qh+xHuiGvLH0DUSvehuMb_S-_dF6Rck5g@mail.gmail.com>
	<1425674907.11962.13.camel@maladmin.com>
	<CAJmwvUYRn4F8vmddAEReK+Fx-O-qfbuzKNNNw_b77zTApDsmHw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C22FEC@SRVEXCHMBX.precheza.cz>

Hi

As you do not accept solution with adding so many NA rows for those you do not have repetitions I think that merge together with some preparation is the way to go.

First of all do not use cbind when constructing data frame

comAn=data.frame(animals,animalYears,animalMass)

# indicator variable how many repetitions in each combination animal year have
comAn$ind<-ave(comAn$animalYears, paste(comAn$animals, comAn$animalYears), FUN=table)

# expected levels (depends on how many years and repetitions for each year do you have)
lev<-expand.grid(levels(comAn$animals), 1:2, 2)

# to correct names
names(lev)[1:2]<-names(comAn)[1:2]
names(lev)[3]<-"ind"

merge(lev, comAn, all=T)

leads to put NA to the row in which required combination is missing.

You can then propagate this NA to any column you wish.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Curtis
> Burkhalter
> Sent: Friday, March 06, 2015 10:01 PM
> To: Tom Wright
> Cc: r-help at r-project.org
> Subject: Re: [R] problem with function that adds rows to dataframe
> based on conditional statement
>
> Hey Tom,
>
> This solution works great, but if I try to then insert it in my
> function that I've displayed above and apply it to my split dataframe I
> get the error message:
>
> Error in `[.default`(xj, i) : invalid subscript type 'list'
>
> The reason why I need to try and get this to work within the function
> is that I'm trying to apply it to a much larger dataframe
> (nrow=12000,ncol=14). The actual data I'm working with consists of a
> sampling year, a site, and a bunch of response variables. For each
> sampling year by site combination I have 3 within year sampling
> occasions. For the sampling year by site combinations that don't have 3
> sampling events I need to fill in the missing occasions with the NAs.
>
> Can you see why I might be getting this error message?
>
> Thanks
>
>
>
> On Fri, Mar 6, 2015 at 1:48 PM, Tom Wright <tom at maladmin.com> wrote:
>
> > If all you want is to add a row of na's could you just do something
> > like:
> >
> > nExpectedRows<-length(unique(animals)) * length(unique(animalYears))
> *
> > 2
> >
> > newDf<-data.frame(animals=rep(NA,nExpectedRows-nrow(comAn)),
> >                   animalYears=rep(NA,nExpectedRows-nrow(comAn)),
> >                   animalMass=rep(NA,nExpectedRows-nrow(comAn)))
> >
> > comAn = rbind(comAn,newDf)
> >
> >
> >
> > On Thu, 2015-03-05 at 13:41 -0700, Curtis Burkhalter wrote:
> > > Hello everyone,
> > >
> > > I'm having a problem with a function that I wrote that is supposed
> > > to
> > add a
> > > row to dataframe based upon a conditional statement. To explain
> I've
> > > used an example below:
> > >
> > > #create data frame
> > > animals=c("bird","dog","cat")
> > > animals=rep(animals,each=4)
> > > animals=animals[1:11]
> > > animalYears=c(1,1,2,2,1,1,2,2,1,1,2)
> > > animalMass=round(runif(11,min=10,max=50),0)
> > >
> > > comAn=as.data.frame(cbind(animals,animalYears,animalMass))
> > > comAn
> > >
> > >   * animals* *animalYears* *animalMass*
> > > 1     bird           1         30
> > > 2     bird           1         32
> > > 3     bird           2         27
> > > 4     bird           2         16
> > > 5      dog           1         22
> > > 6      dog           1         25
> > > 7      dog           2         41
> > > 8      dog           2         22
> > > 9      cat           1         30
> > > 10     cat           1         37
> > > 11     cat           2         49
> > >
> > > We can see here that for every type of animal I have two years of
> > > mass measurements, except for the cat in year 2. What I want to do
> > > is add an additional row to the end of the dataframe that consists
> > > strictly of NAs and then I can substitute those out later.
> > >
> > > So what I first did was split the 'comAn' dataframe into the
> > > different Animal by Year combos.
> > >
> > > #This line splits 'com_An' into a list ordered by the Animal by
> Year
> > combos
> > > comAn_split=split(comAn, paste(comAn$animals,comAn$animalYear))
> > >
> > > Then I wrote the function that identifies whether a particular
> > > Animal by Year combo is less than two rows in length and if so it
> > > should add
> > another
> > > row that consists only of NAs using the vector 'NAs':
> > >
> > > #This function identifies the length of each Animal by Year combo
> > > and
> > then
> > > #uses the rbind function built in R to add a row #to each animal by
> > > year combo if they have less than 2 samples
> > >
> > > addNA <- function(comAn) {
> > >   NAs=c(NA,NA,NA)
> > >         ind <- seq_len(nrow(comAn))
> > >         comAn[ifelse(length(ind)<2,rbind(NAs),length(ind)),]
> > > }
> > >
> > > #This applies the function addNs to the animals data organized in
> > > list format addedNAcomAn <- do.call(rbind, lapply(comAn_split,
> > > addNA)) addedNAcomAn
> > >
> > > When I apply the function to the list of the different Animal by
> > > Year combos this is what I get:
> > >        animals animalYears animalMass
> > > bird 1    bird           1         23
> > > bird 2    bird           2         50
> > > cat 1      cat           1         15
> > > cat 2     <NA>        <NA>       <NA>
> > > dog 1      dog           1         23
> > > dog 2      dog           2         38
> > >
> > > What I expect is this:
> > >
> > >    animals animalYears animalMass
> > > 1     bird           1         41
> > > 2     bird           1         23
> > > 3     bird           2         23
> > > 4     bird           2         50
> > > 5      dog           1         49
> > > 6      dog           1         23
> > > 7      dog           2         13
> > > 8      dog           2         38
> > > 9      cat           1         42
> > > 10     cat           1         15
> > > 11     cat           2         33
> > > 12     NA           NA      NA
> > >
> > > Am I conditioning improperly within the function or am I missing
> > something
> > > else. Any help would be greatly appreciated.
> > >
> > > Best
> > >
> >
> >
> >
>
>
> --
> Curtis Burkhalter
>
> https://sites.google.com/site/curtisburkhalter/
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From kmezhoud at gmail.com  Mon Mar  9 11:41:31 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Mon, 9 Mar 2015 10:41:31 +0000
Subject: [R] Rstudio R-devel libR.so
Message-ID: <CALJKBv__2iVp1-4C+q513npuYQKqwiDQ+zD15eBMxhKOYyt7FQ@mail.gmail.com>

Dear All,
I am actually on R-devel using shell consol. When I run RStudio, it can't
find libR.so in the new /lib folder where is libRblas.so  libRlapack.so.
At first step I configure R-devel to share library with ./configure
--enable-R-shlib.

when I copied libR.so from  /usr/lib/R/lib/libR.so (stable version R 3.1)
to /usr/local/R-devel/lib/libR.so (R-devel version), That doesn't work.

please find the detail  at below.
Karim mezhoud




$which R
/usr/bin/R
$R
> R.Version()[13]
$version.string
[1] "R version 3.1.2 (2014-10-31)

> Sys.getenv("R_HOME")
[1] "/usr/lib/R"

> .Library
[1] "/usr/lib/R/library"
> .libPaths()
[1] "/home/mezhoud/R/x86_64-pc-linux-gnu-library/3.1"
[2] "/usr/local/lib/R/site-library"
[3] "/usr/lib/R/site-library"
[4] "/usr/lib/R/library"
"


$sudo apt-get build-dep r-base
$sudo apt-get install subversion ccache
$mkdir ~/svn/
$cd ~/svn/
$svn co https://svn.r-project.org/R/trunk r-devel/R

$cd /svn/r-devel/R
$./configure --enable-R-shlib
$make
$make check
$sudo make install rhome=/usr/local/R-devel

$which R
/usr/local/bin/R

$cd /usr/local/bin
$R

>R.Version()[13]
$version.string
[1] "R Under development (unstable) (2015-03-07 r67951)"

> .libPaths()
[1] "/usr/local/R-devel/library"
> .Library
[1] "/usr/local/R-devel/library"

> Sys.getenv("R_HOME")
[1] "/usr/local/R-devel"

$rstudio
R shared library (/usr/local/R-devel/lib/libR.so) not found.
If this is a custom build of R, was it built with the --enable-R-shlib
option?

$export RSTUDIO_WHICH_R=/usr/local/bin/R
$rstudio
R shared library (/usr/local/R-devel/lib/libR.so) not found.
If this is a custom build of R, was it built with the --enable-R-shlib
option?

$export RSTUDIO_WHICH_R=/usr/local/R-devel/bin/R
$rstudio
R shared library (/usr/local/R-devel/lib/libR.so) not found.
If this is a custom build of R, was it built with the --enable-R-shlib
option?

$sudo locate libR.so
/usr/lib/libR.so
/usr/lib/R/lib/libR.so

	[[alternative HTML version deleted]]


From kridox at ymail.com  Mon Mar  9 11:53:33 2015
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 9 Mar 2015 19:53:33 +0900
Subject: [R] Rstudio R-devel libR.so
In-Reply-To: <CALJKBv__2iVp1-4C+q513npuYQKqwiDQ+zD15eBMxhKOYyt7FQ@mail.gmail.com>
References: <CALJKBv__2iVp1-4C+q513npuYQKqwiDQ+zD15eBMxhKOYyt7FQ@mail.gmail.com>
Message-ID: <CAAcyNCyh6VP+F8DCh87G0Qa=xZc3x8poUym2NmbQs46CGjCGPg@mail.gmail.com>

Hello,

There is a dedicated support to RStudio here: https://support.rstudio.com

Regards,
Pascal

On Mon, Mar 9, 2015 at 7:41 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
> Dear All,
> I am actually on R-devel using shell consol. When I run RStudio, it can't
> find libR.so in the new /lib folder where is libRblas.so  libRlapack.so.
> At first step I configure R-devel to share library with ./configure
> --enable-R-shlib.
>
> when I copied libR.so from  /usr/lib/R/lib/libR.so (stable version R 3.1)
> to /usr/local/R-devel/lib/libR.so (R-devel version), That doesn't work.
>
> please find the detail  at below.
> Karim mezhoud
>
>
>
>
> $which R
> /usr/bin/R
> $R
>> R.Version()[13]
> $version.string
> [1] "R version 3.1.2 (2014-10-31)
>
>> Sys.getenv("R_HOME")
> [1] "/usr/lib/R"
>
>> .Library
> [1] "/usr/lib/R/library"
>> .libPaths()
> [1] "/home/mezhoud/R/x86_64-pc-linux-gnu-library/3.1"
> [2] "/usr/local/lib/R/site-library"
> [3] "/usr/lib/R/site-library"
> [4] "/usr/lib/R/library"
> "
>
>
> $sudo apt-get build-dep r-base
> $sudo apt-get install subversion ccache
> $mkdir ~/svn/
> $cd ~/svn/
> $svn co https://svn.r-project.org/R/trunk r-devel/R
>
> $cd /svn/r-devel/R
> $./configure --enable-R-shlib
> $make
> $make check
> $sudo make install rhome=/usr/local/R-devel
>
> $which R
> /usr/local/bin/R
>
> $cd /usr/local/bin
> $R
>
>>R.Version()[13]
> $version.string
> [1] "R Under development (unstable) (2015-03-07 r67951)"
>
>> .libPaths()
> [1] "/usr/local/R-devel/library"
>> .Library
> [1] "/usr/local/R-devel/library"
>
>> Sys.getenv("R_HOME")
> [1] "/usr/local/R-devel"
>
> $rstudio
> R shared library (/usr/local/R-devel/lib/libR.so) not found.
> If this is a custom build of R, was it built with the --enable-R-shlib
> option?
>
> $export RSTUDIO_WHICH_R=/usr/local/bin/R
> $rstudio
> R shared library (/usr/local/R-devel/lib/libR.so) not found.
> If this is a custom build of R, was it built with the --enable-R-shlib
> option?
>
> $export RSTUDIO_WHICH_R=/usr/local/R-devel/bin/R
> $rstudio
> R shared library (/usr/local/R-devel/lib/libR.so) not found.
> If this is a custom build of R, was it built with the --enable-R-shlib
> option?
>
> $sudo locate libR.so
> /usr/lib/libR.so
> /usr/lib/R/lib/libR.so
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From kmezhoud at gmail.com  Mon Mar  9 12:48:11 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Mon, 9 Mar 2015 11:48:11 +0000
Subject: [R] Rstudio R-devel libR.so
In-Reply-To: <CAAcyNCyh6VP+F8DCh87G0Qa=xZc3x8poUym2NmbQs46CGjCGPg@mail.gmail.com>
References: <CALJKBv__2iVp1-4C+q513npuYQKqwiDQ+zD15eBMxhKOYyt7FQ@mail.gmail.com>
	<CAAcyNCyh6VP+F8DCh87G0Qa=xZc3x8poUym2NmbQs46CGjCGPg@mail.gmail.com>
Message-ID: <CALJKBv96P6ZjxWO9JAxh6vg4fqZ4CGiJX0esEOK6zJMTyhYXqQ@mail.gmail.com>

Thanks Pascal. Not yet resolved.
Here is an example of symbolic link between libR.so
https://support.rstudio.com/hc/communities/public/questions/200661703-R-shared-library-usr-local-lib-R-lib-libR-so-not-found-UBUNTU-11-

When I get a symbolic link with:

 sudo ln -s  /usr/lib/R/lib/libR.so /usr/local/R-devel//lib/libR.so


The R session had a fatal error.


ERROR r error 4 (R code execution error) [errormsg=Error in
.Internal(getOption(x)) :

there is no .Internal function 'getOption'

]; OCCURRED AT: core::Error r::exec::evaluateString(const std::string&,
SEXPREC**, r::sexp::Protect*) /home/ubuntu/rstudio/src/cpp/r/RExec.cpp:



On Mon, Mar 9, 2015 at 10:53 AM, Pascal Oettli <kridox at ymail.com> wrote:

> Hello,
>
> There is a dedicated support to RStudio here: https://support.rstudio.com
>
> Regards,
> Pascal
>
> On Mon, Mar 9, 2015 at 7:41 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
> > Dear All,
> > I am actually on R-devel using shell consol. When I run RStudio, it can't
> > find libR.so in the new /lib folder where is libRblas.so  libRlapack.so.
> > At first step I configure R-devel to share library with ./configure
> > --enable-R-shlib.
> >
> > when I copied libR.so from  /usr/lib/R/lib/libR.so (stable version R 3.1)
> > to /usr/local/R-devel/lib/libR.so (R-devel version), That doesn't work.
> >
> > please find the detail  at below.
> > Karim mezhoud
> >
> >
> >
> >
> > $which R
> > /usr/bin/R
> > $R
> >> R.Version()[13]
> > $version.string
> > [1] "R version 3.1.2 (2014-10-31)
> >
> >> Sys.getenv("R_HOME")
> > [1] "/usr/lib/R"
> >
> >> .Library
> > [1] "/usr/lib/R/library"
> >> .libPaths()
> > [1] "/home/mezhoud/R/x86_64-pc-linux-gnu-library/3.1"
> > [2] "/usr/local/lib/R/site-library"
> > [3] "/usr/lib/R/site-library"
> > [4] "/usr/lib/R/library"
> > "
> >
> >
> > $sudo apt-get build-dep r-base
> > $sudo apt-get install subversion ccache
> > $mkdir ~/svn/
> > $cd ~/svn/
> > $svn co https://svn.r-project.org/R/trunk r-devel/R
> >
> > $cd /svn/r-devel/R
> > $./configure --enable-R-shlib
> > $make
> > $make check
> > $sudo make install rhome=/usr/local/R-devel
> >
> > $which R
> > /usr/local/bin/R
> >
> > $cd /usr/local/bin
> > $R
> >
> >>R.Version()[13]
> > $version.string
> > [1] "R Under development (unstable) (2015-03-07 r67951)"
> >
> >> .libPaths()
> > [1] "/usr/local/R-devel/library"
> >> .Library
> > [1] "/usr/local/R-devel/library"
> >
> >> Sys.getenv("R_HOME")
> > [1] "/usr/local/R-devel"
> >
> > $rstudio
> > R shared library (/usr/local/R-devel/lib/libR.so) not found.
> > If this is a custom build of R, was it built with the --enable-R-shlib
> > option?
> >
> > $export RSTUDIO_WHICH_R=/usr/local/bin/R
> > $rstudio
> > R shared library (/usr/local/R-devel/lib/libR.so) not found.
> > If this is a custom build of R, was it built with the --enable-R-shlib
> > option?
> >
> > $export RSTUDIO_WHICH_R=/usr/local/R-devel/bin/R
> > $rstudio
> > R shared library (/usr/local/R-devel/lib/libR.so) not found.
> > If this is a custom build of R, was it built with the --enable-R-shlib
> > option?
> >
> > $sudo locate libR.so
> > /usr/lib/libR.so
> > /usr/lib/R/lib/libR.so
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Pascal Oettli
> Project Scientist
> JAMSTEC
> Yokohama, Japan
>

	[[alternative HTML version deleted]]


From chrisaa at med.umich.edu  Mon Mar  9 12:51:07 2015
From: chrisaa at med.umich.edu (Andrews, Chris)
Date: Mon, 9 Mar 2015 11:51:07 +0000
Subject: [R] "survMisc" package
In-Reply-To: <CAGpBJKR6PKf=aJZiptw=wzsrD3WQ8vNxscfGrMA-F1-pjLZvNw@mail.gmail.com>
References: <CAGpBJKR6PKf=aJZiptw=wzsrD3WQ8vNxscfGrMA-F1-pjLZvNw@mail.gmail.com>
Message-ID: <30411786F64EEF46856EFBA2CD9177992C39AD9E@UHEXMBSPR03.umhs.med.umich.edu>

The package maintainer may be able to give help.  However, I don't get the same output as you (3.1.2).  Perhaps you can update and solve your problem.

> require(survMisc)
Loading required package: survMisc
Loading required package: survival
Loading required package: splines
Loading required package: ggplot2

Attaching package: ?survMisc?

The following object is masked from ?package:ggplot2?:

    autoplot

The following objects are masked from ?package:stats?:

    AIC, BIC, median, quantile

> data(kidney,package="KMsurv")
> s1 <- survfit(Surv(time=time, event=delta) ~ type, data=kidney )
> comp(s1)
$tne
       t   n e n_type=1 e_type=1 n_type=2 e_type=2
 1:  0.5 119 6       76        6       43        0
 2:  1.5 103 1       60        0       43        1
 3:  2.5  98 2       56        2       42        0
 4:  3.5  89 2       49        1       40        1
 5:  4.5  79 2       43        0       36        2
 6:  5.5  73 1       40        0       33        1
 7:  6.5  66 1       35        1       31        0
 8:  8.5  55 2       30        0       25        2
 9:  9.5  49 1       27        0       22        1
10: 10.5  45 1       25        0       20        1
11: 11.5  40 1       22        0       18        1
12: 15.5  25 2       14        1       11        1
13: 16.5  23 1       13        0       10        1
14: 18.5  20 1       11        0        9        1
15: 23.5   9 1        5        0        4        1
16: 26.5   5 1        3        0        2        1

$tests
$tests$lrTests
                                    ChiSq df       p
Log-rank                      2.529506318  1 0.11174
Gehan-Breslow (mod~ Wilcoxon) 0.002084309  1 0.96359
Tarone-Ware                   0.402738202  1 0.52568
Peto-Peto                     1.399160019  1 0.23686
Mod~ Peto-Peto (Andersen)     1.275908836  1 0.25866
Flem~-Harr~ with p=1, q=1     9.834062861  1 0.00171

$tests$supTests
                                       Q       p
Log-rank                        1.590442 0.22347
Gehan-Breslow (mod~ Wilcoxon)   1.430499 0.30511
Tarone-Ware                     1.260498 0.41467
Peto-Peto                       1.166979 0.48551
Mod~ Peto-Peto (Andersen)       1.185549 0.47085
Renyi Flem~-Harr~ with p=1, q=1 7.460348 0.00000




-----Original Message-----
From: Endy BlackEndy [mailto:pertsou at gmail.com] 
Sent: Sunday, March 08, 2015 12:44 PM
To: r-help
Subject: [R] "survMisc" package

Hi R users. I have some problems with the package ?survMisc?. When I am
loading it I am getting the following



> library(survMisc)

Loading required package: survival

Loading required package: splines

Loading required package: km.ci

Loading required package: ggplot2

Loading required package: data.table

data.table 1.9.4  For help type: ?data.table

*** NB: by=.EACHI is now explicit. See README to restore previous behaviour.

Loading required package: gridExtra

Loading required package: grid

Loading required package: rpart



Attaching package: ?survMisc?



The following objects are masked from ?package:stats?:



    AIC, BIC, median, quantile



   In the above output I noticed the line with the three stars (*). In
order to restore the data.table in its previous behavior I tried to locate
the README file but I couldn?t.

   I ignored that NB in the previous output and I continue to run the
example given in the above mentioned package for the routine comp(). The
commands and the output are given below.

> ### 2 curves

> data(kidney,package="KMsurv")

> s1 <- survfit(Surv(time=time, event=delta) ~ type, data=kidney )

> comp(s1)

$tne

       t          n          e   n_type=1   e_type=1   n_type=2   e_type=2

 1:  1.5    86         2       43                1
43                1

 2:  3.5    80         2       40                1
40                1

 3:  4.5    72         4       36                2
36                2

 4:  5.5    66         2       33                1
33                1

 5:  8.5    60         4       30                2                  30
           2

 6:  9.5    54         2       27                1
27                1

 7: 10.5   50         2       25                1
25                1

 8: 11.5    44         2       22               1
22                1

 9: 15.5    28         4       14               2
14                2

10: 16.5   26         2       13               1
13                1

11: 18.5   22         2       11               1
  11                1

12: 23.5     8         2        4                 1
4                1

13: 26.5     6         2        3                 1
3                1



$tests

$tests$lrTests

                                                        ChiSq df p

Log-rank                                                0  1 1

Gehan-Breslow (mod~ Wilcoxon)             0  1 1

Tarone-Ware                                          0  1 1

Peto-Peto                                              0  1 1

Mod~ Peto-Peto (Andersen)                    0  1 1

Flem~-Harr~ with p=1, q=1                      0  1 1



$tests$supTests

                                                             Q p

Log-rank                                                 0 1

Gehan-Breslow (mod~ Wilcoxon)              0 1

Tarone-Ware                                           0 1

Peto-Peto                                               0 1

Mod~ Peto-Peto (Andersen)                     0 1

Renyi Flem~-Harr~ with p=1, q=1             0 1



Notice the zeros (0) that corresponds to the test statistics. (To my
opinion those zeros are strongly related to the NB above).

   Next I noticed the following strange, to my opinion, thing.  More
precisely I have written the following
routine

proc<-function(){

 rm(list=ls())

 library(survMisc)

 d<-read.table("C:\\Program
Files\\R\\Data\\Survival\\HosmLem.txt",fill=TRUE,header=TRUE)

 d4<-as.factor(d[,4])

 s<-survfit(Surv(d[,2], d[,5])~d4)

 ctest<-comp(s)$tests

 print(ctest)

}

The data used are those of Hosmer and Lemeshow book on Applied Survival
Analysis. The first rows of this data set follow.

id Time Age Drug Censor    entdate    enddate

  1    5  46    0      1   05/15/1990 10/14/1990

  2    6  35    1      0   09/19/1989 03/20/1990

  3    8  30    1      1   04/21/1991 12/20/1991

  4    3  30    1      1   01/03/1991 04/04/1991

  5   22  36    0      1   09/18/1989 07/19/1991

  6    1  32    1      0    03/18/1991 04/17/1991

When I run the function proc() I am getting the answer

> proc()

Error in Surv(d[, 2], d[, 5]) : object 'd' not found

In contrast when I run the same routine command-by-command I am getting the
following output

$lrTests

                                                         ChiSq df p

Log-rank                                                 0  1 1

Gehan-Breslow (mod~ Wilcoxon)              0  1 1

Tarone-Ware                                           0  1 1

Peto-Peto                                               0  1 1

Mod~ Peto-Peto (Andersen)                     0  1 1

Flem~-Harr~ with p=1, q=1                       0  1 1



$supTests

                                                              Q p

Log-rank                                                  0 1

Gehan-Breslow (mod~ Wilcoxon)               0 1

Tarone-Ware                                            0 1

Peto-Peto                                                0 1

Mod~ Peto-Peto (Andersen)                      0 1

Renyi Flem~-Harr~ with p=1, q=1              0 1

Any assistance will greatly appreciated.

Cheers

Endy

I am using the

R version 3.1.1 (2014-07-10) -- "Sock it to Me"

Copyright (C) 2014 The R Foundation for Statistical Computing

Platform: i386-w64-mingw32/i386 (32-bit)

	[[alternative HTML version deleted]]


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 

From leandromarino at leandromarino.com.br  Mon Mar  9 14:47:56 2015
From: leandromarino at leandromarino.com.br (Leandro Marino)
Date: Mon, 9 Mar 2015 10:47:56 -0300
Subject: [R] Show all elements
Message-ID: <CAKSaaFnUfs4+KarQ8ZAsnBu7rW7C=isAnKYaW5UfXxk6=v=5Vg@mail.gmail.com>

Hi,

Look to the following code:

set.seed(1)
dados =
data.frame(valor=rnorm(100),var=sample(LETTERS[c(1,2,3,5)],100,replace=T),peso=rpois(100,2))
dados[1:10,]
dados$var <- factor(dados$var,levels=LETTERS[1:5])
table(dados$var)
 A  B  C  D  E
31 31 19  0 19

When I try to use summarize, Hmisc package it shows me the result without D
category.

g1 <- function(y) wtd.mean(y[,1],y[,2])
summarize(dados[,c(1,3)], llist(var=dados$var), g1,stat.name = 'med')
  var         med
1   A  0.02589377
2   B  0.37123239
3   C -0.57820359
4   E  0.39584514

How do I get med = NA or something else with summarize?

I realy need to the function to return all factors in the var even it they
are an empty set.

thanks in advance.

leandro

	[[alternative HTML version deleted]]


From darwinm13sg37 at hotmail.com  Mon Mar  9 03:08:54 2015
From: darwinm13sg37 at hotmail.com (saran wai)
Date: Mon, 9 Mar 2015 09:08:54 +0700
Subject: [R] R: Reverse Complementary Base Problem
Message-ID: <SNT146-W803594081108622A107F78B71B0@phx.gbl>

Hi I'm new to R programming and trying to write program for Reverse and Complementary Base. the objective is to Design A DNA primer. So I have a DNA sequence with base A T C G and A complement to T; T=A;C=G;G=C.  I just figure out How to Reverse It Already. but for the Complement i can only make it answer for just 1 base but cant be all of the sequence.  and i dont know how to combine reverse and complement function. here is my code and im totallt confuse with it. Cn someone help me with this problem? You will be my life savior! thank you! strReverse <- function(x)   sapply(lapply(strsplit(x, NULL), rev), paste, collapse="") strReverse(c("ATCGGTCAATCGA")) complement.base = function(base){   if(base == 'A' | base ==  'a')   print("T")   if(base == 'T' | base == 't') print("A")   if(base == 'G' | base == 'g') print("C")   if(base == 'C' | base == 'c') print("G")} complement.base(base="A") 		 	   		  
	[[alternative HTML version deleted]]


From Matthias.Weber at fntsoftware.com  Mon Mar  9 13:45:50 2015
From: Matthias.Weber at fntsoftware.com (Matthias Weber)
Date: Mon, 9 Mar 2015 13:45:50 +0100
Subject: [R] calculate value in dependence of target value
Message-ID: <7E39CF5278A2C948968C39502CF451020174D1BE2E96@mail.ell.fnt.de>

Hello together,

i have a litte problem. Maybe anyone can help me.

I have to calculate a new column in dependence of a target value.

As a example: My target value is 100.000
At the moment I have a data.frame with the following values.

     ID    VALUE
1   11    10000
2   12    50000
3   13    30000
4   14    20000

The new column ("MARGE") should be calculated with the following graduation:
Until the VALUE reach 50% of the target value (50.000) = 2%
Until the VALUE reach 75% of the target value (75.000) = 4%
Until the VALUE reach 100% of the target value (<100.000) = 8%
If the VALUE goes above 100% of the value (>100.000) = 10%

The result looks like this one:

     ID    VALUE  MARGE
1   11    10000          200      (result of 10.000 * 2%)
2   12    50000         1200     (result of 40.000 * 2% + 10.000 * 4%)
3   13    30000         1800     (result of 15.000 * 4% + 15.000 * 8%)
4   14    20000         1800     (result of 10.000 * 8% + 10.000 * 10%)

Is there anyway to calculate the column "MARGE" automatically in R?

Thanks a lot for your help.

Best regards.

Mat

________________________________
This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.

Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.

	[[alternative HTML version deleted]]


From loris.bennett at fu-berlin.de  Mon Mar  9 14:55:39 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Mon, 9 Mar 2015 14:55:39 +0100
Subject: [R] Add sum line to plot of multiple x values
Message-ID: <87k2yqs2as.fsf@hornfels.zedat.fu-berlin.de>

Hi,

Here are my data:

> d
   user files       date
1 alice    18 2013-09-15
2   bob     5 2013-09-15
3 carol    21 2013-09-15
4 alice    22 2013-09-08
5   bob     9 2013-09-08
6 carol    14 2013-09-08
7 alice    26 2013-09-01
8   bob     3 2013-09-01
9 carol    22 2013-09-01

I would like to plot the number of files against date for all users, so
I have:

  library(ggplot2)

  people <- c("alice","bob","carol")
  user <- c(rep(people,3))
  files <- c(18,5,21,22,9,14,26,3,22)
  date <- c(rep("2013-09-15",3),rep("2013-09-08",3),rep("2013-09-01",3))
  d <- data.frame(user=user,files=files,date=date)

  p <- ggplot()
  p <- p + geom_line(data=d,aes(x=date,y=files,group=user,colour=user))

I would now like to add a line to show the total number of files as a
function of date.  I tried

  p <- p + geom_line(data=d,aes(x=date,y=sum(files),group=date),colour='black')

I don't get a black line, but the plot is scaled such that I can see
that sum(file) for all values of 'file', rather than those for each
date, is being used.

I would like to know how to do this correctly, but I would rather be
able to work it out for myself.  However, if I decide, say, that I don't
know exactly what the 'group' argument does, how do I find it out?

?geom_line doesn't have it, although the examples there use it. ?ggplot
doesn't mention it. ?group gives me stuff about formatting text
arguments. ??group only leads me to ?ggplot2::add_group, which also does
not seem to help. 

Am I at fault for trying to learn R in an ad hoc manner, to which the
documentation of R does not lend itself, or am I missing something?

Cheers,

Loris

-- 
This signature is currently under construction.


From jdnewmil at dcn.davis.CA.us  Mon Mar  9 15:37:07 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 09 Mar 2015 07:37:07 -0700
Subject: [R] Rstudio R-devel libR.so
In-Reply-To: <CALJKBv96P6ZjxWO9JAxh6vg4fqZ4CGiJX0esEOK6zJMTyhYXqQ@mail.gmail.com>
References: <CALJKBv__2iVp1-4C+q513npuYQKqwiDQ+zD15eBMxhKOYyt7FQ@mail.gmail.com>
	<CAAcyNCyh6VP+F8DCh87G0Qa=xZc3x8poUym2NmbQs46CGjCGPg@mail.gmail.com>
	<CALJKBv96P6ZjxWO9JAxh6vg4fqZ4CGiJX0esEOK6zJMTyhYXqQ@mail.gmail.com>
Message-ID: <35EF0083-3352-4227-B280-0C9E02C2C53E@dcn.davis.CA.us>

Please read the Posting Guide. Unreleased versions of R are off-topic in this mailing list (see the R-devel mailing list). RStudio-specific questions are also off-topic here (should be about R, not IDEs).
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 9, 2015 4:48:11 AM PDT, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>Thanks Pascal. Not yet resolved.
>Here is an example of symbolic link between libR.so
>https://support.rstudio.com/hc/communities/public/questions/200661703-R-shared-library-usr-local-lib-R-lib-libR-so-not-found-UBUNTU-11-
>
>When I get a symbolic link with:
>
> sudo ln -s  /usr/lib/R/lib/libR.so /usr/local/R-devel//lib/libR.so
>
>
>The R session had a fatal error.
>
>
>ERROR r error 4 (R code execution error) [errormsg=Error in
>.Internal(getOption(x)) :
>
>there is no .Internal function 'getOption'
>
>]; OCCURRED AT: core::Error r::exec::evaluateString(const std::string&,
>SEXPREC**, r::sexp::Protect*) /home/ubuntu/rstudio/src/cpp/r/RExec.cpp:
>
>
>
>On Mon, Mar 9, 2015 at 10:53 AM, Pascal Oettli <kridox at ymail.com>
>wrote:
>
>> Hello,
>>
>> There is a dedicated support to RStudio here:
>https://support.rstudio.com
>>
>> Regards,
>> Pascal
>>
>> On Mon, Mar 9, 2015 at 7:41 PM, Karim Mezhoud <kmezhoud at gmail.com>
>wrote:
>> > Dear All,
>> > I am actually on R-devel using shell consol. When I run RStudio, it
>can't
>> > find libR.so in the new /lib folder where is libRblas.so 
>libRlapack.so.
>> > At first step I configure R-devel to share library with ./configure
>> > --enable-R-shlib.
>> >
>> > when I copied libR.so from  /usr/lib/R/lib/libR.so (stable version
>R 3.1)
>> > to /usr/local/R-devel/lib/libR.so (R-devel version), That doesn't
>work.
>> >
>> > please find the detail  at below.
>> > Karim mezhoud
>> >
>> >
>> >
>> >
>> > $which R
>> > /usr/bin/R
>> > $R
>> >> R.Version()[13]
>> > $version.string
>> > [1] "R version 3.1.2 (2014-10-31)
>> >
>> >> Sys.getenv("R_HOME")
>> > [1] "/usr/lib/R"
>> >
>> >> .Library
>> > [1] "/usr/lib/R/library"
>> >> .libPaths()
>> > [1] "/home/mezhoud/R/x86_64-pc-linux-gnu-library/3.1"
>> > [2] "/usr/local/lib/R/site-library"
>> > [3] "/usr/lib/R/site-library"
>> > [4] "/usr/lib/R/library"
>> > "
>> >
>> >
>> > $sudo apt-get build-dep r-base
>> > $sudo apt-get install subversion ccache
>> > $mkdir ~/svn/
>> > $cd ~/svn/
>> > $svn co https://svn.r-project.org/R/trunk r-devel/R
>> >
>> > $cd /svn/r-devel/R
>> > $./configure --enable-R-shlib
>> > $make
>> > $make check
>> > $sudo make install rhome=/usr/local/R-devel
>> >
>> > $which R
>> > /usr/local/bin/R
>> >
>> > $cd /usr/local/bin
>> > $R
>> >
>> >>R.Version()[13]
>> > $version.string
>> > [1] "R Under development (unstable) (2015-03-07 r67951)"
>> >
>> >> .libPaths()
>> > [1] "/usr/local/R-devel/library"
>> >> .Library
>> > [1] "/usr/local/R-devel/library"
>> >
>> >> Sys.getenv("R_HOME")
>> > [1] "/usr/local/R-devel"
>> >
>> > $rstudio
>> > R shared library (/usr/local/R-devel/lib/libR.so) not found.
>> > If this is a custom build of R, was it built with the
>--enable-R-shlib
>> > option?
>> >
>> > $export RSTUDIO_WHICH_R=/usr/local/bin/R
>> > $rstudio
>> > R shared library (/usr/local/R-devel/lib/libR.so) not found.
>> > If this is a custom build of R, was it built with the
>--enable-R-shlib
>> > option?
>> >
>> > $export RSTUDIO_WHICH_R=/usr/local/R-devel/bin/R
>> > $rstudio
>> > R shared library (/usr/local/R-devel/lib/libR.so) not found.
>> > If this is a custom build of R, was it built with the
>--enable-R-shlib
>> > option?
>> >
>> > $sudo locate libR.so
>> > /usr/lib/libR.so
>> > /usr/lib/R/lib/libR.so
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Pascal Oettli
>> Project Scientist
>> JAMSTEC
>> Yokohama, Japan
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Mar  9 15:50:44 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 9 Mar 2015 14:50:44 +0000
Subject: [R] Add sum line to plot of multiple x values
In-Reply-To: <87k2yqs2as.fsf@hornfels.zedat.fu-berlin.de>
References: <87k2yqs2as.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C231CF@SRVEXCHMBX.precheza.cz>

Hi

Not extremely clear what do you want to plot. Do you want to add a line which marks total number of files each day regardless of user? Or a total number of files regardless of date coloured by user?

In each case you shall search functions geom_hline or geom_abline

http://stackoverflow.com/questions/13254441/add-a-horizontal-line-to-plot-and-legend-in-ggplot2

ggplot is rather complicated but very flexible

Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Loris
> Bennett
> Sent: Monday, March 09, 2015 2:56 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Add sum line to plot of multiple x values
>
> Hi,
>
> Here are my data:
>
> > d
>    user files       date
> 1 alice    18 2013-09-15
> 2   bob     5 2013-09-15
> 3 carol    21 2013-09-15
> 4 alice    22 2013-09-08
> 5   bob     9 2013-09-08
> 6 carol    14 2013-09-08
> 7 alice    26 2013-09-01
> 8   bob     3 2013-09-01
> 9 carol    22 2013-09-01
>
> I would like to plot the number of files against date for all users, so
> I have:
>
>   library(ggplot2)
>
>   people <- c("alice","bob","carol")
>   user <- c(rep(people,3))
>   files <- c(18,5,21,22,9,14,26,3,22)
>   date <- c(rep("2013-09-15",3),rep("2013-09-08",3),rep("2013-09-
> 01",3))
>   d <- data.frame(user=user,files=files,date=date)
>
>   p <- ggplot()
>   p <- p + geom_line(data=d,aes(x=date,y=files,group=user,colour=user))
>
> I would now like to add a line to show the total number of files as a
> function of date.  I tried
>
>   p <- p +
> geom_line(data=d,aes(x=date,y=sum(files),group=date),colour='black')
>
> I don't get a black line, but the plot is scaled such that I can see
> that sum(file) for all values of 'file', rather than those for each
> date, is being used.
>
> I would like to know how to do this correctly, but I would rather be
> able to work it out for myself.  However, if I decide, say, that I
> don't
> know exactly what the 'group' argument does, how do I find it out?
>
> ?geom_line doesn't have it, although the examples there use it. ?ggplot
> doesn't mention it. ?group gives me stuff about formatting text
> arguments. ??group only leads me to ?ggplot2::add_group, which also
> does
> not seem to help.
>
> Am I at fault for trying to learn R in an ad hoc manner, to which the
> documentation of R does not lend itself, or am I missing something?
>
> Cheers,
>
> Loris
>
> --
> This signature is currently under construction.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From boris.steipe at utoronto.ca  Mon Mar  9 15:54:15 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 9 Mar 2015 10:54:15 -0400
Subject: [R] R: Reverse Complementary Base Problem
In-Reply-To: <SNT146-W803594081108622A107F78B71B0@phx.gbl>
References: <SNT146-W803594081108622A107F78B71B0@phx.gbl>
Message-ID: <DEADD151-7CA0-4F06-9D3C-25A0A68FD875@utoronto.ca>

Use reverseComplement() in the Biostrings package.
B.


On Mar 8, 2015, at 10:08 PM, saran wai <darwinm13sg37 at hotmail.com> wrote:

> Hi I'm new to R programming and trying to write program for Reverse and Complementary Base. the objective is to Design A DNA primer. So I have a DNA sequence with base A T C G and A complement to T; T=A;C=G;G=C.  I just figure out How to Reverse It Already. but for the Complement i can only make it answer for just 1 base but cant be all of the sequence.  and i dont know how to combine reverse and complement function. here is my code and im totallt confuse with it. Cn someone help me with this problem? You will be my life savior! thank you! strReverse <- function(x)   sapply(lapply(strsplit(x, NULL), rev), paste, collapse="") strReverse(c("ATCGGTCAATCGA")) complement.base = function(base){   if(base == 'A' | base ==  'a')   print("T")   if(base == 'T' | base == 't') print("A")   if(base == 'G' | base == 'g') print("C")   if(base == 'C' | base == 'c') print("G")} complement.base(base="A") 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Mar  9 16:07:37 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 9 Mar 2015 15:07:37 +0000
Subject: [R] calculate value in dependence of target value
In-Reply-To: <7E39CF5278A2C948968C39502CF451020174D1BE2E96@mail.ell.fnt.de>
References: <7E39CF5278A2C948968C39502CF451020174D1BE2E96@mail.ell.fnt.de>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D66CF7C@mb02.ads.tamu.edu>

It is very hard to figure out what you are trying to do. 

1. All of the VALUEs are greater than the target of 100
2. Your description of what you want does not match your example.

Perhaps VALUE should be divided by 1000 (e.g. not 10000, but 10)?
Perhaps your targets do not apply to VALUE, but to cumulative VALUE?

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matthias Weber
Sent: Monday, March 9, 2015 7:46 AM
To: r-help at r-project.org
Subject: [R] calculate value in dependence of target value

Hello together,

i have a litte problem. Maybe anyone can help me.

I have to calculate a new column in dependence of a target value.

As a example: My target value is 100.000
At the moment I have a data.frame with the following values.

     ID    VALUE
1   11    10000
2   12    50000
3   13    30000
4   14    20000

The new column ("MARGE") should be calculated with the following graduation:
Until the VALUE reach 50% of the target value (50.000) = 2%
Until the VALUE reach 75% of the target value (75.000) = 4%
Until the VALUE reach 100% of the target value (<100.000) = 8%
If the VALUE goes above 100% of the value (>100.000) = 10%

The result looks like this one:

     ID    VALUE  MARGE
1   11    10000          200      (result of 10.000 * 2%)
2   12    50000         1200     (result of 40.000 * 2% + 10.000 * 4%)
3   13    30000         1800     (result of 15.000 * 4% + 15.000 * 8%)
4   14    20000         1800     (result of 10.000 * 8% + 10.000 * 10%)

Is there anyway to calculate the column "MARGE" automatically in R?

Thanks a lot for your help.

Best regards.

Mat

________________________________
This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.

Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Mon Mar  9 16:59:25 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 9 Mar 2015 15:59:25 +0000
Subject: [R] Extract year from date
In-Reply-To: <05AB7693-1D99-497F-BCEE-FD2A6344B7C1@gmail.com>
References: <05AB7693-1D99-497F-BCEE-FD2A6344B7C1@gmail.com>
Message-ID: <D1230CFF.1218F1%macqueen1@llnl.gov>

You need to solve step 1 (converting to Date class) before you can solve
step 2 (getting the year as a number).

In the data you are starting with, the first value in the Date column is
41163. You don't say whether that column is numeric or character, so let's
try it both ways:

> as.Date('41163','%m/%d/%Y')
[1] NA

> as.Date(41163,'%m/%d/%Y')
Error in charToDate(x) :
  character string is not in a standard unambiguous format


Whatever it is, it is not formatted "%m/%d/%Y", so step 1 fails.


On the other hand, if you start with something that is in fact formatted
as a date:

> tmp <-  as.Date('3/2/2015','%m/%d/%Y')
> format(tmp,'%Y')
[1] "2015"
> as.numeric(format(tmp,'%Y'))
[1] 2015


you get the year as a number, using the method you tried.

So, what do 41163 and all the rest of the numbers in your Date column
actually represent???

Mark Sharp is probably correct in expecting that they represent the number
of days since some base date, and an easy way to see that would be to try
the core of step 1:

> as.Date(41163)
Error in as.Date.numeric(41163) : 'origin' must be supplied

It would be up to you, of course, to find out what the origin is. If
1/1/1900 is correct, then


> as.numeric( format( as.Date( 41163, origin='1900-1-1'), '%Y'))
[1] 2012


(I personally prefer to use base R as much as possible)

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/7/15, 11:50 PM, "Steve Archambault" <archstevej at gmail.com> wrote:

>Hi all,
>
>I am trying in vain to create a new object "Year" in my data frame from
>existing Date data. I have tried many different approaches, but can't seem
>to get it to work. Here is an example of some code I tried.
>
>date1<- as.Date(wells$Date,"%m/%d/%Y")
>wells$year<-as.numeric(format(date1, "%Y"))
>
>I am starting with data that looks like this.
>
>        ID  Date DepthtoWater_bgs test test2
>1  BC-0004 41163           260.60    3     1
>2  BC-0004 41255           261.65    4     2
>3  BC-0003 41345           166.58    5     3
>4  BC-0002 41351           317.85    6     4
>5  BC-0004 41355           262.15    7     5
>6  BC-0003 41438           167.55    8     6
>7  BC-0004 41438           265.45    9     7
>8  BC-0002 41443           317.25   10     8
>9  BC-0002 41521           321.25   11     9
>10 BC-0003 41522           168.65   12    10
>11 BC-0004 41522           266.15   13    11
>12 BC-0003 41627           168.95   14    12
>13 BC-0004 41627           265.25   15    13
>14 BC-0002 41634           312.31   16    14
>15 BC-0003 41703           169.25   17    15
>16 BC-0004 41703           265.05   18    16
>17 BC-0002 41710           313.01   19    17
>18 BC-0003 41795           168.85   20    18
>19 BC-0004 41795           266.95   21    19
>20 BC-0002 41801           330.41   22    20
>21 BC-0003 41905           169.75   23    21
>22 BC-0004 41905           267.75   24    22
>23 BC-0002 41906           321.01   25    23
>
>Any help would be greatly appreciated!
>
>-Steve
>Sent from my iPhone
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sophia.kyriakou17 at gmail.com  Mon Mar  9 15:18:06 2015
From: sophia.kyriakou17 at gmail.com (Sophia Kyriakou)
Date: Mon, 9 Mar 2015 16:18:06 +0200
Subject: [R] Help with optim() to maximize log-likelihood
Message-ID: <CAO4gA+qokumHoZwvbU7EY3xaBBo2LnQjRcWxQkzcHm3U9OZ6kw@mail.gmail.com>

hello, I am using the optim function to maximize the log likelihood of a
generalized linear mixed model and I am trying to replicate glmer's
estimated components. If I set both the sample and subject size to q=m=100
I replicate glmer's results for the random intercept model with parameters
 beta=-1 and sigma^2=1. But if I change beta to 2 glmer works and optim
gives me the error message "function cannot be evaluated at initial
parameters".

If anyone could please help?
Thanks

 # likelihood function
 ll <- function(x,Y,m){
 beta <- x[1]
 psi <- x[2]
 q <- length(Y)
  p <- 20
 rule20 <- gaussHermiteData(p)
 wStar <- exp(rule20$x * rule20$x + log(rule20$w))
 # Integrate over(-Inf, +Inf) using adaptive Gauss-Hermite quadrature
 g <- function(alpha, beta, psi, y, m) {-y+m*exp(alpha + beta)/(1 +
exp(alpha + beta)) + alpha/exp(psi)}
 DDfLik <- deriv(expression(-y+m*exp(alpha + beta)/(1 + exp(alpha + beta))
+ alpha/exp(psi)),
 namevec = "alpha", func = TRUE,function.arg = c("alpha", "beta", "psi",
"y", "m"))
   int0 <- rep(NA,q)
 piYc_ir <- matrix(NA,q,p)
 for (i in 1:q){
 muHat <- uniroot(g, c(-10, 10),extendInt ="yes", beta = beta, psi = psi, y
= Y[i], m = m)$root
 jHat <- attr(DDfLik(alpha = muHat, beta, psi, Y[i], m), "gradient")
 sigmaHat <- 1/sqrt(jHat)
 z <- muHat + sqrt(2) * sigmaHat * rule20$x
 piYc_ir[i,] <-
choose(m,Y[i])*exp(Y[i]*(z+beta))*exp(-z^2/(2*exp(psi)))/((1+exp(z+beta))^m*sqrt(2*pi*exp(psi)))
 int0[i] <- sqrt(2)*sigmaHat*sum(wStar*piYc_ir[i,])
 }
 ll <- -sum(log(int0))
 ll
 }

 beta <- 2
 sigma2 <- 1
 m <- 100
 q <- 100

 cl <- seq.int(q)
 tot <- rep(m,q)

 set.seed(123)
 alpha <- rnorm(q, 0, sqrt(sigma2))
 Y <- rbinom(q,m,plogis(alpha+beta))

 dat <- data.frame(y = Y, tot = tot, cl = cl)
 f1 <- glmer(cbind(y, tot - y) ~ 1 + (1 | cl), data = dat,family =
binomial(),nAGQ = 20)
 betaH <- summary(f1)$coefficients[1]
 sigma2H <- as.numeric(summary(f1)$varcor)
 thetaglmer <- c(betaH,sigma2H)

 logL <- function(x) ll(x,Y,m)
 thetaMLb <- optim(c(plogis(sum(Y/m)),log(sigma2H)),fn=logL)$par
 Error in optim(c(plogis(sum(Y/m)), log(sigma2H)), fn = logL) :  function
cannot be evaluated at initial parameters

thetaglmer
[1] 2.1128529 0.8311484
 (thetaML <- c(thetaMLb[1],exp(thetaMLb[2])))

	[[alternative HTML version deleted]]


From Matthias.Weber at fntsoftware.com  Mon Mar  9 16:25:12 2015
From: Matthias.Weber at fntsoftware.com (Matthias Weber)
Date: Mon, 9 Mar 2015 16:25:12 +0100
Subject: [R] calculate value in dependence of target value
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D66CF7C@mb02.ads.tamu.edu>
References: <7E39CF5278A2C948968C39502CF451020174D1BE2E96@mail.ell.fnt.de>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D66CF7C@mb02.ads.tamu.edu>
Message-ID: <7E39CF5278A2C948968C39502CF451020174D1BE2E9B@mail.ell.fnt.de>

Hi David,

thanks for the reply. My spelling of the numbers was not correct. What I mean with 100.000 is 100000.00 !
I have corrected the values in my example below me.

Maybe you can understand it better now.

Crucially is, that the "MARGE" rises up in dependence of the ID. The ID 11 will be count with 2% because we don't reach the 50% hurdle (50000). The ID 12 will reach the 50% hurdle, so the ID 12 should be count with 1200 (result of 40000 * 2% + 10000 * 4%). The 10000 with 4% will be credited more, because they exceed the 50% Target Value.

Thanks for your help.

Best regards.

Mat

-----Urspr?ngliche Nachricht-----
Von: David L Carlson [mailto:dcarlson at tamu.edu]
Gesendet: Montag, 9. M?rz 2015 16:08
An: Matthias Weber; r-help at r-project.org
Betreff: RE: calculate value in dependence of target value

It is very hard to figure out what you are trying to do.

1. All of the VALUEs are greater than the target of 100 2. Your description of what you want does not match your example.

Perhaps VALUE should be divided by 1000 (e.g. not 10000, but 10)?
Perhaps your targets do not apply to VALUE, but to cumulative VALUE?

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matthias Weber
Sent: Monday, March 9, 2015 7:46 AM
To: r-help at r-project.org
Subject: [R] calculate value in dependence of target value

Hello together,

i have a litte problem. Maybe anyone can help me.

I have to calculate a new column in dependence of a target value.

As a example: My target value is 100000. At the moment I have a data.frame with the following values.

     ID    VALUE
1   11    10000
2   12    50000
3   13    30000
4   14    20000

The new column ("MARGE") should be calculated with the following graduation:
Until the VALUE reach 50% of the target value (50000) = 2%

Until the VALUE reach 75% of the target value (75000) = 4%

Until the VALUE reach 100% of the target value (<100000) = 8%

If the VALUE goes above 100% of the value (>100000) = 10%

The result looks like this one:

     ID    VALUE  MARGE
1   11    10000          200      (result of 10000 * 2%)
2   12    50000         1200     (result of 40000 * 2% + 10000 * 4%)
3   13    30000         1800     (result of 15000 * 4% + 15000 * 8%)
4   14    20000         1800     (result of 10000 * 8% + 10000 * 10%)

Is there anyway to calculate the column "MARGE" automatically in R?

Thanks a lot for your help.

Best regards.

Mat

This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.

Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.


From loris.bennett at fu-berlin.de  Mon Mar  9 16:34:52 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Mon, 9 Mar 2015 16:34:52 +0100
Subject: [R] Add sum line to plot of multiple x values
References: <87k2yqs2as.fsf@hornfels.zedat.fu-berlin.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C231CF@SRVEXCHMBX.precheza.cz>
Message-ID: <87fv9erxpf.fsf@hornfels.zedat.fu-berlin.de>

PIKAL Petr <petr.pikal at precheza.cz> writes:

> Hi
>
> Not extremely clear what do you want to plot. Do you want to add a
> line which marks total number of files each day regardless of user? Or
> a total number of files regardless of date coloured by user?

Sorry, I was unclear.  I meant that I would like to plot the following:

1. For each user: the number of files for each date (my code does this)
2. The sum of files of all users for each date (this is what I still
   need) 

> In each case you shall search functions geom_hline or geom_abline
>
> http://stackoverflow.com/questions/13254441/add-a-horizontal-line-to-plot-and-legend-in-ggplot2

So I don't want a straight line

> ggplot is rather complicated but very flexible

I don't mind ggplot being complicated, but I find the documentation a
little impenetrable.

Cheers,

Loris


>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Loris
>> Bennett
>> Sent: Monday, March 09, 2015 2:56 PM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] Add sum line to plot of multiple x values
>>
>> Hi,
>>
>> Here are my data:
>>
>> > d
>>    user files       date
>> 1 alice    18 2013-09-15
>> 2   bob     5 2013-09-15
>> 3 carol    21 2013-09-15
>> 4 alice    22 2013-09-08
>> 5   bob     9 2013-09-08
>> 6 carol    14 2013-09-08
>> 7 alice    26 2013-09-01
>> 8   bob     3 2013-09-01
>> 9 carol    22 2013-09-01
>>
>> I would like to plot the number of files against date for all users, so
>> I have:
>>
>>   library(ggplot2)
>>
>>   people <- c("alice","bob","carol")
>>   user <- c(rep(people,3))
>>   files <- c(18,5,21,22,9,14,26,3,22)
>>   date <- c(rep("2013-09-15",3),rep("2013-09-08",3),rep("2013-09-
>> 01",3))
>>   d <- data.frame(user=user,files=files,date=date)
>>
>>   p <- ggplot()
>>   p <- p + geom_line(data=d,aes(x=date,y=files,group=user,colour=user))
>>
>> I would now like to add a line to show the total number of files as a
>> function of date.  I tried
>>
>>   p <- p +
>> geom_line(data=d,aes(x=date,y=sum(files),group=date),colour='black')
>>
>> I don't get a black line, but the plot is scaled such that I can see
>> that sum(file) for all values of 'file', rather than those for each
>> date, is being used.
>>
>> I would like to know how to do this correctly, but I would rather be
>> able to work it out for myself.  However, if I decide, say, that I
>> don't
>> know exactly what the 'group' argument does, how do I find it out?
>>
>> ?geom_line doesn't have it, although the examples there use it. ?ggplot
>> doesn't mention it. ?group gives me stuff about formatting text
>> arguments. ??group only leads me to ?ggplot2::add_group, which also
>> does
>> not seem to help.
>>
>> Am I at fault for trying to learn R in an ad hoc manner, to which the
>> documentation of R does not lend itself, or am I missing something?
>>
>> Cheers,
>>
>> Loris
>>
>> --
>> This signature is currently under construction.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From highstat at highstat.com  Mon Mar  9 18:03:11 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 09 Mar 2015 19:03:11 +0200
Subject: [R] Book: Beginner's Guide to Data Exploration and Visualisation
 with R.
Message-ID: <54FDD24F.2010304@highstat.com>


We are please to announce the following book:

Title: Beginner's Guide to Data Exploration and Visualisation with R.
Authors: Ieno & Zuur


Book website: http://www.highstat.com/BGDEV.htm

Paperback or EBook can be order (exclusively) from:
http://www.highstat.com/bookorder.htm

TOC: http://www.highstat.com/BGS/DV/TOC_Online.pdf
Price: 29 GBP


Outline:
In 2010 we published a paper in the journal Methods in Ecology and Evolution entitled ?A protocol for data exploration to avoid common statistical problems?. Little did we know at the time that this paper would become one of the journal?s all-time top papers, both top downloaded and top cited papers, with 22,472 downloads between 2010 and 2014.

Based on this success we decided to extend the material in the paper into a book. It is part of our 'Beginner?s Guide to ...' book series. We tried to write this book in such a way that the statistical knowledge level is as low as possible. A knowledge of linear regression is all that you need.


Keywords:
Outliers, normality, homogeneity, collinearity, relationships, confounding. Case studies



Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From bbolker at gmail.com  Mon Mar  9 18:17:27 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 Mar 2015 17:17:27 +0000
Subject: [R] Help with optim() to maximize log-likelihood
References: <CAO4gA+qokumHoZwvbU7EY3xaBBo2LnQjRcWxQkzcHm3U9OZ6kw@mail.gmail.com>
Message-ID: <loom.20150309T181555-115@post.gmane.org>

Sophia Kyriakou <sophia.kyriakou17 <at> gmail.com> writes:

> 
> hello, I am using the optim function to maximize the log likelihood of a
> generalized linear mixed model and I am trying to replicate glmer's
> estimated components. If I set both the sample and subject size to q=m=100
> I replicate glmer's results for the random intercept model with parameters
>  beta=-1 and sigma^2=1. But if I change beta to 2 glmer works and optim
> gives me the error message "function cannot be evaluated at initial
> parameters".
> 
> If anyone could please help?
> Thanks

 snip to make gmane happy.

It looks like you're getting floating-point under/overflow.  If you do
all the computations on the log scale first and then exponentiate,
it seems to work, i.e.:

        piYc_ir[i,] <- lchoose(m,Y[i]) + Y[i]*(z+beta) + (-z^2/(2*exp(psi))) - 
            m*(log1p(exp(z+beta))) - 0.5*(log(2*pi)+psi)
        piYc_ir[i,] <- exp(piYc_ir[i,])

follow-ups should probably go to r-sig-mixed-models at r-project.org
instead ...

  Ben Bolker


From cryan at binghamton.edu  Mon Mar  9 18:28:47 2015
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Mon, 09 Mar 2015 13:28:47 -0400
Subject: [R] plotting the one-dimensional density of events in time
In-Reply-To: <CAF8bMcb0Oymoe6fqBHK8zwfAhaXQ8BUpV2vOYahRmZjDEM2ZMA@mail.gmail.com>
References: <54FA1634.3030804@binghamton.edu>
	<CAF8bMcb0Oymoe6fqBHK8zwfAhaXQ8BUpV2vOYahRmZjDEM2ZMA@mail.gmail.com>
Message-ID: <54FDD84F.8080703@binghamton.edu>

Tom and Bill--

Thanks! Both excellent solutions.

--Chris

Christopher W. Ryan, MD, MS
cryanatbinghamtondotedu

Early success is a terrible teacher. You?re essentially being rewarded
for a lack of preparation, so when you find yourself in a situation
where you must prepare, you can?t do it. You don?t know how.
--Chris Hadfield, An Astronaut's Guide to Life on Earth

William Dunlap wrote:
> You could change the x component of density's output back into a Date object
> and let plot choose a Date axis in its usual way.  E.g.,
>   > den <- density(as.numeric(dd))
>   > den$x <- as.Date(den$x, origin=as.Date("1970-01-01"))
>   > plot(den$x, den$y)
> (You probably will also want to normalize the y component to be on a
> specific
> per time unit, say day or year, basis.)
> 
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
> 
> On Fri, Mar 6, 2015 at 1:03 PM, Christopher W. Ryan
> <cryan at binghamton.edu <mailto:cryan at binghamton.edu>> wrote:
> 
>     I have the dates of occurence of a repetitive event. I would like to
>     plot the density of these events, as well as their specific temporal
>     location.  This is as far as I have gotten:
> 
>     # generate some sample data: dates in 2014
>     random.dates <- sample(1:31, 100, replace=TRUE)
>     random.months <- sample(1:12, 100, replace=TRUE)
>     dd <- as.Date(as.character((paste(random.dates, random.months, "2014",
>     sep="-"))), format="%d-%m-%Y")
>     dd <- dd[!is.na <http://is.na>(dd)]
> 
>     # plot density with a "rug".
>     density(as.numeric(dd))
>     plot(density(as.numeric(dd)))
>     rug(as.numeric(dd))
> 
>     # But horizontal axis label is not very informative
>     # would prefer labeling the start of each month
>     plot(density(as.numeric(dd)), axes=FALSE)
>     library(zoo)
>     new.axis <- as.yearmon(dd)
> 
>     # but then what? This is where I get stuck--adding back a sensible axis
> 
>     Grateful for any guidance.
> 
>     Thanks.
> 
>     --Chris
>     --
>     Christopher W. Ryan, MD, MS
>     cryanatbinghamtondotedu
> 
>     Early success is a terrible teacher. You?re essentially being rewarded
>     for a lack of preparation, so when you find yourself in a situation
>     where you must prepare, you can?t do it. You don?t know how.
>     --Chris Hadfield, An Astronaut's Guide to Life on Earth
> 
> 
>     ---
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
> 
> 


---


From cryan at binghamton.edu  Mon Mar  9 18:28:47 2015
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Mon, 09 Mar 2015 13:28:47 -0400
Subject: [R] plotting the one-dimensional density of events in time
In-Reply-To: <CAF8bMcb0Oymoe6fqBHK8zwfAhaXQ8BUpV2vOYahRmZjDEM2ZMA@mail.gmail.com>
References: <54FA1634.3030804@binghamton.edu>
	<CAF8bMcb0Oymoe6fqBHK8zwfAhaXQ8BUpV2vOYahRmZjDEM2ZMA@mail.gmail.com>
Message-ID: <54FDD84F.8080703@binghamton.edu>

Tom and Bill--

Thanks! Both excellent solutions.

--Chris

Christopher W. Ryan, MD, MS
cryanatbinghamtondotedu

Early success is a terrible teacher. You?re essentially being rewarded
for a lack of preparation, so when you find yourself in a situation
where you must prepare, you can?t do it. You don?t know how.
--Chris Hadfield, An Astronaut's Guide to Life on Earth

William Dunlap wrote:
> You could change the x component of density's output back into a Date object
> and let plot choose a Date axis in its usual way.  E.g.,
>   > den <- density(as.numeric(dd))
>   > den$x <- as.Date(den$x, origin=as.Date("1970-01-01"))
>   > plot(den$x, den$y)
> (You probably will also want to normalize the y component to be on a
> specific
> per time unit, say day or year, basis.)
> 
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
> 
> On Fri, Mar 6, 2015 at 1:03 PM, Christopher W. Ryan
> <cryan at binghamton.edu <mailto:cryan at binghamton.edu>> wrote:
> 
>     I have the dates of occurence of a repetitive event. I would like to
>     plot the density of these events, as well as their specific temporal
>     location.  This is as far as I have gotten:
> 
>     # generate some sample data: dates in 2014
>     random.dates <- sample(1:31, 100, replace=TRUE)
>     random.months <- sample(1:12, 100, replace=TRUE)
>     dd <- as.Date(as.character((paste(random.dates, random.months, "2014",
>     sep="-"))), format="%d-%m-%Y")
>     dd <- dd[!is.na <http://is.na>(dd)]
> 
>     # plot density with a "rug".
>     density(as.numeric(dd))
>     plot(density(as.numeric(dd)))
>     rug(as.numeric(dd))
> 
>     # But horizontal axis label is not very informative
>     # would prefer labeling the start of each month
>     plot(density(as.numeric(dd)), axes=FALSE)
>     library(zoo)
>     new.axis <- as.yearmon(dd)
> 
>     # but then what? This is where I get stuck--adding back a sensible axis
> 
>     Grateful for any guidance.
> 
>     Thanks.
> 
>     --Chris
>     --
>     Christopher W. Ryan, MD, MS
>     cryanatbinghamtondotedu
> 
>     Early success is a terrible teacher. You?re essentially being rewarded
>     for a lack of preparation, so when you find yourself in a situation
>     where you must prepare, you can?t do it. You don?t know how.
>     --Chris Hadfield, An Astronaut's Guide to Life on Earth
> 
> 
>     ---
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
> 
> 


---


From bluebarbarossa at hotmail.com  Mon Mar  9 18:47:56 2015
From: bluebarbarossa at hotmail.com (White Sky)
Date: Mon, 9 Mar 2015 17:47:56 +0000
Subject: [R] R/3.1.3 source installation
Message-ID: <DUB122-W43202C31CC1EAF4F64EA57DF1B0@phx.gbl>

R 3.1.3 is available for installation via source-code.
However ./configure terminates with








checking for dummy main to link with Fortran 77 libraries... none
checking for Fortran 77 name-mangling scheme... unknown
configure: WARNING: unknown Fortran name-mangling scheme
checking whether gfortran appends underscores to external names... unknown
configure: error: cannot use Fortran
Mac OSX 10.9.5 gfortran-4.2.3 (64bit)
Underscores are appended to external names by default but this doesn't seem to be recognised.
I have a feeling the problem might in the configure* file## DANGER!  We really needs the results of _AC_F77_NAME_MANGLING as## stored in the cache var ac_cv_f77_mangling which is not documented









## and hence may change ...
and then
{ $as_echo "$as_me:${as_lineno-$LINENO}: checking whether ${F77} appends underscores to external names" >&5$as_echo_n "checking whether ${F77} appends underscores to external names... " >&6; }









if ${r_cv_prog_f77_append_underscore+:} false; then :
 		 	   		  
	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Mon Mar  9 19:03:42 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 09 Mar 2015 18:03:42 +0000
Subject: [R] R/3.1.3 source installation
In-Reply-To: <DUB122-W43202C31CC1EAF4F64EA57DF1B0@phx.gbl>
References: <DUB122-W43202C31CC1EAF4F64EA57DF1B0@phx.gbl>
Message-ID: <54FDE07E.2030001@stats.ox.ac.uk>

This is the wrong list: see the posting guide.  As it is about compiled 
code, R-help is quite inappropriate, and as it is Mac-specific, post to 
R-sig-mac.

The issue appears to be that you did not follow the R-admin manual and 
used the wrong Fortran compiler: gfortran-4.2.3 is documented for 
Mountain Lion or earlier.  But you did not say exactly what you did use ....

On 09/03/2015 17:47, White Sky wrote:
> R 3.1.3 is available for installation via source-code.
> However ./configure terminates with
>
>
>
>
>
>
>
>
> checking for dummy main to link with Fortran 77 libraries... none
> checking for Fortran 77 name-mangling scheme... unknown
> configure: WARNING: unknown Fortran name-mangling scheme
> checking whether gfortran appends underscores to external names... unknown
> configure: error: cannot use Fortran
> Mac OSX 10.9.5 gfortran-4.2.3 (64bit)
> Underscores are appended to external names by default but this doesn't seem to be recognised.
> I have a feeling the problem might in the configure* file## DANGER!  We really needs the results of _AC_F77_NAME_MANGLING as## stored in the cache var ac_cv_f77_mangling which is not documented
>
>
>
>
>
>
>
>
>
> ## and hence may change ...
> and then
> { $as_echo "$as_me:${as_lineno-$LINENO}: checking whether ${F77} appends underscores to external names" >&5$as_echo_n "checking whether ${F77} appends underscores to external names... " >&6; }
>
>
>
>
>
>
>
>
>
> if ${r_cv_prog_f77_append_underscore+:} false; then :
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From tmrsg11 at gmail.com  Mon Mar  9 19:14:40 2015
From: tmrsg11 at gmail.com (C W)
Date: Mon, 9 Mar 2015 14:14:40 -0400
Subject: [R] Change the argument function inside R function in GPfit package
Message-ID: <CAE2FW2k00WdgUtv8Ewh=xK+zokPnP--RyHDtOHgmE1ZB-Q+jMg@mail.gmail.com>

Hi R list,

I am using the GPfit package to fit Gaussian Process model.

The kernel in the package is,
K(x, x') = sigma^2 * exp(x-x')^2

My kernel have an extra term,
K((x, z), (x', z')) = sigma^2 * exp(x-x')^2 * exp(z-z')^2

The function corr_matrix() is,
corr_matrix(X, beta, corr=list(type="exponential",power=1.95))
github source: https://github.com/cran/GPfit/blob/master/R/corr_matrix.R

I am changing the corr argument, so it looks like mine.  How should I do it?

Also, what package do you guys recommend for GP modeling?  I know GPstuff
or GPML but that's Matlab.

Thanks very much.

Mike

	[[alternative HTML version deleted]]


From Kristina.Loderer at psy.lmu.de  Mon Mar  9 18:40:56 2015
From: Kristina.Loderer at psy.lmu.de (Kristina Loderer)
Date: Mon, 09 Mar 2015 18:40:56 +0100
Subject: [R] SPSS command "match files" for merging one-to-many
 (hierarchical) equivalent in R?
Message-ID: <54FDE938020000D90002E03F@f11-gwia-1.fak11.uni-muenchen.de>

Dear R community,

to combine data sets of hierarchical, nested nature (i.e., data sets
linked by, for example, the variable "study ID" and then also by
"outcome_variable_1" and "outcome_variable_2") I can use the match files
command in SPSS. What is the equivalent command / function in R? Is it
the merge function, or the match function? The more I read, the more
confused I become..

Thank your for help in advance!

Kristina Loderer

-----------------------------------------
Kristina Loderer
Ludwig-Maximilians-Universit?t M?nchen
Department Psychologie
Leopoldstr. 13
D-80802 M?nchen

Telefon: +49 (89) 2180-6047
Email: Kristina.Loderer at psy.lmu.de

-----------------------------------------


From sophia.kyriakou17 at gmail.com  Mon Mar  9 19:07:39 2015
From: sophia.kyriakou17 at gmail.com (Sophia Kyriakou)
Date: Mon, 9 Mar 2015 20:07:39 +0200
Subject: [R] Help with optim() to maximize log-likelihood
In-Reply-To: <loom.20150309T181555-115@post.gmane.org>
References: <CAO4gA+qokumHoZwvbU7EY3xaBBo2LnQjRcWxQkzcHm3U9OZ6kw@mail.gmail.com>
	<loom.20150309T181555-115@post.gmane.org>
Message-ID: <CAO4gA+o=nbS47ov9gPmUz1w3RoWfbjGGRhL3zXcapWEHRJZz0Q@mail.gmail.com>

yes Ben, this works indeed! Thanks a million!!

On Mon, Mar 9, 2015 at 7:17 PM, Ben Bolker <bbolker at gmail.com> wrote:

> Sophia Kyriakou <sophia.kyriakou17 <at> gmail.com> writes:
>
> >
> > hello, I am using the optim function to maximize the log likelihood of a
> > generalized linear mixed model and I am trying to replicate glmer's
> > estimated components. If I set both the sample and subject size to
> q=m=100
> > I replicate glmer's results for the random intercept model with
> parameters
> >  beta=-1 and sigma^2=1. But if I change beta to 2 glmer works and optim
> > gives me the error message "function cannot be evaluated at initial
> > parameters".
> >
> > If anyone could please help?
> > Thanks
>
>  snip to make gmane happy.
>
> It looks like you're getting floating-point under/overflow.  If you do
> all the computations on the log scale first and then exponentiate,
> it seems to work, i.e.:
>
>         piYc_ir[i,] <- lchoose(m,Y[i]) + Y[i]*(z+beta) +
> (-z^2/(2*exp(psi))) -
>             m*(log1p(exp(z+beta))) - 0.5*(log(2*pi)+psi)
>         piYc_ir[i,] <- exp(piYc_ir[i,])
>
> follow-ups should probably go to r-sig-mixed-models at r-project.org
> instead ...
>
>   Ben Bolker
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From zilefacelvis at yahoo.com  Mon Mar  9 18:13:57 2015
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Mon, 9 Mar 2015 17:13:57 +0000 (UTC)
Subject: [R] Fitting fevd fuction to list R
In-Reply-To: <1745460694.5536797.1425606588075.JavaMail.yahoo@mail.yahoo.com>
References: <1745460694.5536797.1425606588075.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1041469611.1699340.1425921237563.JavaMail.yahoo@mail.yahoo.com>

I have data for 90 climate stations. For each station, I have made 100+ simulations using a statistical model. So, in R, I have 90 dataframes, each dataframe has 100+ simulations arranged column-wise. 

Now, I would like to fit an extreme value distribution (EVD) to each climate station. That is, fit an EVD each to the 100+ simulations and make an average of the results. Repeat the same for all other climate stations. 


So far, I can apply 'fevd' function to each column in a dataframe. How can I apply this on list object?

library(extRemes) 

out.df <- lapply(df, fevd,type="GEV",method = c("MLE"))# fit GEv to each column of dataframe 
#lapply(out.df,plot) # make plots for all columns 
rlcis<-lapply(out.df,return.level, do.ci=TRUE,method="normal",return.period=c(2,5,10,20,50,100))# calc return and CIs for all columns 

lst=list(df,df,df,df) 

df=structure(list(Sim001 = c(120.79, 59.35, 51.14, 104.85, 51.09, 
138.91, 254.94, 56.44, 68.3, 51.69, 51.31, 51.08, 37.17, 38.02, 
62.13, 111.48, 118.38, 45.54, 44.87, 49.59), Sim002 = c(50.25, 
31.17, 67.48, 104.56, 59.82, 38.09, 50.76, 70.25, 35.8, 59.2, 
47.89, 55.21, 74.38, 51.88, 124.09, 91.86, 109.28, 65.61, 69.54, 
55.89), Sim003 = c(30.22, 50.07, 57.66, 57.97, 62.73, 43.84, 
103.61, 53.05, 60.71, 46.57, 65.87, 33.27, 60.24, 43.63, 115.68, 
37.24, 43.27, 46.38, 122.97, 86.02), Sim004 = c(38.6, 39.02, 
45.74, 201.55, 110.78, 49.91, 63.5, 48.65, 94.43, 37.01, 32.61, 
46.39, 120.25, 45.38, 70.26, 94.02, 67.35, 55.62, 59.3, 33.96 
), Sim005 = c(43.54, 68.42, 86.02, 78.9, 40.68, 59.97, 34.5, 
48.47, 68.81, 32, 49.53, 51.23, 51.42, 61.17, 38.02, 52.96, 45.25, 
39.18, 42.33, 97.15), Sim006 = c(45.96, 65.21, 94.81, 106.71, 
46.95, 26.93, 39.45, 33.79, 50.36, 31.22, 128.37, 177.03, 82.07, 
58.02, 32.5, 96.37, 73.77, 48.96, 143.52, 50.14), Sim007 = c(66.3, 
53.99, 162.7, 100.22, 48.76, 74.06, 49.3, 62.66, 158, 82.57, 
94.07, 93.01, 53.88, 160.91, 63.71, 44.93, 63.82, 56.7, 58.92, 
101.52), Sim008 = c(130.62, 75.48, 126.46, 49.97, 71.69, 66.81, 
89.33, 52.68, 29.19, 75.88, 89.69, 59.41, 84.16, 104.49, 65.04, 
66.41, 88.5, 56.64, 62.48, 77.08), Sim009 = c(60.58, 71.85, 62.08, 
57.4, 63.08, 45.38, 50.97, 59.42, 159.44, 120.94, 58.66, 54.57, 
77.45, 49.63, 48.88, 91.03, 103.42, 56.9, 97.04, 69.89), Sim010 = c(48.63, 
51.07, 65.13, 47.59, 94.73, 42.43, 68.77, 95.83, 42.16, 133.1, 
67.2, 56.91, 138.57, 39.26, 79.75, 123.67, 64.27, 64.83, 78.88, 
89.74), Sim011 = c(59.85, 53.73, 116.88, 95.06, 113.44, 87.64, 
47.37, 42.42, 36.69, 39.11, 76.91, 59.85, 76.29, 118.37, 39.14, 
50.76, 98.06, 40.71, 53.03, 42.93), Sim012 = c(128.35, 60.21, 
60.19, 51.69, 51.47, 35.44, 101.72, 82.83, 50.72, 68.66, 80.84, 
59.98, 79.84, 35.52, 128.69, 53.35, 84.77, 18.38, 28.98, 48), 
Sim013 = c(52.88, 117.11, 103.3, 103.59, 119.06, 62.66, 65.64, 
75.91, 81.78, 80.31, 22.83, 79.22, 51.33, 79.63, 86.26, 54.44, 
42.86, 63.95, 166.87, 58.48), Sim014 = c(50.28, 123.9, 35.87, 
133.52, 94.28, 62.35, 58.54, 42.08, 67.7, 101.44, 34.68, 
45.98, 60.99, 60.06, 79.76, 61.93, 59.4, 42.02, 56.45, 81.41 
), Sim015 = c(50.32, 39.01, 100.3, 105.38, 55.49, 36.36, 
56.49, 107.52, 38.7, 73.09, 98.22, 44.19, 50.17, 56.69, 44.82, 
44.09, 57.57, 52.55, 90.37, 78.62), Sim016 = c(35.2, 62.77, 
35.25, 52.05, 93.51, 65.84, 43.85, 54.52, 39.17, 62.02, 47.6, 
34.42, 190.57, 38.46, 94.9, 73.34, 78.5, 52.84, 103.7, 51.48 
), Sim017 = c(69.03, 58.19, 130.37, 80.04, 52.96, 65.14, 
65.08, 45.95, 65.35, 41.95, 78.67, 78.41, 56.51, 63.52, 52.93, 
52.32, 70.14, 81.59, 70.99, 105.02), Sim018 = c(55.98, 44.37, 
59.07, 36.65, 44.16, 26.62, 125.38, 75.54, 75.46, 25.62, 
22.95, 65.74, 72.86, 53.5, 32.05, 58.98, 70.87, 30.95, 78.25, 
54.75), Sim019 = c(147.82, 37.48, 161.91, 46.28, 95.4, 74.79, 
53.51, 58.73, 50.96, 32.03, 50.08, 60.03, 76.75, 45.31, 58.29, 
52.91, 42.84, 74.52, 83.19, 43.8), Sim020 = c(59.33, 218.52, 
64.55, 73.07, 59.9, 39.09, 129.88, 61.53, 56.7, 38.55, 62.2, 
29.25, 52.74, 57.86, 46.04, 80.03, 44.61, 88.52, 45.36, 93.97 
), Sim021 = c(93.44, 41.32, 67.08, 99.15, 89.43, 31.64, 38.59, 
65.08, 58.9, 52.7, 47.39, 47.91, 90.93, 54.57, 51.26, 44.59, 
33.52, 38.69, 44.92, 50.46), Sim022 = c(43.37, 43.47, 63.15, 
77.19, 117.13, 77.32, 65.36, 67.49, 49.18, 87.66, 70.09, 
110.66, 70.85, 46.71, 55.36, 45.53, 30.55, 51.7, 46.08, 65.91 
), Sim023 = c(65.76, 42.75, 50.2, 58.23, 69.27, 75.63, 46.72, 
72.47, 62.53, 50.87, 58.8, 63.61, 39.99, 91.36, 66.07, 100.32, 
55.34, 32.59, 59.8, 43.96), Sim024 = c(174.2, 70.17, 47.86, 
71.24, 91.39, 40.5, 28.66, 64.57, 33.02, 46.27, 68.56, 56.68, 
97.28, 46.24, 65.76, 72.53, 60.26, 128.26, 85.63, 107.29), 
Sim025 = c(84.66, 38.95, 43.63, 41.33, 108.67, 62.94, 64.73, 
57.26, 42.11, 100.24, 28, 35.95, 175.8, 61.64, 81.42, 67.55, 
68.12, 35.1, 46.63, 105.43), Sim026 = c(64.17, 55.25, 59.21, 
49.21, 104.75, 129.05, 76.05, 69.88, 110.19, 40.71, 103.17, 
74.32, 64.18, 55.66, 105.93, 36.25, 81.08, 75.96, 81.67, 
99.22), Sim027 = c(55.07, 53.32, 71.68, 37.51, 96.35, 42.25, 
41.22, 41.09, 67.46, 69.64, 54.6, 37.63, 106.3, 121.53, 67, 
24.6, 64.82, 64.82, 68.65, 98.26), Sim028 = c(56.44, 27.16, 
45.64, 59.74, 55.09, 28.91, 94.48, 42.9, 91.21, 79.34, 41.06, 
42.36, 57.21, 38.13, 46.28, 75.48, 83.1, 72.94, 98.49, 66.73 
), Sim029 = c(49.77, 49.29, 54.16, 83.52, 48.06, 61.06, 26.69, 
68.11, 51.43, 56.84, 35.05, 87.57, 160.17, 48.4, 95.22, 74.41, 
69.18, 43.84, 65.14, 65.05), Sim030 = c(63.45, 62.12, 81.56, 
66.5, 53.21, 49.33, 44.95, 50.49, 81.7, 59.45, 46.68, 100.52, 
128.92, 75.38, 74.2, 46.92, 96.02, 42.79, 73.97, 35.67), 
Sim031 = c(42.32, 44.08, 63.43, 74.42, 78.09, 59.41, 54.34, 
103.51, 74.34, 42.34, 32.86, 76.19, 56.32, 79, 79.11, 37.75, 
46.15, 43.67, 78.34, 115.33), Sim032 = c(60.6, 46.4, 179.78, 
102.86, 57.86, 34.29, 68.26, 56.88, 103.82, 97.29, 56.46, 
104.64, 58.03, 70.71, 53.61, 111.52, 77.73, 49.03, 48.64, 
69.16), Sim033 = c(35.23, 42.14, 64.93, 74.66, 183.2, 26.87, 
59.4, 73.74, 63.13, 37.65, 64.59, 45, 75.46, 78.81, 66.73, 
56.63, 50.68, 56.87, 69.41, 86.37), Sim034 = c(51.52, 108.22, 
47.16, 41.77, 62.01, 85.64, 66.62, 58.47, 167.55, 34.71, 
73.55, 43.42, 122.87, 53.81, 48.08, 59.5, 83.6, 46.33, 55.82, 
76.99), Sim035 = c(37.25, 41.93, 74.69, 61.38, 78.29, 70.13, 
56.44, 36.66, 94.21, 97.32, 46, 45.78, 32.85, 57.05, 61.26, 
69.1, 43.26, 41.41, 69.67, 147.57), Sim036 = c(67.96, 59.22, 
65.29, 64.49, 41.23, 39.53, 46.21, 32.87, 88.47, 59.53, 44.28, 
73.41, 38.3, 72.1, 77.33, 43.23, 99.6, 49.46, 63.7, 54.96 
), Sim037 = c(73.31, 60.02, 46.72, 69.75, 39.97, 42.39, 69, 
70.86, 86.68, 79.96, 46.88, 43.91, 70.03, 53.46, 59.72, 112.63, 
44.71, 91.34, 80.78, 58.28), Sim038 = c(66.82, 67.99, 72.85, 
108.32, 45.14, 54.1, 68.67, 68.01, 51.8, 43.09, 43.94, 46.68, 
61.19, 75.64, 74.25, 43.64, 114.62, 43.71, 43.1, 66.72), 
Sim039 = c(41.57, 39.89, 172.91, 45.93, 146.08, 64.04, 51.16, 
60.84, 63.01, 59.85, 43.72, 118.3, 57.85, 64.73, 141.46, 
48.84, 109.66, 53.85, 49.28, 33.75), Sim040 = c(41.66, 203.26, 
29.55, 64.55, 43.06, 85.98, 89.09, 80.92, 83.08, 40.77, 47.7, 
120.21, 88.37, 71.86, 86.6, 122.06, 59.61, 73.06, 67.51, 
165.09), Sim041 = c(43.02, 33.99, 32.19, 60.84, 34.49, 31.81, 
46.81, 56.2, 74.42, 59.62, 48.4, 53.33, 78.04, 100.36, 92.8, 
147.88, 89.32, 38.73, 76.25, 93.83), Sim042 = c(64.27, 49.35, 
99.48, 86.88, 24.19, 54.45, 111.73, 72.6, 57.73, 75.14, 42.85, 
96.38, 55.17, 82.13, 72.9, 68.29, 76.44, 41.64, 83.17, 89.69 
), Sim043 = c(92.51, 127.4, 68.69, 45.07, 65.78, 40.81, 35.22, 
41.47, 50.94, 73.3, 55.48, 91.55, 60.15, 39.31, 110.71, 73.27, 
92.3, 64.83, 74.21, 57.68), Sim044 = c(46.86, 68.48, 51.29, 
83.66, 87.2, 79.22, 62.5, 25.17, 44.04, 55.36, 69.23, 23.23, 
43.22, 43.38, 34.28, 96.67, 42.1, 52, 95.03, 43.73), Sim045 = c(111.78, 
63.81, 126.77, 49.3, 60.11, 42.84, 47, 22.98, 48.41, 144.18, 
42.21, 85.14, 105.72, 86.97, 55.17, 73.22, 122.86, 60.04, 
31.13, 95.21), Sim046 = c(43.29, 40.17, 53.99, 29.43, 87.25, 
58.74, 81.31, 74.3, 48.47, 91.82, 60.84, 74.5, 94.22, 43.77, 
55.42, 71.17, 54.49, 76.96, 58.04, 57.95), Sim047 = c(51.58, 
50.48, 51.44, 38.82, 49.5, 59.16, 46.11, 43.95, 109.03, 57.92, 
62.12, 68.25, 42.59, 82.52, 63.36, 84.1, 77.16, 183.01, 80.42, 
57.06), Sim048 = c(39.95, 57.88, 33.13, 57.07, 123.89, 39.91, 
94.86, 80.16, 104.46, 86.94, 87.65, 82.74, 69.6, 79.83, 32.9, 
34.05, 45.11, 83.16, 78.13, 56.18), Sim049 = c(15.68, 65.54, 
71.53, 148.3, 79.93, 49.64, 82.59, 34, 77.56, 92.19, 158.28, 
82.13, 46.34, 93.22, 93.89, 59.37, 47.72, 40.11, 128.32, 
67.29), Sim050 = c(37.63, 43.41, 143.61, 157.48, 39.44, 73.62, 
75.41, 86.69, 58.29, 66.7, 45.95, 34.3, 61.8, 78.35, 58.18, 
60.04, 84.08, 76.19, 70.58, 73.57), Sim051 = c(68.28, 50.97, 
62.66, 45.23, 92.23, 93.46, 53.17, 108.31, 45.67, 121.95, 
46.52, 66.13, 75.3, 42.31, 85.94, 77.72, 111.41, 57.23, 203.79, 
68.42), Sim052 = c(86.42, 75.88, 57.99, 72.95, 129.47, 78.71, 
63.86, 66.31, 69.14, 84.81, 118.46, 67.52, 40.33, 87.73, 
46.34, 55.88, 66.93, 85.46, 130.03, 85.77), Sim053 = c(69.54, 
94.8, 158.78, 47.58, 45.09, 29.65, 69.53, 36.24, 101.68, 
63.58, 54.03, 157.1, 52.78, 72.2, 45.35, 103.47, 53.52, 43.74, 
60.9, 85.14), Sim054 = c(39.92, 48.19, 36.69, 49.01, 46.39, 
95.15, 139.94, 109.69, 72.34, 45.89, 72.94, 64.4, 61.13, 
28.13, 95.76, 133.6, 121.57, 40.21, 118.29, 33.56), Sim055 = c(80.18, 
64.11, 73.13, 43.64, 72.62, 93.36, 55.58, 72.2, 44.95, 176.77, 
33.08, 87.33, 50.86, 75.27, 74.68, 110.55, 34.23, 58.23, 
73.04, 77.96), Sim056 = c(51.11, 48.25, 68.3, 34.38, 41.18, 
45.43, 51.55, 72.79, 77.97, 170.95, 79.26, 43.51, 53.14, 
38.4, 65.34, 68.69, 71.58, 109.44, 35.29, 95.03), Sim057 = c(117.02, 
35.8, 49.18, 53.25, 61.22, 49.9, 78.82, 26.87, 113.83, 41.02, 
78.64, 48.17, 47.2, 28.92, 69.97, 56.97, 41.39, 43.83, 148.6, 
68.75), Sim058 = c(66.01, 62.38, 61.91, 100.88, 75.68, 70.96, 
119.97, 40.18, 84.75, 42.18, 81.37, 74.45, 62.03, 39.8, 63.51, 
35.9, 60.29, 51.93, 71.17, 113.18), Sim059 = c(50.1, 49.47, 
29.68, 43.19, 35.17, 95.79, 50.49, 46.12, 41.36, 55.78, 27.66, 
40.3, 47.85, 81.82, 37.56, 71, 56.49, 54.95, 49.76, 58.16 
), Sim060 = c(59.82, 36.35, 88.85, 116.35, 45.49, 133.77, 
41.36, 44.67, 34.49, 78.62, 57.15, 88.35, 28.35, 60.38, 68.16, 
150.2, 68.82, 68.36, 68.9, 35.27), Sim061 = c(78.89, 94.1, 
46.84, 70.41, 82.07, 63.92, 74.85, 45.1, 65.33, 52.73, 66.52, 
37.47, 67.55, 137.72, 82.13, 85.19, 66.18, 73.32, 67.15, 
57.61), Sim062 = c(81.25, 93.78, 43.91, 34.15, 97.4, 109.88, 
91.72, 62.36, 70.51, 59.99, 48.28, 62.83, 41.18, 50.3, 42.9, 
51.33, 39.26, 83.69, 42.38, 129.54), Sim063 = c(92.2, 53.54, 
78.81, 62.42, 83.9, 48.32, 36.29, 57.05, 46.86, 51.3, 69.92, 
58.82, 41.7, 80.2, 82.66, 78.44, 113.14, 72.73, 55.48, 78.88 
), Sim064 = c(68.46, 92.47, 40.15, 49.84, 38.22, 25.36, 77.04, 
80.5, 68.33, 42.91, 74.06, 74.03, 71.53, 91.14, 55.99, 41.71, 
45.23, 48.98, 65.36, 65.36), Sim065 = c(52.28, 120.72, 50.94, 
46.4, 59.19, 55.21, 134.89, 58.24, 54.64, 39.89, 77.4, 57.98, 
48.69, 43.63, 63.83, 113.99, 39.76, 62.65, 58.85, 63.1), 
Sim066 = c(78.03, 66.85, 27.91, 90.69, 28.72, 71.36, 73.96, 
103.19, 74.18, 43.95, 75.8, 140.66, 112.48, 59.78, 109.98, 
66.22, 123.03, 72.69, 76.89, 66.23), Sim067 = c(30.57, 61.86, 
81.85, 59.19, 57.64, 42.83, 39.97, 73.42, 66.35, 62.56, 77.06, 
60.96, 61.36, 90.85, 61.42, 121.89, 33.37, 38.83, 39.13, 
70.39), Sim068 = c(48.16, 63.75, 76.4, 17.38, 52.2, 61.95, 
73.14, 82.07, 33.54, 52.51, 61.77, 43.03, 68.15, 99, 41.97, 
94.21, 63.38, 72.88, 84.45, 77.36), Sim069 = c(199.92, 50.89, 
82.86, 30.25, 73.31, 51.05, 85.51, 52.66, 111.93, 43.89, 
114.57, 36, 46.55, 118.81, 83.79, 87.48, 76.51, 36.57, 63.2, 
55.37), Sim070 = c(77.63, 69.78, 41.28, 99.35, 80.91, 50.35, 
63.28, 86.09, 41.5, 77.95, 49.99, 64.87, 80.73, 44.15, 59.28, 
64.36, 95.07, 40.8, 103.74, 68.12), Sim071 = c(73.13, 90.19, 
39.37, 92.21, 38.72, 59.3, 59.63, 38.1, 77.38, 34.77, 74.84, 
43.84, 48.66, 69.32, 78.65, 89.51, 112.98, 83.36, 79.77, 
69.33), Sim072 = c(48.94, 79.94, 56.45, 71.4, 114.35, 61.25, 
88.91, 40.43, 71.21, 36.4, 53.34, 31.73, 70.45, 70.68, 26.03, 
77.17, 139.23, 30.64, 54.62, 45.7), Sim073 = c(90.61, 42.67, 
47.8, 62.26, 61.79, 78.01, 120.58, 61.89, 66.23, 69.28, 84.8, 
117.08, 70.77, 49, 65.52, 56.2, 124.19, 86.22, 104.7, 59.75 
), Sim074 = c(108.82, 74.84, 52.64, 61.65, 95.5, 100.88, 
61.06, 66.21, 134.45, 67.34, 67.65, 184.28, 82.28, 63.28, 
80.68, 58.1, 69.79, 114.61, 114.38, 60.15), Sim075 = c(56.4, 
71.83, 52.8, 46.04, 57.72, 78.28, 37.17, 54.41, 149.06, 35.09, 
70.95, 60.31, 107.83, 62.06, 36.78, 119.39, 54.17, 39.29, 
52.15, 91.5), Sim076 = c(73.24, 79.73, 58.04, 75.6, 99.1, 
59.95, 91.25, 55.96, 89.8, 103.72, 128.09, 56.35, 70.41, 
63.03, 67.42, 33.68, 52.25, 55.44, 40.41, 43.04), Sim077 = c(62.17, 
71.66, 51.93, 38.59, 104.54, 70.61, 69.26, 85.57, 56.65, 
56.74, 53.78, 73.24, 87.02, 63.44, 23.16, 31.31, 73.08, 24.96, 
74.46, 65.09), Sim078 = c(82.22, 44.23, 111.1, 43.37, 27.78, 
59.32, 60.79, 44.29, 34.12, 127.79, 43.09, 89.62, 59.46, 
54.22, 33.99, 85.2, 59.62, 38.53, 56.52, 45.58), Sim079 = c(74.24, 
40.5, 50.01, 62.35, 72.25, 86.32, 64.82, 94.35, 84.82, 73.1, 
34.69, 24.8, 59.56, 121.09, 73.31, 31.34, 90.42, 36.34, 69.64, 
78.18), Sim080 = c(55.04, 82.85, 19.32, 89.09, 66.21, 47.31, 
76.09, 75.88, 51.53, 103.09, 39.1, 61.51, 49.17, 78.87, 56.77, 
36.57, 91.1, 58.45, 46.61, 72.83), Sim081 = c(64.36, 99.43, 
55.1, 69.66, 54.11, 47.28, 59.61, 86.49, 81.46, 60.81, 51.63, 
69.41, 75.07, 73.5, 45.67, 36.28, 62.59, 52.71, 85.94, 83.04 
), Sim082 = c(52.98, 82.61, 54.28, 53.08, 57.04, 47.4, 64.55, 
72.55, 80.88, 61.19, 49.76, 36.32, 60.83, 80.69, 52.83, 72.73, 
76.1, 46.38, 65.93, 71.06), Sim083 = c(69.07, 81.13, 53.04, 
39.36, 28.55, 41.81, 36.99, 81.61, 109.19, 54.24, 60, 57.54, 
136.52, 93.04, 58.7, 73.08, 35.66, 34.86, 45.09, 76.62), 
Sim084 = c(90.19, 43.42, 75.16, 75.16, 33.06, 48.17, 71.74, 
29.67, 56.77, 26.87, 87.69, 81.29, 58.08, 65.15, 101.91, 
87.23, 42.49, 33.56, 77.63, 54.36), Sim085 = c(63.49, 82.74, 
59.87, 77.88, 40.73, 71.23, 120.13, 64.18, 87.58, 121.86, 
64.96, 62.73, 38.4, 85.41, 79.58, 49.38, 49, 62.84, 90.14, 
49.72), Sim086 = c(88.33, 80.44, 132.63, 107.53, 64.24, 43.19, 
130.09, 107.91, 60.15, 58.14, 53.03, 90.76, 78.17, 139.56, 
71.73, 82.55, 53.2, 68.94, 55, 59.18), Sim087 = c(49.11, 
62.7, 48.76, 99.97, 75.04, 34.77, 60.68, 68.9, 36.76, 112.95, 
34.86, 73.13, 52.06, 152.08, 104.78, 119.68, 42.02, 45.43, 
63.73, 125.19), Sim088 = c(67.52, 91.09, 91.14, 66.95, 60.57, 
45.83, 61, 35.04, 63.79, 111.8, 87.27, 53.01, 56.64, 60.25, 
31.08, 96.81, 113.34, 37.46, 73.03, 83.45), Sim089 = c(42.77, 
75.16, 114, 154.67, 56.7, 79.89, 81.79, 42.84, 109.66, 41.33, 
28.78, 31.88, 118.83, 59.86, 91.98, 71.25, 32.23, 44.86, 
81.37, 50.76), Sim090 = c(48.1, 80.97, 50.54, 63.82, 59.58, 
57.5, 63.89, 35.23, 47.96, 72.27, 36.25, 64.75, 89.16, 70.78, 
51.19, 59.98, 46.58, 42.59, 58.91, 55.28), Sim091 = c(63.06, 
68.09, 130.1, 57.53, 109.23, 32.15, 67.64, 56.55, 60.23, 
53.15, 120.2, 40.62, 89.09, 85.86, 58.44, 44.27, 77.34, 38.93, 
50.17, 69.32), Sim092 = c(38.79, 43.18, 123.18, 59.46, 48.14, 
72.46, 69.64, 45.79, 51.93, 38.79, 53.44, 46.58, 41.82, 49.96, 
72.31, 123.45, 66.02, 46.77, 37.24, 41.9), Sim093 = c(79.67, 
47.85, 72, 66.98, 76.16, 58.75, 52.11, 60.08, 44, 61.48, 
59.37, 55.79, 85.44, 43.41, 58.68, 98.53, 96.74, 61.61, 65.88, 
65.4), Sim094 = c(43.82, 36.17, 50.2, 75.13, 48.34, 35.14, 
71.98, 40.37, 84.7, 76.9, 104.48, 49.85, 100.88, 105.98, 
187.59, 46.83, 52.21, 43.24, 54.13, 81.76), Sim095 = c(93, 
60.84, 37.51, 101.75, 53.11, 53.08, 62.82, 111.24, 30.74, 
49.81, 42.1, 66.54, 71.24, 67.26, 64.89, 48.8, 63.78, 51.24, 
81.58, 60.91), Sim096 = c(73.68, 51.34, 148.38, 44.37, 85.09, 
24.63, 85.84, 80.44, 93.39, 196.38, 42.76, 62.17, 42.13, 
56.12, 56.71, 39.55, 81.37, 40.32, 72.2, 40.77), Sim097 = c(48.89, 
97.01, 29.05, 112.77, 28.27, 57.75, 85.94, 51.69, 58.61, 
32.72, 35.08, 44.03, 121.13, 88.94, 69.46, 75.61, 55.79, 
70.04, 47.91, 217.15), Sim098 = c(110.83, 53.7, 115.46, 50.46, 
92.72, 43.66, 88.45, 63.93, 54.36, 74.44, 54.67, 56.96, 46.54, 
86.65, 60.91, 61.26, 47.6, 55.04, 59.69, 49.21), Sim099 = c(31.68, 
47.26, 94.13, 66.91, 122.04, 55.12, 65.5, 113.39, 84.46, 
79.77, 51.33, 56.98, 72.55, 55.98, 89.94, 56.12, 57.61, 47.81, 
74.62, 72.74), Sim100 = c(57.1, 46.75, 32.57, 44.22, 67.5, 
64.69, 46.55, 99.27, 71.21, 90.31, 68.15, 58.36, 46.42, 44.41, 
80.41, 35.38, 95.21, 52.11, 55.61, 41.38)), .Names = c("Sim001", 
"Sim002", "Sim003", "Sim004", "Sim005", "Sim006", "Sim007", "Sim008", 
"Sim009", "Sim010", "Sim011", "Sim012", "Sim013", "Sim014", "Sim015", 
"Sim016", "Sim017", "Sim018", "Sim019", "Sim020", "Sim021", "Sim022", 
"Sim023", "Sim024", "Sim025", "Sim026", "Sim027", "Sim028", "Sim029", 
"Sim030", "Sim031", "Sim032", "Sim033", "Sim034", "Sim035", "Sim036", 
"Sim037", "Sim038", "Sim039", "Sim040", "Sim041", "Sim042", "Sim043", 
"Sim044", "Sim045", "Sim046", "Sim047", "Sim048", "Sim049", "Sim050", 
"Sim051", "Sim052", "Sim053", "Sim054", "Sim055", "Sim056", "Sim057", 
"Sim058", "Sim059", "Sim060", "Sim061", "Sim062", "Sim063", "Sim064", 
"Sim065", "Sim066", "Sim067", "Sim068", "Sim069", "Sim070", "Sim071", 
"Sim072", "Sim073", "Sim074", "Sim075", "Sim076", "Sim077", "Sim078", 
"Sim079", "Sim080", "Sim081", "Sim082", "Sim083", "Sim084", "Sim085", 
"Sim086", "Sim087", "Sim088", "Sim089", "Sim090", "Sim091", "Sim092", 
"Sim093", "Sim094", "Sim095", "Sim096", "Sim097", "Sim098", "Sim099", 
"Sim100"), row.names = c(NA, 20L), class = "data.frame") 

2) The ouput for the last column looks like: 

$Sim100 
FUN(x = X[[100L]], type = "GEV", method = ..2) 

[1] "Normal Approx." 

95% lower CI  Estimate 95% upper CI 
2-year return level       47.45112  56.12244     64.79377 
5-year return level       60.89166  73.38495     85.87825 
10-year return level      66.75437  85.28832    103.82226 
20-year return level      68.03104  97.07476    126.11849 
50-year return level      62.95423 112.88572    162.81720 
100-year return level     54.12096 125.15808    196.19519 

For each df in lst, I would like to make an avearge of 

                        95% lower CI  Estimate 95% upper CI 
2-year return level  47.45112        56.12244         64.79377 
5-year return level  60.89166  7      3.38495         85.87825 
10-year return level  66.75437       85.28832        103.82226 
20-year return level  68.03104       97.07476        126.11849 
50-year return level  62.95423       112.88572       162.81720 
100-year return level  54.12096      125.15808       196.19519 

in each df. For example, 47.45112 is the mean of 95% lower CIs for 2-year return level for all columns in df1.The final format for each dataframe in lst is as shown here with rownames, and colnames. So,if lst has 4 dfs, then lst.final should have 4 dfs with the above format.

Please help.
AT.


From murdoch.duncan at gmail.com  Mon Mar  9 19:53:16 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 09 Mar 2015 14:53:16 -0400
Subject: [R] SPSS command "match files" for merging one-to-many
 (hierarchical) equivalent in R?
In-Reply-To: <54FDE938020000D90002E03F@f11-gwia-1.fak11.uni-muenchen.de>
References: <54FDE938020000D90002E03F@f11-gwia-1.fak11.uni-muenchen.de>
Message-ID: <54FDEC1C.50901@gmail.com>

On 09/03/2015 1:40 PM, Kristina Loderer wrote:
> Dear R community,
>
> to combine data sets of hierarchical, nested nature (i.e., data sets
> linked by, for example, the variable "study ID" and then also by
> "outcome_variable_1" and "outcome_variable_2") I can use the match files
> command in SPSS. What is the equivalent command / function in R? Is it
> the merge function, or the match function? The more I read, the more
> confused I become..
>

I don't know SPSS at all, so I can't help you.  If nobody else does, you 
might try putting together a tiny example in R showing what you're 
starting with, and what you want to produce.  From what you wrote, I'd 
guess merge(), not match(), but you might really be asking for something 
completely different.

Duncan Murdoch


From marc_schwartz at me.com  Mon Mar  9 19:58:25 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 09 Mar 2015 13:58:25 -0500
Subject: [R] SPSS command "match files" for merging one-to-many
 (hierarchical) equivalent in R?
In-Reply-To: <54FDEC1C.50901@gmail.com>
References: <54FDE938020000D90002E03F@f11-gwia-1.fak11.uni-muenchen.de>
	<54FDEC1C.50901@gmail.com>
Message-ID: <755831A5-8369-4A36-B3F2-4C3CBE35C825@me.com>


> On Mar 9, 2015, at 1:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 09/03/2015 1:40 PM, Kristina Loderer wrote:
>> Dear R community,
>> 
>> to combine data sets of hierarchical, nested nature (i.e., data sets
>> linked by, for example, the variable "study ID" and then also by
>> "outcome_variable_1" and "outcome_variable_2") I can use the match files
>> command in SPSS. What is the equivalent command / function in R? Is it
>> the merge function, or the match function? The more I read, the more
>> confused I become..
>> 
> 
> I don't know SPSS at all, so I can't help you.  If nobody else does, you might try putting together a tiny example in R showing what you're starting with, and what you want to produce.  From what you wrote, I'd guess merge(), not match(), but you might really be asking for something completely different.
> 
> Duncan Murdoch


Based upon the info here:

  http://www.ats.ucla.edu/stat/spss/modules/merge.htm

I would go with ?merge, since the desired functionality appears to be a relational join operation.

Regards,

Marc Schwartz


From jdnewmil at dcn.davis.ca.us  Mon Mar  9 20:21:45 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 9 Mar 2015 12:21:45 -0700 (PDT)
Subject: [R] calculate value in dependence of target value
In-Reply-To: <7E39CF5278A2C948968C39502CF451020174D1BE2E9B@mail.ell.fnt.de>
References: <7E39CF5278A2C948968C39502CF451020174D1BE2E96@mail.ell.fnt.de>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D66CF7C@mb02.ads.tamu.edu>
	<7E39CF5278A2C948968C39502CF451020174D1BE2E9B@mail.ell.fnt.de>
Message-ID: <alpine.BSF.2.00.1503091220590.8117@pedal.dcn.davis.ca.us>


> target <- 100000
>
> breakpts <- data.frame( PctTarget=c(50,75,100,Inf), Mult=c(2,4,8,10) )
> breakpts$LastPct <- c( 0, breakpts$PctTarget[ -nrow( breakpts ) ] )
> breakpts$Range <- cut( breakpts$PctTarget, c( 0, breakpts$PctTarget ), 
include.lowest=TRUE )
> breakpts$DeltaPct <- with( breakpts, diff( c( 0, PctTarget ) ) )
> breakpts$CumMARGE <- target / 1e4 * with( breakpts, cumsum( DeltaPct * 
Mult ) )
> breakpts$LastCumMARGE <- c( 0, breakpts$CumMARGE[ -nrow( breakpts ) ] )
>
> dta <- data.frame( ID=11:14, VALUE=c(10000,50000,30000,20000) )
> dta$CumVALUE <- cumsum( dta$VALUE )
> dta$CumPct <- 100 * dta$CumVALUE / target
> dta$Range <- cut( dta$CumPct, c( 0, breakpts$PctTarget ), 
include.lowest=TRUE )
>
> dta
   ID VALUE CumVALUE CumPct     Range
1 11 10000    10000     10    [0,50]
2 12 50000    60000     60   (50,75]
3 13 30000    90000     90  (75,100]
4 14 20000   110000    110 (100,Inf]
> breakpts
   PctTarget Mult LastPct     Range DeltaPct CumMARGE LastCumMARGE
1        50    2       0    [0,50]       50     1000            0
2        75    4      50   (50,75]       25     2000         1000
3       100    8      75  (75,100]       25     4000         2000
4       Inf   10     100 (100,Inf]      Inf      Inf         4000
>
> #dta2 <- merge( dta, breakpts, all.x=TRUE, by="Range" )
> #dta2 <- dta2[ order( dta2$ID ), ]
>
> dta2 <- cbind( dta, breakpts[ match( dta$Range, breakpts$Range ), 
-which( "Range"==names( breakpts ) ) ] )
>
> dta2$CumMARGE <- with( dta2, Mult/100 * ( CumVALUE - target * LastPct / 
100 ) + LastCumMARGE )
> dta2$MARGE <- with( dta2, diff( c( 0, CumMARGE ) ) )
>
> dta2
   ID VALUE CumVALUE CumPct     Range PctTarget Mult LastPct DeltaPct 
CumMARGE LastCumMARGE MARGE
1 11 10000    10000     10    [0,50]        50    2       0       50 
200            0   200
2 12 50000    60000     60   (50,75]        75    4      50       25 
1400         1000  1200
3 13 30000    90000     90  (75,100]       100    8      75       25 
3200         2000  1800
4 14 20000   110000    110 (100,Inf]       Inf   10     100      Inf 
5000         4000  1800
>
>
> target <- 100000
>
> breakpts <- data.frame( PctTarget=c(50,75,100,Inf), Mult=c(2,4,8,10) )
> breakpts$LastPct <- c( 0, breakpts$PctTarget[ -nrow( breakpts ) ] )
> breakpts$Range <- cut( breakpts$PctTarget, c( 0, breakpts$PctTarget ), 
include.lowest=TRUE )
> breakpts$DeltaPct <- with( breakpts, diff( c( 0, PctTarget ) ) )
> breakpts$CumMARGE <- target / 1e4 * with( breakpts, cumsum( DeltaPct * 
Mult ) )
> breakpts$LastCumMARGE <- c( 0, breakpts$CumMARGE[ -nrow( breakpts ) ] )
>
> dta <- data.frame( ID=11:14, VALUE=c(10000,50000,30000,20000) )
> dta$CumVALUE <- cumsum( dta$VALUE )
> dta$CumPct <- 100 * dta$CumVALUE / target
> dta$Range <- cut( dta$CumPct, c( 0, breakpts$PctTarget ), 
include.lowest=TRUE )
>
> dta
   ID VALUE CumVALUE CumPct     Range
1 11 10000    10000     10    [0,50]
2 12 50000    60000     60   (50,75]
3 13 30000    90000     90  (75,100]
4 14 20000   110000    110 (100,Inf]
> breakpts
   PctTarget Mult LastPct     Range DeltaPct CumMARGE LastCumMARGE
1        50    2       0    [0,50]       50     1000            0
2        75    4      50   (50,75]       25     2000         1000
3       100    8      75  (75,100]       25     4000         2000
4       Inf   10     100 (100,Inf]      Inf      Inf         4000
>
> #dta2 <- merge( dta, breakpts, all.x=TRUE, by="Range" )
> #dta2 <- dta2[ order( dta2$ID ), ]
>
> dta2 <- cbind( dta, breakpts[ match( dta$Range, breakpts$Range ), 
-which( "Range"==names( breakpts ) ) ] )
>
> dta2$CumMARGE <- with( dta2, Mult/100 * ( CumVALUE - target * LastPct / 
100 ) + LastCumMARGE )
> dta2$MARGE <- diff( c( 0, dta2$CumMARGE ) )
>
> dta2
   ID VALUE CumVALUE CumPct     Range PctTarget Mult LastPct DeltaPct 
CumMARGE LastCumMARGE MARGE
1 11 10000    10000     10    [0,50]        50    2       0       50 
200            0   200
2 12 50000    60000     60   (50,75]        75    4      50       25 
1400         1000  1200
3 13 30000    90000     90  (75,100]       100    8      75       25 
3200         2000  1800
4 14 20000   110000    110 (100,Inf]       Inf   10     100      Inf 
5000         4000  1800
>

On Mon, 9 Mar 2015, Matthias Weber wrote:

> Hi David,
>
> thanks for the reply. My spelling of the numbers was not correct. What I mean with 100.000 is 100000.00 !
> I have corrected the values in my example below me.
>
> Maybe you can understand it better now.
>
> Crucially is, that the "MARGE" rises up in dependence of the ID. The ID 11 will be count with 2% because we don't reach the 50% hurdle (50000). The ID 12 will reach the 50% hurdle, so the ID 12 should be count with 1200 (result of 40000 * 2% + 10000 * 4%). The 10000 with 4% will be credited more, because they exceed the 50% Target Value.
>
> Thanks for your help.
>
> Best regards.
>
> Mat
>
> -----Urspr?ngliche Nachricht-----
> Von: David L Carlson [mailto:dcarlson at tamu.edu]
> Gesendet: Montag, 9. M?rz 2015 16:08
> An: Matthias Weber; r-help at r-project.org
> Betreff: RE: calculate value in dependence of target value
>
> It is very hard to figure out what you are trying to do.
>
> 1. All of the VALUEs are greater than the target of 100 2. Your description of what you want does not match your example.
>
> Perhaps VALUE should be divided by 1000 (e.g. not 10000, but 10)?
> Perhaps your targets do not apply to VALUE, but to cumulative VALUE?
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matthias Weber
> Sent: Monday, March 9, 2015 7:46 AM
> To: r-help at r-project.org
> Subject: [R] calculate value in dependence of target value
>
> Hello together,
>
> i have a litte problem. Maybe anyone can help me.
>
> I have to calculate a new column in dependence of a target value.
>
> As a example: My target value is 100000. At the moment I have a data.frame with the following values.
>
>     ID    VALUE
> 1   11    10000
> 2   12    50000
> 3   13    30000
> 4   14    20000
>
> The new column ("MARGE") should be calculated with the following graduation:
> Until the VALUE reach 50% of the target value (50000) = 2%
>
> Until the VALUE reach 75% of the target value (75000) = 4%
>
> Until the VALUE reach 100% of the target value (<100000) = 8%
>
> If the VALUE goes above 100% of the value (>100000) = 10%
>
> The result looks like this one:
>
>     ID    VALUE  MARGE
> 1   11    10000          200      (result of 10000 * 2%)
> 2   12    50000         1200     (result of 40000 * 2% + 10000 * 4%)
> 3   13    30000         1800     (result of 15000 * 4% + 15000 * 8%)
> 4   14    20000         1800     (result of 10000 * 8% + 10000 * 10%)
>
> Is there anyway to calculate the column "MARGE" automatically in R?
>
> Thanks a lot for your help.
>
> Best regards.
>
> Mat
>
> This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.
>
> Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From david at revolutionanalytics.com  Mon Mar  9 21:49:49 2015
From: david at revolutionanalytics.com (David Smith)
Date: Mon, 9 Mar 2015 15:49:49 -0500
Subject: [R] Revolutions blog: February roundup
Message-ID: <CABgvEC9Zg1=G+nmQ21U6T=XZLwaJyRQpAQhyE=My4YUE9+_p8w@mail.gmail.com>

For more than 6 years, Revolution Analytics staff and guests have
written about R every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of February:

The John M. Chambers Statistical Software Award announcement for 2015:
http://bit.ly/1CWIfXT

The new R package "distcomp" allows researchers to collaborate on data
spread across multiple sites: http://bit.ly/1CWIfXU

I gave an interview to theCUBE on R, data science, and Microsoft's
acquisition of Revolution Analytics: http://bit.ly/1CWIfaC

R is used to measure impact of climate change, and other Strata
keynote presentations: http://bit.ly/1CWIfqQ

Some tricks for monitoring the progress on parallel R jobs using
foreach: http://bit.ly/1CWIfaD

"Analytics Marketplaces" are all the rage today, but CRAN was there
first: http://bit.ly/1CWIfXS

A preview of some of the major R-related conferences and events of
2015: http://bit.ly/1CWIfXV

The checkpoint package has been updated to make it even easier to run
R scripts with fixed R package versions: http://bit.ly/1CWIfqS

A tutorial to introduce R to users of Microsoft Excel: http://bit.ly/1CWIfqT

R used to assess the "virality" of posts on new-media sites like
Buzzfeed: http://bit.ly/1CWIfqU

A review of the HP Workshop on Distributed Computing in R featuring
Luke Tierney, Dirk Eddelbuettel, Martin Morgan, Simon Urbanek and
other R luminaries: http://bit.ly/1CWIfXX

R is the top-ranked language on GitHub, as measured by the number of
forks per repository: http://bit.ly/1CWIfXW

You can use the rcrunchbase package to access data on startup
companies: http://bit.ly/1CWIfXY

The R package "syuzhet" applies sentiment analysis to novels to infer
their dramatic arc: http://bit.ly/1CWIfqX

The new "quickcheck" package provides assertion-based testing with
random inputs for R: http://bit.ly/1CWIfqY

A theorem for calculating an upper bound for the generalization error
of a machine learning classifier: http://bit.ly/1CWIfXZ

Some practical advice for sharing Shiny applications with
shinyapps.io: http://bit.ly/1CWIfqZ

A visualization of Paris's street orientations reveals the history of
the city: http://bit.ly/1CWIfY0

General interest stories (not related to R) in the past month
included: how our brains trick us into seeing the wrong colors
(http://bit.ly/1CWIfr0), an hilarious parody of cooking shows
(http://bit.ly/1CWIfr4), a new ASA website to help journalists with
Statistics (http://bit.ly/1CWIfY1), the statistical model behind the
rules of cricket (http://bit.ly/1CWIfY2), and why rivers meander
(http://bit.ly/1CWIfr6).

Meeting times for local R user groups (http://bit.ly/eC5YQe) can be
found on the updated R Community Calendar at: http://bit.ly/bb3naW

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com or via Twitter (I'm
@revodavid).

Cheers,
# David

-- 
David M Smith <david at revolutionanalytics.com>
Chief Community Officer, Revolution Analytics
http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Chicago IL, USA)
Twitter: @revodavid


From erinm.hodgess at gmail.com  Mon Mar  9 21:52:25 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Mon, 9 Mar 2015 16:52:25 -0400
Subject: [R]  question about the geometric distribution, please
Message-ID: <CACxE24=qoX8F55QtMbtXUXNWG1EHtKq-+2=xySe4vvpyjqaDQQ@mail.gmail.com>

Hello!

The function rgeom is based on the geometric distribution such that x = 0,
1, ....

Is there a function which produces the geometric results such that x = 1,
2, ...
please?

Thought I'd check before I started coding.

Thank you!

Sincerely,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Mar  9 21:55:02 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 9 Mar 2015 20:55:02 +0000
Subject: [R] calculate value in dependence of target value
In-Reply-To: <alpine.BSF.2.00.1503091220590.8117@pedal.dcn.davis.ca.us>
References: <7E39CF5278A2C948968C39502CF451020174D1BE2E96@mail.ell.fnt.de>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D66CF7C@mb02.ads.tamu.edu>
	<7E39CF5278A2C948968C39502CF451020174D1BE2E9B@mail.ell.fnt.de>
	<alpine.BSF.2.00.1503091220590.8117@pedal.dcn.davis.ca.us>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D66D0F8@mb02.ads.tamu.edu>

This works for your example data, but I'd recommend testing it carefully before using it.

> dat <- data.frame(ID=11:14, VALUE=c(1, 5, 3, 2)*10000)
> HURD <- c(50, 75, 100)*1000
> PCT <- c(.02, .04, .08, .1)
> dat$CVALUE <- cumsum(dat$VALUE)
> dat$LVALUE <- dat$CVALUE - dat$VALUE
> dat
  ID VALUE CVALUE LVALUE
1 11 10000  10000      0
2 12 50000  60000  10000
3 13 30000  90000  60000
4 14 20000 110000  90000
> 
> for (idx in seq_len(nrow(dat))) {
+     rng <- sort(c(HURD, unlist(dat[idx,3:4])))
+     a <- which(names(rng) == "LVALUE")
+     b <- which(names(rng) == "CVALUE")
+     diff(rng[a:b])
+     ng <- length(diff(rng[a:b]))
+     dat$MARGE[idx] <- sum(PCT[a:(a+ng-1)]* diff(rng[a:b]))
+ }
> dat
  ID VALUE CVALUE LVALUE MARGE
1 11 10000  10000      0   200
2 12 50000  60000  10000  1200
3 13 30000  90000  60000  1800
4 14 20000 110000  90000  1800

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Monday, March 9, 2015 2:22 PM
To: Matthias Weber
Cc: David L Carlson; r-help at r-project.org
Subject: Re: [R] calculate value in dependence of target value


> target <- 100000
>
> breakpts <- data.frame( PctTarget=c(50,75,100,Inf), Mult=c(2,4,8,10) )
> breakpts$LastPct <- c( 0, breakpts$PctTarget[ -nrow( breakpts ) ] )
> breakpts$Range <- cut( breakpts$PctTarget, c( 0, breakpts$PctTarget ), 
include.lowest=TRUE )
> breakpts$DeltaPct <- with( breakpts, diff( c( 0, PctTarget ) ) )
> breakpts$CumMARGE <- target / 1e4 * with( breakpts, cumsum( DeltaPct * 
Mult ) )
> breakpts$LastCumMARGE <- c( 0, breakpts$CumMARGE[ -nrow( breakpts ) ] )
>
> dta <- data.frame( ID=11:14, VALUE=c(10000,50000,30000,20000) )
> dta$CumVALUE <- cumsum( dta$VALUE )
> dta$CumPct <- 100 * dta$CumVALUE / target
> dta$Range <- cut( dta$CumPct, c( 0, breakpts$PctTarget ), 
include.lowest=TRUE )
>
> dta
   ID VALUE CumVALUE CumPct     Range
1 11 10000    10000     10    [0,50]
2 12 50000    60000     60   (50,75]
3 13 30000    90000     90  (75,100]
4 14 20000   110000    110 (100,Inf]
> breakpts
   PctTarget Mult LastPct     Range DeltaPct CumMARGE LastCumMARGE
1        50    2       0    [0,50]       50     1000            0
2        75    4      50   (50,75]       25     2000         1000
3       100    8      75  (75,100]       25     4000         2000
4       Inf   10     100 (100,Inf]      Inf      Inf         4000
>
> #dta2 <- merge( dta, breakpts, all.x=TRUE, by="Range" )
> #dta2 <- dta2[ order( dta2$ID ), ]
>
> dta2 <- cbind( dta, breakpts[ match( dta$Range, breakpts$Range ), 
-which( "Range"==names( breakpts ) ) ] )
>
> dta2$CumMARGE <- with( dta2, Mult/100 * ( CumVALUE - target * LastPct / 
100 ) + LastCumMARGE )
> dta2$MARGE <- with( dta2, diff( c( 0, CumMARGE ) ) )
>
> dta2
   ID VALUE CumVALUE CumPct     Range PctTarget Mult LastPct DeltaPct 
CumMARGE LastCumMARGE MARGE
1 11 10000    10000     10    [0,50]        50    2       0       50 
200            0   200
2 12 50000    60000     60   (50,75]        75    4      50       25 
1400         1000  1200
3 13 30000    90000     90  (75,100]       100    8      75       25 
3200         2000  1800
4 14 20000   110000    110 (100,Inf]       Inf   10     100      Inf 
5000         4000  1800
>
>
> target <- 100000
>
> breakpts <- data.frame( PctTarget=c(50,75,100,Inf), Mult=c(2,4,8,10) )
> breakpts$LastPct <- c( 0, breakpts$PctTarget[ -nrow( breakpts ) ] )
> breakpts$Range <- cut( breakpts$PctTarget, c( 0, breakpts$PctTarget ), 
include.lowest=TRUE )
> breakpts$DeltaPct <- with( breakpts, diff( c( 0, PctTarget ) ) )
> breakpts$CumMARGE <- target / 1e4 * with( breakpts, cumsum( DeltaPct * 
Mult ) )
> breakpts$LastCumMARGE <- c( 0, breakpts$CumMARGE[ -nrow( breakpts ) ] )
>
> dta <- data.frame( ID=11:14, VALUE=c(10000,50000,30000,20000) )
> dta$CumVALUE <- cumsum( dta$VALUE )
> dta$CumPct <- 100 * dta$CumVALUE / target
> dta$Range <- cut( dta$CumPct, c( 0, breakpts$PctTarget ), 
include.lowest=TRUE )
>
> dta
   ID VALUE CumVALUE CumPct     Range
1 11 10000    10000     10    [0,50]
2 12 50000    60000     60   (50,75]
3 13 30000    90000     90  (75,100]
4 14 20000   110000    110 (100,Inf]
> breakpts
   PctTarget Mult LastPct     Range DeltaPct CumMARGE LastCumMARGE
1        50    2       0    [0,50]       50     1000            0
2        75    4      50   (50,75]       25     2000         1000
3       100    8      75  (75,100]       25     4000         2000
4       Inf   10     100 (100,Inf]      Inf      Inf         4000
>
> #dta2 <- merge( dta, breakpts, all.x=TRUE, by="Range" )
> #dta2 <- dta2[ order( dta2$ID ), ]
>
> dta2 <- cbind( dta, breakpts[ match( dta$Range, breakpts$Range ), 
-which( "Range"==names( breakpts ) ) ] )
>
> dta2$CumMARGE <- with( dta2, Mult/100 * ( CumVALUE - target * LastPct / 
100 ) + LastCumMARGE )
> dta2$MARGE <- diff( c( 0, dta2$CumMARGE ) )
>
> dta2
   ID VALUE CumVALUE CumPct     Range PctTarget Mult LastPct DeltaPct 
CumMARGE LastCumMARGE MARGE
1 11 10000    10000     10    [0,50]        50    2       0       50 
200            0   200
2 12 50000    60000     60   (50,75]        75    4      50       25 
1400         1000  1200
3 13 30000    90000     90  (75,100]       100    8      75       25 
3200         2000  1800
4 14 20000   110000    110 (100,Inf]       Inf   10     100      Inf 
5000         4000  1800
>

On Mon, 9 Mar 2015, Matthias Weber wrote:

> Hi David,
>
> thanks for the reply. My spelling of the numbers was not correct. What I mean with 100.000 is 100000.00 !
> I have corrected the values in my example below me.
>
> Maybe you can understand it better now.
>
> Crucially is, that the "MARGE" rises up in dependence of the ID. The ID 11 will be count with 2% because we don't reach the 50% hurdle (50000). The ID 12 will reach the 50% hurdle, so the ID 12 should be count with 1200 (result of 40000 * 2% + 10000 * 4%). The 10000 with 4% will be credited more, because they exceed the 50% Target Value.
>
> Thanks for your help.
>
> Best regards.
>
> Mat
>
> -----Urspr?ngliche Nachricht-----
> Von: David L Carlson [mailto:dcarlson at tamu.edu]
> Gesendet: Montag, 9. M?rz 2015 16:08
> An: Matthias Weber; r-help at r-project.org
> Betreff: RE: calculate value in dependence of target value
>
> It is very hard to figure out what you are trying to do.
>
> 1. All of the VALUEs are greater than the target of 100 2. Your description of what you want does not match your example.
>
> Perhaps VALUE should be divided by 1000 (e.g. not 10000, but 10)?
> Perhaps your targets do not apply to VALUE, but to cumulative VALUE?
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matthias Weber
> Sent: Monday, March 9, 2015 7:46 AM
> To: r-help at r-project.org
> Subject: [R] calculate value in dependence of target value
>
> Hello together,
>
> i have a litte problem. Maybe anyone can help me.
>
> I have to calculate a new column in dependence of a target value.
>
> As a example: My target value is 100000. At the moment I have a data.frame with the following values.
>
>     ID    VALUE
> 1   11    10000
> 2   12    50000
> 3   13    30000
> 4   14    20000
>
> The new column ("MARGE") should be calculated with the following graduation:
> Until the VALUE reach 50% of the target value (50000) = 2%
>
> Until the VALUE reach 75% of the target value (75000) = 4%
>
> Until the VALUE reach 100% of the target value (<100000) = 8%
>
> If the VALUE goes above 100% of the value (>100000) = 10%
>
> The result looks like this one:
>
>     ID    VALUE  MARGE
> 1   11    10000          200      (result of 10000 * 2%)
> 2   12    50000         1200     (result of 40000 * 2% + 10000 * 4%)
> 3   13    30000         1800     (result of 15000 * 4% + 15000 * 8%)
> 4   14    20000         1800     (result of 10000 * 8% + 10000 * 10%)
>
> Is there anyway to calculate the column "MARGE" automatically in R?
>
> Thanks a lot for your help.
>
> Best regards.
>
> Mat
>
> This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.
>
> Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From firespot71 at gmail.com  Mon Mar  9 21:57:12 2015
From: firespot71 at gmail.com (Thomas)
Date: Mon, 9 Mar 2015 21:57:12 +0100
Subject: [R] increase max. console output lines
Message-ID: <mdl1fa$guv$1@ger.gmane.org>

Hi,

I have a lengthy R script, which just got a bit too long for the console 
output to cache all executions history, i.e. when scrolling to the top 
the first few commands executed are not listed any more.
What is the current limit (characters? lines?) and how do I increase it?

R is 2.14, Win7, 64-bit if that matters.

thanks, Thomas


From dwinsemius at comcast.net  Mon Mar  9 22:26:31 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 9 Mar 2015 14:26:31 -0700
Subject: [R] question about the geometric distribution, please
In-Reply-To: <CACxE24=qoX8F55QtMbtXUXNWG1EHtKq-+2=xySe4vvpyjqaDQQ@mail.gmail.com>
References: <CACxE24=qoX8F55QtMbtXUXNWG1EHtKq-+2=xySe4vvpyjqaDQQ@mail.gmail.com>
Message-ID: <198A89CC-0C41-4E37-8E74-2E717483C68B@comcast.net>


On Mar 9, 2015, at 1:52 PM, Erin Hodgess wrote:

> Hello!
> 
> The function rgeom is based on the geometric distribution such that x = 0,
> 1, ....
> 
> Is there a function which produces the geometric results such that x = 1,
> 2, ...
> please?
> 
> Thought I'd check before I started coding.

This seemed unclear or trivial. Cannot decide which from the description. The arguments to rgeom are "n" and "prob". If you want a geometric-like result with a "shifted" range, then just add one to the rgeom result.


> 
> Thank you!
> 
> Sincerely,
> Erin
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
> 	[[alternative HTML version deleted]]

-- 

David Winsemius
Alameda, CA, USA


From WilliamsBL at cardiff.ac.uk  Mon Mar  9 22:05:40 2015
From: WilliamsBL at cardiff.ac.uk (Beth Williams)
Date: Mon, 9 Mar 2015 21:05:40 +0000
Subject: [R] APE
Message-ID: <1425935133781.19867@cardiff.ac.uk>

Dear All,


I am having some trouble with R and would be extremely grateful if anyone has a way around this. I have loaded a nexus tree from PAUP into R using the command read.nexus and this loaded,  it was reported as "rooted; with no branch lengths". I then used the command "compute.brlen(mytree)" to compute the branch lengths and this was reported as "rooted; includes branch lengths". I added my community data (samp) and then tried to compute the phylogenetic diversity with the command "> pd(samp, mytree, include.root=TRUE)" however it said it could not calculate the PD as there were no branch lengths. Is there a way to incorporate the branch lengths into the calculation for PD?


Thanks for your time,

Beth

	[[alternative HTML version deleted]]


From daouda at newschool.edu  Mon Mar  9 23:24:23 2015
From: daouda at newschool.edu (adel daoud)
Date: Mon, 9 Mar 2015 18:24:23 -0400
Subject: [R] Alpha not working in geom_rect
In-Reply-To: <CA+8X3fU9mzs_JtJ9MENYQ08A-MH96soBm5ej2cEm=h9eP6pnMA@mail.gmail.com>
References: <1425749980919-4704291.post@n4.nabble.com>
	<CA+8X3fU9mzs_JtJ9MENYQ08A-MH96soBm5ej2cEm=h9eP6pnMA@mail.gmail.com>
Message-ID: <CAEJCy7j6dN-=N86qhGbMR_Leiq8wq9sOqTSzY3nB-b0GPm+M4g@mail.gmail.com>

Hi Jim,

Thanks for the input but that did not work. I am suing Rstudio by the way
and I guess that has a better device that would support ggplot output.

The annotate options works but that does not explain why the geom_area does
not work:
annotate("rect", xmin=2, xmax=10, ymin=0,  ymax=1, fill="black", alpha=0.5)

Best
Adel


--

Adel Daoud, PhD, Researcher



The New School for Social Research,

Visiting Scholar in the Economics Department,

6 East 16th Street New York, NY 10003,

daouda at newschool.edu





University of Gothenburg

Department of Sociology and Work Science,

Box 720

405 30, G?teborg, Sweden

Visiting address: Spr?ngkullsgatan 25, room F411

Spr?ngkullsgatan 25, room K109

+46 031-786 41 73

Adel.daoud at sociology.gu.se

On Sun, Mar 8, 2015 at 12:46 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Adel,
> Almost certainly because the device you were using doesn't support
> transparency.Try it with a PDF device and check the resulting file in a PDF
> reader:
>
> pdf("ad.pdf")
> print(p)
> dev.off()
>
> Jim
>
>
> On Sun, Mar 8, 2015 at 4:39 AM, Adel <adel.daoud at socav.gu.se> wrote:
>
>> Hi
>> I am trying to activate the alpha argument to work, but for some reason it
>> does not to play with me. Anybody has an idea why?
>>
>>
>> p <- ggplot(data = prediction_df, aes(x=x, y=prediction, fill=threshold))
>> +
>> geom_area(colour="black", size=.2, alpha=.4) +
>> scale_fill_brewer(palette="Set1",
>> breaks=rev(levels(prediction_df$threshold)))
>> p + geom_rect(aes(xmin=2, xmax=10, ymin=(0), ymax=(1)), fill="black",
>> alpha=0.5)
>>
>>
>> prediction_df
>>      x prediction  threshold
>> 1  -10  0.5694161       noAF
>> 2   -9  0.5700513       noAF
>> 3   -8  0.5706863       noAF
>> 4   -7  0.5713211       noAF
>> 5   -6  0.5719556       noAF
>> 6   -5  0.5725899       noAF
>> 7   -4  0.5732240       noAF
>> 8   -3  0.5738578       noAF
>> 9   -2  0.5744914       noAF
>> 10  -1  0.5751247       noAF
>> 11   0  0.5757578       noAF
>> 12   1  0.5763906       noAF
>> 13   2  0.5770232       noAF
>> 14   3  0.5776556       noAF
>> 15   4  0.5782876       noAF
>> 16   5  0.5789195       noAF
>> 17   6  0.5795510       noAF
>> 18   7  0.5801823       noAF
>> 19   8  0.5808134       noAF
>> 20   9  0.5814441       noAF
>> 21  10  0.5820747       noAF
>> 22 -10  0.2359140   singleAF
>> 23  -9  0.2356847   singleAF
>> 24  -8  0.2354550   singleAF
>> 25  -7  0.2352249   singleAF
>> 26  -6  0.2349943   singleAF
>> 27  -5  0.2347634   singleAF
>> 28  -4  0.2345321   singleAF
>> 29  -3  0.2343003   singleAF
>> 30  -2  0.2340682   singleAF
>> 31  -1  0.2338356   singleAF
>> 32   0  0.2336027   singleAF
>> 33   1  0.2333694   singleAF
>> 34   2  0.2331357   singleAF
>> 35   3  0.2329016   singleAF
>> 36   4  0.2326671   singleAF
>> 37   5  0.2324322   singleAF
>> 38   6  0.2321969   singleAF
>> 39   7  0.2319613   singleAF
>> 40   8  0.2317253   singleAF
>> 41   9  0.2314889   singleAF
>> 42  10  0.2312522   singleAF
>> 43 -10  0.1946699 multipleAF
>> 44  -9  0.1942640 multipleAF
>> 45  -8  0.1938587 multipleAF
>> 46  -7  0.1934540 multipleAF
>> 47  -6  0.1930500 multipleAF
>> 48  -5  0.1926467 multipleAF
>> 49  -4  0.1922440 multipleAF
>> 50  -3  0.1918419 multipleAF
>> 51  -2  0.1914404 multipleAF
>> 52  -1  0.1910397 multipleAF
>> 53   0  0.1906395 multipleAF
>> 54   1  0.1902400 multipleAF
>> 55   2  0.1898411 multipleAF
>> 56   3  0.1894429 multipleAF
>> 57   4  0.1890453 multipleAF
>> 58   5  0.1886483 multipleAF
>> 59   6  0.1882520 multipleAF
>> 60   7  0.1878564 multipleAF
>> 61   8  0.1874613 multipleAF
>> 62   9  0.1870669 multipleAF
>> 63  10  0.1866732 multipleAF
>>
>>
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Alpha-not-working-in-geom-rect-tp4704291.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From imran at infoscoutinc.com  Mon Mar  9 22:27:00 2015
From: imran at infoscoutinc.com (Imran Akbar)
Date: Mon, 9 Mar 2015 14:27:00 -0700
Subject: [R] R can't find tcl-tk
Message-ID: <CACHqeJLKOsntwkTxx7pU4H10xc9Mr+xsFDs8JuWQrQTsTYPDNA@mail.gmail.com>

Hi,

I've installed the latest version of R from source on Amazon Linux with the
following config flags:
./configure --with-tcl-config=/opt/ActiveTcl-8.6/lib/tclConfig.sh
--with-tk-config=/opt/ActiveTcl-8.6/lib/tkConfig.sh

After running make and make install, I try to run R and install the
'anesrake' package, but one of the dependencies fails with this error:

error: Tcl/Tk support is not available on this system

How can I fix this?

regards,
imran

	[[alternative HTML version deleted]]


From JS.Huang at protective.com  Mon Mar  9 22:17:27 2015
From: JS.Huang at protective.com (Huang, JS)
Date: Mon, 9 Mar 2015 21:17:27 +0000
Subject: [R] question about the geometric distribution, please
In-Reply-To: <CACxE24=qoX8F55QtMbtXUXNWG1EHtKq-+2=xySe4vvpyjqaDQQ@mail.gmail.com>
References: <CACxE24=qoX8F55QtMbtXUXNWG1EHtKq-+2=xySe4vvpyjqaDQQ@mail.gmail.com>
Message-ID: <5A753D062E22614F99E148EDA0621F15CC094D1E@PBMSX04W.secure.protective.com>

Maybe you are looking for rnbinom?

JS Huang
636.536.5635


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Erin Hodgess
Sent: Monday, March 09, 2015 3:52 PM
To: R help
Subject: [R] question about the geometric distribution, please

Hello!

The function rgeom is based on the geometric distribution such that x = 0, 1, ....

Is there a function which produces the geometric results such that x = 1, 2, ...
please?

Thought I'd check before I started coding.

Thank you!

Sincerely,
Erin


--
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice: This e-mail communication and any
attachments may contain confidential and privileged information for
the use of the designated recipients named above. If you are not
the intended recipient, you are hereby notified that you have
received this communication in error and that any review,
disclosure, dissemination, distribution or copying of it or its
contents is prohibited. If you have received this communication in
error, please notify me immediately by replying to this message and
deleting it from your computer. Thank you.


From paul.j.sweeting at gmail.com  Mon Mar  9 23:33:28 2015
From: paul.j.sweeting at gmail.com (Paul Sweeting)
Date: Mon, 9 Mar 2015 22:33:28 -0000
Subject: [R] svg2swf - controlling the looping of flash files
Message-ID: <00f101d05ab9$110abb70$33203250$@gmail.com>

Hi

 

I'm using svg2swf to collate a number of svg outputs into an swf file.  I've
got this working (mainly.) except that I can't control the looping behaviour
of the swf file.  In other words, when it's loaded into html it loops
continuously.  Is there any way to stop the animation looping, so it just
plays through once when loaded?  The code I use is (broadly):

 

               svg("testplot%d.svg",onefile = FALSE)

               for(j in 1:360){

                              print(cloud(x~y*z, groups=tail,
data=norm_dots_chart, screen=list(z=0,x=0,y=j)))

               }

               dev.off()

               output = svg2swf(sprintf("testplot%d.svg", 1:360), interval =
0.04)

               swf2html(output) 

 

Thank you!


	[[alternative HTML version deleted]]


From hui.du at savvyrookies.com  Mon Mar  9 23:39:33 2015
From: hui.du at savvyrookies.com (Hui Du)
Date: Mon, 9 Mar 2015 15:39:33 -0700
Subject: [R] How to access https page
Message-ID: <CAAu=cySbps8CcJCZ4P56CfXAZ-rgMWKmnG1RQVSVotM5Laa6aQ@mail.gmail.com>

Hi All,

I am trying to parse some information from website, say, a linkedin page.
The linkedin url was

url = "http://www.linkedin.com/in/huidu"

I had no problem to use readLines and XML package to collect the
information I need. However, that url became "
https://www.linkedin.com/in/huidu" now.

url = "https://www.linkedin.com/in/huidu"

It failed readLines function.

> readLines(url)
Error in file(con, "r") : cannot open the connection
In addition: Warning message:
In file(con, "r") : unsupported URL scheme


Do you know any way to read-in web information if the url is https? Thanks
a lot.

Hui

	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Tue Mar 10 01:13:16 2015
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Tue, 10 Mar 2015 11:13:16 +1100
Subject: [R] How to access https page
In-Reply-To: <CAAu=cySbps8CcJCZ4P56CfXAZ-rgMWKmnG1RQVSVotM5Laa6aQ@mail.gmail.com>
References: <CAAu=cySbps8CcJCZ4P56CfXAZ-rgMWKmnG1RQVSVotM5Laa6aQ@mail.gmail.com>
Message-ID: <CAKL8G3GpkQihtTH23p1HWgoMxZ=1ewzdtQ3if+imaxA5ko4Cag@mail.gmail.com>

Hi Hui,

I have used the source_url function in the devtools package with good
results.  Give it a shot!

Best,
Jorge.-


On Tue, Mar 10, 2015 at 9:39 AM, Hui Du <hui.du at savvyrookies.com> wrote:

> Hi All,
>
> I am trying to parse some information from website, say, a linkedin page.
> The linkedin url was
>
> url = "http://www.linkedin.com/in/huidu"
>
> I had no problem to use readLines and XML package to collect the
> information I need. However, that url became "
> https://www.linkedin.com/in/huidu" now.
>
> url = "https://www.linkedin.com/in/huidu"
>
> It failed readLines function.
>
> > readLines(url)
> Error in file(con, "r") : cannot open the connection
> In addition: Warning message:
> In file(con, "r") : unsupported URL scheme
>
>
> Do you know any way to read-in web information if the url is https? Thanks
> a lot.
>
> Hui
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From s.blomberg1 at uq.edu.au  Tue Mar 10 01:21:33 2015
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Tue, 10 Mar 2015 10:21:33 +1000
Subject: [R] APE
In-Reply-To: <1425935133781.19867@cardiff.ac.uk>
References: <1425935133781.19867@cardiff.ac.uk>
Message-ID: <54FE390D.4000309@uq.edu.au>

It's hard to tell what you did exactly. Did you do:

mytree <- compute.brlen(mytree)

? That should have worked. I've cc'ed this message to r-sig-phylo, which 
is the more appropriate forum.

Cheers,

Simon.

On 10/03/15 07:05, Beth Williams wrote:
> Dear All,
>
>
> I am having some trouble with R and would be extremely grateful if anyone has a way around this. I have loaded a nexus tree from PAUP into R using the command read.nexus and this loaded,  it was reported as "rooted; with no branch lengths". I then used the command "compute.brlen(mytree)" to compute the branch lengths and this was reported as "rooted; includes branch lengths". I added my community data (samp) and then tried to compute the phylogenetic diversity with the command "> pd(samp, mytree, include.root=TRUE)" however it said it could not calculate the PD as there were no branch lengths. Is there a way to incorporate the branch lengths into the calculation for PD?
>
>
> Thanks for your time,
>
> Beth
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat, AStat.
Senior Lecturer and Consultant Statistician
School of Biological Sciences
The University of Queensland
St. Lucia Queensland 4072
Australia
T: +61 7 3365 2506
email: S.Blomberg1_at_uq.edu.au
http://www.evolutionarystatistics.org

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

Basically, I'm not interested in doing research
and I never have been. I'm interested in
understanding, which is quite a different thing.
- David Blackwell


From tmrsg11 at gmail.com  Tue Mar 10 02:20:23 2015
From: tmrsg11 at gmail.com (C W)
Date: Mon, 9 Mar 2015 21:20:23 -0400
Subject: [R] Change the argument function inside R function in GPfit
	package
In-Reply-To: <CAE2FW2k00WdgUtv8Ewh=xK+zokPnP--RyHDtOHgmE1ZB-Q+jMg@mail.gmail.com>
References: <CAE2FW2k00WdgUtv8Ewh=xK+zokPnP--RyHDtOHgmE1ZB-Q+jMg@mail.gmail.com>
Message-ID: <CAE2FW2mj8UcXN=Y-Wsr234KM8aMBU2L_WZnKqz7T8RHG0yaRVA@mail.gmail.com>

I guess I should re-frame my question with real data.

> xx
     [,1]
[1,]  0.0
[2,]  0.2
[3,]  0.4
[4,]  0.6
[5,]  0.8
> yy
          [,1]
[1,] 0.0000000
[2,] 0.1652000
[3,] 0.4343223
[4,] 0.5996505
[5,] 0.7195857
> cor.mat
            [,1]       [,2]      [,3]       [,4]        [,5]
[1,] 1.000000000 0.64822376 0.1873066 0.02489388 0.001546431
[2,] 0.648223760 1.00000000 0.6482238 0.18730656 0.024893894
[3,] 0.187306626 0.64822376 1.0000000 0.64822364 0.187306626
[4,] 0.024893881 0.18730656 0.6482236 1.00000000 0.648223880
[5,] 0.001546431 0.02489389 0.1873066 0.64822388 1.000000000


or
xx <- structure(c(0, 0.199999994947575, 0.39999998989515,
0.600000028498471,
0.7999999797903), .Dim = c(5L, 1L))
yy <- structure(c(0, 0.165199951246566, 0.434322340944441,
0.599650488376824,
0.719585664934966), .Dim = c(5L, 1L))
cor.mat <- structure(c(1, 0.648223760165366, 0.187306626057348,
0.0248938807581023,
0.00154643121052443, 0.648223760165366, 1, 0.648223760165366,
0.187306559286623, 0.0248938938021518, 0.187306626057348,
0.648223760165366,
1, 0.648223640552069, 0.187306626057348, 0.0248938807581023,
0.187306559286623, 0.648223640552069, 1, 0.64822387977866,
0.00154643121052443,
0.0248938938021518, 0.187306626057348, 0.64822387977866, 1), .Dim = c(5L,
5L))


Now if I do,
> GP_fit(xx, yy, corr=cor.mat)
Error in corr$type : $ operator is invalid for atomic vectors


How could I fix it?

Thanks!

-M

On Mon, Mar 9, 2015 at 2:14 PM, C W <tmrsg11 at gmail.com> wrote:

> Hi R list,
>
> I am using the GPfit package to fit Gaussian Process model.
>
> The kernel in the package is,
> K(x, x') = sigma^2 * exp(x-x')^2
>
> My kernel have an extra term,
> K((x, z), (x', z')) = sigma^2 * exp(x-x')^2 * exp(z-z')^2
>
> The function corr_matrix() is,
> corr_matrix(X, beta, corr=list(type="exponential",power=1.95))
> github source: https://github.com/cran/GPfit/blob/master/R/corr_matrix.R
>
> I am changing the corr argument, so it looks like mine.  How should I do
> it?
>
> Also, what package do you guys recommend for GP modeling?  I know GPstuff
> or GPML but that's Matlab.
>
> Thanks very much.
>
> Mike
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Mar 10 02:42:43 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 09 Mar 2015 18:42:43 -0700
Subject: [R] Alpha not working in geom_rect
In-Reply-To: <CAEJCy7j6dN-=N86qhGbMR_Leiq8wq9sOqTSzY3nB-b0GPm+M4g@mail.gmail.com>
References: <1425749980919-4704291.post@n4.nabble.com>
	<CA+8X3fU9mzs_JtJ9MENYQ08A-MH96soBm5ej2cEm=h9eP6pnMA@mail.gmail.com>
	<CAEJCy7j6dN-=N86qhGbMR_Leiq8wq9sOqTSzY3nB-b0GPm+M4g@mail.gmail.com>
Message-ID: <3B099CE2-79B7-46DE-BCD7-4D8B63D9BE4D@dcn.davis.CA.us>

I have run into this a couple of times ... If you generate the rectangles once per row of your data, the fill gets more and more "dense" so your alpha seems to not work. The annotate call only paints the rectangle once so you don't have this problem.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 9, 2015 3:24:23 PM PDT, adel daoud <daouda at newschool.edu> wrote:
>Hi Jim,
>
>Thanks for the input but that did not work. I am suing Rstudio by the
>way
>and I guess that has a better device that would support ggplot output.
>
>The annotate options works but that does not explain why the geom_area
>does
>not work:
>annotate("rect", xmin=2, xmax=10, ymin=0,  ymax=1, fill="black",
>alpha=0.5)
>
>Best
>Adel
>
>
>--
>
>Adel Daoud, PhD, Researcher
>
>
>
>The New School for Social Research,
>
>Visiting Scholar in the Economics Department,
>
>6 East 16th Street New York, NY 10003,
>
>daouda at newschool.edu
>
>
>
>
>
>University of Gothenburg
>
>Department of Sociology and Work Science,
>
>Box 720
>
>405 30, G?teborg, Sweden
>
>Visiting address: Spr?ngkullsgatan 25, room F411
>
>Spr?ngkullsgatan 25, room K109
>
>+46 031-786 41 73
>
>Adel.daoud at sociology.gu.se
>
>On Sun, Mar 8, 2015 at 12:46 AM, Jim Lemon <drjimlemon at gmail.com>
>wrote:
>
>> Hi Adel,
>> Almost certainly because the device you were using doesn't support
>> transparency.Try it with a PDF device and check the resulting file in
>a PDF
>> reader:
>>
>> pdf("ad.pdf")
>> print(p)
>> dev.off()
>>
>> Jim
>>
>>
>> On Sun, Mar 8, 2015 at 4:39 AM, Adel <adel.daoud at socav.gu.se> wrote:
>>
>>> Hi
>>> I am trying to activate the alpha argument to work, but for some
>reason it
>>> does not to play with me. Anybody has an idea why?
>>>
>>>
>>> p <- ggplot(data = prediction_df, aes(x=x, y=prediction,
>fill=threshold))
>>> +
>>> geom_area(colour="black", size=.2, alpha=.4) +
>>> scale_fill_brewer(palette="Set1",
>>> breaks=rev(levels(prediction_df$threshold)))
>>> p + geom_rect(aes(xmin=2, xmax=10, ymin=(0), ymax=(1)),
>fill="black",
>>> alpha=0.5)
>>>
>>>
>>> prediction_df
>>>      x prediction  threshold
>>> 1  -10  0.5694161       noAF
>>> 2   -9  0.5700513       noAF
>>> 3   -8  0.5706863       noAF
>>> 4   -7  0.5713211       noAF
>>> 5   -6  0.5719556       noAF
>>> 6   -5  0.5725899       noAF
>>> 7   -4  0.5732240       noAF
>>> 8   -3  0.5738578       noAF
>>> 9   -2  0.5744914       noAF
>>> 10  -1  0.5751247       noAF
>>> 11   0  0.5757578       noAF
>>> 12   1  0.5763906       noAF
>>> 13   2  0.5770232       noAF
>>> 14   3  0.5776556       noAF
>>> 15   4  0.5782876       noAF
>>> 16   5  0.5789195       noAF
>>> 17   6  0.5795510       noAF
>>> 18   7  0.5801823       noAF
>>> 19   8  0.5808134       noAF
>>> 20   9  0.5814441       noAF
>>> 21  10  0.5820747       noAF
>>> 22 -10  0.2359140   singleAF
>>> 23  -9  0.2356847   singleAF
>>> 24  -8  0.2354550   singleAF
>>> 25  -7  0.2352249   singleAF
>>> 26  -6  0.2349943   singleAF
>>> 27  -5  0.2347634   singleAF
>>> 28  -4  0.2345321   singleAF
>>> 29  -3  0.2343003   singleAF
>>> 30  -2  0.2340682   singleAF
>>> 31  -1  0.2338356   singleAF
>>> 32   0  0.2336027   singleAF
>>> 33   1  0.2333694   singleAF
>>> 34   2  0.2331357   singleAF
>>> 35   3  0.2329016   singleAF
>>> 36   4  0.2326671   singleAF
>>> 37   5  0.2324322   singleAF
>>> 38   6  0.2321969   singleAF
>>> 39   7  0.2319613   singleAF
>>> 40   8  0.2317253   singleAF
>>> 41   9  0.2314889   singleAF
>>> 42  10  0.2312522   singleAF
>>> 43 -10  0.1946699 multipleAF
>>> 44  -9  0.1942640 multipleAF
>>> 45  -8  0.1938587 multipleAF
>>> 46  -7  0.1934540 multipleAF
>>> 47  -6  0.1930500 multipleAF
>>> 48  -5  0.1926467 multipleAF
>>> 49  -4  0.1922440 multipleAF
>>> 50  -3  0.1918419 multipleAF
>>> 51  -2  0.1914404 multipleAF
>>> 52  -1  0.1910397 multipleAF
>>> 53   0  0.1906395 multipleAF
>>> 54   1  0.1902400 multipleAF
>>> 55   2  0.1898411 multipleAF
>>> 56   3  0.1894429 multipleAF
>>> 57   4  0.1890453 multipleAF
>>> 58   5  0.1886483 multipleAF
>>> 59   6  0.1882520 multipleAF
>>> 60   7  0.1878564 multipleAF
>>> 61   8  0.1874613 multipleAF
>>> 62   9  0.1870669 multipleAF
>>> 63  10  0.1866732 multipleAF
>>>
>>>
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>>
>http://r.789695.n4.nabble.com/Alpha-not-working-in-geom-rect-tp4704291.html
>>> Sent from the R help mailing list archive at Nabble.com.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Tue Mar 10 07:28:38 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Mar 2015 06:28:38 +0000
Subject: [R] How to access https page
In-Reply-To: <CAAu=cySbps8CcJCZ4P56CfXAZ-rgMWKmnG1RQVSVotM5Laa6aQ@mail.gmail.com>
References: <CAAu=cySbps8CcJCZ4P56CfXAZ-rgMWKmnG1RQVSVotM5Laa6aQ@mail.gmail.com>
Message-ID: <54FE8F16.1070401@stats.ox.ac.uk>

On 09/03/2015 22:39, Hui Du wrote:
> Hi All,
>
> I am trying to parse some information from website, say, a linkedin page.
> The linkedin url was
>
> url = "http://www.linkedin.com/in/huidu"
>
> I had no problem to use readLines and XML package to collect the
> information I need. However, that url became "
> https://www.linkedin.com/in/huidu" now.
>
> url = "https://www.linkedin.com/in/huidu"
>
> It failed readLines function.
>
>> readLines(url)
> Error in file(con, "r") : cannot open the connection
> In addition: Warning message:
> In file(con, "r") : unsupported URL scheme
>
>
> Do you know any way to read-in web information if the url is https? Thanks
> a lot.

Try R-devel, soon to become R 3.2.0.  That has support for this on 
platforms where libcurl is installed (which should be possible almost 
everywhere).

You did not give the 'at a minimum' information required by the posting 
guide.  This has long been possible on Windows with --internet2.

>
> Hui
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From petr.pikal at precheza.cz  Tue Mar 10 09:16:18 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 10 Mar 2015 08:16:18 +0000
Subject: [R] Add sum line to plot of multiple x values
In-Reply-To: <87fv9erxpf.fsf@hornfels.zedat.fu-berlin.de>
References: <87k2yqs2as.fsf@hornfels.zedat.fu-berlin.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C231CF@SRVEXCHMBX.precheza.cz>
	<87fv9erxpf.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23303@SRVEXCHMBX.precheza.cz>

Hi

see inline

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Loris
> Bennett
> Sent: Monday, March 09, 2015 4:35 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Add sum line to plot of multiple x values
>
> PIKAL Petr <petr.pikal at precheza.cz> writes:
>
> > Hi
> >
> > Not extremely clear what do you want to plot. Do you want to add a
> > line which marks total number of files each day regardless of user?
> Or
> > a total number of files regardless of date coloured by user?
>
> Sorry, I was unclear.  I meant that I would like to plot the following:
>
> 1. For each user: the number of files for each date (my code does this)
> 2. The sum of files of all users for each date (this is what I still
>    need)
>
> > In each case you shall search functions geom_hline or geom_abline
> >
> > http://stackoverflow.com/questions/13254441/add-a-horizontal-line-to-
> plot-and-legend-in-ggplot2
>
> So I don't want a straight line

but in your code is

>> geom_line(data=d,aes(x=date,y=sum(files),group=date),colour='black')

so you apparently want some sort of line.

anyway, if I do

d.ag<-aggregate(d$files, list(d$date), sum)

I can add

p+geom_point(data=d.ag,aes(x=Group.1,y=x), size=5)

and I get summary points.

If you want lines you can do

p+geom_hline(data=d.ag,aes(yintercept=x, colour=Group.1))

or you can fiddle with geom_segment

>
> > ggplot is rather complicated but very flexible
>
> I don't mind ggplot being complicated, but I find the documentation a
> little impenetrable.

You can find plenty of help when you just try to google on the item searching. Actually this is what I do when the solution is not obvious or requires some hidden instruction.

Cheers
Petr

>
> Cheers,
>
> Loris
>
>
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Loris
> >> Bennett
> >> Sent: Monday, March 09, 2015 2:56 PM
> >> To: r-help at stat.math.ethz.ch
> >> Subject: [R] Add sum line to plot of multiple x values
> >>
> >> Hi,
> >>
> >> Here are my data:
> >>
> >> > d
> >>    user files       date
> >> 1 alice    18 2013-09-15
> >> 2   bob     5 2013-09-15
> >> 3 carol    21 2013-09-15
> >> 4 alice    22 2013-09-08
> >> 5   bob     9 2013-09-08
> >> 6 carol    14 2013-09-08
> >> 7 alice    26 2013-09-01
> >> 8   bob     3 2013-09-01
> >> 9 carol    22 2013-09-01
> >>
> >> I would like to plot the number of files against date for all users,
> so
> >> I have:
> >>
> >>   library(ggplot2)
> >>
> >>   people <- c("alice","bob","carol")
> >>   user <- c(rep(people,3))
> >>   files <- c(18,5,21,22,9,14,26,3,22)
> >>   date <- c(rep("2013-09-15",3),rep("2013-09-08",3),rep("2013-09-
> >> 01",3))
> >>   d <- data.frame(user=user,files=files,date=date)
> >>
> >>   p <- ggplot()
> >>   p <- p +
> geom_line(data=d,aes(x=date,y=files,group=user,colour=user))
> >>
> >> I would now like to add a line to show the total number of files as
> a
> >> function of date.  I tried
> >>
> >>   p <- p +
> >> geom_line(data=d,aes(x=date,y=sum(files),group=date),colour='black')
> >>
> >> I don't get a black line, but the plot is scaled such that I can see
> >> that sum(file) for all values of 'file', rather than those for each
> >> date, is being used.
> >>
> >> I would like to know how to do this correctly, but I would rather be
> >> able to work it out for myself.  However, if I decide, say, that I
> >> don't
> >> know exactly what the 'group' argument does, how do I find it out?
> >>
> >> ?geom_line doesn't have it, although the examples there use it.
> ?ggplot
> >> doesn't mention it. ?group gives me stuff about formatting text
> >> arguments. ??group only leads me to ?ggplot2::add_group, which also
> >> does
> >> not seem to help.
> >>
> >> Am I at fault for trying to learn R in an ad hoc manner, to which
> the
> >> documentation of R does not lend itself, or am I missing something?
> >>
> >> Cheers,
> >>
> >> Loris
> >>
> >> --
> >> This signature is currently under construction.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ________________________________

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Tue Mar 10 09:49:52 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 10 Mar 2015 08:49:52 +0000
Subject: [R] Show all elements
In-Reply-To: <CAKSaaFnUfs4+KarQ8ZAsnBu7rW7C=isAnKYaW5UfXxk6=v=5Vg@mail.gmail.com>
References: <CAKSaaFnUfs4+KarQ8ZAsnBu7rW7C=isAnKYaW5UfXxk6=v=5Vg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23343@SRVEXCHMBX.precheza.cz>

Hi

the source of your problem is most probably that aggregate uses conversion of group variable to factor and therefore empty level is lost.

From aggregate help page:

by a list of grouping elements, each as long as the variables in the data frame x. The elements are coerced to factors before use.

The only option I can come with is

> sapply(split(dados[,c(1,3)], dados$var), g1)
          A           B           C           D           E
 0.02589377  0.37123239 -0.57820359         NaN  0.39584514

but maybe there is some trick I did not find.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Leandro
> Marino
> Sent: Monday, March 09, 2015 2:48 PM
> To: r-help at r-project.org
> Subject: [R] Show all elements
>
> Hi,
>
> Look to the following code:
>
> set.seed(1)
> dados =
> data.frame(valor=rnorm(100),var=sample(LETTERS[c(1,2,3,5)],100,replace=
> T),peso=rpois(100,2))
> dados[1:10,]
> dados$var <- factor(dados$var,levels=LETTERS[1:5])
> table(dados$var)
>  A  B  C  D  E
> 31 31 19  0 19
>
> When I try to use summarize, Hmisc package it shows me the result
> without D category.
>
> g1 <- function(y) wtd.mean(y[,1],y[,2])
> summarize(dados[,c(1,3)], llist(var=dados$var), g1,stat.name = 'med')
>   var         med
> 1   A  0.02589377
> 2   B  0.37123239
> 3   C -0.57820359
> 4   E  0.39584514
>
> How do I get med = NA or something else with summarize?
>
> I realy need to the function to return all factors in the var even it
> they are an empty set.
>
> thanks in advance.
>
> leandro
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From marongiu.luigi at gmail.com  Tue Mar 10 12:26:28 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Tue, 10 Mar 2015 11:26:28 +0000
Subject: [R] pcrfit model for qpcR package
Message-ID: <CAMk+s2SLPrpSgXcxRpH4MtKoWVL9AWVTwYHPadi=21uSom+rbQ@mail.gmail.com>

Dear all,
I have been trying to apply the Cy0 algorithm of the package qpcR by
creating an object "obj" with the normalized fluorescent data from a
384 plate whose characteristics were TaqMan chemistry and 45 cycles.
The import of the object was successful but when I implemented the
pcrfit model (indicating in column 1 the number of cycles and in the
successive columns the actual data) I obtained an error in
model.frame.default. Yet the dataframe is composed by 384 columns (+ 1
for the cycles) and each by 45 rows (+ 1 for the column titles).
Would you have some tips on how to debug this problem?
Many thanks,
Best regards,
Luigi


>>>
Here is a sample of the code I have written (the result database is
attached for further reference)

> obj<-pcrimport2(
+   file="cq.data.txt",
+   sep="\t",
+   dec=".",
+   header=TRUE,
+   colClasses="numeric",
+   quote=""
+   )
# j<-2:385 to be implemented with a loop cycle, to read obj columns
# i<-1:384 to be implemented with a loop cycle, to write the results
# Cy is an object with 384 values
>   model<-pcrfit(obj, cyc=1, j, model=l4, do.optim=TRUE, robust=FALSE)
>   Cy[i]<-Cy0(model, plot=FALSE)


[1] Error in model.frame.default(formula = ~Fluo + Cycles, data =
DATA, weights = WEIGHTS,  :
  variable lengths differ (found for '(do.optim)')


From yixuan.qiu at cos.name  Tue Mar 10 01:20:14 2015
From: yixuan.qiu at cos.name (Yixuan Qiu)
Date: Mon, 9 Mar 2015 20:20:14 -0400
Subject: [R] svg2swf - controlling the looping of flash files
In-Reply-To: <00f101d05ab9$110abb70$33203250$@gmail.com>
References: <00f101d05ab9$110abb70$33203250$@gmail.com>
Message-ID: <CAFr_7yH4wzBzm1oA6V=cEp-GVYsqVntAFSRPkgu+0KzorXR0sw@mail.gmail.com>

Hello Paul,
So far there is no way to stop the animation after its first run. If this
feature is needed I could try to implement it in the future version of
R2SWF.


Best,
Yixuan

2015-03-09 18:33 GMT-04:00 Paul Sweeting <paul.j.sweeting at gmail.com>:

> Hi
>
>
>
> I'm using svg2swf to collate a number of svg outputs into an swf file.
> I've
> got this working (mainly.) except that I can't control the looping
> behaviour
> of the swf file.  In other words, when it's loaded into html it loops
> continuously.  Is there any way to stop the animation looping, so it just
> plays through once when loaded?  The code I use is (broadly):
>
>
>
>                svg("testplot%d.svg",onefile = FALSE)
>
>                for(j in 1:360){
>
>                               print(cloud(x~y*z, groups=tail,
> data=norm_dots_chart, screen=list(z=0,x=0,y=j)))
>
>                }
>
>                dev.off()
>
>                output = svg2swf(sprintf("testplot%d.svg", 1:360), interval
> =
> 0.04)
>
>                swf2html(output)
>
>
>
> Thank you!
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Yixuan Qiu <yixuan.qiu at cos.name>
Department of Statistics,
Purdue University

	[[alternative HTML version deleted]]


From jasmineangel0503 at gmail.com  Tue Mar 10 04:16:07 2015
From: jasmineangel0503 at gmail.com (=?UTF-8?B?5p2O5YCp6Zuv?=)
Date: Tue, 10 Mar 2015 11:16:07 +0800
Subject: [R] Error: cannot allocate vector of size 64.0 Mb When Using
	Read.zoo()
Message-ID: <CAFQz0UbH-111A+vf7-Vb8DAOL=Z6L_SGp5myz8Kv1BGERUXzYg@mail.gmail.com>

Hi all,

*Problem Description*
I encountered the *Error: cannot allocate vector of size 64.0 Mb* when I
was using read.zoo to convert a data.frame called 'origin' to zoo object
named 'target'

*About the Data & Code*
My data frame(origin) contains 5340191 obs. of 3 variables[Data,
Numeric,Character]
The code looks like
*target<-read.zoo(origin,format="%m/%d/%Y",index.column=1,split=3)*

*SessionInfo:*
R version 3.1.2 (2014-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Installed memory: 4.00 GB (3.82 GB usable)
Result of memory.size() : 3812.85

I try to calculate the required memory but I don't know what are the
operations in such conversion process. Therefore I have no idea if my data
is too mass to handle or I was using a low efficient method. Can anyone
help me with this problem?

By the way, as this is the first time I turn to mailing list for help, I am
not sure if I ask in the right manner. Please tell me if any
suggestions.Thank you.


Best regards,
Jasmine

	[[alternative HTML version deleted]]


From loris.bennett at fu-berlin.de  Tue Mar 10 10:15:17 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 10 Mar 2015 10:15:17 +0100
Subject: [R] Add sum line to plot of multiple x values
References: <87k2yqs2as.fsf@hornfels.zedat.fu-berlin.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C231CF@SRVEXCHMBX.precheza.cz>
	<87fv9erxpf.fsf@hornfels.zedat.fu-berlin.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23303@SRVEXCHMBX.precheza.cz>
Message-ID: <87bnk11ae2.fsf@hornfels.zedat.fu-berlin.de>

Hi Petr,

See inline.

PIKAL Petr <petr.pikal at precheza.cz> writes:

> Hi
>
> see inline
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Loris
>> Bennett
>> Sent: Monday, March 09, 2015 4:35 PM
>> To: r-help at stat.math.ethz.ch
>> Subject: Re: [R] Add sum line to plot of multiple x values
>>
>> PIKAL Petr <petr.pikal at precheza.cz> writes:
>>
>> > Hi
>> >
>> > Not extremely clear what do you want to plot. Do you want to add a
>> > line which marks total number of files each day regardless of user?
>> Or
>> > a total number of files regardless of date coloured by user?
>>
>> Sorry, I was unclear.  I meant that I would like to plot the following:
>>
>> 1. For each user: the number of files for each date (my code does this)
>> 2. The sum of files of all users for each date (this is what I still
>>    need)
>>
>> > In each case you shall search functions geom_hline or geom_abline
>> >
>> > http://stackoverflow.com/questions/13254441/add-a-horizontal-line-to-
>> plot-and-legend-in-ggplot2
>>
>> So I don't want a straight line
>
> but in your code is
>
>>> geom_line(data=d,aes(x=date,y=sum(files),group=date),colour='black')
>
> so you apparently want some sort of line.

Yes, but see below.

> anyway, if I do
>
> d.ag<-aggregate(d$files, list(d$date), sum)
>
> I can add
>
> p+geom_point(data=d.ag,aes(x=Group.1,y=x), size=5)
>
> and I get summary points.

Thanks, this works.

> If you want lines you can do
>
> p+geom_hline(data=d.ag,aes(yintercept=x, colour=Group.1))
>
> or you can fiddle with geom_segment

I don't want an hline, just a line joining the dots I get using
geom_point.  I thought something like

  p + geom_line(data=d.ag,aes(x=as.character(Group.1),y=x)

would work.  However, while I get a plot with axes labelled in the
correct ranges, no line is plotted.  Explicitly setting the colour with

  p + geom_line(data=d.ag,aes(x=as.character(Group.1),y=x),colour="red")

doesn't help.  What am I doing wrong?

>>
>> > ggplot is rather complicated but very flexible
>>
>> I don't mind ggplot being complicated, but I find the documentation a
>> little impenetrable.
>
> You can find plenty of help when you just try to google on the item
> searching. Actually this is what I do when the solution is not obvious
> or requires some hidden instruction.

This is what I normally resort to with varying degrees of success.  It
just seems a bit of a shame the some of the documentation for such a
good piece of software does indeed appear to be rather "hidden".

> Cheers
> Petr
>
>>
>> Cheers,
>>
>> Loris
>>
>>
>> >> -----Original Message-----
>> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> Loris
>> >> Bennett
>> >> Sent: Monday, March 09, 2015 2:56 PM
>> >> To: r-help at stat.math.ethz.ch
>> >> Subject: [R] Add sum line to plot of multiple x values
>> >>
>> >> Hi,
>> >>
>> >> Here are my data:
>> >>
>> >> > d
>> >>    user files       date
>> >> 1 alice    18 2013-09-15
>> >> 2   bob     5 2013-09-15
>> >> 3 carol    21 2013-09-15
>> >> 4 alice    22 2013-09-08
>> >> 5   bob     9 2013-09-08
>> >> 6 carol    14 2013-09-08
>> >> 7 alice    26 2013-09-01
>> >> 8   bob     3 2013-09-01
>> >> 9 carol    22 2013-09-01
>> >>
>> >> I would like to plot the number of files against date for all users,
>> so
>> >> I have:
>> >>
>> >>   library(ggplot2)
>> >>
>> >>   people <- c("alice","bob","carol")
>> >>   user <- c(rep(people,3))
>> >>   files <- c(18,5,21,22,9,14,26,3,22)
>> >>   date <- c(rep("2013-09-15",3),rep("2013-09-08",3),rep("2013-09-
>> >> 01",3))
>> >>   d <- data.frame(user=user,files=files,date=date)
>> >>
>> >>   p <- ggplot()
>> >>   p <- p +
>> geom_line(data=d,aes(x=date,y=files,group=user,colour=user))
>> >>
>> >> I would now like to add a line to show the total number of files as
>> a
>> >> function of date.  I tried
>> >>
>> >>   p <- p +
>> >> geom_line(data=d,aes(x=date,y=sum(files),group=date),colour='black')
>> >>
>> >> I don't get a black line, but the plot is scaled such that I can see
>> >> that sum(file) for all values of 'file', rather than those for each
>> >> date, is being used.
>> >>
>> >> I would like to know how to do this correctly, but I would rather be
>> >> able to work it out for myself.  However, if I decide, say, that I
>> >> don't
>> >> know exactly what the 'group' argument does, how do I find it out?
>> >>
>> >> ?geom_line doesn't have it, although the examples there use it.
>> ?ggplot
>> >> doesn't mention it. ?group gives me stuff about formatting text
>> >> arguments. ??group only leads me to ?ggplot2::add_group, which also
>> >> does
>> >> not seem to help.
>> >>
>> >> Am I at fault for trying to learn R in an ad hoc manner, to which
>> the
>> >> documentation of R does not lend itself, or am I missing something?
>> >>
>> >> Cheers,
>> >>
>> >> Loris
>> >>
>> >> --
>> >> This signature is currently under construction.
>> >>

-- 
This signature is currently under construction.


From kathryn.harrold at northampton.ac.uk  Tue Mar 10 11:24:03 2015
From: kathryn.harrold at northampton.ac.uk (kat123)
Date: Tue, 10 Mar 2015 03:24:03 -0700 (PDT)
Subject: [R] logit in "car" package
Message-ID: <1425983043570-4704408.post@n4.nabble.com>

I have run a logit data transformation in R using the logit function in the
package car.

http://cran.r-project.org/web/packages/car/car.pdf

If i run logit on a column of data that contains a 0 value it makes and
adjustment according to the literature of 0.025.

I thought this meant that it was running the transformation as 

log((p+0.025)/ (1-(p+0.025)))

However, if I run individual values through this equation they do not match
up to the output of the logit function.

Any suggestions?

 



--
View this message in context: http://r.789695.n4.nabble.com/logit-in-car-package-tp4704408.html
Sent from the R help mailing list archive at Nabble.com.


From daouda at newschool.edu  Tue Mar 10 03:15:02 2015
From: daouda at newschool.edu (adel daoud)
Date: Mon, 9 Mar 2015 22:15:02 -0400
Subject: [R] Alpha not working in geom_rect
In-Reply-To: <3B099CE2-79B7-46DE-BCD7-4D8B63D9BE4D@dcn.davis.CA.us>
References: <1425749980919-4704291.post@n4.nabble.com>
	<CA+8X3fU9mzs_JtJ9MENYQ08A-MH96soBm5ej2cEm=h9eP6pnMA@mail.gmail.com>
	<CAEJCy7j6dN-=N86qhGbMR_Leiq8wq9sOqTSzY3nB-b0GPm+M4g@mail.gmail.com>
	<3B099CE2-79B7-46DE-BCD7-4D8B63D9BE4D@dcn.davis.CA.us>
Message-ID: <CAEJCy7j75-zp2Jg-7qqDwBkU3PnQbzObVw2bSaVrE0oJE5xBfg@mail.gmail.com>

Thanks for the info Jeff. I will stick to using annotate()


--

Adel Daoud, PhD, Researcher



The New School for Social Research,

Visiting Scholar in the Economics Department,

6 East 16th Street New York, NY 10003,

daouda at newschool.edu





University of Gothenburg

Department of Sociology and Work Science,

Box 720

405 30, G?teborg, Sweden

Visiting address: Spr?ngkullsgatan 25, room F411

Spr?ngkullsgatan 25, room K109

+46 031-786 41 73

Adel.daoud at sociology.gu.se

On Mon, Mar 9, 2015 at 9:42 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I have run into this a couple of times ... If you generate the rectangles
> once per row of your data, the fill gets more and more "dense" so your
> alpha seems to not work. The annotate call only paints the rectangle once
> so you don't have this problem.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On March 9, 2015 3:24:23 PM PDT, adel daoud <daouda at newschool.edu> wrote:
> >Hi Jim,
> >
> >Thanks for the input but that did not work. I am suing Rstudio by the
> >way
> >and I guess that has a better device that would support ggplot output.
> >
> >The annotate options works but that does not explain why the geom_area
> >does
> >not work:
> >annotate("rect", xmin=2, xmax=10, ymin=0,  ymax=1, fill="black",
> >alpha=0.5)
> >
> >Best
> >Adel
> >
> >
> >--
> >
> >Adel Daoud, PhD, Researcher
> >
> >
> >
> >The New School for Social Research,
> >
> >Visiting Scholar in the Economics Department,
> >
> >6 East 16th Street New York, NY 10003,
> >
> >daouda at newschool.edu
> >
> >
> >
> >
> >
> >University of Gothenburg
> >
> >Department of Sociology and Work Science,
> >
> >Box 720
> >
> >405 30, G?teborg, Sweden
> >
> >Visiting address: Spr?ngkullsgatan 25, room F411
> >
> >Spr?ngkullsgatan 25, room K109
> >
> >+46 031-786 41 73
> >
> >Adel.daoud at sociology.gu.se
> >
> >On Sun, Mar 8, 2015 at 12:46 AM, Jim Lemon <drjimlemon at gmail.com>
> >wrote:
> >
> >> Hi Adel,
> >> Almost certainly because the device you were using doesn't support
> >> transparency.Try it with a PDF device and check the resulting file in
> >a PDF
> >> reader:
> >>
> >> pdf("ad.pdf")
> >> print(p)
> >> dev.off()
> >>
> >> Jim
> >>
> >>
> >> On Sun, Mar 8, 2015 at 4:39 AM, Adel <adel.daoud at socav.gu.se> wrote:
> >>
> >>> Hi
> >>> I am trying to activate the alpha argument to work, but for some
> >reason it
> >>> does not to play with me. Anybody has an idea why?
> >>>
> >>>
> >>> p <- ggplot(data = prediction_df, aes(x=x, y=prediction,
> >fill=threshold))
> >>> +
> >>> geom_area(colour="black", size=.2, alpha=.4) +
> >>> scale_fill_brewer(palette="Set1",
> >>> breaks=rev(levels(prediction_df$threshold)))
> >>> p + geom_rect(aes(xmin=2, xmax=10, ymin=(0), ymax=(1)),
> >fill="black",
> >>> alpha=0.5)
> >>>
> >>>
> >>> prediction_df
> >>>      x prediction  threshold
> >>> 1  -10  0.5694161       noAF
> >>> 2   -9  0.5700513       noAF
> >>> 3   -8  0.5706863       noAF
> >>> 4   -7  0.5713211       noAF
> >>> 5   -6  0.5719556       noAF
> >>> 6   -5  0.5725899       noAF
> >>> 7   -4  0.5732240       noAF
> >>> 8   -3  0.5738578       noAF
> >>> 9   -2  0.5744914       noAF
> >>> 10  -1  0.5751247       noAF
> >>> 11   0  0.5757578       noAF
> >>> 12   1  0.5763906       noAF
> >>> 13   2  0.5770232       noAF
> >>> 14   3  0.5776556       noAF
> >>> 15   4  0.5782876       noAF
> >>> 16   5  0.5789195       noAF
> >>> 17   6  0.5795510       noAF
> >>> 18   7  0.5801823       noAF
> >>> 19   8  0.5808134       noAF
> >>> 20   9  0.5814441       noAF
> >>> 21  10  0.5820747       noAF
> >>> 22 -10  0.2359140   singleAF
> >>> 23  -9  0.2356847   singleAF
> >>> 24  -8  0.2354550   singleAF
> >>> 25  -7  0.2352249   singleAF
> >>> 26  -6  0.2349943   singleAF
> >>> 27  -5  0.2347634   singleAF
> >>> 28  -4  0.2345321   singleAF
> >>> 29  -3  0.2343003   singleAF
> >>> 30  -2  0.2340682   singleAF
> >>> 31  -1  0.2338356   singleAF
> >>> 32   0  0.2336027   singleAF
> >>> 33   1  0.2333694   singleAF
> >>> 34   2  0.2331357   singleAF
> >>> 35   3  0.2329016   singleAF
> >>> 36   4  0.2326671   singleAF
> >>> 37   5  0.2324322   singleAF
> >>> 38   6  0.2321969   singleAF
> >>> 39   7  0.2319613   singleAF
> >>> 40   8  0.2317253   singleAF
> >>> 41   9  0.2314889   singleAF
> >>> 42  10  0.2312522   singleAF
> >>> 43 -10  0.1946699 multipleAF
> >>> 44  -9  0.1942640 multipleAF
> >>> 45  -8  0.1938587 multipleAF
> >>> 46  -7  0.1934540 multipleAF
> >>> 47  -6  0.1930500 multipleAF
> >>> 48  -5  0.1926467 multipleAF
> >>> 49  -4  0.1922440 multipleAF
> >>> 50  -3  0.1918419 multipleAF
> >>> 51  -2  0.1914404 multipleAF
> >>> 52  -1  0.1910397 multipleAF
> >>> 53   0  0.1906395 multipleAF
> >>> 54   1  0.1902400 multipleAF
> >>> 55   2  0.1898411 multipleAF
> >>> 56   3  0.1894429 multipleAF
> >>> 57   4  0.1890453 multipleAF
> >>> 58   5  0.1886483 multipleAF
> >>> 59   6  0.1882520 multipleAF
> >>> 60   7  0.1878564 multipleAF
> >>> 61   8  0.1874613 multipleAF
> >>> 62   9  0.1870669 multipleAF
> >>> 63  10  0.1866732 multipleAF
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> --
> >>> View this message in context:
> >>>
> >
> http://r.789695.n4.nabble.com/Alpha-not-working-in-geom-rect-tp4704291.html
> >>> Sent from the R help mailing list archive at Nabble.com.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From namrathakmurthy.05 at gmail.com  Tue Mar 10 06:49:09 2015
From: namrathakmurthy.05 at gmail.com (Namratha K)
Date: Tue, 10 Mar 2015 11:19:09 +0530
Subject: [R] Are there any implemented function for A/B testing?
Message-ID: <CAAZhZmaR_wEA=mvQz5wm22YkBSsVt_TWc9OjanUTQRmz0vycvQ@mail.gmail.com>

Is there any method or built-in function for implementing a/b testing using
R language
Are there any function developed to implement a/b testing in R language?

	[[alternative HTML version deleted]]


From loris.bennett at fu-berlin.de  Tue Mar 10 13:42:30 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 10 Mar 2015 13:42:30 +0100
Subject: [R] Add sum line to plot of multiple x values
References: <87k2yqs2as.fsf@hornfels.zedat.fu-berlin.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C231CF@SRVEXCHMBX.precheza.cz>
	<87fv9erxpf.fsf@hornfels.zedat.fu-berlin.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23303@SRVEXCHMBX.precheza.cz>
	<87bnk11ae2.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <87mw3lyqfd.fsf@hornfels.zedat.fu-berlin.de>

Loris Bennett <loris.bennett at fu-berlin.de> writes:

> Hi Petr,
>
> See inline.
>
> PIKAL Petr <petr.pikal at precheza.cz> writes:
>
>> Hi
>>
>> see inline
>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Loris
>>> Bennett
>>> Sent: Monday, March 09, 2015 4:35 PM
>>> To: r-help at stat.math.ethz.ch
>>> Subject: Re: [R] Add sum line to plot of multiple x values
>>>
>>> PIKAL Petr <petr.pikal at precheza.cz> writes:
>>>
>>> > Hi
>>> >
>>> > Not extremely clear what do you want to plot. Do you want to add a
>>> > line which marks total number of files each day regardless of user?
>>> Or
>>> > a total number of files regardless of date coloured by user?
>>>
>>> Sorry, I was unclear.  I meant that I would like to plot the following:
>>>
>>> 1. For each user: the number of files for each date (my code does this)
>>> 2. The sum of files of all users for each date (this is what I still
>>>    need)
>>>
>>> > In each case you shall search functions geom_hline or geom_abline
>>> >
>>> > http://stackoverflow.com/questions/13254441/add-a-horizontal-line-to-
>>> plot-and-legend-in-ggplot2
>>>
>>> So I don't want a straight line
>>
>> but in your code is
>>
>>>> geom_line(data=d,aes(x=date,y=sum(files),group=date),colour='black')
>>
>> so you apparently want some sort of line.
>
> Yes, but see below.
>
>> anyway, if I do
>>
>> d.ag<-aggregate(d$files, list(d$date), sum)
>>
>> I can add
>>
>> p+geom_point(data=d.ag,aes(x=Group.1,y=x), size=5)
>>
>> and I get summary points.
>
> Thanks, this works.
>
>> If you want lines you can do
>>
>> p+geom_hline(data=d.ag,aes(yintercept=x, colour=Group.1))
>>
>> or you can fiddle with geom_segment
>
> I don't want an hline, just a line joining the dots I get using
> geom_point.  I thought something like
>
>   p + geom_line(data=d.ag,aes(x=as.character(Group.1),y=x)
>
> would work.  However, while I get a plot with axes labelled in the
> correct ranges, no line is plotted.  Explicitly setting the colour with
>
>   p + geom_line(data=d.ag,aes(x=as.character(Group.1),y=x),colour="red")
>
> doesn't help.  What am I doing wrong?

I found the answer by googling "geom_line doesn?t draw lines".  The
following does what I want:

  ggplot(data=d.ag,aes(x=as.character(Group.1),y=x,group=1)) +_geom_line()

My understanding is that, because 'Group.1' is a factor, the 'x' values
are not considered as belonging to the same group and geom_line only
connects points within a group.

>>> > ggplot is rather complicated but very flexible
>>>
>>> I don't mind ggplot being complicated, but I find the documentation a
>>> little impenetrable.
>>
>> You can find plenty of help when you just try to google on the item
>> searching. Actually this is what I do when the solution is not obvious
>> or requires some hidden instruction.
>
> This is what I normally resort to with varying degrees of success.  It
> just seems a bit of a shame the some of the documentation for such a
> good piece of software does indeed appear to be rather "hidden".
>
>> Cheers
>> Petr
>>
>>>
>>> Cheers,
>>>
>>> Loris
>>>
>>>
>>> >> -----Original Message-----
>>> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> Loris
>>> >> Bennett
>>> >> Sent: Monday, March 09, 2015 2:56 PM
>>> >> To: r-help at stat.math.ethz.ch
>>> >> Subject: [R] Add sum line to plot of multiple x values
>>> >>
>>> >> Hi,
>>> >>
>>> >> Here are my data:
>>> >>
>>> >> > d
>>> >>    user files       date
>>> >> 1 alice    18 2013-09-15
>>> >> 2   bob     5 2013-09-15
>>> >> 3 carol    21 2013-09-15
>>> >> 4 alice    22 2013-09-08
>>> >> 5   bob     9 2013-09-08
>>> >> 6 carol    14 2013-09-08
>>> >> 7 alice    26 2013-09-01
>>> >> 8   bob     3 2013-09-01
>>> >> 9 carol    22 2013-09-01
>>> >>
>>> >> I would like to plot the number of files against date for all users,
>>> so
>>> >> I have:
>>> >>
>>> >>   library(ggplot2)
>>> >>
>>> >>   people <- c("alice","bob","carol")
>>> >>   user <- c(rep(people,3))
>>> >>   files <- c(18,5,21,22,9,14,26,3,22)
>>> >>   date <- c(rep("2013-09-15",3),rep("2013-09-08",3),rep("2013-09-
>>> >> 01",3))
>>> >>   d <- data.frame(user=user,files=files,date=date)
>>> >>
>>> >>   p <- ggplot()
>>> >>   p <- p +
>>> geom_line(data=d,aes(x=date,y=files,group=user,colour=user))
>>> >>
>>> >> I would now like to add a line to show the total number of files as
>>> a
>>> >> function of date.  I tried
>>> >>
>>> >>   p <- p +
>>> >> geom_line(data=d,aes(x=date,y=sum(files),group=date),colour='black')
>>> >>
>>> >> I don't get a black line, but the plot is scaled such that I can see
>>> >> that sum(file) for all values of 'file', rather than those for each
>>> >> date, is being used.
>>> >>
>>> >> I would like to know how to do this correctly, but I would rather be
>>> >> able to work it out for myself.  However, if I decide, say, that I
>>> >> don't
>>> >> know exactly what the 'group' argument does, how do I find it out?
>>> >>
>>> >> ?geom_line doesn't have it, although the examples there use it.
>>> ?ggplot
>>> >> doesn't mention it. ?group gives me stuff about formatting text
>>> >> arguments. ??group only leads me to ?ggplot2::add_group, which also
>>> >> does
>>> >> not seem to help.
>>> >>
>>> >> Am I at fault for trying to learn R in an ad hoc manner, to which
>>> the
>>> >> documentation of R does not lend itself, or am I missing something?
>>> >>
>>> >> Cheers,
>>> >>
>>> >> Loris
>>> >>
>>> >> --
>>> >> This signature is currently under construction.
>>> >>

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From sarah.goslee at gmail.com  Tue Mar 10 13:50:55 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 10 Mar 2015 08:50:55 -0400
Subject: [R] Are there any implemented function for A/B testing?
In-Reply-To: <CAAZhZmaR_wEA=mvQz5wm22YkBSsVt_TWc9OjanUTQRmz0vycvQ@mail.gmail.com>
References: <CAAZhZmaR_wEA=mvQz5wm22YkBSsVt_TWc9OjanUTQRmz0vycvQ@mail.gmail.com>
Message-ID: <CAM_vjunv2W=Xix2RF_xtthFgUSw2Bzef6++FQR2Ja2qtJzJJKA@mail.gmail.com>

You already asked this, and show no signs of having either read the
responses or out any effort into trying to find out yourself.

Go to
http://rseek.org
and search for
"a/b testing"

Read the results, try out the examples. After that, if you still have
specific R questions, this list is the place to come for help. But you've
got to put some effort in yourself.

Sarah

On Tuesday, March 10, 2015, Namratha K <namrathakmurthy.05 at gmail.com> wrote:

> Is there any method or built-in function for implementing a/b testing using
> R language
> Are there any function developed to implement a/b testing in R language?
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Tue Mar 10 14:31:49 2015
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 10 Mar 2015 09:31:49 -0400
Subject: [R] logit in "car" package
In-Reply-To: <1425983043570-4704408.post@n4.nabble.com>
References: <1425983043570-4704408.post@n4.nabble.com>
Message-ID: <web-551325838@cgpsrv2.cis.mcmaster.ca>

Dear Kathryn,

On Tue, 10 Mar 2015 03:24:03 -0700 (PDT)
 kat123 <kathryn.harrold at northampton.ac.uk> wrote:
> I have run a logit data transformation in R using the logit function in the
> package car.
> 
> http://cran.r-project.org/web/packages/car/car.pdf
> 
> If i run logit on a column of data that contains a 0 value it makes and
> adjustment according to the literature of 0.025.
> 
> I thought this meant that it was running the transformation as 
> 
> log((p+0.025)/ (1-(p+0.025)))

It's not that simple -- think what would happen if there were both 0s and 1s in the data:

> p <- 0:1

> log((p+0.025)/ (1-(p+0.025)))
[1] -3.663562       NaN
Warning message:
In log((p + 0.025)/(1 - (p + 0.025))) : NaNs produced

> logit(p)
[1] -3.663562  3.663562
Warning message:
In logit(p) : proportions remapped to (0.025, 0.975)

> log(c(0.025, 0.975)/(1 - c(0.025, 0.975)))
[1] -3.663562  3.663562


To see what logit() does simply print it by typing logit at the command prompt.

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	
> 
> However, if I run individual values through this equation they do not match
> up to the output of the logit function.
> 
> Any suggestions?
> 
>  
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/logit-in-car-package-tp4704408.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nashjc at uottawa.ca  Tue Mar 10 14:39:20 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Tue, 10 Mar 2015 09:39:20 -0400
Subject: [R] Help with optim() to maximize log-likelihood
In-Reply-To: <mailman.1.1425985202.24342.r-help@r-project.org>
References: <mailman.1.1425985202.24342.r-help@r-project.org>
Message-ID: <54FEF408.6090707@uottawa.ca>

1) It helps to include the require statements for those of us who work
outside your particular box.
   lme4 and (as far as I can guess) fastGHQuad
are needed.

2) Most nonlinear functions have domains where they cannot be
evaluated. I'd be richer than Warren Buffett if I got $5 for
each time someone said "your optimizer doesn't work" and I
found   f(start, ...) was NaN or Inf, as in this case, i.e.,

 start <- c(plogis(sum(Y/m)),log(sigma2H))
 cat("starting params:")
 print(start)
 tryf0 <- ll(start,Y,m)
 print(tryf0)


It really is worthwhile actually computing your function at the initial
parameters EVERY time. (Or turn on the trace etc.)

JN

On 15-03-10 07:00 AM, r-help-request at r-project.org wrote:
> Message: 12
> Date: Mon, 9 Mar 2015 16:18:06 +0200
> From: Sophia Kyriakou <sophia.kyriakou17 at gmail.com>
> To: r-help at r-project.org
> Subject: [R] Help with optim() to maximize log-likelihood
> Message-ID:
> 	<CAO4gA+qokumHoZwvbU7EY3xaBBo2LnQjRcWxQkzcHm3U9OZ6kw at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> hello, I am using the optim function to maximize the log likelihood of a
> generalized linear mixed model and I am trying to replicate glmer's
> estimated components. If I set both the sample and subject size to q=m=100
> I replicate glmer's results for the random intercept model with parameters
>  beta=-1 and sigma^2=1. But if I change beta to 2 glmer works and optim
> gives me the error message "function cannot be evaluated at initial
> parameters".
> 
> If anyone could please help?
> Thanks
> 
>  # likelihood function
>  ll <- function(x,Y,m){
>  beta <- x[1]
>  psi <- x[2]
>  q <- length(Y)
>   p <- 20
>  rule20 <- gaussHermiteData(p)
>  wStar <- exp(rule20$x * rule20$x + log(rule20$w))
>  # Integrate over(-Inf, +Inf) using adaptive Gauss-Hermite quadrature
>  g <- function(alpha, beta, psi, y, m) {-y+m*exp(alpha + beta)/(1 +
> exp(alpha + beta)) + alpha/exp(psi)}
>  DDfLik <- deriv(expression(-y+m*exp(alpha + beta)/(1 + exp(alpha + beta))
> + alpha/exp(psi)),
>  namevec = "alpha", func = TRUE,function.arg = c("alpha", "beta", "psi",
> "y", "m"))
>    int0 <- rep(NA,q)
>  piYc_ir <- matrix(NA,q,p)
>  for (i in 1:q){
>  muHat <- uniroot(g, c(-10, 10),extendInt ="yes", beta = beta, psi = psi, y
> = Y[i], m = m)$root
>  jHat <- attr(DDfLik(alpha = muHat, beta, psi, Y[i], m), "gradient")
>  sigmaHat <- 1/sqrt(jHat)
>  z <- muHat + sqrt(2) * sigmaHat * rule20$x
>  piYc_ir[i,] <-
> choose(m,Y[i])*exp(Y[i]*(z+beta))*exp(-z^2/(2*exp(psi)))/((1+exp(z+beta))^m*sqrt(2*pi*exp(psi)))
>  int0[i] <- sqrt(2)*sigmaHat*sum(wStar*piYc_ir[i,])
>  }
>  ll <- -sum(log(int0))
>  ll
>  }
> 
>  beta <- 2
>  sigma2 <- 1
>  m <- 100
>  q <- 100
> 
>  cl <- seq.int(q)
>  tot <- rep(m,q)
> 
>  set.seed(123)
>  alpha <- rnorm(q, 0, sqrt(sigma2))
>  Y <- rbinom(q,m,plogis(alpha+beta))
> 
>  dat <- data.frame(y = Y, tot = tot, cl = cl)
>  f1 <- glmer(cbind(y, tot - y) ~ 1 + (1 | cl), data = dat,family =
> binomial(),nAGQ = 20)
>  betaH <- summary(f1)$coefficients[1]
>  sigma2H <- as.numeric(summary(f1)$varcor)
>  thetaglmer <- c(betaH,sigma2H)
> 
>  logL <- function(x) ll(x,Y,m)
>  thetaMLb <- optim(c(plogis(sum(Y/m)),log(sigma2H)),fn=logL)$par
>  Error in optim(c(plogis(sum(Y/m)), log(sigma2H)), fn = logL) :  function
> cannot be evaluated at initial parameters
> 
> thetaglmer
> [1] 2.1128529 0.8311484
>  (thetaML <- c(thetaMLb[1],exp(thetaMLb[2])))
> 
> 	[[alternative HTML version deleted]]
>


From petr.pikal at precheza.cz  Tue Mar 10 14:41:15 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 10 Mar 2015 13:41:15 +0000
Subject: [R] Add sum line to plot of multiple x values
In-Reply-To: <87mw3lyqfd.fsf@hornfels.zedat.fu-berlin.de>
References: <87k2yqs2as.fsf@hornfels.zedat.fu-berlin.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C231CF@SRVEXCHMBX.precheza.cz>
	<87fv9erxpf.fsf@hornfels.zedat.fu-berlin.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23303@SRVEXCHMBX.precheza.cz>
	<87bnk11ae2.fsf@hornfels.zedat.fu-berlin.de>
	<87mw3lyqfd.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C234F1@SRVEXCHMBX.precheza.cz>

Hi

Yes, your understanding is correct

the same can be achieved by:

p+geom_point(data=d.ag,aes(x=Group.1,y=x), size=5)+
geom_line(data=d.ag,aes(x=1:3, y=x))

as factors are treated from 1 to number of levels if given as x aestetics.

The whole code is

library(ggplot2)
people <- c("alice","bob","carol")
user <- c(rep(people,3))
files <- c(18,5,21,22,9,14,26,3,22)
date <- c(rep("2013-09-15",3),rep("2013-09-08",3),rep("2013-09-01",3))
d <- data.frame(user=user,files=files,date=date)
p <- ggplot()
p <- p + geom_line(data=d,aes(x=date,y=files,group=user,colour=user))
d.ag<-aggregate(d$files, list(d$date), sum)
p+geom_point(data=d.ag,aes(x=Group.1,y=x), size=5)+
geom_line(data=d.ag,aes(x=1:3, y=x))

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Loris
> Bennett
> Sent: Tuesday, March 10, 2015 1:43 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Add sum line to plot of multiple x values
>
> Loris Bennett <loris.bennett at fu-berlin.de> writes:
>
> > Hi Petr,
> >
> > See inline.
> >
> > PIKAL Petr <petr.pikal at precheza.cz> writes:
> >
> >> Hi
> >>
> >> see inline
> >>
> >>> -----Original Message-----
> >>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> >>> Loris Bennett
> >>> Sent: Monday, March 09, 2015 4:35 PM
> >>> To: r-help at stat.math.ethz.ch
> >>> Subject: Re: [R] Add sum line to plot of multiple x values
> >>>
> >>> PIKAL Petr <petr.pikal at precheza.cz> writes:
> >>>
> >>> > Hi
> >>> >
> >>> > Not extremely clear what do you want to plot. Do you want to add
> a
> >>> > line which marks total number of files each day regardless of
> user?
> >>> Or
> >>> > a total number of files regardless of date coloured by user?
> >>>
> >>> Sorry, I was unclear.  I meant that I would like to plot the
> following:
> >>>
> >>> 1. For each user: the number of files for each date (my code does
> >>> this) 2. The sum of files of all users for each date (this is what
> I still
> >>>    need)
> >>>
> >>> > In each case you shall search functions geom_hline or geom_abline
> >>> >
> >>> > http://stackoverflow.com/questions/13254441/add-a-horizontal-
> line-
> >>> > to-
> >>> plot-and-legend-in-ggplot2
> >>>
> >>> So I don't want a straight line
> >>
> >> but in your code is
> >>
> >>>>
> geom_line(data=d,aes(x=date,y=sum(files),group=date),colour='black'
> >>>> )
> >>
> >> so you apparently want some sort of line.
> >
> > Yes, but see below.
> >
> >> anyway, if I do
> >>
> >> d.ag<-aggregate(d$files, list(d$date), sum)
> >>
> >> I can add
> >>
> >> p+geom_point(data=d.ag,aes(x=Group.1,y=x), size=5)
> >>
> >> and I get summary points.
> >
> > Thanks, this works.
> >
> >> If you want lines you can do
> >>
> >> p+geom_hline(data=d.ag,aes(yintercept=x, colour=Group.1))
> >>
> >> or you can fiddle with geom_segment
> >
> > I don't want an hline, just a line joining the dots I get using
> > geom_point.  I thought something like
> >
> >   p + geom_line(data=d.ag,aes(x=as.character(Group.1),y=x)
> >
> > would work.  However, while I get a plot with axes labelled in the
> > correct ranges, no line is plotted.  Explicitly setting the colour
> > with
> >
> >   p +
> > geom_line(data=d.ag,aes(x=as.character(Group.1),y=x),colour="red")
> >
> > doesn't help.  What am I doing wrong?
>
> I found the answer by googling "geom_line doesn?t draw lines".  The
> following does what I want:
>
>   ggplot(data=d.ag,aes(x=as.character(Group.1),y=x,group=1))
> +_geom_line()
>
> My understanding is that, because 'Group.1' is a factor, the 'x' values
> are not considered as belonging to the same group and geom_line only
> connects points within a group.
>
> >>> > ggplot is rather complicated but very flexible
> >>>
> >>> I don't mind ggplot being complicated, but I find the documentation
> >>> a little impenetrable.
> >>
> >> You can find plenty of help when you just try to google on the item
> >> searching. Actually this is what I do when the solution is not
> >> obvious or requires some hidden instruction.
> >
> > This is what I normally resort to with varying degrees of success.
> It
> > just seems a bit of a shame the some of the documentation for such a
> > good piece of software does indeed appear to be rather "hidden".
> >
> >> Cheers
> >> Petr
> >>
> >>>
> >>> Cheers,
> >>>
> >>> Loris
> >>>
> >>>
> >>> >> -----Original Message-----
> >>> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> >>> Loris
> >>> >> Bennett
> >>> >> Sent: Monday, March 09, 2015 2:56 PM
> >>> >> To: r-help at stat.math.ethz.ch
> >>> >> Subject: [R] Add sum line to plot of multiple x values
> >>> >>
> >>> >> Hi,
> >>> >>
> >>> >> Here are my data:
> >>> >>
> >>> >> > d
> >>> >>    user files       date
> >>> >> 1 alice    18 2013-09-15
> >>> >> 2   bob     5 2013-09-15
> >>> >> 3 carol    21 2013-09-15
> >>> >> 4 alice    22 2013-09-08
> >>> >> 5   bob     9 2013-09-08
> >>> >> 6 carol    14 2013-09-08
> >>> >> 7 alice    26 2013-09-01
> >>> >> 8   bob     3 2013-09-01
> >>> >> 9 carol    22 2013-09-01
> >>> >>
> >>> >> I would like to plot the number of files against date for all
> >>> >> users,
> >>> so
> >>> >> I have:
> >>> >>
> >>> >>   library(ggplot2)
> >>> >>
> >>> >>   people <- c("alice","bob","carol")
> >>> >>   user <- c(rep(people,3))
> >>> >>   files <- c(18,5,21,22,9,14,26,3,22)
> >>> >>   date <- c(rep("2013-09-15",3),rep("2013-09-08",3),rep("2013-
> 09-
> >>> >> 01",3))
> >>> >>   d <- data.frame(user=user,files=files,date=date)
> >>> >>
> >>> >>   p <- ggplot()
> >>> >>   p <- p +
> >>> geom_line(data=d,aes(x=date,y=files,group=user,colour=user))
> >>> >>
> >>> >> I would now like to add a line to show the total number of files
> >>> >> as
> >>> a
> >>> >> function of date.  I tried
> >>> >>
> >>> >>   p <- p +
> >>> >>
> geom_line(data=d,aes(x=date,y=sum(files),group=date),colour='blac
> >>> >> k')
> >>> >>
> >>> >> I don't get a black line, but the plot is scaled such that I can
> >>> >> see that sum(file) for all values of 'file', rather than those
> >>> >> for each date, is being used.
> >>> >>
> >>> >> I would like to know how to do this correctly, but I would
> rather
> >>> >> be able to work it out for myself.  However, if I decide, say,
> >>> >> that I don't know exactly what the 'group' argument does, how do
> >>> >> I find it out?
> >>> >>
> >>> >> ?geom_line doesn't have it, although the examples there use it.
> >>> ?ggplot
> >>> >> doesn't mention it. ?group gives me stuff about formatting text
> >>> >> arguments. ??group only leads me to ?ggplot2::add_group, which
> >>> >> also does not seem to help.
> >>> >>
> >>> >> Am I at fault for trying to learn R in an ad hoc manner, to
> which
> >>> the
> >>> >> documentation of R does not lend itself, or am I missing
> something?
> >>> >>
> >>> >> Cheers,
> >>> >>
> >>> >> Loris
> >>> >>
> >>> >> --
> >>> >> This signature is currently under construction.
> >>> >>
>
> --
> Dr. Loris Bennett (Mr.)
> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-
> berlin.de
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From kw1958 at gmail.com  Tue Mar 10 15:25:10 2015
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Tue, 10 Mar 2015 10:25:10 -0400
Subject: [R] C#
Message-ID: <6427B89C-ABA7-4519-9B3D-073F59E9E813@gmail.com>

I will keep this short as this might be the wrong list:

I have found one (beta) project that allows R to interface with C#.

Are there others? Any favorites.

Best,
KW


From ligges at statistik.tu-dortmund.de  Tue Mar 10 15:48:55 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 10 Mar 2015 15:48:55 +0100
Subject: [R] Error: cannot allocate vector of size 64.0 Mb When Using
 Read.zoo()
In-Reply-To: <CAFQz0UbH-111A+vf7-Vb8DAOL=Z6L_SGp5myz8Kv1BGERUXzYg@mail.gmail.com>
References: <CAFQz0UbH-111A+vf7-Vb8DAOL=Z6L_SGp5myz8Kv1BGERUXzYg@mail.gmail.com>
Message-ID: <54FF0457.60005@statistik.tu-dortmund.de>



On 10.03.2015 04:16, ??? wrote:
> Hi all,
>
> *Problem Description*
> I encountered the *Error: cannot allocate vector of size 64.0 Mb* when I
> was using read.zoo to convert a data.frame called 'origin' to zoo object
> named 'target'
>
> *About the Data & Code*
> My data frame(origin) contains 5340191 obs. of 3 variables[Data,
> Numeric,Character]
> The code looks like
> *target<-read.zoo(origin,format="%m/%d/%Y",index.column=1,split=3)*
>
> *SessionInfo:*
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Installed memory: 4.00 GB (3.82 GB usable)
> Result of memory.size() : 3812.85

I guess you have lots of stuff in your workspace? Clean that uop and try 
again.

Best,
Uwe Ligges


>
> I try to calculate the required memory but I don't know what are the
> operations in such conversion process. Therefore I have no idea if my data
> is too mass to handle or I was using a low efficient method. Can anyone
> help me with this problem?
>
> By the way, as this is the first time I turn to mailing list for help, I am
> not sure if I ask in the right manner. Please tell me if any
> suggestions.Thank you.
>
>
> Best regards,
> Jasmine
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From afaafonso at gmail.com  Tue Mar 10 14:31:12 2015
From: afaafonso at gmail.com (Anabela Afonso)
Date: Tue, 10 Mar 2015 13:31:12 +0000
Subject: [R] Error in svychisq and svyttest with svrepdesign
Message-ID: <CAOeKbO7iajBP+ZBmiD2-iELODECFnZJUCPvvHWquj4Kj_ecr_Q@mail.gmail.com>

Dear Forum,

I?m working with a complex sample and with replication weights. I defined
my design svrepdesign function. I?m trying to run svychisq and
svyttest function
from the survey package and I get the error:



Error in crossprod(x, y) :

  requires numeric/complex matrix/vector arguments



I can?t understand this error. I kindly ask if someone can help me out.



Thanks in advance,




Here is my code and some output:

> library(foreign); library(survey)

> dados<-read.spss("dadosSPSS.sav", use.value.labels=T, to.data.frame=T)

> class(dados)

[1] "data.frame"

> str(dados)

'data.frame':    7624 obs. of  4 variables:

 $ Sex     : Factor w/ 2 levels "Male","Female": 1 1 1 1 1 1 1 1 1 1 ...

 $ Computer: Factor w/ 2 levels "Yes","NO": 1 1 2 1 1 1 1 1 1 2 ...

 $ Color   : Factor w/ 3 levels "Red","Green",..: 1 1 1 1 1 1 1 1 1 1 ...

 $ Number  : num  2 1 0 2 1 2 1 2 1 0 ...

 $ final.w : num  1267 596 1143 1069 542 ...

# Note: Variable Color with NA

> repdes<-svrepdesign(data=dados, repweights=rep.w, scale=1, rscales=r.sc, type="JKn", weights=~final.w, combined.weights=F)

> summary(repdes)

Call: svrepdesign.default(data = dados, repweights = rep.w, scale = 1,

    rscales = r.sc, type = "JKn", weights = ~final.w, combined.weights = F)

Stratified cluster jackknife (JKn) with 428 replicates.

Variables:

[1] "Sex"      "Computer" "Color"    "Number"   "final.w"



> svytable(~Sex+Computer, repdes)

        Computer

Sex            Yes        NO

  Male   1501598.7 1063055.3

  Female 1485933.1  810557.9



> svytable(~Sex+Color, repdes)  # NA are ignored

        Color

Sex            Red     Green    Yellow

  Male   2060708.5  219678.4  286038.6

  Female 1840511.7  229763.8  224444.0



> svychisq(~Sex+Computer, repdes)

Error in crossprod(x, y) :

  requires numeric/complex matrix/vector arguments



> svychisq(~Sex+Color, repdes)

Error in crossprod(x, y) :

  requires numeric/complex matrix/vector arguments



> svyttest(Number ~Sex, repdes)

Error in crossprod(x, y) :

  requires numeric/complex matrix/vector arguments

	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Tue Mar 10 16:22:11 2015
From: ajdamico at gmail.com (Anthony Damico)
Date: Tue, 10 Mar 2015 11:22:11 -0400
Subject: [R] Error in svychisq and svyttest with svrepdesign
In-Reply-To: <CAOeKbO7iajBP+ZBmiD2-iELODECFnZJUCPvvHWquj4Kj_ecr_Q@mail.gmail.com>
References: <CAOeKbO7iajBP+ZBmiD2-iELODECFnZJUCPvvHWquj4Kj_ecr_Q@mail.gmail.com>
Message-ID: <CAOwvMDxaZKjtZcDs6LxM7yu4dOwxWf9grvEaEwFcAcWdYcbq7w@mail.gmail.com>

hi anabela, please provide a complete reproducible example.  you need to
use ?dput  -- we are not able to import "dadosSPSS.sav" so we cannot
recreate your problem in order to help you.  thanks!

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example



On Tue, Mar 10, 2015 at 9:31 AM, Anabela Afonso <afaafonso at gmail.com> wrote:

> Dear Forum,
>
> I?m working with a complex sample and with replication weights. I defined
> my design svrepdesign function. I?m trying to run svychisq and
> svyttest function
> from the survey package and I get the error:
>
>
>
> Error in crossprod(x, y) :
>
>   requires numeric/complex matrix/vector arguments
>
>
>
> I can?t understand this error. I kindly ask if someone can help me out.
>
>
>
> Thanks in advance,
>
>
>
>
> Here is my code and some output:
>
> > library(foreign); library(survey)
>
> > dados<-read.spss("dadosSPSS.sav", use.value.labels=T, to.data.frame=T)
>
> > class(dados)
>
> [1] "data.frame"
>
> > str(dados)
>
> 'data.frame':    7624 obs. of  4 variables:
>
>  $ Sex     : Factor w/ 2 levels "Male","Female": 1 1 1 1 1 1 1 1 1 1 ...
>
>  $ Computer: Factor w/ 2 levels "Yes","NO": 1 1 2 1 1 1 1 1 1 2 ...
>
>  $ Color   : Factor w/ 3 levels "Red","Green",..: 1 1 1 1 1 1 1 1 1 1 ...
>
>  $ Number  : num  2 1 0 2 1 2 1 2 1 0 ...
>
>  $ final.w : num  1267 596 1143 1069 542 ...
>
> # Note: Variable Color with NA
>
> > repdes<-svrepdesign(data=dados, repweights=rep.w, scale=1, rscales=r.sc,
> type="JKn", weights=~final.w, combined.weights=F)
>
> > summary(repdes)
>
> Call: svrepdesign.default(data = dados, repweights = rep.w, scale = 1,
>
>     rscales = r.sc, type = "JKn", weights = ~final.w, combined.weights =
> F)
>
> Stratified cluster jackknife (JKn) with 428 replicates.
>
> Variables:
>
> [1] "Sex"      "Computer" "Color"    "Number"   "final.w"
>
>
>
> > svytable(~Sex+Computer, repdes)
>
>         Computer
>
> Sex            Yes        NO
>
>   Male   1501598.7 1063055.3
>
>   Female 1485933.1  810557.9
>
>
>
> > svytable(~Sex+Color, repdes)  # NA are ignored
>
>         Color
>
> Sex            Red     Green    Yellow
>
>   Male   2060708.5  219678.4  286038.6
>
>   Female 1840511.7  229763.8  224444.0
>
>
>
> > svychisq(~Sex+Computer, repdes)
>
> Error in crossprod(x, y) :
>
>   requires numeric/complex matrix/vector arguments
>
>
>
> > svychisq(~Sex+Color, repdes)
>
> Error in crossprod(x, y) :
>
>   requires numeric/complex matrix/vector arguments
>
>
>
> > svyttest(Number ~Sex, repdes)
>
> Error in crossprod(x, y) :
>
>   requires numeric/complex matrix/vector arguments
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From paul.j.sweeting at gmail.com  Tue Mar 10 17:09:27 2015
From: paul.j.sweeting at gmail.com (Paul Sweeting)
Date: Tue, 10 Mar 2015 16:09:27 -0000
Subject: [R] svg2swf - controlling the looping of flash files
In-Reply-To: <CAFr_7yH4wzBzm1oA6V=cEp-GVYsqVntAFSRPkgu+0KzorXR0sw@mail.gmail.com>
References: <00f101d05ab9$110abb70$33203250$@gmail.com>
	<CAFr_7yH4wzBzm1oA6V=cEp-GVYsqVntAFSRPkgu+0KzorXR0sw@mail.gmail.com>
Message-ID: <001001d05b4c$96fd7720$c4f86560$@gmail.com>

Hi Yixuan

 

Thanks for your reply. I think it would be useful to have the option of a ?loop = FALSE? option in this function.  However, I?m not sure how long a shelf life swf files will have, given everything seems to be moving away from flash?

 

Paul

 

From: Yixuan Qiu [mailto:yixuan.qiu at cos.name] 
Sent: 10 March 2015 00:20
To: Paul Sweeting
Cc: r-help
Subject: Re: [R] svg2swf - controlling the looping of flash files

 

Hello Paul,

So far there is no way to stop the animation after its first run. If this feature is needed I could try to implement it in the future version of R2SWF.



Best,

Yixuan

 

2015-03-09 18:33 GMT-04:00 Paul Sweeting <paul.j.sweeting at gmail.com <mailto:paul.j.sweeting at gmail.com> >:

Hi



I'm using svg2swf to collate a number of svg outputs into an swf file.  I've
got this working (mainly.) except that I can't control the looping behaviour
of the swf file.  In other words, when it's loaded into html it loops
continuously.  Is there any way to stop the animation looping, so it just
plays through once when loaded?  The code I use is (broadly):



               svg("testplot%d.svg",onefile = FALSE)

               for(j in 1:360){

                              print(cloud(x~y*z, groups=tail,
data=norm_dots_chart, screen=list(z=0,x=0,y=j)))

               }

               dev.off()

               output = svg2swf(sprintf("testplot%d.svg", 1:360), interval =
0.04)

               swf2html(output)



Thank you!


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




-- 

Yixuan Qiu <yixuan.qiu at cos.name <mailto:yixuan.qiu at cos.name> >
Department of Statistics,
Purdue University


	[[alternative HTML version deleted]]


From jasmineangel0503 at gmail.com  Tue Mar 10 19:08:17 2015
From: jasmineangel0503 at gmail.com (=?UTF-8?B?5p2O5YCp6Zuv?=)
Date: Wed, 11 Mar 2015 02:08:17 +0800
Subject: [R] Error: cannot allocate vector of size 64.0 Mb When Using
	Read.zoo()
In-Reply-To: <54FF0457.60005@statistik.tu-dortmund.de>
References: <CAFQz0UbH-111A+vf7-Vb8DAOL=Z6L_SGp5myz8Kv1BGERUXzYg@mail.gmail.com>
	<54FF0457.60005@statistik.tu-dortmund.de>
Message-ID: <CAFQz0Ua-gfeD-4Cr79K-frjQD6hjG5+biwvi6-msGxW-it-H8A@mail.gmail.com>

I dont think so. I removed all variables except for the data I was to use
and tried gc() to release some memories. But the error still happened.

Regards,
Jasmine
On 10 Mar, 2015 10:49 pm, "Uwe Ligges" <ligges at statistik.tu-dortmund.de>
wrote:

>
>
> On 10.03.2015 04:16, ??? wrote:
>
>> Hi all,
>>
>> *Problem Description*
>> I encountered the *Error: cannot allocate vector of size 64.0 Mb* when I
>> was using read.zoo to convert a data.frame called 'origin' to zoo object
>> named 'target'
>>
>> *About the Data & Code*
>> My data frame(origin) contains 5340191 obs. of 3 variables[Data,
>> Numeric,Character]
>> The code looks like
>> *target<-read.zoo(origin,format="%m/%d/%Y",index.column=1,split=3)*
>>
>> *SessionInfo:*
>> R version 3.1.2 (2014-10-31)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Installed memory: 4.00 GB (3.82 GB usable)
>> Result of memory.size() : 3812.85
>>
>
> I guess you have lots of stuff in your workspace? Clean that uop and try
> again.
>
> Best,
> Uwe Ligges
>
>
>
>> I try to calculate the required memory but I don't know what are the
>> operations in such conversion process. Therefore I have no idea if my data
>> is too mass to handle or I was using a low efficient method. Can anyone
>> help me with this problem?
>>
>> By the way, as this is the first time I turn to mailing list for help, I
>> am
>> not sure if I ask in the right manner. Please tell me if any
>> suggestions.Thank you.
>>
>>
>> Best regards,
>> Jasmine
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From jeroen.ooms at stat.ucla.edu  Tue Mar 10 20:07:03 2015
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Tue, 10 Mar 2015 12:07:03 -0700
Subject: [R] How to access https page
In-Reply-To: <CAAu=cySbps8CcJCZ4P56CfXAZ-rgMWKmnG1RQVSVotM5Laa6aQ@mail.gmail.com>
References: <CAAu=cySbps8CcJCZ4P56CfXAZ-rgMWKmnG1RQVSVotM5Laa6aQ@mail.gmail.com>
Message-ID: <CABFfbXvrOJKLc-ZQuWNCd_S=R5-fbHy7i4n_aDTS5__UUU+bGg@mail.gmail.com>

On Mon, Mar 9, 2015 at 3:39 PM, Hui Du <hui.du at savvyrookies.com> wrote:

> > readLines(url)
> Error in file(con, "r") : cannot open the connection
> In addition: Warning message:
> In file(con, "r") : unsupported URL scheme
>

Try:

library(curl)
readLines(curl(url))

	[[alternative HTML version deleted]]


From curtisburkhalter at gmail.com  Tue Mar 10 20:43:32 2015
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Tue, 10 Mar 2015 13:43:32 -0600
Subject: [R] problem applying the same function twice
Message-ID: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>

Hey everyone,

I've written a function that adds NAs to a dataframe where data is missing
and it seems to work great if I only need to run it once, but if I run it
two times in a row I run into problems. I've created a workable example to
explain what I mean and why I would do this.

In my dataframe there are areas where I need to add two rows of NAs (b/c I
need to have 3 animal x year combos and for cat in year 2 I only have one)
so I thought that I'd just run my code twice using the function in the code
below. Everything works great when I run it the first time, but when I run
it again it says that the value returned to the list 'x' is of length 0. I
don't understand why the function works the first time around and adds an
NA to the 'animalMass' column, but won't do it again. I've used
(print(str(dataframe)) to see if there is a change in class or type when
the function runs through the original dataframe and there is for
'animalYears', but I just convert it back before rerunning the function for
second time.

Any thoughts on this would be greatly appreciated b/c my actual data
dataframe I have to input into WinBUGS is 14000x12, so it's not a trivial
thing to just add in an NA here or there.

>comAn
   animals animalYears animalMass
1     bird           1         29
2     bird           1         48
3     bird           1         36
4     bird           2         20
5     bird           2         34
6     bird           2         34
7      dog           1         21
8      dog           1         28
9      dog           1         25
10     dog           2         35
11     dog           2         18
12     dog           2         11
13     cat           1         46
14     cat           1         33
15     cat           1         48
16     cat           2         21

So every animal has 3 measurements per year, except for the cat in year two
which has only 1. I run the code below and get:

#combs defines the different combinations of
#animals and animalYears
combs<-paste(comAn$animals,comAn$animalYears,sep=':')
#counts defines how long the different combinations are
counts<-ave(1:nrow(comAn),combs,FUN=length)
#missing defines the combs that have length less than one and puts it in
#the data frame missing
missing<-data.frame(vals=combs[counts<2],count=counts[counts<2])

genRows<-function(dat){
        vals<-strsplit(dat[1],':')[[1]]
                #not sure why dat[2] is being converted to a string
        newRows<-2-as.numeric(dat[2])
        newDf<-data.frame(animals=rep(vals[1],newRows),
                          animalYears=rep(vals[2],newRows),
                          animalMass=rep(NA,newRows))
        return(newDf)
        }


x<-apply(missing,1,genRows)
comAn=rbind(comAn,
        do.call(rbind,x))

> comAn
   animals animalYears animalMass
1     bird           1         29
2     bird           1         48
3     bird           1         36
4     bird           2         20
5     bird           2         34
6     bird           2         34
7      dog           1         21
8      dog           1         28
9      dog           1         25
10     dog           2         35
11     dog           2         18
12     dog           2         11
13     cat           1         46
14     cat           1         33
15     cat           1         48
16     cat           2         21
17     cat           2       <NA>

So far so good, but then I adjust the code so that it reads (**notice the
change in the specification in 'missing' to counts<3**):

#combs defines the different combinations of
#animals and animalYears
combs<-paste(comAn$animals,comAn$animalYears,sep=':')
#counts defines how long the different combinations are
counts<-ave(1:nrow(comAn),combs,FUN=length)
#missing defines the combs that have length less than one and puts it in
#the data frame missing
missing<-data.frame(vals=combs[counts<3],count=counts[counts<3])

genRows<-function(dat){
        vals<-strsplit(dat[1],':')[[1]]
                #not sure why dat[2] is being converted to a string
        newRows<-2-as.numeric(dat[2])
        newDf<-data.frame(animals=rep(vals[1],newRows),
                          animalYears=rep(vals[2],newRows),
                          animalMass=rep(NA,newRows))
        return(newDf)
        }


x<-apply(missing,1,genRows)
comAn=rbind(comAn,
        do.call(rbind,x))

The result for 'x' then reads:

> x
[[1]]
[1] animals     animalYears animalMass
<0 rows> (or 0-length row.names)

Any thoughts on why it might be doing this instead of adding an additional
row to get the result:

> comAn
   animals animalYears animalMass
1     bird           1         29
2     bird           1         48
3     bird           1         36
4     bird           2         20
5     bird           2         34
6     bird           2         34
7      dog           1         21
8      dog           1         28
9      dog           1         25
10     dog           2         35
11     dog           2         18
12     dog           2         11
13     cat           1         46
14     cat           1         33
15     cat           1         48
16     cat           2         21
17     cat           2       <NA>
18     cat           2       <NA>

Thanks
-- 
Curtis Burkhalter

https://sites.google.com/site/curtisburkhalter/

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Tue Mar 10 21:04:37 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 10 Mar 2015 16:04:37 -0400
Subject: [R] problem applying the same function twice
In-Reply-To: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>
References: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>
Message-ID: <CAM_vju=bLmXg99ZrhfdOw9C9bMDJ=evbVKOFtAZvg-ug3NcEeQ@mail.gmail.com>

Hi,

I didn't work through your code, because it looked overly complicated.
Here's a more general approach that does what you appear to want:

# use dput() to provide reproducible data please!
comAn <- structure(list(animals = c("bird", "bird", "bird", "bird", "bird",
"bird", "dog", "dog", "dog", "dog", "dog", "dog", "cat", "cat",
"cat", "cat"), animalYears = c(1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), animalMass = c(29L, 48L, 36L,
20L, 34L, 34L, 21L, 28L, 25L, 35L, 18L, 11L, 46L, 33L, 48L, 21L
)), .Names = c("animals", "animalYears", "animalMass"), class =
"data.frame", row.names = c("1",
"2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
"14", "15", "16"))


# add reps to comAn
# assumes comAn is already sorted on animals, animalYears
comAn$reps <- unlist(sapply(rle(do.call("paste",
comAn[,1:2]))$lengths, seq_len))

# create full set of combinations
outgrid <- expand.grid(animals=unique(comAn$animals),
animalYears=unique(comAn$animalYears), reps=unique(comAn$reps),
stringsAsFactors=FALSE)

# combine with comAn
comAn.full <- merge(outgrid, comAn, all.x=TRUE)

> comAn.full
   animals animalYears reps animalMass
1     bird           1    1         29
2     bird           1    2         48
3     bird           1    3         36
4     bird           2    1         20
5     bird           2    2         34
6     bird           2    3         34
7      cat           1    1         46
8      cat           1    2         33
9      cat           1    3         48
10     cat           2    1         21
11     cat           2    2         NA
12     cat           2    3         NA
13     dog           1    1         21
14     dog           1    2         28
15     dog           1    3         25
16     dog           2    1         35
17     dog           2    2         18
18     dog           2    3         11
>

On Tue, Mar 10, 2015 at 3:43 PM, Curtis Burkhalter
<curtisburkhalter at gmail.com> wrote:
> Hey everyone,
>
> I've written a function that adds NAs to a dataframe where data is missing
> and it seems to work great if I only need to run it once, but if I run it
> two times in a row I run into problems. I've created a workable example to
> explain what I mean and why I would do this.
>
> In my dataframe there are areas where I need to add two rows of NAs (b/c I
> need to have 3 animal x year combos and for cat in year 2 I only have one)
> so I thought that I'd just run my code twice using the function in the code
> below. Everything works great when I run it the first time, but when I run
> it again it says that the value returned to the list 'x' is of length 0. I
> don't understand why the function works the first time around and adds an
> NA to the 'animalMass' column, but won't do it again. I've used
> (print(str(dataframe)) to see if there is a change in class or type when
> the function runs through the original dataframe and there is for
> 'animalYears', but I just convert it back before rerunning the function for
> second time.
>
> Any thoughts on this would be greatly appreciated b/c my actual data
> dataframe I have to input into WinBUGS is 14000x12, so it's not a trivial
> thing to just add in an NA here or there.
>
>>comAn
>    animals animalYears animalMass
> 1     bird           1         29
> 2     bird           1         48
> 3     bird           1         36
> 4     bird           2         20
> 5     bird           2         34
> 6     bird           2         34
> 7      dog           1         21
> 8      dog           1         28
> 9      dog           1         25
> 10     dog           2         35
> 11     dog           2         18
> 12     dog           2         11
> 13     cat           1         46
> 14     cat           1         33
> 15     cat           1         48
> 16     cat           2         21
>
> So every animal has 3 measurements per year, except for the cat in year two
> which has only 1. I run the code below and get:
>
> #combs defines the different combinations of
> #animals and animalYears
> combs<-paste(comAn$animals,comAn$animalYears,sep=':')
> #counts defines how long the different combinations are
> counts<-ave(1:nrow(comAn),combs,FUN=length)
> #missing defines the combs that have length less than one and puts it in
> #the data frame missing
> missing<-data.frame(vals=combs[counts<2],count=counts[counts<2])
>
> genRows<-function(dat){
>         vals<-strsplit(dat[1],':')[[1]]
>                 #not sure why dat[2] is being converted to a string
>         newRows<-2-as.numeric(dat[2])
>         newDf<-data.frame(animals=rep(vals[1],newRows),
>                           animalYears=rep(vals[2],newRows),
>                           animalMass=rep(NA,newRows))
>         return(newDf)
>         }
>
>
> x<-apply(missing,1,genRows)
> comAn=rbind(comAn,
>         do.call(rbind,x))
>
>> comAn
>    animals animalYears animalMass
> 1     bird           1         29
> 2     bird           1         48
> 3     bird           1         36
> 4     bird           2         20
> 5     bird           2         34
> 6     bird           2         34
> 7      dog           1         21
> 8      dog           1         28
> 9      dog           1         25
> 10     dog           2         35
> 11     dog           2         18
> 12     dog           2         11
> 13     cat           1         46
> 14     cat           1         33
> 15     cat           1         48
> 16     cat           2         21
> 17     cat           2       <NA>
>
> So far so good, but then I adjust the code so that it reads (**notice the
> change in the specification in 'missing' to counts<3**):
>
> #combs defines the different combinations of
> #animals and animalYears
> combs<-paste(comAn$animals,comAn$animalYears,sep=':')
> #counts defines how long the different combinations are
> counts<-ave(1:nrow(comAn),combs,FUN=length)
> #missing defines the combs that have length less than one and puts it in
> #the data frame missing
> missing<-data.frame(vals=combs[counts<3],count=counts[counts<3])
>
> genRows<-function(dat){
>         vals<-strsplit(dat[1],':')[[1]]
>                 #not sure why dat[2] is being converted to a string
>         newRows<-2-as.numeric(dat[2])
>         newDf<-data.frame(animals=rep(vals[1],newRows),
>                           animalYears=rep(vals[2],newRows),
>                           animalMass=rep(NA,newRows))
>         return(newDf)
>         }
>
>
> x<-apply(missing,1,genRows)
> comAn=rbind(comAn,
>         do.call(rbind,x))
>
> The result for 'x' then reads:
>
>> x
> [[1]]
> [1] animals     animalYears animalMass
> <0 rows> (or 0-length row.names)
>
> Any thoughts on why it might be doing this instead of adding an additional
> row to get the result:
>
>> comAn
>    animals animalYears animalMass
> 1     bird           1         29
> 2     bird           1         48
> 3     bird           1         36
> 4     bird           2         20
> 5     bird           2         34
> 6     bird           2         34
> 7      dog           1         21
> 8      dog           1         28
> 9      dog           1         25
> 10     dog           2         35
> 11     dog           2         18
> 12     dog           2         11
> 13     cat           1         46
> 14     cat           1         33
> 15     cat           1         48
> 16     cat           2         21
> 17     cat           2       <NA>
> 18     cat           2       <NA>
>
> Thanks
> --
> Curtis Burkhalter


From wdunlap at tibco.com  Tue Mar 10 21:13:37 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 10 Mar 2015 13:13:37 -0700
Subject: [R] problem applying the same function twice
In-Reply-To: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>
References: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>
Message-ID: <CAF8bMca5yVq4ovksY_W585pP41FeAuNhie+o_d0GkiVWs8VtUw@mail.gmail.com>

The key to your problem may be that
   x<-apply(missing,1,genRows)
converts 'missing' to a matrix, with the same type for all columns
then makes x either a list or a matrix but never a data.frame.
Those features of apply may mess up the rest of your calculations.

Don't use apply().


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Mar 10, 2015 at 12:43 PM, Curtis Burkhalter <
curtisburkhalter at gmail.com> wrote:

> Hey everyone,
>
> I've written a function that adds NAs to a dataframe where data is missing
> and it seems to work great if I only need to run it once, but if I run it
> two times in a row I run into problems. I've created a workable example to
> explain what I mean and why I would do this.
>
> In my dataframe there are areas where I need to add two rows of NAs (b/c I
> need to have 3 animal x year combos and for cat in year 2 I only have one)
> so I thought that I'd just run my code twice using the function in the code
> below. Everything works great when I run it the first time, but when I run
> it again it says that the value returned to the list 'x' is of length 0. I
> don't understand why the function works the first time around and adds an
> NA to the 'animalMass' column, but won't do it again. I've used
> (print(str(dataframe)) to see if there is a change in class or type when
> the function runs through the original dataframe and there is for
> 'animalYears', but I just convert it back before rerunning the function for
> second time.
>
> Any thoughts on this would be greatly appreciated b/c my actual data
> dataframe I have to input into WinBUGS is 14000x12, so it's not a trivial
> thing to just add in an NA here or there.
>
> >comAn
>    animals animalYears animalMass
> 1     bird           1         29
> 2     bird           1         48
> 3     bird           1         36
> 4     bird           2         20
> 5     bird           2         34
> 6     bird           2         34
> 7      dog           1         21
> 8      dog           1         28
> 9      dog           1         25
> 10     dog           2         35
> 11     dog           2         18
> 12     dog           2         11
> 13     cat           1         46
> 14     cat           1         33
> 15     cat           1         48
> 16     cat           2         21
>
> So every animal has 3 measurements per year, except for the cat in year two
> which has only 1. I run the code below and get:
>
> #combs defines the different combinations of
> #animals and animalYears
> combs<-paste(comAn$animals,comAn$animalYears,sep=':')
> #counts defines how long the different combinations are
> counts<-ave(1:nrow(comAn),combs,FUN=length)
> #missing defines the combs that have length less than one and puts it in
> #the data frame missing
> missing<-data.frame(vals=combs[counts<2],count=counts[counts<2])
>
> genRows<-function(dat){
>         vals<-strsplit(dat[1],':')[[1]]
>                 #not sure why dat[2] is being converted to a string
>         newRows<-2-as.numeric(dat[2])
>         newDf<-data.frame(animals=rep(vals[1],newRows),
>                           animalYears=rep(vals[2],newRows),
>                           animalMass=rep(NA,newRows))
>         return(newDf)
>         }
>
>
> x<-apply(missing,1,genRows)
> comAn=rbind(comAn,
>         do.call(rbind,x))
>
> > comAn
>    animals animalYears animalMass
> 1     bird           1         29
> 2     bird           1         48
> 3     bird           1         36
> 4     bird           2         20
> 5     bird           2         34
> 6     bird           2         34
> 7      dog           1         21
> 8      dog           1         28
> 9      dog           1         25
> 10     dog           2         35
> 11     dog           2         18
> 12     dog           2         11
> 13     cat           1         46
> 14     cat           1         33
> 15     cat           1         48
> 16     cat           2         21
> 17     cat           2       <NA>
>
> So far so good, but then I adjust the code so that it reads (**notice the
> change in the specification in 'missing' to counts<3**):
>
> #combs defines the different combinations of
> #animals and animalYears
> combs<-paste(comAn$animals,comAn$animalYears,sep=':')
> #counts defines how long the different combinations are
> counts<-ave(1:nrow(comAn),combs,FUN=length)
> #missing defines the combs that have length less than one and puts it in
> #the data frame missing
> missing<-data.frame(vals=combs[counts<3],count=counts[counts<3])
>
> genRows<-function(dat){
>         vals<-strsplit(dat[1],':')[[1]]
>                 #not sure why dat[2] is being converted to a string
>         newRows<-2-as.numeric(dat[2])
>         newDf<-data.frame(animals=rep(vals[1],newRows),
>                           animalYears=rep(vals[2],newRows),
>                           animalMass=rep(NA,newRows))
>         return(newDf)
>         }
>
>
> x<-apply(missing,1,genRows)
> comAn=rbind(comAn,
>         do.call(rbind,x))
>
> The result for 'x' then reads:
>
> > x
> [[1]]
> [1] animals     animalYears animalMass
> <0 rows> (or 0-length row.names)
>
> Any thoughts on why it might be doing this instead of adding an additional
> row to get the result:
>
> > comAn
>    animals animalYears animalMass
> 1     bird           1         29
> 2     bird           1         48
> 3     bird           1         36
> 4     bird           2         20
> 5     bird           2         34
> 6     bird           2         34
> 7      dog           1         21
> 8      dog           1         28
> 9      dog           1         25
> 10     dog           2         35
> 11     dog           2         18
> 12     dog           2         11
> 13     cat           1         46
> 14     cat           1         33
> 15     cat           1         48
> 16     cat           2         21
> 17     cat           2       <NA>
> 18     cat           2       <NA>
>
> Thanks
> --
> Curtis Burkhalter
>
> https://sites.google.com/site/curtisburkhalter/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From curtisburkhalter at gmail.com  Tue Mar 10 21:35:21 2015
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Tue, 10 Mar 2015 14:35:21 -0600
Subject: [R] problem applying the same function twice
In-Reply-To: <CAM_vju=bLmXg99ZrhfdOw9C9bMDJ=evbVKOFtAZvg-ug3NcEeQ@mail.gmail.com>
References: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>
	<CAM_vju=bLmXg99ZrhfdOw9C9bMDJ=evbVKOFtAZvg-ug3NcEeQ@mail.gmail.com>
Message-ID: <CAJmwvUaSPpO05PtqjGO5GKnrWoHMf2s9A-aAibpVUQdbUXBWBA@mail.gmail.com>

Sarah,

This strategy works great for this small dataset, but when I attempt your
method with my data set I reach the maximum allowable memory allocation and
the operation just stalls and then stops completely before it is finished.
Do you know of a way around this?

Thanks

On Tue, Mar 10, 2015 at 2:04 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hi,
>
> I didn't work through your code, because it looked overly complicated.
> Here's a more general approach that does what you appear to want:
>
> # use dput() to provide reproducible data please!
> comAn <- structure(list(animals = c("bird", "bird", "bird", "bird", "bird",
> "bird", "dog", "dog", "dog", "dog", "dog", "dog", "cat", "cat",
> "cat", "cat"), animalYears = c(1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
> 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), animalMass = c(29L, 48L, 36L,
> 20L, 34L, 34L, 21L, 28L, 25L, 35L, 18L, 11L, 46L, 33L, 48L, 21L
> )), .Names = c("animals", "animalYears", "animalMass"), class =
> "data.frame", row.names = c("1",
> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
> "14", "15", "16"))
>
>
> # add reps to comAn
> # assumes comAn is already sorted on animals, animalYears
> comAn$reps <- unlist(sapply(rle(do.call("paste",
> comAn[,1:2]))$lengths, seq_len))
>
> # create full set of combinations
> outgrid <- expand.grid(animals=unique(comAn$animals),
> animalYears=unique(comAn$animalYears), reps=unique(comAn$reps),
> stringsAsFactors=FALSE)
>
> # combine with comAn
> comAn.full <- merge(outgrid, comAn, all.x=TRUE)
>
> > comAn.full
>    animals animalYears reps animalMass
> 1     bird           1    1         29
> 2     bird           1    2         48
> 3     bird           1    3         36
> 4     bird           2    1         20
> 5     bird           2    2         34
> 6     bird           2    3         34
> 7      cat           1    1         46
> 8      cat           1    2         33
> 9      cat           1    3         48
> 10     cat           2    1         21
> 11     cat           2    2         NA
> 12     cat           2    3         NA
> 13     dog           1    1         21
> 14     dog           1    2         28
> 15     dog           1    3         25
> 16     dog           2    1         35
> 17     dog           2    2         18
> 18     dog           2    3         11
> >
>
> On Tue, Mar 10, 2015 at 3:43 PM, Curtis Burkhalter
> <curtisburkhalter at gmail.com> wrote:
> > Hey everyone,
> >
> > I've written a function that adds NAs to a dataframe where data is
> missing
> > and it seems to work great if I only need to run it once, but if I run it
> > two times in a row I run into problems. I've created a workable example
> to
> > explain what I mean and why I would do this.
> >
> > In my dataframe there are areas where I need to add two rows of NAs (b/c
> I
> > need to have 3 animal x year combos and for cat in year 2 I only have
> one)
> > so I thought that I'd just run my code twice using the function in the
> code
> > below. Everything works great when I run it the first time, but when I
> run
> > it again it says that the value returned to the list 'x' is of length 0.
> I
> > don't understand why the function works the first time around and adds an
> > NA to the 'animalMass' column, but won't do it again. I've used
> > (print(str(dataframe)) to see if there is a change in class or type when
> > the function runs through the original dataframe and there is for
> > 'animalYears', but I just convert it back before rerunning the function
> for
> > second time.
> >
> > Any thoughts on this would be greatly appreciated b/c my actual data
> > dataframe I have to input into WinBUGS is 14000x12, so it's not a trivial
> > thing to just add in an NA here or there.
> >
> >>comAn
> >    animals animalYears animalMass
> > 1     bird           1         29
> > 2     bird           1         48
> > 3     bird           1         36
> > 4     bird           2         20
> > 5     bird           2         34
> > 6     bird           2         34
> > 7      dog           1         21
> > 8      dog           1         28
> > 9      dog           1         25
> > 10     dog           2         35
> > 11     dog           2         18
> > 12     dog           2         11
> > 13     cat           1         46
> > 14     cat           1         33
> > 15     cat           1         48
> > 16     cat           2         21
> >
> > So every animal has 3 measurements per year, except for the cat in year
> two
> > which has only 1. I run the code below and get:
> >
> > #combs defines the different combinations of
> > #animals and animalYears
> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
> > #counts defines how long the different combinations are
> > counts<-ave(1:nrow(comAn),combs,FUN=length)
> > #missing defines the combs that have length less than one and puts it in
> > #the data frame missing
> > missing<-data.frame(vals=combs[counts<2],count=counts[counts<2])
> >
> > genRows<-function(dat){
> >         vals<-strsplit(dat[1],':')[[1]]
> >                 #not sure why dat[2] is being converted to a string
> >         newRows<-2-as.numeric(dat[2])
> >         newDf<-data.frame(animals=rep(vals[1],newRows),
> >                           animalYears=rep(vals[2],newRows),
> >                           animalMass=rep(NA,newRows))
> >         return(newDf)
> >         }
> >
> >
> > x<-apply(missing,1,genRows)
> > comAn=rbind(comAn,
> >         do.call(rbind,x))
> >
> >> comAn
> >    animals animalYears animalMass
> > 1     bird           1         29
> > 2     bird           1         48
> > 3     bird           1         36
> > 4     bird           2         20
> > 5     bird           2         34
> > 6     bird           2         34
> > 7      dog           1         21
> > 8      dog           1         28
> > 9      dog           1         25
> > 10     dog           2         35
> > 11     dog           2         18
> > 12     dog           2         11
> > 13     cat           1         46
> > 14     cat           1         33
> > 15     cat           1         48
> > 16     cat           2         21
> > 17     cat           2       <NA>
> >
> > So far so good, but then I adjust the code so that it reads (**notice the
> > change in the specification in 'missing' to counts<3**):
> >
> > #combs defines the different combinations of
> > #animals and animalYears
> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
> > #counts defines how long the different combinations are
> > counts<-ave(1:nrow(comAn),combs,FUN=length)
> > #missing defines the combs that have length less than one and puts it in
> > #the data frame missing
> > missing<-data.frame(vals=combs[counts<3],count=counts[counts<3])
> >
> > genRows<-function(dat){
> >         vals<-strsplit(dat[1],':')[[1]]
> >                 #not sure why dat[2] is being converted to a string
> >         newRows<-2-as.numeric(dat[2])
> >         newDf<-data.frame(animals=rep(vals[1],newRows),
> >                           animalYears=rep(vals[2],newRows),
> >                           animalMass=rep(NA,newRows))
> >         return(newDf)
> >         }
> >
> >
> > x<-apply(missing,1,genRows)
> > comAn=rbind(comAn,
> >         do.call(rbind,x))
> >
> > The result for 'x' then reads:
> >
> >> x
> > [[1]]
> > [1] animals     animalYears animalMass
> > <0 rows> (or 0-length row.names)
> >
> > Any thoughts on why it might be doing this instead of adding an
> additional
> > row to get the result:
> >
> >> comAn
> >    animals animalYears animalMass
> > 1     bird           1         29
> > 2     bird           1         48
> > 3     bird           1         36
> > 4     bird           2         20
> > 5     bird           2         34
> > 6     bird           2         34
> > 7      dog           1         21
> > 8      dog           1         28
> > 9      dog           1         25
> > 10     dog           2         35
> > 11     dog           2         18
> > 12     dog           2         11
> > 13     cat           1         46
> > 14     cat           1         33
> > 15     cat           1         48
> > 16     cat           2         21
> > 17     cat           2       <NA>
> > 18     cat           2       <NA>
> >
> > Thanks
> > --
> > Curtis Burkhalter
>



-- 
Curtis Burkhalter

https://sites.google.com/site/curtisburkhalter/

	[[alternative HTML version deleted]]


From curtisburkhalter at gmail.com  Tue Mar 10 21:35:49 2015
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Tue, 10 Mar 2015 14:35:49 -0600
Subject: [R] problem applying the same function twice
In-Reply-To: <CAF8bMca5yVq4ovksY_W585pP41FeAuNhie+o_d0GkiVWs8VtUw@mail.gmail.com>
References: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>
	<CAF8bMca5yVq4ovksY_W585pP41FeAuNhie+o_d0GkiVWs8VtUw@mail.gmail.com>
Message-ID: <CAJmwvUay-fmmGtosduK_1eKw=rddq-NnucDEgu97n9kerjEZHw@mail.gmail.com>

William,

You say not to use apply here, but what would you use in its place?

Thanks

On Tue, Mar 10, 2015 at 2:13 PM, William Dunlap <wdunlap at tibco.com> wrote:

> The key to your problem may be that
>    x<-apply(missing,1,genRows)
> converts 'missing' to a matrix, with the same type for all columns
> then makes x either a list or a matrix but never a data.frame.
> Those features of apply may mess up the rest of your calculations.
>
> Don't use apply().
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Mar 10, 2015 at 12:43 PM, Curtis Burkhalter <
> curtisburkhalter at gmail.com> wrote:
>
>> Hey everyone,
>>
>> I've written a function that adds NAs to a dataframe where data is missing
>> and it seems to work great if I only need to run it once, but if I run it
>> two times in a row I run into problems. I've created a workable example to
>> explain what I mean and why I would do this.
>>
>> In my dataframe there are areas where I need to add two rows of NAs (b/c I
>> need to have 3 animal x year combos and for cat in year 2 I only have one)
>> so I thought that I'd just run my code twice using the function in the
>> code
>> below. Everything works great when I run it the first time, but when I run
>> it again it says that the value returned to the list 'x' is of length 0. I
>> don't understand why the function works the first time around and adds an
>> NA to the 'animalMass' column, but won't do it again. I've used
>> (print(str(dataframe)) to see if there is a change in class or type when
>> the function runs through the original dataframe and there is for
>> 'animalYears', but I just convert it back before rerunning the function
>> for
>> second time.
>>
>> Any thoughts on this would be greatly appreciated b/c my actual data
>> dataframe I have to input into WinBUGS is 14000x12, so it's not a trivial
>> thing to just add in an NA here or there.
>>
>> >comAn
>>    animals animalYears animalMass
>> 1     bird           1         29
>> 2     bird           1         48
>> 3     bird           1         36
>> 4     bird           2         20
>> 5     bird           2         34
>> 6     bird           2         34
>> 7      dog           1         21
>> 8      dog           1         28
>> 9      dog           1         25
>> 10     dog           2         35
>> 11     dog           2         18
>> 12     dog           2         11
>> 13     cat           1         46
>> 14     cat           1         33
>> 15     cat           1         48
>> 16     cat           2         21
>>
>> So every animal has 3 measurements per year, except for the cat in year
>> two
>> which has only 1. I run the code below and get:
>>
>> #combs defines the different combinations of
>> #animals and animalYears
>> combs<-paste(comAn$animals,comAn$animalYears,sep=':')
>> #counts defines how long the different combinations are
>> counts<-ave(1:nrow(comAn),combs,FUN=length)
>> #missing defines the combs that have length less than one and puts it in
>> #the data frame missing
>> missing<-data.frame(vals=combs[counts<2],count=counts[counts<2])
>>
>> genRows<-function(dat){
>>         vals<-strsplit(dat[1],':')[[1]]
>>                 #not sure why dat[2] is being converted to a string
>>         newRows<-2-as.numeric(dat[2])
>>         newDf<-data.frame(animals=rep(vals[1],newRows),
>>                           animalYears=rep(vals[2],newRows),
>>                           animalMass=rep(NA,newRows))
>>         return(newDf)
>>         }
>>
>>
>> x<-apply(missing,1,genRows)
>> comAn=rbind(comAn,
>>         do.call(rbind,x))
>>
>> > comAn
>>    animals animalYears animalMass
>> 1     bird           1         29
>> 2     bird           1         48
>> 3     bird           1         36
>> 4     bird           2         20
>> 5     bird           2         34
>> 6     bird           2         34
>> 7      dog           1         21
>> 8      dog           1         28
>> 9      dog           1         25
>> 10     dog           2         35
>> 11     dog           2         18
>> 12     dog           2         11
>> 13     cat           1         46
>> 14     cat           1         33
>> 15     cat           1         48
>> 16     cat           2         21
>> 17     cat           2       <NA>
>>
>> So far so good, but then I adjust the code so that it reads (**notice the
>> change in the specification in 'missing' to counts<3**):
>>
>> #combs defines the different combinations of
>> #animals and animalYears
>> combs<-paste(comAn$animals,comAn$animalYears,sep=':')
>> #counts defines how long the different combinations are
>> counts<-ave(1:nrow(comAn),combs,FUN=length)
>> #missing defines the combs that have length less than one and puts it in
>> #the data frame missing
>> missing<-data.frame(vals=combs[counts<3],count=counts[counts<3])
>>
>> genRows<-function(dat){
>>         vals<-strsplit(dat[1],':')[[1]]
>>                 #not sure why dat[2] is being converted to a string
>>         newRows<-2-as.numeric(dat[2])
>>         newDf<-data.frame(animals=rep(vals[1],newRows),
>>                           animalYears=rep(vals[2],newRows),
>>                           animalMass=rep(NA,newRows))
>>         return(newDf)
>>         }
>>
>>
>> x<-apply(missing,1,genRows)
>> comAn=rbind(comAn,
>>         do.call(rbind,x))
>>
>> The result for 'x' then reads:
>>
>> > x
>> [[1]]
>> [1] animals     animalYears animalMass
>> <0 rows> (or 0-length row.names)
>>
>> Any thoughts on why it might be doing this instead of adding an additional
>> row to get the result:
>>
>> > comAn
>>    animals animalYears animalMass
>> 1     bird           1         29
>> 2     bird           1         48
>> 3     bird           1         36
>> 4     bird           2         20
>> 5     bird           2         34
>> 6     bird           2         34
>> 7      dog           1         21
>> 8      dog           1         28
>> 9      dog           1         25
>> 10     dog           2         35
>> 11     dog           2         18
>> 12     dog           2         11
>> 13     cat           1         46
>> 14     cat           1         33
>> 15     cat           1         48
>> 16     cat           2         21
>> 17     cat           2       <NA>
>> 18     cat           2       <NA>
>>
>> Thanks
>> --
>> Curtis Burkhalter
>>
>> https://sites.google.com/site/curtisburkhalter/
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
Curtis Burkhalter

https://sites.google.com/site/curtisburkhalter/

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Tue Mar 10 21:50:13 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 10 Mar 2015 16:50:13 -0400
Subject: [R] problem applying the same function twice
In-Reply-To: <CAJmwvUaSPpO05PtqjGO5GKnrWoHMf2s9A-aAibpVUQdbUXBWBA@mail.gmail.com>
References: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>
	<CAM_vju=bLmXg99ZrhfdOw9C9bMDJ=evbVKOFtAZvg-ug3NcEeQ@mail.gmail.com>
	<CAJmwvUaSPpO05PtqjGO5GKnrWoHMf2s9A-aAibpVUQdbUXBWBA@mail.gmail.com>
Message-ID: <CAM_vju=f6CTPbq8XJgx6eNAr_UFSK_Lx0ETgpFG2vdoX3OFOLw@mail.gmail.com>

You said your data only had 14000 rows, which really isn't many.

How many possible combinations do you have, and how many do you need to add?

On Tue, Mar 10, 2015 at 4:35 PM, Curtis Burkhalter
<curtisburkhalter at gmail.com> wrote:
> Sarah,
>
> This strategy works great for this small dataset, but when I attempt your
> method with my data set I reach the maximum allowable memory allocation and
> the operation just stalls and then stops completely before it is finished.
> Do you know of a way around this?
>
> Thanks
>
> On Tue, Mar 10, 2015 at 2:04 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> Hi,
>>
>> I didn't work through your code, because it looked overly complicated.
>> Here's a more general approach that does what you appear to want:
>>
>> # use dput() to provide reproducible data please!
>> comAn <- structure(list(animals = c("bird", "bird", "bird", "bird",
>> "bird",
>> "bird", "dog", "dog", "dog", "dog", "dog", "dog", "cat", "cat",
>> "cat", "cat"), animalYears = c(1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
>> 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), animalMass = c(29L, 48L, 36L,
>> 20L, 34L, 34L, 21L, 28L, 25L, 35L, 18L, 11L, 46L, 33L, 48L, 21L
>> )), .Names = c("animals", "animalYears", "animalMass"), class =
>> "data.frame", row.names = c("1",
>> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
>> "14", "15", "16"))
>>
>>
>> # add reps to comAn
>> # assumes comAn is already sorted on animals, animalYears
>> comAn$reps <- unlist(sapply(rle(do.call("paste",
>> comAn[,1:2]))$lengths, seq_len))
>>
>> # create full set of combinations
>> outgrid <- expand.grid(animals=unique(comAn$animals),
>> animalYears=unique(comAn$animalYears), reps=unique(comAn$reps),
>> stringsAsFactors=FALSE)
>>
>> # combine with comAn
>> comAn.full <- merge(outgrid, comAn, all.x=TRUE)
>>
>> > comAn.full
>>    animals animalYears reps animalMass
>> 1     bird           1    1         29
>> 2     bird           1    2         48
>> 3     bird           1    3         36
>> 4     bird           2    1         20
>> 5     bird           2    2         34
>> 6     bird           2    3         34
>> 7      cat           1    1         46
>> 8      cat           1    2         33
>> 9      cat           1    3         48
>> 10     cat           2    1         21
>> 11     cat           2    2         NA
>> 12     cat           2    3         NA
>> 13     dog           1    1         21
>> 14     dog           1    2         28
>> 15     dog           1    3         25
>> 16     dog           2    1         35
>> 17     dog           2    2         18
>> 18     dog           2    3         11
>> >
>>
>> On Tue, Mar 10, 2015 at 3:43 PM, Curtis Burkhalter
>> <curtisburkhalter at gmail.com> wrote:
>> > Hey everyone,
>> >
>> > I've written a function that adds NAs to a dataframe where data is
>> > missing
>> > and it seems to work great if I only need to run it once, but if I run
>> > it
>> > two times in a row I run into problems. I've created a workable example
>> > to
>> > explain what I mean and why I would do this.
>> >
>> > In my dataframe there are areas where I need to add two rows of NAs (b/c
>> > I
>> > need to have 3 animal x year combos and for cat in year 2 I only have
>> > one)
>> > so I thought that I'd just run my code twice using the function in the
>> > code
>> > below. Everything works great when I run it the first time, but when I
>> > run
>> > it again it says that the value returned to the list 'x' is of length 0.
>> > I
>> > don't understand why the function works the first time around and adds
>> > an
>> > NA to the 'animalMass' column, but won't do it again. I've used
>> > (print(str(dataframe)) to see if there is a change in class or type when
>> > the function runs through the original dataframe and there is for
>> > 'animalYears', but I just convert it back before rerunning the function
>> > for
>> > second time.
>> >
>> > Any thoughts on this would be greatly appreciated b/c my actual data
>> > dataframe I have to input into WinBUGS is 14000x12, so it's not a
>> > trivial
>> > thing to just add in an NA here or there.
>> >
>> >>comAn
>> >    animals animalYears animalMass
>> > 1     bird           1         29
>> > 2     bird           1         48
>> > 3     bird           1         36
>> > 4     bird           2         20
>> > 5     bird           2         34
>> > 6     bird           2         34
>> > 7      dog           1         21
>> > 8      dog           1         28
>> > 9      dog           1         25
>> > 10     dog           2         35
>> > 11     dog           2         18
>> > 12     dog           2         11
>> > 13     cat           1         46
>> > 14     cat           1         33
>> > 15     cat           1         48
>> > 16     cat           2         21
>> >
>> > So every animal has 3 measurements per year, except for the cat in year
>> > two
>> > which has only 1. I run the code below and get:
>> >
>> > #combs defines the different combinations of
>> > #animals and animalYears
>> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
>> > #counts defines how long the different combinations are
>> > counts<-ave(1:nrow(comAn),combs,FUN=length)
>> > #missing defines the combs that have length less than one and puts it in
>> > #the data frame missing
>> > missing<-data.frame(vals=combs[counts<2],count=counts[counts<2])
>> >
>> > genRows<-function(dat){
>> >         vals<-strsplit(dat[1],':')[[1]]
>> >                 #not sure why dat[2] is being converted to a string
>> >         newRows<-2-as.numeric(dat[2])
>> >         newDf<-data.frame(animals=rep(vals[1],newRows),
>> >                           animalYears=rep(vals[2],newRows),
>> >                           animalMass=rep(NA,newRows))
>> >         return(newDf)
>> >         }
>> >
>> >
>> > x<-apply(missing,1,genRows)
>> > comAn=rbind(comAn,
>> >         do.call(rbind,x))
>> >
>> >> comAn
>> >    animals animalYears animalMass
>> > 1     bird           1         29
>> > 2     bird           1         48
>> > 3     bird           1         36
>> > 4     bird           2         20
>> > 5     bird           2         34
>> > 6     bird           2         34
>> > 7      dog           1         21
>> > 8      dog           1         28
>> > 9      dog           1         25
>> > 10     dog           2         35
>> > 11     dog           2         18
>> > 12     dog           2         11
>> > 13     cat           1         46
>> > 14     cat           1         33
>> > 15     cat           1         48
>> > 16     cat           2         21
>> > 17     cat           2       <NA>
>> >
>> > So far so good, but then I adjust the code so that it reads (**notice
>> > the
>> > change in the specification in 'missing' to counts<3**):
>> >
>> > #combs defines the different combinations of
>> > #animals and animalYears
>> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
>> > #counts defines how long the different combinations are
>> > counts<-ave(1:nrow(comAn),combs,FUN=length)
>> > #missing defines the combs that have length less than one and puts it in
>> > #the data frame missing
>> > missing<-data.frame(vals=combs[counts<3],count=counts[counts<3])
>> >
>> > genRows<-function(dat){
>> >         vals<-strsplit(dat[1],':')[[1]]
>> >                 #not sure why dat[2] is being converted to a string
>> >         newRows<-2-as.numeric(dat[2])
>> >         newDf<-data.frame(animals=rep(vals[1],newRows),
>> >                           animalYears=rep(vals[2],newRows),
>> >                           animalMass=rep(NA,newRows))
>> >         return(newDf)
>> >         }
>> >
>> >
>> > x<-apply(missing,1,genRows)
>> > comAn=rbind(comAn,
>> >         do.call(rbind,x))
>> >
>> > The result for 'x' then reads:
>> >
>> >> x
>> > [[1]]
>> > [1] animals     animalYears animalMass
>> > <0 rows> (or 0-length row.names)
>> >
>> > Any thoughts on why it might be doing this instead of adding an
>> > additional
>> > row to get the result:
>> >
>> >> comAn
>> >    animals animalYears animalMass
>> > 1     bird           1         29
>> > 2     bird           1         48
>> > 3     bird           1         36
>> > 4     bird           2         20
>> > 5     bird           2         34
>> > 6     bird           2         34
>> > 7      dog           1         21
>> > 8      dog           1         28
>> > 9      dog           1         25
>> > 10     dog           2         35
>> > 11     dog           2         18
>> > 12     dog           2         11
>> > 13     cat           1         46
>> > 14     cat           1         33
>> > 15     cat           1         48
>> > 16     cat           2         21
>> > 17     cat           2       <NA>
>> > 18     cat           2       <NA>
>> >
>> > Thanks
>> > --
>> > Curtis Burkhalter
>
>


From curtisburkhalter at gmail.com  Tue Mar 10 21:57:14 2015
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Tue, 10 Mar 2015 14:57:14 -0600
Subject: [R] problem applying the same function twice
In-Reply-To: <CAM_vju=f6CTPbq8XJgx6eNAr_UFSK_Lx0ETgpFG2vdoX3OFOLw@mail.gmail.com>
References: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>
	<CAM_vju=bLmXg99ZrhfdOw9C9bMDJ=evbVKOFtAZvg-ug3NcEeQ@mail.gmail.com>
	<CAJmwvUaSPpO05PtqjGO5GKnrWoHMf2s9A-aAibpVUQdbUXBWBA@mail.gmail.com>
	<CAM_vju=f6CTPbq8XJgx6eNAr_UFSK_Lx0ETgpFG2vdoX3OFOLw@mail.gmail.com>
Message-ID: <CAJmwvUYfbCT-KaHdEvkDvG-RW_Yx6_421jxgj-zTLzitxazD5w@mail.gmail.com>

Sarah,

I have 669 sites and each site has 7 years of data, so if I'm thinking
correctly then there should be 4683 possible combinations of site x year.
For each year though I need 3 sampling periods so that there is something
like the following:

site 1      year1      sample 1
site 1      year1      sample 2
site 1      year1      sample 3
site 2      year1      sample 1
site 2      year1      sample 2
site 2      year1      sample 3.....
site 669   year7      sample 1
site 669   year7     sample 2
site 669   year7     sample 3.

I have my max memory allocation set to the amount of RAM (8GB) on my
laptop, but it still 'times out' due to memory problems.

On Tue, Mar 10, 2015 at 2:50 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> You said your data only had 14000 rows, which really isn't many.
>
> How many possible combinations do you have, and how many do you need to
> add?
>
> On Tue, Mar 10, 2015 at 4:35 PM, Curtis Burkhalter
> <curtisburkhalter at gmail.com> wrote:
> > Sarah,
> >
> > This strategy works great for this small dataset, but when I attempt your
> > method with my data set I reach the maximum allowable memory allocation
> and
> > the operation just stalls and then stops completely before it is
> finished.
> > Do you know of a way around this?
> >
> > Thanks
> >
> > On Tue, Mar 10, 2015 at 2:04 PM, Sarah Goslee <sarah.goslee at gmail.com>
> > wrote:
> >>
> >> Hi,
> >>
> >> I didn't work through your code, because it looked overly complicated.
> >> Here's a more general approach that does what you appear to want:
> >>
> >> # use dput() to provide reproducible data please!
> >> comAn <- structure(list(animals = c("bird", "bird", "bird", "bird",
> >> "bird",
> >> "bird", "dog", "dog", "dog", "dog", "dog", "dog", "cat", "cat",
> >> "cat", "cat"), animalYears = c(1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
> >> 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), animalMass = c(29L, 48L, 36L,
> >> 20L, 34L, 34L, 21L, 28L, 25L, 35L, 18L, 11L, 46L, 33L, 48L, 21L
> >> )), .Names = c("animals", "animalYears", "animalMass"), class =
> >> "data.frame", row.names = c("1",
> >> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
> >> "14", "15", "16"))
> >>
> >>
> >> # add reps to comAn
> >> # assumes comAn is already sorted on animals, animalYears
> >> comAn$reps <- unlist(sapply(rle(do.call("paste",
> >> comAn[,1:2]))$lengths, seq_len))
> >>
> >> # create full set of combinations
> >> outgrid <- expand.grid(animals=unique(comAn$animals),
> >> animalYears=unique(comAn$animalYears), reps=unique(comAn$reps),
> >> stringsAsFactors=FALSE)
> >>
> >> # combine with comAn
> >> comAn.full <- merge(outgrid, comAn, all.x=TRUE)
> >>
> >> > comAn.full
> >>    animals animalYears reps animalMass
> >> 1     bird           1    1         29
> >> 2     bird           1    2         48
> >> 3     bird           1    3         36
> >> 4     bird           2    1         20
> >> 5     bird           2    2         34
> >> 6     bird           2    3         34
> >> 7      cat           1    1         46
> >> 8      cat           1    2         33
> >> 9      cat           1    3         48
> >> 10     cat           2    1         21
> >> 11     cat           2    2         NA
> >> 12     cat           2    3         NA
> >> 13     dog           1    1         21
> >> 14     dog           1    2         28
> >> 15     dog           1    3         25
> >> 16     dog           2    1         35
> >> 17     dog           2    2         18
> >> 18     dog           2    3         11
> >> >
> >>
> >> On Tue, Mar 10, 2015 at 3:43 PM, Curtis Burkhalter
> >> <curtisburkhalter at gmail.com> wrote:
> >> > Hey everyone,
> >> >
> >> > I've written a function that adds NAs to a dataframe where data is
> >> > missing
> >> > and it seems to work great if I only need to run it once, but if I run
> >> > it
> >> > two times in a row I run into problems. I've created a workable
> example
> >> > to
> >> > explain what I mean and why I would do this.
> >> >
> >> > In my dataframe there are areas where I need to add two rows of NAs
> (b/c
> >> > I
> >> > need to have 3 animal x year combos and for cat in year 2 I only have
> >> > one)
> >> > so I thought that I'd just run my code twice using the function in the
> >> > code
> >> > below. Everything works great when I run it the first time, but when I
> >> > run
> >> > it again it says that the value returned to the list 'x' is of length
> 0.
> >> > I
> >> > don't understand why the function works the first time around and adds
> >> > an
> >> > NA to the 'animalMass' column, but won't do it again. I've used
> >> > (print(str(dataframe)) to see if there is a change in class or type
> when
> >> > the function runs through the original dataframe and there is for
> >> > 'animalYears', but I just convert it back before rerunning the
> function
> >> > for
> >> > second time.
> >> >
> >> > Any thoughts on this would be greatly appreciated b/c my actual data
> >> > dataframe I have to input into WinBUGS is 14000x12, so it's not a
> >> > trivial
> >> > thing to just add in an NA here or there.
> >> >
> >> >>comAn
> >> >    animals animalYears animalMass
> >> > 1     bird           1         29
> >> > 2     bird           1         48
> >> > 3     bird           1         36
> >> > 4     bird           2         20
> >> > 5     bird           2         34
> >> > 6     bird           2         34
> >> > 7      dog           1         21
> >> > 8      dog           1         28
> >> > 9      dog           1         25
> >> > 10     dog           2         35
> >> > 11     dog           2         18
> >> > 12     dog           2         11
> >> > 13     cat           1         46
> >> > 14     cat           1         33
> >> > 15     cat           1         48
> >> > 16     cat           2         21
> >> >
> >> > So every animal has 3 measurements per year, except for the cat in
> year
> >> > two
> >> > which has only 1. I run the code below and get:
> >> >
> >> > #combs defines the different combinations of
> >> > #animals and animalYears
> >> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
> >> > #counts defines how long the different combinations are
> >> > counts<-ave(1:nrow(comAn),combs,FUN=length)
> >> > #missing defines the combs that have length less than one and puts it
> in
> >> > #the data frame missing
> >> > missing<-data.frame(vals=combs[counts<2],count=counts[counts<2])
> >> >
> >> > genRows<-function(dat){
> >> >         vals<-strsplit(dat[1],':')[[1]]
> >> >                 #not sure why dat[2] is being converted to a string
> >> >         newRows<-2-as.numeric(dat[2])
> >> >         newDf<-data.frame(animals=rep(vals[1],newRows),
> >> >                           animalYears=rep(vals[2],newRows),
> >> >                           animalMass=rep(NA,newRows))
> >> >         return(newDf)
> >> >         }
> >> >
> >> >
> >> > x<-apply(missing,1,genRows)
> >> > comAn=rbind(comAn,
> >> >         do.call(rbind,x))
> >> >
> >> >> comAn
> >> >    animals animalYears animalMass
> >> > 1     bird           1         29
> >> > 2     bird           1         48
> >> > 3     bird           1         36
> >> > 4     bird           2         20
> >> > 5     bird           2         34
> >> > 6     bird           2         34
> >> > 7      dog           1         21
> >> > 8      dog           1         28
> >> > 9      dog           1         25
> >> > 10     dog           2         35
> >> > 11     dog           2         18
> >> > 12     dog           2         11
> >> > 13     cat           1         46
> >> > 14     cat           1         33
> >> > 15     cat           1         48
> >> > 16     cat           2         21
> >> > 17     cat           2       <NA>
> >> >
> >> > So far so good, but then I adjust the code so that it reads (**notice
> >> > the
> >> > change in the specification in 'missing' to counts<3**):
> >> >
> >> > #combs defines the different combinations of
> >> > #animals and animalYears
> >> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
> >> > #counts defines how long the different combinations are
> >> > counts<-ave(1:nrow(comAn),combs,FUN=length)
> >> > #missing defines the combs that have length less than one and puts it
> in
> >> > #the data frame missing
> >> > missing<-data.frame(vals=combs[counts<3],count=counts[counts<3])
> >> >
> >> > genRows<-function(dat){
> >> >         vals<-strsplit(dat[1],':')[[1]]
> >> >                 #not sure why dat[2] is being converted to a string
> >> >         newRows<-2-as.numeric(dat[2])
> >> >         newDf<-data.frame(animals=rep(vals[1],newRows),
> >> >                           animalYears=rep(vals[2],newRows),
> >> >                           animalMass=rep(NA,newRows))
> >> >         return(newDf)
> >> >         }
> >> >
> >> >
> >> > x<-apply(missing,1,genRows)
> >> > comAn=rbind(comAn,
> >> >         do.call(rbind,x))
> >> >
> >> > The result for 'x' then reads:
> >> >
> >> >> x
> >> > [[1]]
> >> > [1] animals     animalYears animalMass
> >> > <0 rows> (or 0-length row.names)
> >> >
> >> > Any thoughts on why it might be doing this instead of adding an
> >> > additional
> >> > row to get the result:
> >> >
> >> >> comAn
> >> >    animals animalYears animalMass
> >> > 1     bird           1         29
> >> > 2     bird           1         48
> >> > 3     bird           1         36
> >> > 4     bird           2         20
> >> > 5     bird           2         34
> >> > 6     bird           2         34
> >> > 7      dog           1         21
> >> > 8      dog           1         28
> >> > 9      dog           1         25
> >> > 10     dog           2         35
> >> > 11     dog           2         18
> >> > 12     dog           2         11
> >> > 13     cat           1         46
> >> > 14     cat           1         33
> >> > 15     cat           1         48
> >> > 16     cat           2         21
> >> > 17     cat           2       <NA>
> >> > 18     cat           2       <NA>
> >> >
> >> > Thanks
> >> > --
> >> > Curtis Burkhalter
> >
> >
>



-- 
Curtis Burkhalter

https://sites.google.com/site/curtisburkhalter/

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Tue Mar 10 22:12:03 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 10 Mar 2015 17:12:03 -0400
Subject: [R] problem applying the same function twice
In-Reply-To: <CAJmwvUYfbCT-KaHdEvkDvG-RW_Yx6_421jxgj-zTLzitxazD5w@mail.gmail.com>
References: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>
	<CAM_vju=bLmXg99ZrhfdOw9C9bMDJ=evbVKOFtAZvg-ug3NcEeQ@mail.gmail.com>
	<CAJmwvUaSPpO05PtqjGO5GKnrWoHMf2s9A-aAibpVUQdbUXBWBA@mail.gmail.com>
	<CAM_vju=f6CTPbq8XJgx6eNAr_UFSK_Lx0ETgpFG2vdoX3OFOLw@mail.gmail.com>
	<CAJmwvUYfbCT-KaHdEvkDvG-RW_Yx6_421jxgj-zTLzitxazD5w@mail.gmail.com>
Message-ID: <CAM_vjumrX2cj27QgMCdQ0nWx5uTrq=yrdnnZgghydQr9Fh416A@mail.gmail.com>

Yeah, that's tiny:

> fullout <- expand.grid(site=1:669, year=1:7, sample=1:3)
> dim(fullout)
[1] 14049     3


Almost certainly the problem is that your expand.grid result doesn't
have the same column names as your actual data file, so merge() is
trying to make an enormous result. Note how when I made outgrid in the
example I named the columns.

Make sure that the names are identical!


On Tue, Mar 10, 2015 at 4:57 PM, Curtis Burkhalter
<curtisburkhalter at gmail.com> wrote:
> Sarah,
>
> I have 669 sites and each site has 7 years of data, so if I'm thinking
> correctly then there should be 4683 possible combinations of site x year.
> For each year though I need 3 sampling periods so that there is something
> like the following:
>
> site 1      year1      sample 1
> site 1      year1      sample 2
> site 1      year1      sample 3
> site 2      year1      sample 1
> site 2      year1      sample 2
> site 2      year1      sample 3.....
> site 669   year7      sample 1
> site 669   year7     sample 2
> site 669   year7     sample 3.
>
> I have my max memory allocation set to the amount of RAM (8GB) on my laptop,
> but it still 'times out' due to memory problems.
>
> On Tue, Mar 10, 2015 at 2:50 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> You said your data only had 14000 rows, which really isn't many.
>>
>> How many possible combinations do you have, and how many do you need to
>> add?
>>
>> On Tue, Mar 10, 2015 at 4:35 PM, Curtis Burkhalter
>> <curtisburkhalter at gmail.com> wrote:
>> > Sarah,
>> >
>> > This strategy works great for this small dataset, but when I attempt
>> > your
>> > method with my data set I reach the maximum allowable memory allocation
>> > and
>> > the operation just stalls and then stops completely before it is
>> > finished.
>> > Do you know of a way around this?
>> >
>> > Thanks
>> >
>> > On Tue, Mar 10, 2015 at 2:04 PM, Sarah Goslee <sarah.goslee at gmail.com>
>> > wrote:
>> >>
>> >> Hi,
>> >>
>> >> I didn't work through your code, because it looked overly complicated.
>> >> Here's a more general approach that does what you appear to want:
>> >>
>> >> # use dput() to provide reproducible data please!
>> >> comAn <- structure(list(animals = c("bird", "bird", "bird", "bird",
>> >> "bird",
>> >> "bird", "dog", "dog", "dog", "dog", "dog", "dog", "cat", "cat",
>> >> "cat", "cat"), animalYears = c(1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
>> >> 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), animalMass = c(29L, 48L, 36L,
>> >> 20L, 34L, 34L, 21L, 28L, 25L, 35L, 18L, 11L, 46L, 33L, 48L, 21L
>> >> )), .Names = c("animals", "animalYears", "animalMass"), class =
>> >> "data.frame", row.names = c("1",
>> >> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
>> >> "14", "15", "16"))
>> >>
>> >>
>> >> # add reps to comAn
>> >> # assumes comAn is already sorted on animals, animalYears
>> >> comAn$reps <- unlist(sapply(rle(do.call("paste",
>> >> comAn[,1:2]))$lengths, seq_len))
>> >>
>> >> # create full set of combinations
>> >> outgrid <- expand.grid(animals=unique(comAn$animals),
>> >> animalYears=unique(comAn$animalYears), reps=unique(comAn$reps),
>> >> stringsAsFactors=FALSE)
>> >>
>> >> # combine with comAn
>> >> comAn.full <- merge(outgrid, comAn, all.x=TRUE)
>> >>
>> >> > comAn.full
>> >>    animals animalYears reps animalMass
>> >> 1     bird           1    1         29
>> >> 2     bird           1    2         48
>> >> 3     bird           1    3         36
>> >> 4     bird           2    1         20
>> >> 5     bird           2    2         34
>> >> 6     bird           2    3         34
>> >> 7      cat           1    1         46
>> >> 8      cat           1    2         33
>> >> 9      cat           1    3         48
>> >> 10     cat           2    1         21
>> >> 11     cat           2    2         NA
>> >> 12     cat           2    3         NA
>> >> 13     dog           1    1         21
>> >> 14     dog           1    2         28
>> >> 15     dog           1    3         25
>> >> 16     dog           2    1         35
>> >> 17     dog           2    2         18
>> >> 18     dog           2    3         11
>> >> >
>> >>
>> >> On Tue, Mar 10, 2015 at 3:43 PM, Curtis Burkhalter
>> >> <curtisburkhalter at gmail.com> wrote:
>> >> > Hey everyone,
>> >> >
>> >> > I've written a function that adds NAs to a dataframe where data is
>> >> > missing
>> >> > and it seems to work great if I only need to run it once, but if I
>> >> > run
>> >> > it
>> >> > two times in a row I run into problems. I've created a workable
>> >> > example
>> >> > to
>> >> > explain what I mean and why I would do this.
>> >> >
>> >> > In my dataframe there are areas where I need to add two rows of NAs
>> >> > (b/c
>> >> > I
>> >> > need to have 3 animal x year combos and for cat in year 2 I only have
>> >> > one)
>> >> > so I thought that I'd just run my code twice using the function in
>> >> > the
>> >> > code
>> >> > below. Everything works great when I run it the first time, but when
>> >> > I
>> >> > run
>> >> > it again it says that the value returned to the list 'x' is of length
>> >> > 0.
>> >> > I
>> >> > don't understand why the function works the first time around and
>> >> > adds
>> >> > an
>> >> > NA to the 'animalMass' column, but won't do it again. I've used
>> >> > (print(str(dataframe)) to see if there is a change in class or type
>> >> > when
>> >> > the function runs through the original dataframe and there is for
>> >> > 'animalYears', but I just convert it back before rerunning the
>> >> > function
>> >> > for
>> >> > second time.
>> >> >
>> >> > Any thoughts on this would be greatly appreciated b/c my actual data
>> >> > dataframe I have to input into WinBUGS is 14000x12, so it's not a
>> >> > trivial
>> >> > thing to just add in an NA here or there.
>> >> >
>> >> >>comAn
>> >> >    animals animalYears animalMass
>> >> > 1     bird           1         29
>> >> > 2     bird           1         48
>> >> > 3     bird           1         36
>> >> > 4     bird           2         20
>> >> > 5     bird           2         34
>> >> > 6     bird           2         34
>> >> > 7      dog           1         21
>> >> > 8      dog           1         28
>> >> > 9      dog           1         25
>> >> > 10     dog           2         35
>> >> > 11     dog           2         18
>> >> > 12     dog           2         11
>> >> > 13     cat           1         46
>> >> > 14     cat           1         33
>> >> > 15     cat           1         48
>> >> > 16     cat           2         21
>> >> >
>> >> > So every animal has 3 measurements per year, except for the cat in
>> >> > year
>> >> > two
>> >> > which has only 1. I run the code below and get:
>> >> >
>> >> > #combs defines the different combinations of
>> >> > #animals and animalYears
>> >> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
>> >> > #counts defines how long the different combinations are
>> >> > counts<-ave(1:nrow(comAn),combs,FUN=length)
>> >> > #missing defines the combs that have length less than one and puts it
>> >> > in
>> >> > #the data frame missing
>> >> > missing<-data.frame(vals=combs[counts<2],count=counts[counts<2])
>> >> >
>> >> > genRows<-function(dat){
>> >> >         vals<-strsplit(dat[1],':')[[1]]
>> >> >                 #not sure why dat[2] is being converted to a string
>> >> >         newRows<-2-as.numeric(dat[2])
>> >> >         newDf<-data.frame(animals=rep(vals[1],newRows),
>> >> >                           animalYears=rep(vals[2],newRows),
>> >> >                           animalMass=rep(NA,newRows))
>> >> >         return(newDf)
>> >> >         }
>> >> >
>> >> >
>> >> > x<-apply(missing,1,genRows)
>> >> > comAn=rbind(comAn,
>> >> >         do.call(rbind,x))
>> >> >
>> >> >> comAn
>> >> >    animals animalYears animalMass
>> >> > 1     bird           1         29
>> >> > 2     bird           1         48
>> >> > 3     bird           1         36
>> >> > 4     bird           2         20
>> >> > 5     bird           2         34
>> >> > 6     bird           2         34
>> >> > 7      dog           1         21
>> >> > 8      dog           1         28
>> >> > 9      dog           1         25
>> >> > 10     dog           2         35
>> >> > 11     dog           2         18
>> >> > 12     dog           2         11
>> >> > 13     cat           1         46
>> >> > 14     cat           1         33
>> >> > 15     cat           1         48
>> >> > 16     cat           2         21
>> >> > 17     cat           2       <NA>
>> >> >
>> >> > So far so good, but then I adjust the code so that it reads (**notice
>> >> > the
>> >> > change in the specification in 'missing' to counts<3**):
>> >> >
>> >> > #combs defines the different combinations of
>> >> > #animals and animalYears
>> >> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
>> >> > #counts defines how long the different combinations are
>> >> > counts<-ave(1:nrow(comAn),combs,FUN=length)
>> >> > #missing defines the combs that have length less than one and puts it
>> >> > in
>> >> > #the data frame missing
>> >> > missing<-data.frame(vals=combs[counts<3],count=counts[counts<3])
>> >> >
>> >> > genRows<-function(dat){
>> >> >         vals<-strsplit(dat[1],':')[[1]]
>> >> >                 #not sure why dat[2] is being converted to a string
>> >> >         newRows<-2-as.numeric(dat[2])
>> >> >         newDf<-data.frame(animals=rep(vals[1],newRows),
>> >> >                           animalYears=rep(vals[2],newRows),
>> >> >                           animalMass=rep(NA,newRows))
>> >> >         return(newDf)
>> >> >         }
>> >> >
>> >> >
>> >> > x<-apply(missing,1,genRows)
>> >> > comAn=rbind(comAn,
>> >> >         do.call(rbind,x))
>> >> >
>> >> > The result for 'x' then reads:
>> >> >
>> >> >> x
>> >> > [[1]]
>> >> > [1] animals     animalYears animalMass
>> >> > <0 rows> (or 0-length row.names)
>> >> >
>> >> > Any thoughts on why it might be doing this instead of adding an
>> >> > additional
>> >> > row to get the result:
>> >> >
>> >> >> comAn
>> >> >    animals animalYears animalMass
>> >> > 1     bird           1         29
>> >> > 2     bird           1         48
>> >> > 3     bird           1         36
>> >> > 4     bird           2         20
>> >> > 5     bird           2         34
>> >> > 6     bird           2         34
>> >> > 7      dog           1         21
>> >> > 8      dog           1         28
>> >> > 9      dog           1         25
>> >> > 10     dog           2         35
>> >> > 11     dog           2         18
>> >> > 12     dog           2         11
>> >> > 13     cat           1         46
>> >> > 14     cat           1         33
>> >> > 15     cat           1         48
>> >> > 16     cat           2         21
>> >> > 17     cat           2       <NA>
>> >> > 18     cat           2       <NA>
>> >> >
>> >> > Thanks
>> >> > --
>> >> > Curtis Burkhalter
>> >
>> >


From curtisburkhalter at gmail.com  Tue Mar 10 22:35:46 2015
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Tue, 10 Mar 2015 15:35:46 -0600
Subject: [R] problem applying the same function twice
In-Reply-To: <CAM_vjumrX2cj27QgMCdQ0nWx5uTrq=yrdnnZgghydQr9Fh416A@mail.gmail.com>
References: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>
	<CAM_vju=bLmXg99ZrhfdOw9C9bMDJ=evbVKOFtAZvg-ug3NcEeQ@mail.gmail.com>
	<CAJmwvUaSPpO05PtqjGO5GKnrWoHMf2s9A-aAibpVUQdbUXBWBA@mail.gmail.com>
	<CAM_vju=f6CTPbq8XJgx6eNAr_UFSK_Lx0ETgpFG2vdoX3OFOLw@mail.gmail.com>
	<CAJmwvUYfbCT-KaHdEvkDvG-RW_Yx6_421jxgj-zTLzitxazD5w@mail.gmail.com>
	<CAM_vjumrX2cj27QgMCdQ0nWx5uTrq=yrdnnZgghydQr9Fh416A@mail.gmail.com>
Message-ID: <CAJmwvUYSZ8akeimhdrS3hZBQJcfEFKUreaKgg93-BscS87euvw@mail.gmail.com>

Thanks Sarah, one of my column names was missing a letter so it was
throwing things off. It works super fast now and is exactly what I needed.
My actual data set  has about 6 other ancillary response data data columns,
is there a way to combine the 'full' data set I just created with the
original in case I need any of the other response variables. E.g.

FULL:                                          Original:
                                           Combined:
site    year     sample                    site    year     sample
color     shape                  site    year     sample     color
shape
1        1         10                           1        1         10
     blue       diamond              1        1         10            blue
      diamond
1         1        12                           1         1        12
     green     pyramid               1         1        12            green
    pyramid
1         1        NA
                                               1         1        NA
    NA        NA

Thanks

On Tue, Mar 10, 2015 at 3:12 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Yeah, that's tiny:
>
> > fullout <- expand.grid(site=1:669, year=1:7, sample=1:3)
> > dim(fullout)
> [1] 14049     3
>
>
> Almost certainly the problem is that your expand.grid result doesn't
> have the same column names as your actual data file, so merge() is
> trying to make an enormous result. Note how when I made outgrid in the
> example I named the columns.
>
> Make sure that the names are identical!
>
>
> On Tue, Mar 10, 2015 at 4:57 PM, Curtis Burkhalter
> <curtisburkhalter at gmail.com> wrote:
> > Sarah,
> >
> > I have 669 sites and each site has 7 years of data, so if I'm thinking
> > correctly then there should be 4683 possible combinations of site x year.
> > For each year though I need 3 sampling periods so that there is something
> > like the following:
> >
> > site 1      year1      sample 1
> > site 1      year1      sample 2
> > site 1      year1      sample 3
> > site 2      year1      sample 1
> > site 2      year1      sample 2
> > site 2      year1      sample 3.....
> > site 669   year7      sample 1
> > site 669   year7     sample 2
> > site 669   year7     sample 3.
> >
> > I have my max memory allocation set to the amount of RAM (8GB) on my
> laptop,
> > but it still 'times out' due to memory problems.
> >
> > On Tue, Mar 10, 2015 at 2:50 PM, Sarah Goslee <sarah.goslee at gmail.com>
> > wrote:
> >>
> >> You said your data only had 14000 rows, which really isn't many.
> >>
> >> How many possible combinations do you have, and how many do you need to
> >> add?
> >>
> >> On Tue, Mar 10, 2015 at 4:35 PM, Curtis Burkhalter
> >> <curtisburkhalter at gmail.com> wrote:
> >> > Sarah,
> >> >
> >> > This strategy works great for this small dataset, but when I attempt
> >> > your
> >> > method with my data set I reach the maximum allowable memory
> allocation
> >> > and
> >> > the operation just stalls and then stops completely before it is
> >> > finished.
> >> > Do you know of a way around this?
> >> >
> >> > Thanks
> >> >
> >> > On Tue, Mar 10, 2015 at 2:04 PM, Sarah Goslee <sarah.goslee at gmail.com
> >
> >> > wrote:
> >> >>
> >> >> Hi,
> >> >>
> >> >> I didn't work through your code, because it looked overly
> complicated.
> >> >> Here's a more general approach that does what you appear to want:
> >> >>
> >> >> # use dput() to provide reproducible data please!
> >> >> comAn <- structure(list(animals = c("bird", "bird", "bird", "bird",
> >> >> "bird",
> >> >> "bird", "dog", "dog", "dog", "dog", "dog", "dog", "cat", "cat",
> >> >> "cat", "cat"), animalYears = c(1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
> >> >> 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), animalMass = c(29L, 48L, 36L,
> >> >> 20L, 34L, 34L, 21L, 28L, 25L, 35L, 18L, 11L, 46L, 33L, 48L, 21L
> >> >> )), .Names = c("animals", "animalYears", "animalMass"), class =
> >> >> "data.frame", row.names = c("1",
> >> >> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
> >> >> "14", "15", "16"))
> >> >>
> >> >>
> >> >> # add reps to comAn
> >> >> # assumes comAn is already sorted on animals, animalYears
> >> >> comAn$reps <- unlist(sapply(rle(do.call("paste",
> >> >> comAn[,1:2]))$lengths, seq_len))
> >> >>
> >> >> # create full set of combinations
> >> >> outgrid <- expand.grid(animals=unique(comAn$animals),
> >> >> animalYears=unique(comAn$animalYears), reps=unique(comAn$reps),
> >> >> stringsAsFactors=FALSE)
> >> >>
> >> >> # combine with comAn
> >> >> comAn.full <- merge(outgrid, comAn, all.x=TRUE)
> >> >>
> >> >> > comAn.full
> >> >>    animals animalYears reps animalMass
> >> >> 1     bird           1    1         29
> >> >> 2     bird           1    2         48
> >> >> 3     bird           1    3         36
> >> >> 4     bird           2    1         20
> >> >> 5     bird           2    2         34
> >> >> 6     bird           2    3         34
> >> >> 7      cat           1    1         46
> >> >> 8      cat           1    2         33
> >> >> 9      cat           1    3         48
> >> >> 10     cat           2    1         21
> >> >> 11     cat           2    2         NA
> >> >> 12     cat           2    3         NA
> >> >> 13     dog           1    1         21
> >> >> 14     dog           1    2         28
> >> >> 15     dog           1    3         25
> >> >> 16     dog           2    1         35
> >> >> 17     dog           2    2         18
> >> >> 18     dog           2    3         11
> >> >> >
> >> >>
> >> >> On Tue, Mar 10, 2015 at 3:43 PM, Curtis Burkhalter
> >> >> <curtisburkhalter at gmail.com> wrote:
> >> >> > Hey everyone,
> >> >> >
> >> >> > I've written a function that adds NAs to a dataframe where data is
> >> >> > missing
> >> >> > and it seems to work great if I only need to run it once, but if I
> >> >> > run
> >> >> > it
> >> >> > two times in a row I run into problems. I've created a workable
> >> >> > example
> >> >> > to
> >> >> > explain what I mean and why I would do this.
> >> >> >
> >> >> > In my dataframe there are areas where I need to add two rows of NAs
> >> >> > (b/c
> >> >> > I
> >> >> > need to have 3 animal x year combos and for cat in year 2 I only
> have
> >> >> > one)
> >> >> > so I thought that I'd just run my code twice using the function in
> >> >> > the
> >> >> > code
> >> >> > below. Everything works great when I run it the first time, but
> when
> >> >> > I
> >> >> > run
> >> >> > it again it says that the value returned to the list 'x' is of
> length
> >> >> > 0.
> >> >> > I
> >> >> > don't understand why the function works the first time around and
> >> >> > adds
> >> >> > an
> >> >> > NA to the 'animalMass' column, but won't do it again. I've used
> >> >> > (print(str(dataframe)) to see if there is a change in class or type
> >> >> > when
> >> >> > the function runs through the original dataframe and there is for
> >> >> > 'animalYears', but I just convert it back before rerunning the
> >> >> > function
> >> >> > for
> >> >> > second time.
> >> >> >
> >> >> > Any thoughts on this would be greatly appreciated b/c my actual
> data
> >> >> > dataframe I have to input into WinBUGS is 14000x12, so it's not a
> >> >> > trivial
> >> >> > thing to just add in an NA here or there.
> >> >> >
> >> >> >>comAn
> >> >> >    animals animalYears animalMass
> >> >> > 1     bird           1         29
> >> >> > 2     bird           1         48
> >> >> > 3     bird           1         36
> >> >> > 4     bird           2         20
> >> >> > 5     bird           2         34
> >> >> > 6     bird           2         34
> >> >> > 7      dog           1         21
> >> >> > 8      dog           1         28
> >> >> > 9      dog           1         25
> >> >> > 10     dog           2         35
> >> >> > 11     dog           2         18
> >> >> > 12     dog           2         11
> >> >> > 13     cat           1         46
> >> >> > 14     cat           1         33
> >> >> > 15     cat           1         48
> >> >> > 16     cat           2         21
> >> >> >
> >> >> > So every animal has 3 measurements per year, except for the cat in
> >> >> > year
> >> >> > two
> >> >> > which has only 1. I run the code below and get:
> >> >> >
> >> >> > #combs defines the different combinations of
> >> >> > #animals and animalYears
> >> >> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
> >> >> > #counts defines how long the different combinations are
> >> >> > counts<-ave(1:nrow(comAn),combs,FUN=length)
> >> >> > #missing defines the combs that have length less than one and puts
> it
> >> >> > in
> >> >> > #the data frame missing
> >> >> > missing<-data.frame(vals=combs[counts<2],count=counts[counts<2])
> >> >> >
> >> >> > genRows<-function(dat){
> >> >> >         vals<-strsplit(dat[1],':')[[1]]
> >> >> >                 #not sure why dat[2] is being converted to a string
> >> >> >         newRows<-2-as.numeric(dat[2])
> >> >> >         newDf<-data.frame(animals=rep(vals[1],newRows),
> >> >> >                           animalYears=rep(vals[2],newRows),
> >> >> >                           animalMass=rep(NA,newRows))
> >> >> >         return(newDf)
> >> >> >         }
> >> >> >
> >> >> >
> >> >> > x<-apply(missing,1,genRows)
> >> >> > comAn=rbind(comAn,
> >> >> >         do.call(rbind,x))
> >> >> >
> >> >> >> comAn
> >> >> >    animals animalYears animalMass
> >> >> > 1     bird           1         29
> >> >> > 2     bird           1         48
> >> >> > 3     bird           1         36
> >> >> > 4     bird           2         20
> >> >> > 5     bird           2         34
> >> >> > 6     bird           2         34
> >> >> > 7      dog           1         21
> >> >> > 8      dog           1         28
> >> >> > 9      dog           1         25
> >> >> > 10     dog           2         35
> >> >> > 11     dog           2         18
> >> >> > 12     dog           2         11
> >> >> > 13     cat           1         46
> >> >> > 14     cat           1         33
> >> >> > 15     cat           1         48
> >> >> > 16     cat           2         21
> >> >> > 17     cat           2       <NA>
> >> >> >
> >> >> > So far so good, but then I adjust the code so that it reads
> (**notice
> >> >> > the
> >> >> > change in the specification in 'missing' to counts<3**):
> >> >> >
> >> >> > #combs defines the different combinations of
> >> >> > #animals and animalYears
> >> >> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
> >> >> > #counts defines how long the different combinations are
> >> >> > counts<-ave(1:nrow(comAn),combs,FUN=length)
> >> >> > #missing defines the combs that have length less than one and puts
> it
> >> >> > in
> >> >> > #the data frame missing
> >> >> > missing<-data.frame(vals=combs[counts<3],count=counts[counts<3])
> >> >> >
> >> >> > genRows<-function(dat){
> >> >> >         vals<-strsplit(dat[1],':')[[1]]
> >> >> >                 #not sure why dat[2] is being converted to a string
> >> >> >         newRows<-2-as.numeric(dat[2])
> >> >> >         newDf<-data.frame(animals=rep(vals[1],newRows),
> >> >> >                           animalYears=rep(vals[2],newRows),
> >> >> >                           animalMass=rep(NA,newRows))
> >> >> >         return(newDf)
> >> >> >         }
> >> >> >
> >> >> >
> >> >> > x<-apply(missing,1,genRows)
> >> >> > comAn=rbind(comAn,
> >> >> >         do.call(rbind,x))
> >> >> >
> >> >> > The result for 'x' then reads:
> >> >> >
> >> >> >> x
> >> >> > [[1]]
> >> >> > [1] animals     animalYears animalMass
> >> >> > <0 rows> (or 0-length row.names)
> >> >> >
> >> >> > Any thoughts on why it might be doing this instead of adding an
> >> >> > additional
> >> >> > row to get the result:
> >> >> >
> >> >> >> comAn
> >> >> >    animals animalYears animalMass
> >> >> > 1     bird           1         29
> >> >> > 2     bird           1         48
> >> >> > 3     bird           1         36
> >> >> > 4     bird           2         20
> >> >> > 5     bird           2         34
> >> >> > 6     bird           2         34
> >> >> > 7      dog           1         21
> >> >> > 8      dog           1         28
> >> >> > 9      dog           1         25
> >> >> > 10     dog           2         35
> >> >> > 11     dog           2         18
> >> >> > 12     dog           2         11
> >> >> > 13     cat           1         46
> >> >> > 14     cat           1         33
> >> >> > 15     cat           1         48
> >> >> > 16     cat           2         21
> >> >> > 17     cat           2       <NA>
> >> >> > 18     cat           2       <NA>
> >> >> >
> >> >> > Thanks
> >> >> > --
> >> >> > Curtis Burkhalter
> >> >
> >> >
>



-- 
Curtis Burkhalter

https://sites.google.com/site/curtisburkhalter/

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Mar 10 22:40:44 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 10 Mar 2015 14:40:44 -0700
Subject: [R] problem applying the same function twice
In-Reply-To: <CAJmwvUYfbCT-KaHdEvkDvG-RW_Yx6_421jxgj-zTLzitxazD5w@mail.gmail.com>
References: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>
	<CAM_vju=bLmXg99ZrhfdOw9C9bMDJ=evbVKOFtAZvg-ug3NcEeQ@mail.gmail.com>
	<CAJmwvUaSPpO05PtqjGO5GKnrWoHMf2s9A-aAibpVUQdbUXBWBA@mail.gmail.com>
	<CAM_vju=f6CTPbq8XJgx6eNAr_UFSK_Lx0ETgpFG2vdoX3OFOLw@mail.gmail.com>
	<CAJmwvUYfbCT-KaHdEvkDvG-RW_Yx6_421jxgj-zTLzitxazD5w@mail.gmail.com>
Message-ID: <089E46D3-CB82-4C5A-966D-3E81617DD9A0@dcn.davis.CA.us>

You may find it beneficial to investigate packages dplyr, data.table, or a combination of the two for handling large data sets in memory. Or, perhaps dplyr with a SQL back end for working on disk (I have not tried that myself yet).

I do find your excuse for manufacturing data records uncompelling, though. Of the information necessary to draw valid conclusions is absent, the results you obtain by doing so is going to be questionable at best.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 10, 2015 1:57:14 PM PDT, Curtis Burkhalter <curtisburkhalter at gmail.com> wrote:
>Sarah,
>
>I have 669 sites and each site has 7 years of data, so if I'm thinking
>correctly then there should be 4683 possible combinations of site x
>year.
>For each year though I need 3 sampling periods so that there is
>something
>like the following:
>
>site 1      year1      sample 1
>site 1      year1      sample 2
>site 1      year1      sample 3
>site 2      year1      sample 1
>site 2      year1      sample 2
>site 2      year1      sample 3.....
>site 669   year7      sample 1
>site 669   year7     sample 2
>site 669   year7     sample 3.
>
>I have my max memory allocation set to the amount of RAM (8GB) on my
>laptop, but it still 'times out' due to memory problems.
>
>On Tue, Mar 10, 2015 at 2:50 PM, Sarah Goslee <sarah.goslee at gmail.com>
>wrote:
>
>> You said your data only had 14000 rows, which really isn't many.
>>
>> How many possible combinations do you have, and how many do you need
>to
>> add?
>>
>> On Tue, Mar 10, 2015 at 4:35 PM, Curtis Burkhalter
>> <curtisburkhalter at gmail.com> wrote:
>> > Sarah,
>> >
>> > This strategy works great for this small dataset, but when I
>attempt your
>> > method with my data set I reach the maximum allowable memory
>allocation
>> and
>> > the operation just stalls and then stops completely before it is
>> finished.
>> > Do you know of a way around this?
>> >
>> > Thanks
>> >
>> > On Tue, Mar 10, 2015 at 2:04 PM, Sarah Goslee
><sarah.goslee at gmail.com>
>> > wrote:
>> >>
>> >> Hi,
>> >>
>> >> I didn't work through your code, because it looked overly
>complicated.
>> >> Here's a more general approach that does what you appear to want:
>> >>
>> >> # use dput() to provide reproducible data please!
>> >> comAn <- structure(list(animals = c("bird", "bird", "bird",
>"bird",
>> >> "bird",
>> >> "bird", "dog", "dog", "dog", "dog", "dog", "dog", "cat", "cat",
>> >> "cat", "cat"), animalYears = c(1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
>> >> 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), animalMass = c(29L, 48L, 36L,
>> >> 20L, 34L, 34L, 21L, 28L, 25L, 35L, 18L, 11L, 46L, 33L, 48L, 21L
>> >> )), .Names = c("animals", "animalYears", "animalMass"), class =
>> >> "data.frame", row.names = c("1",
>> >> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
>> >> "14", "15", "16"))
>> >>
>> >>
>> >> # add reps to comAn
>> >> # assumes comAn is already sorted on animals, animalYears
>> >> comAn$reps <- unlist(sapply(rle(do.call("paste",
>> >> comAn[,1:2]))$lengths, seq_len))
>> >>
>> >> # create full set of combinations
>> >> outgrid <- expand.grid(animals=unique(comAn$animals),
>> >> animalYears=unique(comAn$animalYears), reps=unique(comAn$reps),
>> >> stringsAsFactors=FALSE)
>> >>
>> >> # combine with comAn
>> >> comAn.full <- merge(outgrid, comAn, all.x=TRUE)
>> >>
>> >> > comAn.full
>> >>    animals animalYears reps animalMass
>> >> 1     bird           1    1         29
>> >> 2     bird           1    2         48
>> >> 3     bird           1    3         36
>> >> 4     bird           2    1         20
>> >> 5     bird           2    2         34
>> >> 6     bird           2    3         34
>> >> 7      cat           1    1         46
>> >> 8      cat           1    2         33
>> >> 9      cat           1    3         48
>> >> 10     cat           2    1         21
>> >> 11     cat           2    2         NA
>> >> 12     cat           2    3         NA
>> >> 13     dog           1    1         21
>> >> 14     dog           1    2         28
>> >> 15     dog           1    3         25
>> >> 16     dog           2    1         35
>> >> 17     dog           2    2         18
>> >> 18     dog           2    3         11
>> >> >
>> >>
>> >> On Tue, Mar 10, 2015 at 3:43 PM, Curtis Burkhalter
>> >> <curtisburkhalter at gmail.com> wrote:
>> >> > Hey everyone,
>> >> >
>> >> > I've written a function that adds NAs to a dataframe where data
>is
>> >> > missing
>> >> > and it seems to work great if I only need to run it once, but if
>I run
>> >> > it
>> >> > two times in a row I run into problems. I've created a workable
>> example
>> >> > to
>> >> > explain what I mean and why I would do this.
>> >> >
>> >> > In my dataframe there are areas where I need to add two rows of
>NAs
>> (b/c
>> >> > I
>> >> > need to have 3 animal x year combos and for cat in year 2 I only
>have
>> >> > one)
>> >> > so I thought that I'd just run my code twice using the function
>in the
>> >> > code
>> >> > below. Everything works great when I run it the first time, but
>when I
>> >> > run
>> >> > it again it says that the value returned to the list 'x' is of
>length
>> 0.
>> >> > I
>> >> > don't understand why the function works the first time around
>and adds
>> >> > an
>> >> > NA to the 'animalMass' column, but won't do it again. I've used
>> >> > (print(str(dataframe)) to see if there is a change in class or
>type
>> when
>> >> > the function runs through the original dataframe and there is
>for
>> >> > 'animalYears', but I just convert it back before rerunning the
>> function
>> >> > for
>> >> > second time.
>> >> >
>> >> > Any thoughts on this would be greatly appreciated b/c my actual
>data
>> >> > dataframe I have to input into WinBUGS is 14000x12, so it's not
>a
>> >> > trivial
>> >> > thing to just add in an NA here or there.
>> >> >
>> >> >>comAn
>> >> >    animals animalYears animalMass
>> >> > 1     bird           1         29
>> >> > 2     bird           1         48
>> >> > 3     bird           1         36
>> >> > 4     bird           2         20
>> >> > 5     bird           2         34
>> >> > 6     bird           2         34
>> >> > 7      dog           1         21
>> >> > 8      dog           1         28
>> >> > 9      dog           1         25
>> >> > 10     dog           2         35
>> >> > 11     dog           2         18
>> >> > 12     dog           2         11
>> >> > 13     cat           1         46
>> >> > 14     cat           1         33
>> >> > 15     cat           1         48
>> >> > 16     cat           2         21
>> >> >
>> >> > So every animal has 3 measurements per year, except for the cat
>in
>> year
>> >> > two
>> >> > which has only 1. I run the code below and get:
>> >> >
>> >> > #combs defines the different combinations of
>> >> > #animals and animalYears
>> >> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
>> >> > #counts defines how long the different combinations are
>> >> > counts<-ave(1:nrow(comAn),combs,FUN=length)
>> >> > #missing defines the combs that have length less than one and
>puts it
>> in
>> >> > #the data frame missing
>> >> > missing<-data.frame(vals=combs[counts<2],count=counts[counts<2])
>> >> >
>> >> > genRows<-function(dat){
>> >> >         vals<-strsplit(dat[1],':')[[1]]
>> >> >                 #not sure why dat[2] is being converted to a
>string
>> >> >         newRows<-2-as.numeric(dat[2])
>> >> >         newDf<-data.frame(animals=rep(vals[1],newRows),
>> >> >                           animalYears=rep(vals[2],newRows),
>> >> >                           animalMass=rep(NA,newRows))
>> >> >         return(newDf)
>> >> >         }
>> >> >
>> >> >
>> >> > x<-apply(missing,1,genRows)
>> >> > comAn=rbind(comAn,
>> >> >         do.call(rbind,x))
>> >> >
>> >> >> comAn
>> >> >    animals animalYears animalMass
>> >> > 1     bird           1         29
>> >> > 2     bird           1         48
>> >> > 3     bird           1         36
>> >> > 4     bird           2         20
>> >> > 5     bird           2         34
>> >> > 6     bird           2         34
>> >> > 7      dog           1         21
>> >> > 8      dog           1         28
>> >> > 9      dog           1         25
>> >> > 10     dog           2         35
>> >> > 11     dog           2         18
>> >> > 12     dog           2         11
>> >> > 13     cat           1         46
>> >> > 14     cat           1         33
>> >> > 15     cat           1         48
>> >> > 16     cat           2         21
>> >> > 17     cat           2       <NA>
>> >> >
>> >> > So far so good, but then I adjust the code so that it reads
>(**notice
>> >> > the
>> >> > change in the specification in 'missing' to counts<3**):
>> >> >
>> >> > #combs defines the different combinations of
>> >> > #animals and animalYears
>> >> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
>> >> > #counts defines how long the different combinations are
>> >> > counts<-ave(1:nrow(comAn),combs,FUN=length)
>> >> > #missing defines the combs that have length less than one and
>puts it
>> in
>> >> > #the data frame missing
>> >> > missing<-data.frame(vals=combs[counts<3],count=counts[counts<3])
>> >> >
>> >> > genRows<-function(dat){
>> >> >         vals<-strsplit(dat[1],':')[[1]]
>> >> >                 #not sure why dat[2] is being converted to a
>string
>> >> >         newRows<-2-as.numeric(dat[2])
>> >> >         newDf<-data.frame(animals=rep(vals[1],newRows),
>> >> >                           animalYears=rep(vals[2],newRows),
>> >> >                           animalMass=rep(NA,newRows))
>> >> >         return(newDf)
>> >> >         }
>> >> >
>> >> >
>> >> > x<-apply(missing,1,genRows)
>> >> > comAn=rbind(comAn,
>> >> >         do.call(rbind,x))
>> >> >
>> >> > The result for 'x' then reads:
>> >> >
>> >> >> x
>> >> > [[1]]
>> >> > [1] animals     animalYears animalMass
>> >> > <0 rows> (or 0-length row.names)
>> >> >
>> >> > Any thoughts on why it might be doing this instead of adding an
>> >> > additional
>> >> > row to get the result:
>> >> >
>> >> >> comAn
>> >> >    animals animalYears animalMass
>> >> > 1     bird           1         29
>> >> > 2     bird           1         48
>> >> > 3     bird           1         36
>> >> > 4     bird           2         20
>> >> > 5     bird           2         34
>> >> > 6     bird           2         34
>> >> > 7      dog           1         21
>> >> > 8      dog           1         28
>> >> > 9      dog           1         25
>> >> > 10     dog           2         35
>> >> > 11     dog           2         18
>> >> > 12     dog           2         11
>> >> > 13     cat           1         46
>> >> > 14     cat           1         33
>> >> > 15     cat           1         48
>> >> > 16     cat           2         21
>> >> > 17     cat           2       <NA>
>> >> > 18     cat           2       <NA>
>> >> >
>> >> > Thanks
>> >> > --
>> >> > Curtis Burkhalter
>> >
>> >
>>


From erinm.hodgess at gmail.com  Tue Mar 10 23:17:18 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 10 Mar 2015 18:17:18 -0400
Subject: [R]  .Rprofile vs. First (more of an opinion question)
Message-ID: <CACxE24m8=LNVr8Bgy++JRH3KmNtX2UmjyJm6+MOeS4Ur+ZubpA@mail.gmail.com>

Hello again

I am using R-3.1.2 on Windows 7.

I am the only one using this particular computer.

My question is probably more of an opinion question.

I want to set a "repos" with the options.  Also, I want to setwd and load a
particular workspace.

Am I better off to put everything into .Rprofile, please?  Or .First?

Or put the options into .Rprofile and everything else into .First, please?

Thanks for any help,
Sincerely,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Mar 10 23:38:20 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 11 Mar 2015 11:38:20 +1300
Subject: [R] .Rprofile vs. First (more of an opinion question)
In-Reply-To: <CACxE24m8=LNVr8Bgy++JRH3KmNtX2UmjyJm6+MOeS4Ur+ZubpA@mail.gmail.com>
References: <CACxE24m8=LNVr8Bgy++JRH3KmNtX2UmjyJm6+MOeS4Ur+ZubpA@mail.gmail.com>
Message-ID: <54FF725C.3060806@auckland.ac.nz>

On 11/03/15 11:17, Erin Hodgess wrote:
> Hello again
>
> I am using R-3.1.2 on Windows 7.
>
> I am the only one using this particular computer.
>
> My question is probably more of an opinion question.
>
> I want to set a "repos" with the options.  Also, I want to setwd and load a
> particular workspace.
>
> Am I better off to put everything into .Rprofile, please?  Or .First?
>
> Or put the options into .Rprofile and everything else into .First, please?
>
> Thanks for any help.

How do you create your .First() function and get it into your workspace?

I may be confused here, but I think that you would need to make sure 
that this is done in each workspace (in each working directory) that you 
use.  It may be the case that you use only a single working directory, 
but it is generally good practice to use a different working directory 
for each separate project that you engage in.

In contrast, putting your settings in .Rprofile causes them to be 
applied in any working directory in which you start R.

I also think that there's more danger of .RData getting lost or 
over-written --- it is getting used all the time, whereas .Rprofile just 
sits there and does its thing once it's been created --- than there is 
of .Rprofile getting lost or over-written.

Consequently my 2 bob's worth is:  Use .Rprofile.

Of course, this is a case of the blind leading the blind.  Caveat lector.

cheers,

Rolf


-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From sarah.goslee at gmail.com  Wed Mar 11 00:57:55 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 10 Mar 2015 19:57:55 -0400
Subject: [R] problem applying the same function twice
In-Reply-To: <CAJmwvUYSZ8akeimhdrS3hZBQJcfEFKUreaKgg93-BscS87euvw@mail.gmail.com>
References: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>
	<CAM_vju=bLmXg99ZrhfdOw9C9bMDJ=evbVKOFtAZvg-ug3NcEeQ@mail.gmail.com>
	<CAJmwvUaSPpO05PtqjGO5GKnrWoHMf2s9A-aAibpVUQdbUXBWBA@mail.gmail.com>
	<CAM_vju=f6CTPbq8XJgx6eNAr_UFSK_Lx0ETgpFG2vdoX3OFOLw@mail.gmail.com>
	<CAJmwvUYfbCT-KaHdEvkDvG-RW_Yx6_421jxgj-zTLzitxazD5w@mail.gmail.com>
	<CAM_vjumrX2cj27QgMCdQ0nWx5uTrq=yrdnnZgghydQr9Fh416A@mail.gmail.com>
	<CAJmwvUYSZ8akeimhdrS3hZBQJcfEFKUreaKgg93-BscS87euvw@mail.gmail.com>
Message-ID: <CAM_vjunXYBwB5zv0ZMqN-Kvuo4FFi+N_QFVuj=7jT3Greswc0g@mail.gmail.com>

I think you're kind of missing the way this works:

the data frame created by expand.grid() should ONLY have site, year,
sample (with the exact names used in the data itself).
Then the merged data frame will have the full site,year,sample
combinations, along with ALL the data variables. Your animal example
only had one measured variable, but the same method will work with any
number.
Reading ?merge might help you understand.

Sarah

On Tue, Mar 10, 2015 at 5:35 PM, Curtis Burkhalter
<curtisburkhalter at gmail.com> wrote:
>
> Thanks Sarah, one of my column names was missing a letter so it was throwing
> things off. It works super fast now and is exactly what I needed. My actual
> data set  has about 6 other ancillary response data data columns, is there a
> way to combine the 'full' data set I just created with the original in case
> I need any of the other response variables. E.g.
>
> FULL:                                          Original:
> Combined:
> site    year     sample                    site    year     sample     color
> shape                  site    year     sample     color     shape
> 1        1         10                           1        1         10
> blue       diamond              1        1         10            blue
> diamond
> 1         1        12                           1         1        12
> green     pyramid               1         1        12            green
> pyramid
> 1         1        NA
> 1         1        NA           NA        NA
>
> Thanks
>
> On Tue, Mar 10, 2015 at 3:12 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> Yeah, that's tiny:
>>
>> > fullout <- expand.grid(site=1:669, year=1:7, sample=1:3)
>> > dim(fullout)
>> [1] 14049     3
>>
>>
>> Almost certainly the problem is that your expand.grid result doesn't
>> have the same column names as your actual data file, so merge() is
>> trying to make an enormous result. Note how when I made outgrid in the
>> example I named the columns.
>>
>> Make sure that the names are identical!
>>
>>
>> On Tue, Mar 10, 2015 at 4:57 PM, Curtis Burkhalter
>> <curtisburkhalter at gmail.com> wrote:
>> > Sarah,
>> >
>> > I have 669 sites and each site has 7 years of data, so if I'm thinking
>> > correctly then there should be 4683 possible combinations of site x
>> > year.
>> > For each year though I need 3 sampling periods so that there is
>> > something
>> > like the following:
>> >
>> > site 1      year1      sample 1
>> > site 1      year1      sample 2
>> > site 1      year1      sample 3
>> > site 2      year1      sample 1
>> > site 2      year1      sample 2
>> > site 2      year1      sample 3.....
>> > site 669   year7      sample 1
>> > site 669   year7     sample 2
>> > site 669   year7     sample 3.
>> >
>> > I have my max memory allocation set to the amount of RAM (8GB) on my
>> > laptop,
>> > but it still 'times out' due to memory problems.
>> >
>> > On Tue, Mar 10, 2015 at 2:50 PM, Sarah Goslee <sarah.goslee at gmail.com>
>> > wrote:
>> >>
>> >> You said your data only had 14000 rows, which really isn't many.
>> >>
>> >> How many possible combinations do you have, and how many do you need to
>> >> add?
>> >>
>> >> On Tue, Mar 10, 2015 at 4:35 PM, Curtis Burkhalter
>> >> <curtisburkhalter at gmail.com> wrote:
>> >> > Sarah,
>> >> >
>> >> > This strategy works great for this small dataset, but when I attempt
>> >> > your
>> >> > method with my data set I reach the maximum allowable memory
>> >> > allocation
>> >> > and
>> >> > the operation just stalls and then stops completely before it is
>> >> > finished.
>> >> > Do you know of a way around this?
>> >> >
>> >> > Thanks
>> >> >
>> >> > On Tue, Mar 10, 2015 at 2:04 PM, Sarah Goslee
>> >> > <sarah.goslee at gmail.com>
>> >> > wrote:
>> >> >>
>> >> >> Hi,
>> >> >>
>> >> >> I didn't work through your code, because it looked overly
>> >> >> complicated.
>> >> >> Here's a more general approach that does what you appear to want:
>> >> >>
>> >> >> # use dput() to provide reproducible data please!
>> >> >> comAn <- structure(list(animals = c("bird", "bird", "bird", "bird",
>> >> >> "bird",
>> >> >> "bird", "dog", "dog", "dog", "dog", "dog", "dog", "cat", "cat",
>> >> >> "cat", "cat"), animalYears = c(1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
>> >> >> 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), animalMass = c(29L, 48L, 36L,
>> >> >> 20L, 34L, 34L, 21L, 28L, 25L, 35L, 18L, 11L, 46L, 33L, 48L, 21L
>> >> >> )), .Names = c("animals", "animalYears", "animalMass"), class =
>> >> >> "data.frame", row.names = c("1",
>> >> >> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
>> >> >> "14", "15", "16"))
>> >> >>
>> >> >>
>> >> >> # add reps to comAn
>> >> >> # assumes comAn is already sorted on animals, animalYears
>> >> >> comAn$reps <- unlist(sapply(rle(do.call("paste",
>> >> >> comAn[,1:2]))$lengths, seq_len))
>> >> >>
>> >> >> # create full set of combinations
>> >> >> outgrid <- expand.grid(animals=unique(comAn$animals),
>> >> >> animalYears=unique(comAn$animalYears), reps=unique(comAn$reps),
>> >> >> stringsAsFactors=FALSE)
>> >> >>
>> >> >> # combine with comAn
>> >> >> comAn.full <- merge(outgrid, comAn, all.x=TRUE)
>> >> >>
>> >> >> > comAn.full
>> >> >>    animals animalYears reps animalMass
>> >> >> 1     bird           1    1         29
>> >> >> 2     bird           1    2         48
>> >> >> 3     bird           1    3         36
>> >> >> 4     bird           2    1         20
>> >> >> 5     bird           2    2         34
>> >> >> 6     bird           2    3         34
>> >> >> 7      cat           1    1         46
>> >> >> 8      cat           1    2         33
>> >> >> 9      cat           1    3         48
>> >> >> 10     cat           2    1         21
>> >> >> 11     cat           2    2         NA
>> >> >> 12     cat           2    3         NA
>> >> >> 13     dog           1    1         21
>> >> >> 14     dog           1    2         28
>> >> >> 15     dog           1    3         25
>> >> >> 16     dog           2    1         35
>> >> >> 17     dog           2    2         18
>> >> >> 18     dog           2    3         11
>> >> >> >
>> >> >>
>> >> >> On Tue, Mar 10, 2015 at 3:43 PM, Curtis Burkhalter
>> >> >> <curtisburkhalter at gmail.com> wrote:
>> >> >> > Hey everyone,
>> >> >> >
>> >> >> > I've written a function that adds NAs to a dataframe where data is
>> >> >> > missing
>> >> >> > and it seems to work great if I only need to run it once, but if I
>> >> >> > run
>> >> >> > it
>> >> >> > two times in a row I run into problems. I've created a workable
>> >> >> > example
>> >> >> > to
>> >> >> > explain what I mean and why I would do this.
>> >> >> >
>> >> >> > In my dataframe there are areas where I need to add two rows of
>> >> >> > NAs
>> >> >> > (b/c
>> >> >> > I
>> >> >> > need to have 3 animal x year combos and for cat in year 2 I only
>> >> >> > have
>> >> >> > one)
>> >> >> > so I thought that I'd just run my code twice using the function in
>> >> >> > the
>> >> >> > code
>> >> >> > below. Everything works great when I run it the first time, but
>> >> >> > when
>> >> >> > I
>> >> >> > run
>> >> >> > it again it says that the value returned to the list 'x' is of
>> >> >> > length
>> >> >> > 0.
>> >> >> > I
>> >> >> > don't understand why the function works the first time around and
>> >> >> > adds
>> >> >> > an
>> >> >> > NA to the 'animalMass' column, but won't do it again. I've used
>> >> >> > (print(str(dataframe)) to see if there is a change in class or
>> >> >> > type
>> >> >> > when
>> >> >> > the function runs through the original dataframe and there is for
>> >> >> > 'animalYears', but I just convert it back before rerunning the
>> >> >> > function
>> >> >> > for
>> >> >> > second time.
>> >> >> >
>> >> >> > Any thoughts on this would be greatly appreciated b/c my actual
>> >> >> > data
>> >> >> > dataframe I have to input into WinBUGS is 14000x12, so it's not a
>> >> >> > trivial
>> >> >> > thing to just add in an NA here or there.
>> >> >> >
>> >> >> >>comAn
>> >> >> >    animals animalYears animalMass
>> >> >> > 1     bird           1         29
>> >> >> > 2     bird           1         48
>> >> >> > 3     bird           1         36
>> >> >> > 4     bird           2         20
>> >> >> > 5     bird           2         34
>> >> >> > 6     bird           2         34
>> >> >> > 7      dog           1         21
>> >> >> > 8      dog           1         28
>> >> >> > 9      dog           1         25
>> >> >> > 10     dog           2         35
>> >> >> > 11     dog           2         18
>> >> >> > 12     dog           2         11
>> >> >> > 13     cat           1         46
>> >> >> > 14     cat           1         33
>> >> >> > 15     cat           1         48
>> >> >> > 16     cat           2         21
>> >> >> >
>> >> >> > So every animal has 3 measurements per year, except for the cat in
>> >> >> > year
>> >> >> > two
>> >> >> > which has only 1. I run the code below and get:
>> >> >> >
>> >> >> > #combs defines the different combinations of
>> >> >> > #animals and animalYears
>> >> >> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
>> >> >> > #counts defines how long the different combinations are
>> >> >> > counts<-ave(1:nrow(comAn),combs,FUN=length)
>> >> >> > #missing defines the combs that have length less than one and puts
>> >> >> > it
>> >> >> > in
>> >> >> > #the data frame missing
>> >> >> > missing<-data.frame(vals=combs[counts<2],count=counts[counts<2])
>> >> >> >
>> >> >> > genRows<-function(dat){
>> >> >> >         vals<-strsplit(dat[1],':')[[1]]
>> >> >> >                 #not sure why dat[2] is being converted to a
>> >> >> > string
>> >> >> >         newRows<-2-as.numeric(dat[2])
>> >> >> >         newDf<-data.frame(animals=rep(vals[1],newRows),
>> >> >> >                           animalYears=rep(vals[2],newRows),
>> >> >> >                           animalMass=rep(NA,newRows))
>> >> >> >         return(newDf)
>> >> >> >         }
>> >> >> >
>> >> >> >
>> >> >> > x<-apply(missing,1,genRows)
>> >> >> > comAn=rbind(comAn,
>> >> >> >         do.call(rbind,x))
>> >> >> >
>> >> >> >> comAn
>> >> >> >    animals animalYears animalMass
>> >> >> > 1     bird           1         29
>> >> >> > 2     bird           1         48
>> >> >> > 3     bird           1         36
>> >> >> > 4     bird           2         20
>> >> >> > 5     bird           2         34
>> >> >> > 6     bird           2         34
>> >> >> > 7      dog           1         21
>> >> >> > 8      dog           1         28
>> >> >> > 9      dog           1         25
>> >> >> > 10     dog           2         35
>> >> >> > 11     dog           2         18
>> >> >> > 12     dog           2         11
>> >> >> > 13     cat           1         46
>> >> >> > 14     cat           1         33
>> >> >> > 15     cat           1         48
>> >> >> > 16     cat           2         21
>> >> >> > 17     cat           2       <NA>
>> >> >> >
>> >> >> > So far so good, but then I adjust the code so that it reads
>> >> >> > (**notice
>> >> >> > the
>> >> >> > change in the specification in 'missing' to counts<3**):
>> >> >> >
>> >> >> > #combs defines the different combinations of
>> >> >> > #animals and animalYears
>> >> >> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
>> >> >> > #counts defines how long the different combinations are
>> >> >> > counts<-ave(1:nrow(comAn),combs,FUN=length)
>> >> >> > #missing defines the combs that have length less than one and puts
>> >> >> > it
>> >> >> > in
>> >> >> > #the data frame missing
>> >> >> > missing<-data.frame(vals=combs[counts<3],count=counts[counts<3])
>> >> >> >
>> >> >> > genRows<-function(dat){
>> >> >> >         vals<-strsplit(dat[1],':')[[1]]
>> >> >> >                 #not sure why dat[2] is being converted to a
>> >> >> > string
>> >> >> >         newRows<-2-as.numeric(dat[2])
>> >> >> >         newDf<-data.frame(animals=rep(vals[1],newRows),
>> >> >> >                           animalYears=rep(vals[2],newRows),
>> >> >> >                           animalMass=rep(NA,newRows))
>> >> >> >         return(newDf)
>> >> >> >         }
>> >> >> >
>> >> >> >
>> >> >> > x<-apply(missing,1,genRows)
>> >> >> > comAn=rbind(comAn,
>> >> >> >         do.call(rbind,x))
>> >> >> >
>> >> >> > The result for 'x' then reads:
>> >> >> >
>> >> >> >> x
>> >> >> > [[1]]
>> >> >> > [1] animals     animalYears animalMass
>> >> >> > <0 rows> (or 0-length row.names)
>> >> >> >
>> >> >> > Any thoughts on why it might be doing this instead of adding an
>> >> >> > additional
>> >> >> > row to get the result:
>> >> >> >
>> >> >> >> comAn
>> >> >> >    animals animalYears animalMass
>> >> >> > 1     bird           1         29
>> >> >> > 2     bird           1         48
>> >> >> > 3     bird           1         36
>> >> >> > 4     bird           2         20
>> >> >> > 5     bird           2         34
>> >> >> > 6     bird           2         34
>> >> >> > 7      dog           1         21
>> >> >> > 8      dog           1         28
>> >> >> > 9      dog           1         25
>> >> >> > 10     dog           2         35
>> >> >> > 11     dog           2         18
>> >> >> > 12     dog           2         11
>> >> >> > 13     cat           1         46
>> >> >> > 14     cat           1         33
>> >> >> > 15     cat           1         48
>> >> >> > 16     cat           2         21
>> >> >> > 17     cat           2       <NA>
>> >> >> > 18     cat           2       <NA>
>> >> >> >
>> >> >> > Thanks
>> >> >> > --
>> >> >> > Curtis Burkhalter
>> >> >
>> >> >


From curtisburkhalter at gmail.com  Wed Mar 11 01:46:35 2015
From: curtisburkhalter at gmail.com (Curtis Burkhalter)
Date: Tue, 10 Mar 2015 18:46:35 -0600
Subject: [R] problem applying the same function twice
In-Reply-To: <CAM_vjunXYBwB5zv0ZMqN-Kvuo4FFi+N_QFVuj=7jT3Greswc0g@mail.gmail.com>
References: <CAJmwvUZqUZUPezsJycfx37osBQdYzcZZFdTipTUQyAvWcyxezw@mail.gmail.com>
	<CAM_vju=bLmXg99ZrhfdOw9C9bMDJ=evbVKOFtAZvg-ug3NcEeQ@mail.gmail.com>
	<CAJmwvUaSPpO05PtqjGO5GKnrWoHMf2s9A-aAibpVUQdbUXBWBA@mail.gmail.com>
	<CAM_vju=f6CTPbq8XJgx6eNAr_UFSK_Lx0ETgpFG2vdoX3OFOLw@mail.gmail.com>
	<CAJmwvUYfbCT-KaHdEvkDvG-RW_Yx6_421jxgj-zTLzitxazD5w@mail.gmail.com>
	<CAM_vjumrX2cj27QgMCdQ0nWx5uTrq=yrdnnZgghydQr9Fh416A@mail.gmail.com>
	<CAJmwvUYSZ8akeimhdrS3hZBQJcfEFKUreaKgg93-BscS87euvw@mail.gmail.com>
	<CAM_vjunXYBwB5zv0ZMqN-Kvuo4FFi+N_QFVuj=7jT3Greswc0g@mail.gmail.com>
Message-ID: <CAJmwvUamHMGyixoPnQAcxa_o-d8tAHATMBX7f-V=NPwm1UbuTw@mail.gmail.com>

Sarah,

I realized what I was saying after I pressed send on the email. It makes
perfect sense now, thanks so much for your help and patience.
On Mar 10, 2015 5:57 PM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:

> I think you're kind of missing the way this works:
>
> the data frame created by expand.grid() should ONLY have site, year,
> sample (with the exact names used in the data itself).
> Then the merged data frame will have the full site,year,sample
> combinations, along with ALL the data variables. Your animal example
> only had one measured variable, but the same method will work with any
> number.
> Reading ?merge might help you understand.
>
> Sarah
>
> On Tue, Mar 10, 2015 at 5:35 PM, Curtis Burkhalter
> <curtisburkhalter at gmail.com> wrote:
> >
> > Thanks Sarah, one of my column names was missing a letter so it was
> throwing
> > things off. It works super fast now and is exactly what I needed. My
> actual
> > data set  has about 6 other ancillary response data data columns, is
> there a
> > way to combine the 'full' data set I just created with the original in
> case
> > I need any of the other response variables. E.g.
> >
> > FULL:                                          Original:
> > Combined:
> > site    year     sample                    site    year     sample
>  color
> > shape                  site    year     sample     color     shape
> > 1        1         10                           1        1         10
> > blue       diamond              1        1         10            blue
> > diamond
> > 1         1        12                           1         1        12
> > green     pyramid               1         1        12            green
> > pyramid
> > 1         1        NA
> > 1         1        NA           NA        NA
> >
> > Thanks
> >
> > On Tue, Mar 10, 2015 at 3:12 PM, Sarah Goslee <sarah.goslee at gmail.com>
> > wrote:
> >>
> >> Yeah, that's tiny:
> >>
> >> > fullout <- expand.grid(site=1:669, year=1:7, sample=1:3)
> >> > dim(fullout)
> >> [1] 14049     3
> >>
> >>
> >> Almost certainly the problem is that your expand.grid result doesn't
> >> have the same column names as your actual data file, so merge() is
> >> trying to make an enormous result. Note how when I made outgrid in the
> >> example I named the columns.
> >>
> >> Make sure that the names are identical!
> >>
> >>
> >> On Tue, Mar 10, 2015 at 4:57 PM, Curtis Burkhalter
> >> <curtisburkhalter at gmail.com> wrote:
> >> > Sarah,
> >> >
> >> > I have 669 sites and each site has 7 years of data, so if I'm thinking
> >> > correctly then there should be 4683 possible combinations of site x
> >> > year.
> >> > For each year though I need 3 sampling periods so that there is
> >> > something
> >> > like the following:
> >> >
> >> > site 1      year1      sample 1
> >> > site 1      year1      sample 2
> >> > site 1      year1      sample 3
> >> > site 2      year1      sample 1
> >> > site 2      year1      sample 2
> >> > site 2      year1      sample 3.....
> >> > site 669   year7      sample 1
> >> > site 669   year7     sample 2
> >> > site 669   year7     sample 3.
> >> >
> >> > I have my max memory allocation set to the amount of RAM (8GB) on my
> >> > laptop,
> >> > but it still 'times out' due to memory problems.
> >> >
> >> > On Tue, Mar 10, 2015 at 2:50 PM, Sarah Goslee <sarah.goslee at gmail.com
> >
> >> > wrote:
> >> >>
> >> >> You said your data only had 14000 rows, which really isn't many.
> >> >>
> >> >> How many possible combinations do you have, and how many do you need
> to
> >> >> add?
> >> >>
> >> >> On Tue, Mar 10, 2015 at 4:35 PM, Curtis Burkhalter
> >> >> <curtisburkhalter at gmail.com> wrote:
> >> >> > Sarah,
> >> >> >
> >> >> > This strategy works great for this small dataset, but when I
> attempt
> >> >> > your
> >> >> > method with my data set I reach the maximum allowable memory
> >> >> > allocation
> >> >> > and
> >> >> > the operation just stalls and then stops completely before it is
> >> >> > finished.
> >> >> > Do you know of a way around this?
> >> >> >
> >> >> > Thanks
> >> >> >
> >> >> > On Tue, Mar 10, 2015 at 2:04 PM, Sarah Goslee
> >> >> > <sarah.goslee at gmail.com>
> >> >> > wrote:
> >> >> >>
> >> >> >> Hi,
> >> >> >>
> >> >> >> I didn't work through your code, because it looked overly
> >> >> >> complicated.
> >> >> >> Here's a more general approach that does what you appear to want:
> >> >> >>
> >> >> >> # use dput() to provide reproducible data please!
> >> >> >> comAn <- structure(list(animals = c("bird", "bird", "bird",
> "bird",
> >> >> >> "bird",
> >> >> >> "bird", "dog", "dog", "dog", "dog", "dog", "dog", "cat", "cat",
> >> >> >> "cat", "cat"), animalYears = c(1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
> >> >> >> 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L), animalMass = c(29L, 48L, 36L,
> >> >> >> 20L, 34L, 34L, 21L, 28L, 25L, 35L, 18L, 11L, 46L, 33L, 48L, 21L
> >> >> >> )), .Names = c("animals", "animalYears", "animalMass"), class =
> >> >> >> "data.frame", row.names = c("1",
> >> >> >> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
> >> >> >> "14", "15", "16"))
> >> >> >>
> >> >> >>
> >> >> >> # add reps to comAn
> >> >> >> # assumes comAn is already sorted on animals, animalYears
> >> >> >> comAn$reps <- unlist(sapply(rle(do.call("paste",
> >> >> >> comAn[,1:2]))$lengths, seq_len))
> >> >> >>
> >> >> >> # create full set of combinations
> >> >> >> outgrid <- expand.grid(animals=unique(comAn$animals),
> >> >> >> animalYears=unique(comAn$animalYears), reps=unique(comAn$reps),
> >> >> >> stringsAsFactors=FALSE)
> >> >> >>
> >> >> >> # combine with comAn
> >> >> >> comAn.full <- merge(outgrid, comAn, all.x=TRUE)
> >> >> >>
> >> >> >> > comAn.full
> >> >> >>    animals animalYears reps animalMass
> >> >> >> 1     bird           1    1         29
> >> >> >> 2     bird           1    2         48
> >> >> >> 3     bird           1    3         36
> >> >> >> 4     bird           2    1         20
> >> >> >> 5     bird           2    2         34
> >> >> >> 6     bird           2    3         34
> >> >> >> 7      cat           1    1         46
> >> >> >> 8      cat           1    2         33
> >> >> >> 9      cat           1    3         48
> >> >> >> 10     cat           2    1         21
> >> >> >> 11     cat           2    2         NA
> >> >> >> 12     cat           2    3         NA
> >> >> >> 13     dog           1    1         21
> >> >> >> 14     dog           1    2         28
> >> >> >> 15     dog           1    3         25
> >> >> >> 16     dog           2    1         35
> >> >> >> 17     dog           2    2         18
> >> >> >> 18     dog           2    3         11
> >> >> >> >
> >> >> >>
> >> >> >> On Tue, Mar 10, 2015 at 3:43 PM, Curtis Burkhalter
> >> >> >> <curtisburkhalter at gmail.com> wrote:
> >> >> >> > Hey everyone,
> >> >> >> >
> >> >> >> > I've written a function that adds NAs to a dataframe where data
> is
> >> >> >> > missing
> >> >> >> > and it seems to work great if I only need to run it once, but
> if I
> >> >> >> > run
> >> >> >> > it
> >> >> >> > two times in a row I run into problems. I've created a workable
> >> >> >> > example
> >> >> >> > to
> >> >> >> > explain what I mean and why I would do this.
> >> >> >> >
> >> >> >> > In my dataframe there are areas where I need to add two rows of
> >> >> >> > NAs
> >> >> >> > (b/c
> >> >> >> > I
> >> >> >> > need to have 3 animal x year combos and for cat in year 2 I only
> >> >> >> > have
> >> >> >> > one)
> >> >> >> > so I thought that I'd just run my code twice using the function
> in
> >> >> >> > the
> >> >> >> > code
> >> >> >> > below. Everything works great when I run it the first time, but
> >> >> >> > when
> >> >> >> > I
> >> >> >> > run
> >> >> >> > it again it says that the value returned to the list 'x' is of
> >> >> >> > length
> >> >> >> > 0.
> >> >> >> > I
> >> >> >> > don't understand why the function works the first time around
> and
> >> >> >> > adds
> >> >> >> > an
> >> >> >> > NA to the 'animalMass' column, but won't do it again. I've used
> >> >> >> > (print(str(dataframe)) to see if there is a change in class or
> >> >> >> > type
> >> >> >> > when
> >> >> >> > the function runs through the original dataframe and there is
> for
> >> >> >> > 'animalYears', but I just convert it back before rerunning the
> >> >> >> > function
> >> >> >> > for
> >> >> >> > second time.
> >> >> >> >
> >> >> >> > Any thoughts on this would be greatly appreciated b/c my actual
> >> >> >> > data
> >> >> >> > dataframe I have to input into WinBUGS is 14000x12, so it's not
> a
> >> >> >> > trivial
> >> >> >> > thing to just add in an NA here or there.
> >> >> >> >
> >> >> >> >>comAn
> >> >> >> >    animals animalYears animalMass
> >> >> >> > 1     bird           1         29
> >> >> >> > 2     bird           1         48
> >> >> >> > 3     bird           1         36
> >> >> >> > 4     bird           2         20
> >> >> >> > 5     bird           2         34
> >> >> >> > 6     bird           2         34
> >> >> >> > 7      dog           1         21
> >> >> >> > 8      dog           1         28
> >> >> >> > 9      dog           1         25
> >> >> >> > 10     dog           2         35
> >> >> >> > 11     dog           2         18
> >> >> >> > 12     dog           2         11
> >> >> >> > 13     cat           1         46
> >> >> >> > 14     cat           1         33
> >> >> >> > 15     cat           1         48
> >> >> >> > 16     cat           2         21
> >> >> >> >
> >> >> >> > So every animal has 3 measurements per year, except for the cat
> in
> >> >> >> > year
> >> >> >> > two
> >> >> >> > which has only 1. I run the code below and get:
> >> >> >> >
> >> >> >> > #combs defines the different combinations of
> >> >> >> > #animals and animalYears
> >> >> >> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
> >> >> >> > #counts defines how long the different combinations are
> >> >> >> > counts<-ave(1:nrow(comAn),combs,FUN=length)
> >> >> >> > #missing defines the combs that have length less than one and
> puts
> >> >> >> > it
> >> >> >> > in
> >> >> >> > #the data frame missing
> >> >> >> > missing<-data.frame(vals=combs[counts<2],count=counts[counts<2])
> >> >> >> >
> >> >> >> > genRows<-function(dat){
> >> >> >> >         vals<-strsplit(dat[1],':')[[1]]
> >> >> >> >                 #not sure why dat[2] is being converted to a
> >> >> >> > string
> >> >> >> >         newRows<-2-as.numeric(dat[2])
> >> >> >> >         newDf<-data.frame(animals=rep(vals[1],newRows),
> >> >> >> >                           animalYears=rep(vals[2],newRows),
> >> >> >> >                           animalMass=rep(NA,newRows))
> >> >> >> >         return(newDf)
> >> >> >> >         }
> >> >> >> >
> >> >> >> >
> >> >> >> > x<-apply(missing,1,genRows)
> >> >> >> > comAn=rbind(comAn,
> >> >> >> >         do.call(rbind,x))
> >> >> >> >
> >> >> >> >> comAn
> >> >> >> >    animals animalYears animalMass
> >> >> >> > 1     bird           1         29
> >> >> >> > 2     bird           1         48
> >> >> >> > 3     bird           1         36
> >> >> >> > 4     bird           2         20
> >> >> >> > 5     bird           2         34
> >> >> >> > 6     bird           2         34
> >> >> >> > 7      dog           1         21
> >> >> >> > 8      dog           1         28
> >> >> >> > 9      dog           1         25
> >> >> >> > 10     dog           2         35
> >> >> >> > 11     dog           2         18
> >> >> >> > 12     dog           2         11
> >> >> >> > 13     cat           1         46
> >> >> >> > 14     cat           1         33
> >> >> >> > 15     cat           1         48
> >> >> >> > 16     cat           2         21
> >> >> >> > 17     cat           2       <NA>
> >> >> >> >
> >> >> >> > So far so good, but then I adjust the code so that it reads
> >> >> >> > (**notice
> >> >> >> > the
> >> >> >> > change in the specification in 'missing' to counts<3**):
> >> >> >> >
> >> >> >> > #combs defines the different combinations of
> >> >> >> > #animals and animalYears
> >> >> >> > combs<-paste(comAn$animals,comAn$animalYears,sep=':')
> >> >> >> > #counts defines how long the different combinations are
> >> >> >> > counts<-ave(1:nrow(comAn),combs,FUN=length)
> >> >> >> > #missing defines the combs that have length less than one and
> puts
> >> >> >> > it
> >> >> >> > in
> >> >> >> > #the data frame missing
> >> >> >> > missing<-data.frame(vals=combs[counts<3],count=counts[counts<3])
> >> >> >> >
> >> >> >> > genRows<-function(dat){
> >> >> >> >         vals<-strsplit(dat[1],':')[[1]]
> >> >> >> >                 #not sure why dat[2] is being converted to a
> >> >> >> > string
> >> >> >> >         newRows<-2-as.numeric(dat[2])
> >> >> >> >         newDf<-data.frame(animals=rep(vals[1],newRows),
> >> >> >> >                           animalYears=rep(vals[2],newRows),
> >> >> >> >                           animalMass=rep(NA,newRows))
> >> >> >> >         return(newDf)
> >> >> >> >         }
> >> >> >> >
> >> >> >> >
> >> >> >> > x<-apply(missing,1,genRows)
> >> >> >> > comAn=rbind(comAn,
> >> >> >> >         do.call(rbind,x))
> >> >> >> >
> >> >> >> > The result for 'x' then reads:
> >> >> >> >
> >> >> >> >> x
> >> >> >> > [[1]]
> >> >> >> > [1] animals     animalYears animalMass
> >> >> >> > <0 rows> (or 0-length row.names)
> >> >> >> >
> >> >> >> > Any thoughts on why it might be doing this instead of adding an
> >> >> >> > additional
> >> >> >> > row to get the result:
> >> >> >> >
> >> >> >> >> comAn
> >> >> >> >    animals animalYears animalMass
> >> >> >> > 1     bird           1         29
> >> >> >> > 2     bird           1         48
> >> >> >> > 3     bird           1         36
> >> >> >> > 4     bird           2         20
> >> >> >> > 5     bird           2         34
> >> >> >> > 6     bird           2         34
> >> >> >> > 7      dog           1         21
> >> >> >> > 8      dog           1         28
> >> >> >> > 9      dog           1         25
> >> >> >> > 10     dog           2         35
> >> >> >> > 11     dog           2         18
> >> >> >> > 12     dog           2         11
> >> >> >> > 13     cat           1         46
> >> >> >> > 14     cat           1         33
> >> >> >> > 15     cat           1         48
> >> >> >> > 16     cat           2         21
> >> >> >> > 17     cat           2       <NA>
> >> >> >> > 18     cat           2       <NA>
> >> >> >> >
> >> >> >> > Thanks
> >> >> >> > --
> >> >> >> > Curtis Burkhalter
> >> >> >
> >> >> >
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Mar 11 01:51:15 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 10 Mar 2015 17:51:15 -0700
Subject: [R] .Rprofile vs. First (more of an opinion question)
In-Reply-To: <54FF725C.3060806@auckland.ac.nz>
References: <CACxE24m8=LNVr8Bgy++JRH3KmNtX2UmjyJm6+MOeS4Ur+ZubpA@mail.gmail.com>
	<54FF725C.3060806@auckland.ac.nz>
Message-ID: <E5A53229-B271-42D9-BEAB-73142B2F62F4@dcn.davis.CA.us>

I concur with Rolf.

.RData files (the ones with nothing before the period) are just traps for your future self, with no documentation. I avoid them like the plague. I refer to specifically-named Something.RData files in my .R/.Rnw/.Rmd files to cache results of long computations, but they are optional in my workflow because I always have R code that can regenerate them.

.Rprofile files offer consistency of behavior  regardless of which working directory you use, and you can comment them.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 10, 2015 3:38:20 PM PDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>On 11/03/15 11:17, Erin Hodgess wrote:
>> Hello again
>>
>> I am using R-3.1.2 on Windows 7.
>>
>> I am the only one using this particular computer.
>>
>> My question is probably more of an opinion question.
>>
>> I want to set a "repos" with the options.  Also, I want to setwd and
>load a
>> particular workspace.
>>
>> Am I better off to put everything into .Rprofile, please?  Or .First?
>>
>> Or put the options into .Rprofile and everything else into .First,
>please?
>>
>> Thanks for any help.
>
>How do you create your .First() function and get it into your
>workspace?
>
>I may be confused here, but I think that you would need to make sure 
>that this is done in each workspace (in each working directory) that
>you 
>use.  It may be the case that you use only a single working directory, 
>but it is generally good practice to use a different working directory 
>for each separate project that you engage in.
>
>In contrast, putting your settings in .Rprofile causes them to be 
>applied in any working directory in which you start R.
>
>I also think that there's more danger of .RData getting lost or 
>over-written --- it is getting used all the time, whereas .Rprofile
>just 
>sits there and does its thing once it's been created --- than there is 
>of .Rprofile getting lost or over-written.
>
>Consequently my 2 bob's worth is:  Use .Rprofile.
>
>Of course, this is a case of the blind leading the blind.  Caveat
>lector.
>
>cheers,
>
>Rolf


From yixuan.qiu at cos.name  Wed Mar 11 04:56:49 2015
From: yixuan.qiu at cos.name (Yixuan Qiu)
Date: Tue, 10 Mar 2015 23:56:49 -0400
Subject: [R] svg2swf - controlling the looping of flash files
In-Reply-To: <001001d05b4c$96fd7720$c4f86560$@gmail.com>
References: <00f101d05ab9$110abb70$33203250$@gmail.com>
	<CAFr_7yH4wzBzm1oA6V=cEp-GVYsqVntAFSRPkgu+0KzorXR0sw@mail.gmail.com>
	<001001d05b4c$96fd7720$c4f86560$@gmail.com>
Message-ID: <CAFr_7yHaOrULpg3Hghcj+xd5OXATb8UK=EziysyFiiPyBdNX6Q@mail.gmail.com>

Hi Paul,
One workaround for this problem is to manually edit the HTML that
contains the Flash animation, by adding a "loop" parameter in the
<embed> tag:

<embed width="480" height="480" name="plugin" loop="false" src="a.swf"
type="application/x-shockwave-flash">


This works for Firefox at least.



Best,
Yixuan

2015-03-10 12:09 GMT-04:00 Paul Sweeting <paul.j.sweeting at gmail.com>:
> Hi Yixuan
>
>
>
> Thanks for your reply. I think it would be useful to have the option of a
> ?loop = FALSE? option in this function.  However, I?m not sure how long a
> shelf life swf files will have, given everything seems to be moving away
> from flash?
>
>
>
> Paul
>
>
>
> From: Yixuan Qiu [mailto:yixuan.qiu at cos.name]
> Sent: 10 March 2015 00:20
> To: Paul Sweeting
> Cc: r-help
> Subject: Re: [R] svg2swf - controlling the looping of flash files
>
>
>
> Hello Paul,
>
> So far there is no way to stop the animation after its first run. If this
> feature is needed I could try to implement it in the future version of
> R2SWF.
>
> Best,
>
> Yixuan
>
>
>
> 2015-03-09 18:33 GMT-04:00 Paul Sweeting <paul.j.sweeting at gmail.com>:
>
> Hi
>
>
>
> I'm using svg2swf to collate a number of svg outputs into an swf file.  I've
> got this working (mainly.) except that I can't control the looping behaviour
> of the swf file.  In other words, when it's loaded into html it loops
> continuously.  Is there any way to stop the animation looping, so it just
> plays through once when loaded?  The code I use is (broadly):
>
>
>
>                svg("testplot%d.svg",onefile = FALSE)
>
>                for(j in 1:360){
>
>                               print(cloud(x~y*z, groups=tail,
> data=norm_dots_chart, screen=list(z=0,x=0,y=j)))
>
>                }
>
>                dev.off()
>
>                output = svg2swf(sprintf("testplot%d.svg", 1:360), interval =
> 0.04)
>
>                swf2html(output)
>
>
>
> Thank you!
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
>
> Yixuan Qiu <yixuan.qiu at cos.name>
> Department of Statistics,
> Purdue University



-- 
Yixuan Qiu <yixuan.qiu at cos.name>
Department of Statistics,
Purdue University


From archstevej at gmail.com  Tue Mar 10 23:53:24 2015
From: archstevej at gmail.com (Steven Archambault)
Date: Tue, 10 Mar 2015 16:53:24 -0600
Subject: [R] Panel Data--filling in missing dates in a span only
Message-ID: <620B964B-7204-4B9E-9290-1B36191B24F5@gmail.com>

Hi folks,

I have this panel data (below), with observations missing in each of the panels. I want to fill in years for the missing data, but only those years within the span of the existing data. For instance, BC-0002 needs on year, 1995. I do not want any years after the last observation.

structure(list(ID = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label = c("BC-0002", 
"BC-0003", "BC-0004"), class = "factor"), Date = c(1989L, 1990L, 
1991L, 1992L, 1993L, 1994L, 1996L, 1989L, 1990L, 1991L, 1992L, 
1993L, 1994L, 1996L, 1995L, 1996L, 1997L, 1998L, 2000L, 1994L, 
1993L, 1999L, 1998L), DepthtoWater_bgs = c(317.85, 317.25, 321.25, 
312.31, 313.01, 330.41, 321.01, 166.58, 167.55, 168.65, 168.95, 
169.25, 168.85, 169.75, 260.6, 261.65, 262.15, 265.45, 266.15, 
265.25, 265.05, 266.95, 267.75)), .Names = c("ID", "Date", "DepthtoWater_bgs"
), class = "data.frame", row.names = c(NA, -23L))


I have been using this code to expand the entire panels, but it is not what exactly what I want.

fexp <- expand.grid(ID=unique(wells$ID), Date=unique(wells$Date))
merge(fexp, wells, all=TRUE) 

Any help would be much appreciated!

Thanks,
Steve

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Wed Mar 11 08:01:06 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Wed, 11 Mar 2015 09:01:06 +0200
Subject: [R] Comparing each component of vector to each component of a
	Matrix.
Message-ID: <CAGh51gQ0ap3pn4Jr+K6C8+=nGRRquCXKwWwurieVg6VVLVwFCg@mail.gmail.com>

Hi All,

I need a help on a loop which can compare the each component of vector to
each component of a Matrix.

Let a vector b = {b1, b2, ...,bn} and 2x2  matrix A = Aij.

I need to compare each component of the vector with each component of a
matrix and print 1 if the component is less or equal to one and print 0
otherwise.

bi <= Aij, print 1 and 0 otherwise.

Any help is appreciated.

Regards,
Frederic.


Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From sven.templer at gmail.com  Wed Mar 11 08:26:40 2015
From: sven.templer at gmail.com (Sven E. Templer)
Date: Wed, 11 Mar 2015 08:26:40 +0100
Subject: [R] Comparing each component of vector to each component of a
	Matrix.
In-Reply-To: <CAGh51gQ0ap3pn4Jr+K6C8+=nGRRquCXKwWwurieVg6VVLVwFCg@mail.gmail.com>
References: <CAGh51gQ0ap3pn4Jr+K6C8+=nGRRquCXKwWwurieVg6VVLVwFCg@mail.gmail.com>
Message-ID: <CAHuTOvraJamQOWL_CE=jQJe+GFEEzoi9kcvKD-xUxrkjjO8j-g@mail.gmail.com>

Hi,

you didn't specify values in A, and you first wanted to compare bi
with Aij, but then also which bi is less/equal to zero.

For the first case, with

A <- matrix(0:3,2)
b <- seq(-1,5)

and a comparison function for bi less/equal to Aij like

f <- function (bi) {as.integer(bi<=A)}

you can iterate along b with

lapply(b, f) # contains results as matrices in a list, each with same
dimensions as A
sapply(b, f) # aligns results to an length(A)*length(b) matrix


Best,
S.



On 11 March 2015 at 08:01, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
> Hi All,
>
> I need a help on a loop which can compare the each component of vector to
> each component of a Matrix.
>
> Let a vector b = {b1, b2, ...,bn} and 2x2  matrix A = Aij.
>
> I need to compare each component of the vector with each component of a
> matrix and print 1 if the component is less or equal to one and print 0
> otherwise.
>
> bi <= Aij, print 1 and 0 otherwise.
>
> Any help is appreciated.
>
> Regards,
> Frederic.
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sorenh at math.aau.dk  Wed Mar 11 09:36:48 2015
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Wed, 11 Mar 2015 08:36:48 +0000
Subject: [R] Checking whether specific packages (from bioconductor) are
 installed when loading a package
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C3A172B5E0@AD-EXCHMBX2-1.aau.dk>

Dear all,

My package 'gRbase' uses three packages from Bioconductor and these are not automatically installed when gRbase is installed. My instructions (on the package webpage) to users are therefore to run:

source("http://bioconductor.org/biocLite.R"); biocLite(c("graph","RBGL","Rgraphviz"))

When loading gRbase, it is checked whether these Bioconductor packages are available, but I would like to add a message about how to install the packages if they are not.

Does this go into .onAttach or .onLoad or elsewhere?

Thanks in advance
S?ren


From drjimlemon at gmail.com  Wed Mar 11 09:37:10 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 11 Mar 2015 19:37:10 +1100
Subject: [R] .Rprofile vs. First (more of an opinion question)
In-Reply-To: <E5A53229-B271-42D9-BEAB-73142B2F62F4@dcn.davis.CA.us>
References: <CACxE24m8=LNVr8Bgy++JRH3KmNtX2UmjyJm6+MOeS4Ur+ZubpA@mail.gmail.com>
	<54FF725C.3060806@auckland.ac.nz>
	<E5A53229-B271-42D9-BEAB-73142B2F62F4@dcn.davis.CA.us>
Message-ID: <CA+8X3fXvV+VPs_pbAmpC+Hu+oO6Bj9jwk5M3cH76zZKXemJwbA@mail.gmail.com>

Hi Erin,
If you want to use .First, just put it in the directory where you start up
your R session, use it to change all the options that you want for all
projects, then source a file to switch to the directory that you want. I
call mine "SelectAnalysis.R" and it just displays a list of current
projects from which I select one with a letter key.

Jim


On Wed, Mar 11, 2015 at 11:51 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I concur with Rolf.
>
> .RData files (the ones with nothing before the period) are just traps for
> your future self, with no documentation. I avoid them like the plague. I
> refer to specifically-named Something.RData files in my .R/.Rnw/.Rmd files
> to cache results of long computations, but they are optional in my workflow
> because I always have R code that can regenerate them.
>
> .Rprofile files offer consistency of behavior  regardless of which working
> directory you use, and you can comment them.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On March 10, 2015 3:38:20 PM PDT, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> >On 11/03/15 11:17, Erin Hodgess wrote:
> >> Hello again
> >>
> >> I am using R-3.1.2 on Windows 7.
> >>
> >> I am the only one using this particular computer.
> >>
> >> My question is probably more of an opinion question.
> >>
> >> I want to set a "repos" with the options.  Also, I want to setwd and
> >load a
> >> particular workspace.
> >>
> >> Am I better off to put everything into .Rprofile, please?  Or .First?
> >>
> >> Or put the options into .Rprofile and everything else into .First,
> >please?
> >>
> >> Thanks for any help.
> >
> >How do you create your .First() function and get it into your
> >workspace?
> >
> >I may be confused here, but I think that you would need to make sure
> >that this is done in each workspace (in each working directory) that
> >you
> >use.  It may be the case that you use only a single working directory,
> >but it is generally good practice to use a different working directory
> >for each separate project that you engage in.
> >
> >In contrast, putting your settings in .Rprofile causes them to be
> >applied in any working directory in which you start R.
> >
> >I also think that there's more danger of .RData getting lost or
> >over-written --- it is getting used all the time, whereas .Rprofile
> >just
> >sits there and does its thing once it's been created --- than there is
> >of .Rprofile getting lost or over-written.
> >
> >Consequently my 2 bob's worth is:  Use .Rprofile.
> >
> >Of course, this is a case of the blind leading the blind.  Caveat
> >lector.
> >
> >cheers,
> >
> >Rolf
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Mar 11 10:46:42 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 11 Mar 2015 22:46:42 +1300
Subject: [R] Comparing each component of vector to each component of a
 Matrix.
In-Reply-To: <CAGh51gQ0ap3pn4Jr+K6C8+=nGRRquCXKwWwurieVg6VVLVwFCg@mail.gmail.com>
References: <CAGh51gQ0ap3pn4Jr+K6C8+=nGRRquCXKwWwurieVg6VVLVwFCg@mail.gmail.com>
Message-ID: <55000F02.2020803@auckland.ac.nz>

On 11/03/15 20:01, Frederic Ntirenganya wrote:
> Hi All,
>
> I need a help on a loop which can compare the each component of vector to
> each component of a Matrix.
>
> Let a vector b = {b1, b2, ...,bn} and 2x2  matrix A = Aij.
>
> I need to compare each component of the vector with each component of a
> matrix and print 1 if the component is less or equal to one and print 0
> otherwise.
>
> bi <= Aij, print 1 and 0 otherwise.
>
> Any help is appreciated.

outer(b,A,"<=")+0

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From rni.boh at gmail.com  Wed Mar 11 11:31:30 2015
From: rni.boh at gmail.com (Bob O'Hara)
Date: Wed, 11 Mar 2015 11:31:30 +0100
Subject: [R] end of string in a character class in grep
Message-ID: <CAN-Z0xX0e=O-frScsWe2bajdZNdqrnpnbmrybEQj+0JvVn3c8A@mail.gmail.com>

Hi!

I'm trying to persuade R's regular expressions to do what I want. I
have a vector of strings which are names of variables, some of which
are elements of strings. I want to reformat all of the variables into
a list, so (for example)  beta[1] and beta[2] would be a vector in the
list. Where I'm struggling is how to pick out the correct variables.

The problem is that if I have a sub-string, str, then I want to find
the strings that is either the same as the sub-string, or is the
substring followed by a '['. I feel I should be able to do this within
a character class if I could give it an end of string character, i.e.
'[$\\[]' where $ is not a literal $, but the end of the string (i.e.
how it's interpreted outside a character class)

Here's an example, using $ where I want the end of string:

> VarNames <- c("alpha", "beta[1]", "beta[2]", "m", "mu.k", "mu.r")
> TryNames <- unique(gsub('[]\\[1-9]',"",VarNames))
>
> VarNames[grep(paste('^',TryNames[1], '[$\\[]', sep=""), VarNames)] # want "alpha"
character(0)
> VarNames[grep(paste('^',TryNames[2], '[$\\[]', sep=""), VarNames)] # Gives waht I want
[1] "beta[1]" "beta[2]"
> VarNames[grep(paste('^',TryNames[3], '[$\\[]', sep=""), VarNames)] # want "m"
character(0)
> VarNames[grep(paste('^',TryNames[3], sep=""), VarNames)] # gives more than "m"
[1] "m"    "mu.k" "mu.r"

Is it possible to do this, or will I have to resort to using '|'
(which works but is ugly & will only get uglier in the future)?

Bob

-- 
Bob O'Hara

Biodiversity and Climate Research Centre
Senckenberganlage 25
D-60325 Frankfurt am Main,
Germany

Tel: +49 69 798 40226
Mobile: +49 1515 888 5440
WWW:   http://www.bik-f.de/root/index.php?page_id=219
Blog: http://occamstypewriter.org/boboh/
Journal of Negative Results - EEB: www.jnr-eeb.org


From ripley at stats.ox.ac.uk  Wed Mar 11 12:05:21 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Mar 2015 11:05:21 +0000
Subject: [R] end of string in a character class in grep
In-Reply-To: <CAN-Z0xX0e=O-frScsWe2bajdZNdqrnpnbmrybEQj+0JvVn3c8A@mail.gmail.com>
References: <CAN-Z0xX0e=O-frScsWe2bajdZNdqrnpnbmrybEQj+0JvVn3c8A@mail.gmail.com>
Message-ID: <55002171.7030204@stats.ox.ac.uk>

On 11/03/2015 10:31, Bob O'Hara wrote:
> Hi!
>
> I'm trying to persuade R's regular expressions to do what I want. I

This is not "R's regular expressions" , but the world's regular expressions.

> have a vector of strings which are names of variables, some of which
> are elements of strings. I want to reformat all of the variables into
> a list, so (for example)  beta[1] and beta[2] would be a vector in the
> list. Where I'm struggling is how to pick out the correct variables.
>
> The problem is that if I have a sub-string, str, then I want to find
> the strings that is either the same as the sub-string, or is the
> substring followed by a '['. I feel I should be able to do this within
> a character class if I could give it an end of string character, i.e.
> '[$\\[]' where $ is not a literal $, but the end of the string (i.e.
> how it's interpreted outside a character class)

$ inside a character class is a character, not a metacharacter.

>
> Here's an example, using $ where I want the end of string:
>
>> VarNames <- c("alpha", "beta[1]", "beta[2]", "m", "mu.k", "mu.r")
>> TryNames <- unique(gsub('[]\\[1-9]',"",VarNames))
>>
>> VarNames[grep(paste('^',TryNames[1], '[$\\[]', sep=""), VarNames)] # want "alpha"
> character(0)
>> VarNames[grep(paste('^',TryNames[2], '[$\\[]', sep=""), VarNames)] # Gives waht I want
> [1] "beta[1]" "beta[2]"
>> VarNames[grep(paste('^',TryNames[3], '[$\\[]', sep=""), VarNames)] # want "m"
> character(0)
>> VarNames[grep(paste('^',TryNames[3], sep=""), VarNames)] # gives more than "m"
> [1] "m"    "mu.k" "mu.r"
>
> Is it possible to do this, or will I have to resort to using '|'
> (which works but is ugly & will only get uglier in the future)?

Why is

grep(paste0('^', TryNames[1], '($|\\[)'), VarNames, value = TRUE)

not a lot less ugly than the code you present?

>
> Bob
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From jvadams at usgs.gov  Wed Mar 11 12:08:07 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 11 Mar 2015 06:08:07 -0500
Subject: [R] Panel Data--filling in missing dates in a span only
In-Reply-To: <620B964B-7204-4B9E-9290-1B36191B24F5@gmail.com>
References: <620B964B-7204-4B9E-9290-1B36191B24F5@gmail.com>
Message-ID: <CAN5YmCEjkKAo3HsQMNCnY5AsxG+QC7fx8HUekjxAzPMuXxYLfQ@mail.gmail.com>

Steve,

Here is one approach that works.  I am calling your first data frame "df".

# list all years from min to max observed in each ID
years <- tapply(df$Date, df$ID, function(x) min(x):max(x))

# create a data frame based on the observed range of years
fulldf <- data.frame(ID=rep(names(years), sapply(years, length)),
  Date=unlist(years))

# merge the data frame of observations with the data frame with all years
merge(fulldf, df, all=TRUE)

Jean

On Tue, Mar 10, 2015 at 5:53 PM, Steven Archambault <archstevej at gmail.com>
wrote:

> Hi folks,
>
> I have this panel data (below), with observations missing in each of the
> panels. I want to fill in years for the missing data, but only those years
> within the span of the existing data. For instance, BC-0002 needs on year,
> 1995. I do not want any years after the last observation.
>
> structure(list(ID = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
> c("BC-0002",
> "BC-0003", "BC-0004"), class = "factor"), Date = c(1989L, 1990L,
> 1991L, 1992L, 1993L, 1994L, 1996L, 1989L, 1990L, 1991L, 1992L,
> 1993L, 1994L, 1996L, 1995L, 1996L, 1997L, 1998L, 2000L, 1994L,
> 1993L, 1999L, 1998L), DepthtoWater_bgs = c(317.85, 317.25, 321.25,
> 312.31, 313.01, 330.41, 321.01, 166.58, 167.55, 168.65, 168.95,
> 169.25, 168.85, 169.75, 260.6, 261.65, 262.15, 265.45, 266.15,
> 265.25, 265.05, 266.95, 267.75)), .Names = c("ID", "Date",
> "DepthtoWater_bgs"
> ), class = "data.frame", row.names = c(NA, -23L))
>
>
> I have been using this code to expand the entire panels, but it is not
> what exactly what I want.
>
> fexp <- expand.grid(ID=unique(wells$ID), Date=unique(wells$Date))
> merge(fexp, wells, all=TRUE)
>
> Any help would be much appreciated!
>
> Thanks,
> Steve
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pollaroid at gmail.com  Wed Mar 11 12:19:51 2015
From: pollaroid at gmail.com (Kuma Raj)
Date: Wed, 11 Mar 2015 12:19:51 +0100
Subject: [R] Aggegate minutes data to hourly data
Message-ID: <CAAC1QdDicf7o2Bvr8sC_Z0SB72O70eZY6rqsG-7yC12-W+qgQg@mail.gmail.com>

I have a measurement that was taken in 15 minutes or more and want to
aggregate it by hour. How could I do that?

Sample data is found below
date_time concentration
26/11/2013 15:46 529.25
26/11/2013 16:03 1596
26/11/2013 16:23 1027.111
26/11/2013 16:39 1001.9
26/11/2013 16:54 -80.25
26/11/2013 17:12 1064.125
26/11/2013 11:14 7969.7
26/11/2013 11:32 522
26/11/2013 11:58 845.111
26/11/2013 12:12 1166.875
26/11/2013 12:30 473.375
26/11/2013 12:42 466.2
26/11/2013 07:47 4358.833
26/11/2013 08:05 1257.545
26/11/2013 08:24 828.6
26/11/2013 08:45 942
26/11/2013 08:58 758.111
26/11/2013 09:13 832.333
26/11/2013 15:45 1876.909
26/11/2013 16:07 574.25
26/11/2013 16:27 1736.846
26/11/2013 16:43 1024.857
26/11/2013 16:59 858.538
26/11/2013 17:15 912.455
26/11/2013 11:18 2086.143
26/11/2013 11:39 2078.667
26/11/2013 12:03 1619.072
26/11/2013 12:16 1197.583
26/11/2013 12:35 619.308
26/11/2013 12:51 1222.571
26/11/2013 07:49 1357.929
26/11/2013 08:08 1120
26/11/2013 08:29 1381.6
26/11/2013 08:48 1493.429
26/11/2013 09:03 1113.786
26/11/2013 09:18 1217.143


From shouro at gmail.com  Wed Mar 11 12:23:14 2015
From: shouro at gmail.com (Shouro Dasgupta)
Date: Wed, 11 Mar 2015 12:23:14 +0100
Subject: [R] Aggegate minutes data to hourly data
In-Reply-To: <CAAC1QdDicf7o2Bvr8sC_Z0SB72O70eZY6rqsG-7yC12-W+qgQg@mail.gmail.com>
References: <CAAC1QdDicf7o2Bvr8sC_Z0SB72O70eZY6rqsG-7yC12-W+qgQg@mail.gmail.com>
Message-ID: <CAMx+UYcsKDPO7yA_bGfK5TGmZDe+hk+mC+hMCORgVM2WcbUdLQ@mail.gmail.com>

http://stats.stackexchange.com/questions/7268/how-to-aggregate-by-minute-data-for-a-week-into-hourly-means

On Wed, Mar 11, 2015 at 12:19 PM, Kuma Raj <pollaroid at gmail.com> wrote:

> I have a measurement that was taken in 15 minutes or more and want to
> aggregate it by hour. How could I do that?
>
> Sample data is found below
> date_time concentration
> 26/11/2013 15:46 529.25
> 26/11/2013 16:03 1596
> 26/11/2013 16:23 1027.111
> 26/11/2013 16:39 1001.9
> 26/11/2013 16:54 -80.25
> 26/11/2013 17:12 1064.125
> 26/11/2013 11:14 7969.7
> 26/11/2013 11:32 522
> 26/11/2013 11:58 845.111
> 26/11/2013 12:12 1166.875
> 26/11/2013 12:30 473.375
> 26/11/2013 12:42 466.2
> 26/11/2013 07:47 4358.833
> 26/11/2013 08:05 1257.545
> 26/11/2013 08:24 828.6
> 26/11/2013 08:45 942
> 26/11/2013 08:58 758.111
> 26/11/2013 09:13 832.333
> 26/11/2013 15:45 1876.909
> 26/11/2013 16:07 574.25
> 26/11/2013 16:27 1736.846
> 26/11/2013 16:43 1024.857
> 26/11/2013 16:59 858.538
> 26/11/2013 17:15 912.455
> 26/11/2013 11:18 2086.143
> 26/11/2013 11:39 2078.667
> 26/11/2013 12:03 1619.072
> 26/11/2013 12:16 1197.583
> 26/11/2013 12:35 619.308
> 26/11/2013 12:51 1222.571
> 26/11/2013 07:49 1357.929
> 26/11/2013 08:08 1120
> 26/11/2013 08:29 1381.6
> 26/11/2013 08:48 1493.429
> 26/11/2013 09:03 1113.786
> 26/11/2013 09:18 1217.143
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From amelia_marsh08 at yahoo.com  Wed Mar 11 10:41:43 2015
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Wed, 11 Mar 2015 09:41:43 +0000 (UTC)
Subject: [R] Gamma Distribution - is there any problem with "pgamma"?
Message-ID: <664401303.1769960.1426066903320.JavaMail.yahoo@mail.yahoo.com>

Dear R forum

I have following data

amounts = c(928906.144,156091.0576,433798.3404,993425.7224,1323976.364,649106.9339, 369967.2612,2528872.35,1226093.655,1145446.149,1809624.453,599329.0394,2200955.213,2583318.064,745625.8069,961828.8828,1744841.313,1939390.005,1077873.654,729924.2713,803584.2636,287020.8529,530910.9004,818574.0089,1908133.51,262336.0893,593808.2542,780258.1354)

# Estimating Gamma distribution parameters

shape_gamma	    	<-    		(mean(amounts)/sd(amounts))^2 


scale_gamma      <-    		(sd(amounts)^2/mean(amounts))


Fx    				<-    		pgamma(amounts, shape_gamma, scale_gamma)



I get following values of Fx

> Fx 
[1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 



I have tried this for different dataset but still each time I am getting values of Fx as 1's only.

Is there any problem with pgamma command?

Kindly advise.

Regards

Amelia


From albmont at centroin.com.br  Wed Mar 11 12:25:37 2015
From: albmont at centroin.com.br (ALBERTO VIEIRA FERREIRA MONTEIRO)
Date: Wed, 11 Mar 2015 08:25:37 -0300
Subject: [R] Annoyance with %/%
Message-ID: <CAEyj4=_NM-ntxE+zx+GutEL_kU_WwZXrnUU2mZfsa=HzU8aAaA@mail.gmail.com>

I've just found an annoyance with the behaviour of %/% which, BTW,
violated the sacred rule that for all a, and non-zero b:

a = b * (a %/% b) + a %% b

Namely, that Inf %/% n is not Inf, but NaN.

Why is this so? It's an annoyance, because in expressions like:

big.vector.1[a, b, c] <- big.vector.2[a, b, c] %/% n

we must treat Inf and -Inf as exceptions, when a simple division does
not have these exceptions

BTW, I treated this exception the way Grace Hopper would be proud of, namely,
"it's easier to ask forgiveness than it is to get permission", but at
the cost of memory:

big.vector.1 <- big.vector.2
big.vector.1[a, b, c] <- big.vector.2[a, b, c] %/% n
tst <- is.nan(big.vector.1)
if (any(tst)) big.vector.1[tst] <- big.vector.2

Alberto Monteiro


From albmont at centroin.com.br  Wed Mar 11 12:47:12 2015
From: albmont at centroin.com.br (ALBERTO VIEIRA FERREIRA MONTEIRO)
Date: Wed, 11 Mar 2015 08:47:12 -0300
Subject: [R] Extract year from date
Message-ID: <CAEyj4=9uqDBDERWCrxD9UZRR-WnM9cK9-UF4GojCmCbV34W34g@mail.gmail.com>

I think these dates are from some historical database, as they are
labeled "BC". And the days might refer to some Epoch of ancient
calendars, maybe the Chinese Calendar whose Epoch was 105 BC (at least
if we can trust Wikipedia:
https://en.wikipedia.org/wiki/Chinese_calendar )

Alberto Monteiro


From martyn.byng at nag.co.uk  Wed Mar 11 12:48:47 2015
From: martyn.byng at nag.co.uk (Martyn Byng)
Date: Wed, 11 Mar 2015 11:48:47 +0000
Subject: [R] Gamma Distribution - is there any problem with "pgamma"?
In-Reply-To: <664401303.1769960.1426066903320.JavaMail.yahoo@mail.yahoo.com>
References: <664401303.1769960.1426066903320.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <DB3PR05MB07786DDFB87CAED0CBC29563A1190@DB3PR05MB0778.eurprd05.prod.outlook.com>

Hi,

Try

pgamma(amounts,shape_gamma,scale=scale_gamma)

as I am guessing you mean scale_gamma to be the scale of the distribution, but are using it as the rate ( = 1 / scale) instead

Martyn

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Amelia Marsh
Sent: 11 March 2015 09:42
To: r-help at r-project.org
Subject: [R] Gamma Distribution - is there any problem with "pgamma"?

Dear R forum

I have following data

amounts = c(928906.144,156091.0576,433798.3404,993425.7224,1323976.364,649106.9339, 369967.2612,2528872.35,1226093.655,1145446.149,1809624.453,599329.0394,2200955.213,2583318.064,745625.8069,961828.8828,1744841.313,1939390.005,1077873.654,729924.2713,803584.2636,287020.8529,530910.9004,818574.0089,1908133.51,262336.0893,593808.2542,780258.1354)

# Estimating Gamma distribution parameters

shape_gamma	    	<-    		(mean(amounts)/sd(amounts))^2 


scale_gamma      <-    		(sd(amounts)^2/mean(amounts))


Fx    				<-    		pgamma(amounts, shape_gamma, scale_gamma)



I get following values of Fx

> Fx 
[1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 



I have tried this for different dataset but still each time I am getting values of Fx as 1's only.

Is there any problem with pgamma command?

Kindly advise.

Regards

Amelia

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________________________________________________
This e-mail has been scanned for all viruses by Star.\ _...{{dropped:3}}


From bbolker at gmail.com  Wed Mar 11 12:54:14 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Mar 2015 11:54:14 +0000
Subject: [R] Gamma Distribution - is there any problem with "pgamma"?
References: <664401303.1769960.1426066903320.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <loom.20150311T125008-340@post.gmane.org>

Amelia Marsh <amelia_marsh08 <at> yahoo.com> writes:

> 
> Dear R forum
> 
> I have following data
> 
> amounts = c(928906.144,156091.0576,433798.3404,993425.7224,
> 1323976.364,649106.9339, 369967.2612,2528872.35,1226093.655,
> 1145446.149,1809624.453,599329.0394,2200955.213,2583318.064,
> 745625.8069,961828.8828,1744841.313,1939390.005,1077873.654,
> 729924.2713,803584.2636,287020.8529,530910.9004,818574.0089,
> 1908133.51,262336.0893,593808.2542,780258.1354)
 
> # Estimating Gamma distribution parameters
> 
> shape_gamma	    	<-    		(mean(amounts)/sd(amounts))^2 
> 
> scale_gamma      <-    		(sd(amounts)^2/mean(amounts))
>

 The default parameterization of the Gamma distribution in R 
uses a rate parameter, not a scale parameter.  You can override this:
 
Fx <-	pgamma(amounts, shape_gamma, scale=scale_gamma)

or

Fx <-	pgamma(amounts, shape_gamma, rate=1/scale_gamma)

One place you can find a description of the parameterizations
in R is 

http://journal.r-project.org/archive/2013-1/lebauer-dietze-bolker.pdf


From nashjc at uottawa.ca  Wed Mar 11 14:00:15 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Wed, 11 Mar 2015 09:00:15 -0400
Subject: [R] .Rdata files -- fortune?
In-Reply-To: <mailman.1.1426071602.12262.r-help@r-project.org>
References: <mailman.1.1426071602.12262.r-help@r-project.org>
Message-ID: <55003C5F.70904@uottawa.ca>

Well put. I avoid them too, and go so far as to seek and destroy so they
don't get loaded unnoticed and cause unwanted consequences.

".RData files (the ones with nothing before the period) are just traps
for your future self, with no documentation. I avoid them like the plague."


JN

On 15-03-11 07:00 AM, r-help-request at r-project.org wrote:
> Message: 34
> Date: Tue, 10 Mar 2015 17:51:15 -0700
> From: Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
> To: Rolf Turner <r.turner at auckland.ac.nz>, Erin Hodgess
> 	<erinm.hodgess at gmail.com>, R help <r-help at stat.math.ethz.ch>
> Subject: Re: [R] .Rprofile vs. First (more of an opinion question)
> Message-ID: <E5A53229-B271-42D9-BEAB-73142B2F62F4 at dcn.davis.CA.us>
> Content-Type: text/plain; charset="UTF-8"
> 
> I concur with Rolf.
> 
> .RData files (the ones with nothing before the period) are just traps for your future self, with no documentation. I avoid them like the plague. I refer to specifically-named Something.RData files in my .R/.Rnw/.Rmd files to cache results of long computations, but they are optional in my workflow because I always have R code that can regenerate them.
> 
> .Rprofile files offer consistency of behavior  regardless of which working directory you use, and you can comment them.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.


From mtmorgan at fredhutch.org  Wed Mar 11 14:19:20 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Wed, 11 Mar 2015 06:19:20 -0700
Subject: [R] Checking whether specific packages (from bioconductor) are
 installed when loading a package
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C3A172B5E0@AD-EXCHMBX2-1.aau.dk>
References: <7E8037094A0C2146AA3E6F94DAE621C3A172B5E0@AD-EXCHMBX2-1.aau.dk>
Message-ID: <550040D8.7050407@fredhutch.org>

On 03/11/2015 01:36 AM, S?ren H?jsgaard wrote:
> Dear all,
>
> My package 'gRbase' uses three packages from Bioconductor and these are not automatically installed when gRbase is installed. My instructions (on the package webpage) to users are therefore to run:
>

Treat Bioconductor packages as any other, listing them in Depends: or Imports: 
or Suggests: as described in 'Writing R Extensions'. CRAN builds packages with 
access to the Bioconductor repository. Your CRAN users chooseBioCmirror() and 
setRepositories() before using install.packages(), and Bioc dependencies are 
installed like any other dependency.

> source("http://bioconductor.org/biocLite.R"); biocLite(c("graph","RBGL","Rgraphviz"))
>
> When loading gRbase, it is checked whether these Bioconductor packages are available, but I would like to add a message about how to install the packages if they are not.
>

This functionality is provided by Depends: and Imports:, so is not relevant for 
packages listed in this part of your DESCRIPTION file. You're only asking for 
advice on packages that are in Suggests:. It does not matter that these are 
Bioconductor packages or CRAN packages or ... the packages in Suggests: are not, 
by default, installed when your package was installed (see the 'dependencies' 
argument to install.packages()).

> Does this go into .onAttach or .onLoad or elsewhere?

Or not at all. If the package belongs in Suggests: and provides some special 
functionality not needed by the package most of the time (else it would be in 
Imports: [most likely] or Depends:) then there will be some few points in the 
code where the package is used and you need to alert the user to the special 
condition they've encountered. You'll want to fully specify the package and 
function to be used

   RBGL::transitive.closure(...)

(full specification provides similar advantage to Import:'ing a symbol into your 
package, avoiding symbol look-up along the search() path, potentially getting a 
function transitive.closure() defined by the user or a package different from 
RBGL). If RBGL is not available, the above code will fail, and the user will be 
told that "there is no package called 'RBGL'".

One common strategy for nicer messages is to

     if (!requireNamespace("RBGL)")
         stop("your more tailored message")

in the few code chunks before your use of RBGL::transitive.closure(). 
requireNamespace() loads but does not attach the RBGL package, so the symbols 
are available when fully qualified RBGL:: but the package does not interfere 
with the user search() path.

Which I guess brings us to your question, and the answer is probably that if 
after the above you were to still wish to add a message at package start-up, 
then the right place would be .onLoad(), so that users of your package, as well 
as users of packages that Import: (load) but do not Depend: (attach) on your 
package, will see the message.

Also, this belongs on the R-devel mailing list.

Hope that's helpful,

Martin

>
> Thanks in advance
> S?ren
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From givolis at gmail.com  Wed Mar 11 15:32:03 2015
From: givolis at gmail.com (Simon Givoli)
Date: Wed, 11 Mar 2015 16:32:03 +0200
Subject: [R] (no subject)
Message-ID: <CAN=5oGhFFn2rM_g8L-tGSESAbb72uw2RkHA_NVdpc_P5WoPwpQ@mail.gmail.com>

Hi,

I'm trying to extract sequences from my data, using the SPADE algorithm in
the arulesSequences package:

1 1 8 1100 31 45 31 45 1 5 1200
1 2 100 1100 31 45 1 5 31
1 3 59 1100 31 45 1 81 1000 1 1 5
1 4 69 1100 31 45 17 1000 610 1000 1 1 81
1 5 31 1100 31 45 81 1000

(library(Matrix
(library(arules
(library(arulesSequences

((x<-read_baskets(file.choose(), info = c("sequenceID","eventID","size
("as(x,"data.frame

((s1 <- cspade(x, parameter = list(support = 0.4), control = list(verbose =
TRUE

R-studio starts to run the commands and than seems to stall:



:parameter specification
support : 0.4
maxsize :  10
maxlen  :  10

:algorithmic control
bfstype  : FALSE
verbose  :  TRUE
summary  : FALSE
tidLists : FALSE

[preprocessing ... 1 partition(s), 0 MB [0.1s
mining transactions ...

This also happened when I tried ti run the commands on only 10 observations.

Any suggestions as to what is wrong?

Simon
?

	[[alternative HTML version deleted]]


From givolis at gmail.com  Wed Mar 11 15:36:58 2015
From: givolis at gmail.com (Simon Givoli)
Date: Wed, 11 Mar 2015 16:36:58 +0200
Subject: [R] R-studio stalls in arulesSequences
Message-ID: <CAN=5oGgCCToSSkx0W7YbkbTj+xUWuVmKZHvVNnY770cj4o9S0g@mail.gmail.com>

Hi,

I'm trying to extract sequences from my data, using the SPADE algorithm in
the arulesSequences package:

1 1 8 1100 31 45 31 45 1 5 1200
1 2 100 1100 31 45 1 5 31
1 3 59 1100 31 45 1 81 1000 1 1 5
1 4 69 1100 31 45 17 1000 610 1000 1 1 81
1 5 31 1100 31 45 81 1000

(library(Matrix
(library(arules
(library(arulesSequences

((x<-read_baskets(file.choose(), info = c("sequenceID","eventID","size
("as(x,"data.frame

((s1 <- cspade(x, parameter = list(support = 0.4), control = list(verbose =
TRUE

R-studio starts to run the commands and than seems to stall:



:parameter specification
support : 0.4
maxsize :  10
maxlen  :  10

:algorithmic control
bfstype  : FALSE
verbose  :  TRUE
summary  : FALSE
tidLists : FALSE

[preprocessing ... 1 partition(s), 0 MB [0.1s
mining transactions ...

This also happened when I tried ti run the commands on only 10 observations.

Any suggestions as to what is wrong?

Simon

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Mar 11 16:09:29 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 11 Mar 2015 11:09:29 -0400
Subject: [R] R-studio stalls in arulesSequences
In-Reply-To: <CAN=5oGgCCToSSkx0W7YbkbTj+xUWuVmKZHvVNnY770cj4o9S0g@mail.gmail.com>
References: <CAN=5oGgCCToSSkx0W7YbkbTj+xUWuVmKZHvVNnY770cj4o9S0g@mail.gmail.com>
Message-ID: <CAM_vju=e6_GBvRH=29WKbSttG1qgY7f7zVt_K7y4FpPyWvnpnw@mail.gmail.com>

Please don't post in HTML - your code is unreadable.

Using dput() to provide some of your data may also encourage people to
help you figure out what's wrong.

Without a reproducible example that includes some sample data (fake is
fine), the code you used, and some clear idea of what output you
expect, it's impossible to figure out how to help you. Here are some
suggestions for creating a good reproducible example:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example


On Wed, Mar 11, 2015 at 10:36 AM, Simon Givoli <givolis at gmail.com> wrote:
> Hi,
>
> I'm trying to extract sequences from my data, using the SPADE algorithm in
> the arulesSequences package:
>
> 1 1 8 1100 31 45 31 45 1 5 1200
> 1 2 100 1100 31 45 1 5 31
> 1 3 59 1100 31 45 1 81 1000 1 1 5
> 1 4 69 1100 31 45 17 1000 610 1000 1 1 81
> 1 5 31 1100 31 45 81 1000
>
> (library(Matrix
> (library(arules
> (library(arulesSequences
>
> ((x<-read_baskets(file.choose(), info = c("sequenceID","eventID","size
> ("as(x,"data.frame
>
> ((s1 <- cspade(x, parameter = list(support = 0.4), control = list(verbose =
> TRUE
>
> R-studio starts to run the commands and than seems to stall:
>
>
>
> :parameter specification
> support : 0.4
> maxsize :  10
> maxlen  :  10
>
> :algorithmic control
> bfstype  : FALSE
> verbose  :  TRUE
> summary  : FALSE
> tidLists : FALSE
>
> [preprocessing ... 1 partition(s), 0 MB [0.1s
> mining transactions ...
>
> This also happened when I tried ti run the commands on only 10 observations.
>
> Any suggestions as to what is wrong?
>
> Simon
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.functionaldiversity.org


From wdunlap at tibco.com  Wed Mar 11 16:14:54 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 11 Mar 2015 08:14:54 -0700
Subject: [R] Annoyance with %/%
In-Reply-To: <CAEyj4=_NM-ntxE+zx+GutEL_kU_WwZXrnUU2mZfsa=HzU8aAaA@mail.gmail.com>
References: <CAEyj4=_NM-ntxE+zx+GutEL_kU_WwZXrnUU2mZfsa=HzU8aAaA@mail.gmail.com>
Message-ID: <CAF8bMcbX9xZY7yoMGxNwFFZDb4tT_owMaJU_B55udE53M3VL1g@mail.gmail.com>

> %/% which, BTW,
> violated the sacred rule that for all a, and non-zero b:
>
> a = b * (a %/% b) + a %% b
>
> Namely, that Inf %/% n is not Inf, but NaN.

But the other sacred rule is that a%%b is >=0 and <b.

By the way, you will run into problems with %% long before Inf.  E.g.,
  > (1 + 2^53) %% 2 # 1 if you had infinite precision
  [1] 0
  > (2 + 2^53) %% 2
  [1] 0
  Warning message:
  probable complete loss of accuracy in modulus


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Mar 11, 2015 at 4:25 AM, ALBERTO VIEIRA FERREIRA MONTEIRO <
albmont at centroin.com.br> wrote:

> I've just found an annoyance with the behaviour of %/% which, BTW,
> violated the sacred rule that for all a, and non-zero b:
>
> a = b * (a %/% b) + a %% b
>
> Namely, that Inf %/% n is not Inf, but NaN.
>
> Why is this so? It's an annoyance, because in expressions like:
>
> big.vector.1[a, b, c] <- big.vector.2[a, b, c] %/% n
>
> we must treat Inf and -Inf as exceptions, when a simple division does
> not have these exceptions
>
> BTW, I treated this exception the way Grace Hopper would be proud of,
> namely,
> "it's easier to ask forgiveness than it is to get permission", but at
> the cost of memory:
>
> big.vector.1 <- big.vector.2
> big.vector.1[a, b, c] <- big.vector.2[a, b, c] %/% n
> tst <- is.nan(big.vector.1)
> if (any(tst)) big.vector.1[tst] <- big.vector.2
>
> Alberto Monteiro
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From varinsacha at yahoo.fr  Wed Mar 11 16:26:06 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Wed, 11 Mar 2015 15:26:06 +0000 (UTC)
Subject: [R] Drawing/Plotting Cramer's V and Eta-square distribution
Message-ID: <641449313.4538109.1426087566004.JavaMail.yahoo@mail.yahoo.com>

Hi R-Experts,

Thanks to the R package "SuppDists", I can draw/plot the sampling distribution of the Pearson (and/or Spearman) rho coefficient.

install.packages("SuppDists")
library(SuppDists)
curve(dPearson(x,85,rho=0.64),from=-1,to=1)

Do you know a package (or some packages) I could use if I want to draw the sampling distribution of the Cramer's V and the sampling distribution of the Eta-square ? I hope and guess there must be some packages...

Many thanks for your response.

SV

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Wed Mar 11 16:37:40 2015
From: jholtman at gmail.com (jim holtman)
Date: Wed, 11 Mar 2015 11:37:40 -0400
Subject: [R] Annoyance with %/%
In-Reply-To: <CAF8bMcbX9xZY7yoMGxNwFFZDb4tT_owMaJU_B55udE53M3VL1g@mail.gmail.com>
References: <CAEyj4=_NM-ntxE+zx+GutEL_kU_WwZXrnUU2mZfsa=HzU8aAaA@mail.gmail.com>
	<CAF8bMcbX9xZY7yoMGxNwFFZDb4tT_owMaJU_B55udE53M3VL1g@mail.gmail.com>
Message-ID: <CAAxdm-7xrAURDmVsWzHuMrTGiz5YOYyhET7JDX-R4bEpOfvEMw@mail.gmail.com>

shouldn't your last expression be:

if (any(tst)) big.vector.1[tst] <- big.vector.2[tst]


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Mar 11, 2015 at 11:14 AM, William Dunlap <wdunlap at tibco.com> wrote:

> > %/% which, BTW,
> > violated the sacred rule that for all a, and non-zero b:
> >
> > a = b * (a %/% b) + a %% b
> >
> > Namely, that Inf %/% n is not Inf, but NaN.
>
> But the other sacred rule is that a%%b is >=0 and <b.
>
> By the way, you will run into problems with %% long before Inf.  E.g.,
>   > (1 + 2^53) %% 2 # 1 if you had infinite precision
>   [1] 0
>   > (2 + 2^53) %% 2
>   [1] 0
>   Warning message:
>   probable complete loss of accuracy in modulus
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Wed, Mar 11, 2015 at 4:25 AM, ALBERTO VIEIRA FERREIRA MONTEIRO <
> albmont at centroin.com.br> wrote:
>
> > I've just found an annoyance with the behaviour of %/% which, BTW,
> > violated the sacred rule that for all a, and non-zero b:
> >
> > a = b * (a %/% b) + a %% b
> >
> > Namely, that Inf %/% n is not Inf, but NaN.
> >
> > Why is this so? It's an annoyance, because in expressions like:
> >
> > big.vector.1[a, b, c] <- big.vector.2[a, b, c] %/% n
> >
> > we must treat Inf and -Inf as exceptions, when a simple division does
> > not have these exceptions
> >
> > BTW, I treated this exception the way Grace Hopper would be proud of,
> > namely,
> > "it's easier to ask forgiveness than it is to get permission", but at
> > the cost of memory:
> >
> > big.vector.1 <- big.vector.2
> > big.vector.1[a, b, c] <- big.vector.2[a, b, c] %/% n
> > tst <- is.nan(big.vector.1)
> > if (any(tst)) big.vector.1[tst] <- big.vector.2
> >
> > Alberto Monteiro
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From albmont at centroin.com.br  Wed Mar 11 17:04:44 2015
From: albmont at centroin.com.br (ALBERTO VIEIRA FERREIRA MONTEIRO)
Date: Wed, 11 Mar 2015 13:04:44 -0300
Subject: [R] Annoyance with %/%
In-Reply-To: <CAAxdm-7xrAURDmVsWzHuMrTGiz5YOYyhET7JDX-R4bEpOfvEMw@mail.gmail.com>
References: <CAEyj4=_NM-ntxE+zx+GutEL_kU_WwZXrnUU2mZfsa=HzU8aAaA@mail.gmail.com>
	<CAF8bMcbX9xZY7yoMGxNwFFZDb4tT_owMaJU_B55udE53M3VL1g@mail.gmail.com>
	<CAAxdm-7xrAURDmVsWzHuMrTGiz5YOYyhET7JDX-R4bEpOfvEMw@mail.gmail.com>
Message-ID: <CAEyj4=8L=5Xps0QR2=p1Vig1oemCsYbp8HJaeFFv_-rSRJjrhg@mail.gmail.com>

> shouldn't your last expression be:
>
> if (any(tst)) big.vector.1[tst] <- big.vector.2[tst]
>
>
Sure, that was a typo.

Also, I know that `%%` does not make sense neither for Inf nor for big
numbers, but `%/%` - since it's "only" a special case of `/` - should
make sense; it should be "equivalent" (obviously doing some
machine-optimization) to `%/%` <- function(x, y) floor(x / y) (which
works fine for infinite x and non-zero y)

Alberto Monteiro


From jdnewmil at dcn.davis.CA.us  Wed Mar 11 18:04:15 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 11 Mar 2015 10:04:15 -0700
Subject: [R] R-studio stalls in arulesSequences
In-Reply-To: <CAM_vju=e6_GBvRH=29WKbSttG1qgY7f7zVt_K7y4FpPyWvnpnw@mail.gmail.com>
References: <CAN=5oGgCCToSSkx0W7YbkbTj+xUWuVmKZHvVNnY770cj4o9S0g@mail.gmail.com>
	<CAM_vju=e6_GBvRH=29WKbSttG1qgY7f7zVt_K7y4FpPyWvnpnw@mail.gmail.com>
Message-ID: <5B4F33AA-9564-4CF6-B1A0-DA8CD2425BC6@dcn.davis.CA.us>

Also, of the problem only occurs in RStudio then your question would need to be asked in their support forum. They do override some standard R functions so occasionally there are bugs introduced by that. Check if it occurs in plain R before posting here.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 11, 2015 8:09:29 AM PDT, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>Please don't post in HTML - your code is unreadable.
>
>Using dput() to provide some of your data may also encourage people to
>help you figure out what's wrong.
>
>Without a reproducible example that includes some sample data (fake is
>fine), the code you used, and some clear idea of what output you
>expect, it's impossible to figure out how to help you. Here are some
>suggestions for creating a good reproducible example:
>http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
>
>On Wed, Mar 11, 2015 at 10:36 AM, Simon Givoli <givolis at gmail.com>
>wrote:
>> Hi,
>>
>> I'm trying to extract sequences from my data, using the SPADE
>algorithm in
>> the arulesSequences package:
>>
>> 1 1 8 1100 31 45 31 45 1 5 1200
>> 1 2 100 1100 31 45 1 5 31
>> 1 3 59 1100 31 45 1 81 1000 1 1 5
>> 1 4 69 1100 31 45 17 1000 610 1000 1 1 81
>> 1 5 31 1100 31 45 81 1000
>>
>> (library(Matrix
>> (library(arules
>> (library(arulesSequences
>>
>> ((x<-read_baskets(file.choose(), info =
>c("sequenceID","eventID","size
>> ("as(x,"data.frame
>>
>> ((s1 <- cspade(x, parameter = list(support = 0.4), control =
>list(verbose =
>> TRUE
>>
>> R-studio starts to run the commands and than seems to stall:
>>
>>
>>
>> :parameter specification
>> support : 0.4
>> maxsize :  10
>> maxlen  :  10
>>
>> :algorithmic control
>> bfstype  : FALSE
>> verbose  :  TRUE
>> summary  : FALSE
>> tidLists : FALSE
>>
>> [preprocessing ... 1 partition(s), 0 MB [0.1s
>> mining transactions ...
>>
>> This also happened when I tried ti run the commands on only 10
>observations.
>>
>> Any suggestions as to what is wrong?
>>
>> Simon
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jttkim at googlemail.com  Wed Mar 11 16:44:16 2015
From: jttkim at googlemail.com (Jan Kim)
Date: Wed, 11 Mar 2015 15:44:16 +0000
Subject: [R] .Rdata files -- fortune?
In-Reply-To: <55003C5F.70904@uottawa.ca>
References: <mailman.1.1426071602.12262.r-help@r-project.org>
	<55003C5F.70904@uottawa.ca>
Message-ID: <20150311154415.GB2730@localhost>

On Wed, Mar 11, 2015 at 09:00:15AM -0400, Prof J C Nash (U30A) wrote:
> Well put. I avoid them too, and go so far as to seek and destroy so they
> don't get loaded unnoticed and cause unwanted consequences.
> 
> ".RData files (the ones with nothing before the period) are just traps
> for your future self, with no documentation. I avoid them like the plague."

I absolutely agree. While I've solved the issue for myself long
ago by always putting something like

    alias R='R --no-save --no-restore'

into my startup scripts (~/.bashrc or the like), I've seen too many
others caught out by implicit saving / restoring of workspaces (e.g.
by somehow just accepting that R "only works properly in this particular
directory" and therefore doing all their work there at the cost of
adopting various anti-patterns with respect to organising work into
directories.

Personally I think that auto saving / restoring workspaces should
be reviewed, as it can, in practice, make it harder for people to
render their work in a self-contained and reproducible way.

Best regards, Jan

> 
> JN
> 
> On 15-03-11 07:00 AM, r-help-request at r-project.org wrote:
> > Message: 34
> > Date: Tue, 10 Mar 2015 17:51:15 -0700
> > From: Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
> > To: Rolf Turner <r.turner at auckland.ac.nz>, Erin Hodgess
> > 	<erinm.hodgess at gmail.com>, R help <r-help at stat.math.ethz.ch>
> > Subject: Re: [R] .Rprofile vs. First (more of an opinion question)
> > Message-ID: <E5A53229-B271-42D9-BEAB-73142B2F62F4 at dcn.davis.CA.us>
> > Content-Type: text/plain; charset="UTF-8"
> > 
> > I concur with Rolf.
> > 
> > .RData files (the ones with nothing before the period) are just traps for your future self, with no documentation. I avoid them like the plague. I refer to specifically-named Something.RData files in my .R/.Rnw/.Rmd files to cache results of long computations, but they are optional in my workflow because I always have R code that can regenerate them.
> > 
> > .Rprofile files offer consistency of behavior  regardless of which working directory you use, and you can comment them.
> > ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
> >                                       Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> > --------------------------------------------------------------------------- 
> > Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
 +- Jan T. Kim -------------------------------------------------------+
 |             email: jttkim at gmail.com                                |
 |             WWW:   http://www.jtkim.dreamhosters.com/              |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*


From locon833 at gmail.com  Wed Mar 11 17:01:59 2015
From: locon833 at gmail.com (Lauren O'Connell)
Date: Wed, 11 Mar 2015 12:01:59 -0400
Subject: [R] Adding Column to a Data Frame
Message-ID: <CAE7r1ggHc3R0oqLb=4KHnL7qUk12yD2Eathk-a9cxtAJ2u3HGw@mail.gmail.com>

I am trying to add a column with data to a data frame that already has
information but am getting this error:

> rich.stats4 = merge(rich.stats,Location,Month,by="X.SampleID")
Error in fix.by(by.x, x) :
  'by' must specify one or more columns as numbers, names or logical


I have two separate data frames that contain my sample names with location
and with month:

#Create data frame of all sample names and month sample was taken

Month =
data.frame(X.SampleID=sample_data(Lauren5000)$X.SampleID,MonthSampleTaken=sample_data(Lauren5000)$MonthSampleTaken)

head(Month)



#Create data frame of all samples names and location of sample

Location =
data.frame(X.SampleID=sample_data(Lauren5000)$X.SampleID,Location=sample_data(Lauren5000)$Location)

head(Location)

I was able to add my "MonthSampleTaken" variable by using this command:

>rich.stats2 = merge(rich.stats, Month,by="X.SampleID")

> head(rich.stats2)

  X.SampleID    mean       sd MonthSampleTaken

1      PE101 1421.34 19.44961         February

2      PE102 1336.24 25.43882         February

3      PE104 1418.75 21.92889            March

4      PE105 1331.03 20.55712            March

5      PE107 1320.21 20.91942            March

6      PE108 1328.41 20.49247            March


I now want to add my sample site location, but can't figure out how to do
this. Any help would be greatly appreciated.


Cheers,

Lauren

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Mar 11 18:25:07 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 11 Mar 2015 17:25:07 +0000
Subject: [R] Adding Column to a Data Frame
In-Reply-To: <CAE7r1ggHc3R0oqLb=4KHnL7qUk12yD2Eathk-a9cxtAJ2u3HGw@mail.gmail.com>
References: <CAE7r1ggHc3R0oqLb=4KHnL7qUk12yD2Eathk-a9cxtAJ2u3HGw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D66D92E@mb02.ads.tamu.edu>

The merge function combines 2, not 3 files at a time. Maybe

rich.stats2 = merge(rich.stats, Month, by="X.SampleID")
rich.stats3 = merge(rich.stats2, Location, by="X.SampleID")

Reading the manual page will help:

?merge

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Lauren O'Connell
Sent: Wednesday, March 11, 2015 11:02 AM
To: r-help at r-project.org
Subject: [R] Adding Column to a Data Frame

I am trying to add a column with data to a data frame that already has
information but am getting this error:

> rich.stats4 = merge(rich.stats,Location,Month,by="X.SampleID")
Error in fix.by(by.x, x) :
  'by' must specify one or more columns as numbers, names or logical


I have two separate data frames that contain my sample names with location
and with month:

#Create data frame of all sample names and month sample was taken

Month =
data.frame(X.SampleID=sample_data(Lauren5000)$X.SampleID,MonthSampleTaken=sample_data(Lauren5000)$MonthSampleTaken)

head(Month)



#Create data frame of all samples names and location of sample

Location =
data.frame(X.SampleID=sample_data(Lauren5000)$X.SampleID,Location=sample_data(Lauren5000)$Location)

head(Location)

I was able to add my "MonthSampleTaken" variable by using this command:

>rich.stats2 = merge(rich.stats, Month,by="X.SampleID")

> head(rich.stats2)

  X.SampleID    mean       sd MonthSampleTaken

1      PE101 1421.34 19.44961         February

2      PE102 1336.24 25.43882         February

3      PE104 1418.75 21.92889            March

4      PE105 1331.03 20.55712            March

5      PE107 1320.21 20.91942            March

6      PE108 1328.41 20.49247            March


I now want to add my sample site location, but can't figure out how to do
this. Any help would be greatly appreciated.


Cheers,

Lauren

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From amelia_marsh08 at yahoo.com  Wed Mar 11 19:58:02 2015
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Thu, 12 Mar 2015 02:58:02 +0800
Subject: [R] Gamma Distribution - is there any problem with "pgamma"?
In-Reply-To: <DB3PR05MB07786DDFB87CAED0CBC29563A1190@DB3PR05MB0778.eurprd05.prod.outlook.com>
Message-ID: <1426100282.13321.YahooMailBasic@web192701.mail.sg3.yahoo.com>

Dear Mr Byng,

Thanks a lot for your great help. Appreciate.

Regards

Amelia
--------------------------------------------
On Wed, 11/3/15, Martyn Byng <martyn.byng at nag.co.uk> wrote:

 Subject: RE: [R] Gamma Distribution - is there any problem with "pgamma"?

elp at r-project.org>
 Date: Wednesday, 11 March, 2015, 11:48 AM

 Hi,

 Try

 pgamma(amounts,shape_gamma,scale=scale_gamma)

 as I am guessing you mean
 scale_gamma to be the scale of the distribution, but are
 using it as the rate ( = 1 / scale) instead

 Martyn

 -----Original Message-----
 From: R-help [mailto:r-help-bounces at r-project.org]
 On Behalf Of Amelia Marsh
 Sent: 11 March
 2015 09:42
 To: r-help at r-project.org
 Subject: [R] Gamma Distribution - is there any
 problem with "pgamma"?

 Dear R forum

 I
 have following data

 amounts
 =
 c(928906.144,156091.0576,433798.3404,993425.7224,1323976.364,649106.9339,
 369967.2612,2528872.35,1226093.655,1145446.149,1809624.453,599329.0394,2200955.213,2583318.064,745625.8069,961828.8828,1744841.313,1939390.005,1077873.654,729924.2713,803584.2636,287020.8529,530910.9004,818574.0089,1908133.51,262336.0893,593808.2542,780258.1354)

 # Estimating Gamma
 distribution parameters

 shape_gamma??? ? ? ??? <-? ?
 ??? ??? (mean(amounts)/sd(amounts))^2 


 scale_gamma?
 ? ? <-? ? ??? ???
 (sd(amounts)^2/mean(amounts))


 Fx? ? ??? ??? ???
 ??? <-? ? ??? ??? pgamma(amounts, shape_gamma,
 scale_gamma)



 I get following values of
 Fx

 > Fx 
 [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 



 I have tried this for
 different dataset but still each time I am getting values of
 Fx as 1's only.

 Is
 there any problem with pgamma command?

 Kindly advise.

 Regards

 Amelia

 ______________________________________________
 R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 and provide commented, minimal, self-contained,
 reproducible code.

 ________________________________________________________________________
 This e-mail has been scanned for all viruses by
 Star.


From macqueen1 at llnl.gov  Wed Mar 11 20:05:56 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 11 Mar 2015 19:05:56 +0000
Subject: [R] R can't find tcl-tk
In-Reply-To: <CACHqeJLKOsntwkTxx7pU4H10xc9Mr+xsFDs8JuWQrQTsTYPDNA@mail.gmail.com>
References: <CACHqeJLKOsntwkTxx7pU4H10xc9Mr+xsFDs8JuWQrQTsTYPDNA@mail.gmail.com>
Message-ID: <D125E00F.121DAA%macqueen1@llnl.gov>

What is the result of

   capabilities()['tcltk']

?
-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/9/15, 2:27 PM, "Imran Akbar" <imran at infoscoutinc.com> wrote:

>Hi,
>
>I've installed the latest version of R from source on Amazon Linux with
>the
>following config flags:
>./configure --with-tcl-config=/opt/ActiveTcl-8.6/lib/tclConfig.sh
>--with-tk-config=/opt/ActiveTcl-8.6/lib/tkConfig.sh
>
>After running make and make install, I try to run R and install the
>'anesrake' package, but one of the dependencies fails with this error:
>
>error: Tcl/Tk support is not available on this system
>
>How can I fix this?
>
>regards,
>imran
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dusa.adrian at unibuc.ro  Wed Mar 11 20:27:10 2015
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Wed, 11 Mar 2015 21:27:10 +0200
Subject: [R] regex find anything which is not a number
Message-ID: <CAJ=0CtBws+3cDQkqgWD98cpFc5ysvOZEeB+DK=KLbOCJYWcEXw@mail.gmail.com>

Hi everyone,

I need a regular expression to find those positions in a character
vector which contain something which is not a number (either positive
or negative, having decimals or not).

myvector <- c("a3", "N.A", "1.2", "-3", "3-2", "2.")

In this vector, only positions 3 and 4 are numbers, the rest should be captured.
So far I am able to detect anything which is not a number, excluding - and .

> grep("[^-0-9.]", myvector)
[1] 1 2

I still need to capture positions 5 and 6, which in human language
would mean to detect anything which contains a "-" or a "." anywhere
else except at the beginning of a number.

Thanks very much in advance,
Adrian


-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania


From pdalgd at gmail.com  Wed Mar 11 20:55:14 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 11 Mar 2015 20:55:14 +0100
Subject: [R] R can't find tcl-tk
In-Reply-To: <D125E00F.121DAA%macqueen1@llnl.gov>
References: <CACHqeJLKOsntwkTxx7pU4H10xc9Mr+xsFDs8JuWQrQTsTYPDNA@mail.gmail.com>
	<D125E00F.121DAA%macqueen1@llnl.gov>
Message-ID: <1F1A151B-3044-46ED-A0F1-B6AABD0FF248@gmail.com>


> On 11 Mar 2015, at 20:05 , MacQueen, Don <macqueen1 at llnl.gov> wrote:
> 
> What is the result of
> 
>   capabilities()['tcltk']
> 
> ?

- and did the configure actually succeed, tcl-wise? Should be near the end of the output in, like

  Interfaces supported:      X11, aqua, tcltk

Also notice that if you run R on a remote connection, you may need some trickery to get an X server that the Tk parts can connect to (SSH tunnels and such.). 

> -- 
> Don MacQueen
> 
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> 
> 
> 
> 
> 
> On 3/9/15, 2:27 PM, "Imran Akbar" <imran at infoscoutinc.com> wrote:
> 
>> Hi,
>> 
>> I've installed the latest version of R from source on Amazon Linux with
>> the
>> following config flags:
>> ./configure --with-tcl-config=/opt/ActiveTcl-8.6/lib/tclConfig.sh
>> --with-tk-config=/opt/ActiveTcl-8.6/lib/tkConfig.sh
>> 
>> After running make and make install, I try to run R and install the
>> 'anesrake' package, but one of the dependencies fails with this error:
>> 
>> error: Tcl/Tk support is not available on this system
>> 
>> How can I fix this?
>> 
>> regards,
>> imran
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From john.archie.mckown at gmail.com  Wed Mar 11 21:00:38 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 11 Mar 2015 15:00:38 -0500
Subject: [R] regex find anything which is not a number
In-Reply-To: <CAJ=0CtBws+3cDQkqgWD98cpFc5ysvOZEeB+DK=KLbOCJYWcEXw@mail.gmail.com>
References: <CAJ=0CtBws+3cDQkqgWD98cpFc5ysvOZEeB+DK=KLbOCJYWcEXw@mail.gmail.com>
Message-ID: <CAAJSdjgW+K+jLSuAu3PiEA_KELLMwk=yb0r5JNcqT5Bqc1A8CA@mail.gmail.com>

See if the following will work for you:

grep('^-?[0-9]+([.]?[0-9]+)?$',myvector,perl=TRUE,invert=TRUE)

> myvector <- c("a3", "N.A", "1.2", "-3", "3-2", "2.")
> grep('^-?[0-9]+([.][0-9]+)?$',myvector,perl=TRUE,invert=TRUE)
[1] 1 2 5 6
>

The key is to match a number, and then invert the TRUE / FALSE (invert=TRUE).
^ == start of string
-? == 0 or 1 minus signs
[0-9]+ == one or more digits

optionally followed by the following via use of (...)?
[.] == an actual period. I tried to escape this, but it failed
[0-9]+ == followed by one or more digits

$ == followed by the end of the string.

so: optional minus, followed by one or more digits, optionally
followed by (a period with one or more ending digits).


On Wed, Mar 11, 2015 at 2:27 PM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
> Hi everyone,
>
> I need a regular expression to find those positions in a character
> vector which contain something which is not a number (either positive
> or negative, having decimals or not).
>
> myvector <- c("a3", "N.A", "1.2", "-3", "3-2", "2.")
>
> In this vector, only positions 3 and 4 are numbers, the rest should be captured.
> So far I am able to detect anything which is not a number, excluding - and .
>
>> grep("[^-0-9.]", myvector)
> [1] 1 2
>
> I still need to capture positions 5 and 6, which in human language
> would mean to detect anything which contains a "-" or a "." anywhere
> else except at the beginning of a number.
>
> Thanks very much in advance,
> Adrian
>
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown


From dusa.adrian at unibuc.ro  Wed Mar 11 21:20:31 2015
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Wed, 11 Mar 2015 22:20:31 +0200
Subject: [R] regex find anything which is not a number
In-Reply-To: <CAAJSdjgW+K+jLSuAu3PiEA_KELLMwk=yb0r5JNcqT5Bqc1A8CA@mail.gmail.com>
References: <CAJ=0CtBws+3cDQkqgWD98cpFc5ysvOZEeB+DK=KLbOCJYWcEXw@mail.gmail.com>
	<CAAJSdjgW+K+jLSuAu3PiEA_KELLMwk=yb0r5JNcqT5Bqc1A8CA@mail.gmail.com>
Message-ID: <CAJ=0CtBAEO=+UB0WM3FD7-601rz0GRsNA=5W2WC80UkH_022QQ@mail.gmail.com>

Perfect, perfect, perfect.
Thanks very much, John.
Adrian

On Wed, Mar 11, 2015 at 10:00 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> See if the following will work for you:
>
> grep('^-?[0-9]+([.]?[0-9]+)?$',myvector,perl=TRUE,invert=TRUE)
>
>> myvector <- c("a3", "N.A", "1.2", "-3", "3-2", "2.")
>> grep('^-?[0-9]+([.][0-9]+)?$',myvector,perl=TRUE,invert=TRUE)
> [1] 1 2 5 6
>>
>
> The key is to match a number, and then invert the TRUE / FALSE (invert=TRUE).
> ^ == start of string
> -? == 0 or 1 minus signs
> [0-9]+ == one or more digits
>
> optionally followed by the following via use of (...)?
> [.] == an actual period. I tried to escape this, but it failed
> [0-9]+ == followed by one or more digits
>
> $ == followed by the end of the string.
>
> so: optional minus, followed by one or more digits, optionally
> followed by (a period with one or more ending digits).
>
>
> On Wed, Mar 11, 2015 at 2:27 PM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
>> Hi everyone,
>>
>> I need a regular expression to find those positions in a character
>> vector which contain something which is not a number (either positive
>> or negative, having decimals or not).
>>
>> myvector <- c("a3", "N.A", "1.2", "-3", "3-2", "2.")
>>
>> In this vector, only positions 3 and 4 are numbers, the rest should be captured.
>> So far I am able to detect anything which is not a number, excluding - and .
>>
>>> grep("[^-0-9.]", myvector)
>> [1] 1 2
>>
>> I still need to capture positions 5 and 6, which in human language
>> would mean to detect anything which contains a "-" or a "." anywhere
>> else except at the beginning of a number.
>>
>> Thanks very much in advance,
>> Adrian
>>
>>
>> --
>> Adrian Dusa
>> University of Bucharest
>> Romanian Social Data Archive
>> Soseaua Panduri nr.90
>> 050663 Bucharest sector 5
>> Romania
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> He's about as useful as a wax frying pan.
>
> 10 to the 12th power microphones = 1 Megaphone
>
> Maranatha! <><
> John McKown



-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania


From amelia_marsh08 at yahoo.com  Wed Mar 11 20:00:27 2015
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Thu, 12 Mar 2015 03:00:27 +0800
Subject: [R] Gamma Distribution - is there any problem with "pgamma"?
In-Reply-To: <loom.20150311T125008-340@post.gmane.org>
Message-ID: <1426100427.94529.YahooMailBasic@web192703.mail.sg3.yahoo.com>

Dear Sir,

Thanks a lot for your help and guidance.

Regards

Amelia


--`------------------------------------------
On Wed, 11/3/15, Ben Bolker <bbolker at gmail.com> wrote:

 Subject: Re: [R] Gamma Distribution - is there any problem with "pgamma"?
 To: r-help at stat.math.ethz.ch
 Date: Wednesday, 11 March, 2015, 11:54 AM
 
 Amelia Marsh <amelia_marsh08
 <at> yahoo.com> writes:
 
 > 
 > Dear R forum
 > 
 > I have following data
 > 
 > amounts =
 c(928906.144,156091.0576,433798.3404,993425.7224,
 >  
 369967.2612,2528872.35,1226093.655,
 >
 1145446.149,1809624.453,599329.0394,2200955.213,2583318.064,
 >
 745625.8069,961828.8828,1744841.313,1939390.005,1077873.654,
 >
 729924.2713,803584.2636,287020.8529,530910.9004,818574.0089,
 > 1908133.51,262336.0893,593808.2542,780258.1354)
  
 > # Estimating Gamma distribution parameters
 > 
 > shape_gamma??? ? ?
 ??? <-? ? ???
 ??? (mean(amounts)/sd(amounts))^2 
 > 
 > scale_gamma? ? ? <-? ?
 ??? ???
 (sd(amounts)^2/mean(amounts))
 >
 
  The default parameterization of the Gamma distribution in R
 
 uses a rate parameter, not a scale parameter.? You can
 override this:
  
 Fx <-??? pgamma(amounts, shape_gamma,
 scale=scale_gamma)
 
 or
 
 Fx <-??? pgamma(amounts, shape_gamma,
 rate=1/scale_gamma)
 
 One place you can find a description of the
 parameterizations
 in R is 
 
 http://journal.r-project.org/archive/2013-1/lebauer-dietze-bolker.pdf
 
 ______________________________________________
 R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 and provide commented, minimal, self-contained, reproducible
 code.


From kmezhoud at gmail.com  Wed Mar 11 22:00:34 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 11 Mar 2015 21:00:34 +0000
Subject: [R] R can't find tcl-tk
In-Reply-To: <1F1A151B-3044-46ED-A0F1-B6AABD0FF248@gmail.com>
References: <CACHqeJLKOsntwkTxx7pU4H10xc9Mr+xsFDs8JuWQrQTsTYPDNA@mail.gmail.com>
	<D125E00F.121DAA%macqueen1@llnl.gov>
	<1F1A151B-3044-46ED-A0F1-B6AABD0FF248@gmail.com>
Message-ID: <CALJKBv9U3MqBNr5bmkZoRjzwyEjz=CLg8c6QMJ+v3QZQXJ7Y5w@mail.gmail.com>

Hi,$I had this problem,
delete all and reconfigure ONLY with:
cd /tools
./rsyns.....
cd ..
./configure --enable-R-shlib
make
make install

be sure to be in your  /home


kmezhoud

On Wed, Mar 11, 2015 at 7:55 PM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> > On 11 Mar 2015, at 20:05 , MacQueen, Don <macqueen1 at llnl.gov> wrote:
> >
> > What is the result of
> >
> >   capabilities()['tcltk']
> >
> > ?
>
> - and did the configure actually succeed, tcl-wise? Should be near the end
> of the output in, like
>
>   Interfaces supported:      X11, aqua, tcltk
>
> Also notice that if you run R on a remote connection, you may need some
> trickery to get an X server that the Tk parts can connect to (SSH tunnels
> and such.).
>
> > --
> > Don MacQueen
> >
> > Lawrence Livermore National Laboratory
> > 7000 East Ave., L-627
> > Livermore, CA 94550
> > 925-423-1062
> >
> >
> >
> >
> >
> > On 3/9/15, 2:27 PM, "Imran Akbar" <imran at infoscoutinc.com> wrote:
> >
> >> Hi,
> >>
> >> I've installed the latest version of R from source on Amazon Linux with
> >> the
> >> following config flags:
> >> ./configure --with-tcl-config=/opt/ActiveTcl-8.6/lib/tclConfig.sh
> >> --with-tk-config=/opt/ActiveTcl-8.6/lib/tkConfig.sh
> >>
> >> After running make and make install, I try to run R and install the
> >> 'anesrake' package, but one of the dependencies fails with this error:
> >>
> >> error: Tcl/Tk support is not available on this system
> >>
> >> How can I fix this?
> >>
> >> regards,
> >> imran
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From erich.neuwirth at univie.ac.at  Wed Mar 11 23:41:53 2015
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Wed, 11 Mar 2015 23:41:53 +0100
Subject: [R] tcltk problem
Message-ID: <E691E95A-64EF-43F3-A63F-11C65CA0242F@univie.ac.at>

OSX 10.10.2
R 3.1.3
XQuartz installed.

I am trying to run one of the tcltk demos
This one works:

tt <- tktoplevel()
label.widget <- tklabel(tt, text = "Hello, World!")
button.widget <- tkbutton(tt, text = "Push",
                          command = function()cat("OW!\n"))
tkpack(label.widget, button.widget) # geometry manager
                                    # see Tk-commands


But the next one breaks:
> if(as.character(tcl("info", "tclversion")) >= "8.5") {
+   # make use of themed widgets
+   # list themes
+   as.character(tcl("ttk::style", "theme", "names"))
+   # select a theme -- here pre-XP windows
+   tcl("ttk::style", "theme use", "winnative")
+ } else {
+   # use Tk 8.0 widgets
+ }
Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
  [tcl] bad command "theme use": must be configure, map, lookup, layout, theme, or element.

What is going wrong here?

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150311/c0310ba3/attachment.bin>

From HDoran at air.org  Thu Mar 12 00:47:19 2015
From: HDoran at air.org (Doran, Harold)
Date: Wed, 11 Mar 2015 23:47:19 +0000
Subject: [R] twitteR and wordcloud()
Message-ID: <D1264C45.249F9%hdoran@air.org>

I am trying to replicate the twitter and word cloud example found here

https://sites.google.com/site/miningtwitter/questions/talking-about/wordclouds/wordcloud1

When implemented verbatim, I replicate results and all works fine. But, when I make a slight modification to the code it fails in creating the tdm matrix. I found only one other question on this same topic at stack overflow with no answer leading to a solution.

Here is my code for a reproducible example, though you would need the twitteR tokens etc to run this on your own.

Any idea why the tdm step fails?

library(twitteR)
library(tm)
library(wordcloud)
library(RColorBrewer)

mach_tweets = searchTwitter("#machine", n=50, lang="en")
mach_text = sapply(mach_tweets, function(x) x$getText())
mach_corpus = Corpus(VectorSource(mach_text))

# create document term matrix applying some transformations
tdm = TermDocumentMatrix(mach_corpus,
   control = list(removePunctuation = TRUE,
   #stopwords = c(stopwords()),
   removeNumbers = TRUE, tolower = TRUE))

   # define tdm as matrix
m = as.matrix(tdm)
# get word counts in decreasing order
word_freqs = sort(rowSums(m), decreasing=TRUE)
# create a data frame with words and their frequencies
dm = data.frame(word=names(word_freqs), freq=word_freqs)

wordcloud(dm$word, dm$freq, random.order=FALSE, colors=brewer.pal(8, "Dark2?))



In fact, earlier today on a different computer than I am working on now, I wrote the following function and it works perfectly

tweets <- function(string, n, min){
                tweets <- searchTwitter(as.character(string), n=n)
                tweets_text <- sapply(tweets, function(x) x$getText())
                tweets_text_corpus <- Corpus(VectorSource(tweets_text))
                tweets_text_corpus <- tm_map(tweets_text_corpus, removePunctuation)
                tweets_text_corpus <- tm_map(tweets_text_corpus, function(x)removeWords(x,stopwords()))
                #wordcloud(tweets_text_corpus)
                myDtm <- TermDocumentMatrix(tweets_text_corpus, control = list(minWordLength = 1))
                m <- as.matrix(myDtm)
                v <- sort(rowSums(m), decreasing=TRUE)
                #wordcloud(names(v), v, scale = c(4,2), min.freq= min )
                v
                }

v <- tweets('#beer', n= 20)

But, when I run it on my Mac at home it also fails at the tdm step.

	[[alternative HTML version deleted]]


From kp1005 at gmail.com  Thu Mar 12 07:08:31 2015
From: kp1005 at gmail.com (Kruti Pandya)
Date: Wed, 11 Mar 2015 23:08:31 -0700
Subject: [R] reading multiple text files from web
Message-ID: <CAORW=u44SbDxe=3yEpc=RUC-2rJQ7J+Mq_Wcpj_y6Oeo1_bm0Q@mail.gmail.com>

I am trying to extract information ?OS Vendor? and ?OS Name? from the
following text file online.

http://spec.org/jEnterprise2010/results/res2013q3/jEnterprise2010-20130904-00045.txt


 My goal is to extract these two attributes from all the text files
available from  this link given below and put it in a dataframe as follows.

OS Vendor                                OS Name

Oracle Corporation    Oracle Solaris 11.1 64-bit SRU 10.5"k

Text files link :
https://www.spec.org/jEnterprise2010/results/jEnterprise2010.html


I got a list of all text files from the HTML page. I am trying to
write a function that can pick one link at a time from getlinks and
extract the attributes and then put it in a dataframe.  I do not know
how to read the files from getlinks object that contains the links.  I
tried converting getlinks to a dataframe via as.data.frame(getlinks)
but that got rid of the quotes that I need in order to read them one
by one. Also once I get the attributes how do I put them side by side
in the dataframe format.


###code#########

install.packages(c("RCurl","XML"))

library(bitops)

library(RCurl)

library(XML)

webpage = htmlParse("http://spec.org/jEnterprise2010/results/jEnterprise2010.html",error=function(...){},
useInternalNodes = TRUE)

links<- xpathSApply(webpage,"//a/@href")

getlinks<-links[grep(".txt",links)]

######### function to read all text files and extract attributes##########

readfiles=function(x) { a<-readLines(x)


sm <- "Java EE AppServer & Database Server HW (SUT
hardware)"


s<-grep(sm, a, fixed=TRUE)


e<-grep("^\\S", a[-(1:s)])[1]


grep("OS Vendor", a[(s+1):(s+e-1)], fixed=T, value=T)[1]

grep("OS Name", a[(s+1):(s+e-1)], fixed=T,
value=T)[1]

}

######### For single file was able to extract the attributes #########

txt1<-readLines("http://spec.org/jEnterprise2010/results/res2013q3/jEnterprise2010-20130904-00045.txt")

#Get the OS Vendor and OS Name

sm<- "Java EE AppServer & Database Server HW (SUT hardware)"

s<-grep(sm,txt1, fixed=TRUE)

e<-grep("^\\S",txt1[-(1:s)])[1]

grep("OS Vendor", txt1[(s+1):(s+e-1)], fixed=T, value=T)[1]


grep("OS Name", txt1[(s+1):(s+e-1)], fixed=T, value=T)[1]


Will appreciate any help !


Thanks.

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Thu Mar 12 08:35:22 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Thu, 12 Mar 2015 07:35:22 +0000
Subject: [R] tcltk problem
In-Reply-To: <E691E95A-64EF-43F3-A63F-11C65CA0242F@univie.ac.at>
References: <E691E95A-64EF-43F3-A63F-11C65CA0242F@univie.ac.at>
Message-ID: <CALJKBv97oQz06m9bN9NTGr0=R2L9vst0U1FUszctOb0=H_p3gw@mail.gmail.com>

Hi,
Here same working example.
http://mcu.edu.tw/~chenmh/teaching/project/r/reference/RTclTkExamples/
Best,
Karim

On Wed, Mar 11, 2015 at 10:41 PM, Erich Neuwirth <
erich.neuwirth at univie.ac.at> wrote:

> OSX 10.10.2
> R 3.1.3
> XQuartz installed.
>
> I am trying to run one of the tcltk demos
> This one works:
>
> tt <- tktoplevel()
> label.widget <- tklabel(tt, text = "Hello, World!")
> button.widget <- tkbutton(tt, text = "Push",
>                           command = function()cat("OW!\n"))
> tkpack(label.widget, button.widget) # geometry manager
>                                     # see Tk-commands
>
>
> But the next one breaks:
> > if(as.character(tcl("info", "tclversion")) >= "8.5") {
> +   # make use of themed widgets
> +   # list themes
> +   as.character(tcl("ttk::style", "theme", "names"))
> +   # select a theme -- here pre-XP windows
> +   tcl("ttk::style", "theme use", "winnative")
> + } else {
> +   # use Tk 8.0 widgets
> + }
> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>   [tcl] bad command "theme use": must be configure, map, lookup, layout,
> theme, or element.
>
> What is going wrong here?
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From popx at j-paine.org  Thu Mar 12 08:55:53 2015
From: popx at j-paine.org (Jocelyn Ireson-Paine)
Date: Thu, 12 Mar 2015 07:55:53 +0000 (GMT)
Subject: [R] How to filter data using sets generated by flattening with
 dcast, when I can't store those sets in a data frame
Message-ID: <alpine.LRH.2.02.1503120748540.25235@sphinx.mythic-beasts.com>

This is a fairly long question. It's about a problem that's easy to 
specify in terms of sets, but that I found hard to solve in R by using 
them, because of the strange design of R data structures. In explaining 
it, I'm going to touch on the reshape2 library, dcast, sets, and the 
non-orthogonality of R.

My problem stems from some drug-trial data that I've been analysing for 
the Oxford Pain Research Unit. Here's an example. Imagine a data frame 
representing patients in a trial of pain-relief drugs. The trial lasts for 
ten days. Each patient's pain is measured once a day, and the values are 
recorded in a data frame, one row per patient per day. Like this:

   ID  Day  Pain
    1    1  10
    1    2   9
    1    4   7
    1    7   2
    2    2   8
    2    3   7
    3    1  10
    3    3   6
    3    4   6
    3    8   2

Unfortunately, many patients have measurements missing. Thus, in the 
example above, patient 1 was only observed on days 1, 2, 4, and 7, rather 
than on the full ten days. But a patient's measurements are only useful to 
us if that patient has a certain minimum set of days, so I need to check 
for patients who lack those days. Let's assume that these days are numbers 
1, 4, and 9.

Such a question is trivial to state in terms of sets. Let D(i) denote the 
set of days on which patient i was measured: then I want to find out which 
patients p, or how many patients p, have a D(p) that contains the set 
{1,4,9}.

The obvious way to solve this is to write a function that tells me whether 
one set is a superset of another. Then flatten my data frame so that it 
looks like this:

   ID  Days
    1  {1,2,4,7}
    2  {2,3}
    3  {1,3,4,8}

And finally, filter it by some R translation of

   flattened[ includes( flattened$Days, {1,4,9} ), ]

I started with the built-in functions that operate on sets represented as 
vectors. These are described in
  https://stat.ethz.ch/R-manual/R-devel/library/base/html/sets.html ,
"Set Operations". For example:

   > union( c(1,2,3), c(2,4,6) )
   [1] 1 2 3 4 6
   > intersect( c(1,2,3), c(2,4,6) )
   [1] 2

So I first wrote a set-inclusion function:

   # True if vector a is a superset of vector b.
   #
   includes <- function( a, b )
   {
     return( setequal( union( a, b ), a ) )
   }

Here are some sample calls:

   > includes( c(1), c() )
   [1] TRUE
   > includes( c(1), c(1) )
   [1] TRUE
   > includes( c(1), c(1,2) )
   [1] FALSE
   > includes( c(2,1), c(1,2) )
   [1] TRUE
   > includes( c(2,1,3), c(1,2) )
   [1] TRUE
   > includes( c(2,1,3), c(4,1,2) )
   [1] FALSE

I then made myself a variable holding my sample data frame:

   df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
                   , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
                   )

And I tried flattening it, using dcast and an aggregator function as 
described in (amongst many other places) 
http://seananderson.ca/2013/10/19/reshape.html , "An Introduction to 
reshape2" by Sean C. Anderson.

The idea behind this is that (for my data) dcast will call the aggregator 
function once per patient ID, passing it all the Day values for the 
patient. The aggregator must combine them in some way, and dcast puts its 
results into a new column. For example, here's an aggregator that merely 
sums its arguments:

   aggregator_making_sum <- function( ... )
   {
     return( sum( ... ) )
   }

If I call it, I get this:

   >  dcast( df, ID~. , fun.aggregate=aggregator_making_sum )
   Using Day as value column: use value.var to override.
     ID  .
   1  1 14
   2  2  5
   3  3 16

And here's an aggregator that converts the argument list to a string:

   aggregator_making_string <- function( ... )
   {
     return( toString( ... ) )
   }

Calling it gives this:

   >  dcast( df, ID~. , fun.aggregate=aggregator_making_string )
   Using Day as value column: use value.var to override.
     ID          .
   1  1 1, 2, 4, 7
   2  2       2, 3
   3  3 1, 3, 4, 8

In both of these, the three dots denote all arguments to the aggregator, 
as explained in Burns Statistics's 
http://www.burns-stat.com/the-three-dots-construct-in-r/ . My first 
aggregator sums them; my second converts them to a string. Both uses of 
dcast generate a data frame with a column named "." , which contains the 
aggregates. In the second data frame, that may not be so clear: the first 
column of numbers is row numbers; the second column of numbers are the 
IDs; and the remaining columns form the strings, belonging to "." .

But what I want is neither a sum nor a string but a set. Specifically, a 
set that's compatible with the R set operations I called in my 'includes' 
function. Since these sets are vectors, my aggregator should just pack its 
arguments into a vector:

   aggregator_making_set <- function( ... )
   {
     return( c( ... ) )
   }

But when I tried it, I got an error:

   > dcast( df, ID~. , fun.aggregate=aggregator_making_set )
   Using Day as value column: use value.var to override.
   Error in vapply(indices, fun, .default) : values must be length 0,
    but FUN(X[[1]]) result is length 4

It's not an informative error message, because it expects me to know how 
dcast is coded. And I'm surprised that values need to be length 0: length 
1 would seem more appropriate. But perhaps it's trying to say that 'c' 
doesn't work on three-dots argument lists. Let's test that hypothesis:

   test_c_on_three_dots <- function( ... )
   {
     return( c( ... ) )
   }

   >   test_c_on_three_dots( 1 )
   [1] 1
   >   test_c_on_three_dots( 1, 2 )
   [1] 1 2
   >   test_c_on_three_dots( 1, 2, 3 )
   [1] 1 2 3

So 'c' does indeed work on three-dots argument lists. The error must have 
been caused by something else. Let's try making a set and putting it into 
a data frame directly:

   > df <- data.frame( col1=c(1,2), col2=c(3,4) )
   > df
     col1 col2
   1    1    3
   2    2    4
   > set <- union( c(5,6), c(6,7) )
   > set
   [1] 5 6 7
   > df[ 1, ]$col1 <- set
   Error in `$<-.data.frame`(`*tmp*`, "col1", value = c(5, 6, 7)) :
     replacement has 3 rows, data has 1

So that's the problem. Already in 1968, there was a language named Algol68 
which had arrays and, in order to make things easy for its programmers, 
allowed you to create arrays of every data type the language provided. You 
could have arrays of Booleans, arrays of integers, arrays of records, 
arrays of discriminated unions, arrays of procedures, arrays of I/O 
formats, arrays of pointers, and arrays of arrays. The idea was 
"orthogonality" (see for example 
http://stackoverflow.com/questions/1527393/what-is-orthogonality ): that 
the programmer does not have to think about unexpected interactions 
between the concept of array and the concept of the element type, because 
there are none. If you have a data type, you can make arrays of that type. 
Pop-2 (1970), Snobol4 (1966), and Lisp (1958) were similarly generous. But 
R (1993) isn't. It wants to make life hard by forcing me to use different 
kinds of container for different kinds of element. And by providing a nice 
implementation of sets and then not letting me store them.

So I thought about the kinds of data that I _can_ store in a data frame 
and generate by flattening. Strings! So I decided to use my 
aggregator_making_string function to make a string representation of the 
set of days, and to write a set-inclusion function that compared these 
sets against sets represented as vectors:

   includes2 <- function( a_as_string, b )
   {
     a <- as.numeric( unlist( strsplit( a_as_string, split="," ) ) )
     return( setequal( union( a, b ), a ) )
   }

Here are some example calls:

   > includes2( '1,2,3', c(1) )
   [1] TRUE
   > includes2( '1,2,3', c(1,2) )
   [1] TRUE
   > includes2( '1,2,3', c(1,2,4) )
   [1] FALSE
   > includes2( '1,2,3', c(3) )
   [1] TRUE
   > includes2( '1,2,3', c(0,3) )
   [1] FALSE
   >

I then tried using it:

   df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
                   , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
                   )

   aggregator_making_string <- function( ... )
   {
     return( toString( ... ) )
   }

   flattened <- dcast( df, ID~. , fun.aggregate=aggregator_making_string )

   # Which patients have a day 1?
   flattened[ includes2( flattened$. , c(1) ), ]

Unfortunately, that didn't work. The final statement selected every row of 
'flattened'. I eventually realised that I had to vectorise 'includes2':

   includes3 <- Vectorize( includes2, "a_as_string" )

And that did work:

   >   flattened[ includes3( flattened$. , c(1) ), ]
     ID          .
   1  1 1, 2, 4, 7
   3  3 1, 3, 4, 8
   >   flattened[ includes3( flattened$. , c(1,2) ), ]
     ID          .
   1  1 1, 2, 4, 7
   >   flattened[ includes3( flattened$. , c(1,3) ), ]
     ID          .
   3  3 1, 3, 4, 8
   >   flattened[ includes3( flattened$. , c(2) ), ]
     ID          .
   1  1 1, 2, 4, 7
   2  2       2, 3

The moral of this email tale is that sets are really useful for filtering 
data, and dcast ought to be really useful for generating sets, but R 
refuses to let me store them in the data frame that dcast generates. I can 
fudge it by representing the sets as strings, but is there a cleaner way 
to solve the problem?

Cheers,

Jocelyn Ireson-Paine
07768 534 091
http://www.jocelyns-cartoons.uk
http://www.j-paine.org


From miaojpm at gmail.com  Thu Mar 12 09:04:05 2015
From: miaojpm at gmail.com (jpm miao)
Date: Thu, 12 Mar 2015 16:04:05 +0800
Subject: [R] Extracting slots from an object (e.g.: object produced by unit
 root test function "urdfTest")
Message-ID: <CABcx46DBznU0WDJh6x+jByW2RSBaa8QeNsQMMXFxkhRxFn=pSQ@mail.gmail.com>

Hi,

   I run a statistical test function in the package "fUnitRoots" that
returns a S4 object but I am wondering how to extract the p-value, one of
the output elements.

The document of the function "urdfTest":
.....
All tests return an object of class "fHTEST" with the following slots:

@call
.....
@test
a list object which holds the output of the underlying test function.
@title
.....
The entries of the @test slot include the following components:

$statistic
......
$p.value
the p-value of the test.
.....
(end)

   I store the result of the test test in an element of a list
(adf1["r3m"][[1]]), and I want to extract the p-value. I was expecting the
p-value via adf1["r3m"][[1]]@test$p.value but it gives only an error
message. Could someone tell me how to extract the p-value? Thanks!!!

>adf1["r3m"][[1]]<-urdfTest(dat[,i], lags = 1, type = "ct")
> adf1["r3m"][[1]]
 [1] "  "
 [2] "  Test regression trend "
 [3] "  "
 [4] "  Call:"
 [5] "  lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)"
 [6] "  "
 [7] "  Residuals:"
 [8] "      Min      1Q  Median      3Q     Max "
 [9] "  -3.0785 -0.0485  0.0072  0.0627  3.5672 "
[10] "  "
[11] "  Coefficients:"
[12] "                Estimate Std. Error t value Pr(>|t|)    "
[13] "  (Intercept) -1.733e-02  9.529e-03  -1.818  0.06910 .  "
[14] "  z.lag.1     -7.060e-03  2.343e-03  -3.013  0.00261 ** "
[15] "  tt           5.299e-06  4.927e-06   1.076  0.28221    "
[16] "  z.diff.lag  -1.035e-01  1.859e-02  -5.569 2.81e-08 ***"
[17] "  ---"
[18] "  Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1"
[19] "  "
[20] "  Residual standard error: 0.2107 on 2864 degrees of freedom"
[21] "  Multiple R-squared:  0.01461,\tAdjusted R-squared:  0.01358 "
[22] "  F-statistic: 14.15 on 3 and 2864 DF,  p-value: 3.716e-09"
[23] "  "
[24] "  "
[25] "  Value of test-statistic is: -3.0134 3.0697 4.5828 "
[26] "  "
[27] "  Critical values for test statistics: "
[28] "        1pct  5pct 10pct"
[29] "  tau3 -3.96 -3.41 -3.12"
[30] "  phi2  6.09  4.68  4.03"
[31] "  phi3  8.27  6.25  5.34"

> adf1["r3m"][[1]]@test
Error: trying to get slot "test" from an object of a basic class
("character") with no slots
> adf1["r3m"][[1]]@test$p-value
Error: trying to get slot "test" from an object of a basic class
("character") with no slots

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Mar 12 09:04:48 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 12 Mar 2015 09:04:48 +0100
Subject: [R] tcltk problem
In-Reply-To: <E691E95A-64EF-43F3-A63F-11C65CA0242F@univie.ac.at>
References: <E691E95A-64EF-43F3-A63F-11C65CA0242F@univie.ac.at>
Message-ID: <208B6895-F6E5-4C65-80C0-BCB97BAF929C@gmail.com>


> On 11 Mar 2015, at 23:41 , Erich Neuwirth <erich.neuwirth at univie.ac.at> wrote:
> 
> OSX 10.10.2
> R 3.1.3
> XQuartz installed.
> 
> I am trying to run one of the tcltk demos

Which demos? Doesn't look like any the ones in the package. 

(Please at least be specific when you imply that someone is publishing bad code.)

> This one works:
> 
> tt <- tktoplevel()
> label.widget <- tklabel(tt, text = "Hello, World!")
> button.widget <- tkbutton(tt, text = "Push",
>                          command = function()cat("OW!\n"))
> tkpack(label.widget, button.widget) # geometry manager
>                                    # see Tk-commands
> 
> 
> But the next one breaks:
>> if(as.character(tcl("info", "tclversion")) >= "8.5") {
> +   # make use of themed widgets
> +   # list themes
> +   as.character(tcl("ttk::style", "theme", "names"))
> +   # select a theme -- here pre-XP windows
> +   tcl("ttk::style", "theme use", "winnative")
> + } else {
> +   # use Tk 8.0 widgets
> + }
> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>  [tcl] bad command "theme use": must be configure, map, lookup, layout, theme, or element.
> 
> What is going wrong here?

Presumably "theme use" wants to be "theme", "use".

(Many moons ago, tcl() just pasted words together and executed the result as a Tcl command via .Tcl. Looks like the author expected .Tcl("ttk::style theme use winnative"), but nowadays it uses .Tcl.objv() which expects a vector of Tcl words so there is a difference between two words and one word with a space in the middle. The puzzling bit is that I'd have thunk Tcl 8.5 to be considerably later than the change to tcl()?)


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From erich.neuwirth at univie.ac.at  Thu Mar 12 09:13:00 2015
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Thu, 12 Mar 2015 09:13:00 +0100
Subject: [R] tcltk problem
In-Reply-To: <208B6895-F6E5-4C65-80C0-BCB97BAF929C@gmail.com>
References: <E691E95A-64EF-43F3-A63F-11C65CA0242F@univie.ac.at>
	<208B6895-F6E5-4C65-80C0-BCB97BAF929C@gmail.com>
Message-ID: <6FB65074-646B-4FD9-A301-C3360AC837E8@univie.ac.at>

Thesw are demos for
tclscrollbar
I copied them from the help file to the console manually
as the help file suggested.
> On 12 Mar 2015, at 09:04, peter dalgaard <pdalgd at gmail.com> wrote:
> 
>> 
>> On 11 Mar 2015, at 23:41 , Erich Neuwirth <erich.neuwirth at univie.ac.at <mailto:erich.neuwirth at univie.ac.at>> wrote:
>> 
>> OSX 10.10.2
>> R 3.1.3
>> XQuartz installed.
>> 
>> I am trying to run one of the tcltk demos
> 
> Which demos? Doesn't look like any the ones in the package.
> 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150312/043e81df/attachment.bin>

From erich.neuwirth at univie.ac.at  Thu Mar 12 09:17:08 2015
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Thu, 12 Mar 2015 09:17:08 +0100
Subject: [R] tcltk problem
In-Reply-To: <208B6895-F6E5-4C65-80C0-BCB97BAF929C@gmail.com>
References: <E691E95A-64EF-43F3-A63F-11C65CA0242F@univie.ac.at>
	<208B6895-F6E5-4C65-80C0-BCB97BAF929C@gmail.com>
Message-ID: <0C2AF242-6156-40E1-A3AA-0F9329A0DB29@univie.ac.at>

Sorry,
I get at these demo when I do
?tkscrollbar
Then the help file for many of the UI widgets appears, titled
TkWidgets {tcltk}
On the bottom of this file are the 2 examples I mentioned.
Excuse the incomplete description in the first and the incorrect description in the second message.





> On 12 Mar 2015, at 09:04, peter dalgaard <pdalgd at gmail.com> wrote:
> 
>> 
>> On 11 Mar 2015, at 23:41 , Erich Neuwirth <erich.neuwirth at univie.ac.at <mailto:erich.neuwirth at univie.ac.at>> wrote:
>> 
>> OSX 10.10.2
>> R 3.1.3
>> XQuartz installed.
>> 
>> I am trying to run one of the tcltk demos
> 
> Which demos? Doesn't look like any the ones in the package.
> 
> (Please at least be specific when you imply that someone is publishing bad code.)
> 
>> This one works:
>> 
>> tt <- tktoplevel()
>> label.widget <- tklabel(tt, text = "Hello, World!")
>> button.widget <- tkbutton(tt, text = "Push",
>>                         command = function()cat("OW!\n"))
>> tkpack(label.widget, button.widget) # geometry manager
>>                                   # see Tk-commands
>> 
>> 
>> But the next one breaks:
>>> if(as.character(tcl("info", "tclversion")) >= "8.5") {
>> +   # make use of themed widgets
>> +   # list themes
>> +   as.character(tcl("ttk::style", "theme", "names"))
>> +   # select a theme -- here pre-XP windows
>> +   tcl("ttk::style", "theme use", "winnative")
>> + } else {
>> +   # use Tk 8.0 widgets
>> + }
>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>> [tcl] bad command "theme use": must be configure, map, lookup, layout, theme, or element.
>> 
>> What is going wrong here?
> 
> Presumably "theme use" wants to be "theme", "use".
> 
> (Many moons ago, tcl() just pasted words together and executed the result as a Tcl command via .Tcl. Looks like the author expected .Tcl("ttk::style theme use winnative"), but nowadays it uses .Tcl.objv() which expects a vector of Tcl words so there is a difference between two words and one word with a space in the middle. The puzzling bit is that I'd have thunk Tcl 8.5 to be considerably later than the change to tcl()?)
> 
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk <mailto:pd.mes at cbs.dk>  Priv: PDalgd at gmail.com <mailto:PDalgd at gmail.com>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150312/444522b0/attachment.bin>

From vik at vlr.cc  Thu Mar 12 10:20:37 2015
From: vik at vlr.cc (Vik Rubenfeld)
Date: Thu, 12 Mar 2015 02:20:37 -0700
Subject: [R] Using choiceDes Package to Design MaxDiff?
Message-ID: <FBF4B7C9-76BE-4A00-B9EC-B4B50886A432@vlr.cc>

I?m seeking to design a MaxDiff experiment that will have a number of blocks of this type:

Which of these items is the
most important?

Which of these items is the 
least important?

Item 1
Item 2
Item 3
Item 4

I?m seeking to use the choiceDes package <http://cran.r-project.org/web/packages/choiceDes/choiceDes.pdf> to design the experiment. The relevant function is tradeoff.des. Usage:

tradeoff.des(items, shown, vers, tasks, fname=NULL, Rd=20, Rc=NULL, print=TRUE)

I believe I understand the items, shown and vers parameters:
items: number of total items in the experiment
show: number of items shown per block
vers: number of blocks
...but I?m not quite sure what the tasks parameter is yet. For example, let?s say I have 20 items total in the study. I want to show 4 items per block, with 10 blocks total. I enter:

tempDes <- tradeoff.des(20, 4, 10, 2, "tempDesign.txt", 20, NULL, TRUE)

?hoping that the 2 is the number of questions (most important/least important) per block. I get an error:

Error in optBlock(~., des.d, rep(tasks, vers), nRepeats = Rd) : 
  The number of withinData rows is not large enough to support the blocked model.

If I put the number of blocks up to 50:

 tempDes <- tradeoff.des(20, 4, 50, 2, "tempDesign.txt", 20, NULL, TRUE)

?I get the same error. 

What is the correct way to use choiceDes to design a MaxDiff experiment of this kind?

Thanks very much in advance to all for any thoughts or info!

Best,


-Vik



	[[alternative HTML version deleted]]


From dnbarron at gmail.com  Thu Mar 12 10:20:28 2015
From: dnbarron at gmail.com (David Barron)
Date: Thu, 12 Mar 2015 09:20:28 +0000
Subject: [R] How to filter data using sets generated by flattening with
 dcast, when I can't store those sets in a data frame
In-Reply-To: <alpine.LRH.2.02.1503120748540.25235@sphinx.mythic-beasts.com>
References: <alpine.LRH.2.02.1503120748540.25235@sphinx.mythic-beasts.com>
Message-ID: <CAHuze_K1FaONNS622WyrWtueiU2LJQXvA+bdvairL6fivG5+xQ@mail.gmail.com>

Most of this question is over my head, I'm afraid, but looking at what
I think is the crux of your question, couldn't you achieve the results
you want in two steps, like this:

dta <- data.frame(ID=c(1,1,1,1,2,2,3,3,3,3),
Day=c(1,2,4,7,2,3,1,3,4,8),Pain=c(10,9,7,2,8,7,10,6,6,2))

l1 <- tapply(dta$Day, dta$ID, function(x) x)

sapply(l1, function(x) all(c(1,4,8) %in% x ))

I'm not sure you really need to do it in two steps, but given you said
you wanted a flattened data frame with the Days as a vector, this will
give it to you.  Actually, l1 is a list, but you can turn it in to a
data frame if you really want to.  In the sapply call I changed the
days required to 1, 4 and 8 to show that it does return TRUE if there
is a patient that meets the required criterion.

David

On 12 March 2015 at 07:55, Jocelyn Ireson-Paine <popx at j-paine.org> wrote:
> This is a fairly long question. It's about a problem that's easy to specify
> in terms of sets, but that I found hard to solve in R by using them, because
> of the strange design of R data structures. In explaining it, I'm going to
> touch on the reshape2 library, dcast, sets, and the non-orthogonality of R.
>
> My problem stems from some drug-trial data that I've been analysing for the
> Oxford Pain Research Unit. Here's an example. Imagine a data frame
> representing patients in a trial of pain-relief drugs. The trial lasts for
> ten days. Each patient's pain is measured once a day, and the values are
> recorded in a data frame, one row per patient per day. Like this:
>
>   ID  Day  Pain
>    1    1  10
>    1    2   9
>    1    4   7
>    1    7   2
>    2    2   8
>    2    3   7
>    3    1  10
>    3    3   6
>    3    4   6
>    3    8   2
>
> Unfortunately, many patients have measurements missing. Thus, in the example
> above, patient 1 was only observed on days 1, 2, 4, and 7, rather than on
> the full ten days. But a patient's measurements are only useful to us if
> that patient has a certain minimum set of days, so I need to check for
> patients who lack those days. Let's assume that these days are numbers 1, 4,
> and 9.
>
> Such a question is trivial to state in terms of sets. Let D(i) denote the
> set of days on which patient i was measured: then I want to find out which
> patients p, or how many patients p, have a D(p) that contains the set
> {1,4,9}.
>
> The obvious way to solve this is to write a function that tells me whether
> one set is a superset of another. Then flatten my data frame so that it
> looks like this:
>
>   ID  Days
>    1  {1,2,4,7}
>    2  {2,3}
>    3  {1,3,4,8}
>
> And finally, filter it by some R translation of
>
>   flattened[ includes( flattened$Days, {1,4,9} ), ]
>
> I started with the built-in functions that operate on sets represented as
> vectors. These are described in
>  https://stat.ethz.ch/R-manual/R-devel/library/base/html/sets.html ,
> "Set Operations". For example:
>
>   > union( c(1,2,3), c(2,4,6) )
>   [1] 1 2 3 4 6
>   > intersect( c(1,2,3), c(2,4,6) )
>   [1] 2
>
> So I first wrote a set-inclusion function:
>
>   # True if vector a is a superset of vector b.
>   #
>   includes <- function( a, b )
>   {
>     return( setequal( union( a, b ), a ) )
>   }
>
> Here are some sample calls:
>
>   > includes( c(1), c() )
>   [1] TRUE
>   > includes( c(1), c(1) )
>   [1] TRUE
>   > includes( c(1), c(1,2) )
>   [1] FALSE
>   > includes( c(2,1), c(1,2) )
>   [1] TRUE
>   > includes( c(2,1,3), c(1,2) )
>   [1] TRUE
>   > includes( c(2,1,3), c(4,1,2) )
>   [1] FALSE
>
> I then made myself a variable holding my sample data frame:
>
>   df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
>                   , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
>                   )
>
> And I tried flattening it, using dcast and an aggregator function as
> described in (amongst many other places)
> http://seananderson.ca/2013/10/19/reshape.html , "An Introduction to
> reshape2" by Sean C. Anderson.
>
> The idea behind this is that (for my data) dcast will call the aggregator
> function once per patient ID, passing it all the Day values for the patient.
> The aggregator must combine them in some way, and dcast puts its results
> into a new column. For example, here's an aggregator that merely sums its
> arguments:
>
>   aggregator_making_sum <- function( ... )
>   {
>     return( sum( ... ) )
>   }
>
> If I call it, I get this:
>
>   >  dcast( df, ID~. , fun.aggregate=aggregator_making_sum )
>   Using Day as value column: use value.var to override.
>     ID  .
>   1  1 14
>   2  2  5
>   3  3 16
>
> And here's an aggregator that converts the argument list to a string:
>
>   aggregator_making_string <- function( ... )
>   {
>     return( toString( ... ) )
>   }
>
> Calling it gives this:
>
>   >  dcast( df, ID~. , fun.aggregate=aggregator_making_string )
>   Using Day as value column: use value.var to override.
>     ID          .
>   1  1 1, 2, 4, 7
>   2  2       2, 3
>   3  3 1, 3, 4, 8
>
> In both of these, the three dots denote all arguments to the aggregator, as
> explained in Burns Statistics's
> http://www.burns-stat.com/the-three-dots-construct-in-r/ . My first
> aggregator sums them; my second converts them to a string. Both uses of
> dcast generate a data frame with a column named "." , which contains the
> aggregates. In the second data frame, that may not be so clear: the first
> column of numbers is row numbers; the second column of numbers are the IDs;
> and the remaining columns form the strings, belonging to "." .
>
> But what I want is neither a sum nor a string but a set. Specifically, a set
> that's compatible with the R set operations I called in my 'includes'
> function. Since these sets are vectors, my aggregator should just pack its
> arguments into a vector:
>
>   aggregator_making_set <- function( ... )
>   {
>     return( c( ... ) )
>   }
>
> But when I tried it, I got an error:
>
>   > dcast( df, ID~. , fun.aggregate=aggregator_making_set )
>   Using Day as value column: use value.var to override.
>   Error in vapply(indices, fun, .default) : values must be length 0,
>    but FUN(X[[1]]) result is length 4
>
> It's not an informative error message, because it expects me to know how
> dcast is coded. And I'm surprised that values need to be length 0: length 1
> would seem more appropriate. But perhaps it's trying to say that 'c' doesn't
> work on three-dots argument lists. Let's test that hypothesis:
>
>   test_c_on_three_dots <- function( ... )
>   {
>     return( c( ... ) )
>   }
>
>   >   test_c_on_three_dots( 1 )
>   [1] 1
>   >   test_c_on_three_dots( 1, 2 )
>   [1] 1 2
>   >   test_c_on_three_dots( 1, 2, 3 )
>   [1] 1 2 3
>
> So 'c' does indeed work on three-dots argument lists. The error must have
> been caused by something else. Let's try making a set and putting it into a
> data frame directly:
>
>   > df <- data.frame( col1=c(1,2), col2=c(3,4) )
>   > df
>     col1 col2
>   1    1    3
>   2    2    4
>   > set <- union( c(5,6), c(6,7) )
>   > set
>   [1] 5 6 7
>   > df[ 1, ]$col1 <- set
>   Error in `$<-.data.frame`(`*tmp*`, "col1", value = c(5, 6, 7)) :
>     replacement has 3 rows, data has 1
>
> So that's the problem. Already in 1968, there was a language named Algol68
> which had arrays and, in order to make things easy for its programmers,
> allowed you to create arrays of every data type the language provided. You
> could have arrays of Booleans, arrays of integers, arrays of records, arrays
> of discriminated unions, arrays of procedures, arrays of I/O formats, arrays
> of pointers, and arrays of arrays. The idea was "orthogonality" (see for
> example http://stackoverflow.com/questions/1527393/what-is-orthogonality ):
> that the programmer does not have to think about unexpected interactions
> between the concept of array and the concept of the element type, because
> there are none. If you have a data type, you can make arrays of that type.
> Pop-2 (1970), Snobol4 (1966), and Lisp (1958) were similarly generous. But R
> (1993) isn't. It wants to make life hard by forcing me to use different
> kinds of container for different kinds of element. And by providing a nice
> implementation of sets and then not letting me store them.
>
> So I thought about the kinds of data that I _can_ store in a data frame and
> generate by flattening. Strings! So I decided to use my
> aggregator_making_string function to make a string representation of the set
> of days, and to write a set-inclusion function that compared these sets
> against sets represented as vectors:
>
>   includes2 <- function( a_as_string, b )
>   {
>     a <- as.numeric( unlist( strsplit( a_as_string, split="," ) ) )
>     return( setequal( union( a, b ), a ) )
>   }
>
> Here are some example calls:
>
>   > includes2( '1,2,3', c(1) )
>   [1] TRUE
>   > includes2( '1,2,3', c(1,2) )
>   [1] TRUE
>   > includes2( '1,2,3', c(1,2,4) )
>   [1] FALSE
>   > includes2( '1,2,3', c(3) )
>   [1] TRUE
>   > includes2( '1,2,3', c(0,3) )
>   [1] FALSE
>   >
>
> I then tried using it:
>
>   df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
>                   , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
>                   )
>
>   aggregator_making_string <- function( ... )
>   {
>     return( toString( ... ) )
>   }
>
>   flattened <- dcast( df, ID~. , fun.aggregate=aggregator_making_string )
>
>   # Which patients have a day 1?
>   flattened[ includes2( flattened$. , c(1) ), ]
>
> Unfortunately, that didn't work. The final statement selected every row of
> 'flattened'. I eventually realised that I had to vectorise 'includes2':
>
>   includes3 <- Vectorize( includes2, "a_as_string" )
>
> And that did work:
>
>   >   flattened[ includes3( flattened$. , c(1) ), ]
>     ID          .
>   1  1 1, 2, 4, 7
>   3  3 1, 3, 4, 8
>   >   flattened[ includes3( flattened$. , c(1,2) ), ]
>     ID          .
>   1  1 1, 2, 4, 7
>   >   flattened[ includes3( flattened$. , c(1,3) ), ]
>     ID          .
>   3  3 1, 3, 4, 8
>   >   flattened[ includes3( flattened$. , c(2) ), ]
>     ID          .
>   1  1 1, 2, 4, 7
>   2  2       2, 3
>
> The moral of this email tale is that sets are really useful for filtering
> data, and dcast ought to be really useful for generating sets, but R refuses
> to let me store them in the data frame that dcast generates. I can fudge it
> by representing the sets as strings, but is there a cleaner way to solve the
> problem?
>
> Cheers,
>
> Jocelyn Ireson-Paine
> 07768 534 091
> http://www.jocelyns-cartoons.uk
> http://www.j-paine.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Thu Mar 12 10:42:08 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 12 Mar 2015 10:42:08 +0100
Subject: [R] tcltk problem
In-Reply-To: <0C2AF242-6156-40E1-A3AA-0F9329A0DB29@univie.ac.at>
References: <E691E95A-64EF-43F3-A63F-11C65CA0242F@univie.ac.at>
	<208B6895-F6E5-4C65-80C0-BCB97BAF929C@gmail.com>
	<0C2AF242-6156-40E1-A3AA-0F9329A0DB29@univie.ac.at>
Message-ID: <19028483-F38A-43A2-85F7-525E62949273@gmail.com>

Fixed in R-devel. 

As a curiosity, this seems to have been there the last 7 years without anyone noticing. And the change to tcl() is another 4.5 years older...

The problem with \dontrun sections in examples is that they tend not to be run...

-pd

On 12 Mar 2015, at 09:17 , Erich Neuwirth <erich.neuwirth at univie.ac.at> wrote:

> Sorry,
> I get at these demo when I do
> ?tkscrollbar
> Then the help file for many of the UI widgets appears, titled
> TkWidgets {tcltk}
> On the bottom of this file are the 2 examples I mentioned.
> Excuse the incomplete description in the first and the incorrect description in the second message.
> 
> 
> 
> 
> 
>> On 12 Mar 2015, at 09:04, peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>>> 
>>> On 11 Mar 2015, at 23:41 , Erich Neuwirth <erich.neuwirth at univie.ac.at> wrote:
>>> 
>>> OSX 10.10.2
>>> R 3.1.3
>>> XQuartz installed.
>>> 
>>> I am trying to run one of the tcltk demos
>> 
>> Which demos? Doesn't look like any the ones in the package. 
>> 
>> (Please at least be specific when you imply that someone is publishing bad code.)
>> 
>>> This one works:
>>> 
>>> tt <- tktoplevel()
>>> label.widget <- tklabel(tt, text = "Hello, World!")
>>> button.widget <- tkbutton(tt, text = "Push",
>>>                         command = function()cat("OW!\n"))
>>> tkpack(label.widget, button.widget) # geometry manager
>>>                                   # see Tk-commands
>>> 
>>> 
>>> But the next one breaks:
>>>> if(as.character(tcl("info", "tclversion")) >= "8.5") {
>>> +   # make use of themed widgets
>>> +   # list themes
>>> +   as.character(tcl("ttk::style", "theme", "names"))
>>> +   # select a theme -- here pre-XP windows
>>> +   tcl("ttk::style", "theme use", "winnative")
>>> + } else {
>>> +   # use Tk 8.0 widgets
>>> + }
>>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>>> [tcl] bad command "theme use": must be configure, map, lookup, layout, theme, or element.
>>> 
>>> What is going wrong here?
>> 
>> Presumably "theme use" wants to be "theme", "use".
>> 
>> (Many moons ago, tcl() just pasted words together and executed the result as a Tcl command via .Tcl. Looks like the author expected .Tcl("ttk::style theme use winnative"), but nowadays it uses .Tcl.objv() which expects a vector of Tcl words so there is a difference between two words and one word with a space in the middle. The puzzling bit is that I'd have thunk Tcl 8.5 to be considerably later than the change to tcl()?)
>> 
>> 
>> -- 
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From johanlassen at gmail.com  Thu Mar 12 11:46:12 2015
From: johanlassen at gmail.com (Johan Lassen)
Date: Thu, 12 Mar 2015 11:46:12 +0100
Subject: [R] Introductory courses in R in Denmark?
Message-ID: <CAAqXfse_6tyxKwmW5wE9w5Ah23h8f5s3AzS_GsY=Mk4YbOc65g@mail.gmail.com>

Dear R-forum!

I would like to hear if someone know off some good introductory classes in
Denmark? E.g. one week course with teaching in basic R (how to read/export
in data into/from R with emphasis on txt, csv. and database, how to do
basic operations on data frames and vectors, how to plot data and so on).

Thanks in advance!


-- 
Johan Lassen

"In the cities people live in time -
in the mountains people live in space" (Budistisk munk).

	[[alternative HTML version deleted]]


From dmontaner at cipf.es  Thu Mar 12 12:46:01 2015
From: dmontaner at cipf.es (david montaner)
Date: Thu, 12 Mar 2015 12:46:01 +0100
Subject: [R] Introductory courses in R in Denmark?
In-Reply-To: <CAAqXfse_6tyxKwmW5wE9w5Ah23h8f5s3AzS_GsY=Mk4YbOc65g@mail.gmail.com>
References: <CAAqXfse_6tyxKwmW5wE9w5Ah23h8f5s3AzS_GsY=Mk4YbOc65g@mail.gmail.com>
Message-ID: <CANgQr650jC6nHta1PsCLtN-qQ7q0WeRkMkVNXDOVVSDUnNHYPA@mail.gmail.com>

Dear Johan

>From GENOMETRA we organize this kind of courses on demand

In a couple of weeks we are running one in Valencia:

http://www.genometra.com/cursos/curso_r_2015_03/

Sorry that in this case the program is in Spanish.

If your can find a group of people interested on the course we can go to
Denmark.

Regards

David


On Thu, Mar 12, 2015 at 11:46 AM, Johan Lassen <johanlassen at gmail.com>
wrote:

> Dear R-forum!
>
> I would like to hear if someone know off some good introductory classes in
> Denmark? E.g. one week course with teaching in basic R (how to read/export
> in data into/from R with emphasis on txt, csv. and database, how to do
> basic operations on data frames and vectors, how to plot data and so on).
>
> Thanks in advance!
>
>
> --
> Johan Lassen
>
> "In the cities people live in time -
> in the mountains people live in space" (Budistisk munk).
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From greif.tomas at gmail.com  Thu Mar 12 14:43:00 2015
From: greif.tomas at gmail.com (=?UTF-8?B?VG9tw6HFoSBHcmVpZg==?=)
Date: Thu, 12 Mar 2015 14:43:00 +0100
Subject: [R] Relation of BLAS and LAPACK
Message-ID: <CAGKU+8A66k0HMWR317qSrksKzQC--mk3PdfWwbL+6aWhv4UQcQ@mail.gmail.com>

How BLAS and LAPACK are related, does R need both?

I am trying to understsand different BLAS options in R and I am quite not
sure if LAPACK is part of BLAS, or separate library or something else.
Based on http://www.netlib.org/lapack/ it looks like LAPACK is some kind of
BLAS extension ("LAPACK routines are written so that as much as possible of
the computation is performed by calls to the Basic Linear Algebra
Subprograms (BLAS)").

Tomas

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Mar 12 07:38:40 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 12 Mar 2015 06:38:40 +0000
Subject: [R] .Rdata files -- fortune?
In-Reply-To: <20150311154415.GB2730@localhost>
References: <mailman.1.1426071602.12262.r-help@r-project.org>
	<55003C5F.70904@uottawa.ca> <20150311154415.GB2730@localhost>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23888@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jan Kim
> Sent: Wednesday, March 11, 2015 4:44 PM
> To: r-help at r-project.org
> Subject: Re: [R] .Rdata files -- fortune?
>
> On Wed, Mar 11, 2015 at 09:00:15AM -0400, Prof J C Nash (U30A) wrote:
> > Well put. I avoid them too, and go so far as to seek and destroy so
> > they don't get loaded unnoticed and cause unwanted consequences.
> >
> > ".RData files (the ones with nothing before the period) are just
> traps
> > for your future self, with no documentation. I avoid them like the
> plague."
>
> I absolutely agree. While I've solved the issue for myself long ago by
> always putting something like
>
>     alias R='R --no-save --no-restore'
>
> into my startup scripts (~/.bashrc or the like), I've seen too many
> others caught out by implicit saving / restoring of workspaces (e.g.
> by somehow just accepting that R "only works properly in this
> particular directory" and therefore doing all their work there at the
> cost of adopting various anti-patterns with respect to organising work
> into directories.
>
> Personally I think that auto saving / restoring workspaces should be
> reviewed, as it can, in practice, make it harder for people to render
> their work in a self-contained and reproducible way.

If this is considered I would beg for addind an option to keep autosave work for those who have different approach. If you keep the paradigm one project = one separate directory there shall be no problem with autosaving as you have only one Rdata file together with exported pictures, pdfs, xls and doc files.

If you save history to separate files you can also easily keep track of your work. If autosave is disabled and you could leave your session without warning I bet that there would be hundereds of questions similar to:

I worked whole day and after quitting R all my work is lost.

Cheers
Petr

>
> Best regards, Jan
>
> >
> > JN
> >
> > On 15-03-11 07:00 AM, r-help-request at r-project.org wrote:
> > > Message: 34
> > > Date: Tue, 10 Mar 2015 17:51:15 -0700
> > > From: Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
> > > To: Rolf Turner <r.turner at auckland.ac.nz>, Erin Hodgess
> > >   <erinm.hodgess at gmail.com>, R help <r-help at stat.math.ethz.ch>
> > > Subject: Re: [R] .Rprofile vs. First (more of an opinion question)
> > > Message-ID: <E5A53229-B271-42D9-BEAB-73142B2F62F4 at dcn.davis.CA.us>
> > > Content-Type: text/plain; charset="UTF-8"
> > >
> > > I concur with Rolf.
> > >
> > > .RData files (the ones with nothing before the period) are just
> traps for your future self, with no documentation. I avoid them like
> the plague. I refer to specifically-named Something.RData files in my
> .R/.Rnw/.Rmd files to cache results of long computations, but they are
> optional in my workflow because I always have R code that can
> regenerate them.
> > >
> > > .Rprofile files offer consistency of behavior  regardless of which
> working directory you use, and you can comment them.
> > > -------------------------------------------------------------------
> --------
> > > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
> Live Go...
> > >                                       Live:   OO#.. Dead: OO#..
> Playing
> > > Research Engineer (Solar/Batteries            O.O#.       #.O#.
> with
> > > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> > > -------------------------------------------------------------------
> -
> > > ------- Sent from my phone. Please excuse my brevity.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
>  +- Jan T. Kim -------------------------------------------------------+
>  |             email: jttkim at gmail.com                                |
>  |             WWW:   http://www.jtkim.dreamhosters.com/              |
>  *-----=<  hierarchical systems are for files, not for humans  >=-----*
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From blake.seers at gmail.com  Thu Mar  5 03:59:15 2015
From: blake.seers at gmail.com (Blake Seers)
Date: Thu, 5 Mar 2015 15:59:15 +1300
Subject: [R] [R-pkgs] New package: clifro (v2.4-0)
Message-ID: <CAHayGv9r+tXChjzW2=Jj20rV3=t_DmcycMN97zj5XutPpM-=Lg@mail.gmail.com>

Dear R Users,

I am pleased to inform you that my clifro package has been submitted to
CRAN today:

http://cran.r-project.org/web/packages/clifro/

The clifro package imports data from New Zealand's National Climate
Database (via CliFlo) and provides generic plotting methods for a range of
the various data types. The focus of clifro is to ensure the process from
data acquisition to analysis is as smooth as possible. This removes the
need to manually obtain, validate, import, clean and reshape the data,
before any plotting, analysis or export takes place.

This package may also be helpful for plotting wind data from any dataset
(using the windrose function).

The github page can be viewed here:
https://github.com/ropensci/clifro#enhancing-the-national-climate-database-with-clifro

Any comments, suggestions and feedback are always welcome.

I hope you find this helpful!
Regards
---
Blake

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From wdunlap at tibco.com  Thu Mar 12 15:53:03 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 12 Mar 2015 07:53:03 -0700
Subject: [R] How to filter data using sets generated by flattening with
 dcast, when I can't store those sets in a data frame
In-Reply-To: <alpine.LRH.2.02.1503120748540.25235@sphinx.mythic-beasts.com>
References: <alpine.LRH.2.02.1503120748540.25235@sphinx.mythic-beasts.com>
Message-ID: <CAF8bMcaxUAWdj0jw4r-C0p+A3c8HPN8AHUDJU_KsgT7osAvOZw@mail.gmail.com>

In base R you can do what I think you want with aggregate() and Filter().
E.g.,
  > a <- aggregate(df["Day"], df["ID"], function(x)x)
  > str(a)
  'data.frame':   3 obs. of  2 variables:
   $ ID : num  1 2 3
   $ Day:List of 3
    ..$ 1: num  1 2 4 7
    ..$ 5: num  2 3
    ..$ 7: num  1 3 4 8
  > i14 <- Filter(function(i){all(c(1,4) %in% a$Day[[i]])},
seq_len(nrow(a)))
  > a[i14,]
    ID        Day
  1  1 1, 2, 4, 7
  3  3 1, 3, 4, 8

Note that 'reshape2' is not 'R', it is a user-contributed package that runs
in R.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Mar 12, 2015 at 12:55 AM, Jocelyn Ireson-Paine <popx at j-paine.org>
wrote:

> This is a fairly long question. It's about a problem that's easy to
> specify in terms of sets, but that I found hard to solve in R by using
> them, because of the strange design of R data structures. In explaining it,
> I'm going to touch on the reshape2 library, dcast, sets, and the
> non-orthogonality of R.
>
> My problem stems from some drug-trial data that I've been analysing for
> the Oxford Pain Research Unit. Here's an example. Imagine a data frame
> representing patients in a trial of pain-relief drugs. The trial lasts for
> ten days. Each patient's pain is measured once a day, and the values are
> recorded in a data frame, one row per patient per day. Like this:
>
>   ID  Day  Pain
>    1    1  10
>    1    2   9
>    1    4   7
>    1    7   2
>    2    2   8
>    2    3   7
>    3    1  10
>    3    3   6
>    3    4   6
>    3    8   2
>
> Unfortunately, many patients have measurements missing. Thus, in the
> example above, patient 1 was only observed on days 1, 2, 4, and 7, rather
> than on the full ten days. But a patient's measurements are only useful to
> us if that patient has a certain minimum set of days, so I need to check
> for patients who lack those days. Let's assume that these days are numbers
> 1, 4, and 9.
>
> Such a question is trivial to state in terms of sets. Let D(i) denote the
> set of days on which patient i was measured: then I want to find out which
> patients p, or how many patients p, have a D(p) that contains the set
> {1,4,9}.
>
> The obvious way to solve this is to write a function that tells me whether
> one set is a superset of another. Then flatten my data frame so that it
> looks like this:
>
>   ID  Days
>    1  {1,2,4,7}
>    2  {2,3}
>    3  {1,3,4,8}
>
> And finally, filter it by some R translation of
>
>   flattened[ includes( flattened$Days, {1,4,9} ), ]
>
> I started with the built-in functions that operate on sets represented as
> vectors. These are described in
>  https://stat.ethz.ch/R-manual/R-devel/library/base/html/sets.html ,
> "Set Operations". For example:
>
>   > union( c(1,2,3), c(2,4,6) )
>   [1] 1 2 3 4 6
>   > intersect( c(1,2,3), c(2,4,6) )
>   [1] 2
>
> So I first wrote a set-inclusion function:
>
>   # True if vector a is a superset of vector b.
>   #
>   includes <- function( a, b )
>   {
>     return( setequal( union( a, b ), a ) )
>   }
>
> Here are some sample calls:
>
>   > includes( c(1), c() )
>   [1] TRUE
>   > includes( c(1), c(1) )
>   [1] TRUE
>   > includes( c(1), c(1,2) )
>   [1] FALSE
>   > includes( c(2,1), c(1,2) )
>   [1] TRUE
>   > includes( c(2,1,3), c(1,2) )
>   [1] TRUE
>   > includes( c(2,1,3), c(4,1,2) )
>   [1] FALSE
>
> I then made myself a variable holding my sample data frame:
>
>   df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
>                   , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
>                   )
>
> And I tried flattening it, using dcast and an aggregator function as
> described in (amongst many other places) http://seananderson.ca/2013/
> 10/19/reshape.html , "An Introduction to reshape2" by Sean C. Anderson.
>
> The idea behind this is that (for my data) dcast will call the aggregator
> function once per patient ID, passing it all the Day values for the
> patient. The aggregator must combine them in some way, and dcast puts its
> results into a new column. For example, here's an aggregator that merely
> sums its arguments:
>
>   aggregator_making_sum <- function( ... )
>   {
>     return( sum( ... ) )
>   }
>
> If I call it, I get this:
>
>   >  dcast( df, ID~. , fun.aggregate=aggregator_making_sum )
>   Using Day as value column: use value.var to override.
>     ID  .
>   1  1 14
>   2  2  5
>   3  3 16
>
> And here's an aggregator that converts the argument list to a string:
>
>   aggregator_making_string <- function( ... )
>   {
>     return( toString( ... ) )
>   }
>
> Calling it gives this:
>
>   >  dcast( df, ID~. , fun.aggregate=aggregator_making_string )
>   Using Day as value column: use value.var to override.
>     ID          .
>   1  1 1, 2, 4, 7
>   2  2       2, 3
>   3  3 1, 3, 4, 8
>
> In both of these, the three dots denote all arguments to the aggregator,
> as explained in Burns Statistics's http://www.burns-stat.com/the-
> three-dots-construct-in-r/ . My first aggregator sums them; my second
> converts them to a string. Both uses of dcast generate a data frame with a
> column named "." , which contains the aggregates. In the second data frame,
> that may not be so clear: the first column of numbers is row numbers; the
> second column of numbers are the IDs; and the remaining columns form the
> strings, belonging to "." .
>
> But what I want is neither a sum nor a string but a set. Specifically, a
> set that's compatible with the R set operations I called in my 'includes'
> function. Since these sets are vectors, my aggregator should just pack its
> arguments into a vector:
>
>   aggregator_making_set <- function( ... )
>   {
>     return( c( ... ) )
>   }
>
> But when I tried it, I got an error:
>
>   > dcast( df, ID~. , fun.aggregate=aggregator_making_set )
>   Using Day as value column: use value.var to override.
>   Error in vapply(indices, fun, .default) : values must be length 0,
>    but FUN(X[[1]]) result is length 4
>
> It's not an informative error message, because it expects me to know how
> dcast is coded. And I'm surprised that values need to be length 0: length 1
> would seem more appropriate. But perhaps it's trying to say that 'c'
> doesn't work on three-dots argument lists. Let's test that hypothesis:
>
>   test_c_on_three_dots <- function( ... )
>   {
>     return( c( ... ) )
>   }
>
>   >   test_c_on_three_dots( 1 )
>   [1] 1
>   >   test_c_on_three_dots( 1, 2 )
>   [1] 1 2
>   >   test_c_on_three_dots( 1, 2, 3 )
>   [1] 1 2 3
>
> So 'c' does indeed work on three-dots argument lists. The error must have
> been caused by something else. Let's try making a set and putting it into a
> data frame directly:
>
>   > df <- data.frame( col1=c(1,2), col2=c(3,4) )
>   > df
>     col1 col2
>   1    1    3
>   2    2    4
>   > set <- union( c(5,6), c(6,7) )
>   > set
>   [1] 5 6 7
>   > df[ 1, ]$col1 <- set
>   Error in `$<-.data.frame`(`*tmp*`, "col1", value = c(5, 6, 7)) :
>     replacement has 3 rows, data has 1
>
> So that's the problem. Already in 1968, there was a language named Algol68
> which had arrays and, in order to make things easy for its programmers,
> allowed you to create arrays of every data type the language provided. You
> could have arrays of Booleans, arrays of integers, arrays of records,
> arrays of discriminated unions, arrays of procedures, arrays of I/O
> formats, arrays of pointers, and arrays of arrays. The idea was
> "orthogonality" (see for example http://stackoverflow.com/
> questions/1527393/what-is-orthogonality ): that the programmer does not
> have to think about unexpected interactions between the concept of array
> and the concept of the element type, because there are none. If you have a
> data type, you can make arrays of that type. Pop-2 (1970), Snobol4 (1966),
> and Lisp (1958) were similarly generous. But R (1993) isn't. It wants to
> make life hard by forcing me to use different kinds of container for
> different kinds of element. And by providing a nice implementation of sets
> and then not letting me store them.
>
> So I thought about the kinds of data that I _can_ store in a data frame
> and generate by flattening. Strings! So I decided to use my
> aggregator_making_string function to make a string representation of the
> set of days, and to write a set-inclusion function that compared these sets
> against sets represented as vectors:
>
>   includes2 <- function( a_as_string, b )
>   {
>     a <- as.numeric( unlist( strsplit( a_as_string, split="," ) ) )
>     return( setequal( union( a, b ), a ) )
>   }
>
> Here are some example calls:
>
>   > includes2( '1,2,3', c(1) )
>   [1] TRUE
>   > includes2( '1,2,3', c(1,2) )
>   [1] TRUE
>   > includes2( '1,2,3', c(1,2,4) )
>   [1] FALSE
>   > includes2( '1,2,3', c(3) )
>   [1] TRUE
>   > includes2( '1,2,3', c(0,3) )
>   [1] FALSE
>   >
>
> I then tried using it:
>
>   df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
>                   , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
>                   )
>
>   aggregator_making_string <- function( ... )
>   {
>     return( toString( ... ) )
>   }
>
>   flattened <- dcast( df, ID~. , fun.aggregate=aggregator_making_string )
>
>   # Which patients have a day 1?
>   flattened[ includes2( flattened$. , c(1) ), ]
>
> Unfortunately, that didn't work. The final statement selected every row of
> 'flattened'. I eventually realised that I had to vectorise 'includes2':
>
>   includes3 <- Vectorize( includes2, "a_as_string" )
>
> And that did work:
>
>   >   flattened[ includes3( flattened$. , c(1) ), ]
>     ID          .
>   1  1 1, 2, 4, 7
>   3  3 1, 3, 4, 8
>   >   flattened[ includes3( flattened$. , c(1,2) ), ]
>     ID          .
>   1  1 1, 2, 4, 7
>   >   flattened[ includes3( flattened$. , c(1,3) ), ]
>     ID          .
>   3  3 1, 3, 4, 8
>   >   flattened[ includes3( flattened$. , c(2) ), ]
>     ID          .
>   1  1 1, 2, 4, 7
>   2  2       2, 3
>
> The moral of this email tale is that sets are really useful for filtering
> data, and dcast ought to be really useful for generating sets, but R
> refuses to let me store them in the data frame that dcast generates. I can
> fudge it by representing the sets as strings, but is there a cleaner way to
> solve the problem?
>
> Cheers,
>
> Jocelyn Ireson-Paine
> 07768 534 091
> http://www.jocelyns-cartoons.uk
> http://www.j-paine.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Thu Mar 12 16:13:20 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Mar 2015 15:13:20 +0000
Subject: [R] Relation of BLAS and LAPACK
In-Reply-To: <CAGKU+8A66k0HMWR317qSrksKzQC--mk3PdfWwbL+6aWhv4UQcQ@mail.gmail.com>
References: <CAGKU+8A66k0HMWR317qSrksKzQC--mk3PdfWwbL+6aWhv4UQcQ@mail.gmail.com>
Message-ID: <5501AD10.8020807@stats.ox.ac.uk>

On 12/03/2015 13:43, Tom?? Greif wrote:
> How BLAS and LAPACK are related, does R need both?

Both.

>
> I am trying to understsand different BLAS options in R and I am quite not
> sure if LAPACK is part of BLAS, or separate library or something else.
> Based on http://www.netlib.org/lapack/ it looks like LAPACK is some kind of
> BLAS extension ("LAPACK routines are written so that as much as possible of
> the computation is performed by calls to the Basic Linear Algebra
> Subprograms (BLAS)").

No, LAPACK is a set of routines distinct from BLAS.  However, the 
standard LAPACK tarball includes a reference set of BLAS routines which 
are also available separately.  Hence some confusion.  But the confusion 
is that BLAS is part of LAPACK, not v.v.

This is not an R-help topic (see the posting guide, including what it 
says about HTML mail).

>
> Tomas
>
> 	[[alternative HTML version deleted]]
>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From HDoran at air.org  Thu Mar 12 16:25:28 2015
From: HDoran at air.org (Doran, Harold)
Date: Thu, 12 Mar 2015 15:25:28 +0000
Subject: [R] automate "press enter"
Message-ID: <D1272825.24A45%hdoran@air.org>

I?m dealing with an issue that is seemingly simple, and I?m sure there is an obvious solution. I?m writing a wrapper function that calls functions from another package (twitteR).

However, the function I happen to be using in that package prompts the user the user to enter a ?1? or a ?2? in the workspace before the user can proceed. The actual process looks like this:

> setup_twitter_oauth(APIkey,APIsecret, Accesstoken, Accesssecret)

Use a local file to cache OAuth access credentials between R sessions?
1: Yes
2: No

I know I want the value  ?2? to be entered, but I cannot figure out how to automate it without a human actually entering ?2? and hitting enter when prompted.

Is it possible to automate this so the user doesn?t have to manually hit enter?

Harold



	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Mar 12 16:38:05 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 12 Mar 2015 08:38:05 -0700
Subject: [R] automate "press enter"
In-Reply-To: <D1272825.24A45%hdoran@air.org>
References: <D1272825.24A45%hdoran@air.org>
Message-ID: <CAF8bMca1i2G2atd5wCXGbBnUXx3-tCB6bWN8_wS++=tpsfWmAw@mail.gmail.com>

Poke around the help files (& perhaps source code) for package:httr to see
how to set
options("httr_oauth_cache").  E.g.,

   help(package="httr", "Token-class")


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Mar 12, 2015 at 8:25 AM, Doran, Harold <HDoran at air.org> wrote:

> I?m dealing with an issue that is seemingly simple, and I?m sure there is
> an obvious solution. I?m writing a wrapper function that calls functions
> from another package (twitteR).
>
> However, the function I happen to be using in that package prompts the
> user the user to enter a ?1? or a ?2? in the workspace before the user can
> proceed. The actual process looks like this:
>
> > setup_twitter_oauth(APIkey,APIsecret, Accesstoken, Accesssecret)
>
> Use a local file to cache OAuth access credentials between R sessions?
> 1: Yes
> 2: No
>
> I know I want the value  ?2? to be entered, but I cannot figure out how to
> automate it without a human actually entering ?2? and hitting enter when
> prompted.
>
> Is it possible to automate this so the user doesn?t have to manually hit
> enter?
>
> Harold
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From amango at gmail.com  Thu Mar 12 18:07:57 2015
From: amango at gmail.com (Aman Gill)
Date: Thu, 12 Mar 2015 13:07:57 -0400
Subject: [R] Help with error: arguments imply differing number of rows
Message-ID: <CAKXkWh3GQ2vgF=4SvF1jLb19uFeKBY7eDttAd919RU_CTTFcTg@mail.gmail.com>

Hello,

I am stuck trying to run an analysis using the package picante. I am
running two very similar analyses. One works as expected, but when I try
the other, I get the error:

Error in data.frame(PD = PDs, SR = SR) :
  arguments imply differing number of rows: 34, 35

This is strange to me since the data matrix is the same for both analyses
(numbers of rows and columns are the same; the only difference is the order
of the columns). Each analyses requires a phylogenetic tree (.tre file),
and each tree is very similar. Any thoughts as to what's causing this
problem? The problem may be specific to the function I'm using [pd()], but
since the error is a data.frame error I thought I'd ask here. Here is the
code I'm using:

This works:
phyl_tree <- read.nexus("phyl.tre")
phyl_data <- as.matrix(read.table("phyl_matrix.txt"), header=TRUE, sep =
"\t")
pd.result <- pd(phyl_data, phyl_tree, include.root = TRUE)

This fails (this matrix.txt file is the same as above, except that columns
are ordered to match the tree; I have also used the above matrix.txt file)
chem_tree <- read.nexus("chem.tre")
chem_data <- as.matrix(read.table("chem_matrix.txt"), header=TRUE, sep =
"\t")
pd_chem.result <- pd(chem_data, chem_tree, include.root = TRUE)

ERROR:
Error in data.frame(PD = PDs, SR = SR) :
  arguments imply differing number of rows: 34, 35


To illustrate that the data for each run are very similar (row and column
names are also the same in both data files):

> phyl_tree

Phylogenetic tree with 9 tips and 7 internal nodes.

Tip labels:
Heliantheae, Eupatorieae, Helenieae, Gnaphalieae, Anthemideae, Astereae, ...
Node labels:
root, minCyn, minCic, HelEurHel, HelEur, GnaAnthAst, ...

Rooted; includes branch lengths.

> nrow(phyl_data)
[1] 35
> ncol(phyl_data)
[1] 9
> class(phyl_data)
[1] "matrix"


> chem_tree

Phylogenetic tree with 9 tips and 7 internal nodes.

Tip labels:
Heliantheae, Helenieae, Eupatorieae, Astereae, Gnaphlieae, Senecioneae, ...
Node labels:
root, minC, minAnth, minSen, minGna, HelHel, ...

Rooted; includes branch lengths.

> nrow(chem_data)
[1] 35
> ncol(chem_data)
[1] 9
> class(chem_data)
[1] "matrix"

	[[alternative HTML version deleted]]


From jttkim at googlemail.com  Thu Mar 12 18:22:20 2015
From: jttkim at googlemail.com (Jan Kim)
Date: Thu, 12 Mar 2015 17:22:20 +0000
Subject: [R] .Rdata files -- fortune?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23888@SRVEXCHMBX.precheza.cz>
References: <mailman.1.1426071602.12262.r-help@r-project.org>
	<55003C5F.70904@uottawa.ca> <20150311154415.GB2730@localhost>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23888@SRVEXCHMBX.precheza.cz>
Message-ID: <20150312172219.GA2881@localhost>

Dear Petr, dear All,

On Thu, Mar 12, 2015 at 06:38:40AM +0000, PIKAL Petr wrote:
> Hi
> 
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jan Kim
> > Sent: Wednesday, March 11, 2015 4:44 PM
> > To: r-help at r-project.org
> > Subject: Re: [R] .Rdata files -- fortune?
> >
> > On Wed, Mar 11, 2015 at 09:00:15AM -0400, Prof J C Nash (U30A) wrote:
> > > Well put. I avoid them too, and go so far as to seek and destroy so
> > > they don't get loaded unnoticed and cause unwanted consequences.
> > >
> > > ".RData files (the ones with nothing before the period) are just
> > traps
> > > for your future self, with no documentation. I avoid them like the
> > plague."
> >
> > I absolutely agree. While I've solved the issue for myself long ago by
> > always putting something like
> >
> >     alias R='R --no-save --no-restore'
> >
> > into my startup scripts (~/.bashrc or the like), I've seen too many
> > others caught out by implicit saving / restoring of workspaces (e.g.
> > by somehow just accepting that R "only works properly in this
> > particular directory" and therefore doing all their work there at the
> > cost of adopting various anti-patterns with respect to organising work
> > into directories.
> >
> > Personally I think that auto saving / restoring workspaces should be
> > reviewed, as it can, in practice, make it harder for people to render
> > their work in a self-contained and reproducible way.
> 
> If this is considered I would beg for addind an option to keep autosave work for those who have different approach. If you keep the paradigm one project = one separate directory there shall be no problem with autosaving as you have only one Rdata file together with exported pictures, pdfs, xls and doc files.
> 
> If you save history to separate files you can also easily keep track of your work. If autosave is disabled and you could leave your session without warning I bet that there would be hundereds of questions similar to:
> 
> I worked whole day and after quitting R all my work is lost.

As the auto save / restore feature has been around for several years,
it sure makes sense to withdraw it in a rather gradual process. For
example, as a first step a flag distinguishing autosaved workspaces
from those generated by the user calling save.image could be added
to the workspace file format, subsequently users could be warned about
auto-saved workspaces increasingly prominently, users could be pointed
to ways to customising their startup / exit setup to arrange for
autosave / restore if they really want to retain it (via ~/.Rprofile
and some way to register functions to be invoked upon terminating an
interactive session), and after all those stages the feature could
be withdrawn.

It's a long process but I think it would be worthwhile because it will
improve reproducibility of scientific computing. As an illustration,
one of the patterns how I've seen people becoming dependent on .RData
files is writing a function that references a global variable. The
function may work (in the sense of running without causing an error)
for many months in the directory with the .RData file "providing" that
variable, and when the user finally tries to use the function in an
R process started in another directory, they are mystified and may well
start doing all their work in the one "magical" directory.

Obviously, if that global variable is ever changed, all results generated
previously will no longer be reproducible. And yes, I have found a
function once with a loop "for (i in 1:n)", where "n" was a parameter
that since had been changed to something more descriptive and the error
remained unnoticed because there was a global variable "n" in the
workspace -- and the number of iterations of that loop was controlled
by that, rather than by the parameter of the function.

Saving workspaces as a cache can be a very useful and entirely sensible
thing (as Jeff wrote previously), but if this happens automatically,
this means it can happen where it's not so sensible, and some stuff left
in workspaces accidentally and innocently may turn into a landmine in
the future.

Best regards, Jan

> Cheers
> Petr
> 
> >
> > Best regards, Jan
> >
> > >
> > > JN
> > >
> > > On 15-03-11 07:00 AM, r-help-request at r-project.org wrote:
> > > > Message: 34
> > > > Date: Tue, 10 Mar 2015 17:51:15 -0700
> > > > From: Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
> > > > To: Rolf Turner <r.turner at auckland.ac.nz>, Erin Hodgess
> > > >   <erinm.hodgess at gmail.com>, R help <r-help at stat.math.ethz.ch>
> > > > Subject: Re: [R] .Rprofile vs. First (more of an opinion question)
> > > > Message-ID: <E5A53229-B271-42D9-BEAB-73142B2F62F4 at dcn.davis.CA.us>
> > > > Content-Type: text/plain; charset="UTF-8"
> > > >
> > > > I concur with Rolf.
> > > >
> > > > .RData files (the ones with nothing before the period) are just
> > traps for your future self, with no documentation. I avoid them like
> > the plague. I refer to specifically-named Something.RData files in my
> > .R/.Rnw/.Rmd files to cache results of long computations, but they are
> > optional in my workflow because I always have R code that can
> > regenerate them.
> > > >
> > > > .Rprofile files offer consistency of behavior  regardless of which
> > working directory you use, and you can comment them.
> > > > -------------------------------------------------------------------
> > --------
> > > > Jeff Newmiller                        The     .....       .....  Go
> > Live...
> > > > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
> > Live Go...
> > > >                                       Live:   OO#.. Dead: OO#..
> > Playing
> > > > Research Engineer (Solar/Batteries            O.O#.       #.O#.
> > with
> > > > /Software/Embedded Controllers)               .OO#.       .OO#.
> > rocks...1k
> > > > -------------------------------------------------------------------
> > -
> > > > ------- Sent from my phone. Please excuse my brevity.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> >  +- Jan T. Kim -------------------------------------------------------+
> >  |             email: jttkim at gmail.com                                |
> >  |             WWW:   http://www.jtkim.dreamhosters.com/              |
> >  *-----=<  hierarchical systems are for files, not for humans  >=-----*
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak??koliv k n??mu p??ipojen?? dokumenty jsou d??v??rn?? a jsou ur??eny pouze jeho adres??t??m.
> Jestli??e jste obdr??el(a) tento e-mail omylem, informujte laskav?? neprodlen?? jeho odes??latele. Obsah tohoto emailu i s p????lohami a jeho kopie vyma??te ze sv??ho syst??mu.
> Nejste-li zam????len??m adres??tem tohoto emailu, nejste opr??vn??ni tento email jakkoliv u????vat, roz??i??ovat, kop??rovat ??i zve??ej??ovat.
> Odes??latel e-mailu neodpov??d?? za eventu??ln?? ??kodu zp??sobenou modifikacemi ??i zpo??d??n??m p??enosu e-mailu.
> 
> V p????pad??, ??e je tento e-mail sou????st?? obchodn??ho jedn??n??:
> - vyhrazuje si odes??latel pr??vo ukon??it kdykoliv jedn??n?? o uzav??en?? smlouvy, a to z jak??hokoliv d??vodu i bez uveden?? d??vodu.
> - a obsahuje-li nab??dku, je adres??t opr??vn??n nab??dku bezodkladn?? p??ijmout; Odes??latel tohoto e-mailu (nab??dky) vylu??uje p??ijet?? nab??dky ze strany p????jemce s dodatkem ??i odchylkou.
> - trv?? odes??latel na tom, ??e p????slu??n?? smlouva je uzav??ena teprve v??slovn??m dosa??en??m shody na v??ech jej??ch n??le??itostech.
> - odes??latel tohoto emailu informuje, ??e nen?? opr??vn??n uzav??rat za spole??nost ????dn?? smlouvy s v??jimkou p????pad??, kdy k tomu byl p??semn?? zmocn??n nebo p??semn?? pov????en a takov?? pov????en?? nebo pln?? moc byly adres??tovi tohoto emailu p????padn?? osob??, kterou adres??t zastupuje, p??edlo??eny nebo jejich existence je adres??tovi ??i osob?? j??m zastoupen?? zn??m??.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

-- 
 +- Jan T. Kim -------------------------------------------------------+
 |             email: jttkim at gmail.com                                |
 |             WWW:   http://www.jtkim.dreamhosters.com/              |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*


From dwinsemius at comcast.net  Thu Mar 12 18:23:31 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 12 Mar 2015 10:23:31 -0700
Subject: [R] Extracting slots from an object (e.g.: object produced by
	unit root test function "urdfTest")
In-Reply-To: <CABcx46DBznU0WDJh6x+jByW2RSBaa8QeNsQMMXFxkhRxFn=pSQ@mail.gmail.com>
References: <CABcx46DBznU0WDJh6x+jByW2RSBaa8QeNsQMMXFxkhRxFn=pSQ@mail.gmail.com>
Message-ID: <760CF7BF-00F2-4AF0-9FF5-ECB770CFCFBB@comcast.net>


On Mar 12, 2015, at 1:04 AM, jpm miao wrote:

> Hi,
> 
>   I run a statistical test function in the package "fUnitRoots" that
> returns a S4 object but I am wondering how to extract the p-value, one of
> the output elements.

> The document of the function "urdfTest":
> .....
> All tests return an object of class "fHTEST" with the following slots:
> 
> @call
> .....
> @test
> a list object which holds the output of the underlying test function.
> @title
> .....
> The entries of the @test slot include the following components:
> 
> $statistic
> ......
> $p.value
> the p-value of the test.
> .....
> (end)
> 
>   I store the result of the test test in an element of a list
> (adf1["r3m"][[1]]), and I want to extract the p-value. I was expecting the
> p-value via adf1["r3m"][[1]]@test$p.value but it gives only an error
> message. Could someone tell me how to extract the p-value? Thanks!!!

If you look at the code by typing: fUnitRoots::urdfTest,  you should quickly see why you are seeing text output:

That function is doing the equivalent of a console screenscrape:

...
output = capture.output(summary(urca))[-(1:4)]
...
# and then assigns a trimmed version of that result to the `test`- slot.


So the documentation is misleading in suggesting that a list object is being returned in the `test` slot. It's just a character vestor.


-- 
> 
>> adf1["r3m"][[1]]<-urdfTest(dat[,i], lags = 1, type = "ct")
>> adf1["r3m"][[1]]
> [1] "  "
> [2] "  Test regression trend "
> [3] "  "
> [4] "  Call:"
> [5] "  lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)"
> [6] "  "
> [7] "  Residuals:"
> [8] "      Min      1Q  Median      3Q     Max "
> [9] "  -3.0785 -0.0485  0.0072  0.0627  3.5672 "
> [10] "  "
> [11] "  Coefficients:"
> [12] "                Estimate Std. Error t value Pr(>|t|)    "
> [13] "  (Intercept) -1.733e-02  9.529e-03  -1.818  0.06910 .  "
> [14] "  z.lag.1     -7.060e-03  2.343e-03  -3.013  0.00261 ** "
> [15] "  tt           5.299e-06  4.927e-06   1.076  0.28221    "
> [16] "  z.diff.lag  -1.035e-01  1.859e-02  -5.569 2.81e-08 ***"
> [17] "  ---"
> [18] "  Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1"
> [19] "  "
> [20] "  Residual standard error: 0.2107 on 2864 degrees of freedom"
> [21] "  Multiple R-squared:  0.01461,\tAdjusted R-squared:  0.01358 "
> [22] "  F-statistic: 14.15 on 3 and 2864 DF,  p-value: 3.716e-09"
> [23] "  "
> [24] "  "
> [25] "  Value of test-statistic is: -3.0134 3.0697 4.5828 "
> [26] "  "
> [27] "  Critical values for test statistics: "
> [28] "        1pct  5pct 10pct"
> [29] "  tau3 -3.96 -3.41 -3.12"
> [30] "  phi2  6.09  4.68  4.03"
> [31] "  phi3  8.27  6.25  5.34"
> 

That is being displayed as a multi-element text object. You instead need to show the code that actually created that object.

>> adf1["r3m"][[1]]@test
> Error: trying to get slot "test" from an object of a basic class
> ("character") with no slots
>> adf1["r3m"][[1]]@test$p-value
> Error: trying to get slot "test" from an object of a basic class
> ("character") with no slots
> 
> 	[[alternative HTML version deleted]]

Please learn to post in palin text.

-- 

David Winsemius
Alameda, CA, USA


From tomuxiong at gmail.com  Thu Mar 12 18:15:43 2015
From: tomuxiong at gmail.com (Thomas Nyberg)
Date: Thu, 12 Mar 2015 13:15:43 -0400
Subject: [R] write.csv to text string?
Message-ID: <5501C9BF.4080009@gmail.com>

Hello,

I've found the following useful functionality:

> s <- 'cola,colb\n1,2\n2,3\n'
> read.csv(text=s)
  cola colb
1    1    2
2    2    3


But I haven't found a similar option in write.csv. I.e. I would like to
"write" a dataframe to a string. What would be the easiest way to go
about such a thing? Right now I can only think of using a file as an
intermediary, but that seems a bit silly. Thanks for any help.

Cheers,
Thomas Nyberg


From sarah.goslee at gmail.com  Thu Mar 12 19:10:15 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 12 Mar 2015 14:10:15 -0400
Subject: [R] write.csv to text string?
In-Reply-To: <5501C9BF.4080009@gmail.com>
References: <5501C9BF.4080009@gmail.com>
Message-ID: <CAM_vjunOVNXxiF3kaNwL-VgJN4zePHShGv0vYcyFB3VzHOWwCw@mail.gmail.com>

It's really not a job for the write.* functions, but for the
string-handling functions.

Here's a slightly clunky possibility:

# use your example
s.df <- read.csv(text='cola,colb\n1,2\n2,3\n')

# turn a data frame into a string
paste(
   paste(colnames(s.df), collapse=","),
   paste(apply(s.df, 1, paste, collapse=","), collapse="\n"),
   sep="\n")


On Thu, Mar 12, 2015 at 1:15 PM, Thomas Nyberg <tomuxiong at gmail.com> wrote:
> Hello,
>
> I've found the following useful functionality:
>
>> s <- 'cola,colb\n1,2\n2,3\n'
>> read.csv(text=s)
>   cola colb
> 1    1    2
> 2    2    3
>
>
> But I haven't found a similar option in write.csv. I.e. I would like to
> "write" a dataframe to a string. What would be the easiest way to go
> about such a thing? Right now I can only think of using a file as an
> intermediary, but that seems a bit silly. Thanks for any help.
>
> Cheers,
> Thomas Nyberg


-- 
Sarah Goslee
http://www.functionaldiversity.org


From dwinsemius at comcast.net  Thu Mar 12 19:17:09 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 12 Mar 2015 11:17:09 -0700
Subject: [R] write.csv to text string?
In-Reply-To: <5501C9BF.4080009@gmail.com>
References: <5501C9BF.4080009@gmail.com>
Message-ID: <B6C20A8F-9FFA-4271-8F6E-41291D820E26@comcast.net>


On Mar 12, 2015, at 10:15 AM, Thomas Nyberg wrote:

> Hello,
> 
> I've found the following useful functionality:
> 
>> s <- 'cola,colb\n1,2\n2,3\n'
>> read.csv(text=s)
>  cola colb
> 1    1    2
> 2    2    3
> 
> 
> But I haven't found a similar option in write.csv. I.e. I would like to
> "write" a dataframe to a string.

A data.frame is a list structure.

> What would be the easiest way to go
> about such a thing? Right now I can only think of using a file as an
> intermediary, but that seems a bit silly. Thanks for any help.

I think you are misunderstanding the structure of a computer file. `write.csv` is already doing essentially what you request. "Files" are essentially "strings" of varying sizes. The operating system print methods are displaying the linefeed/carriage in a manner that breaks the string into useful or readable segments on a "page".

If you want to have a text version of what the print.data.frame function returns, then wrap capture.output around print(dfrm). That will produce a character object.

--\n

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Thu Mar 12 19:25:33 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 12 Mar 2015 18:25:33 +0000
Subject: [R] write.csv to text string?
In-Reply-To: <5501C9BF.4080009@gmail.com>
References: <5501C9BF.4080009@gmail.com>
Message-ID: <5501DA1D.9020402@sapo.pt>

Hello,

Maybe using text connections. See ?textConnection.

tc <- textConnection("foo", "w")
s <- 'cola,colb\n1,2\n2,3\n'
cat(s, file = tc)
close(tc)
foo

read.csv(text = foo)


Hope this helps,

Rui Barradas

Em 12-03-2015 17:15, Thomas Nyberg escreveu:
> Hello,
>
> I've found the following useful functionality:
>
>> s <- 'cola,colb\n1,2\n2,3\n'
>> read.csv(text=s)
>    cola colb
> 1    1    2
> 2    2    3
>
>
> But I haven't found a similar option in write.csv. I.e. I would like to
> "write" a dataframe to a string. What would be the easiest way to go
> about such a thing? Right now I can only think of using a file as an
> intermediary, but that seems a bit silly. Thanks for any help.
>
> Cheers,
> Thomas Nyberg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From steve.taylor at aut.ac.nz  Thu Mar 12 20:43:20 2015
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Thu, 12 Mar 2015 19:43:20 +0000
Subject: [R] regex find anything which is not a number
In-Reply-To: <CAJ=0CtBws+3cDQkqgWD98cpFc5ysvOZEeB+DK=KLbOCJYWcEXw@mail.gmail.com>
References: <CAJ=0CtBws+3cDQkqgWD98cpFc5ysvOZEeB+DK=KLbOCJYWcEXw@mail.gmail.com>
Message-ID: <CCE952776B6679469977532BD863C39C9A68E21F@Lewis.autuni.aut.ac.nz>

How about letting a standard function decide which are numbers:

which(!is.na(suppressWarnings(as.numeric(myvector))))

Also works with numbers in scientific notation and (presumably) different decimal characters, e.g. comma if that's what the locale uses.


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Adrian Du?a
Sent: Thursday, 12 March 2015 8:27a
To: r-help at r-project.org
Subject: [R] regex find anything which is not a number

Hi everyone,

I need a regular expression to find those positions in a character
vector which contain something which is not a number (either positive
or negative, having decimals or not).

myvector <- c("a3", "N.A", "1.2", "-3", "3-2", "2.")

In this vector, only positions 3 and 4 are numbers, the rest should be captured.
So far I am able to detect anything which is not a number, excluding - and .

> grep("[^-0-9.]", myvector)
[1] 1 2

I still need to capture positions 5 and 6, which in human language
would mean to detect anything which contains a "-" or a "." anywhere
else except at the beginning of a number.

Thanks very much in advance,
Adrian


-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From john.archie.mckown at gmail.com  Thu Mar 12 20:52:43 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 12 Mar 2015 14:52:43 -0500
Subject: [R] regex find anything which is not a number
In-Reply-To: <CCE952776B6679469977532BD863C39C9A68E21F@Lewis.autuni.aut.ac.nz>
References: <CAJ=0CtBws+3cDQkqgWD98cpFc5ysvOZEeB+DK=KLbOCJYWcEXw@mail.gmail.com>
	<CCE952776B6679469977532BD863C39C9A68E21F@Lewis.autuni.aut.ac.nz>
Message-ID: <CAAJSdjh9ZZ9PU1fgZTdpns4PHoVfsCD-vL35W8-VobO_94pjhw@mail.gmail.com>

On Thu, Mar 12, 2015 at 2:43 PM, Steve Taylor <steve.taylor at aut.ac.nz> wrote:
> How about letting a standard function decide which are numbers:
>
> which(!is.na(suppressWarnings(as.numeric(myvector))))
>
> Also works with numbers in scientific notation and (presumably) different decimal characters, e.g. comma if that's what the locale uses.

One problem is that Adrian wanted, for some reason, to exclude numbers
such as "2." but accept "2.0" . That is, no unnecessary trailing
decimal point. as.numeric() will not fail on "2." since that is a
number. The example grep() specifically excludes this by requiring at
least one digit after any decimal point.

-- 
He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown


From vik at vlr.cc  Thu Mar 12 21:19:56 2015
From: vik at vlr.cc (Vik Rubenfeld)
Date: Thu, 12 Mar 2015 13:19:56 -0700
Subject: [R] Using choiceDes Package to Design MaxDiff?
Message-ID: <59A14C2D-0EEA-4266-9BD3-2CFA10674DFF@vlr.cc>

I?m seeking to design a MaxDiff experiment that will have a number of blocks of this type:

Which of these items is the
most important?

Which of these items is the 
least important?

Item 1
Item 2
Item 3
Item 4

I?m seeking to use the choiceDes package <http://cran.r-project.org/web/packages/choiceDes/choiceDes.pdf> to design the experiment. The relevant function is tradeoff.des. Usage:

tradeoff.des(items, shown, vers, tasks, fname=NULL, Rd=20, Rc=NULL, print=TRUE)

I believe I understand the items, shown and vers parameters:
items: number of total items in the experiment
show: number of items shown per block
vers: number of blocks
...but I?m not quite sure what the tasks parameter is yet. For example, let?s say I have 20 items total in the study. I want to show 4 items per block, with 10 blocks total. I enter:

tempDes <- tradeoff.des(20, 4, 10, 2, "tempDesign.txt", 20, NULL, TRUE)

?hoping that the 2 is the number of questions (most important/least important) per block. I get an error:

Error in optBlock(~., des.d, rep(tasks, vers), nRepeats = Rd) : 
  The number of withinData rows is not large enough to support the blocked model.

If I put the number of blocks up to 50:

 tempDes <- tradeoff.des(20, 4, 50, 2, "tempDesign.txt", 20, NULL, TRUE)

?I get the same error. 

What is the correct way to use choiceDes to design a MaxDiff experiment of this kind?

Thanks very much in advance to all for any thoughts or info!

Best,


-Vik



	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Mar 12 21:37:27 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 13 Mar 2015 09:37:27 +1300
Subject: [R] .Rdata files -- fortune?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23888@SRVEXCHMBX.precheza.cz>
References: <mailman.1.1426071602.12262.r-help@r-project.org>	<55003C5F.70904@uottawa.ca>
	<20150311154415.GB2730@localhost>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23888@SRVEXCHMBX.precheza.cz>
Message-ID: <5501F907.2050105@auckland.ac.nz>

On 12/03/15 19:38, PIKAL Petr wrote:

<SNIP>
>>
>> On Wed, Mar 11, 2015 at 09:00:15AM -0400, Prof J C Nash (U30A) wrote:

<SNIP>

>> Personally I think that auto saving / restoring workspaces should be
>> reviewed, as it can, in practice, make it harder for people to render
>> their work in a self-contained and reproducible way.

> If this is considered I would beg for addind an option to keep
> autosave work for those who have different approach. If you keep the
> paradigm one project = one separate directory there shall be no
> problem with autosaving as you have only one Rdata file together with
> exported pictures, pdfs, xls and doc files.
>
> If you save history to separate files you can also easily keep track
> of your work. If autosave is disabled and you could leave your
> session without warning I bet that there would be hundereds of
> questions similar to:
>
> I worked whole day and after quitting R all my work is lost.

*Very* well put.

I very much advocate keeping the current system as-is.  There is nothing 
at all wrong with .RData files as long as you understand the concept of 
"workspace" and "global environment" --- i.e. as long as you understand 
WTF you're doing.  And if you don't understand, you shouldn't be doing it.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From axel.urbiz at gmail.com  Thu Mar 12 21:39:24 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Thu, 12 Mar 2015 16:39:24 -0400
Subject: [R] Installing R on Linux Red Hat Server
Message-ID: <CAAyVsXJWw_NfWQ8jZg1_igg=ZBmM7cppGULFSAU2-JU7+rwpvg@mail.gmail.com>

Hello,

My apologies if this is not the right place to post this question.

I need to get R installed on a Linux Red Hat server. I have very limited
exposure to R and would appreciate some basic guidance if you could point
me to resources describing the process, requirements, etc.

Thank you in advance for any help.

Best,
Axel.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Mar 12 21:50:27 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 12 Mar 2015 21:50:27 +0100
Subject: [R] write.csv to text string?
In-Reply-To: <5501DA1D.9020402@sapo.pt>
References: <5501C9BF.4080009@gmail.com> <5501DA1D.9020402@sapo.pt>
Message-ID: <F7AF7222-164E-4380-ABEC-82E4B45AADAD@gmail.com>

Or, more in line with what was asked:

con <- textConnection("foo", "w")
write.csv(file=con, airquality)
close(con)
foo

It does, incidentally, look possible to equip write.table (of which write.csv is a special case) with an intern=TRUE setting, which could effectively do the above internally and return the result. There is no documented return value from write.table as far as I can tell.

-pd

> On 12 Mar 2015, at 19:25 , Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> Maybe using text connections. See ?textConnection.
> 
> tc <- textConnection("foo", "w")
> s <- 'cola,colb\n1,2\n2,3\n'
> cat(s, file = tc)
> close(tc)
> foo
> 
> read.csv(text = foo)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 12-03-2015 17:15, Thomas Nyberg escreveu:
>> Hello,
>> 
>> I've found the following useful functionality:
>> 
>>> s <- 'cola,colb\n1,2\n2,3\n'
>>> read.csv(text=s)
>>   cola colb
>> 1    1    2
>> 2    2    3
>> 
>> 
>> But I haven't found a similar option in write.csv. I.e. I would like to
>> "write" a dataframe to a string. What would be the easiest way to go
>> about such a thing? Right now I can only think of using a file as an
>> intermediary, but that seems a bit silly. Thanks for any help.
>> 
>> Cheers,
>> Thomas Nyberg
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From marc_schwartz at me.com  Thu Mar 12 21:55:32 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 12 Mar 2015 15:55:32 -0500
Subject: [R] Installing R on Linux Red Hat Server
In-Reply-To: <CAAyVsXJWw_NfWQ8jZg1_igg=ZBmM7cppGULFSAU2-JU7+rwpvg@mail.gmail.com>
References: <CAAyVsXJWw_NfWQ8jZg1_igg=ZBmM7cppGULFSAU2-JU7+rwpvg@mail.gmail.com>
Message-ID: <C313D5B8-1E2C-4359-B6CC-F24D593C037C@me.com>


> On Mar 12, 2015, at 3:39 PM, Axel Urbiz <axel.urbiz at gmail.com> wrote:
> 
> Hello,
> 
> My apologies if this is not the right place to post this question.
> 
> I need to get R installed on a Linux Red Hat server. I have very limited
> exposure to R and would appreciate some basic guidance if you could point
> me to resources describing the process, requirements, etc.
> 
> Thank you in advance for any help.
> 
> Best,
> Axel.


Hi,

Pointers to some references:

1. The EPEL, which is how you would obtain pre-compiled binary RPMs of R. You will need to have root permissions on the server in order to do this. Once their yum repos are configured on your server, 'sudo yum install R' is essentially what you would need.

  https://fedoraproject.org/wiki/EPEL


2. The R Installation and Administration Manual, which will provide some guidance, in the Linux section and in the appendices (primarily A) for additional items that may be relevant:

  http://cran.r-project.org/manuals.html


3. The R-SIG-Fedora list, which is focused on the use of R on RH and derivative (eg. Fedora) Linux distributions. Follow up questions should be posted there, ideally after you subscribe, lest you be subject to on-going moderation (speaking as a co-moderator of that list).

  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora


Regards,

Marc Schwartz


From sarah.goslee at gmail.com  Thu Mar 12 21:56:55 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 12 Mar 2015 16:56:55 -0400
Subject: [R] Installing R on Linux Red Hat Server
In-Reply-To: <CAAyVsXJWw_NfWQ8jZg1_igg=ZBmM7cppGULFSAU2-JU7+rwpvg@mail.gmail.com>
References: <CAAyVsXJWw_NfWQ8jZg1_igg=ZBmM7cppGULFSAU2-JU7+rwpvg@mail.gmail.com>
Message-ID: <CAM_vju=BKq=2tLVFT6YdV78LHbM7qPPHB7QbTCP5oPWJr=_dcQ@mail.gmail.com>

"Use your package manager" seems like a good place to start.

Googling "install R redhat" seems like another good starting point.

I think for RedHat you'll probably want the EPEL repo.

Sarah

On Thu, Mar 12, 2015 at 4:39 PM, Axel Urbiz <axel.urbiz at gmail.com> wrote:
> Hello,
>
> My apologies if this is not the right place to post this question.
>
> I need to get R installed on a Linux Red Hat server. I have very limited
> exposure to R and would appreciate some basic guidance if you could point
> me to resources describing the process, requirements, etc.
>
> Thank you in advance for any help.
>
> Best,
> Axel.
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From pdalgd at gmail.com  Thu Mar 12 22:06:42 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 12 Mar 2015 22:06:42 +0100
Subject: [R] Installing R on Linux Red Hat Server
In-Reply-To: <CAAyVsXJWw_NfWQ8jZg1_igg=ZBmM7cppGULFSAU2-JU7+rwpvg@mail.gmail.com>
References: <CAAyVsXJWw_NfWQ8jZg1_igg=ZBmM7cppGULFSAU2-JU7+rwpvg@mail.gmail.com>
Message-ID: <3AFB7150-52EC-47BA-AF1D-C28318503E0A@gmail.com>


> On 12 Mar 2015, at 21:39 , Axel Urbiz <axel.urbiz at gmail.com> wrote:
> 
> Hello,
> 
> My apologies if this is not the right place to post this question.

The R-sig-Fedora list is rather more densely packed with people who know about redhat/fedora. 

> I need to get R installed on a Linux Red Hat server. I have very limited
> exposure to R and would appreciate some basic guidance if you could point
> me to resources describing the process, requirements, etc.

It is basically "yum install R", but you need to jiggle repositories around a litte, according to the blog entry below.

https://bluehatrecord.wordpress.com/2014/10/13/installing-r-on-red-hat-enterprise-linux-6-5/ 


> Thank you in advance for any help.
> 
> Best,
> Axel.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tomuxiong at gmail.com  Thu Mar 12 19:23:11 2015
From: tomuxiong at gmail.com (Thomas Nyberg)
Date: Thu, 12 Mar 2015 14:23:11 -0400
Subject: [R] write.csv to text string?
In-Reply-To: <CAAJSdjiNgLZRxjyoyu3OL4ruHXd3UTR4jkz07Bmik60o_1aTNQ@mail.gmail.com>
References: <5501C9BF.4080009@gmail.com>
	<CAAJSdjiNgLZRxjyoyu3OL4ruHXd3UTR4jkz07Bmik60o_1aTNQ@mail.gmail.com>
Message-ID: <5501D98F.4010201@gmail.com>

(Forgot to CC my response to the list...)

Thanks a lot this is exactly what I'm looking for! This is how I'll
probably use it...

----------------
> a
  cola colb
1    1    2
2    2    3

> f <- textConnection("s_a", "w")

> write.csv(a, f, row.names=F)

> close(f)

# Next do something with s_a...though probably not the following which #
is pointless.

> s_a
[1] "\"cola\",\"colb\"" "1,2"               "2,3"

> read.csv(text=s_a)
  cola colb
1    1    2
2    2    3
----------------

Thanks again everyone!

Cheers,
Thomas

On 03/12/2015 02:12 PM, John McKown wrote:
> On Thu, Mar 12, 2015 at 12:15 PM, Thomas Nyberg <tomuxiong at gmail.com> wrote:
>> Hello,
>>
>> I've found the following useful functionality:
>>
>>> s <- 'cola,colb\n1,2\n2,3\n'
>>> read.csv(text=s)
>>   cola colb
>> 1    1    2
>> 2    2    3
>>
>>
>> But I haven't found a similar option in write.csv. I.e. I would like to
>> "write" a dataframe to a string. What would be the easiest way to go
>> about such a thing? Right now I can only think of using a file as an
>> intermediary, but that seems a bit silly. Thanks for any help.
>>
>> Cheers,
>> Thomas Nyberg
> 
> Perhaps something like:
> 
> textConn=textConnection("textCSV",open='w');
> write.csv(file=textConn,s)
> print(textCSV)
> 
> 
>


From tomuxiong at gmail.com  Thu Mar 12 20:12:39 2015
From: tomuxiong at gmail.com (Thomas Nyberg)
Date: Thu, 12 Mar 2015 15:12:39 -0400
Subject: [R] write.csv to text string?
In-Reply-To: <CAAJSdjiNgLZRxjyoyu3OL4ruHXd3UTR4jkz07Bmik60o_1aTNQ@mail.gmail.com>
References: <5501C9BF.4080009@gmail.com>
	<CAAJSdjiNgLZRxjyoyu3OL4ruHXd3UTR4jkz07Bmik60o_1aTNQ@mail.gmail.com>
Message-ID: <5501E527.8080909@gmail.com>

I just wanted to send one final message out about this. My previous post
technically works, but is quite slow with large files/strings. I've
decided instead to do it exactly in the way that I was trying to avoid.
So just to set the record straight, these are the functions I'm going to
be using (the second two only so I can avoid a little extra thinking):

-------
write.csv.str <- function(df, row.names=F) {
    filepath <- tempfile()
    f <- file(filepath, "w")
    write.csv(df, f, row.names=row.names)
    close(f)

    s <- readfile(filepath)
    s
}


read.csv.str <- function(s) {
    read.csv(text=s)
}


readfile <- function(filepath) {
    text <- readChar(filepath, file.info(filepath)$size)
    text
}
-------

Thanks for the help everyone.

Cheers,
Thomas

On 03/12/2015 02:12 PM, John McKown wrote:
> On Thu, Mar 12, 2015 at 12:15 PM, Thomas Nyberg <tomuxiong at gmail.com> wrote:
>> Hello,
>>
>> I've found the following useful functionality:
>>
>>> s <- 'cola,colb\n1,2\n2,3\n'
>>> read.csv(text=s)
>>   cola colb
>> 1    1    2
>> 2    2    3
>>
>>
>> But I haven't found a similar option in write.csv. I.e. I would like to
>> "write" a dataframe to a string. What would be the easiest way to go
>> about such a thing? Right now I can only think of using a file as an
>> intermediary, but that seems a bit silly. Thanks for any help.
>>
>> Cheers,
>> Thomas Nyberg
> 
> Perhaps something like:
> 
> textConn=textConnection("textCSV",open='w');
> write.csv(file=textConn,s)
> print(textCSV)
> 
> 
>


From msamtani at gmail.com  Thu Mar 12 22:12:36 2015
From: msamtani at gmail.com (Mahesh Samtani)
Date: Thu, 12 Mar 2015 17:12:36 -0400
Subject: [R] Lagged Covariate
Message-ID: <CAHB+C46RTLqC2xo11cmyOaanCxMYtVTYvdCLeyHeFJ92C3kb8A@mail.gmail.com>

I am doing some mixed effects modeling where we would like to test the
hypothesis that the dependent variable (Dependent.var) as a function of
time depends on the value of the covariate 6 months to a year earlier. The
difficulty is that not all subjects have measurements every 6 months (as
shown below for the 1st three subjects). We would like to derive the new
datasets for the 6 month lag, 1 year lag and so on using efficient code.
For the 6 month lag the Time zero row could get thrown out and the
covariate column would move one cell down (and the covariate value at year
3 would be taken away as well). Is there some easy way to make these
datasets


   Subj.ID TIME Dependent.Var   Covariate
1        1  0.0   -0.02720222  0.05055147
2        1  0.5   -0.95878074  0.07402854
3        1  1.0    0.05178116  0.15676033
4        1  1.5   -0.90101795  0.05398925
5        1  2.0    0.05873045  0.35908569
6        1  2.5   -0.20770872  0.37844074
7        1  3.0    0.60331684 -1.05727034
8        2  0.0   -0.35234081 -0.43684877
9        2  0.5   -3.41076246  0.34309430
10       2  1.0    3.12190327  0.83680466
11       2  1.5   -0.04691748  0.59614786
12       2  2.0   -0.59465266 -0.09676054
13       2  2.5   -2.30089870 -0.68813666
14       2  3.0    0.07287830 -0.72876164
15       3  0.0   -0.94644384 -1.62981406
16       3  0.5   -1.06351763  0.19774138
17       3  1.0   -0.46948937 -0.59600225
18       3  1.5    1.80077781  0.46992426
19       3  2.0   -0.27466530  1.22268195
20       3  2.5   -0.87696707 -2.29894151
21       3  3.0    0.45811417  1.76158843

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Mar 12 22:19:33 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 12 Mar 2015 14:19:33 -0700
Subject: [R] .Rdata files -- fortune?
In-Reply-To: <5501F907.2050105@auckland.ac.nz>
References: <mailman.1.1426071602.12262.r-help@r-project.org>
	<55003C5F.70904@uottawa.ca> <20150311154415.GB2730@localhost>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23888@SRVEXCHMBX.precheza.cz>
	<5501F907.2050105@auckland.ac.nz>
Message-ID: <AB5BECA4-0B86-4CE3-814E-7018D5C94A8D@dcn.davis.CA.us>

I was positive I knew WTF I was doing until you set me straight, Rolf. ;-)
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 12, 2015 1:37:27 PM PDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>On 12/03/15 19:38, PIKAL Petr wrote:
>
><SNIP>
>>>
>>> On Wed, Mar 11, 2015 at 09:00:15AM -0400, Prof J C Nash (U30A)
>wrote:
>
><SNIP>
>
>>> Personally I think that auto saving / restoring workspaces should be
>>> reviewed, as it can, in practice, make it harder for people to
>render
>>> their work in a self-contained and reproducible way.
>
>> If this is considered I would beg for addind an option to keep
>> autosave work for those who have different approach. If you keep the
>> paradigm one project = one separate directory there shall be no
>> problem with autosaving as you have only one Rdata file together with
>> exported pictures, pdfs, xls and doc files.
>>
>> If you save history to separate files you can also easily keep track
>> of your work. If autosave is disabled and you could leave your
>> session without warning I bet that there would be hundereds of
>> questions similar to:
>>
>> I worked whole day and after quitting R all my work is lost.
>
>*Very* well put.
>
>I very much advocate keeping the current system as-is.  There is
>nothing 
>at all wrong with .RData files as long as you understand the concept of
>
>"workspace" and "global environment" --- i.e. as long as you understand
>
>WTF you're doing.  And if you don't understand, you shouldn't be doing
>it.
>
>cheers,
>
>Rolf Turner


From dusa.adrian at unibuc.ro  Thu Mar 12 23:05:20 2015
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Fri, 13 Mar 2015 00:05:20 +0200
Subject: [R] regex find anything which is not a number
In-Reply-To: <CAAJSdjh9ZZ9PU1fgZTdpns4PHoVfsCD-vL35W8-VobO_94pjhw@mail.gmail.com>
References: <CAJ=0CtBws+3cDQkqgWD98cpFc5ysvOZEeB+DK=KLbOCJYWcEXw@mail.gmail.com>
	<CCE952776B6679469977532BD863C39C9A68E21F@Lewis.autuni.aut.ac.nz>
	<CAAJSdjh9ZZ9PU1fgZTdpns4PHoVfsCD-vL35W8-VobO_94pjhw@mail.gmail.com>
Message-ID: <CAJ=0CtACcFEj7Msr_yO0tj5tpRNVk+aa_kbsfjbMOJK9T9iLhQ@mail.gmail.com>

On Thu, Mar 12, 2015 at 9:52 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> [...]
> One problem is that Adrian wanted, for some reason, to exclude numbers
> such as "2." but accept "2.0" . That is, no unnecessary trailing
> decimal point. as.numeric() will not fail on "2." since that is a
> number. The example grep() specifically excludes this by requiring at
> least one digit after any decimal point.

Indeed, but that was completely unintentional since I knew ".2" should
be a number and I somehow thought "2." was not supposed to be a
number.
I learned a lot about regular expressions (thanks again John), and
both solutions work (thanks very much Steve as well).

Best,
Adrian

-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania


From ssefick at gmail.com  Thu Mar 12 23:40:12 2015
From: ssefick at gmail.com (stephen sefick)
Date: Thu, 12 Mar 2015 17:40:12 -0500
Subject: [R] Installing R on Linux Red Hat Server
In-Reply-To: <CAAyVsXJWw_NfWQ8jZg1_igg=ZBmM7cppGULFSAU2-JU7+rwpvg@mail.gmail.com>
References: <CAAyVsXJWw_NfWQ8jZg1_igg=ZBmM7cppGULFSAU2-JU7+rwpvg@mail.gmail.com>
Message-ID: <CADKEMqgt329gAAN_NbAseFbUbhNT4z0m+tA2OPAKW1+MUAwxog@mail.gmail.com>

Axel, I am running SL 6.5. I use EPEL for R related things without much
hassle.
FWIW,

Stephen

On Thu, Mar 12, 2015 at 3:39 PM, Axel Urbiz <axel.urbiz at gmail.com> wrote:

> Hello,
>
> My apologies if this is not the right place to post this question.
>
> I need to get R installed on a Linux Red Hat server. I have very limited
> exposure to R and would appreciate some basic guidance if you could point
> me to resources describing the process, requirements, etc.
>
> Thank you in advance for any help.
>
> Best,
> Axel.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Fri Mar 13 01:03:50 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 13 Mar 2015 00:03:50 +0000
Subject: [R] Installing R on Linux Red Hat Server
In-Reply-To: <CAAyVsXJWw_NfWQ8jZg1_igg=ZBmM7cppGULFSAU2-JU7+rwpvg@mail.gmail.com>
References: <CAAyVsXJWw_NfWQ8jZg1_igg=ZBmM7cppGULFSAU2-JU7+rwpvg@mail.gmail.com>
Message-ID: <D1277579.122000%macqueen1@llnl.gov>

In contrast to using a package manager as others have suggested, you can
download the "Source Code for all Platforms" from CRAN (currently
R-3.1.3.tar.gz), unpack it somewhere, and follow the instructions in the
INSTALL file. This has worked well for me.

I don't advise one method in preference to the other.

But I will mention that when I first started installing R on RedHat, quite
a few years ago, I found it easier to install from sources (for reasons
that I won't mention because I have no idea if they are still valid).

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/12/15, 1:39 PM, "Axel Urbiz" <axel.urbiz at gmail.com> wrote:

>Hello,
>
>My apologies if this is not the right place to post this question.
>
>I need to get R installed on a Linux Red Hat server. I have very limited
>exposure to R and would appreciate some basic guidance if you could point
>me to resources describing the process, requirements, etc.
>
>Thank you in advance for any help.
>
>Best,
>Axel.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From miaojpm at gmail.com  Fri Mar 13 03:49:42 2015
From: miaojpm at gmail.com (jpm miao)
Date: Fri, 13 Mar 2015 10:49:42 +0800
Subject: [R] Extracting slots from an object (e.g.: object produced by
 unit root test function "urdfTest")
In-Reply-To: <760CF7BF-00F2-4AF0-9FF5-ECB770CFCFBB@comcast.net>
References: <CABcx46DBznU0WDJh6x+jByW2RSBaa8QeNsQMMXFxkhRxFn=pSQ@mail.gmail.com>
	<760CF7BF-00F2-4AF0-9FF5-ECB770CFCFBB@comcast.net>
Message-ID: <CABcx46C3bj6CZ4Muotrbibvx455iqBeLOvMtTk5WOsYSXyD5Pw@mail.gmail.com>

Thank you very much.

Could we extract the p-value in the output of the ur.df function? Does
there exist any unit root test function where the p-value can be extracted?
Thanks!

An example for ur.df function:

data(Raotbl3)
attach(Raotbl3)
lc.df <- ur.df(y=lc, lags=3, type='trend')
summary(lc.df)

2015-03-13 1:23 GMT+08:00 David Winsemius <dwinsemius at comcast.net>:

>
> On Mar 12, 2015, at 1:04 AM, jpm miao wrote:
>
> > Hi,
> >
> >   I run a statistical test function in the package "fUnitRoots" that
> > returns a S4 object but I am wondering how to extract the p-value, one of
> > the output elements.
>
> > The document of the function "urdfTest":
> > .....
> > All tests return an object of class "fHTEST" with the following slots:
> >
> > @call
> > .....
> > @test
> > a list object which holds the output of the underlying test function.
> > @title
> > .....
> > The entries of the @test slot include the following components:
> >
> > $statistic
> > ......
> > $p.value
> > the p-value of the test.
> > .....
> > (end)
> >
> >   I store the result of the test test in an element of a list
> > (adf1["r3m"][[1]]), and I want to extract the p-value. I was expecting
> the
> > p-value via adf1["r3m"][[1]]@test$p.value but it gives only an error
> > message. Could someone tell me how to extract the p-value? Thanks!!!
>
> If you look at the code by typing: fUnitRoots::urdfTest,  you should
> quickly see why you are seeing text output:
>
> That function is doing the equivalent of a console screenscrape:
>
> ...
> output = capture.output(summary(urca))[-(1:4)]
> ...
> # and then assigns a trimmed version of that result to the `test`- slot.
>
>
> So the documentation is misleading in suggesting that a list object is
> being returned in the `test` slot. It's just a character vestor.
>
>
> --
> >
> >> adf1["r3m"][[1]]<-urdfTest(dat[,i], lags = 1, type = "ct")
> >> adf1["r3m"][[1]]
> > [1] "  "
> > [2] "  Test regression trend "
> > [3] "  "
> > [4] "  Call:"
> > [5] "  lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)"
> > [6] "  "
> > [7] "  Residuals:"
> > [8] "      Min      1Q  Median      3Q     Max "
> > [9] "  -3.0785 -0.0485  0.0072  0.0627  3.5672 "
> > [10] "  "
> > [11] "  Coefficients:"
> > [12] "                Estimate Std. Error t value Pr(>|t|)    "
> > [13] "  (Intercept) -1.733e-02  9.529e-03  -1.818  0.06910 .  "
> > [14] "  z.lag.1     -7.060e-03  2.343e-03  -3.013  0.00261 ** "
> > [15] "  tt           5.299e-06  4.927e-06   1.076  0.28221    "
> > [16] "  z.diff.lag  -1.035e-01  1.859e-02  -5.569 2.81e-08 ***"
> > [17] "  ---"
> > [18] "  Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1"
> > [19] "  "
> > [20] "  Residual standard error: 0.2107 on 2864 degrees of freedom"
> > [21] "  Multiple R-squared:  0.01461,\tAdjusted R-squared:  0.01358 "
> > [22] "  F-statistic: 14.15 on 3 and 2864 DF,  p-value: 3.716e-09"
> > [23] "  "
> > [24] "  "
> > [25] "  Value of test-statistic is: -3.0134 3.0697 4.5828 "
> > [26] "  "
> > [27] "  Critical values for test statistics: "
> > [28] "        1pct  5pct 10pct"
> > [29] "  tau3 -3.96 -3.41 -3.12"
> > [30] "  phi2  6.09  4.68  4.03"
> > [31] "  phi3  8.27  6.25  5.34"
> >
>
> That is being displayed as a multi-element text object. You instead need
> to show the code that actually created that object.
>
> >> adf1["r3m"][[1]]@test
> > Error: trying to get slot "test" from an object of a basic class
> > ("character") with no slots
> >> adf1["r3m"][[1]]@test$p-value
> > Error: trying to get slot "test" from an object of a basic class
> > ("character") with no slots
> >
> >       [[alternative HTML version deleted]]
>
> Please learn to post in palin text.
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Fri Mar 13 03:54:49 2015
From: miaojpm at gmail.com (jpm miao)
Date: Fri, 13 Mar 2015 10:54:49 +0800
Subject: [R] Extracting slots from an object (e.g.: object produced by
 unit root test function "urdfTest")
In-Reply-To: <CABcx46C3bj6CZ4Muotrbibvx455iqBeLOvMtTk5WOsYSXyD5Pw@mail.gmail.com>
References: <CABcx46DBznU0WDJh6x+jByW2RSBaa8QeNsQMMXFxkhRxFn=pSQ@mail.gmail.com>
	<760CF7BF-00F2-4AF0-9FF5-ECB770CFCFBB@comcast.net>
	<CABcx46C3bj6CZ4Muotrbibvx455iqBeLOvMtTk5WOsYSXyD5Pw@mail.gmail.com>
Message-ID: <CABcx46A8ViiRokYUFkQC4bG-dSq7pGp7jAA=koiHq2JRZxez3w@mail.gmail.com>

Sorry. Let me modify the question: Does there exist any unit root test
function (with trend or intercept) where the p-value can be extracted? The
function adf.test in tseries package does return the p-value, but there's
no choice of trend or intercept. Thanks.

2015-03-13 10:49 GMT+08:00 jpm miao <miaojpm at gmail.com>:

> Thank you very much.
>
> Could we extract the p-value in the output of the ur.df function? Does
> there exist any unit root test function where the p-value can be extracted?
> Thanks!
>
> An example for ur.df function:
>
> data(Raotbl3)
> attach(Raotbl3)
> lc.df <- ur.df(y=lc, lags=3, type='trend')
> summary(lc.df)
>
> 2015-03-13 1:23 GMT+08:00 David Winsemius <dwinsemius at comcast.net>:
>
>>
>> On Mar 12, 2015, at 1:04 AM, jpm miao wrote:
>>
>> > Hi,
>> >
>> >   I run a statistical test function in the package "fUnitRoots" that
>> > returns a S4 object but I am wondering how to extract the p-value, one
>> of
>> > the output elements.
>>
>> > The document of the function "urdfTest":
>> > .....
>> > All tests return an object of class "fHTEST" with the following slots:
>> >
>> > @call
>> > .....
>> > @test
>> > a list object which holds the output of the underlying test function.
>> > @title
>> > .....
>> > The entries of the @test slot include the following components:
>> >
>> > $statistic
>> > ......
>> > $p.value
>> > the p-value of the test.
>> > .....
>> > (end)
>> >
>> >   I store the result of the test test in an element of a list
>> > (adf1["r3m"][[1]]), and I want to extract the p-value. I was expecting
>> the
>> > p-value via adf1["r3m"][[1]]@test$p.value but it gives only an error
>> > message. Could someone tell me how to extract the p-value? Thanks!!!
>>
>> If you look at the code by typing: fUnitRoots::urdfTest,  you should
>> quickly see why you are seeing text output:
>>
>> That function is doing the equivalent of a console screenscrape:
>>
>> ...
>> output = capture.output(summary(urca))[-(1:4)]
>> ...
>> # and then assigns a trimmed version of that result to the `test`- slot.
>>
>>
>> So the documentation is misleading in suggesting that a list object is
>> being returned in the `test` slot. It's just a character vestor.
>>
>>
>> --
>> >
>> >> adf1["r3m"][[1]]<-urdfTest(dat[,i], lags = 1, type = "ct")
>> >> adf1["r3m"][[1]]
>> > [1] "  "
>> > [2] "  Test regression trend "
>> > [3] "  "
>> > [4] "  Call:"
>> > [5] "  lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)"
>> > [6] "  "
>> > [7] "  Residuals:"
>> > [8] "      Min      1Q  Median      3Q     Max "
>> > [9] "  -3.0785 -0.0485  0.0072  0.0627  3.5672 "
>> > [10] "  "
>> > [11] "  Coefficients:"
>> > [12] "                Estimate Std. Error t value Pr(>|t|)    "
>> > [13] "  (Intercept) -1.733e-02  9.529e-03  -1.818  0.06910 .  "
>> > [14] "  z.lag.1     -7.060e-03  2.343e-03  -3.013  0.00261 ** "
>> > [15] "  tt           5.299e-06  4.927e-06   1.076  0.28221    "
>> > [16] "  z.diff.lag  -1.035e-01  1.859e-02  -5.569 2.81e-08 ***"
>> > [17] "  ---"
>> > [18] "  Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1"
>> > [19] "  "
>> > [20] "  Residual standard error: 0.2107 on 2864 degrees of freedom"
>> > [21] "  Multiple R-squared:  0.01461,\tAdjusted R-squared:  0.01358 "
>> > [22] "  F-statistic: 14.15 on 3 and 2864 DF,  p-value: 3.716e-09"
>> > [23] "  "
>> > [24] "  "
>> > [25] "  Value of test-statistic is: -3.0134 3.0697 4.5828 "
>> > [26] "  "
>> > [27] "  Critical values for test statistics: "
>> > [28] "        1pct  5pct 10pct"
>> > [29] "  tau3 -3.96 -3.41 -3.12"
>> > [30] "  phi2  6.09  4.68  4.03"
>> > [31] "  phi3  8.27  6.25  5.34"
>> >
>>
>> That is being displayed as a multi-element text object. You instead need
>> to show the code that actually created that object.
>>
>> >> adf1["r3m"][[1]]@test
>> > Error: trying to get slot "test" from an object of a basic class
>> > ("character") with no slots
>> >> adf1["r3m"][[1]]@test$p-value
>> > Error: trying to get slot "test" from an object of a basic class
>> > ("character") with no slots
>> >
>> >       [[alternative HTML version deleted]]
>>
>> Please learn to post in palin text.
>>
>> --
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Fri Mar 13 04:30:16 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 12 Mar 2015 22:30:16 -0500
Subject: [R] automate "press enter"
In-Reply-To: <D1272825.24A45%hdoran@air.org>
References: <D1272825.24A45%hdoran@air.org>
Message-ID: <CAN5YmCF-dfZ7sExV14rseoAKCyZedUxPr_KindpsJdMdnvANUg@mail.gmail.com>

Harold,

This did the trick for my application,

options(httr_oauth_cache=TRUE)


See
http://stackoverflow.com/questions/28221405/automated-httr-authentication-with-twitter-provide-response-to-interactive-pro
for details.

Jean

On Thu, Mar 12, 2015 at 10:25 AM, Doran, Harold <HDoran at air.org> wrote:

> I?m dealing with an issue that is seemingly simple, and I?m sure there is
> an obvious solution. I?m writing a wrapper function that calls functions
> from another package (twitteR).
>
> However, the function I happen to be using in that package prompts the
> user the user to enter a ?1? or a ?2? in the workspace before the user can
> proceed. The actual process looks like this:
>
> > setup_twitter_oauth(APIkey,APIsecret, Accesstoken, Accesssecret)
>
> Use a local file to cache OAuth access credentials between R sessions?
> 1: Yes
> 2: No
>
> I know I want the value  ?2? to be entered, but I cannot figure out how to
> automate it without a human actually entering ?2? and hitting enter when
> prompted.
>
> Is it possible to automate this so the user doesn?t have to manually hit
> enter?
>
> Harold
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Mar 13 05:52:24 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 12 Mar 2015 21:52:24 -0700
Subject: [R] Extracting slots from an object (e.g.: object produced by
	unit root test function "urdfTest")
In-Reply-To: <CABcx46C3bj6CZ4Muotrbibvx455iqBeLOvMtTk5WOsYSXyD5Pw@mail.gmail.com>
References: <CABcx46DBznU0WDJh6x+jByW2RSBaa8QeNsQMMXFxkhRxFn=pSQ@mail.gmail.com>
	<760CF7BF-00F2-4AF0-9FF5-ECB770CFCFBB@comcast.net>
	<CABcx46C3bj6CZ4Muotrbibvx455iqBeLOvMtTk5WOsYSXyD5Pw@mail.gmail.com>
Message-ID: <5CCFD81F-6BDC-4EE7-8A39-EBE9BBFDA3CE@comcast.net>


On Mar 12, 2015, at 7:49 PM, jpm miao wrote:

> Thank you very much. 
> 
> Could we extract the p-value in the output of the ur.df function? Does there exist any unit root test function where the p-value can be extracted? Thanks!

If this were an S3 function, it would be a fairly simple operation to hack that code so that it actually delivered what was promised. Then you could use the code you originally attempted. It's not a very large function. In fact I see no reason why you couldn't extract the code you needed and make an S3 function. Or even just use `summary` on the first argument and pull the p-value from the returned object. Many possibilities.

-- 
David.


> 
> An example for ur.df function:
> 
> data(Raotbl3)
> attach(Raotbl3)
> lc.df <- ur.df(y=lc, lags=3, type='trend')
> summary(lc.df)
> 
> 2015-03-13 1:23 GMT+08:00 David Winsemius <dwinsemius at comcast.net>:
> 
> On Mar 12, 2015, at 1:04 AM, jpm miao wrote:
> 
> > Hi,
> >
> >   I run a statistical test function in the package "fUnitRoots" that
> > returns a S4 object but I am wondering how to extract the p-value, one of
> > the output elements.
> 
> > The document of the function "urdfTest":
> > .....
> > All tests return an object of class "fHTEST" with the following slots:
> >
> > @call
> > .....
> > @test
> > a list object which holds the output of the underlying test function.
> > @title
> > .....
> > The entries of the @test slot include the following components:
> >
> > $statistic
> > ......
> > $p.value
> > the p-value of the test.
> > .....
> > (end)
> >
> >   I store the result of the test test in an element of a list
> > (adf1["r3m"][[1]]), and I want to extract the p-value. I was expecting the
> > p-value via adf1["r3m"][[1]]@test$p.value but it gives only an error
> > message. Could someone tell me how to extract the p-value? Thanks!!!
> 
> If you look at the code by typing: fUnitRoots::urdfTest,  you should quickly see why you are seeing text output:
> 
> That function is doing the equivalent of a console screenscrape:
> 
> ...
> output = capture.output(summary(urca))[-(1:4)]
> ...
> # and then assigns a trimmed version of that result to the `test`- slot.
> 
> 
> So the documentation is misleading in suggesting that a list object is being returned in the `test` slot. It's just a character vestor.
> 
> 
> --
> >
> >> adf1["r3m"][[1]]<-urdfTest(dat[,i], lags = 1, type = "ct")
> >> adf1["r3m"][[1]]
> > [1] "  "
> > [2] "  Test regression trend "
> > [3] "  "
> > [4] "  Call:"
> > [5] "  lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)"
> > [6] "  "
> > [7] "  Residuals:"
> > [8] "      Min      1Q  Median      3Q     Max "
> > [9] "  -3.0785 -0.0485  0.0072  0.0627  3.5672 "
> > [10] "  "
> > [11] "  Coefficients:"
> > [12] "                Estimate Std. Error t value Pr(>|t|)    "
> > [13] "  (Intercept) -1.733e-02  9.529e-03  -1.818  0.06910 .  "
> > [14] "  z.lag.1     -7.060e-03  2.343e-03  -3.013  0.00261 ** "
> > [15] "  tt           5.299e-06  4.927e-06   1.076  0.28221    "
> > [16] "  z.diff.lag  -1.035e-01  1.859e-02  -5.569 2.81e-08 ***"
> > [17] "  ---"
> > [18] "  Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1"
> > [19] "  "
> > [20] "  Residual standard error: 0.2107 on 2864 degrees of freedom"
> > [21] "  Multiple R-squared:  0.01461,\tAdjusted R-squared:  0.01358 "
> > [22] "  F-statistic: 14.15 on 3 and 2864 DF,  p-value: 3.716e-09"
> > [23] "  "
> > [24] "  "
> > [25] "  Value of test-statistic is: -3.0134 3.0697 4.5828 "
> > [26] "  "
> > [27] "  Critical values for test statistics: "
> > [28] "        1pct  5pct 10pct"
> > [29] "  tau3 -3.96 -3.41 -3.12"
> > [30] "  phi2  6.09  4.68  4.03"
> > [31] "  phi3  8.27  6.25  5.34"
> >
> 
> That is being displayed as a multi-element text object. You instead need to show the code that actually created that object.
> 
> >> adf1["r3m"][[1]]@test
> > Error: trying to get slot "test" from an object of a basic class
> > ("character") with no slots
> >> adf1["r3m"][[1]]@test$p-value
> > Error: trying to get slot "test" from an object of a basic class
> > ("character") with no slots
> >
> >       [[alternative HTML version deleted]]
> 
> Please learn to post in palin text.
> 
> --
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From kathryn.harrold at northampton.ac.uk  Fri Mar 13 10:12:16 2015
From: kathryn.harrold at northampton.ac.uk (kat123)
Date: Fri, 13 Mar 2015 02:12:16 -0700 (PDT)
Subject: [R] QAIC in glmulti
Message-ID: <1426237936824-4704599.post@n4.nabble.com>

I am trying to run glmulti with the critera QAICc.  I have tried running the
script below but it does not work.


mod1 <- glmulti(RRHOV ~ SNH1000 + W1000 + PSS3000 + PAG1000 + PEL1000 +
SR250 + HE250, data = data1, family= poisson, maxsize = 4, level =1, crit =
qaicc, glmulti-cvalue = 1.414)


Is there somewhere (or someway) else I am meant to specify to the chat value
to get glmulti to run?


Best wishes,

Kathryn



--
View this message in context: http://r.789695.n4.nabble.com/QAIC-in-glmulti-tp4704599.html
Sent from the R help mailing list archive at Nabble.com.


From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri Mar 13 10:26:04 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 13 Mar 2015 10:26:04 +0100
Subject: [R] Course and book announcements on r-help
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0699E4FD@UM-MAIL4112.unimaas.nl>

Dear All,

Just wondering: Is there any official policy on announcing R-related courses and books on r-help?

I didn't find anything on this in the posting guide, but http://www.r-project.org/mail.html#instructions says that r-help is, among other things, for "announcements (not covered by 'R-announce' or 'R-packages', see above)". That sounds a bit like this would cover courses and books, but I am not sure. Obviously, R-announce is not meant for that, as it is "for major announcements about the development of R and the availability of new code" and is to be used "for announcements mainly by the R Core Development Team".

I see the occasional course/book announcement, but it seems to me that there are a lot more courses and books out there compared to how many announcements there are related to them on this mailing list. So, I am wondering if such announcements are somewhat implicitly discouraged.

Best,
Wolfgang

--    
Wolfgang Viechtbauer, Ph.D., Statistician    
Department of Psychiatry and Psychology    
School for Mental Health and Neuroscience    
Faculty of Health, Medicine, and Life Sciences    
Maastricht University, P.O. Box 616 (VIJV1)    
6200 MD Maastricht, The Netherlands    
+31 (43) 388-4170 | http://www.wvbauer.com    


From petr.pikal at precheza.cz  Fri Mar 13 12:31:05 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 13 Mar 2015 11:31:05 +0000
Subject: [R] Help with error: arguments imply differing number of rows
In-Reply-To: <CAKXkWh3GQ2vgF=4SvF1jLb19uFeKBY7eDttAd919RU_CTTFcTg@mail.gmail.com>
References: <CAKXkWh3GQ2vgF=4SvF1jLb19uFeKBY7eDttAd919RU_CTTFcTg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23D2F@SRVEXCHMBX.precheza.cz>

Hi

Without further information you probably do not get answers. Everything seems to be same so the only reason can be that the objects seems to be same but they have some inner distinctions, maybe type of variables.

Are results of

str(your.objects)

same in equivalent objects?

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Aman
> Gill
> Sent: Thursday, March 12, 2015 6:08 PM
> To: r-help at r-project.org
> Subject: [R] Help with error: arguments imply differing number of rows
>
> Hello,
>
> I am stuck trying to run an analysis using the package picante. I am
> running two very similar analyses. One works as expected, but when I
> try
> the other, I get the error:
>
> Error in data.frame(PD = PDs, SR = SR) :
>   arguments imply differing number of rows: 34, 35
>
> This is strange to me since the data matrix is the same for both
> analyses
> (numbers of rows and columns are the same; the only difference is the
> order
> of the columns). Each analyses requires a phylogenetic tree (.tre
> file),
> and each tree is very similar. Any thoughts as to what's causing this
> problem? The problem may be specific to the function I'm using [pd()],
> but
> since the error is a data.frame error I thought I'd ask here. Here is
> the
> code I'm using:
>
> This works:
> phyl_tree <- read.nexus("phyl.tre")
> phyl_data <- as.matrix(read.table("phyl_matrix.txt"), header=TRUE, sep
> =
> "\t")
> pd.result <- pd(phyl_data, phyl_tree, include.root = TRUE)
>
> This fails (this matrix.txt file is the same as above, except that
> columns
> are ordered to match the tree; I have also used the above matrix.txt
> file)
> chem_tree <- read.nexus("chem.tre")
> chem_data <- as.matrix(read.table("chem_matrix.txt"), header=TRUE, sep
> =
> "\t")
> pd_chem.result <- pd(chem_data, chem_tree, include.root = TRUE)
>
> ERROR:
> Error in data.frame(PD = PDs, SR = SR) :
>   arguments imply differing number of rows: 34, 35
>
>
> To illustrate that the data for each run are very similar (row and
> column
> names are also the same in both data files):
>
> > phyl_tree
>
> Phylogenetic tree with 9 tips and 7 internal nodes.
>
> Tip labels:
> Heliantheae, Eupatorieae, Helenieae, Gnaphalieae, Anthemideae,
> Astereae, ...
> Node labels:
> root, minCyn, minCic, HelEurHel, HelEur, GnaAnthAst, ...
>
> Rooted; includes branch lengths.
>
> > nrow(phyl_data)
> [1] 35
> > ncol(phyl_data)
> [1] 9
> > class(phyl_data)
> [1] "matrix"
>
>
> > chem_tree
>
> Phylogenetic tree with 9 tips and 7 internal nodes.
>
> Tip labels:
> Heliantheae, Helenieae, Eupatorieae, Astereae, Gnaphlieae, Senecioneae,
> ...
> Node labels:
> root, minC, minAnth, minSen, minGna, HelHel, ...
>
> Rooted; includes branch lengths.
>
> > nrow(chem_data)
> [1] 35
> > ncol(chem_data)
> [1] 9
> > class(chem_data)
> [1] "matrix"
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Mar 13 12:34:42 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 13 Mar 2015 11:34:42 +0000
Subject: [R] graphs
In-Reply-To: <1425852099806.91103@uef.fi>
References: <1425852099806.91103@uef.fi>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23D42@SRVEXCHMBX.precheza.cz>

Hi

Your example is not reproducible, but I presume you could use ggplot together with predict. However, I wonder how do you want to distinguish 68 curves in one picture.
I would

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mir
> Salam
> Sent: Sunday, March 08, 2015 10:57 PM
> To: r-help at r-project.org
> Subject: [R] graphs
>
> Dear all,
>
>  I need help to get different 68  plots specifc fitted curves in one
> plot with respective field data observations (age vs dominant height).
>
>
>
> aspdomH2<-groupedData(domH2~age|plotno,data=aspdomH2)
>
>
>
> names(aspdomH2)
>
> plotno, age, origin, soilcharacter, domH2,
>
>
>
> plotno-different plot no. I have 68 plots
>
> age- every plot have from age 5 to 30 years
>
> origin- two, native aspen and hybrid aspen
>
> domH2<-dominant height
>
> soilcharacter-3, clay, silt and mold. both origin have different soil
> charcter
>
>
>
> #### then I fit model
>
> fm2cham.nlme<-nlme(domH2~cham(age,b0,b1,b2),
>                data=aspdomH2,
>                fixed = list(b0~1+origin+soilcharacter,b1~ 1,b2 ~
> 1+origin+soilcharacter),
>                random = b0+b2~1|plotno,
>                start=c(b0=26.3387,0,0,0,b1=0.1065,b2=1.9453,0,0,0),
>                weights=varPower(form = ~age, 0.5),
>                correlation=corAR1())
>
>
>
> #### parameter values
>
> Fixed effects: list(b0 ~ 1 + origin + soil character, b1 ~ 1, b2 ~ 1 +
> origin + soil character)
>
>                                         Value
> b0.(Intercept)                 21.081124
> b0.origin1                        7.735064
> b0.soilcharactermold   10.689051
> b0.soilcharactersilt       3.906585
> b1                                      0.079035
> b2.(Intercept)                  1.616360
> b2.origin1                        -0.384421
> b2.soilcharactermold      0.612285
> b2.soilcharactersilt          0.527462
>
>
>
> ##### I can easily get the augmented plot.  I got  different 68 plots
> specific curves.
>
> #######
>
> Any body can help me how can I will get all 68 plots specific fitted
> curves in one plot with respective plot specific age and dominant
> height obervations? (x axis will represent age, y axis will represent
> dominant height and fitted curves of all 68 plots)
>
>
>
>
>
>
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From sham3287 at gmail.com  Fri Mar 13 13:00:45 2015
From: sham3287 at gmail.com (Shameem Akhtar)
Date: Fri, 13 Mar 2015 17:30:45 +0530
Subject: [R] need help on RATQ package
Message-ID: <CADb+ogCAQjtWz-9rqsPOCYmnsvCmwauz3gHhqiUFBGEonX3ECA@mail.gmail.com>

at the time ao installing RATQ packages in my R it is showing an error
(package ?RTAQ? is not available (for R version 3.1.0) )
can any one tell me which version of R is suitable for this (RATQ) package.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Mar 13 13:11:44 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 13 Mar 2015 12:11:44 +0000
Subject: [R] need help on RATQ package
In-Reply-To: <CADb+ogCAQjtWz-9rqsPOCYmnsvCmwauz3gHhqiUFBGEonX3ECA@mail.gmail.com>
References: <CADb+ogCAQjtWz-9rqsPOCYmnsvCmwauz3gHhqiUFBGEonX3ECA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23D83@SRVEXCHMBX.precheza.cz>

Hi

I did not find any RATQ package. If you mean RTAQ package it was removed from CRAN

quote:
Package ?RTAQ? was removed from the CRAN repository.

Formerly available versions can be obtained from the archive.

No clean update received after requests on Nov 2012, Dec 2012, Jan 2013; hence archived 2013-02-23.

AFAIK you have 3 options:

1. Use old R version for which is this package available.
2. Copy a RTAQ directory from old R version to new one (it sometimes works)
3. Compile RTAQ package from sources

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shameem
> Akhtar
> Sent: Friday, March 13, 2015 1:01 PM
> To: r-help at r-project.org
> Subject: [R] need help on RATQ package
>
> at the time ao installing RATQ packages in my R it is showing an error
> (package ?RTAQ? is not available (for R version 3.1.0) ) can any one
> tell me which version of R is suitable for this (RATQ) package.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jrkrideau at inbox.com  Fri Mar 13 15:12:17 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 13 Mar 2015 06:12:17 -0800
Subject: [R] graphs
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23D42@SRVEXCHMBX.precheza.cz>
References: <1425852099806.91103@uef.fi>
Message-ID: <B6BCAAD118B.000012B4jrkrideau@inbox.com>

@Petr 

I agree. I think Mir would get a totally unreadable graph. I occasionally look at some spagetti graphs from climate research, and I find 8 - 12 lines are incomprehensible (I'm not a subject matter expert)'

@Mir

Is there any logical way to break down the data ? I think Petr is correct in that ggplot2 should be able to do it but I'd suggest thinking about, perhaps, facetting the data to produce some reasonable number of panels.

Here is a simple three-panel plot to illustrate what I mean but I have easily produced a 9 or 10 panel plot which reduces visual clutter immensely.

library(plyr) library(ggplot2)

df1 = data.frame(basel_asset_class = c("bank","bank","bank","bank","bank","bank","bank","corporate","corporate","corporate","corporate","corporate","corporate","corporate","sovereign","sovereign","sovereign","sovereign","sovereign","sovereign","sovereign"), ratings = c("AAA","AA","A","BBB","BB","B","CCC","AAA","AA","A","BBB","BB","B","CCC","AAA","AA","A","BBB","BB","B","CCC"), default_probability = c(0.0027,0.0029,0.0031,0.0034,0.0037,0.004,0.0043,0.0025,0.0024,0.0024,0.0023,0.0022,0.0021,0.0021,0.003,0.0031,0.0032,0.0033,0.0034,0.0035,0.0036))

names(df1) <- c("class", "rate", "default")

p <- ggplot(df1, aes(rate, default,colour=class)) + geom_point() + facet_grid(class ~.) + theme(legend.position="none") 
p

John Kane
Kingston ON Canada


> -----Original Message-----
> From: petr.pikal at precheza.cz
> Sent: Fri, 13 Mar 2015 11:34:42 +0000
> To: mir.salam at uef.fi, r-help at r-project.org
> Subject: Re: [R] graphs
> 
> Hi
> 
> Your example is not reproducible, but I presume you could use ggplot
> together with predict. However, I wonder how do you want to distinguish
> 68 curves in one picture.
> I would
> 
> Cheers
> Petr
> 
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mir
>> Salam
>> Sent: Sunday, March 08, 2015 10:57 PM
>> To: r-help at r-project.org
>> Subject: [R] graphs
>> 
>> Dear all,
>> 
>>  I need help to get different 68  plots specifc fitted curves in one
>> plot with respective field data observations (age vs dominant height).
>> 
>> 
>> 
>> aspdomH2<-groupedData(domH2~age|plotno,data=aspdomH2)
>> 
>> 
>> 
>> names(aspdomH2)
>> 
>> plotno, age, origin, soilcharacter, domH2,
>> 
>> 
>> 
>> plotno-different plot no. I have 68 plots
>> 
>> age- every plot have from age 5 to 30 years
>> 
>> origin- two, native aspen and hybrid aspen
>> 
>> domH2<-dominant height
>> 
>> soilcharacter-3, clay, silt and mold. both origin have different soil
>> charcter
>> 
>> 
>> 
>> #### then I fit model
>> 
>> fm2cham.nlme<-nlme(domH2~cham(age,b0,b1,b2),
>>                data=aspdomH2,
>>                fixed = list(b0~1+origin+soilcharacter,b1~ 1,b2 ~
>> 1+origin+soilcharacter),
>>                random = b0+b2~1|plotno,
>>                start=c(b0=26.3387,0,0,0,b1=0.1065,b2=1.9453,0,0,0),
>>                weights=varPower(form = ~age, 0.5),
>>                correlation=corAR1())
>> 
>> 
>> 
>> #### parameter values
>> 
>> Fixed effects: list(b0 ~ 1 + origin + soil character, b1 ~ 1, b2 ~ 1 +
>> origin + soil character)
>> 
>>                                         Value
>> b0.(Intercept)                 21.081124
>> b0.origin1                        7.735064
>> b0.soilcharactermold   10.689051
>> b0.soilcharactersilt       3.906585
>> b1                                      0.079035
>> b2.(Intercept)                  1.616360
>> b2.origin1                        -0.384421
>> b2.soilcharactermold      0.612285
>> b2.soilcharactersilt          0.527462
>> 
>> 
>> 
>> ##### I can easily get the augmented plot.  I got  different 68 plots
>> specific curves.
>> 
>> #######
>> 
>> Any body can help me how can I will get all 68 plots specific fitted
>> curves in one plot with respective plot specific age and dominant
>> height obervations? (x axis will represent age, y axis will represent
>> dominant height and fitted curves of all 68 plots)
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>>       [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by the
> recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Fri Mar 13 15:16:19 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 13 Mar 2015 06:16:19 -0800
Subject: [R] Course and book announcements on r-help
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F0699E4FD@UM-MAIL4112.unimaas.nl>
Message-ID: <B6C5B117C2B.000012C7jrkrideau@inbox.com>

I have the feeling that this was discussed 3-4 years ago and the overall opinion seems to be that if the course or book was relevant then it was acceptable on an occasional basis. No spamming-type or mass selling posts were.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: wolfgang.viechtbauer at maastrichtuniversity.nl
> Sent: Fri, 13 Mar 2015 10:26:04 +0100
> To: r-help at r-project.org
> Subject: [R] Course and book announcements on r-help
> 
> Dear All,
> 
> Just wondering: Is there any official policy on announcing R-related
> courses and books on r-help?
> 
> I didn't find anything on this in the posting guide, but
> http://www.r-project.org/mail.html#instructions says that r-help is,
> among other things, for "announcements (not covered by 'R-announce' or
> 'R-packages', see above)". That sounds a bit like this would cover
> courses and books, but I am not sure. Obviously, R-announce is not meant
> for that, as it is "for major announcements about the development of R
> and the availability of new code" and is to be used "for announcements
> mainly by the R Core Development Team".
> 
> I see the occasional course/book announcement, but it seems to me that
> there are a lot more courses and books out there compared to how many
> announcements there are related to them on this mailing list. So, I am
> wondering if such announcements are somewhat implicitly discouraged.
> 
> Best,
> Wolfgang
> 
> --
> Wolfgang Viechtbauer, Ph.D., Statistician
> Department of Psychiatry and Psychology
> School for Mental Health and Neuroscience
> Faculty of Health, Medicine, and Life Sciences
> Maastricht University, P.O. Box 616 (VIJV1)
> 6200 MD Maastricht, The Netherlands
> +31 (43) 388-4170 | http://www.wvbauer.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From mir.salam at uef.fi  Fri Mar 13 17:27:06 2015
From: mir.salam at uef.fi (Mir Salam)
Date: Fri, 13 Mar 2015 16:27:06 +0000
Subject: [R] graphs
In-Reply-To: <B6BCAAD118B.000012B4jrkrideau@inbox.com>
References: <1425852099806.91103@uef.fi>,
	<B6BCAAD118B.000012B4jrkrideau@inbox.com>
Message-ID: <1426264319187.82319@uef.fi>


__Dear all,

You can see the plot specif curves in the enclosed document. Inclusion of all plot specif curves in one plot may not be look  good and finally it will be unreadable. I am agree with Petrr and John. This graph is more readable.


Best regards
Salam








______________________________________
From: John Kane <jrkrideau at inbox.com>
Sent: Friday, March 13, 2015 4:12 PM
To: PIKAL Petr; Mir Salam; r-help at r-project.org
Subject: Re: [R] graphs

@Petr

I agree. I think Mir would get a totally unreadable graph. I occasionally look at some spagetti graphs from climate research, and I find 8 - 12 lines are incomprehensible (I'm not a subject matter expert)'

@Mir

Is there any logical way to break down the data ? I think Petr is correct in that ggplot2 should be able to do it but I'd suggest thinking about, perhaps, facetting the data to produce some reasonable number of panels.

Here is a simple three-panel plot to illustrate what I mean but I have easily produced a 9 or 10 panel plot which reduces visual clutter immensely.

library(plyr) library(ggplot2)

df1 = data.frame(basel_asset_class = c("bank","bank","bank","bank","bank","bank","bank","corporate","corporate","corporate","corporate","corporate","corporate","corporate","sovereign","sovereign","sovereign","sovereign","sovereign","sovereign","sovereign"), ratings = c("AAA","AA","A","BBB","BB","B","CCC","AAA","AA","A","BBB","BB","B","CCC","AAA","AA","A","BBB","BB","B","CCC"), default_probability = c(0.0027,0.0029,0.0031,0.0034,0.0037,0.004,0.0043,0.0025,0.0024,0.0024,0.0023,0.0022,0.0021,0.0021,0.003,0.0031,0.0032,0.0033,0.0034,0.0035,0.0036))

names(df1) <- c("class", "rate", "default")

p <- ggplot(df1, aes(rate, default,colour=class)) + geom_point() + facet_grid(class ~.) + theme(legend.position="none")
p

John Kane
Kingston ON Canada


> -----Original Message-----
> From: petr.pikal at precheza.cz
> Sent: Fri, 13 Mar 2015 11:34:42 +0000
> To: mir.salam at uef.fi, r-help at r-project.org
> Subject: Re: [R] graphs
>
> Hi
>
> Your example is not reproducible, but I presume you could use ggplot
> together with predict. However, I wonder how do you want to distinguish
> 68 curves in one picture.
> I would
>
> Cheers
> Petr
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mir
>> Salam
>> Sent: Sunday, March 08, 2015 10:57 PM
>> To: r-help at r-project.org
>> Subject: [R] graphs
>>
>> Dear all,
>>
>>  I need help to get different 68  plots specifc fitted curves in one
>> plot with respective field data observations (age vs dominant height).
>>
>>
>>
>> aspdomH2<-groupedData(domH2~age|plotno,data=aspdomH2)
>>
>>
>>
>> names(aspdomH2)
>>
>> plotno, age, origin, soilcharacter, domH2,
>>
>>
>>
>> plotno-different plot no. I have 68 plots
>>
>> age- every plot have from age 5 to 30 years
>>
>> origin- two, native aspen and hybrid aspen
>>
>> domH2<-dominant height
>>
>> soilcharacter-3, clay, silt and mold. both origin have different soil
>> charcter
>>
>>
>>
>> #### then I fit model
>>
>> fm2cham.nlme<-nlme(domH2~cham(age,b0,b1,b2),
>>                data=aspdomH2,
>>                fixed = list(b0~1+origin+soilcharacter,b1~ 1,b2 ~
>> 1+origin+soilcharacter),
>>                random = b0+b2~1|plotno,
>>                start=c(b0=26.3387,0,0,0,b1=0.1065,b2=1.9453,0,0,0),
>>                weights=varPower(form = ~age, 0.5),
>>                correlation=corAR1())
>>
>>
>>
>> #### parameter values
>>
>> Fixed effects: list(b0 ~ 1 + origin + soil character, b1 ~ 1, b2 ~ 1 +
>> origin + soil character)
>>
>>                                         Value
>> b0.(Intercept)                 21.081124
>> b0.origin1                        7.735064
>> b0.soilcharactermold   10.689051
>> b0.soilcharactersilt       3.906585
>> b1                                      0.079035
>> b2.(Intercept)                  1.616360
>> b2.origin1                        -0.384421
>> b2.soilcharactermold      0.612285
>> b2.soilcharactersilt          0.527462
>>
>>
>>
>> ##### I can easily get the augmented plot.  I got  different 68 plots
>> specific curves.
>>
>> #######
>>
>> Any body can help me how can I will get all 68 plots specific fitted
>> curves in one plot with respective plot specific age and dominant
>> height obervations? (x axis will represent age, y axis will represent
>> dominant height and fitted curves of all 68 plots)
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by the
> recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.
Check it out at http://mysecurelogon.com/manager


-------------- next part --------------
A non-text attachment was scrubbed...
Name: aug-2.pdf
Type: application/pdf
Size: 36220 bytes
Desc: aug-2.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150313/84f290d4/attachment.pdf>

From dwinsemius at comcast.net  Fri Mar 13 18:56:14 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Mar 2015 10:56:14 -0700
Subject: [R] graphs
In-Reply-To: <1426264319187.82319@uef.fi>
References: <1425852099806.91103@uef.fi>,
	<B6BCAAD118B.000012B4jrkrideau@inbox.com>
	<1426264319187.82319@uef.fi>
Message-ID: <C5F21FBE-2DBE-4B33-B6AF-97488FBF3C1C@comcast.net>


On Mar 13, 2015, at 9:27 AM, Mir Salam wrote:

> 
> __Dear all,
> 
> You can see the plot specif curves in the enclosed document. Inclusion of all plot specif curves in one plot may not be look  good and finally it will be unreadable. I am agree with Petrr and John. This graph is more readable.
> 

You should remember that both lattice (and, I seem to vaguely remember, ggplot2) allow specification of three "dimensions" for plot layout, the third being for pages. For xyplot which I think is the underlying mechanism for nmle-plot methods, the parameter is `layout` which can be a vector of length 2 or 3. This would only apply to multipage graphics devices but you seem to ahve figured out how to make PDFs so that should apply.

> 
> Best regards
> Salam
> 
> 
> 
> ______________________________________
> From: John Kane <jrkrideau at inbox.com>
> Sent: Friday, March 13, 2015 4:12 PM
> To: PIKAL Petr; Mir Salam; r-help at r-project.org
> Subject: Re: [R] graphs
> 
> @Petr
> 
> I agree. I think Mir would get a totally unreadable graph. I occasionally look at some spagetti graphs from climate research, and I find 8 - 12 lines are incomprehensible (I'm not a subject matter expert)'
> 
> @Mir
> 
> Is there any logical way to break down the data ? I think Petr is correct in that ggplot2 should be able to do it but I'd suggest thinking about, perhaps, facetting the data to produce some reasonable number of panels.
> 
> Here is a simple three-panel plot to illustrate what I mean but I have easily produced a 9 or 10 panel plot which reduces visual clutter immensely.
> 
> library(plyr) library(ggplot2)
> 
> df1 = data.frame(basel_asset_class = c("bank","bank","bank","bank","bank","bank","bank","corporate","corporate","corporate","corporate","corporate","corporate","corporate","sovereign","sovereign","sovereign","sovereign","sovereign","sovereign","sovereign"), ratings = c("AAA","AA","A","BBB","BB","B","CCC","AAA","AA","A","BBB","BB","B","CCC","AAA","AA","A","BBB","BB","B","CCC"), default_probability = c(0.0027,0.0029,0.0031,0.0034,0.0037,0.004,0.0043,0.0025,0.0024,0.0024,0.0023,0.0022,0.0021,0.0021,0.003,0.0031,0.0032,0.0033,0.0034,0.0035,0.0036))
> 
> names(df1) <- c("class", "rate", "default")
> 
> p <- ggplot(df1, aes(rate, default,colour=class)) + geom_point() + facet_grid(class ~.) + theme(legend.position="none")
> p
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: petr.pikal at precheza.cz
>> Sent: Fri, 13 Mar 2015 11:34:42 +0000
>> To: mir.salam at uef.fi, r-help at r-project.org
>> Subject: Re: [R] graphs
>> 
>> Hi
>> 
>> Your example is not reproducible, but I presume you could use ggplot
>> together with predict. However, I wonder how do you want to distinguish
>> 68 curves in one picture.
>> I would
>> 
>> Cheers
>> Petr
>> 
>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mir
>>> Salam
>>> Sent: Sunday, March 08, 2015 10:57 PM
>>> To: r-help at r-project.org
>>> Subject: [R] graphs
>>> 
>>> Dear all,
>>> 
>>> I need help to get different 68  plots specifc fitted curves in one
>>> plot with respective field data observations (age vs dominant height).
>>> 
>>> 
>>> 
>>> aspdomH2<-groupedData(domH2~age|plotno,data=aspdomH2)
>>> 
>>> 
>>> 
>>> names(aspdomH2)
>>> 
>>> plotno, age, origin, soilcharacter, domH2,
>>> 
>>> 
>>> 
>>> plotno-different plot no. I have 68 plots
>>> 
>>> age- every plot have from age 5 to 30 years
>>> 
>>> origin- two, native aspen and hybrid aspen
>>> 
>>> domH2<-dominant height
>>> 
>>> soilcharacter-3, clay, silt and mold. both origin have different soil
>>> charcter
>>> 
>>> 
>>> 
>>> #### then I fit model
>>> 
>>> fm2cham.nlme<-nlme(domH2~cham(age,b0,b1,b2),
>>>               data=aspdomH2,
>>>               fixed = list(b0~1+origin+soilcharacter,b1~ 1,b2 ~
>>> 1+origin+soilcharacter),
>>>               random = b0+b2~1|plotno,
>>>               start=c(b0=26.3387,0,0,0,b1=0.1065,b2=1.9453,0,0,0),
>>>               weights=varPower(form = ~age, 0.5),
>>>               correlation=corAR1())
>>> 
>>> 
>>> 
>>> #### parameter values
>>> 
>>> Fixed effects: list(b0 ~ 1 + origin + soil character, b1 ~ 1, b2 ~ 1 +
>>> origin + soil character)
>>> 
>>>                                        Value
>>> b0.(Intercept)                 21.081124
>>> b0.origin1                        7.735064
>>> b0.soilcharactermold   10.689051
>>> b0.soilcharactersilt       3.906585
>>> b1                                      0.079035
>>> b2.(Intercept)                  1.616360
>>> b2.origin1                        -0.384421
>>> b2.soilcharactermold      0.612285
>>> b2.soilcharactersilt          0.527462
>>> 
>>> 
>>> 
>>> ##### I can easily get the augmented plot.  I got  different 68 plots
>>> specific curves.
>>> 
>>> #######
>>> 
>>> Any body can help me how can I will get all 68 plots specific fitted
>>> curves in one plot with respective plot specific age and dominant
>>> height obervations? (x axis will represent age, y axis will represent
>>> dominant height and fitted curves of all 68 plots)
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>> kopie vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>> 
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>> strany p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>> zn?m?.
>> 
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any
>> manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>> 
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to
>> enter into any contracts on behalf of the company except for cases in
>> which he/she is expressly authorized to do so in writing, and such
>> authorization or power of attorney is submitted to the recipient or the
>> person represented by the recipient, or the existence of such
>> authorization is known to the recipient of the person represented by the
>> recipient.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/manager
> 
> 
> <aug-2.pdf>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Mar 13 18:59:01 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Mar 2015 10:59:01 -0700
Subject: [R] need help on RATQ package
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23D83@SRVEXCHMBX.precheza.cz>
References: <CADb+ogCAQjtWz-9rqsPOCYmnsvCmwauz3gHhqiUFBGEonX3ECA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23D83@SRVEXCHMBX.precheza.cz>
Message-ID: <5F6A234C-5112-48B5-810B-9A3BC849CC91@comcast.net>


On Mar 13, 2015, at 5:11 AM, PIKAL Petr wrote:

> Hi
> 
> I did not find any RATQ package. If you mean RTAQ package it was removed from CRAN
> 
> quote:
> Package ?RTAQ? was removed from the CRAN repository.

Not only that but the first Google hit for a search on RATQ sends you to a page that says using RATQ is deprecated:

http://feb.kuleuven.be/public/N09022/rtaq.htm

-- 
David.
> 
> Formerly available versions can be obtained from the archive.
> 
> No clean update received after requests on Nov 2012, Dec 2012, Jan 2013; hence archived 2013-02-23.
> 
> AFAIK you have 3 options:
> 
> 1. Use old R version for which is this package available.
> 2. Copy a RTAQ directory from old R version to new one (it sometimes works)
> 3. Compile RTAQ package from sources
> 
> Cheers
> Petr
> 
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shameem
>> Akhtar
>> Sent: Friday, March 13, 2015 1:01 PM
>> To: r-help at r-project.org
>> Subject: [R] need help on RATQ package
>> 
>> at the time ao installing RATQ packages in my R it is showing an error
>> (package ?RTAQ? is not available (for R version 3.1.0) ) can any one
>> tell me which version of R is suitable for this (RATQ) package.
>> 
>>      [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From fneiman at monticello.org  Fri Mar 13 21:29:16 2015
From: fneiman at monticello.org (Fraser D. Neiman)
Date: Fri, 13 Mar 2015 20:29:16 +0000
Subject: [R] textplot() in wordcloud package
Message-ID: <2176AD174D58CB4ABBDA99F3458C2017208099CB@GRANGER.monticello.org>

Dear All,

The textplot() function in the wordcloud package seem to do a good job with generating non-overlapping labels on a scatter plot.
But it throws "warnings" when I try to use the pos= parameter to position the text labels relative to a given x-y point.

Here is a simple example:

 x<-runif(100)
 y<-runif(100)
text1<- rep('LAB', 100)
 
 plot(x,y)
 textplot(x,y, text1, new=F, show.lines=F,  
          pos=4)

There were 50 or more warnings (use warnings() to see the first 50)
> warnings()
Warning messages:
1: In strwidth(words[i], cex = cex[i], ...) : "pos" is not a graphical parameter
2: In strheight(words[i], cex = cex[i], ...) : "pos" is not a graphical parameter 

How can I pass the pos=parameter to text() without generating the warnings?

I am doubly puzzled by the warnings because in the graph that results from the foregoing code,
The labels are to the  right of the points, as 'pos=4' requests.

Thanks!

Fraser D. Neiman


From d.naschberger at student.uibk.ac.at  Fri Mar 13 11:47:59 2015
From: d.naschberger at student.uibk.ac.at (acrodaniel)
Date: Fri, 13 Mar 2015 03:47:59 -0700 (PDT)
Subject: [R] R Help Pops um in Webbrowser | how to dissable
Message-ID: <1426243679421-4704603.post@n4.nabble.com>

Hello,

i am new in R. 
When i search for any help in R-Studio.

example ?mean

a new Webpage opens with the help of mean.
I want to see it in R-Studio. It worked until yesterday.

I am using Arch bin version.

Thanks for you help



--
View this message in context: http://r.789695.n4.nabble.com/R-Help-Pops-um-in-Webbrowser-how-to-dissable-tp4704603.html
Sent from the R help mailing list archive at Nabble.com.


From dee88 at windowslive.com  Fri Mar 13 12:38:26 2015
From: dee88 at windowslive.com (=?iso-8859-7?B?xN3z8O/p7eEgyuHr9uHq3Orv9Q==?=)
Date: Fri, 13 Mar 2015 13:38:26 +0200
Subject: [R] svm plot
Message-ID: <DUB128-W84C73D3B7F4989C849580CB8070@phx.gbl>

Hello,

as you can imagine, I am new to R. I have a problem plotting the results of my svm classification of microarray data.
So, I have a matrix of 30 rows (samples) and 306 columns (significant genes). I transform the matrix to a data frame in order to do the classification.
My code is:

data<-t(significantGenes)
labels<-gl(2,20,30)
data<-data.frame(data)

svm.cross <- svm(data, labels, type="C-classification", kernel="polynomial", degree=5, gamma=0.5, coef0=1, cross=10)

This code works great!

But when I try to plot the results (using many different ways listed online), I get the following error:
"Error in terms.default(x) : no terms component nor attribute"

Here is SOME of the ways I've tried to plot the result:
plot(svm.cross, data, formula = V1~V2)
plot(svm.cross, data, formula = V1~V2, slice = list(V1=2,V2=2))
plot(svm.cross, data, formula = data[,1]~data[,2])
and
plot(svm.cross, data,formula=data["V1"]~data[V2]) with error: "Error in model.frame.default(formula, data) : 
  invalid type (list) for variable 'data["V1"]'"

Note that str(data) gives: 'data.frame':   30 obs. of  306 variables:
 $ V1  : num  10.8 10.3 12.5 12.7 11.7 ...
 $ V2  : num  9.5 10.34 11.25 11.56 9.74 ...
 $ V3  : num  9.36 11.67 10.52 11.57 10.25 ...
 $ V4  : num  9.25 8.52 10.61 11.21 9.84 ...
etc.

Thank you so much for your response.

Kind regards,
Despina

 		 	   		  
	[[alternative HTML version deleted]]


From d.naschberger at student.uibk.ac.at  Fri Mar 13 12:42:51 2015
From: d.naschberger at student.uibk.ac.at (acrodaniel)
Date: Fri, 13 Mar 2015 04:42:51 -0700 (PDT)
Subject: [R] R Help Pops um in Webbrowser | how to dissable
In-Reply-To: <1426243679421-4704603.post@n4.nabble.com>
References: <1426243679421-4704603.post@n4.nabble.com>
Message-ID: <1426246971415-4704606.post@n4.nabble.com>

R studio writes that it has a problem with 

.rs.httpdPort()

when startup



--
View this message in context: http://r.789695.n4.nabble.com/R-Help-Pops-um-in-Webbrowser-how-to-dissable-tp4704603p4704606.html
Sent from the R help mailing list archive at Nabble.com.


From madlene.nussbaum at env.ethz.ch  Fri Mar 13 14:17:58 2015
From: madlene.nussbaum at env.ethz.ch (Nussbaum  Madlene)
Date: Fri, 13 Mar 2015 13:17:58 +0000
Subject: [R] mboost: Proportional odds boosting model - how to specify the
 offset?
Message-ID: <847D4A28424E3F4BB8E890216D28B996224E354B@MBX111.d.ethz.ch>



Dear R team

The package mboost allows for boosting of proportional odds models. 
However, I would like to include an offset for every observation. This 
produces an error - no matter how I put the offset (as response 
probabilities or as response link).

Fitting gamboost-models with offset works satisfactory with family = 
Gaussian() or Multinomial().

Questions:
1) How do I need to specify the offset with family = PropOdds()?

2) Where in the mboost-object do I find the Theta's (response category 
dependent intercept)?



# --- minimal example with iris data ---

library(MASS)
library(mboost)

data(iris)
iris$Species <- factor(iris$Species, ordered = T)
p.iris <- polr(Species  ~ Sepal.Length, data = iris)
mlp <- gamboost(Species ~ bols(Sepal.Length) + bols(Sepal.Width),
               data = iris, family = PropOdds(),
	      offset = fitted(p.iris) )

Error in tmp[[i]] : subscript out of bounds


Thank you
M. Nussbaum

-- 

ETH Z?rich
Madlene Nussbaum
Institut f?r Terrestrische ?kosysteme
Boden- und Terrestrische Umweltphysik
CHN E 37.2
Universit?tstrasse 16
CH-8092 Z?rich

Telefon + 44 632 73 21
Mobile  + 79 761 34 66

madlene.nussbaum at env.ethz.ch
www.step.ethz.ch


From hannah_west_i at live.co.uk  Fri Mar 13 16:21:46 2015
From: hannah_west_i at live.co.uk (Hannah west)
Date: Fri, 13 Mar 2015 15:21:46 +0000
Subject: [R] Ancestral state problem (length of phylogenetic and phenotypic
 data don't match)
Message-ID: <DUB122-W2158FFFE53F4A33228C68582070@phx.gbl>

 Dear All,
 
I am trying to do an ancestral state reconstruction in R using the package 'ape'. I have tried trimming my tree in BayesTraits and in R itself, and the resulting tree reports as having 573 species tips, which is the same as my dataset. As far as I can tell everything is loading properly, but every time I try running the ACE codes R returns the following error message;
Error in ace(MCTree, phy = tree, type = "discrete", model = "ER") : 
  length of phenotypic and of phylogenetic data do not match.
 
The code I'm using is 
ace.ER<-ace(MCTree,phy=tree,type="discrete",model="ER")
 
My data summary loads as
'data.frame':   573 obs. of  2 variables:
 $ Species: Factor w/ 573 levels "Abeomelomys_sevia",..: 251 10 16 17 18 25 30 31 32 54 ...
 $ MCAll  : int  0 0 0 0 0 0 0 0 0 0 ...
 
My tree loads as
List of 4
 $ edge       : int [1:1144, 1:2] 574 575 576 576 577 577 578 578 579 579 ...
 $ edge.length: num [1:1144] 64.6 27.3 55.2 3.6 51.6 33.3 18.3 0.1 18.2 18.2 ...
 $ Nnode      : int 572
 $ tip.label  : chr [1:573] "Abeomelomys_sevia" "Abrothrix_longipilis" "Abrothrix_olivaceus" "Acerodon_celebensis" ...
 - attr(*, "class")= chr "phylo"
 - attr(*, "order")= chr "cladewise"
 
And as you can see the tips and data strings should match in length.
 
Any help would be much appreciated. Thank you!
 
(This is my first submission to one of these help threads so let me know if I miss anything vital).
 
 		 	   		  
	[[alternative HTML version deleted]]


From archstevej at gmail.com  Fri Mar 13 16:51:28 2015
From: archstevej at gmail.com (archsteve)
Date: Fri, 13 Mar 2015 08:51:28 -0700 (PDT)
Subject: [R] Date extract Year
In-Reply-To: <54FD142A.7050203@auckland.ac.nz>
References: <1425768716075-4704295.post@n4.nabble.com>
	<7E82AA71-0B9D-46B3-8114-2C0E71D60C45@gmail.com>
	<CAGh51gSuY=SPnwb2Wf1f7drF2s=FP-ykJBukqUuhxEqr-3JvUA@mail.gmail.com>
	<72750608-7D36-40E6-94B0-FC4C3CE83584@gmail.com>
	<54FD142A.7050203@auckland.ac.nz>
Message-ID: <DB76227C-7286-4B78-834D-7E1E9E6F3B8B@gmail.com>

Ha, sorry for the obtuseness Rolf. New to this.  Thanks for your help. 

-Steve


> On Mar 8, 2015, at 9:25 PM, Rolf Turner [via R] <ml-node+s789695n4704335h44 at n4.nabble.com> wrote:
> 
> Rolf Turner





--
View this message in context: http://r.789695.n4.nabble.com/Date-extract-Year-tp4704295p4704614.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From waddeessa at gmail.com  Fri Mar 13 16:36:33 2015
From: waddeessa at gmail.com (Kumsaa)
Date: Fri, 13 Mar 2015 16:36:33 +0100
Subject: [R] Extract month and year as one column
Message-ID: <CALekQEsSfFep9TgyAheCBc2psd+BJc7uZhLcKvYgowi51nY1Lg@mail.gmail.com>

How could I extract both month and year from a date? I know how to
separately extract both using lubridate package:

df$month <- month(df$date)
df$year<- year(df$date)

I wish to extract year and month as one column

> dput(mydf)
structure(list(date = structure(c(14975, 14976, 14977, 14978,
14979, 14980, 14981, 14982, 14983, 14984, 14985, 14986, 14987,
14988, 14989, 15340, 15341, 15342, 15343, 15344, 15345, 15346,
15347, 15348, 15349, 15350, 15351, 15352, 15353, 15354), class = "Date"),
    temp = c(6.5140544091004, 3.69073712745884, 3.04839429519466,
    9.16988228171461, -1.17176248610603, 2.88216040747883,
4.98853844809017,
    4.07520306701834, 9.82902813943658, 2.79305715971987, 8.04721677924611,
    7.50667729759095, 2.91055000121842, 1.65559895014064, 4.8019596483372,
    16.2567986804179, 13.3352908067145, 16.6955807821108, 6.28373374879922,
    6.97181051627531, 5.74282686202818, 4.37018386569785, 12.5725962512824,
    4.6583055309578, 8.76457542037641, 10.7070862034423, 12.84023567151,
    5.78620621848167, 5.98643374478599, 13.0993210289842)), .Names =
c("date",
"temp"), row.names = c(NA, 30L), class = "data.frame")

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Mar 14 01:42:09 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Mar 2015 17:42:09 -0700
Subject: [R] R Help Pops um in Webbrowser | how to dissable
In-Reply-To: <1426246971415-4704606.post@n4.nabble.com>
References: <1426243679421-4704603.post@n4.nabble.com>
	<1426246971415-4704606.post@n4.nabble.com>
Message-ID: <80C33A25-D4E1-4DA8-AA73-817F1F19A548@comcast.net>


On Mar 13, 2015, at 4:42 AM, acrodaniel wrote:

> R studio writes that it has a problem with 
> 
> .rs.httpdPort()
> 
> when startup
> 

RStudio question are best handled on the web forums established to support that product. They are not on-topic for Rhelp.

##########
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Mar 14 01:45:47 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Mar 2015 17:45:47 -0700
Subject: [R] Extract month and year as one column
In-Reply-To: <CALekQEsSfFep9TgyAheCBc2psd+BJc7uZhLcKvYgowi51nY1Lg@mail.gmail.com>
References: <CALekQEsSfFep9TgyAheCBc2psd+BJc7uZhLcKvYgowi51nY1Lg@mail.gmail.com>
Message-ID: <CF555551-628E-4D55-9470-66A16CB82736@comcast.net>


On Mar 13, 2015, at 8:36 AM, Kumsaa wrote:

> How could I extract both month and year from a date? I know how to
> separately extract both using lubridate package:
> 
> df$month <- month(df$date)
> df$year<- year(df$date)

Use format.Date:  # and see ?strptime for more format specifications.

> format(mydf$date, format="%Y %b")
 [1] "2011 Jan" "2011 Jan" "2011 Jan" "2011 Jan" "2011 Jan" "2011 Jan"
 [7] "2011 Jan" "2011 Jan" "2011 Jan" "2011 Jan" "2011 Jan" "2011 Jan"
[13] "2011 Jan" "2011 Jan" "2011 Jan" "2012 Jan" "2012 Jan" "2012 Jan"
[19] "2012 Jan" "2012 Jan" "2012 Jan" "2012 Jan" "2012 Jan" "2012 Jan"
[25] "2012 Jan" "2012 Jan" "2012 Jan" "2012 Jan" "2012 Jan" "2012 Jan"
> 
> I wish to extract year and month as one column
> 
>> dput(mydf)
> structure(list(date = structure(c(14975, 14976, 14977, 14978,
> 14979, 14980, 14981, 14982, 14983, 14984, 14985, 14986, 14987,
> 14988, 14989, 15340, 15341, 15342, 15343, 15344, 15345, 15346,
> 15347, 15348, 15349, 15350, 15351, 15352, 15353, 15354), class = "Date"),
>    temp = c(6.5140544091004, 3.69073712745884, 3.04839429519466,
>    9.16988228171461, -1.17176248610603, 2.88216040747883,
> 4.98853844809017,
>    4.07520306701834, 9.82902813943658, 2.79305715971987, 8.04721677924611,
>    7.50667729759095, 2.91055000121842, 1.65559895014064, 4.8019596483372,
>    16.2567986804179, 13.3352908067145, 16.6955807821108, 6.28373374879922,
>    6.97181051627531, 5.74282686202818, 4.37018386569785, 12.5725962512824,
>    4.6583055309578, 8.76457542037641, 10.7070862034423, 12.84023567151,
>    5.78620621848167, 5.98643374478599, 13.0993210289842)), .Names =
> c("date",
> "temp"), row.names = c(NA, 30L), class = "data.frame")
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Sat Mar 14 02:53:14 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 14 Mar 2015 12:53:14 +1100
Subject: [R] textplot() in wordcloud package
In-Reply-To: <2176AD174D58CB4ABBDA99F3458C2017208099CB@GRANGER.monticello.org>
References: <2176AD174D58CB4ABBDA99F3458C2017208099CB@GRANGER.monticello.org>
Message-ID: <CA+8X3fX2Z5DaWy0RPq4rAv=Q5gvqhD83JB9245YV=o-heiUzSg@mail.gmail.com>

Hi Fraser,
"textplot" is fairly similar to the "thigmophobe.labels" function in
plotrix. I think the problem is that when the user passes an explicit
position for the labels with the default "new=TRUE" argument, the "pos"
argument is passed to the "plot" function, causing the warning. If the
"pos" argument was named rather than extracted from "...", this could be
avoided. However, if you want to specify the position of the labels, you
could probably use the "text" function.

Jim


On Sat, Mar 14, 2015 at 7:29 AM, Fraser D. Neiman <fneiman at monticello.org>
wrote:

> Dear All,
>
> The textplot() function in the wordcloud package seem to do a good job
> with generating non-overlapping labels on a scatter plot.
> But it throws "warnings" when I try to use the pos= parameter to position
> the text labels relative to a given x-y point.
>
> Here is a simple example:
>
>  x<-runif(100)
>  y<-runif(100)
> text1<- rep('LAB', 100)
>
>  plot(x,y)
>  textplot(x,y, text1, new=F, show.lines=F,
>           pos=4)
>
> There were 50 or more warnings (use warnings() to see the first 50)
> > warnings()
> Warning messages:
> 1: In strwidth(words[i], cex = cex[i], ...) : "pos" is not a graphical
> parameter
> 2: In strheight(words[i], cex = cex[i], ...) : "pos" is not a graphical
> parameter
>
> How can I pass the pos=parameter to text() without generating the warnings?
>
> I am doubly puzzled by the warnings because in the graph that results from
> the foregoing code,
> The labels are to the  right of the points, as 'pos=4' requests.
>
> Thanks!
>
> Fraser D. Neiman
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From yhu at mail.nih.gov  Sat Mar 14 03:07:33 2015
From: yhu at mail.nih.gov (Hu, Ying (NIH/NCI) [E])
Date: Sat, 14 Mar 2015 02:07:33 +0000
Subject: [R] Circos plots by using R (updated OmicCircos package)
Message-ID: <C2C3FCBA281D5E43A59A45D0AC0EAFEA274EBE87@msgb04.nih.gov>

Dear R users,

OmicCircos is an R package used to generate high-quality circos plots. The package has been updated (the development version) at http://master.bioconductor.org/packages/3.1/bioc/html/OmicCircos.html. 

In order to use the devel version of Bioconductor, you must install R-devel (http://master.bioconductor.org/developers/how-to/useDevel/) or download it into your local and install it manually. 

If you have any questions, comments or suggestions please feel free to let me know.

Best,
Ying 

Ying Hu Ph.D. 
National Cancer Institute
Center for Biomedical Informatics & Information Technology
9609 Medical Center Drive, MSC 9719, Rm. 1W570
Bethesda, MD  20850
yhu at mail.nih.gov

From ggrothendieck at gmail.com  Sat Mar 14 04:27:35 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 13 Mar 2015 23:27:35 -0400
Subject: [R] Extract month and year as one column
In-Reply-To: <CALekQEsSfFep9TgyAheCBc2psd+BJc7uZhLcKvYgowi51nY1Lg@mail.gmail.com>
References: <CALekQEsSfFep9TgyAheCBc2psd+BJc7uZhLcKvYgowi51nY1Lg@mail.gmail.com>
Message-ID: <CAP01uRnMHREzSwybEz7bBaJDnYCsRwz82srzE6tX01Y9KbBr2g@mail.gmail.com>

On Fri, Mar 13, 2015 at 11:36 AM, Kumsaa <waddeessa at gmail.com> wrote:
> How could I extract both month and year from a date? I know how to
> separately extract both using lubridate package:
>
> df$month <- month(df$date)
> df$year<- year(df$date)
>
> I wish to extract year and month as one column
>
>> dput(mydf)
> structure(list(date = structure(c(14975, 14976, 14977, 14978,
> 14979, 14980, 14981, 14982, 14983, 14984, 14985, 14986, 14987,
> 14988, 14989, 15340, 15341, 15342, 15343, 15344, 15345, 15346,
> 15347, 15348, 15349, 15350, 15351, 15352, 15353, 15354), class = "Date"),
>     temp = c(6.5140544091004, 3.69073712745884, 3.04839429519466,
>     9.16988228171461, -1.17176248610603, 2.88216040747883,
> 4.98853844809017,
>     4.07520306701834, 9.82902813943658, 2.79305715971987, 8.04721677924611,
>     7.50667729759095, 2.91055000121842, 1.65559895014064, 4.8019596483372,
>     16.2567986804179, 13.3352908067145, 16.6955807821108, 6.28373374879922,
>     6.97181051627531, 5.74282686202818, 4.37018386569785, 12.5725962512824,
>     4.6583055309578, 8.76457542037641, 10.7070862034423, 12.84023567151,
>     5.78620621848167, 5.98643374478599, 13.0993210289842)), .Names =
> c("date",
> "temp"), row.names = c(NA, 30L), class = "data.frame")
>

The zoo package has a "yearmon" class that represents dates as year
and month with no day:

> library(zoo)
> transform(mydf, yearmon = as.yearmon(date))
        date      temp  yearmon
1 2011-01-01  6.514054 Jan 2011
2 2011-01-02  3.690737 Jan 2011
3 2011-01-03  3.048394 Jan 2011
4 2011-01-04  9.169882 Jan 2011
5 2011-01-05 -1.171762 Jan 2011
6 2011-01-06  2.882160 Jan 2011
etc.


From tmrsg11 at gmail.com  Sat Mar 14 04:50:54 2015
From: tmrsg11 at gmail.com (C W)
Date: Fri, 13 Mar 2015 23:50:54 -0400
Subject: [R] Is RcppOctave package available for Mac to install?
Message-ID: <CAE2FW2=xU7_yCGyihhTWQ2tt_Fj0GbVj1XW+VgpY1TtSJMARVQ@mail.gmail.com>

Hi everyone,

When I tried to install RcppOctave package I got the following.
> install.packages("RcppOctave")
--- Please select a CRAN mirror for use in this session ---

   package ?RcppOctave? is available as a source package but not as a binary

Warning message:
package ?RcppOctave? is not available (for R version 3.1.2)

I see the RcppOctave_0.14.5.tar.gz  file on CRAN here,
http://cran.r-project.org/web/packages/RcppOctave/index.html

I have not compiled any packages from source, I need to run brew doctor to
fix problems in homebrew before compiling.

I just wanted to make sure the tar.gz file is good to go before I fix
homebrew.

Thanks,

Mike

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Mar 14 07:13:10 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Mar 2015 23:13:10 -0700
Subject: [R] Is RcppOctave package available for Mac to install?
In-Reply-To: <CAE2FW2=xU7_yCGyihhTWQ2tt_Fj0GbVj1XW+VgpY1TtSJMARVQ@mail.gmail.com>
References: <CAE2FW2=xU7_yCGyihhTWQ2tt_Fj0GbVj1XW+VgpY1TtSJMARVQ@mail.gmail.com>
Message-ID: <4DB77641-A8CD-4DEF-845B-D9E6ACBB3E83@comcast.net>


> On Mar 13, 2015, at 11:50 PM, C W <tmrsg11 at gmail.com> wrote:
> 
> Hi everyone,
> 
> When I tried to install RcppOctave package I got the following.
>> install.packages("RcppOctave")
> --- Please select a CRAN mirror for use in this session ---
> 
>  package ?RcppOctave? is available as a source package but not as a binary
> 
> Warning message:
> package ?RcppOctave? is not available (for R version 3.1.2)

pkgmaker
bibtex
registry


> 
> I see the RcppOctave_0.14.5.tar.gz  file on CRAN here,
> http://cran.r-project.org/web/packages/RcppOctave/index.html
> 
> I have not compiled any packages from source, I need to run brew doctor to
> fix problems in homebrew before compiling.

During the (unsuccessful) installation from source, I get the error (not entirely unexpected):

checking for mkoctfile... no
configure: error: mkoctfile not found, is Octave installed?

(I am not surprised because I don?t have Octave installed.)

There are further comments and instructions about installing octave. The instructions to install octave may alter the locations or symlinks for gfortran which might create problems for installing R packages from source, since the directory locations for brew installs are different than those that R expects. You might want to post the question on R-SIG-Mac.

? 
David.

> I just wanted to make sure the tar.gz file is good to go before I fix
> homebrew.
> 
> Thanks,
> 
> Mike
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From julleeyaw at yahoo.ca  Sat Mar 14 08:28:43 2015
From: julleeyaw at yahoo.ca (Julie Lee-Yaw)
Date: Sat, 14 Mar 2015 07:28:43 +0000 (UTC)
Subject: [R] evaluating spatial autocorrelation in a raster
Message-ID: <1225015391.6415335.1426318123255.JavaMail.yahoo@mail.yahoo.com>

Hi
I am attempting to explore the scale of spatial autocorrelation in a raster (eventually across a stack of 10 but for now a single layer) and consequently in a potential sample of points across the landscape (ie. if we wanted to know what sampling design in terms of distance would minimize autocorrelation). I?ve spent a couple of days trying to understand the various ways to evaluate spatial autocorrelation for a raster or points dataset but am struggling with a few questions. I hope someone can kindly shed some light on the following (in my example I?m playing with a single WorldClim layer at a resolution of 1 km, cropped to the eastern third of the USA):
1) In spdep, I?ve done the following (with my [potentially erroneous] thinking laid out in the comments and two questions at the end):
### use the raster package to get a regular sample of points across the raster### because using the full set of cells or their centroids on a large raster seems to crash R downstream
y<-sampleRegular(my raster,size=1000,xy=TRUE)
### tidy point dataset### in particular, missing values (e.g. the ocean) in the raster and thus in the points lead to errors later, so remove these
dd<-y[complete.cases(y),]dd$ID<-row.names(dd)c<-coordinates(dd[,c("x","y")])
### make nb object (provides list of nearest neighbours for lower lag class)### here I?ve chosen k=8 which I?m assuming given the regular sampling of points is almost akin to the ?queens? design in the raster-specific cell2nb command (except for cells near the ocean)
k1_nb<-knn2nb(knearneigh(c,k=8,longlat=TRUE),row.names=IDs)
### make correlogram
sp.cor<-sp.correlogram(k1_nb,dd$V4,order=15,method="I")plot(sp.cor)
Two questions here:?
a) I?ve been able to successfully set the order to 15 but not 20 before there are empty neighbour sets found for this particular dataset. Is there a way, other than by trial and error to tell the maximum order possible?
b) After plotting the correlogram, I get the Moran?s I as a function of lag distance. I see it crosses the 0 line between lags 13 and 14 ?is there a way to tell what distance this amounts to in kms??
2) Using the pgirmess package (which I understand to be calculating the lags in a fundamentally different way) I can get a correlogram with distances?
### so now I reproject the raster to albers equal area in order to have the units on the x axis be metres (and actually the projection I want to use in the end anyways)?### the rest of the steps to create dd2 are the same as above### use the correlog function to create correlogram
pgi.cor <- correlog(coords=dd2[,1:2], z=dd2$V3, method="Moran", nbclass=20)plot(pgi.cor)
Questions:
a) In my new plot, the distance class at which Moran?s I is no longer significantly different from zero is around 600 km. That seems really far to me?am I wrong in my interpretation that this distance represents the distance beyond which sample sites would be are relatively free from autocorrelation? or is this truly representative of the scale of autocorrelation that I can expect in climate data over the relatively modest topographic complexity of the eastern USA??
b) In general, when/ for what types of questions or datasets is the approach used by spdep to generate the lag steps more appropriate than the (fixed bins?) method of pgirmess??
3) Finally?
Please forgive me if I?m approaching this problem incorrectly altogether! I?m eventually hoping to say something along the lines of ?if we take sites x distance apart, we can be fairly sure that the amount of spatial autocorrelation in our climate data will be minimal?. But maybe this is completely ridiculous? I?d be really happy to have some suggestions.?(and on a side note, I?m currently looking for a good introduction to spatial statistics course or textbook?something for the truly uninitiated. Any recommendations?)
Many thanks!
PS. Online sources for some of the code above:
http://www.r-bloggers.com/spatial-correlograms-in-r-a-mini-overview/http://www.bias-project.org.uk/ASDARcourse/unit6_slides.pdf


	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Sat Mar 14 12:07:11 2015
From: ajdamico at gmail.com (Anthony Damico)
Date: Sat, 14 Mar 2015 07:07:11 -0400
Subject: [R] iconv() replaces invalid characters with " " instead of " "
 (two spaces instead of one) on unix?
Message-ID: <CAOwvMDxV5fOKQuAKTft694FhP8=zijve1sCEC+KHh6=NS1mhNg@mail.gmail.com>

hello, i am trying to replace non-ASCII characters in a character string
with a single space.  the iconv() function works as i expect it to on
windows, but on unix, non-ASCII characters are getting replaced with two
spaces instead of one.  i suppose i could write a workaround for my code,
but i'm wondering if i'm making some other mistake?

in the output below, this is the result i'm getting:
[1] "cancelaci  n"

and this is the result i want:
[1] "cancelaci n"

thanks!!

=================

> getOption( "encoding" )
[1] "windows-1252"

> a <- "cancelaci?n"
> iconv(a,"","ASCII")
[1] NA
> iconv(a,"","ASCII",sub=" ")
[1] "cancelaci  n"

=================

> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
 [1] R.utils_1.34.0    R.oo_1.18.0       R.methodsS3_1.6.1 descr_1.0.4
 [5] SAScii_1.0        downloader_0.3    foreign_0.8-61    MonetDB.R_0.9.5
 [9] digest_0.6.6      DBI_0.3.1

loaded via a namespace (and not attached):
[1] xtable_1.7-4

	[[alternative HTML version deleted]]


From isleguard at gmail.com  Sat Mar 14 00:46:48 2015
From: isleguard at gmail.com (Gary Baggett)
Date: Fri, 13 Mar 2015 18:46:48 -0500
Subject: [R] Help with Programmin-1 submission.
Message-ID: <000001d05de7$f8e685b0$eab39110$@gmail.com>

Help.

 

First of all, I admit being a noob when it comes to dealing with R and
Git-hub (but not new to programming[embedded mostly]).  That being said,
this first programming submission with this course is giving me fits.

 

I have the first part of the assignment done, loaded the "submit" source
within my local RStudio and am trying to run "submit ()".  It tries to run,
but then aborts.see below.

 

>source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript
1.R")

> source('H:/RStudio-Projects/Project1/pollutantmean.R')

> submit()

 

Press Enter to continue...

 

| Is the following information correct?

 

Course ID: rprog-012

Submission login (email): isleguard at gmail.com

Submission password: 

 

1: Yes, go ahead!

2: No, I need to change something.

 

Selection: 1

 

| Which part are you submitting?

 

1: 'pollutantmean' part 1

2: 'pollutantmean' part 2

3: 'pollutantmean' part 3

4: 'pollutantmean' part 4

5: 'complete' part 1

6: 'complete' part 2

7: 'complete' part 3

8: 'corr' part 1

9: 'corr' part 2

10: 'corr' part 3

 

Selection: 1

Error in file(filename, "r", encoding = encoding) : 

  cannot open the connection

In addition: Warning message:

In file(filename, "r", encoding = encoding) :

  cannot open file 'pollutantmean.R': No such file or directory

	


> 

 

Any suggestions as to where to go?  It appears to be unable to find my
pollutantmean.R file even though I just sourced it.  The function is in
memory and is in the directory from which I am trying to execute the submit
script.

 

 

Thanks,

Gary Baggett


	[[alternative HTML version deleted]]


From roger.bivand at nhh.no  Sat Mar 14 12:44:42 2015
From: roger.bivand at nhh.no (Roger Bivand)
Date: Sat, 14 Mar 2015 11:44:42 +0000
Subject: [R] evaluating spatial autocorrelation in a raster
References: <1225015391.6415335.1426318123255.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <loom.20150314T123729-176@post.gmane.org>

Julie Lee-Yaw <julleeyaw <at> yahoo.ca> writes:

> 
> Hi
> I am attempting to explore the scale of spatial autocorrelation in a
raster (eventually across a stack of 10
> but for now a single layer) and consequently in a potential sample of
points across the landscape (ie. if we
> wanted to know what sampling design in terms of distance would minimize
autocorrelation). 

This could with advantage been posted on R-sig-geo rather than on R-help.

The main problem will be in the raster resolution, as this will most likely
not match the "natural" resolution of the phenomena of interest, thus
spuriously generating apparent spatial autocorrelation. It may be hard to
choose an appropriate sampling design.

> Please forgive me if I?m approaching this problem incorrectly altogether!
I?m eventually hoping to
> say something along the lines of ?if we take sites x distance apart, we
can be fairly sure that the amount
> of spatial autocorrelation in our climate data will be minimal?. But maybe
this is completely
> ridiculous? I?d be really happy to have some suggestions.?(and on a side
note, I?m currently
> looking for a good introduction to spatial statistics course or
textbook?something for the truly
> uninitiated. Any recommendations?)

Look for work by Werner Mueller on sampling design, and work citing his work.

> Many thanks!
> PS. Online sources for some of the code above:
>
http://www.r-bloggers.com/spatial-correlograms-in-r-a-mini-overview/http://www.bias-project.org.uk/ASDARcourse/unit6_slides.pdf


> 
> 	[[alternative HTML version deleted]]

Please do not post HTML, which is mangled and illegible in many email clients.


> 
> ______________________________________________
> R-help <at> r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please do provide a self-contained example.

Roger

From sarah.goslee at gmail.com  Sat Mar 14 13:26:48 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 14 Mar 2015 08:26:48 -0400
Subject: [R] Help with Programmin-1 submission.
In-Reply-To: <000001d05de7$f8e685b0$eab39110$@gmail.com>
References: <000001d05de7$f8e685b0$eab39110$@gmail.com>
Message-ID: <CAM_vjumyJFKBU5n09QR_HiRq4zEc1F+Xz1efFJ10Bcc3NHX6tg@mail.gmail.com>

Hi Gary,

We have no idea what you're talking about. This is the general world-wide
R-help group; you need to ask on a forum specific to your course.

This group doesn't help with homework anyway, and this is a problem with
your course's stuff, not a general R question.

Sarah



On Friday, March 13, 2015, Gary Baggett <isleguard at gmail.com> wrote:

> Help.
>
>
>
> First of all, I admit being a noob when it comes to dealing with R and
> Git-hub (but not new to programming[embedded mostly]).  That being said,
> this first programming submission with this course is giving me fits.
>
>
>
> I have the first part of the assignment done, loaded the "submit" source
> within my local RStudio and am trying to run "submit ()".  It tries to run,
> but then aborts.see below.
>
>
>
> >source("
> http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript
> 1.R")
>
> > source('H:/RStudio-Projects/Project1/pollutantmean.R')
>
> > submit()
>
>
>
> Press Enter to continue...
>
>
>
> | Is the following information correct?
>
>
>
> Course ID: rprog-012
>
> Submission login (email): isleguard at gmail.com <javascript:;>
>
> Submission password:
>
>
>
> 1: Yes, go ahead!
>
> 2: No, I need to change something.
>
>
>
> Selection: 1
>
>
>
> | Which part are you submitting?
>
>
>
> 1: 'pollutantmean' part 1
>
> 2: 'pollutantmean' part 2
>
> 3: 'pollutantmean' part 3
>
> 4: 'pollutantmean' part 4
>
> 5: 'complete' part 1
>
> 6: 'complete' part 2
>
> 7: 'complete' part 3
>
> 8: 'corr' part 1
>
> 9: 'corr' part 2
>
> 10: 'corr' part 3
>
>
>
> Selection: 1
>
> Error in file(filename, "r", encoding = encoding) :
>
>   cannot open the connection
>
> In addition: Warning message:
>
> In file(filename, "r", encoding = encoding) :
>
>   cannot open file 'pollutantmean.R': No such file or directory
>
>
>
>
> >
>
>
>
> Any suggestions as to where to go?  It appears to be unable to find my
> pollutantmean.R file even though I just sourced it.  The function is in
> memory and is in the directory from which I am trying to execute the submit
> script.
>
>
>
>
>
> Thanks,
>
> Gary Baggett
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Sat Mar 14 13:58:50 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Sat, 14 Mar 2015 07:58:50 -0500
Subject: [R] Help with Programmin-1 submission.
In-Reply-To: <000001d05de7$f8e685b0$eab39110$@gmail.com>
References: <000001d05de7$f8e685b0$eab39110$@gmail.com>
Message-ID: <CAAJSdjio6kNdcZkc+QOg9qF8G9DRFh4wT+XhN8Q6Obb8c_Nr9w@mail.gmail.com>

Gary,

First off, I doubt anyone here will really be able to help you with a
question which is, basically, "How do I submit the R code that I've
worked on to my college as an answer to a programming assignment".
Unless by chance someone else here happens to be taking that course
and knows how to. It's not really an R programming question.

What I can help you with is an apparent misunderstand by you of what
source() does. source() is simply a way to say: read the lines in the
named "file" (not always a disk file) and act as if I had typed it all
in myself on the R command prompt.

Well, I may be chided a bit by others. But I'm bored this morning. And
I don't feel that this is actually a "homework problem". So I looked
at the R code at
http://d396qusza40orc.cloudfront.net/rprog/scripts/submitscript1.R and
at your transcript. Try the following commands:

source("http://d396qusza40orc.cloudfront.net/rprog/scripts/submitscript1.R")

setwd('H:/RStudio-Projects/Project1/')

submit()

Note that I replaced the second source() with a setwd() command. The
first source() defines some R programs for you. The setwd() makes your
"current working directory" be H:/RStudio-Projects/Project1/ which I
guess is where pollutantmean.R resides. The submit() function looks
for a __FILE__ in the __current working directory__ for the code which
you want to submit to your instructor. From what I can see, the
submit() process itself does the required source() to run your R code,
but only from your __current working directory__ (yes, I'm emphasizing
that). The rest of what you did after the submit() command looks to
match what the submit() function was wanting.

Now, I will emphasize yet again that this question is totally outside
the purview of this forum. Your question should have been asked of
your teacher, or a TA, or (as we were called back when I was in
college) a "user's ass" (we weren't P.C,. or even polite, back in the
60s. I had to help people with key punch machines and card readers). I
only went into this because: (1) I'm bored and (2) you look like you
might be just a bit younger that me and I believe in helping kids
succeed <grin>.


On Fri, Mar 13, 2015 at 6:46 PM, Gary Baggett <isleguard at gmail.com> wrote:
> Help.
>
>
>
> First of all, I admit being a noob when it comes to dealing with R and
> Git-hub (but not new to programming[embedded mostly]).  That being said,
> this first programming submission with this course is giving me fits.
>
>
>
> I have the first part of the assignment done, loaded the "submit" source
> within my local RStudio and am trying to run "submit ()".  It tries to run,
> but then aborts.see below.
>
>
>
>>source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript
> 1.R")
>
>> source('H:/RStudio-Projects/Project1/pollutantmean.R')
>
>> submit()
>
>
>
> Press Enter to continue...
>
>
>
> | Is the following information correct?
>
>
>
> Course ID: rprog-012
>
> Submission login (email): isleguard at gmail.com
>
> Submission password:
>
>
>
> 1: Yes, go ahead!
>
> 2: No, I need to change something.
>
>
>
> Selection: 1
>
>
>
> | Which part are you submitting?
>
>
>
> 1: 'pollutantmean' part 1
>
> 2: 'pollutantmean' part 2
>
> 3: 'pollutantmean' part 3
>
> 4: 'pollutantmean' part 4
>
> 5: 'complete' part 1
>
> 6: 'complete' part 2
>
> 7: 'complete' part 3
>
> 8: 'corr' part 1
>
> 9: 'corr' part 2
>
> 10: 'corr' part 3
>
>
>
> Selection: 1
>
> Error in file(filename, "r", encoding = encoding) :
>
>   cannot open the connection
>
> In addition: Warning message:
>
> In file(filename, "r", encoding = encoding) :
>
>   cannot open file 'pollutantmean.R': No such file or directory
>
>
>
>
>>
>
>
>
> Any suggestions as to where to go?  It appears to be unable to find my
> pollutantmean.R file even though I just sourced it.  The function is in
> memory and is in the directory from which I am trying to execute the submit
> script.
>
>
>
>
>
> Thanks,
>
> Gary Baggett
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown


From jrkrideau at inbox.com  Sat Mar 14 15:04:29 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 14 Mar 2015 06:04:29 -0800
Subject: [R] graphs
In-Reply-To: <1426264319187.82319@uef.fi>
References: <b6bcaad118b.000012b4jrkrideau@inbox.com>
	<1425852099806.91103@uef.fi>
Message-ID: <C33DE6BE8F2.000009B5jrkrideau@inbox.com>

I suspect that this does look a bit easier to interpret. It certainly beats 68 lines on one graph. Still it's a lot of individual subplots.

What I was suggesting was grouping all NASS, HASS, etc. together and graphing each so that you get several lines per subplot. I don't know if this makes sense in your context but it should reduce the size of the overall plot.

Ugly simple-minded example of what I meant below.

library(ggplot2)
names   <-  c('hass', "ham", 'nacs', 'nass')
line  <-  c('alpha', "beta")
xval  <-  1:4

dat1  <-  data.frame(group= rep(names, each = 3, 4),
tt  =  rep(line, each =12 , 2),
xx  =  rep(xval, 12 ),
yy  =  rnorm(48))

p  <-  ggplot(dat1, aes(xx, yy, colour = tt)) + geom_line() +
      facet_grid(. ~ group)
p

John Kane
Kingston ON Canada


> -----Original Message-----
> From: mir.salam at uef.fi
> Sent: Fri, 13 Mar 2015 16:27:06 +0000
> To: jrkrideau at inbox.com, petr.pikal at precheza.cz, r-help at r-project.org
> Subject: RE: [R] graphs
> 
> 
> __Dear all,
> 
> You can see the plot specif curves in the enclosed document. Inclusion of
> all plot specif curves in one plot may not be look  good and finally it
> will be unreadable. I am agree with Petrr and John. This graph is more
> readable.
> 
> 
> Best regards
> Salam
> 
> 
> 
> 
> 
> 
> 
> 
> ______________________________________
> From: John Kane <jrkrideau at inbox.com>
> Sent: Friday, March 13, 2015 4:12 PM
> To: PIKAL Petr; Mir Salam; r-help at r-project.org
> Subject: Re: [R] graphs
> 
> @Petr
> 
> I agree. I think Mir would get a totally unreadable graph. I occasionally
> look at some spagetti graphs from climate research, and I find 8 - 12
> lines are incomprehensible (I'm not a subject matter expert)'
> 
> @Mir
> 
> Is there any logical way to break down the data ? I think Petr is correct
> in that ggplot2 should be able to do it but I'd suggest thinking about,
> perhaps, facetting the data to produce some reasonable number of panels.
> 
> Here is a simple three-panel plot to illustrate what I mean but I have
> easily produced a 9 or 10 panel plot which reduces visual clutter
> immensely.
> 
> library(plyr) library(ggplot2)
> 
> df1 = data.frame(basel_asset_class =
c("bank","bank","bank","bank","bank","bank","bank","corporate","corporate","corporate","corporate","corporate","corporate","corporate","sovereign","sovereign","sovereign","sovereign","sovereign","sovereign","sovereign"),
> ratings =
c("AAA","AA","A","BBB","BB","B","CCC","AAA","AA","A","BBB","BB","B","CCC","AAA","AA","A","BBB","BB","B","CCC"),
> default_probability =
> c(0.0027,0.0029,0.0031,0.0034,0.0037,0.004,0.0043,0.0025,0.0024,0.0024,0.0023,0.0022,0.0021,0.0021,0.003,0.0031,0.0032,0.0033,0.0034,0.0035,0.0036))
> 
> names(df1) <- c("class", "rate", "default")
> 
> p <- ggplot(df1, aes(rate, default,colour=class)) + geom_point() +
> facet_grid(class ~.) + theme(legend.position="none")
> p
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: petr.pikal at precheza.cz
>> Sent: Fri, 13 Mar 2015 11:34:42 +0000
>> To: mir.salam at uef.fi, r-help at r-project.org
>> Subject: Re: [R] graphs
>> 
>> Hi
>> 
>> Your example is not reproducible, but I presume you could use ggplot
>> together with predict. However, I wonder how do you want to distinguish
>> 68 curves in one picture.
>> I would
>> 
>> Cheers
>> Petr
>> 
>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mir
>>> Salam
>>> Sent: Sunday, March 08, 2015 10:57 PM
>>> To: r-help at r-project.org
>>> Subject: [R] graphs
>>> 
>>> Dear all,
>>> 
>>>  I need help to get different 68  plots specifc fitted curves in one
>>> plot with respective field data observations (age vs dominant height).
>>> 
>>> 
>>> 
>>> aspdomH2<-groupedData(domH2~age|plotno,data=aspdomH2)
>>> 
>>> 
>>> 
>>> names(aspdomH2)
>>> 
>>> plotno, age, origin, soilcharacter, domH2,
>>> 
>>> 
>>> 
>>> plotno-different plot no. I have 68 plots
>>> 
>>> age- every plot have from age 5 to 30 years
>>> 
>>> origin- two, native aspen and hybrid aspen
>>> 
>>> domH2<-dominant height
>>> 
>>> soilcharacter-3, clay, silt and mold. both origin have different soil
>>> charcter
>>> 
>>> 
>>> 
>>> #### then I fit model
>>> 
>>> fm2cham.nlme<-nlme(domH2~cham(age,b0,b1,b2),
>>>                data=aspdomH2,
>>>                fixed = list(b0~1+origin+soilcharacter,b1~ 1,b2 ~
>>> 1+origin+soilcharacter),
>>>                random = b0+b2~1|plotno,
>>>                start=c(b0=26.3387,0,0,0,b1=0.1065,b2=1.9453,0,0,0),
>>>                weights=varPower(form = ~age, 0.5),
>>>                correlation=corAR1())
>>> 
>>> 
>>> 
>>> #### parameter values
>>> 
>>> Fixed effects: list(b0 ~ 1 + origin + soil character, b1 ~ 1, b2 ~ 1 +
>>> origin + soil character)
>>> 
>>>                                         Value
>>> b0.(Intercept)                 21.081124
>>> b0.origin1                        7.735064
>>> b0.soilcharactermold   10.689051
>>> b0.soilcharactersilt       3.906585
>>> b1                                      0.079035
>>> b2.(Intercept)                  1.616360
>>> b2.origin1                        -0.384421
>>> b2.soilcharactermold      0.612285
>>> b2.soilcharactersilt          0.527462
>>> 
>>> 
>>> 
>>> ##### I can easily get the augmented plot.  I got  different 68 plots
>>> specific curves.
>>> 
>>> #######
>>> 
>>> Any body can help me how can I will get all 68 plots specific fitted
>>> curves in one plot with respective plot specific age and dominant
>>> height obervations? (x axis will represent age, y axis will represent
>>> dominant height and fitted curves of all 68 plots)
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>> kopie vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>> modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>> 
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
>> ze
>> strany p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>> zn?m?.
>> 
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any
>> manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>> 
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into
>> a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer)
>> excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to
>> enter into any contracts on behalf of the company except for cases in
>> which he/she is expressly authorized to do so in writing, and such
>> authorization or power of attorney is submitted to the recipient or the
>> person represented by the recipient, or the existence of such
>> authorization is known to the recipient of the person represented by the
>> recipient.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/manager
> 
>

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From ripley at stats.ox.ac.uk  Sat Mar 14 16:06:30 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 14 Mar 2015 15:06:30 +0000
Subject: [R] iconv() replaces invalid characters with " " instead of " "
 (two spaces instead of one) on unix?
In-Reply-To: <CAOwvMDxV5fOKQuAKTft694FhP8=zijve1sCEC+KHh6=NS1mhNg@mail.gmail.com>
References: <CAOwvMDxV5fOKQuAKTft694FhP8=zijve1sCEC+KHh6=NS1mhNg@mail.gmail.com>
Message-ID: <55044E76.3060602@stats.ox.ac.uk>

On 14/03/2015 11:07, Anthony Damico wrote:
> hello, i am trying to replace non-ASCII characters in a character string
> with a single space.  the iconv() function works as i expect it to on
> windows, but on unix, non-ASCII characters are getting replaced with two
> spaces instead of one.  i suppose i could write a workaround for my code,
> but i'm wondering if i'm making some other mistake?

You are (not reading the help, not writing legible English) ...

      sub: character string.  If not ?NA? it is used to replace any
           non-convertible bytes in the input.

Note *bytes* not characters.  In UTF-8 '?' is two bytes, other non-ASCII 
characters can be 2, 3, 4 (in the current Unicode standard, originally 
in principle up to 6).

We do not know what locale you used on Windows, but in non-CJK locales 
characters == bytes.

I guess chartr() will do what you want using a character range.

>
> in the output below, this is the result i'm getting:
> [1] "cancelaci  n"
>
> and this is the result i want:
> [1] "cancelaci n"
>
> thanks!!
>
> =================
>
>> getOption( "encoding" )
> [1] "windows-1252"

What is the relevance of that?

>
>> a <- "cancelaci?n"
>> iconv(a,"","ASCII")
> [1] NA
>> iconv(a,"","ASCII",sub=" ")
> [1] "cancelaci  n"
>
> =================
>
>> sessionInfo()
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>   [1] R.utils_1.34.0    R.oo_1.18.0       R.methodsS3_1.6.1 descr_1.0.4
>   [5] SAScii_1.0        downloader_0.3    foreign_0.8-61    MonetDB.R_0.9.5
>   [9] digest_0.6.6      DBI_0.3.1
>
> loaded via a namespace (and not attached):
> [1] xtable_1.7-4
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From amango at gmail.com  Sat Mar 14 16:34:12 2015
From: amango at gmail.com (Aman Gill)
Date: Sat, 14 Mar 2015 11:34:12 -0400
Subject: [R] Help with error: arguments imply differing number of rows
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23D2F@SRVEXCHMBX.precheza.cz>
References: <CAKXkWh3GQ2vgF=4SvF1jLb19uFeKBY7eDttAd919RU_CTTFcTg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23D2F@SRVEXCHMBX.precheza.cz>
Message-ID: <CAKXkWh0eg2P2UDgOZw-Mt+Ncr=WQeG=c-2a3wJjNHQA6vo_4xg@mail.gmail.com>

Thanks for the reply. The results of str() are indeed the same. Is there
anything else I can check that might explain the difference?

> str(phyl_tree)
List of 4
 $ edge       : int [1:15, 1:2] 10 11 12 13 14 14 13 12 15 15 ...
 $ Nnode      : int 7
 $ tip.label  : chr [1:9] "Heliantheae" "Eupatorieae" "Helenieae"
"Gnaphalieae" ...
 $ edge.length: num [1:15] 1 1 1 1 1 1 2 1 2 1 ...
 - attr(*, "class")= chr "phylo"
 - attr(*, "order")= chr "cladewise"
>
> str(chem_tree)
List of 4
 $ edge       : int [1:15, 1:2] 10 11 12 13 14 15 15 14 16 16 ...
 $ Nnode      : int 7
 $ tip.label  : chr [1:9] "Heliantheae" "Helenieae" "Eupatorieae"
"Astereae" ...
 $ edge.length: num [1:15] 1 2 1 1 1 1 1 1 1 1 ...
 - attr(*, "class")= chr "phylo"
 - attr(*, "order")= chr "cladewise"

> str(phyl_data)
 int [1:35, 1:9] 0 0 0 1 0 0 0 0 0 1 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:35] "Uroleucon_aeneum" "Uroleucon_aff_atripes"
"Uroleucon_amamianum" "Uroleucon_ambrosiae" ...
  ..$ : chr [1:9] "Heliantheae" "Eupatorieae" "Helenieae" "Gnaphalieae" ...
>
> str(chem_data)
 int [1:35, 1:9] 0 0 0 1 0 0 0 0 0 1 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:35] "Uroleucon_aeneum" "Uroleucon_aff_atripes"
"Uroleucon_amamianum" "Uroleucon_ambrosiae" ...
  ..$ : chr [1:9] "Heliantheae" "Helenieae" "Eupatorieae" "Astereae" ...


On Fri, Mar 13, 2015 at 7:31 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Without further information you probably do not get answers. Everything
> seems to be same so the only reason can be that the objects seems to be
> same but they have some inner distinctions, maybe type of variables.
>
> Are results of
>
> str(your.objects)
>
> same in equivalent objects?
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Aman
> > Gill
> > Sent: Thursday, March 12, 2015 6:08 PM
> > To: r-help at r-project.org
> > Subject: [R] Help with error: arguments imply differing number of rows
> >
> > Hello,
> >
> > I am stuck trying to run an analysis using the package picante. I am
> > running two very similar analyses. One works as expected, but when I
> > try
> > the other, I get the error:
> >
> > Error in data.frame(PD = PDs, SR = SR) :
> >   arguments imply differing number of rows: 34, 35
> >
> > This is strange to me since the data matrix is the same for both
> > analyses
> > (numbers of rows and columns are the same; the only difference is the
> > order
> > of the columns). Each analyses requires a phylogenetic tree (.tre
> > file),
> > and each tree is very similar. Any thoughts as to what's causing this
> > problem? The problem may be specific to the function I'm using [pd()],
> > but
> > since the error is a data.frame error I thought I'd ask here. Here is
> > the
> > code I'm using:
> >
> > This works:
> > phyl_tree <- read.nexus("phyl.tre")
> > phyl_data <- as.matrix(read.table("phyl_matrix.txt"), header=TRUE, sep
> > =
> > "\t")
> > pd.result <- pd(phyl_data, phyl_tree, include.root = TRUE)
> >
> > This fails (this matrix.txt file is the same as above, except that
> > columns
> > are ordered to match the tree; I have also used the above matrix.txt
> > file)
> > chem_tree <- read.nexus("chem.tre")
> > chem_data <- as.matrix(read.table("chem_matrix.txt"), header=TRUE, sep
> > =
> > "\t")
> > pd_chem.result <- pd(chem_data, chem_tree, include.root = TRUE)
> >
> > ERROR:
> > Error in data.frame(PD = PDs, SR = SR) :
> >   arguments imply differing number of rows: 34, 35
> >
> >
> > To illustrate that the data for each run are very similar (row and
> > column
> > names are also the same in both data files):
> >
> > > phyl_tree
> >
> > Phylogenetic tree with 9 tips and 7 internal nodes.
> >
> > Tip labels:
> > Heliantheae, Eupatorieae, Helenieae, Gnaphalieae, Anthemideae,
> > Astereae, ...
> > Node labels:
> > root, minCyn, minCic, HelEurHel, HelEur, GnaAnthAst, ...
> >
> > Rooted; includes branch lengths.
> >
> > > nrow(phyl_data)
> > [1] 35
> > > ncol(phyl_data)
> > [1] 9
> > > class(phyl_data)
> > [1] "matrix"
> >
> >
> > > chem_tree
> >
> > Phylogenetic tree with 9 tips and 7 internal nodes.
> >
> > Tip labels:
> > Heliantheae, Helenieae, Eupatorieae, Astereae, Gnaphlieae, Senecioneae,
> > ...
> > Node labels:
> > root, minC, minAnth, minSen, minGna, HelHel, ...
> >
> > Rooted; includes branch lengths.
> >
> > > nrow(chem_data)
> > [1] 35
> > > ncol(chem_data)
> > [1] 9
> > > class(chem_data)
> > [1] "matrix"
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sat Mar 14 16:44:10 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 14 Mar 2015 11:44:10 -0400
Subject: [R] Help with error: arguments imply differing number of rows
In-Reply-To: <CAKXkWh0eg2P2UDgOZw-Mt+Ncr=WQeG=c-2a3wJjNHQA6vo_4xg@mail.gmail.com>
References: <CAKXkWh3GQ2vgF=4SvF1jLb19uFeKBY7eDttAd919RU_CTTFcTg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23D2F@SRVEXCHMBX.precheza.cz>
	<CAKXkWh0eg2P2UDgOZw-Mt+Ncr=WQeG=c-2a3wJjNHQA6vo_4xg@mail.gmail.com>
Message-ID: <CCBC4993-634E-4822-B47A-34F1633398B5@utoronto.ca>

Not the same. Read carefully...
                                                   
> $ edge       : int [1:15, 1:2] 10 11 12 13 14 14 13 12 15 15 ...
> $ edge       : int [1:15, 1:2] 10 11 12 13 14 15 15 14 16 16 ...
                                                ^^... etc

B.


On Mar 14, 2015, at 11:34 AM, Aman Gill <amango at gmail.com> wrote:

> Thanks for the reply. The results of str() are indeed the same. Is there
> anything else I can check that might explain the difference?
> 
>> str(phyl_tree)
> List of 4
> $ edge       : int [1:15, 1:2] 10 11 12 13 14 14 13 12 15 15 ...
> $ Nnode      : int 7
> $ tip.label  : chr [1:9] "Heliantheae" "Eupatorieae" "Helenieae"
> "Gnaphalieae" ...
> $ edge.length: num [1:15] 1 1 1 1 1 1 2 1 2 1 ...
> - attr(*, "class")= chr "phylo"
> - attr(*, "order")= chr "cladewise"
>> 
>> str(chem_tree)
> List of 4
> $ edge       : int [1:15, 1:2] 10 11 12 13 14 15 15 14 16 16 ...
> $ Nnode      : int 7
> $ tip.label  : chr [1:9] "Heliantheae" "Helenieae" "Eupatorieae"
> "Astereae" ...
> $ edge.length: num [1:15] 1 2 1 1 1 1 1 1 1 1 ...
> - attr(*, "class")= chr "phylo"
> - attr(*, "order")= chr "cladewise"
> 
>> str(phyl_data)
> int [1:35, 1:9] 0 0 0 1 0 0 0 0 0 1 ...
> - attr(*, "dimnames")=List of 2
>  ..$ : chr [1:35] "Uroleucon_aeneum" "Uroleucon_aff_atripes"
> "Uroleucon_amamianum" "Uroleucon_ambrosiae" ...
>  ..$ : chr [1:9] "Heliantheae" "Eupatorieae" "Helenieae" "Gnaphalieae" ...
>> 
>> str(chem_data)
> int [1:35, 1:9] 0 0 0 1 0 0 0 0 0 1 ...
> - attr(*, "dimnames")=List of 2
>  ..$ : chr [1:35] "Uroleucon_aeneum" "Uroleucon_aff_atripes"
> "Uroleucon_amamianum" "Uroleucon_ambrosiae" ...
>  ..$ : chr [1:9] "Heliantheae" "Helenieae" "Eupatorieae" "Astereae" ...
> 
> 
> On Fri, Mar 13, 2015 at 7:31 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
>> Hi
>> 
>> Without further information you probably do not get answers. Everything
>> seems to be same so the only reason can be that the objects seems to be
>> same but they have some inner distinctions, maybe type of variables.
>> 
>> Are results of
>> 
>> str(your.objects)
>> 
>> same in equivalent objects?
>> 
>> Cheers
>> Petr
>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Aman
>>> Gill
>>> Sent: Thursday, March 12, 2015 6:08 PM
>>> To: r-help at r-project.org
>>> Subject: [R] Help with error: arguments imply differing number of rows
>>> 
>>> Hello,
>>> 
>>> I am stuck trying to run an analysis using the package picante. I am
>>> running two very similar analyses. One works as expected, but when I
>>> try
>>> the other, I get the error:
>>> 
>>> Error in data.frame(PD = PDs, SR = SR) :
>>>  arguments imply differing number of rows: 34, 35
>>> 
>>> This is strange to me since the data matrix is the same for both
>>> analyses
>>> (numbers of rows and columns are the same; the only difference is the
>>> order
>>> of the columns). Each analyses requires a phylogenetic tree (.tre
>>> file),
>>> and each tree is very similar. Any thoughts as to what's causing this
>>> problem? The problem may be specific to the function I'm using [pd()],
>>> but
>>> since the error is a data.frame error I thought I'd ask here. Here is
>>> the
>>> code I'm using:
>>> 
>>> This works:
>>> phyl_tree <- read.nexus("phyl.tre")
>>> phyl_data <- as.matrix(read.table("phyl_matrix.txt"), header=TRUE, sep
>>> =
>>> "\t")
>>> pd.result <- pd(phyl_data, phyl_tree, include.root = TRUE)
>>> 
>>> This fails (this matrix.txt file is the same as above, except that
>>> columns
>>> are ordered to match the tree; I have also used the above matrix.txt
>>> file)
>>> chem_tree <- read.nexus("chem.tre")
>>> chem_data <- as.matrix(read.table("chem_matrix.txt"), header=TRUE, sep
>>> =
>>> "\t")
>>> pd_chem.result <- pd(chem_data, chem_tree, include.root = TRUE)
>>> 
>>> ERROR:
>>> Error in data.frame(PD = PDs, SR = SR) :
>>>  arguments imply differing number of rows: 34, 35
>>> 
>>> 
>>> To illustrate that the data for each run are very similar (row and
>>> column
>>> names are also the same in both data files):
>>> 
>>>> phyl_tree
>>> 
>>> Phylogenetic tree with 9 tips and 7 internal nodes.
>>> 
>>> Tip labels:
>>> Heliantheae, Eupatorieae, Helenieae, Gnaphalieae, Anthemideae,
>>> Astereae, ...
>>> Node labels:
>>> root, minCyn, minCic, HelEurHel, HelEur, GnaAnthAst, ...
>>> 
>>> Rooted; includes branch lengths.
>>> 
>>>> nrow(phyl_data)
>>> [1] 35
>>>> ncol(phyl_data)
>>> [1] 9
>>>> class(phyl_data)
>>> [1] "matrix"
>>> 
>>> 
>>>> chem_tree
>>> 
>>> Phylogenetic tree with 9 tips and 7 internal nodes.
>>> 
>>> Tip labels:
>>> Heliantheae, Helenieae, Eupatorieae, Astereae, Gnaphlieae, Senecioneae,
>>> ...
>>> Node labels:
>>> root, minC, minAnth, minSen, minGna, HelHel, ...
>>> 
>>> Rooted; includes branch lengths.
>>> 
>>>> nrow(chem_data)
>>> [1] 35
>>>> ncol(chem_data)
>>> [1] 9
>>>> class(chem_data)
>>> [1] "matrix"
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>> 
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>> 
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>> 
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter
>> into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Sat Mar 14 17:53:58 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 14 Mar 2015 17:53:58 +0100
Subject: [R] Course and book announcements on r-help
In-Reply-To: <B6C5B117C2B.000012C7jrkrideau@inbox.com>
References: <077E31A57DA26E46AB0D493C9966AC730F0699E4FD@UM-MAIL4112.unimaas.nl>
	<B6C5B117C2B.000012C7jrkrideau@inbox.com>
Message-ID: <21764.26534.716141.911224@stat.math.ethz.ch>

>>>>> John Kane <jrkrideau at inbox.com>
>>>>>     on Fri, 13 Mar 2015 06:16:19 -0800 writes:

    > I have the feeling that this was discussed 3-4 years ago
    > and the overall opinion seems to be that if the course or
    > book was relevant then it was acceptable on an occasional
    > basis. No spamming-type or mass selling posts were.  
    > John Kane Kingston ON Canada

Your feeling is pretty good.
At the time -- and still today -- we did not want to impose
rigid rules about this.
As host and principal maintainer of the R-*@r-project.org
mailing list, my current view is as follows:

* Books: 

  Should typically *not* be announced on R-help for the
  following reasons.

  a) The R web page lists books which deal with R as a major theme.
    (http://www.r-project.org/ sidebar 'Documentation' -> 'Books'
       ==> http://www.r-project.org/doc/bib/R-books.html). All R
    Core and some other R Foundation members can edit the
    underlying *.bib source file in R-docs; historically 95% of
    that work has been done by Kurt Hornik and Fritz Leisch.
  b) Books just using R to solve a certain problem abound nowadays
    and should defintely *not* be announced as globally as by
    using R-help.

* Course announcements: 

  You may announce a course "series" once if it's new *and*
  globally accessible online.  All other courses should be
  announced in local R user groups, or similar forums. 

-- -- -- -- -- -- -- -- -- -- -- -- 

And because it's the weekend: 

Motto:

  We humans live much better with guidelines by responsibly applying good judgement.   
  It's only the (digital) machines that need strict unambigous rules.
  Let the AI programmers deal with them and remain human ourselves!

   (inspired by Haim Harari's thoughts in http://edge.org/response-detail/26056)


Best regards,
Martin Maechler, ETH Zurich and R Core


    >> -----Original Message----- From:
    >> wolfgang.viechtbauer at maastrichtuniversity.nl Sent: Fri,
    >> 13 Mar 2015 10:26:04 +0100 To: r-help at r-project.org
    >> Subject: [R] Course and book announcements on r-help
    >> 
    >> Dear All,
    >> 
    >> Just wondering: Is there any official policy on
    >> announcing R-related courses and books on r-help?
    >> 
    >> I didn't find anything on this in the posting guide, but
    >> http://www.r-project.org/mail.html#instructions says that
    >> r-help is, among other things, for "announcements (not
    >> covered by 'R-announce' or 'R-packages', see
    >> above)". That sounds a bit like this would cover courses
    >> and books, but I am not sure. Obviously, R-announce is
    >> not meant for that, as it is "for major announcements
    >> about the development of R and the availability of new
    >> code" and is to be used "for announcements mainly by the
    >> R Core Development Team".
    >> 
    >> I see the occasional course/book announcement, but it
    >> seems to me that there are a lot more courses and books
    >> out there compared to how many announcements there are
    >> related to them on this mailing list. So, I am wondering
    >> if such announcements are somewhat implicitly
    >> discouraged.
    >> 
    >> Best, Wolfgang
    >> 
    >> --
    >> Wolfgang Viechtbauer, Ph.D., Statistician Department of
    >> Psychiatry and Psychology School for Mental Health and
    >> Neuroscience Faculty of Health, Medicine, and Life
    >> Sciences Maastricht University, P.O. Box 616 (VIJV1) 6200
    >> MD Maastricht, The Netherlands +31 (43) 388-4170 |
    >> http://www.wvbauer.com


From spencer.graves at prodsyse.com  Sat Mar 14 18:02:46 2015
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 14 Mar 2015 10:02:46 -0700
Subject: [R] Course and book announcements on r-help
In-Reply-To: <21764.26534.716141.911224@stat.math.ethz.ch>
References: <077E31A57DA26E46AB0D493C9966AC730F0699E4FD@UM-MAIL4112.unimaas.nl>	<B6C5B117C2B.000012C7jrkrideau@inbox.com>
	<21764.26534.716141.911224@stat.math.ethz.ch>
Message-ID: <550469B6.7060004@prodsyse.com>

       While answering a question, I believe it's acceptable (even 
encouraged) to cite a relevant book, even if it's yours ;-)


       Spencer


On 3/14/2015 9:53 AM, Martin Maechler wrote:
>>>>>> John Kane <jrkrideau at inbox.com>
>>>>>>      on Fri, 13 Mar 2015 06:16:19 -0800 writes:
>      > I have the feeling that this was discussed 3-4 years ago
>      > and the overall opinion seems to be that if the course or
>      > book was relevant then it was acceptable on an occasional
>      > basis. No spamming-type or mass selling posts were.
>      > John Kane Kingston ON Canada
>
> Your feeling is pretty good.
> At the time -- and still today -- we did not want to impose
> rigid rules about this.
> As host and principal maintainer of the R-*@r-project.org
> mailing list, my current view is as follows:
>
> * Books:
>
>    Should typically *not* be announced on R-help for the
>    following reasons.
>
>    a) The R web page lists books which deal with R as a major theme.
>      (http://www.r-project.org/ sidebar 'Documentation' -> 'Books'
>         ==> http://www.r-project.org/doc/bib/R-books.html). All R
>      Core and some other R Foundation members can edit the
>      underlying *.bib source file in R-docs; historically 95% of
>      that work has been done by Kurt Hornik and Fritz Leisch.
>    b) Books just using R to solve a certain problem abound nowadays
>      and should defintely *not* be announced as globally as by
>      using R-help.
>
> * Course announcements:
>
>    You may announce a course "series" once if it's new *and*
>    globally accessible online.  All other courses should be
>    announced in local R user groups, or similar forums.
>
> -- -- -- -- -- -- -- -- -- -- -- --
>
> And because it's the weekend:
>
> Motto:
>
>    We humans live much better with guidelines by responsibly applying good judgement.
>    It's only the (digital) machines that need strict unambigous rules.
>    Let the AI programmers deal with them and remain human ourselves!
>
>     (inspired by Haim Harari's thoughts in http://edge.org/response-detail/26056)
>
>
> Best regards,
> Martin Maechler, ETH Zurich and R Core
>
>
>      >> -----Original Message----- From:
>      >> wolfgang.viechtbauer at maastrichtuniversity.nl Sent: Fri,
>      >> 13 Mar 2015 10:26:04 +0100 To: r-help at r-project.org
>      >> Subject: [R] Course and book announcements on r-help
>      >>
>      >> Dear All,
>      >>
>      >> Just wondering: Is there any official policy on
>      >> announcing R-related courses and books on r-help?
>      >>
>      >> I didn't find anything on this in the posting guide, but
>      >> http://www.r-project.org/mail.html#instructions says that
>      >> r-help is, among other things, for "announcements (not
>      >> covered by 'R-announce' or 'R-packages', see
>      >> above)". That sounds a bit like this would cover courses
>      >> and books, but I am not sure. Obviously, R-announce is
>      >> not meant for that, as it is "for major announcements
>      >> about the development of R and the availability of new
>      >> code" and is to be used "for announcements mainly by the
>      >> R Core Development Team".
>      >>
>      >> I see the occasional course/book announcement, but it
>      >> seems to me that there are a lot more courses and books
>      >> out there compared to how many announcements there are
>      >> related to them on this mailing list. So, I am wondering
>      >> if such announcements are somewhat implicitly
>      >> discouraged.
>      >>
>      >> Best, Wolfgang
>      >>
>      >> --
>      >> Wolfgang Viechtbauer, Ph.D., Statistician Department of
>      >> Psychiatry and Psychology School for Mental Health and
>      >> Neuroscience Faculty of Health, Medicine, and Life
>      >> Sciences Maastricht University, P.O. Box 616 (VIJV1) 6200
>      >> MD Maastricht, The Netherlands +31 (43) 388-4170 |
>      >> http://www.wvbauer.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From tmrsg11 at gmail.com  Sat Mar 14 21:16:32 2015
From: tmrsg11 at gmail.com (C W)
Date: Sat, 14 Mar 2015 16:16:32 -0400
Subject: [R] Is RcppOctave package available for Mac to install?
In-Reply-To: <4DB77641-A8CD-4DEF-845B-D9E6ACBB3E83@comcast.net>
References: <CAE2FW2=xU7_yCGyihhTWQ2tt_Fj0GbVj1XW+VgpY1TtSJMARVQ@mail.gmail.com>
	<4DB77641-A8CD-4DEF-845B-D9E6ACBB3E83@comcast.net>
Message-ID: <CAE2FW2n7AObCd80xhORAbtbru5edOqX0RMjsEBDwszuz=LL=Bg@mail.gmail.com>

Hi David,

Thanks for the detail information.  I think I will probably work in Octave
instead, and fix the problem when I have a little more time.

Mike

On Sat, Mar 14, 2015 at 2:13 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Mar 13, 2015, at 11:50 PM, C W <tmrsg11 at gmail.com> wrote:
> >
> > Hi everyone,
> >
> > When I tried to install RcppOctave package I got the following.
> >> install.packages("RcppOctave")
> > --- Please select a CRAN mirror for use in this session ---
> >
> >  package ?RcppOctave? is available as a source package but not as a
> binary
> >
> > Warning message:
> > package ?RcppOctave? is not available (for R version 3.1.2)
>
> pkgmaker
> bibtex
> registry
>
>
> >
> > I see the RcppOctave_0.14.5.tar.gz  file on CRAN here,
> > http://cran.r-project.org/web/packages/RcppOctave/index.html
> >
> > I have not compiled any packages from source, I need to run brew doctor
> to
> > fix problems in homebrew before compiling.
>
> During the (unsuccessful) installation from source, I get the error (not
> entirely unexpected):
>
> checking for mkoctfile... no
> configure: error: mkoctfile not found, is Octave installed?
>
> (I am not surprised because I don?t have Octave installed.)
>
> There are further comments and instructions about installing octave. The
> instructions to install octave may alter the locations or symlinks for
> gfortran which might create problems for installing R packages from source,
> since the directory locations for brew installs are different than those
> that R expects. You might want to post the question on R-SIG-Mac.
>
> ?
> David.
>
> > I just wanted to make sure the tar.gz file is good to go before I fix
> > homebrew.
> >
> > Thanks,
> >
> > Mike
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius, MD
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From raju.mailinglists at gmail.com  Sun Mar 15 00:09:19 2015
From: raju.mailinglists at gmail.com (kamaraju kusumanchi)
Date: Sat, 14 Mar 2015 19:09:19 -0400
Subject: [R] measure of goodness of fit for the model without an
	intercept
In-Reply-To: <D0F02159.961A%yanwu1205@gmail.com>
References: <D0F02159.961A%yanwu1205@gmail.com>
Message-ID: <CABpbYae4Hygu38sy0dthwYWgG4=MpZfTx0xRfyZgoi6+acK2TQ@mail.gmail.com>

On Thu, Jan 29, 2015 at 6:41 PM, Yan Wu <yanwu1205 at gmail.com> wrote:
> Hi,
>
> When I fit the regression model without an intercept term, R-squared tends
> to much larger than the R-squared in the model with an intercept. So in this
> case, what?s a more reasonable measure of the goodness of fit for the model
> without an intercept?
>
> Thanks a lot!!
>
> Yan
>

I am going through the list archives and found your question. I guess
it is unanswered because it is not directly related to R language per
se but is more to do with time series analysis in general.

In general, R square tells you only part of the story. You need to
look at the t-stats of the regression coefficients to understand
whether the betas from the regression are statistically significant.

Further, IIRC R square always increases as more variables are added to
the regression. That is why practitioners look at "adjusted r-square"
instead of "r square" which account for this. So I am curious as to
why your data produces less r square when you add the constant. Is it
possible to upload your data somewhere so pther can take a look at it?

thanks
-- 
Kamaraju S Kusumanchi | http://raju.shoutwiki.com/wiki/Blog


From nickdoban at gmail.com  Sat Mar 14 18:28:28 2015
From: nickdoban at gmail.com (Nicolae Doban)
Date: Sat, 14 Mar 2015 18:28:28 +0100
Subject: [R] A simple For-Loop doesn't work
Message-ID: <CADPWiKiW-uFLp_iXGZEaE72tXy7sS4MBoRApY1OOi+7LVsmKbg@mail.gmail.com>

Hello,

my name is Nick and I'm working on a project. I'm having trouble with
building a simple for-loop. In this loop I want to read csv files, perform
a corr function and save it to a pdf file. I tried to solve this problem by
looking for solutions online but couldn't figure it out. Could you also
tell me if if it is possible to name the dataframe(grid.table())?Could you
please help me?

The code I wrote and which doesn't work is:
*                                        <Code>*
Data <- c("July", "August",  "September")

pdf("Cor.pdf")
setwd("path")
for(i in 1:6){

  Data[i] <- read.csv(Data[i],".csv", header=T)

  grid.table(cor(Data[i][3:10]))
  corrgram(Data[i], order=TRUE, lower.panel=panel.shade,
           upper.panel=panel.pie, text.panel=panel.txt,
           main=Data[i],"Cor")

}
dev.off()
*                                            </Code>*

Thank you,
Nick

	[[alternative HTML version deleted]]


From marek.r at lutonsky.net  Sat Mar 14 23:02:55 2015
From: marek.r at lutonsky.net (marekl)
Date: Sat, 14 Mar 2015 15:02:55 -0700 (PDT)
Subject: [R] =?utf-8?q?Persons_with_objects_=E2=80=93=3E_Objects_and_perso?=
	=?utf-8?q?ns?=
Message-ID: <1426370575108-4704655.post@n4.nabble.com>

Hi,

I have a table with persons in rows and objects associated to these persons.
And I need to transform it to table with objects in rows and persons next to
them. As it is shown on the picture. 

<http://r.789695.n4.nabble.com/file/n4704655/Persons%2C_Objects.png> 

Can you please help me how to make this transformation in R?

Thank you



--
View this message in context: http://r.789695.n4.nabble.com/Persons-with-objects-Objects-and-persons-tp4704655.html
Sent from the R help mailing list archive at Nabble.com.


From lyle00 at gmail.com  Sun Mar 15 04:50:22 2015
From: lyle00 at gmail.com (Lyle Warren)
Date: Sun, 15 Mar 2015 14:50:22 +1100
Subject: [R] How am i able to create Box plots of a factor (weight)
 separated by other factors (breed)?
Message-ID: <CAA3AKSd7MaqJ+3GC0ceg4exeeba3uHvk9ar7i2SW93NrJFpLaw@mail.gmail.com>

>
>
> I have data with columns for animal ID, breed, and weight.
>
> I'd like to create a box plot of weight, separated by breed (there are 4
> breeds).
>
> Any ideas?
>
> Here's a sample of the data (there are 100 rows):
>
> id      weight  breed
> 1       453     brahman
> 2       527     brahman
> 3       520     brahman
> 4       460     brahman
> 5       496     brahman
> 6       461     brahman
> 7       519     brahman
> 8       472     brahman
> 9       531     brahman
> 10      473     brahman
> 11      509     brahman
> 12      503     brahman
>
> Thanks for your help!
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Sun Mar 15 09:18:17 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sun, 15 Mar 2015 09:18:17 +0100
Subject: [R] How am i able to create Box plots of a factor (weight)
 separated by other factors (breed)?
In-Reply-To: <CAA3AKSd7MaqJ+3GC0ceg4exeeba3uHvk9ar7i2SW93NrJFpLaw@mail.gmail.com>
References: <CAA3AKSd7MaqJ+3GC0ceg4exeeba3uHvk9ar7i2SW93NrJFpLaw@mail.gmail.com>
Message-ID: <CAJuCY5yO=EHuZjoA53DDG3kkAFX8HY0dT+6b5aALsz1UBOv1+g@mail.gmail.com>

Have a look at http://docs.ggplot2.org/current/geom_boxplot.html

You will find several examples there.

Best regards
Op 15-mrt.-2015 04:59 schreef "Lyle Warren" <lyle00 at gmail.com>:

> >
> >
> > I have data with columns for animal ID, breed, and weight.
> >
> > I'd like to create a box plot of weight, separated by breed (there are 4
> > breeds).
> >
> > Any ideas?
> >
> > Here's a sample of the data (there are 100 rows):
> >
> > id      weight  breed
> > 1       453     brahman
> > 2       527     brahman
> > 3       520     brahman
> > 4       460     brahman
> > 5       496     brahman
> > 6       461     brahman
> > 7       519     brahman
> > 8       472     brahman
> > 9       531     brahman
> > 10      473     brahman
> > 11      509     brahman
> > 12      503     brahman
> >
> > Thanks for your help!
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sergio.fonda99 at gmail.com  Sun Mar 15 09:26:52 2015
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Sun, 15 Mar 2015 09:26:52 +0100
Subject: [R] A simple For-Loop doesn't work
In-Reply-To: <CADPWiKiW-uFLp_iXGZEaE72tXy7sS4MBoRApY1OOi+7LVsmKbg@mail.gmail.com>
References: <CADPWiKiW-uFLp_iXGZEaE72tXy7sS4MBoRApY1OOi+7LVsmKbg@mail.gmail.com>
Message-ID: <CAJRuHopA2tP_fp8S29Zwim5qSiLF+HcYrGb_fT6YKh8F2Wu1Vg@mail.gmail.com>

Pay attention to the i counter in the loop: it runs from 1 to 6 but data
has only 3 elements
 Il 15/mar/2015 04:56 "Nicolae Doban" <nickdoban at gmail.com> ha scritto:

> Hello,
>
> my name is Nick and I'm working on a project. I'm having trouble with
> building a simple for-loop. In this loop I want to read csv files, perform
> a corr function and save it to a pdf file. I tried to solve this problem by
> looking for solutions online but couldn't figure it out. Could you also
> tell me if if it is possible to name the dataframe(grid.table())?Could you
> please help me?
>
> The code I wrote and which doesn't work is:
> *                                        <Code>*
> Data <- c("July", "August",  "September")
>
> pdf("Cor.pdf")
> setwd("path")
> for(i in 1:6){
>
>   Data[i] <- read.csv(Data[i],".csv", header=T)
>
>   grid.table(cor(Data[i][3:10]))
>   corrgram(Data[i], order=TRUE, lower.panel=panel.shade,
>            upper.panel=panel.pie, text.panel=panel.txt,
>            main=Data[i],"Cor")
>
> }
> dev.off()
> *                                            </Code>*
>
> Thank you,
> Nick
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rainer.schuermann at gmx.net  Sun Mar 15 09:40:44 2015
From: rainer.schuermann at gmx.net (Rainer Schuermann)
Date: Sun, 15 Mar 2015 09:40:44 +0100
Subject: [R] A simple For-Loop doesn't work
In-Reply-To: <CADPWiKiW-uFLp_iXGZEaE72tXy7sS4MBoRApY1OOi+7LVsmKbg@mail.gmail.com>
References: <CADPWiKiW-uFLp_iXGZEaE72tXy7sS4MBoRApY1OOi+7LVsmKbg@mail.gmail.com>
Message-ID: <201503150940.44589.rainer.schuermann@gmx.net>

Hi Nick,

Your code is not exactly "commented, minimal, self-contained, reproducible" and contains a number of inconsistencies (Data has three elements, your loop expects six). Try something like

Data <- c("July", "August",  "September")
...
for( x in Data )
{
	currentData <- read.csv( paste( x, ".csv", sep = "" ), header = TRUE )
	...
}

to get your loop going.

Rgds,
Rainer



On Saturday 14 March 2015 18:28:28 Nicolae Doban wrote:
> Hello,
> 
> my name is Nick and I'm working on a project. I'm having trouble with
> building a simple for-loop. In this loop I want to read csv files, perform
> a corr function and save it to a pdf file. I tried to solve this problem by
> looking for solutions online but couldn't figure it out. Could you also
> tell me if if it is possible to name the dataframe(grid.table())?Could you
> please help me?
> 
> The code I wrote and which doesn't work is:
> *                                        <Code>*
> Data <- c("July", "August",  "September")
> 
> pdf("Cor.pdf")
> setwd("path")
> for(i in 1:6){
> 
>   Data[i] <- read.csv(Data[i],".csv", header=T)
> 
>   grid.table(cor(Data[i][3:10]))
>   corrgram(Data[i], order=TRUE, lower.panel=panel.shade,
>            upper.panel=panel.pie, text.panel=panel.txt,
>            main=Data[i],"Cor")
> 
> }
> dev.off()
> *                                            </Code>*
> 
> Thank you,
> Nick
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bhh at xs4all.nl  Sun Mar 15 09:45:41 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 15 Mar 2015 09:45:41 +0100
Subject: [R] A simple For-Loop doesn't work
In-Reply-To: <CADPWiKiW-uFLp_iXGZEaE72tXy7sS4MBoRApY1OOi+7LVsmKbg@mail.gmail.com>
References: <CADPWiKiW-uFLp_iXGZEaE72tXy7sS4MBoRApY1OOi+7LVsmKbg@mail.gmail.com>
Message-ID: <7D7E50E6-5076-4AAB-80A0-407DB64DE8FA@xs4all.nl>


> On 14-03-2015, at 18:28, Nicolae Doban <nickdoban at gmail.com> wrote:
> 
> Hello,
> 
> my name is Nick and I'm working on a project. I'm having trouble with
> building a simple for-loop. In this loop I want to read csv files, perform
> a corr function and save it to a pdf file. I tried to solve this problem by
> looking for solutions online but couldn't figure it out. Could you also
> tell me if if it is possible to name the dataframe(grid.table())?Could you
> please help me?
> 
> The code I wrote and which doesn't work is:
> *                                        <Code>*
> Data <- c("July", "August",  "September")
> 
> pdf("Cor.pdf")
> setwd("path")
> for(i in 1:6){
> 
>  Data[i] <- read.csv(Data[i],".csv", header=T)
> 
>  grid.table(cor(Data[i][3:10]))
>  corrgram(Data[i], order=TRUE, lower.panel=panel.shade,
>           upper.panel=panel.pie, text.panel=panel.txt,
>           main=Data[i],"Cor")
> 
> }
> dev.off()
> *                                            </Code>*
> 

You did not tell us what error messages you are getting or what is going wrong.

In addition to the previous remark: you are not creating the file name in read.csv in the correct way.
The filename is a single string. Create it with e.g. paste0(Data[i],?csv?) or possibly if required with file.path(?).

Furthermore you are overwriting Data[i] with the result of read.csv. Why?
Use something like DT <- read.csv(?.) and change the remainder of your commands to use DT.

Please do not use the abbreviation T for TRUE.

> Thank you,


> Nick
> 
> 	[[alternative HTML version deleted]]
> 

Please do not post in html as the Posting guide asks.

Berend


From drjimlemon at gmail.com  Sun Mar 15 11:46:24 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 15 Mar 2015 21:46:24 +1100
Subject: [R]
	=?utf-8?q?Persons_with_objects_=E2=80=93=3E_Objects_and_perso?=
	=?utf-8?q?ns?=
In-Reply-To: <1426370575108-4704655.post@n4.nabble.com>
References: <1426370575108-4704655.post@n4.nabble.com>
Message-ID: <CA+8X3fXn8M9NLyBbGhH9p7UcdLEmEHOUwFXNQB7wp9ytwrHPvw@mail.gmail.com>

Hi mareki,
The transformation is not too difficult, but the table format in your
example will cause a bit of difficulty. The following function from the
plotrix package:

categoryReshape<-function(x) {
 dimx<-dim(x)
 if(is.null(dimx) || dimx[2]==1)
  stop("Can only reshape a matrix or data frame with at least two columns")
 row_values<-sort(unique(x[,1]))
 column_values<-sort(unique(x[,2]))
 newx<-

as.data.frame(matrix(0,nrow=length(row_values),ncol=length(column_values)))
 for(row in 1:dimx[1]) {
  row_index<-which(row_values %in% x[row,1])
  column_index<-which(column_values %in% x[row,2])
  newx[row_index,column_index]<-1
 }
 names(newx)<-column_values
 rownames(newx)<-row_values
 return(newx)
}

will take a matrix or data frame like this:

table1<-read.table(text="object,person
A,1
A,2
A,3
A,4
A,5
B,1
B,2
B,3
C,2
C,3
C,5
D,4
E,2
E,3
E,4
E,5",sep=",",header=TRUE)

and transform it into a data frame like this:

 categoryReshape(table1)
  1 2 3 4 5
A 1 1 1 1 1
B 1 1 1 0 0
C 0 1 1 0 1
D 0 0 0 1 0
E 0 1 1 1 1

Then if you take each column and format it like this;

concat_labels<-function(x,labels)
return(paste(labels[as.logical(x)],collapse=";"))
sapply(table2,concat.labels,rownames(tables))

        1         2         3         4         5
    "A;B" "A;B;C;E" "A;B;C;E"   "A;D;E"   "A;C;E"

you have pretty much what you want.

Jim


On Sun, Mar 15, 2015 at 9:02 AM, marekl <marek.r at lutonsky.net> wrote:

> Hi,
>
> I have a table with persons in rows and objects associated to these
> persons.
> And I need to transform it to table with objects in rows and persons next
> to
> them. As it is shown on the picture.
>
> <http://r.789695.n4.nabble.com/file/n4704655/Persons%2C_Objects.png>
>
> Can you please help me how to make this transformation in R?
>
> Thank you
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Persons-with-objects-Objects-and-persons-tp4704655.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marongiu.luigi at gmail.com  Sun Mar 15 12:05:55 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Sun, 15 Mar 2015 11:05:55 +0000
Subject: [R] create pcrfit model with qpcR package
Message-ID: <CAMk+s2T8m63DXX+Eo4C7=UKssj0xPfL42cx+mbShBnUyJsw7HA@mail.gmail.com>

Dear all,
I am trying to set a model using the pcrfit() function of the qpcR
package. I have defined a dataframe with 45 cycles (rows) and 4
readings (columns) derived from a TaqMan qPCR with relative
quantification. The data is based on the normalized fluorescent
results (main fluorescence minus ROX).
The example reported herein has a couple of readings with abnormal
amplification (which would be the usual kind of results for the PCR I
am carrying out) and two with a proper amplification; the plot section
of the example is meant to describe the data itself.
For each implementation, the error returned is:

Error in model.frame.default(formula = ~Fluo + Cycles, data = DATA,
weights = WEIGHTS,  :
  variable lengths differ (found for '(do.optim)')

However each column has 45 rows.

Any tips on how to problem-solve this issue?
Many thanks,
Luigi

PS:
The following example writes a file in the current folder, uses it for
the pcrfit modelling and then removes it.
>>>
# define working directory
setwd(getwd())

# qpcR
if(!is.element('qpcR', installed.packages()[,1]))
{
  install.packages('qpcR')
} else {
  library(qpcR)
}

# create dataframe
col.0<-1:45
col.a<-c(-0.033,  -0.027,    -0.015,    -0.007,    -0.001,    0.001,
 0.003,    0.004,    0.005,    0.003,    0.004,    0.001,    0.002,
0.002,    0.001,    0.002,    0.002,    0.001,    0.001,    0.001,
0.004,    0.002,    -0.001,    0.001,    0.001,    -0.001,    -0.002,
  -0.001,    0.001,    -0.001,    -0.002,    -0.001,    -0.002,
-0.001,    -0.003,    -0.004,    -0.002,    -0.001,    -0.002,
-0.001,    0.001,    0.001,    0.002,    0.003,    0.006)
col.b<-c(-0.128,    -0.116,    -0.089,    -0.068,    -0.048,
-0.032,    -0.018,    -0.006,    0.004,    0.009,    0.015,    0.02,
 0.024,    0.025,    0.028,    0.029,    0.028,    0.029,    0.029,
0.026,    0.025,    0.024,    0.023,    0.019,    0.018,    0.018,
0.015,    0.012,    0.01,    0.009,    0.006,    0.003,    -0.001,
-0.003,    -0.006,    -0.01,    -0.012,    -0.014,    -0.017,
-0.02,    -0.023,    -0.024,    -0.027,    -0.029,    -0.029)
col.c<-c(-0.045,    -0.048,    -0.043,    -0.036,    -0.023,    -0.01,
   0.006,    0.02,    0.029,    0.034,    0.037,    0.032,    0.026,
 0.017,    0.01,    -0.002,    -0.013,    -0.021,    -0.029,
-0.034,    -0.025,    0.006,    0.065,    0.163,    0.301,    0.477,
 0.68,    0.89,    1.092,    1.254,    1.41,    1.546,    1.664,
1.772,    1.865,    1.929,    1.983,    2.032,    2.066,    2.09,
2.108,    2.126,    2.129,    2.13,    2.142)
col.d<-c(-0.049,    -0.04,    -0.026,    -0.013,    -0.006,    0.002,
  0.007,    0.009,    0.01,    0.01,    0.009,    0.007,    0.007,
0.007,    0.005,    0.003,    0,    -0.002,    -0.005,    -0.006,
-0.006,    -0.008,    -0.005,    0,    0.01,    0.032,    0.072,
0.14,    0.237,    0.361,    0.51,    0.677,    0.847,    1.016,
1.181,    1.336,    1.481,    1.619,    1.742,    1.858,    1.962,
2.056,    2.136,    2.212,    2.27)
x.file<-cbind(col.0, col.a, col.b, col.c, col.d)

# write data working file
write.table(
  x.file,
  file="x.file.txt",
  sep="\t",
  eol = "\n",
  na = "NA",
  dec = ".",
  quote = FALSE,
  col.names = TRUE,
  row.names = FALSE,
  append = FALSE
)

# create objects
obj<-pcrimport2(
  file="x.file.txt",
  sep="\t",
  dec=".",
  header=TRUE,
  colClasses="numeric",
  quote=""
)

# calculate Cy0
Cy<-1:4
model<-1:4
model[1]<-pcrfit(obj, cyc=1, 2, model=l4, do.optim=TRUE, robust=FALSE)
model[2]<-pcrfit(obj, cyc=1, 3, model=l4, do.optim=TRUE, robust=FALSE)
model[3]<-pcrfit(obj, cyc=1, 4, model=l4, do.optim=TRUE, robust=FALSE)
model[4]<-pcrfit(obj, cyc=1, 5, model=l4, do.optim=TRUE, robust=FALSE)
Cy[1]<-Cy0(model[1], plot=FALSE)
Cy[2]<-Cy0(model[2], plot=FALSE)
Cy[3]<-Cy0(model[3], plot=FALSE)
Cy[4]<-Cy0(model[4], plot=FALSE)

# plot results as control
plot(col.a ~ col.0)
plot(col.b ~ col.0)
plot(col.c ~ col.0)
plot(col.d ~ col.0)

# remove working file
unlink("x.file.txt",
       recursive = FALSE,
       force = FALSE
)


From ruipbarradas at sapo.pt  Sun Mar 15 12:45:09 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 15 Mar 2015 11:45:09 +0000
Subject: [R] How am i able to create Box plots of a factor (weight)
 separated by other factors (breed)?
In-Reply-To: <CAA3AKSd7MaqJ+3GC0ceg4exeeba3uHvk9ar7i2SW93NrJFpLaw@mail.gmail.com>
References: <CAA3AKSd7MaqJ+3GC0ceg4exeeba3uHvk9ar7i2SW93NrJFpLaw@mail.gmail.com>
Message-ID: <550570C5.3090105@sapo.pt>

Hello,

Try, if your data.frame is named 'animal',

boxplot(weight ~ breed, data = animal)

Hope this helps,

Rui Barradas

Em 15-03-2015 03:50, Lyle Warren escreveu:
>>
>>
>> I have data with columns for animal ID, breed, and weight.
>>
>> I'd like to create a box plot of weight, separated by breed (there are 4
>> breeds).
>>
>> Any ideas?
>>
>> Here's a sample of the data (there are 100 rows):
>>
>> id      weight  breed
>> 1       453     brahman
>> 2       527     brahman
>> 3       520     brahman
>> 4       460     brahman
>> 5       496     brahman
>> 6       461     brahman
>> 7       519     brahman
>> 8       472     brahman
>> 9       531     brahman
>> 10      473     brahman
>> 11      509     brahman
>> 12      503     brahman
>>
>> Thanks for your help!
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at inbox.com  Sun Mar 15 13:53:39 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 15 Mar 2015 04:53:39 -0800
Subject: [R] How am i able to create Box plots of a factor (weight)
 separated by other factors (breed)?
In-Reply-To: <CAA3AKSd7MaqJ+3GC0ceg4exeeba3uHvk9ar7i2SW93NrJFpLaw@mail.gmail.com>
Message-ID: <CF3236F77B8.00000488jrkrideau@inbox.com>

As a follow up to Thierry's response.

With data as dat1

dat1  <-  structure(list(id = 1:12, weight = c(453L, 527L, 520L, 460L, 
496L, 461L, 519L, 472L, 531L, 473L, 509L, 503L), breed = c("brahman", 
"brahman", "brahman", "brahman", "durham", "durham", "durham", 
"durham", "durham", "durham", "durham", "durham")), .Names = c("id", 
"weight", "breed"), class = "data.frame", row.names = c(NA, -12L
))

library(ggplot2)
ggplot(dat1, aes(breed, weight)) +
      geom_boxplot()
library(ggplot2)
ggplot(dat1, aes(breed, weight)) +
      geom_boxplot()

I would note that it is difficult to break down the data by breed when your sample data only included brahman as a breed.  In the sample data above I changed a few entries to my favourite breed of Durham.

Have a look at one (or both) of these links for some useful suggestions on how to ask questions on R-help.  In particular, read about dput.  It is by far the best way to supply sample data for the readers.

Good luck

John Kane
Kingston ON Canada


> -----Original Message-----
> From: lyle00 at gmail.com
> Sent: Sun, 15 Mar 2015 14:50:22 +1100
> To: r-help at r-project.org
> Subject: [R] How am i able to create Box plots of a factor (weight)
> separated by other factors (breed)?
> 
>> 
>> 
>> I have data with columns for animal ID, breed, and weight.
>> 
>> I'd like to create a box plot of weight, separated by breed (there are 4
>> breeds).
>> 
>> Any ideas?
>> 
>> Here's a sample of the data (there are 100 rows):
>> 
>> id      weight  breed
>> 1       453     brahman
>> 2       527     brahman
>> 3       520     brahman
>> 4       460     brahman
>> 5       496     brahman
>> 6       461     brahman
>> 7       519     brahman
>> 8       472     brahman
>> 9       531     brahman
>> 10      473     brahman
>> 11      509     brahman
>> 12      503     brahman
>> 
>> Thanks for your help!
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From rshepard at appl-ecosys.com  Sun Mar 15 13:55:10 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Sun, 15 Mar 2015 05:55:10 -0700 (PDT)
Subject: [R] How am i able to create Box plots of a factor (weight)
 separated by other factors (breed)?
In-Reply-To: <CAA3AKSd7MaqJ+3GC0ceg4exeeba3uHvk9ar7i2SW93NrJFpLaw@mail.gmail.com>
References: <CAA3AKSd7MaqJ+3GC0ceg4exeeba3uHvk9ar7i2SW93NrJFpLaw@mail.gmail.com>
Message-ID: <alpine.LNX.2.11.1503150550550.4591@localhost>

On Sun, 15 Mar 2015, Lyle Warren wrote:

>> I have data with columns for animal ID, breed, and weight.
>> I'd like to create a box plot of weight, separated by breed (there are 4
>> breeds).

>> Any ideas?

   1. Did you check the help page: ?boxplot

>> Here's a sample of the data (there are 100 rows):
>>
>> id      weight  breed
>> 1       453     brahman
>> 2       527     brahman
>> 3       520     brahman
>> 4       460     brahman
>> 5       496     brahman
>> 6       461     brahman
>> 7       519     brahman
>> 8       472     brahman
>> 9       531     brahman
>> 10      473     brahman
>> 11      509     brahman
>> 12      503     brahman

   B. Perhaps something like this?

   boxplot(weight ~ breed)

   Look at the use of a formula when plotting.

   If I misread your intent I apologize.

HTH,

Rich


From jrkrideau at inbox.com  Sun Mar 15 13:55:58 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 15 Mar 2015 04:55:58 -0800
Subject: [R]
 =?utf-8?q?Persons_with_objects_=E2=80=93=3E_Objects_and_perso?=
 =?utf-8?q?ns?=
In-Reply-To: <1426370575108-4704655.post@n4.nabble.com>
Message-ID: <CF37641E56D.0000048Djrkrideau@inbox.com>

https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
http://xkcd.com/1478/

John Kane
Kingston ON Canada


> -----Original Message-----
> From: marek.r at lutonsky.net
> Sent: Sat, 14 Mar 2015 15:02:55 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] Persons with objects ?> Objects and persons
> 
> Hi,
> 
> I have a table with persons in rows and objects associated to these
> persons.
> And I need to transform it to table with objects in rows and persons next
> to
> them. As it is shown on the picture.
> 
> <http://r.789695.n4.nabble.com/file/n4704655/Persons%2C_Objects.png>
> 
> Can you please help me how to make this transformation in R?
> 
> Thank you
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Persons-with-objects-Objects-and-persons-tp4704655.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jrkrideau at inbox.com  Sun Mar 15 13:58:49 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 15 Mar 2015 04:58:49 -0800
Subject: [R] How am i able to create Box plots of a factor (weight)
 separated by other factors (breed)?
In-Reply-To: <CF3236F77B8.00000488jrkrideau@inbox.com>
References: <caa3aksd7maqj+3gc0ceg4exeeba3uhvk9ar7i2sw93nrjfplaw@mail.gmail.com>
Message-ID: <CF3DC65386A.00000491jrkrideau@inbox.com>

Oops missed the links.  Once more...
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
http://xkcd.com/1478/

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jrkrideau at inbox.com
> Sent: Sun, 15 Mar 2015 04:53:39 -0800
> To: lyle00 at gmail.com, r-help at r-project.org
> Subject: Re: [R] How am i able to create Box plots of a factor (weight)
> separated by other factors (breed)?
> 
> As a follow up to Thierry's response.
> 
> With data as dat1
> 
> dat1  <-  structure(list(id = 1:12, weight = c(453L, 527L, 520L, 460L,
> 496L, 461L, 519L, 472L, 531L, 473L, 509L, 503L), breed = c("brahman",
> "brahman", "brahman", "brahman", "durham", "durham", "durham",
> "durham", "durham", "durham", "durham", "durham")), .Names = c("id",
> "weight", "breed"), class = "data.frame", row.names = c(NA, -12L
> ))
> 
> library(ggplot2)
> ggplot(dat1, aes(breed, weight)) +
>       geom_boxplot()
> library(ggplot2)
> ggplot(dat1, aes(breed, weight)) +
>       geom_boxplot()
> 
> I would note that it is difficult to break down the data by breed when
> your sample data only included brahman as a breed.  In the sample data
> above I changed a few entries to my favourite breed of Durham.
> 
> Have a look at one (or both) of these links for some useful suggestions
> on how to ask questions on R-help.  In particular, read about dput.  It
> is by far the best way to supply sample data for the readers.
> 
> Good luck
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: lyle00 at gmail.com
>> Sent: Sun, 15 Mar 2015 14:50:22 +1100
>> To: r-help at r-project.org
>> Subject: [R] How am i able to create Box plots of a factor (weight)
>> separated by other factors (breed)?
>> 
>>> 
>>> 
>>> I have data with columns for animal ID, breed, and weight.
>>> 
>>> I'd like to create a box plot of weight, separated by breed (there are
>>> 4
>>> breeds).
>>> 
>>> Any ideas?
>>> 
>>> Here's a sample of the data (there are 100 rows):
>>> 
>>> id      weight  breed
>>> 1       453     brahman
>>> 2       527     brahman
>>> 3       520     brahman
>>> 4       460     brahman
>>> 5       496     brahman
>>> 6       461     brahman
>>> 7       519     brahman
>>> 8       472     brahman
>>> 9       531     brahman
>>> 10      473     brahman
>>> 11      509     brahman
>>> 12      503     brahman
>>> 
>>> Thanks for your help!
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Send any screenshot to your friends in seconds...
Works in all emails, instant messengers, blogs, forums and social networks.
TRY IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if2 for FREE


From jeremyclarkbio at gmail.com  Sun Mar 15 12:04:29 2015
From: jeremyclarkbio at gmail.com (Jeremy Clark)
Date: Sun, 15 Mar 2015 12:04:29 +0100
Subject: [R] R match - could be improved ?
Message-ID: <CACyTWRbhhjv8qyec7c0EHxQkrZTVTBi0yUoJg1QPc15pxBeY5g@mail.gmail.com>

?Dear All,

The following gives a very unpleasant experience with apparently random NAs
- probably it's my bad formatting of the coding - but the effect is
unexpected and if undetected can lead to considerable problems:

myvector1 = NULL

myvector3 = NULL

myvector4 = NULL

myvector5 = NULL



myvector1 <- c(1:100)





myvector3[[1]] <- seq(myvector1[1], myvector1["length"(myvector1)], by =
0.01)

myvector4[[1]] <- seq(95, 100, by = 0.01)



myvector5[[1]] <- match(myvector4[[1]], myvector3[[1]])



myvector5



## A solution (but rather annoying):



myvector5[[1]] <- match(as.list(myvector4[[1]]), as.list(myvector3[[1]]))

myvector5
?
Could anyone tell me why the NAs occur ??

Many thanks.?

	[[alternative HTML version deleted]]


From marek at lutonsky.net  Sun Mar 15 12:46:40 2015
From: marek at lutonsky.net (=?UTF-8?Q?Marek_Lutonsk=C3=BD?=)
Date: Sun, 15 Mar 2015 12:46:40 +0100
Subject: [R]
	=?utf-8?q?Persons_with_objects_=E2=80=93=3E_Objects_and_perso?=
	=?utf-8?q?ns?=
In-Reply-To: <CA+8X3fXn8M9NLyBbGhH9p7UcdLEmEHOUwFXNQB7wp9ytwrHPvw@mail.gmail.com>
References: <1426370575108-4704655.post@n4.nabble.com>
	<CA+8X3fXn8M9NLyBbGhH9p7UcdLEmEHOUwFXNQB7wp9ytwrHPvw@mail.gmail.com>
Message-ID: <CADcmMUZnSABjGSrPracDGTX9yKFkmD9OXJgLrD0ZfhstTBax6A@mail.gmail.com>

Hi Jim,

thank you very much for the code.

Marek


On Sun, Mar 15, 2015 at 11:46 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi mareki,
> The transformation is not too difficult, but the table format in your
> example will cause a bit of difficulty. The following function from the
> plotrix package:
>
> categoryReshape<-function(x) {
>  dimx<-dim(x)
>  if(is.null(dimx) || dimx[2]==1)
>   stop("Can only reshape a matrix or data frame with at least two columns")
>  row_values<-sort(unique(x[,1]))
>  column_values<-sort(unique(x[,2]))
>  newx<-
>
> as.data.frame(matrix(0,nrow=length(row_values),ncol=length(column_values)))
>  for(row in 1:dimx[1]) {
>   row_index<-which(row_values %in% x[row,1])
>   column_index<-which(column_values %in% x[row,2])
>   newx[row_index,column_index]<-1
>  }
>  names(newx)<-column_values
>  rownames(newx)<-row_values
>  return(newx)
> }
>
> will take a matrix or data frame like this:
>
> table1<-read.table(text="object,person
> A,1
> A,2
> A,3
> A,4
> A,5
> B,1
> B,2
> B,3
> C,2
> C,3
> C,5
> D,4
> E,2
> E,3
> E,4
> E,5",sep=",",header=TRUE)
>
> and transform it into a data frame like this:
>
>  categoryReshape(table1)
>   1 2 3 4 5
> A 1 1 1 1 1
> B 1 1 1 0 0
> C 0 1 1 0 1
> D 0 0 0 1 0
> E 0 1 1 1 1
>
> Then if you take each column and format it like this;
>
> concat_labels<-function(x,labels)
> return(paste(labels[as.logical(x)],collapse=";"))
> sapply(table2,concat.labels,rownames(tables))
>
>         1         2         3         4         5
>     "A;B" "A;B;C;E" "A;B;C;E"   "A;D;E"   "A;C;E"
>
> you have pretty much what you want.
>
> Jim
>
>
> On Sun, Mar 15, 2015 at 9:02 AM, marekl <marek.r at lutonsky.net> wrote:
>
>> Hi,
>>
>> I have a table with persons in rows and objects associated to these
>> persons.
>> And I need to transform it to table with objects in rows and persons next
>> to
>> them. As it is shown on the picture.
>>
>> <http://r.789695.n4.nabble.com/file/n4704655/Persons%2C_Objects.png>
>>
>> Can you please help me how to make this transformation in R?
>>
>> Thank you
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Persons-with-objects-Objects-and-persons-tp4704655.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Mar 15 18:18:10 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 15 Mar 2015 10:18:10 -0700
Subject: [R] R match - could be improved ?
In-Reply-To: <CACyTWRbhhjv8qyec7c0EHxQkrZTVTBi0yUoJg1QPc15pxBeY5g@mail.gmail.com>
References: <CACyTWRbhhjv8qyec7c0EHxQkrZTVTBi0yUoJg1QPc15pxBeY5g@mail.gmail.com>
Message-ID: <E9B7A9E8-0F4B-4A03-9482-87B053FA5D3E@dcn.davis.CA.us>

This list is a plain text list. Posting in HTML frequently leads to corrupted code on the receiving end. Be sure to read the Posting Guide.

In no programming language is it a good idea to assume equality with floating point values. See FAQ 7.31. In cases like this use integers to create sequences and then generate floating point from them. Do not go fishing in floating point data for specific values.

Also, you seem to be using list objects for no apparent reason.

myvector1 <- c(1L:100L)

myvector3 <- seq(10L*myvector1[1], 10L*myvector1[ length(myvector1) ])

myvector4 <- seq(950L, 1000L)

myvector5 <- match(myvector4, myvector3)

I think the as.list is working because match is internally converting to character and comparing that... which makes the as.list solution rather inefficient art best.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 15, 2015 4:04:29 AM PDT, Jeremy Clark <jeremyclarkbio at gmail.com> wrote:
>?Dear All,
>
>The following gives a very unpleasant experience with apparently random
>NAs
>- probably it's my bad formatting of the coding - but the effect is
>unexpected and if undetected can lead to considerable problems:
>
>myvector1 = NULL
>
>myvector3 = NULL
>
>myvector4 = NULL
>
>myvector5 = NULL
>
>
>
>myvector1 <- c(1:100)
>
>
>
>
>
>myvector3[[1]] <- seq(myvector1[1], myvector1["length"(myvector1)], by
>=
>0.01)
>
>myvector4[[1]] <- seq(95, 100, by = 0.01)
>
>
>
>myvector5[[1]] <- match(myvector4[[1]], myvector3[[1]])
>
>
>
>myvector5
>
>
>
>## A solution (but rather annoying):
>
>
>
>myvector5[[1]] <- match(as.list(myvector4[[1]]),
>as.list(myvector3[[1]]))
>
>myvector5
>?
>Could anyone tell me why the NAs occur ??
>
>Many thanks.?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From info at aghmed.fsnet.co.uk  Sun Mar 15 18:24:55 2015
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sun, 15 Mar 2015 17:24:55 +0000
Subject: [R] R match - could be improved ?
In-Reply-To: <CACyTWRbhhjv8qyec7c0EHxQkrZTVTBi0yUoJg1QPc15pxBeY5g@mail.gmail.com>
References: <CACyTWRbhhjv8qyec7c0EHxQkrZTVTBi0yUoJg1QPc15pxBeY5g@mail.gmail.com>
Message-ID: <5505C067.8030704@aghmed.fsnet.co.uk>

Dear Jeremy

The NAs do not seem random to me as the gaps between successive NAs are 
either 3, 8 or 11.

Have you considered the possibility that the finite precision of real 
numbers in computers may be the issue here?

On 15/03/2015 11:04, Jeremy Clark wrote:
> ?Dear All,
>
> The following gives a very unpleasant experience with apparently random NAs
> - probably it's my bad formatting of the coding - but the effect is
> unexpected and if undetected can lead to considerable problems:
>
> myvector1 = NULL
>
> myvector3 = NULL
>
> myvector4 = NULL
>
> myvector5 = NULL
>
>
>
> myvector1 <- c(1:100)
>
>
>
>
>
> myvector3[[1]] <- seq(myvector1[1], myvector1["length"(myvector1)], by =
> 0.01)
>
> myvector4[[1]] <- seq(95, 100, by = 0.01)
>
>
>
> myvector5[[1]] <- match(myvector4[[1]], myvector3[[1]])
>
>
>
> myvector5
>
>
>
> ## A solution (but rather annoying):
>
>
>
> myvector5[[1]] <- match(as.list(myvector4[[1]]), as.list(myvector3[[1]]))
>
> myvector5
> ?
> Could anyone tell me why the NAs occur ??
>
> Many thanks.?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5751 / Virus Database: 4306/9307 - Release Date: 03/15/15
>

-- 
Michael
http://www.dewey.myzen.co.uk


From glennmschultz at me.com  Sun Mar 15 20:35:24 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Sun, 15 Mar 2015 19:35:24 +0000 (GMT)
Subject: [R] ggplot2 help
Message-ID: <6e45a249-cfb4-447e-9235-bef2d500e1d6@me.com>

All,?

I am doing something wrong but I don't see what. ?When I plot in ggplot all the lines are on top of one another but the data is not. ?Any help is appreciated.

Thanks,
Glenn?

# -------- I use this function to generate data
Burnout <- function(beta1 = numeric(),?
? ? ? ? ? ? ? ? ? ? ? beta2= numeric(),?
? ? ? ? ? ? ? ? ? ? ? MaxIncen = numeric(),?
? ? ? ? ? ? ? ? ? ? ? LoanAge = numeric()){
? exp(beta1 * LoanAge + ?beta2 * MaxIncen)}

# -------------------- Build the data frame for plotting
? BO.Vector <- data.frame(c(seq(1,360,1)))
? BO.Vector[,2] <- cbind(Burnout(beta1 = -.05, beta2 = 0, MaxIncen = 25, LoanAge = BO.Vector[,1]))
? BO.Vector[,3] <- cbind(Burnout(beta1 = -.04, beta2 = 0, MaxIncen = 25, LoanAge = BO.Vector[,1]))
? BO.Vector[,4] <- cbind(Burnout(beta1 = -.03, beta2 = 0, MaxIncen = 25, LoanAge = BO.Vector[,1]))
? BO.Vector[,5] <- cbind(Burnout(beta1 = -.02, beta2 = 0, MaxIncen = 25, LoanAge = BO.Vector[,1]))
? BO.Vector[,6] <- cbind(Burnout(beta1 = -.01, beta2 = 0, MaxIncen = 25, LoanAge = BO.Vector[,1]))

? colnames(BO.Vector) <- c("LoanAge", "-.05", "-.04", "-.03", "-.02", "-.01")
? colnames(BO.vector) <- c("LoanAge", "-.05", "-.04")

# ------------------- reshape 2 prepare for ggplot2
? BO.Vector <- melt(BO.Vector, id = "LoanAge")


# --------------- plot (not working)
? ggplot(BO.Vector, aes(x= LoanAge, y = value, color = variable, linetype = variable)) +
? geom_line()+
? theme_minimal() +
? labs(colour = "Legend", linetype = "Legend", x = "Loan Age", y = "Burnout") +?
? theme(panel.grid.major = element_line(size = .25, color = "grey")) +
? theme(axis.text = element_text(size = 15)) +
? theme(axis.title = element_text(size = 20)) +
? theme(legend.position = c(.9, .4)) +
? scale_colour_manual(values = cbbPalette)?



From robertsonburns at btinternet.com  Sun Mar 15 18:15:24 2015
From: robertsonburns at btinternet.com (J Robertson-Burns)
Date: Sun, 15 Mar 2015 17:15:24 +0000
Subject: [R] R match - could be improved ?
In-Reply-To: <CACyTWRbhhjv8qyec7c0EHxQkrZTVTBi0yUoJg1QPc15pxBeY5g@mail.gmail.com>
References: <CACyTWRbhhjv8qyec7c0EHxQkrZTVTBi0yUoJg1QPc15pxBeY5g@mail.gmail.com>
Message-ID: <5505BE2C.5030200@btinternet.com>

I believe that you are in Circle 1 of The R Inferno.

http://www.burns-stat.com/documents/books/the-r-inferno/

Pat

On 15/03/2015 11:04, Jeremy Clark wrote:
> ?Dear All,
>
> The following gives a very unpleasant experience with apparently random NAs
> - probably it's my bad formatting of the coding - but the effect is
> unexpected and if undetected can lead to considerable problems:
>
> myvector1 = NULL
>
> myvector3 = NULL
>
> myvector4 = NULL
>
> myvector5 = NULL
>
>
>
> myvector1 <- c(1:100)
>
>
>
>
>
> myvector3[[1]] <- seq(myvector1[1], myvector1["length"(myvector1)], by =
> 0.01)
>
> myvector4[[1]] <- seq(95, 100, by = 0.01)
>
>
>
> myvector5[[1]] <- match(myvector4[[1]], myvector3[[1]])
>
>
>
> myvector5
>
>
>
> ## A solution (but rather annoying):
>
>
>
> myvector5[[1]] <- match(as.list(myvector4[[1]]), as.list(myvector3[[1]]))
>
> myvector5
> ?
> Could anyone tell me why the NAs occur ??
>
> Many thanks.?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From luizepidemiologia at gmail.com  Sun Mar 15 19:02:57 2015
From: luizepidemiologia at gmail.com (Luiz Max Carvalho)
Date: Sun, 15 Mar 2015 18:02:57 +0000
Subject: [R] Prevent line truncation in system2() output
Message-ID: <CAFX+KZmO3WJNYx+Jww2b+ttVqgUEB2MNCTxESNOJZW=kJ=fBTA@mail.gmail.com>

Hey all,

I'm developing an application that calls third party software using
system2(...,  stdout = TRUE) and then reads this using textConnection() +
 read.csv ().

Problem is that sometimes the output is bigger than 8096 bytes and then the
lines are split (from system2 documentation), what messes up what I have
set up to read the output.

Is there any way of preventing system2() from breaking the lines? I think I
can work around this issue, but I'm looking for a cleaner solution for the
time being.

Cheers,

Luiz

-- 
Luiz Max Fagundes de Carvalho
PhD student, Institute of Evolutionary Biology,  School of Biological
Sciences,
Ashworth Laboratories, Ash 2, office 123
University of Edinburgh, United Kingdom.
http://br.linkedin.com/pub/luiz-max-carvalho/49/687/283

	[[alternative HTML version deleted]]


From popx at j-paine.org  Sun Mar 15 21:06:25 2015
From: popx at j-paine.org (Jocelyn Ireson-Paine)
Date: Sun, 15 Mar 2015 20:06:25 +0000 (GMT)
Subject: [R] How to filter data using sets generated by flattening with
 dcast, when I can't store those sets in a data frame
In-Reply-To: <CAHuze_K1FaONNS622WyrWtueiU2LJQXvA+bdvairL6fivG5+xQ@mail.gmail.com>
References: <alpine.LRH.2.02.1503120748540.25235@sphinx.mythic-beasts.com>
	<CAHuze_K1FaONNS622WyrWtueiU2LJQXvA+bdvairL6fivG5+xQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.02.1503151941150.30165@sphinx.mythic-beasts.com>

David, and also William Dunlap, thanks for taking the time to reply, with 
examples. Both your answers are very helpful.

William noted that 'reshape2' is not 'R', but a user-contributed package 
that runs in R. I agree, and I'm not confusing one with the other. But 
what I don't like is that somewhere in the interaction between them, 
generality is lost.

I contrast this with a means of aggregating data that I use when 
programming in Lisp, Prolog, and other "functional" languages. This is 
aggregation by "folding" a list of values. The idea is explained at 
http://wiki.tcl.tk/17983 , "Fold in functional programming" by "juef", 
amongst other places. He/she gives a common example: take a list of 
values, such as
   (1 2 3 4)
and "fold" the + operation over it. Doing so runs + along the list forming 
intermediate sums and adding the next value to them, until all values have 
been summed.

Here, 'fold' is analogous to dcast, with + being analogous to the function 
dcast takes for its fun.aggregate argument. But the good thing about 
'fold' is that it does not restrict the type of result that its 
aggregation function can return. The result can be a number, a string, a 
list, a list of lists, an array, or any other type. I'd like dcast to be 
as general.

Jocelyn Ireson-Paine
07768 534 091
http://www.jocelyns-cartoons.uk
http://www.j-paine.org

On Thu, 12 Mar 2015, David Barron wrote:

> Most of this question is over my head, I'm afraid, but looking at what
> I think is the crux of your question, couldn't you achieve the results
> you want in two steps, like this:
>
> dta <- data.frame(ID=c(1,1,1,1,2,2,3,3,3,3),
> Day=c(1,2,4,7,2,3,1,3,4,8),Pain=c(10,9,7,2,8,7,10,6,6,2))
>
> l1 <- tapply(dta$Day, dta$ID, function(x) x)
>
> sapply(l1, function(x) all(c(1,4,8) %in% x ))
>
> I'm not sure you really need to do it in two steps, but given you said
> you wanted a flattened data frame with the Days as a vector, this will
> give it to you.  Actually, l1 is a list, but you can turn it in to a
> data frame if you really want to.  In the sapply call I changed the
> days required to 1, 4 and 8 to show that it does return TRUE if there
> is a patient that meets the required criterion.
>
> David
>
> On 12 March 2015 at 07:55, Jocelyn Ireson-Paine <popx at j-paine.org> wrote:
>> This is a fairly long question. It's about a problem that's easy to specify
>> in terms of sets, but that I found hard to solve in R by using them, because
>> of the strange design of R data structures. In explaining it, I'm going to
>> touch on the reshape2 library, dcast, sets, and the non-orthogonality of R.
>>
>> My problem stems from some drug-trial data that I've been analysing for the
>> Oxford Pain Research Unit. Here's an example. Imagine a data frame
>> representing patients in a trial of pain-relief drugs. The trial lasts for
>> ten days. Each patient's pain is measured once a day, and the values are
>> recorded in a data frame, one row per patient per day. Like this:
>>
>>   ID  Day  Pain
>>    1    1  10
>>    1    2   9
>>    1    4   7
>>    1    7   2
>>    2    2   8
>>    2    3   7
>>    3    1  10
>>    3    3   6
>>    3    4   6
>>    3    8   2
>>
>> Unfortunately, many patients have measurements missing. Thus, in the example
>> above, patient 1 was only observed on days 1, 2, 4, and 7, rather than on
>> the full ten days. But a patient's measurements are only useful to us if
>> that patient has a certain minimum set of days, so I need to check for
>> patients who lack those days. Let's assume that these days are numbers 1, 4,
>> and 9.
>>
>> Such a question is trivial to state in terms of sets. Let D(i) denote the
>> set of days on which patient i was measured: then I want to find out which
>> patients p, or how many patients p, have a D(p) that contains the set
>> {1,4,9}.
>>
>> The obvious way to solve this is to write a function that tells me whether
>> one set is a superset of another. Then flatten my data frame so that it
>> looks like this:
>>
>>   ID  Days
>>    1  {1,2,4,7}
>>    2  {2,3}
>>    3  {1,3,4,8}
>>
>> And finally, filter it by some R translation of
>>
>>   flattened[ includes( flattened$Days, {1,4,9} ), ]
>>
>> I started with the built-in functions that operate on sets represented as
>> vectors. These are described in
>>  https://stat.ethz.ch/R-manual/R-devel/library/base/html/sets.html ,
>> "Set Operations". For example:
>>
>>  > union( c(1,2,3), c(2,4,6) )
>>   [1] 1 2 3 4 6
>>  > intersect( c(1,2,3), c(2,4,6) )
>>   [1] 2
>>
>> So I first wrote a set-inclusion function:
>>
>>   # True if vector a is a superset of vector b.
>>   #
>>   includes <- function( a, b )
>>   {
>>     return( setequal( union( a, b ), a ) )
>>   }
>>
>> Here are some sample calls:
>>
>>  > includes( c(1), c() )
>>   [1] TRUE
>>  > includes( c(1), c(1) )
>>   [1] TRUE
>>  > includes( c(1), c(1,2) )
>>   [1] FALSE
>>  > includes( c(2,1), c(1,2) )
>>   [1] TRUE
>>  > includes( c(2,1,3), c(1,2) )
>>   [1] TRUE
>>  > includes( c(2,1,3), c(4,1,2) )
>>   [1] FALSE
>>
>> I then made myself a variable holding my sample data frame:
>>
>>   df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
>>                   , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
>>                   )
>>
>> And I tried flattening it, using dcast and an aggregator function as
>> described in (amongst many other places)
>> http://seananderson.ca/2013/10/19/reshape.html , "An Introduction to
>> reshape2" by Sean C. Anderson.
>>
>> The idea behind this is that (for my data) dcast will call the aggregator
>> function once per patient ID, passing it all the Day values for the patient.
>> The aggregator must combine them in some way, and dcast puts its results
>> into a new column. For example, here's an aggregator that merely sums its
>> arguments:
>>
>>   aggregator_making_sum <- function( ... )
>>   {
>>     return( sum( ... ) )
>>   }
>>
>> If I call it, I get this:
>>
>>  >  dcast( df, ID~. , fun.aggregate=aggregator_making_sum )
>>   Using Day as value column: use value.var to override.
>>     ID  .
>>   1  1 14
>>   2  2  5
>>   3  3 16
>>
>> And here's an aggregator that converts the argument list to a string:
>>
>>   aggregator_making_string <- function( ... )
>>   {
>>     return( toString( ... ) )
>>   }
>>
>> Calling it gives this:
>>
>>  >  dcast( df, ID~. , fun.aggregate=aggregator_making_string )
>>   Using Day as value column: use value.var to override.
>>     ID          .
>>   1  1 1, 2, 4, 7
>>   2  2       2, 3
>>   3  3 1, 3, 4, 8
>>
>> In both of these, the three dots denote all arguments to the aggregator, as
>> explained in Burns Statistics's
>> http://www.burns-stat.com/the-three-dots-construct-in-r/ . My first
>> aggregator sums them; my second converts them to a string. Both uses of
>> dcast generate a data frame with a column named "." , which contains the
>> aggregates. In the second data frame, that may not be so clear: the first
>> column of numbers is row numbers; the second column of numbers are the IDs;
>> and the remaining columns form the strings, belonging to "." .
>>
>> But what I want is neither a sum nor a string but a set. Specifically, a set
>> that's compatible with the R set operations I called in my 'includes'
>> function. Since these sets are vectors, my aggregator should just pack its
>> arguments into a vector:
>>
>>   aggregator_making_set <- function( ... )
>>   {
>>     return( c( ... ) )
>>   }
>>
>> But when I tried it, I got an error:
>>
>>  > dcast( df, ID~. , fun.aggregate=aggregator_making_set )
>>   Using Day as value column: use value.var to override.
>>   Error in vapply(indices, fun, .default) : values must be length 0,
>>    but FUN(X[[1]]) result is length 4
>>
>> It's not an informative error message, because it expects me to know how
>> dcast is coded. And I'm surprised that values need to be length 0: length 1
>> would seem more appropriate. But perhaps it's trying to say that 'c' doesn't
>> work on three-dots argument lists. Let's test that hypothesis:
>>
>>   test_c_on_three_dots <- function( ... )
>>   {
>>     return( c( ... ) )
>>   }
>>
>>  >   test_c_on_three_dots( 1 )
>>   [1] 1
>>  >   test_c_on_three_dots( 1, 2 )
>>   [1] 1 2
>>  >   test_c_on_three_dots( 1, 2, 3 )
>>   [1] 1 2 3
>>
>> So 'c' does indeed work on three-dots argument lists. The error must have
>> been caused by something else. Let's try making a set and putting it into a
>> data frame directly:
>>
>>  > df <- data.frame( col1=c(1,2), col2=c(3,4) )
>>  > df
>>     col1 col2
>>   1    1    3
>>   2    2    4
>>  > set <- union( c(5,6), c(6,7) )
>>  > set
>>   [1] 5 6 7
>>  > df[ 1, ]$col1 <- set
>>   Error in `$<-.data.frame`(`*tmp*`, "col1", value = c(5, 6, 7)) :
>>     replacement has 3 rows, data has 1
>>
>> So that's the problem. Already in 1968, there was a language named Algol68
>> which had arrays and, in order to make things easy for its programmers,
>> allowed you to create arrays of every data type the language provided. You
>> could have arrays of Booleans, arrays of integers, arrays of records, arrays
>> of discriminated unions, arrays of procedures, arrays of I/O formats, arrays
>> of pointers, and arrays of arrays. The idea was "orthogonality" (see for
>> example http://stackoverflow.com/questions/1527393/what-is-orthogonality ):
>> that the programmer does not have to think about unexpected interactions
>> between the concept of array and the concept of the element type, because
>> there are none. If you have a data type, you can make arrays of that type.
>> Pop-2 (1970), Snobol4 (1966), and Lisp (1958) were similarly generous. But R
>> (1993) isn't. It wants to make life hard by forcing me to use different
>> kinds of container for different kinds of element. And by providing a nice
>> implementation of sets and then not letting me store them.
>>
>> So I thought about the kinds of data that I _can_ store in a data frame and
>> generate by flattening. Strings! So I decided to use my
>> aggregator_making_string function to make a string representation of the set
>> of days, and to write a set-inclusion function that compared these sets
>> against sets represented as vectors:
>>
>>   includes2 <- function( a_as_string, b )
>>   {
>>     a <- as.numeric( unlist( strsplit( a_as_string, split="," ) ) )
>>     return( setequal( union( a, b ), a ) )
>>   }
>>
>> Here are some example calls:
>>
>>  > includes2( '1,2,3', c(1) )
>>   [1] TRUE
>>  > includes2( '1,2,3', c(1,2) )
>>   [1] TRUE
>>  > includes2( '1,2,3', c(1,2,4) )
>>   [1] FALSE
>>  > includes2( '1,2,3', c(3) )
>>   [1] TRUE
>>  > includes2( '1,2,3', c(0,3) )
>>   [1] FALSE
>>  >
>>
>> I then tried using it:
>>
>>   df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
>>                   , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
>>                   )
>>
>>   aggregator_making_string <- function( ... )
>>   {
>>     return( toString( ... ) )
>>   }
>>
>>   flattened <- dcast( df, ID~. , fun.aggregate=aggregator_making_string )
>>
>>   # Which patients have a day 1?
>>   flattened[ includes2( flattened$. , c(1) ), ]
>>
>> Unfortunately, that didn't work. The final statement selected every row of
>> 'flattened'. I eventually realised that I had to vectorise 'includes2':
>>
>>   includes3 <- Vectorize( includes2, "a_as_string" )
>>
>> And that did work:
>>
>>  >   flattened[ includes3( flattened$. , c(1) ), ]
>>     ID          .
>>   1  1 1, 2, 4, 7
>>   3  3 1, 3, 4, 8
>>  >   flattened[ includes3( flattened$. , c(1,2) ), ]
>>     ID          .
>>   1  1 1, 2, 4, 7
>>  >   flattened[ includes3( flattened$. , c(1,3) ), ]
>>     ID          .
>>   3  3 1, 3, 4, 8
>>  >   flattened[ includes3( flattened$. , c(2) ), ]
>>     ID          .
>>   1  1 1, 2, 4, 7
>>   2  2       2, 3
>>
>> The moral of this email tale is that sets are really useful for filtering
>> data, and dcast ought to be really useful for generating sets, but R refuses
>> to let me store them in the data frame that dcast generates. I can fudge it
>> by representing the sets as strings, but is there a cleaner way to solve the
>> problem?
>>
>> Cheers,
>>
>> Jocelyn Ireson-Paine
>> 07768 534 091
>> http://www.jocelyns-cartoons.uk
>> http://www.j-paine.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Sun Mar 15 21:14:17 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 15 Mar 2015 13:14:17 -0700
Subject: [R] Prevent line truncation in system2() output
In-Reply-To: <CAFX+KZmO3WJNYx+Jww2b+ttVqgUEB2MNCTxESNOJZW=kJ=fBTA@mail.gmail.com>
References: <CAFX+KZmO3WJNYx+Jww2b+ttVqgUEB2MNCTxESNOJZW=kJ=fBTA@mail.gmail.com>
Message-ID: <7F849AF2-AD1C-4B7C-8CFC-8E9075B61544@dcn.davis.CA.us>

You don't say which operating system you are using, but this sounds like it could easily be affected by your OS (even of in this case it isn't). My suggestion would be to use a temporary file.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 15, 2015 11:02:57 AM PDT, Luiz Max Carvalho <luizepidemiologia at gmail.com> wrote:
>Hey all,
>
>I'm developing an application that calls third party software using
>system2(...,  stdout = TRUE) and then reads this using textConnection()
>+
> read.csv ().
>
>Problem is that sometimes the output is bigger than 8096 bytes and then
>the
>lines are split (from system2 documentation), what messes up what I
>have
>set up to read the output.
>
>Is there any way of preventing system2() from breaking the lines? I
>think I
>can work around this issue, but I'm looking for a cleaner solution for
>the
>time being.
>
>Cheers,
>
>Luiz


From thierry.onkelinx at inbo.be  Sun Mar 15 22:41:12 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sun, 15 Mar 2015 22:41:12 +0100
Subject: [R] ggplot2 help
In-Reply-To: <6e45a249-cfb4-447e-9235-bef2d500e1d6@me.com>
References: <6e45a249-cfb4-447e-9235-bef2d500e1d6@me.com>
Message-ID: <CAJuCY5wMk+opSB24rHrS_fgBFvBM1wrcfMAW2c7kqaquOAr_qQ@mail.gmail.com>

I can't reproduce the problem with your code. I just get an error because
cbbPalette is not available. Omitting the scale_colour_manual() form your
code give a sensible plot.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-15 20:35 GMT+01:00 Glenn Schultz <glennmschultz at me.com>:

> All,
>
> I am doing something wrong but I don't see what.  When I plot in ggplot
> all the lines are on top of one another but the data is not.  Any help is
> appreciated.
>
> Thanks,
> Glenn
>
> # -------- I use this function to generate data
> Burnout <- function(beta1 = numeric(),
>                       beta2= numeric(),
>                       MaxIncen = numeric(),
>                       LoanAge = numeric()){
>   exp(beta1 * LoanAge +  beta2 * MaxIncen)}
>
> # -------------------- Build the data frame for plotting
>   BO.Vector <- data.frame(c(seq(1,360,1)))
>   BO.Vector[,2] <- cbind(Burnout(beta1 = -.05, beta2 = 0, MaxIncen = 25,
> LoanAge = BO.Vector[,1]))
>   BO.Vector[,3] <- cbind(Burnout(beta1 = -.04, beta2 = 0, MaxIncen = 25,
> LoanAge = BO.Vector[,1]))
>   BO.Vector[,4] <- cbind(Burnout(beta1 = -.03, beta2 = 0, MaxIncen = 25,
> LoanAge = BO.Vector[,1]))
>   BO.Vector[,5] <- cbind(Burnout(beta1 = -.02, beta2 = 0, MaxIncen = 25,
> LoanAge = BO.Vector[,1]))
>   BO.Vector[,6] <- cbind(Burnout(beta1 = -.01, beta2 = 0, MaxIncen = 25,
> LoanAge = BO.Vector[,1]))
>
>   colnames(BO.Vector) <- c("LoanAge", "-.05", "-.04", "-.03", "-.02",
> "-.01")
>   colnames(BO.vector) <- c("LoanAge", "-.05", "-.04")
>
> # ------------------- reshape 2 prepare for ggplot2
>   BO.Vector <- melt(BO.Vector, id = "LoanAge")
>
>
> # --------------- plot (not working)
>   ggplot(BO.Vector, aes(x= LoanAge, y = value, color = variable, linetype
> = variable)) +
>   geom_line()+
>   theme_minimal() +
>   labs(colour = "Legend", linetype = "Legend", x = "Loan Age", y =
> "Burnout") +
>   theme(panel.grid.major = element_line(size = .25, color = "grey")) +
>   theme(axis.text = element_text(size = 15)) +
>   theme(axis.title = element_text(size = 20)) +
>   theme(legend.position = c(.9, .4)) +
>   scale_colour_manual(values = cbbPalette)
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Sun Mar 15 22:42:21 2015
From: hannah.hlx at gmail.com (li li)
Date: Sun, 15 Mar 2015 17:42:21 -0400
Subject: [R] xlims of box() function
Message-ID: <CAHLnndaeaQ2XJE1y01ogHb8k2jtMq9v-jh=v70gBoA5V9P_Ouw@mail.gmail.com>

Hi all,
  It looks like the limits for x axis for box function in R is from -1 to
1. How can I change this limit?
  Thanks for your help.
     Hanna

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Mar 15 22:54:02 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 15 Mar 2015 14:54:02 -0700
Subject: [R] xlims of box() function
In-Reply-To: <CAHLnndaeaQ2XJE1y01ogHb8k2jtMq9v-jh=v70gBoA5V9P_Ouw@mail.gmail.com>
References: <CAHLnndaeaQ2XJE1y01ogHb8k2jtMq9v-jh=v70gBoA5V9P_Ouw@mail.gmail.com>
Message-ID: <71D71600-BCC7-4819-9DAA-0AD4263997E8@dcn.davis.CA.us>

This is nonsense. Please provide a reproducible example.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 15, 2015 2:42:21 PM PDT, li li <hannah.hlx at gmail.com> wrote:
>Hi all,
>It looks like the limits for x axis for box function in R is from -1 to
>1. How can I change this limit?
>  Thanks for your help.
>     Hanna
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From luizepidemiologia at gmail.com  Sun Mar 15 21:17:15 2015
From: luizepidemiologia at gmail.com (Luiz Max Carvalho)
Date: Sun, 15 Mar 2015 20:17:15 +0000
Subject: [R] Prevent line truncation in system2() output
In-Reply-To: <7F849AF2-AD1C-4B7C-8CFC-8E9075B61544@dcn.davis.CA.us>
References: <CAFX+KZmO3WJNYx+Jww2b+ttVqgUEB2MNCTxESNOJZW=kJ=fBTA@mail.gmail.com>
	<7F849AF2-AD1C-4B7C-8CFC-8E9075B61544@dcn.davis.CA.us>
Message-ID: <CAFX+KZ=kv=Ed7zuU7BBo0Sh3bp4O3HPeAvc3mB1BFNwAHDTKkg@mail.gmail.com>

Sorry for that. It's Ubuntu 14.04.  I would like to avoid a temporary file
altogether, but if there is not other way...

Thanks,

Luiz

On 15 March 2015 at 20:14, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> You don't say which operating system you are using, but this sounds like
> it could easily be affected by your OS (even of in this case it isn't). My
> suggestion would be to use a temporary file.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On March 15, 2015 11:02:57 AM PDT, Luiz Max Carvalho <
> luizepidemiologia at gmail.com> wrote:
> >Hey all,
> >
> >I'm developing an application that calls third party software using
> >system2(...,  stdout = TRUE) and then reads this using textConnection()
> >+
> > read.csv ().
> >
> >Problem is that sometimes the output is bigger than 8096 bytes and then
> >the
> >lines are split (from system2 documentation), what messes up what I
> >have
> >set up to read the output.
> >
> >Is there any way of preventing system2() from breaking the lines? I
> >think I
> >can work around this issue, but I'm looking for a cleaner solution for
> >the
> >time being.
> >
> >Cheers,
> >
> >Luiz
>
>


-- 
Luiz Max Fagundes de Carvalho
PhD student, Institute of Evolutionary Biology,  School of Biological
Sciences,
Ashworth Laboratories, Ash 2, office 123
University of Edinburgh, United Kingdom.
http://br.linkedin.com/pub/luiz-max-carvalho/49/687/283

	[[alternative HTML version deleted]]


From lyle00 at gmail.com  Sun Mar 15 23:50:53 2015
From: lyle00 at gmail.com (Lyle Warren)
Date: Mon, 16 Mar 2015 09:50:53 +1100
Subject: [R] How am i able to create Box plots of a factor (weight)
 separated by other factors (breed)?
In-Reply-To: <CF3DC65386A.00000491jrkrideau@inbox.com>
References: <caa3aksd7maqj+3gc0ceg4exeeba3uhvk9ar7i2sw93nrjfplaw@mail.gmail.com>
	<CF3236F77B8.00000488jrkrideau@inbox.com>
	<CF3DC65386A.00000491jrkrideau@inbox.com>
Message-ID: <CAA3AKSezfAE3DaY42wFVp7iNyx-sENKVZ3=o4A4LTO-dKqGvTA@mail.gmail.com>

Thanks very much everybody - I think i've got it now!


On 15 March 2015 at 23:58, John Kane <jrkrideau at inbox.com> wrote:

> Oops missed the links.  Once more...
> https://github.com/hadley/devtools/wiki/Reproducibility
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> http://xkcd.com/1478/
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: jrkrideau at inbox.com
> > Sent: Sun, 15 Mar 2015 04:53:39 -0800
> > To: lyle00 at gmail.com, r-help at r-project.org
> > Subject: Re: [R] How am i able to create Box plots of a factor (weight)
> > separated by other factors (breed)?
> >
> > As a follow up to Thierry's response.
> >
> > With data as dat1
> >
> > dat1  <-  structure(list(id = 1:12, weight = c(453L, 527L, 520L, 460L,
> > 496L, 461L, 519L, 472L, 531L, 473L, 509L, 503L), breed = c("brahman",
> > "brahman", "brahman", "brahman", "durham", "durham", "durham",
> > "durham", "durham", "durham", "durham", "durham")), .Names = c("id",
> > "weight", "breed"), class = "data.frame", row.names = c(NA, -12L
> > ))
> >
> > library(ggplot2)
> > ggplot(dat1, aes(breed, weight)) +
> >       geom_boxplot()
> > library(ggplot2)
> > ggplot(dat1, aes(breed, weight)) +
> >       geom_boxplot()
> >
> > I would note that it is difficult to break down the data by breed when
> > your sample data only included brahman as a breed.  In the sample data
> > above I changed a few entries to my favourite breed of Durham.
> >
> > Have a look at one (or both) of these links for some useful suggestions
> > on how to ask questions on R-help.  In particular, read about dput.  It
> > is by far the best way to supply sample data for the readers.
> >
> > Good luck
> >
> > John Kane
> > Kingston ON Canada
> >
> >
> >> -----Original Message-----
> >> From: lyle00 at gmail.com
> >> Sent: Sun, 15 Mar 2015 14:50:22 +1100
> >> To: r-help at r-project.org
> >> Subject: [R] How am i able to create Box plots of a factor (weight)
> >> separated by other factors (breed)?
> >>
> >>>
> >>>
> >>> I have data with columns for animal ID, breed, and weight.
> >>>
> >>> I'd like to create a box plot of weight, separated by breed (there are
> >>> 4
> >>> breeds).
> >>>
> >>> Any ideas?
> >>>
> >>> Here's a sample of the data (there are 100 rows):
> >>>
> >>> id      weight  breed
> >>> 1       453     brahman
> >>> 2       527     brahman
> >>> 3       520     brahman
> >>> 4       460     brahman
> >>> 5       496     brahman
> >>> 6       461     brahman
> >>> 7       519     brahman
> >>> 8       472     brahman
> >>> 9       531     brahman
> >>> 10      473     brahman
> >>> 11      509     brahman
> >>> 12      503     brahman
> >>>
> >>> Thanks for your help!
> >>>
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ____________________________________________________________
> > FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Send any screenshot to your friends in seconds...
> Works in all emails, instant messengers, blogs, forums and social networks.
> TRY IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if2 for FREE
>
>
>

	[[alternative HTML version deleted]]


From kp1005 at gmail.com  Mon Mar 16 00:03:22 2015
From: kp1005 at gmail.com (Kruti Pandya)
Date: Sun, 15 Mar 2015 16:03:22 -0700
Subject: [R] wrapper function in R
Message-ID: <CAORW=u6f7NYMSBu05ZgsQqcXV+uB+G2tQWvjnTgnvM2NhgxU9Q@mail.gmail.com>

I want to extract each of the logical expressions of
 generateRandomNKNetwork function and evaluate each expression as follows:

h[[1]]<-function (x) {(!x[3] & x[1]) | (x[3] & !x[1])}



 h[[1]](c(data[,1]))



[1] TRUE



h[[1]](c(data[,2]))



[1] TRUE



I applied a wrapper function to pass the elements of g[[i]] in h[[i]] and
make it a function of x.So that I can evaluate each of the Boolean
expression for each row of my data matrix.

My wrapper function doesn?t work. I do not get an error but when I list
elements of h it is blank. Will appreciate any help.Also, are there any
good resources to learn functional programming in R ?

 install.packages("BoolNet")

library(BoolNet)

n<-generateRandomNKNetwork(3,2,readableFunctions="canonical")


# wrapper function to extract the boolean functions

wrapper <-function(y) {function(x) {(y)}}



# Create random binary matrix

gendata <- function(n,p ) {

  matrix(rbinom(n * p, 1, 0.5), ncol = p, nrow = n)

}



data<-gendata(5,3)





#function to extract logical expressions

f=list()

g=list()

h=list()

for (i in 1:3){

  f[[i]]<-noquote(n$interactions[[paste0("Gene",i)]]$expression)

  g[[i]]<-gsub("(Gene)([[:digit:]])", "x[\\2]", f[[i]])

  h[[i]]<-wrapper(g[[i]]) #apply wrapper function



#evaluate h at each row of data

   #for(i in 1:nrow(data)) {

  #h[[i]](c(data[i,])

  #}

}





> h

[[1]]

function (x)

{

    (y)

}

<environment: 0x00000000283fa8c0>



[[2]]

function (x)

{

    (y)

}

<environment: 0x00000000283ec018>



[[3]]

function (x)

{

    (y)

}

<environment: 0x00000000283e4b38>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Mar 16 00:06:55 2015
From: jholtman at gmail.com (jim holtman)
Date: Sun, 15 Mar 2015 19:06:55 -0400
Subject: [R] [datatable-help] R beginner
In-Reply-To: <CALbKBAm=Wv2fSRx0sukYjaw8vMeyK3ybMkrwarzZ+ph+4fm+mw@mail.gmail.com>
References: <1426448493840-4704684.post@n4.nabble.com>
	<CAAxdm-5oNRg4UFzxRapZFk_NAwtvbcR=C8WKobzLA9f9EmjFQg@mail.gmail.com>
	<CALbKBAm=Wv2fSRx0sukYjaw8vMeyK3ybMkrwarzZ+ph+4fm+mw@mail.gmail.com>
Message-ID: <CAAxdm-6=0st5QVgpdf8BvgiysM0jFqefm9QkC8yBkqVXHuu7yw@mail.gmail.com>

Here is how I processed the files you sent.  I used XLConnect to access
EXCEL.

> require(XLConnect)
> # I happen to use XLConnect for accessing EXCEL
> miRNA <- readWorksheetFromFile("/temp/miRNA.xls", 1)  # read in the
spreadsheets
> genes <- readWorksheetFromFile("/temp/gene.xls", 1)
> str(miRNA)  # see what the structures are so I know the names
'data.frame':   8 obs. of  2 variables:
 $ MiRNA.name    : chr  "mir256" "mir785" "mir415" "mir1245" ...
 $ position.start: num  458965 896 9689877 11525478 11689689 ...
> str(genes)
'data.frame':   10 obs. of  4 variables:
 $ gene.name    : chr  "AA" "AB" "AC" "AD" ...
 $ chromosome   : num  1 1 2 4 8 9 8 11 12 13
 $ positon.Start: num  251 4256 245226 449623 8214587 ...
 $ position.end : num  2586 8922 247899 490256 8358964 ...
>
> require(sqldf)
> # the use of backquotes (`) is because the names include a period (.)
that is special to SQL
> matches <- sqldf("
+     select m.*, g.*
+     from miRNA as m
+     join genes as g
+         on m.`position.start` between g.`positon.Start` and
g.`position.end`
+ ")
>
> matches
  MiRNA.name position.start gene.name chromosome positon.Start position.end
1     mir256         458965        AD          4        449623       490256
2     mir785            896        AA          1           251         2586
3     mir415        9689877        AF          9       9545878      9896698
4    mir1245       11525478        AH         11      11458789     11895251
5      mir96       11689689        AH         11      11458789     11895251
6     mir145           5890        AB          1          4256         8922
7     mir785       12247847        AI         12      12047896     12365478
8     mir895         246789        AC          2        245226       247899
>



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Mar 15, 2015 at 6:29 PM, cyrille sage <
cyrille.laurent.sage at gmail.com> wrote:

> HI Jim
>
> thanks a lot for your answer
>
> I have some question
>
> I attached two excel files name gene and miRNA as an example of what kind
> of data I will have to deal with. this two files are just example.
>
> I was thinking that I will have first to load the file ine R using
>
> Library(gdata)
> gene<-read.xls("path:/gene.xls")
> mir<-read.xls("path:/miRNA.xls")
>
> so now I have two list (gene and miRNA) in R
>
> but I do not know how to call specifically the column (3 and 4) in the
> gene file and the column 2 for the MiRNA list for the comparison and to do
> the comparison according to the number of miRNA in my list.
>
> for example can I do this
>
> start<-sample(gene[3, ],length (gene [3]))
>
> I told you i am a biginner
>
> Papy
>
> On Sun, Mar 15, 2015 at 5:16 PM, jim holtman <jholtman at gmail.com> wrote:
>
>> You didn't provide any test data, so I made some up with the sizes you
>> gave.  This uses the 'sqldf' package and took about 2 minutes to come up
>> with the matches.
>>
>> > n <- 200000
>> > mi <- 4500
>> > start <- sample(n * 10, n)  # start times
>> > int <- sample(1000, n, TRUE)  # interval between start and end
>> > genes <- data.frame(gene = paste0('gene', 1:n)
>> +                 , start = start
>> +                 , end = start + int
>> +                 , stringsAsFactors = FALSE
>> +                 )
>> > miRNA <- data.frame(name = paste0('mi', 1:mi)
>> +                 , pos = sample(n * 9, mi)
>> +                 , stringsAsFactors = FALSE
>> +                 )
>> > require(sqldf)
>> Loading required package: sqldf
>> Loading required package: gsubfn
>> Loading required package: proto
>> Loading required package: RSQLite
>> Loading required package: DBI
>> > matches <- sqldf("
>> +     select m.*, g.*
>> +     from miRNA as m
>> +     join genes as g
>> +         on m.pos between g.start and g.end
>> + ")
>> Loading required package: tcltk
>> >
>> > str(matches)
>> 'data.frame':   225045 obs. of  5 variables:
>>  $ name : chr  "mi1" "mi1" "mi1" "mi1" ...
>>  $ pos  : int  279341 279341 279341 279341 279341 279341 279341 279341
>> 279341 279341 ...
>>  $ gene : chr  "gene3133" "gene14326" "gene14997" "gene17652" ...
>>  $ start: int  279000 278623 279157 279296 278379 279055 279180 279273
>> 278938 278960 ...
>>  $ end  : int  279924 279444 280150 279930 279347 279861 279782 280268
>> 279791 279796 ...
>> > head(matches)
>>   name    pos      gene  start    end
>> 1  mi1 279341  gene3133 279000 279924
>> 2  mi1 279341 gene14326 278623 279444
>> 3  mi1 279341 gene14997 279157 280150
>> 4  mi1 279341 gene17652 279296 279930
>> 5  mi1 279341 gene21208 278379 279347
>> 6  mi1 279341 gene30889 279055 279861
>>
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Sun, Mar 15, 2015 at 3:41 PM, Papysounours <
>> Cyrille.laurent.sage at gmail.com> wrote:
>>
>>> Hi
>>>
>>> I am just starting R programming because i need it to analyse new
>>> sequencing
>>> data. I got two list of data (excel table) one is gene list with
>>> chromosomal
>>> position (like start:123456 end:124567), the other is miRNA list with
>>> only
>>> one position (like 123789).
>>>  In the first liste i have around 20000 row (meaning 20000 gene name to
>>> compare to) and for the second around 4500 row (4500 miRNA).
>>> I want to compare the position of each individual miRNA position (
>>> genestart<=miRNA<=geneend ) to the entire list of gene in order to get
>>> in a
>>> new table the name of the miRNA (first colum of the miRNA list) and the
>>> name
>>> of the gene  (first colum of the gene list) related to the miRNA.
>>> Hope thisis not to much to ask.
>>> Papy
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>> http://r.789695.n4.nabble.com/R-beginner-tp4704684.html
>>> Sent from the datatable-help mailing list archive at Nabble.com.
>>> _______________________________________________
>>> datatable-help mailing list
>>> datatable-help at lists.r-forge.r-project.org
>>>
>>> https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/datatable-help
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From pnsinha68 at gmail.com  Mon Mar 16 05:03:07 2015
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Mon, 16 Mar 2015 09:33:07 +0530
Subject: [R] Plotting straight line
Message-ID: <CADcgpJeKEVraDfWRcaYHh2utXij9+Cq4vaAfMv771kfh8e1xGw@mail.gmail.com>

I want to plot a straight line where y=m*x+1 (where x varying from -5
to +5) and and m will change from 0.5 to 5. All the straight lines
needs to be overlaid.
Thanks
Parth


From jdnewmil at dcn.davis.CA.us  Mon Mar 16 05:43:20 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 15 Mar 2015 21:43:20 -0700
Subject: [R] Plotting straight line
In-Reply-To: <CADcgpJeKEVraDfWRcaYHh2utXij9+Cq4vaAfMv771kfh8e1xGw@mail.gmail.com>
References: <CADcgpJeKEVraDfWRcaYHh2utXij9+Cq4vaAfMv771kfh8e1xGw@mail.gmail.com>
Message-ID: <6B1EC1D7-B44D-4A9D-B5B5-532A5EA02D10@dcn.davis.CA.us>

That you want to do this is fascinating. Since you are so intent on doing this I am sure you have already Googled "R plot several lines" and used the examples you found to help make your plots by now. Do keep in mind that there are three common but distinctly different graphing systems available in R: base graphics, lattice graphics, and the ggplot2 package. The first two come with the base software, while the third requires a package from CRAN. Each has advantages and disadvantages, so do try out each while you are at it.

What you don't appear to have done is read the Posting Guide or the footer in any message on this list. This list is not here to to your work/homework for you, and a reproducible example illustrating just where you are having difficulty will let us help you get out of a bind much more effectively than just doing your work for you from scratch.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 15, 2015 9:03:07 PM PDT, Partha Sinha <pnsinha68 at gmail.com> wrote:
>I want to plot a straight line where y=m*x+1 (where x varying from -5
>to +5) and and m will change from 0.5 to 5. All the straight lines
>needs to be overlaid.
>Thanks
>Parth
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Mar 16 09:19:10 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 16 Mar 2015 19:19:10 +1100
Subject: [R] ggplot2 help
In-Reply-To: <CAJuCY5wMk+opSB24rHrS_fgBFvBM1wrcfMAW2c7kqaquOAr_qQ@mail.gmail.com>
References: <6e45a249-cfb4-447e-9235-bef2d500e1d6@me.com>
	<CAJuCY5wMk+opSB24rHrS_fgBFvBM1wrcfMAW2c7kqaquOAr_qQ@mail.gmail.com>
Message-ID: <CA+8X3fUs7RQ=jWzPbi30X3RF9mcRGhpscu5T1qhJF0m05aNWwA@mail.gmail.com>

Hi Glenn,
I think it may be your column names. When I substitute the following for
the last three sections of your example, I get a plot that looks correct.
Obviously I have just made up the colors.

colnames(BO.Vector) <- c("LoanAge", "minus05", "minus04", "minus03",
"minus02", "minus01")
plot(BO.Vector$LoanAge,BO.Vector$minus05,type="l",col=5)
lines(BO.Vector$LoanAge,BO.Vector$minus04,col=4)
lines(BO.Vector$LoanAge,BO.Vector$minus03,col=3)
lines(BO.Vector$LoanAge,BO.Vector$minus02,col=2)
lines(BO.Vector$LoanAge,BO.Vector$minus01,col=1)

Jim


On Mon, Mar 16, 2015 at 8:41 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> I can't reproduce the problem with your code. I just get an error because
> cbbPalette is not available. Omitting the scale_colour_manual() form your
> code give a sensible plot.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-03-15 20:35 GMT+01:00 Glenn Schultz <glennmschultz at me.com>:
>
> > All,
> >
> > I am doing something wrong but I don't see what.  When I plot in ggplot
> > all the lines are on top of one another but the data is not.  Any help is
> > appreciated.
> >
> > Thanks,
> > Glenn
> >
> > # -------- I use this function to generate data
> > Burnout <- function(beta1 = numeric(),
> >                       beta2= numeric(),
> >                       MaxIncen = numeric(),
> >                       LoanAge = numeric()){
> >   exp(beta1 * LoanAge +  beta2 * MaxIncen)}
> >
> > # -------------------- Build the data frame for plotting
> >   BO.Vector <- data.frame(c(seq(1,360,1)))
> >   BO.Vector[,2] <- cbind(Burnout(beta1 = -.05, beta2 = 0, MaxIncen = 25,
> > LoanAge = BO.Vector[,1]))
> >   BO.Vector[,3] <- cbind(Burnout(beta1 = -.04, beta2 = 0, MaxIncen = 25,
> > LoanAge = BO.Vector[,1]))
> >   BO.Vector[,4] <- cbind(Burnout(beta1 = -.03, beta2 = 0, MaxIncen = 25,
> > LoanAge = BO.Vector[,1]))
> >   BO.Vector[,5] <- cbind(Burnout(beta1 = -.02, beta2 = 0, MaxIncen = 25,
> > LoanAge = BO.Vector[,1]))
> >   BO.Vector[,6] <- cbind(Burnout(beta1 = -.01, beta2 = 0, MaxIncen = 25,
> > LoanAge = BO.Vector[,1]))
> >
> >   colnames(BO.Vector) <- c("LoanAge", "-.05", "-.04", "-.03", "-.02",
> > "-.01")
> >   colnames(BO.vector) <- c("LoanAge", "-.05", "-.04")
> >
> > # ------------------- reshape 2 prepare for ggplot2
> >   BO.Vector <- melt(BO.Vector, id = "LoanAge")
> >
> >
> > # --------------- plot (not working)
> >   ggplot(BO.Vector, aes(x= LoanAge, y = value, color = variable, linetype
> > = variable)) +
> >   geom_line()+
> >   theme_minimal() +
> >   labs(colour = "Legend", linetype = "Legend", x = "Loan Age", y =
> > "Burnout") +
> >   theme(panel.grid.major = element_line(size = .25, color = "grey")) +
> >   theme(axis.text = element_text(size = 15)) +
> >   theme(axis.title = element_text(size = 20)) +
> >   theme(legend.position = c(.9, .4)) +
> >   scale_colour_manual(values = cbbPalette)
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sri4mailing at gmail.com  Mon Mar 16 11:38:47 2015
From: sri4mailing at gmail.com (Srikanth Gumma)
Date: Mon, 16 Mar 2015 10:38:47 +0000
Subject: [R] Unsupported Fortran 90 compiler or Fortran 90
Message-ID: <CACSaa1VXnUiQgwT4duA8RwNW+ZgsS68WPSupV=T7P_HWJ8=itg@mail.gmail.com>

Hi,

I'm trying to install diveRsity package in our R installation. however it
always fails with the error message "Unsupported Fortran 90 compiler or
Fortran 90". Below is the full output. Appreciate any help.

R

R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> install.packages("diversity")
--- Please select a CRAN mirror for use in this session ---
Warning messages:
1: package ?diversity? is not available (for R version 3.1.2)
2: Perhaps you meant ?diveRsity? ?
> install.packages("diveRsity")
also installing the dependencies ?glasso?, ?qgraph?

trying URL 'http://cran.rstudio.com/src/contrib/glasso_1.8.tar.gz'
Content type 'application/x-gzip' length 41768 bytes (40 Kb)
opened URL
==================================================
downloaded 40 Kb

trying URL 'http://cran.rstudio.com/src/contrib/qgraph_1.3.1.tar.gz'
Content type 'application/x-gzip' length 211062 bytes (206 Kb)
opened URL
==================================================
downloaded 206 Kb

trying URL 'http://cran.rstudio.com/src/contrib/diveRsity_1.9.73.tar.gz'
Content type 'application/x-gzip' length 1330144 bytes (1.3 Mb)
opened URL
==================================================
downloaded 1.3 Mb

* installing *source* package ?glasso? ...
** package ?glasso? successfully unpacked and MD5 sums checked
 This package requires a fortran 90 compiler. We assume
 that your fortran 90 environment is set up appropriately.
 Reference: Section on 'Using F95 code' in R-exts manual.
 R_HOME is /app1/centos6.3/gnu/apps/R-3.1.2/lib64/R
    Unsupported Fortran 90 compiler or Fortran 90
    compilers unavailable! Stop!
ERROR: configuration failed for package ?glasso?
* removing ?/nfs/app1/centos6.3/gnu/apps/R-3.1.2/lib64/R/library/glasso?
ERROR: dependency ?glasso? is not available for package ?qgraph?
* removing ?/nfs/app1/centos6.3/gnu/apps/R-3.1.2/lib64/R/library/qgraph?
ERROR: dependency ?qgraph? is not available for package ?diveRsity?
* removing ?/nfs/app1/centos6.3/gnu/apps/R-3.1.2/lib64/R/library/diveRsity?

The downloaded source packages are in
        ?/tmp/Rtmp2IAilr/downloaded_packages?
Warning messages:
1: In install.packages("diveRsity") :
  installation of package ?glasso? had non-zero exit status
2: In install.packages("diveRsity") :
  installation of package ?qgraph? had non-zero exit status
3: In install.packages("diveRsity") :
  installation of package ?diveRsity? had non-zero exit status

Regards
Srikanth.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Mar 16 12:17:47 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 16 Mar 2015 11:17:47 +0000
Subject: [R] measure of goodness of fit for the model without
	an	intercept
In-Reply-To: <CABpbYae4Hygu38sy0dthwYWgG4=MpZfTx0xRfyZgoi6+acK2TQ@mail.gmail.com>
References: <D0F02159.961A%yanwu1205@gmail.com>
	<CABpbYae4Hygu38sy0dthwYWgG4=MpZfTx0xRfyZgoi6+acK2TQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C24106@SRVEXCHMBX.precheza.cz>

Hi

see Faq 7.41 Why does summary() report strange results for the R^2 estimate when I fit a linear model with no intercept?

And some explanation in

http://stackoverflow.com/questions/20333600/why-does-summary-overestimate-the-r-squared-with-a-no-intercept-model-formula

I found somewhere https://online.stat.psu.edu/~ajw13/stat501/SpecialTopics/Reg_thru_origin.pdf that you can use correlation between observed and predicted values.

Quote:
Given these inconsistencies, Hocking (1996, p. 178)
notes: ?It is natural to ask if there is a measure
analogous to R2 for the no-intercept model. We
suggest the square of the sample correlation
between observed and predicted values?.

But I am not an expert in this matter.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> kamaraju kusumanchi
> Sent: Sunday, March 15, 2015 12:09 AM
> To: Yan Wu
> Cc: r-help at r-project.org
> Subject: Re: [R] measure of goodness of fit for the model without an
> intercept
>
> On Thu, Jan 29, 2015 at 6:41 PM, Yan Wu <yanwu1205 at gmail.com> wrote:
> > Hi,
> >
> > When I fit the regression model without an intercept term, R-squared
> > tends to much larger than the R-squared in the model with an
> > intercept. So in this case, what?s a more reasonable measure of the
> > goodness of fit for the model without an intercept?
> >
> > Thanks a lot!!
> >
> > Yan
> >
>
> I am going through the list archives and found your question. I guess
> it is unanswered because it is not directly related to R language per
> se but is more to do with time series analysis in general.
>
> In general, R square tells you only part of the story. You need to look
> at the t-stats of the regression coefficients to understand whether the
> betas from the regression are statistically significant.
>
> Further, IIRC R square always increases as more variables are added to
> the regression. That is why practitioners look at "adjusted r-square"
> instead of "r square" which account for this. So I am curious as to why
> your data produces less r square when you add the constant. Is it
> possible to upload your data somewhere so pther can take a look at it?
>
> thanks
> --
> Kamaraju S Kusumanchi | http://raju.shoutwiki.com/wiki/Blog
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ripley at stats.ox.ac.uk  Mon Mar 16 12:21:19 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 16 Mar 2015 11:21:19 +0000
Subject: [R] Unsupported Fortran 90 compiler or Fortran 90
In-Reply-To: <CACSaa1VXnUiQgwT4duA8RwNW+ZgsS68WPSupV=T7P_HWJ8=itg@mail.gmail.com>
References: <CACSaa1VXnUiQgwT4duA8RwNW+ZgsS68WPSupV=T7P_HWJ8=itg@mail.gmail.com>
Message-ID: <5506BCAF.2010309@stats.ox.ac.uk>

On 16/03/2015 10:38, Srikanth Gumma wrote:
> Hi,
>
> I'm trying to install diveRsity package in our R installation. however it
> always fails with the error message "Unsupported Fortran 90 compiler or
> Fortran 90". Below is the full output. Appreciate any help.

Ask the maintainer of the package concerned (glasso).  Its way of 
detecting the complier is flaky (and does not meet current CRAN 
requirements on cross-platform portability).

>
> R
>
> R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
> Copyright (C) 2014 The R Foundation for Statistical Computing
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>    Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
>> install.packages("diversity")
> --- Please select a CRAN mirror for use in this session ---
> Warning messages:
> 1: package ?diversity? is not available (for R version 3.1.2)
> 2: Perhaps you meant ?diveRsity? ?
>> install.packages("diveRsity")
> also installing the dependencies ?glasso?, ?qgraph?
>
> trying URL 'http://cran.rstudio.com/src/contrib/glasso_1.8.tar.gz'
> Content type 'application/x-gzip' length 41768 bytes (40 Kb)
> opened URL
> ==================================================
> downloaded 40 Kb
>
> trying URL 'http://cran.rstudio.com/src/contrib/qgraph_1.3.1.tar.gz'
> Content type 'application/x-gzip' length 211062 bytes (206 Kb)
> opened URL
> ==================================================
> downloaded 206 Kb
>
> trying URL 'http://cran.rstudio.com/src/contrib/diveRsity_1.9.73.tar.gz'
> Content type 'application/x-gzip' length 1330144 bytes (1.3 Mb)
> opened URL
> ==================================================
> downloaded 1.3 Mb
>
> * installing *source* package ?glasso? ...
> ** package ?glasso? successfully unpacked and MD5 sums checked
>   This package requires a fortran 90 compiler. We assume
>   that your fortran 90 environment is set up appropriately.
>   Reference: Section on 'Using F95 code' in R-exts manual.
>   R_HOME is /app1/centos6.3/gnu/apps/R-3.1.2/lib64/R
>      Unsupported Fortran 90 compiler or Fortran 90
>      compilers unavailable! Stop!
> ERROR: configuration failed for package ?glasso?
> * removing ?/nfs/app1/centos6.3/gnu/apps/R-3.1.2/lib64/R/library/glasso?
> ERROR: dependency ?glasso? is not available for package ?qgraph?
> * removing ?/nfs/app1/centos6.3/gnu/apps/R-3.1.2/lib64/R/library/qgraph?
> ERROR: dependency ?qgraph? is not available for package ?diveRsity?
> * removing ?/nfs/app1/centos6.3/gnu/apps/R-3.1.2/lib64/R/library/diveRsity?
>
> The downloaded source packages are in
>          ?/tmp/Rtmp2IAilr/downloaded_packages?
> Warning messages:
> 1: In install.packages("diveRsity") :
>    installation of package ?glasso? had non-zero exit status
> 2: In install.packages("diveRsity") :
>    installation of package ?qgraph? had non-zero exit status
> 3: In install.packages("diveRsity") :
>    installation of package ?diveRsity? had non-zero exit status
>
> Regards
> Srikanth.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From Brian.Middleton at astrazeneca.com  Mon Mar 16 11:10:02 2015
From: Brian.Middleton at astrazeneca.com (Middleton, Brian J)
Date: Mon, 16 Mar 2015 10:10:02 +0000
Subject: [R] lme random interactions
Message-ID: <DB5PR04MB1064D2FAC085F235A64069DBF6020@DB5PR04MB1064.eurprd04.prod.outlook.com>

I have a method comparison problem, comparing Labs where a set of compounds are assayed on 3 different dates for each lab. Both labs will be used to assess compounds in the future, so the scientists will potentially contrast a compound at assayed at Lab A with one assayed at Lab B, This implies I ought to regard the Lab*Compound interaction as random. I also have the date within Lab as a random term and the Compound*date as random (and as separate variances for each Lab).

If I regard the Compound*Lab effect as fixed this code works

lme.out <- lme ( data=data, Resp ~ Lab + Compound + Compound:Lab,
   random = pdIdent(~Lab-1|Date)  ,
    weights = varIdent(form=~1|Lab)
)

The trouble is when I try to regard it as random, eg.

lme2.out <- lme ( data=data, Resp ~ Lab + Compound,
   random = list( ~Compound:Lab,  pdIdent(~Lab-1|Date)  ),
    weights = varIdent(form=~1|Lab)
  )

It appears as if the random interaction is not allowed ... Is this right ? Is there a way to fit the interaction as random together with the other random terms ?

I have tried lme4 but note that "lme4 does not currently implement nlme's features for modeling heteroscedasticity" but "does implement crossed random effects". No joy in my hands though. Nor with lmer ...

Any help gratefully received, thanks,

Brian (trying to convert from SAS !)



________________________________

AstraZeneca UK Limited is a company incorporated in Engl...{{dropped:26}}


From maechler at lynne.stat.math.ethz.ch  Mon Mar 16 16:15:39 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Mon, 16 Mar 2015 16:15:39 +0100
Subject: [R] Course and book announcements on r-help
In-Reply-To: <550469B6.7060004@prodsyse.com>
References: <077E31A57DA26E46AB0D493C9966AC730F0699E4FD@UM-MAIL4112.unimaas.nl>
	<B6C5B117C2B.000012C7jrkrideau@inbox.com>
	<21764.26534.716141.911224@stat.math.ethz.ch>
	<550469B6.7060004@prodsyse.com>
Message-ID: <21766.62363.562009.313199@stat.math.ethz.ch>

>>>>> Spencer Graves <spencer.graves at prodsyse.com>
>>>>>     on Sat, 14 Mar 2015 10:02:46 -0700 writes:

    >        While answering a question, I believe it's
    > acceptable (even encouraged) to cite a relevant book, even
    > if it's yours ;-)

    >        Spencer

Definitely, Spencer.  
I was talking about explicit announcements.

Martin

    > On 3/14/2015 9:53 AM, Martin Maechler wrote:
    >>>>>>> John Kane <jrkrideau at inbox.com> on Fri, 13 Mar 2015
    >>>>>>> 06:16:19 -0800 writes:
    >> > I have the feeling that this was discussed 3-4 years
    >> ago > and the overall opinion seems to be that if the
    >> course or > book was relevant then it was acceptable on
    >> an occasional > basis. No spamming-type or mass selling
    >> posts were.  > John Kane Kingston ON Canada
    >> 
    >> Your feeling is pretty good.  At the time -- and still
    >> today -- we did not want to impose rigid rules about
    >> this.  As host and principal maintainer of the
    >> R-*@r-project.org mailing list, my current view is as
    >> follows:
    >> 
    >> * Books:
    >> 
    >> Should typically *not* be announced on R-help for the
    >> following reasons.
    >> 
    >> a) The R web page lists books which deal with R as a
    >> major theme.  (http://www.r-project.org/ sidebar
    >> 'Documentation' -> 'Books' ==>
    >> http://www.r-project.org/doc/bib/R-books.html). All R
    >> Core and some other R Foundation members can edit the
    >> underlying *.bib source file in R-docs; historically 95%
    >> of that work has been done by Kurt Hornik and Fritz
    >> Leisch.  b) Books just using R to solve a certain problem
    >> abound nowadays and should defintely *not* be announced
    >> as globally as by using R-help.
    >> 
    >> * Course announcements:
    >> 
    >> You may announce a course "series" once if it's new *and*
    >> globally accessible online.  All other courses should be
    >> announced in local R user groups, or similar forums.
    >> 
    >> -- -- -- -- -- -- -- -- -- -- -- --
    >> 
    >> And because it's the weekend:
    >> 
    >> Motto:
    >> 
    >> We humans live much better with guidelines by responsibly
    >> applying good judgement.  It's only the (digital)
    >> machines that need strict unambigous rules.  Let the AI
    >> programmers deal with them and remain human ourselves!
    >> 
    >> (inspired by Haim Harari's thoughts in
    >> http://edge.org/response-detail/26056)
    >> 
    >> 
    >> Best regards, Martin Maechler, ETH Zurich and R Core
    >> 
    >> 
    >> >> -----Original Message----- From: >>
    >> wolfgang.viechtbauer at maastrichtuniversity.nl Sent: Fri,
    >> >> 13 Mar 2015 10:26:04 +0100 To: r-help at r-project.org >>
    >> Subject: [R] Course and book announcements on r-help
    >> >>
    >> >> Dear All,
    >> >>
    >> >> Just wondering: Is there any official policy on >>
    >> announcing R-related courses and books on r-help?
    >> >>
    >> >> I didn't find anything on this in the posting guide,
    >> but >> http://www.r-project.org/mail.html#instructions
    >> says that >> r-help is, among other things, for
    >> "announcements (not >> covered by 'R-announce' or
    >> 'R-packages', see >> above)". That sounds a bit like this
    >> would cover courses >> and books, but I am not
    >> sure. Obviously, R-announce is >> not meant for that, as
    >> it is "for major announcements >> about the development
    >> of R and the availability of new >> code" and is to be
    >> used "for announcements mainly by the >> R Core
    >> Development Team".
    >> >>
    >> >> I see the occasional course/book announcement, but it
    >> >> seems to me that there are a lot more courses and
    >> books >> out there compared to how many announcements
    >> there are >> related to them on this mailing list. So, I
    >> am wondering >> if such announcements are somewhat
    >> implicitly >> discouraged.
    >> >>
    >> >> Best, Wolfgang
    >> >>
    >> >> --
    >> >> Wolfgang Viechtbauer, Ph.D., Statistician Department
    >> of >> Psychiatry and Psychology School for Mental Health
    >> and >> Neuroscience Faculty of Health, Medicine, and Life
    >> >> Sciences Maastricht University, P.O. Box 616 (VIJV1)
    >> 6200 >> MD Maastricht, The Netherlands +31 (43) 388-4170
    >> | >> http://www.wvbauer.com
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.
    >> 
    >> 

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Mar 16 16:43:59 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 16 Mar 2015 15:43:59 +0000
Subject: [R] textplot() in wordcloud package
In-Reply-To: <2176AD174D58CB4ABBDA99F3458C2017208099CB@GRANGER.monticello.org>
References: <2176AD174D58CB4ABBDA99F3458C2017208099CB@GRANGER.monticello.org>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D675A69@mb02.ads.tamu.edu>

You should contact the package maintainer about this. The problem is that the pos= argument is being passed to strwidth() and strheight() and those functions do not know what to do with it. In the meantime:

suppressWarnings(textplot(x,y, text1, new=F, show.lines=F,  
          pos=4))

will eliminate the warnings.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fraser D. Neiman
Sent: Friday, March 13, 2015 3:29 PM
To: r-help at r-project.org
Subject: [R] textplot() in wordcloud package

Dear All,

The textplot() function in the wordcloud package seem to do a good job with generating non-overlapping labels on a scatter plot.
But it throws "warnings" when I try to use the pos= parameter to position the text labels relative to a given x-y point.

Here is a simple example:

 x<-runif(100)
 y<-runif(100)
text1<- rep('LAB', 100)

 plot(x,y)
 textplot(x,y, text1, new=F, show.lines=F,  
          pos=4)

There were 50 or more warnings (use warnings() to see the first 50)
> warnings()
Warning messages:
1: In strwidth(words[i], cex = cex[i], ...) : "pos" is not a graphical parameter
2: In strheight(words[i], cex = cex[i], ...) : "pos" is not a graphical parameter 

How can I pass the pos=parameter to text() without generating the warnings?

I am doubly puzzled by the warnings because in the graph that results from the foregoing code,
The labels are to the  right of the points, as 'pos=4' requests.

Thanks!

Fraser D. Neiman

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Mar 16 17:01:32 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 16 Mar 2015 16:01:32 +0000
Subject: [R] textplot() in wordcloud package
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D675A69@mb02.ads.tamu.edu>
References: <2176AD174D58CB4ABBDA99F3458C2017208099CB@GRANGER.monticello.org>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D675A69@mb02.ads.tamu.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D675A7F@mb02.ads.tamu.edu>

Another possibility is to use pointLabel() in package maptools. For your example

library(maptools)

plot(x,y)
pointLabel(x, y, text1)

Advantages of pointLabel() are that it returns a list of the x and y coordinates of the labels that you can tweak if necessary and, at least in your example, it does a better job of avoiding labels being chopped at the plot margins.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Monday, March 16, 2015 10:44 AM
To: Fraser D. Neiman; r-help at r-project.org
Subject: Re: [R] textplot() in wordcloud package

You should contact the package maintainer about this. The problem is that the pos= argument is being passed to strwidth() and strheight() and those functions do not know what to do with it. In the meantime:

suppressWarnings(textplot(x,y, text1, new=F, show.lines=F,  
          pos=4))

will eliminate the warnings.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fraser D. Neiman
Sent: Friday, March 13, 2015 3:29 PM
To: r-help at r-project.org
Subject: [R] textplot() in wordcloud package

Dear All,

The textplot() function in the wordcloud package seem to do a good job with generating non-overlapping labels on a scatter plot.
But it throws "warnings" when I try to use the pos= parameter to position the text labels relative to a given x-y point.

Here is a simple example:

 x<-runif(100)
 y<-runif(100)
text1<- rep('LAB', 100)

 plot(x,y)
 textplot(x,y, text1, new=F, show.lines=F,  
          pos=4)

There were 50 or more warnings (use warnings() to see the first 50)
> warnings()
Warning messages:
1: In strwidth(words[i], cex = cex[i], ...) : "pos" is not a graphical parameter
2: In strheight(words[i], cex = cex[i], ...) : "pos" is not a graphical parameter 

How can I pass the pos=parameter to text() without generating the warnings?

I am doubly puzzled by the warnings because in the graph that results from the foregoing code,
The labels are to the  right of the points, as 'pos=4' requests.

Thanks!

Fraser D. Neiman

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From fneiman at monticello.org  Mon Mar 16 17:16:43 2015
From: fneiman at monticello.org (Fraser D. Neiman)
Date: Mon, 16 Mar 2015 16:16:43 +0000
Subject: [R] textplot() in wordcloud package
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D675A7F@mb02.ads.tamu.edu>
References: <2176AD174D58CB4ABBDA99F3458C2017208099CB@GRANGER.monticello.org>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D675A69@mb02.ads.tamu.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D675A7F@mb02.ads.tamu.edu>
Message-ID: <2176AD174D58CB4ABBDA99F3458C201720809E85@GRANGER.monticello.org>


Just a quick note to thank David Carlson and Jim lemon for the helpful replies on this... 

The easiest solution are to punt on WordCloud and use either the plotrix or maptools packages.

In plotrix the function is thigmophobe.labels().  In mapTools it's pointLabel()

Neither complains when you pass it the pos= parameter.

Thank you one and all!

Best, Fraser



-----Original Message-----
From: David L Carlson [mailto:dcarlson at tamu.edu] 
Sent: Monday, March 16, 2015 12:02 PM
To: David L Carlson; Fraser D. Neiman; r-help at r-project.org
Subject: RE: textplot() in wordcloud package

Another possibility is to use pointLabel() in package maptools. For your example

library(maptools)

plot(x,y)
pointLabel(x, y, text1)

Advantages of pointLabel() are that it returns a list of the x and y coordinates of the labels that you can tweak if necessary and, at least in your example, it does a better job of avoiding labels being chopped at the plot margins.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Monday, March 16, 2015 10:44 AM
To: Fraser D. Neiman; r-help at r-project.org
Subject: Re: [R] textplot() in wordcloud package

You should contact the package maintainer about this. The problem is that the pos= argument is being passed to strwidth() and strheight() and those functions do not know what to do with it. In the meantime:

suppressWarnings(textplot(x,y, text1, new=F, show.lines=F,  
          pos=4))

will eliminate the warnings.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fraser D. Neiman
Sent: Friday, March 13, 2015 3:29 PM
To: r-help at r-project.org
Subject: [R] textplot() in wordcloud package

Dear All,

The textplot() function in the wordcloud package seem to do a good job with generating non-overlapping labels on a scatter plot.
But it throws "warnings" when I try to use the pos= parameter to position the text labels relative to a given x-y point.

Here is a simple example:

 x<-runif(100)
 y<-runif(100)
text1<- rep('LAB', 100)

 plot(x,y)
 textplot(x,y, text1, new=F, show.lines=F,  
          pos=4)

There were 50 or more warnings (use warnings() to see the first 50)
> warnings()
Warning messages:
1: In strwidth(words[i], cex = cex[i], ...) : "pos" is not a graphical parameter
2: In strheight(words[i], cex = cex[i], ...) : "pos" is not a graphical parameter 

How can I pass the pos=parameter to text() without generating the warnings?

I am doubly puzzled by the warnings because in the graph that results from the foregoing code, The labels are to the  right of the points, as 'pos=4' requests.

Thanks!

Fraser D. Neiman

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Mar 16 18:04:59 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 16 Mar 2015 10:04:59 -0700
Subject: [R] How to filter data using sets generated by flattening with
 dcast, when I can't store those sets in a data frame
In-Reply-To: <alpine.LRH.2.02.1503151941150.30165@sphinx.mythic-beasts.com>
References: <alpine.LRH.2.02.1503120748540.25235@sphinx.mythic-beasts.com>
	<CAHuze_K1FaONNS622WyrWtueiU2LJQXvA+bdvairL6fivG5+xQ@mail.gmail.com>
	<alpine.LRH.2.02.1503151941150.30165@sphinx.mythic-beasts.com>
Message-ID: <CAF8bMcZh2XxjM6WHgnuyuC=k0ZrrLpkWkGDK3Zt4zNQzAx-36w@mail.gmail.com>

  William noted that 'reshape2' is not 'R', but a user-contributed
  package that runs in R. I agree, and I'm not confusing one with
  the other. But what I don't like is that somewhere in the interaction
  between them, generality is lost.

That lack of generality is something that you can discuss with the
maintainer of reshape2.
  > maintainer("reshape2")
  [1] "Hadley Wickham <h.wickham at gmail.com>"
In the meantime, explore functions in base R such as Reduce, Filter, lapply,
and split.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Mar 15, 2015 at 1:06 PM, Jocelyn Ireson-Paine <popx at j-paine.org>
wrote:

> David, and also William Dunlap, thanks for taking the time to reply, with
> examples. Both your answers are very helpful.
>
> William noted that 'reshape2' is not 'R', but a user-contributed package
> that runs in R. I agree, and I'm not confusing one with the other. But what
> I don't like is that somewhere in the interaction between them, generality
> is lost.
>
> I contrast this with a means of aggregating data that I use when
> programming in Lisp, Prolog, and other "functional" languages. This is
> aggregation by "folding" a list of values. The idea is explained at
> http://wiki.tcl.tk/17983 , "Fold in functional programming" by "juef",
> amongst other places. He/she gives a common example: take a list of values,
> such as
>   (1 2 3 4)
> and "fold" the + operation over it. Doing so runs + along the list forming
> intermediate sums and adding the next value to them, until all values have
> been summed.
>
> Here, 'fold' is analogous to dcast, with + being analogous to the function
> dcast takes for its fun.aggregate argument. But the good thing about 'fold'
> is that it does not restrict the type of result that its aggregation
> function can return. The result can be a number, a string, a list, a list
> of lists, an array, or any other type. I'd like dcast to be as general.
>
> Jocelyn Ireson-Paine
> 07768 534 091
> http://www.jocelyns-cartoons.uk
> http://www.j-paine.org
>
> On Thu, 12 Mar 2015, David Barron wrote:
>
>  Most of this question is over my head, I'm afraid, but looking at what
>> I think is the crux of your question, couldn't you achieve the results
>> you want in two steps, like this:
>>
>> dta <- data.frame(ID=c(1,1,1,1,2,2,3,3,3,3),
>> Day=c(1,2,4,7,2,3,1,3,4,8),Pain=c(10,9,7,2,8,7,10,6,6,2))
>>
>> l1 <- tapply(dta$Day, dta$ID, function(x) x)
>>
>> sapply(l1, function(x) all(c(1,4,8) %in% x ))
>>
>> I'm not sure you really need to do it in two steps, but given you said
>> you wanted a flattened data frame with the Days as a vector, this will
>> give it to you.  Actually, l1 is a list, but you can turn it in to a
>> data frame if you really want to.  In the sapply call I changed the
>> days required to 1, 4 and 8 to show that it does return TRUE if there
>> is a patient that meets the required criterion.
>>
>> David
>>
>> On 12 March 2015 at 07:55, Jocelyn Ireson-Paine <popx at j-paine.org> wrote:
>>
>>> This is a fairly long question. It's about a problem that's easy to
>>> specify
>>> in terms of sets, but that I found hard to solve in R by using them,
>>> because
>>> of the strange design of R data structures. In explaining it, I'm going
>>> to
>>> touch on the reshape2 library, dcast, sets, and the non-orthogonality of
>>> R.
>>>
>>> My problem stems from some drug-trial data that I've been analysing for
>>> the
>>> Oxford Pain Research Unit. Here's an example. Imagine a data frame
>>> representing patients in a trial of pain-relief drugs. The trial lasts
>>> for
>>> ten days. Each patient's pain is measured once a day, and the values are
>>> recorded in a data frame, one row per patient per day. Like this:
>>>
>>>   ID  Day  Pain
>>>    1    1  10
>>>    1    2   9
>>>    1    4   7
>>>    1    7   2
>>>    2    2   8
>>>    2    3   7
>>>    3    1  10
>>>    3    3   6
>>>    3    4   6
>>>    3    8   2
>>>
>>> Unfortunately, many patients have measurements missing. Thus, in the
>>> example
>>> above, patient 1 was only observed on days 1, 2, 4, and 7, rather than on
>>> the full ten days. But a patient's measurements are only useful to us if
>>> that patient has a certain minimum set of days, so I need to check for
>>> patients who lack those days. Let's assume that these days are numbers
>>> 1, 4,
>>> and 9.
>>>
>>> Such a question is trivial to state in terms of sets. Let D(i) denote the
>>> set of days on which patient i was measured: then I want to find out
>>> which
>>> patients p, or how many patients p, have a D(p) that contains the set
>>> {1,4,9}.
>>>
>>> The obvious way to solve this is to write a function that tells me
>>> whether
>>> one set is a superset of another. Then flatten my data frame so that it
>>> looks like this:
>>>
>>>   ID  Days
>>>    1  {1,2,4,7}
>>>    2  {2,3}
>>>    3  {1,3,4,8}
>>>
>>> And finally, filter it by some R translation of
>>>
>>>   flattened[ includes( flattened$Days, {1,4,9} ), ]
>>>
>>> I started with the built-in functions that operate on sets represented as
>>> vectors. These are described in
>>>  https://stat.ethz.ch/R-manual/R-devel/library/base/html/sets.html ,
>>> "Set Operations". For example:
>>>
>>>  > union( c(1,2,3), c(2,4,6) )
>>>   [1] 1 2 3 4 6
>>>  > intersect( c(1,2,3), c(2,4,6) )
>>>   [1] 2
>>>
>>> So I first wrote a set-inclusion function:
>>>
>>>   # True if vector a is a superset of vector b.
>>>   #
>>>   includes <- function( a, b )
>>>   {
>>>     return( setequal( union( a, b ), a ) )
>>>   }
>>>
>>> Here are some sample calls:
>>>
>>>  > includes( c(1), c() )
>>>   [1] TRUE
>>>  > includes( c(1), c(1) )
>>>   [1] TRUE
>>>  > includes( c(1), c(1,2) )
>>>   [1] FALSE
>>>  > includes( c(2,1), c(1,2) )
>>>   [1] TRUE
>>>  > includes( c(2,1,3), c(1,2) )
>>>   [1] TRUE
>>>  > includes( c(2,1,3), c(4,1,2) )
>>>   [1] FALSE
>>>
>>> I then made myself a variable holding my sample data frame:
>>>
>>>   df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
>>>                   , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
>>>                   )
>>>
>>> And I tried flattening it, using dcast and an aggregator function as
>>> described in (amongst many other places)
>>> http://seananderson.ca/2013/10/19/reshape.html , "An Introduction to
>>> reshape2" by Sean C. Anderson.
>>>
>>> The idea behind this is that (for my data) dcast will call the aggregator
>>> function once per patient ID, passing it all the Day values for the
>>> patient.
>>> The aggregator must combine them in some way, and dcast puts its results
>>> into a new column. For example, here's an aggregator that merely sums its
>>> arguments:
>>>
>>>   aggregator_making_sum <- function( ... )
>>>   {
>>>     return( sum( ... ) )
>>>   }
>>>
>>> If I call it, I get this:
>>>
>>>  >  dcast( df, ID~. , fun.aggregate=aggregator_making_sum )
>>>   Using Day as value column: use value.var to override.
>>>     ID  .
>>>   1  1 14
>>>   2  2  5
>>>   3  3 16
>>>
>>> And here's an aggregator that converts the argument list to a string:
>>>
>>>   aggregator_making_string <- function( ... )
>>>   {
>>>     return( toString( ... ) )
>>>   }
>>>
>>> Calling it gives this:
>>>
>>>  >  dcast( df, ID~. , fun.aggregate=aggregator_making_string )
>>>   Using Day as value column: use value.var to override.
>>>     ID          .
>>>   1  1 1, 2, 4, 7
>>>   2  2       2, 3
>>>   3  3 1, 3, 4, 8
>>>
>>> In both of these, the three dots denote all arguments to the aggregator,
>>> as
>>> explained in Burns Statistics's
>>> http://www.burns-stat.com/the-three-dots-construct-in-r/ . My first
>>> aggregator sums them; my second converts them to a string. Both uses of
>>> dcast generate a data frame with a column named "." , which contains the
>>> aggregates. In the second data frame, that may not be so clear: the first
>>> column of numbers is row numbers; the second column of numbers are the
>>> IDs;
>>> and the remaining columns form the strings, belonging to "." .
>>>
>>> But what I want is neither a sum nor a string but a set. Specifically, a
>>> set
>>> that's compatible with the R set operations I called in my 'includes'
>>> function. Since these sets are vectors, my aggregator should just pack
>>> its
>>> arguments into a vector:
>>>
>>>   aggregator_making_set <- function( ... )
>>>   {
>>>     return( c( ... ) )
>>>   }
>>>
>>> But when I tried it, I got an error:
>>>
>>>  > dcast( df, ID~. , fun.aggregate=aggregator_making_set )
>>>   Using Day as value column: use value.var to override.
>>>   Error in vapply(indices, fun, .default) : values must be length 0,
>>>    but FUN(X[[1]]) result is length 4
>>>
>>> It's not an informative error message, because it expects me to know how
>>> dcast is coded. And I'm surprised that values need to be length 0:
>>> length 1
>>> would seem more appropriate. But perhaps it's trying to say that 'c'
>>> doesn't
>>> work on three-dots argument lists. Let's test that hypothesis:
>>>
>>>   test_c_on_three_dots <- function( ... )
>>>   {
>>>     return( c( ... ) )
>>>   }
>>>
>>>  >   test_c_on_three_dots( 1 )
>>>   [1] 1
>>>  >   test_c_on_three_dots( 1, 2 )
>>>   [1] 1 2
>>>  >   test_c_on_three_dots( 1, 2, 3 )
>>>   [1] 1 2 3
>>>
>>> So 'c' does indeed work on three-dots argument lists. The error must have
>>> been caused by something else. Let's try making a set and putting it
>>> into a
>>> data frame directly:
>>>
>>>  > df <- data.frame( col1=c(1,2), col2=c(3,4) )
>>>  > df
>>>     col1 col2
>>>   1    1    3
>>>   2    2    4
>>>  > set <- union( c(5,6), c(6,7) )
>>>  > set
>>>   [1] 5 6 7
>>>  > df[ 1, ]$col1 <- set
>>>   Error in `$<-.data.frame`(`*tmp*`, "col1", value = c(5, 6, 7)) :
>>>     replacement has 3 rows, data has 1
>>>
>>> So that's the problem. Already in 1968, there was a language named
>>> Algol68
>>> which had arrays and, in order to make things easy for its programmers,
>>> allowed you to create arrays of every data type the language provided.
>>> You
>>> could have arrays of Booleans, arrays of integers, arrays of records,
>>> arrays
>>> of discriminated unions, arrays of procedures, arrays of I/O formats,
>>> arrays
>>> of pointers, and arrays of arrays. The idea was "orthogonality" (see for
>>> example http://stackoverflow.com/questions/1527393/what-is-orthogonality
>>> ):
>>> that the programmer does not have to think about unexpected interactions
>>> between the concept of array and the concept of the element type, because
>>> there are none. If you have a data type, you can make arrays of that
>>> type.
>>> Pop-2 (1970), Snobol4 (1966), and Lisp (1958) were similarly generous.
>>> But R
>>> (1993) isn't. It wants to make life hard by forcing me to use different
>>> kinds of container for different kinds of element. And by providing a
>>> nice
>>> implementation of sets and then not letting me store them.
>>>
>>> So I thought about the kinds of data that I _can_ store in a data frame
>>> and
>>> generate by flattening. Strings! So I decided to use my
>>> aggregator_making_string function to make a string representation of the
>>> set
>>> of days, and to write a set-inclusion function that compared these sets
>>> against sets represented as vectors:
>>>
>>>   includes2 <- function( a_as_string, b )
>>>   {
>>>     a <- as.numeric( unlist( strsplit( a_as_string, split="," ) ) )
>>>     return( setequal( union( a, b ), a ) )
>>>   }
>>>
>>> Here are some example calls:
>>>
>>>  > includes2( '1,2,3', c(1) )
>>>   [1] TRUE
>>>  > includes2( '1,2,3', c(1,2) )
>>>   [1] TRUE
>>>  > includes2( '1,2,3', c(1,2,4) )
>>>   [1] FALSE
>>>  > includes2( '1,2,3', c(3) )
>>>   [1] TRUE
>>>  > includes2( '1,2,3', c(0,3) )
>>>   [1] FALSE
>>>  >
>>>
>>> I then tried using it:
>>>
>>>   df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
>>>                   , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
>>>                   )
>>>
>>>   aggregator_making_string <- function( ... )
>>>   {
>>>     return( toString( ... ) )
>>>   }
>>>
>>>   flattened <- dcast( df, ID~. , fun.aggregate=aggregator_making_string
>>> )
>>>
>>>   # Which patients have a day 1?
>>>   flattened[ includes2( flattened$. , c(1) ), ]
>>>
>>> Unfortunately, that didn't work. The final statement selected every row
>>> of
>>> 'flattened'. I eventually realised that I had to vectorise 'includes2':
>>>
>>>   includes3 <- Vectorize( includes2, "a_as_string" )
>>>
>>> And that did work:
>>>
>>>  >   flattened[ includes3( flattened$. , c(1) ), ]
>>>     ID          .
>>>   1  1 1, 2, 4, 7
>>>   3  3 1, 3, 4, 8
>>>  >   flattened[ includes3( flattened$. , c(1,2) ), ]
>>>     ID          .
>>>   1  1 1, 2, 4, 7
>>>  >   flattened[ includes3( flattened$. , c(1,3) ), ]
>>>     ID          .
>>>   3  3 1, 3, 4, 8
>>>  >   flattened[ includes3( flattened$. , c(2) ), ]
>>>     ID          .
>>>   1  1 1, 2, 4, 7
>>>   2  2       2, 3
>>>
>>> The moral of this email tale is that sets are really useful for filtering
>>> data, and dcast ought to be really useful for generating sets, but R
>>> refuses
>>> to let me store them in the data frame that dcast generates. I can fudge
>>> it
>>> by representing the sets as strings, but is there a cleaner way to solve
>>> the
>>> problem?
>>>
>>> Cheers,
>>>
>>> Jocelyn Ireson-Paine
>>> 07768 534 091
>>> http://www.jocelyns-cartoons.uk
>>> http://www.j-paine.org
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Mar 16 18:07:06 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 16 Mar 2015 10:07:06 -0700
Subject: [R]
 =?windows-1252?q?Persons_with_objects_=96=3E_Objects_and_pers?=
 =?windows-1252?q?ons?=
In-Reply-To: <CA+8X3fXn8M9NLyBbGhH9p7UcdLEmEHOUwFXNQB7wp9ytwrHPvw@mail.gmail.com>
References: <1426370575108-4704655.post@n4.nabble.com>
	<CA+8X3fXn8M9NLyBbGhH9p7UcdLEmEHOUwFXNQB7wp9ytwrHPvw@mail.gmail.com>
Message-ID: <15269FB9-C272-4F7B-9912-FCE4E73BE119@comcast.net>


On Mar 15, 2015, at 3:46 AM, Jim Lemon wrote:

> Hi mareki,
> The transformation is not too difficult, but the table format in your
> example will cause a bit of difficulty. The following function from the
> plotrix package:
> 
> categoryReshape<-function(x) {
> dimx<-dim(x)
> if(is.null(dimx) || dimx[2]==1)
>  stop("Can only reshape a matrix or data frame with at least two columns")
> row_values<-sort(unique(x[,1]))
> column_values<-sort(unique(x[,2]))
> newx<-
> 
> as.data.frame(matrix(0,nrow=length(row_values),ncol=length(column_values)))
> for(row in 1:dimx[1]) {
>  row_index<-which(row_values %in% x[row,1])
>  column_index<-which(column_values %in% x[row,2])
>  newx[row_index,column_index]<-1
> }
> names(newx)<-column_values
> rownames(newx)<-row_values
> return(newx)
> }
> 
> will take a matrix or data frame like this:
> 
> table1<-read.table(text="object,person
> A,1
> A,2
> A,3
> A,4
> A,5
> B,1
> B,2
> B,3
> C,2
> C,3
> C,5
> D,4
> E,2
> E,3
> E,4
> E,5",sep=",",header=TRUE)
> 
> and transform it into a data frame like this:
> 
> categoryReshape(table1)
>  1 2 3 4 5
> A 1 1 1 1 1
> B 1 1 1 0 0
> C 0 1 1 0 1
> D 0 0 0 1 0
> E 0 1 1 1 1
> 

> Then if you take each column and format it like this;
> 
> concat_labels<-function(x,labels)
> return(paste(labels[as.logical(x)],collapse=";"))
> sapply(table2,concat.labels,rownames(tables))
> 
>        1         2         3         4         5
>    "A;B" "A;B;C;E" "A;B;C;E"   "A;D;E"   "A;C;E"

This would be another way of approaching this:

> data.frame( pobjects= 
             with( table1, tapply(object, person, FUN=paste, collapse=";")))
  pobjects
1      A;B
2  A;B;C;E
3  A;B;C;E
4    A;D;E
5    A;C;E

You could also use Jim's data example to build an object that looks more like your input:

test <- data.frame( opersons= with(table1, tapply(person, object, paste, collapse=";")))
test
   opersons
A 1;2;3;4;5
B     1;2;3
C     2;3;5
D         4
E   2;3;4;5

And this would let you recover Jim's input object:

> stack( sapply(test$opersons, strsplit, ";") )
   values ind
1       1   A
2       2   A
3       3   A
4       4   A
5       5   A
6       1   B
7       2   B
8       3   B
9       2   C
10      3   C
11      5   C
12      4   D
13      2   E
14      3   E
15      4   E
16      5   E

> 
> you have pretty much what you want.
> 
> Jim
> 
> 
> On Sun, Mar 15, 2015 at 9:02 AM, marekl <marek.r at lutonsky.net> wrote:
> 
>> Hi,
>> 
>> I have a table with persons in rows and objects associated to these
>> persons.
>> And I need to transform it to table with objects in rows and persons next
>> to
>> them. As it is shown on the picture.
>> 
>> <http://r.789695.n4.nabble.com/file/n4704655/Persons%2C_Objects.png>
>> 
>> Can you please help me how to make this transformation in R?
>> 
>> Thank you
>> 

And don't forget that Nabble is not Rhelp:

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Mar 16 18:19:17 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 16 Mar 2015 10:19:17 -0700
Subject: [R] How to filter data using sets generated by flattening with
	dcast, when I can't store those sets in a data frame
In-Reply-To: <alpine.LRH.2.02.1503151941150.30165@sphinx.mythic-beasts.com>
References: <alpine.LRH.2.02.1503120748540.25235@sphinx.mythic-beasts.com>
	<CAHuze_K1FaONNS622WyrWtueiU2LJQXvA+bdvairL6fivG5+xQ@mail.gmail.com>
	<alpine.LRH.2.02.1503151941150.30165@sphinx.mythic-beasts.com>
Message-ID: <CAB83DEB-2FD0-40D1-9441-7B2ADD5EF23B@comcast.net>


On Mar 15, 2015, at 1:06 PM, Jocelyn Ireson-Paine wrote:

> David, and also William Dunlap, thanks for taking the time to reply, with examples. Both your answers are very helpful.
> 
> William noted that 'reshape2' is not 'R', but a user-contributed package that runs in R. I agree, and I'm not confusing one with the other. But what I don't like is that somewhere in the interaction between them, generality is lost.
> 
> I contrast this with a means of aggregating data that I use when programming in Lisp, Prolog, and other "functional" languages. This is aggregation by "folding" a list of values. The idea is explained at http://wiki.tcl.tk/17983 , "Fold in functional programming" by "juef", amongst other places. He/she gives a common example: take a list of values, such as
>  (1 2 3 4)
> and "fold" the + operation over it. Doing so runs + along the list forming intermediate sums and adding the next value to them, until all values have been summed.
> 
> Here, 'fold' is analogous to dcast, with + being analogous to the function dcast takes for its fun.aggregate argument. But the good thing about 'fold' is that it does not restrict the type of result that its aggregation function can return. The result can be a number, a string, a list, a list of lists, an array, or any other type. I'd like dcast to be as general.

Since `dcast` is part of what I have seen called the "hadleyverse", your feature request should go to Hadley Wickham. Base R has the Reduce function:

> Reduce("+", 1:4)
[1] 10
> Reduce("+", 1:4, accumulate=TRUE)
[1]  1  3  6 10

It's described in the help page ?Reduce for other functional programming methods that were modeled after Lisp macros.

-- 
David.
> 
> Jocelyn Ireson-Paine
> 07768 534 091
> http://www.jocelyns-cartoons.uk
> http://www.j-paine.org
> 
> On Thu, 12 Mar 2015, David Barron wrote:
> 
>> Most of this question is over my head, I'm afraid, but looking at what
>> I think is the crux of your question, couldn't you achieve the results
>> you want in two steps, like this:
>> 
>> dta <- data.frame(ID=c(1,1,1,1,2,2,3,3,3,3),
>> Day=c(1,2,4,7,2,3,1,3,4,8),Pain=c(10,9,7,2,8,7,10,6,6,2))
>> 
>> l1 <- tapply(dta$Day, dta$ID, function(x) x)
>> 
>> sapply(l1, function(x) all(c(1,4,8) %in% x ))
>> 
>> I'm not sure you really need to do it in two steps, but given you said
>> you wanted a flattened data frame with the Days as a vector, this will
>> give it to you.  Actually, l1 is a list, but you can turn it in to a
>> data frame if you really want to.  In the sapply call I changed the
>> days required to 1, 4 and 8 to show that it does return TRUE if there
>> is a patient that meets the required criterion.
>> 
>> David
>> 
>> On 12 March 2015 at 07:55, Jocelyn Ireson-Paine <popx at j-paine.org> wrote:
>>> This is a fairly long question. It's about a problem that's easy to specify
>>> in terms of sets, but that I found hard to solve in R by using them, because
>>> of the strange design of R data structures. In explaining it, I'm going to
>>> touch on the reshape2 library, dcast, sets, and the non-orthogonality of R.
>>> 
>>> My problem stems from some drug-trial data that I've been analysing for the
>>> Oxford Pain Research Unit. Here's an example. Imagine a data frame
>>> representing patients in a trial of pain-relief drugs. The trial lasts for
>>> ten days. Each patient's pain is measured once a day, and the values are
>>> recorded in a data frame, one row per patient per day. Like this:
>>> 
>>>  ID  Day  Pain
>>>   1    1  10
>>>   1    2   9
>>>   1    4   7
>>>   1    7   2
>>>   2    2   8
>>>   2    3   7
>>>   3    1  10
>>>   3    3   6
>>>   3    4   6
>>>   3    8   2
>>> 
>>> Unfortunately, many patients have measurements missing. Thus, in the example
>>> above, patient 1 was only observed on days 1, 2, 4, and 7, rather than on
>>> the full ten days. But a patient's measurements are only useful to us if
>>> that patient has a certain minimum set of days, so I need to check for
>>> patients who lack those days. Let's assume that these days are numbers 1, 4,
>>> and 9.
>>> 
>>> Such a question is trivial to state in terms of sets. Let D(i) denote the
>>> set of days on which patient i was measured: then I want to find out which
>>> patients p, or how many patients p, have a D(p) that contains the set
>>> {1,4,9}.
>>> 
>>> The obvious way to solve this is to write a function that tells me whether
>>> one set is a superset of another. Then flatten my data frame so that it
>>> looks like this:
>>> 
>>>  ID  Days
>>>   1  {1,2,4,7}
>>>   2  {2,3}
>>>   3  {1,3,4,8}
>>> 
>>> And finally, filter it by some R translation of
>>> 
>>>  flattened[ includes( flattened$Days, {1,4,9} ), ]
>>> 
>>> I started with the built-in functions that operate on sets represented as
>>> vectors. These are described in
>>> https://stat.ethz.ch/R-manual/R-devel/library/base/html/sets.html ,
>>> "Set Operations". For example:
>>> 
>>> > union( c(1,2,3), c(2,4,6) )
>>>  [1] 1 2 3 4 6
>>> > intersect( c(1,2,3), c(2,4,6) )
>>>  [1] 2
>>> 
>>> So I first wrote a set-inclusion function:
>>> 
>>>  # True if vector a is a superset of vector b.
>>>  #
>>>  includes <- function( a, b )
>>>  {
>>>    return( setequal( union( a, b ), a ) )
>>>  }
>>> 
>>> Here are some sample calls:
>>> 
>>> > includes( c(1), c() )
>>>  [1] TRUE
>>> > includes( c(1), c(1) )
>>>  [1] TRUE
>>> > includes( c(1), c(1,2) )
>>>  [1] FALSE
>>> > includes( c(2,1), c(1,2) )
>>>  [1] TRUE
>>> > includes( c(2,1,3), c(1,2) )
>>>  [1] TRUE
>>> > includes( c(2,1,3), c(4,1,2) )
>>>  [1] FALSE
>>> 
>>> I then made myself a variable holding my sample data frame:
>>> 
>>>  df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
>>>                  , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
>>>                  )
>>> 
>>> And I tried flattening it, using dcast and an aggregator function as
>>> described in (amongst many other places)
>>> http://seananderson.ca/2013/10/19/reshape.html , "An Introduction to
>>> reshape2" by Sean C. Anderson.
>>> 
>>> The idea behind this is that (for my data) dcast will call the aggregator
>>> function once per patient ID, passing it all the Day values for the patient.
>>> The aggregator must combine them in some way, and dcast puts its results
>>> into a new column. For example, here's an aggregator that merely sums its
>>> arguments:
>>> 
>>>  aggregator_making_sum <- function( ... )
>>>  {
>>>    return( sum( ... ) )
>>>  }
>>> 
>>> If I call it, I get this:
>>> 
>>> >  dcast( df, ID~. , fun.aggregate=aggregator_making_sum )
>>>  Using Day as value column: use value.var to override.
>>>    ID  .
>>>  1  1 14
>>>  2  2  5
>>>  3  3 16
>>> 
>>> And here's an aggregator that converts the argument list to a string:
>>> 
>>>  aggregator_making_string <- function( ... )
>>>  {
>>>    return( toString( ... ) )
>>>  }
>>> 
>>> Calling it gives this:
>>> 
>>> >  dcast( df, ID~. , fun.aggregate=aggregator_making_string )
>>>  Using Day as value column: use value.var to override.
>>>    ID          .
>>>  1  1 1, 2, 4, 7
>>>  2  2       2, 3
>>>  3  3 1, 3, 4, 8
>>> 
>>> In both of these, the three dots denote all arguments to the aggregator, as
>>> explained in Burns Statistics's
>>> http://www.burns-stat.com/the-three-dots-construct-in-r/ . My first
>>> aggregator sums them; my second converts them to a string. Both uses of
>>> dcast generate a data frame with a column named "." , which contains the
>>> aggregates. In the second data frame, that may not be so clear: the first
>>> column of numbers is row numbers; the second column of numbers are the IDs;
>>> and the remaining columns form the strings, belonging to "." .
>>> 
>>> But what I want is neither a sum nor a string but a set. Specifically, a set
>>> that's compatible with the R set operations I called in my 'includes'
>>> function. Since these sets are vectors, my aggregator should just pack its
>>> arguments into a vector:
>>> 
>>>  aggregator_making_set <- function( ... )
>>>  {
>>>    return( c( ... ) )
>>>  }
>>> 
>>> But when I tried it, I got an error:
>>> 
>>> > dcast( df, ID~. , fun.aggregate=aggregator_making_set )
>>>  Using Day as value column: use value.var to override.
>>>  Error in vapply(indices, fun, .default) : values must be length 0,
>>>   but FUN(X[[1]]) result is length 4
>>> 
>>> It's not an informative error message, because it expects me to know how
>>> dcast is coded. And I'm surprised that values need to be length 0: length 1
>>> would seem more appropriate. But perhaps it's trying to say that 'c' doesn't
>>> work on three-dots argument lists. Let's test that hypothesis:
>>> 
>>>  test_c_on_three_dots <- function( ... )
>>>  {
>>>    return( c( ... ) )
>>>  }
>>> 
>>> >   test_c_on_three_dots( 1 )
>>>  [1] 1
>>> >   test_c_on_three_dots( 1, 2 )
>>>  [1] 1 2
>>> >   test_c_on_three_dots( 1, 2, 3 )
>>>  [1] 1 2 3
>>> 
>>> So 'c' does indeed work on three-dots argument lists. The error must have
>>> been caused by something else. Let's try making a set and putting it into a
>>> data frame directly:
>>> 
>>> > df <- data.frame( col1=c(1,2), col2=c(3,4) )
>>> > df
>>>    col1 col2
>>>  1    1    3
>>>  2    2    4
>>> > set <- union( c(5,6), c(6,7) )
>>> > set
>>>  [1] 5 6 7
>>> > df[ 1, ]$col1 <- set
>>>  Error in `$<-.data.frame`(`*tmp*`, "col1", value = c(5, 6, 7)) :
>>>    replacement has 3 rows, data has 1
>>> 
>>> So that's the problem. Already in 1968, there was a language named Algol68
>>> which had arrays and, in order to make things easy for its programmers,
>>> allowed you to create arrays of every data type the language provided. You
>>> could have arrays of Booleans, arrays of integers, arrays of records, arrays
>>> of discriminated unions, arrays of procedures, arrays of I/O formats, arrays
>>> of pointers, and arrays of arrays. The idea was "orthogonality" (see for
>>> example http://stackoverflow.com/questions/1527393/what-is-orthogonality ):
>>> that the programmer does not have to think about unexpected interactions
>>> between the concept of array and the concept of the element type, because
>>> there are none. If you have a data type, you can make arrays of that type.
>>> Pop-2 (1970), Snobol4 (1966), and Lisp (1958) were similarly generous. But R
>>> (1993) isn't. It wants to make life hard by forcing me to use different
>>> kinds of container for different kinds of element. And by providing a nice
>>> implementation of sets and then not letting me store them.
>>> 
>>> So I thought about the kinds of data that I _can_ store in a data frame and
>>> generate by flattening. Strings! So I decided to use my
>>> aggregator_making_string function to make a string representation of the set
>>> of days, and to write a set-inclusion function that compared these sets
>>> against sets represented as vectors:
>>> 
>>>  includes2 <- function( a_as_string, b )
>>>  {
>>>    a <- as.numeric( unlist( strsplit( a_as_string, split="," ) ) )
>>>    return( setequal( union( a, b ), a ) )
>>>  }
>>> 
>>> Here are some example calls:
>>> 
>>> > includes2( '1,2,3', c(1) )
>>>  [1] TRUE
>>> > includes2( '1,2,3', c(1,2) )
>>>  [1] TRUE
>>> > includes2( '1,2,3', c(1,2,4) )
>>>  [1] FALSE
>>> > includes2( '1,2,3', c(3) )
>>>  [1] TRUE
>>> > includes2( '1,2,3', c(0,3) )
>>>  [1] FALSE
>>> >
>>> 
>>> I then tried using it:
>>> 
>>>  df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
>>>                  , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
>>>                  )
>>> 
>>>  aggregator_making_string <- function( ... )
>>>  {
>>>    return( toString( ... ) )
>>>  }
>>> 
>>>  flattened <- dcast( df, ID~. , fun.aggregate=aggregator_making_string )
>>> 
>>>  # Which patients have a day 1?
>>>  flattened[ includes2( flattened$. , c(1) ), ]
>>> 
>>> Unfortunately, that didn't work. The final statement selected every row of
>>> 'flattened'. I eventually realised that I had to vectorise 'includes2':
>>> 
>>>  includes3 <- Vectorize( includes2, "a_as_string" )
>>> 
>>> And that did work:
>>> 
>>> >   flattened[ includes3( flattened$. , c(1) ), ]
>>>    ID          .
>>>  1  1 1, 2, 4, 7
>>>  3  3 1, 3, 4, 8
>>> >   flattened[ includes3( flattened$. , c(1,2) ), ]
>>>    ID          .
>>>  1  1 1, 2, 4, 7
>>> >   flattened[ includes3( flattened$. , c(1,3) ), ]
>>>    ID          .
>>>  3  3 1, 3, 4, 8
>>> >   flattened[ includes3( flattened$. , c(2) ), ]
>>>    ID          .
>>>  1  1 1, 2, 4, 7
>>>  2  2       2, 3
>>> 
>>> The moral of this email tale is that sets are really useful for filtering
>>> data, and dcast ought to be really useful for generating sets, but R refuses
>>> to let me store them in the data frame that dcast generates. I can fudge it
>>> by representing the sets as strings, but is there a cleaner way to solve the
>>> problem?
>>> 
>>> Cheers,
>>> 
>>> Jocelyn Ireson-Paine
>>> 07768 534 091
>>> http://www.jocelyns-cartoons.uk
>>> http://www.j-paine.org
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From karrri at hotmail.com  Mon Mar 16 15:52:23 2015
From: karrri at hotmail.com (=?Windows-1252?B?S2FycmkgSGVsbHN0cvZt?=)
Date: Mon, 16 Mar 2015 16:52:23 +0200
Subject: [R] Package related error, starting with Error in namespaceExport(ns,
 exports)
Message-ID: <DUB114-W9909D0CC90CE0AC99D9CB8DE020@phx.gbl>

Hi everyone!
I?m very new to R (2 weeks now) and very rusty with programming (last time I studied it was 20 years ago)Recently started a course in R, because Excel just doesnt cut it anymore.
System: R 3.1.2. , Windows 7, Platform: i386-w64-mingw32/i386 (32-bit), updated to R 3.1.3 during the battle.
General issue:  Error in namespaceExport(ns, exports).
Attending the class, we were asked to submit our functions with a submission script. Download went ok, "source("submitscript1.R)" as well without issues. However "submit()" , the function itself, produces the following error:
> source("submitscript1.R")> submit()Error in namespaceExport(ns, exports) :   undefined exports: bitFlip, bitAnd, bitOr, bitXor, bitShiftL, bitShiftR, cksumError: package ?bitops? could not be loaded
So I have undefined exports and an unloadable package called bitops. I later found out from Stackoverflow that stating "dependencies=TRUE might have averted this issue.. I have uninstalled and reinstalled everything R-related 3 times now, no use. No-one on the course discussion forum could assist with this either, posteed in a few threads there.
I tried "install.packages(bitops)", but then the package couldnt be located, download was ok. 
1. I have no idea how to fix this.
2. On another issue I got a similar error, when trying to "library("swirl"), namely :
Error in namespaceExport(ns, exports) :   undefined exports: bitFlip, bitAnd, bitOr, bitXor, bitShiftL, bitShiftR, cksumError: package or namespace load failed for ?swirl?
> remove.packages("swirl")Removing package from ?C:/Users/nakki/Documents/R/win-library/3.1?(as ?lib? is unspecified)
I wonder if these problems are related?
3. Is it normal for R to store packages in two different libraries? In my effort to fix this I tried "update.packages()" a couple times and noticed that I had two libraries, one in Documents folder, and another in Program files.
4. Is there a way to fix package installments manually, when the downloads are ok? I.E. copy-pasting the a file (which one, dont know) to a specific location in Windows?

Sorry for the long post, as I said I?m new to this, and didnt know which details are relevant and which are not..
BR, Karri 		 	   		  
	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Mon Mar 16 20:54:15 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 16 Mar 2015 14:54:15 -0500
Subject: [R] Plotting straight line
In-Reply-To: <CADcgpJeKEVraDfWRcaYHh2utXij9+Cq4vaAfMv771kfh8e1xGw@mail.gmail.com>
References: <CADcgpJeKEVraDfWRcaYHh2utXij9+Cq4vaAfMv771kfh8e1xGw@mail.gmail.com>
Message-ID: <CAN5YmCHQZpmKMAyUhp1WQWT6eCEf1W+ezBDKPxK=4hWMhQGvSQ@mail.gmail.com>

Something like this might help you get started.

x <- seq(-5, 5, 1)
m <- seq(0.5, 5, 0.5)
plot(0, 0, type="n", xlab="", ylab="", xlim=range(x), ylim=range(outer(m,
x)+1))
invisible(lapply(m, function(slope) abline(1, slope)))

Jean

On Sun, Mar 15, 2015 at 11:03 PM, Partha Sinha <pnsinha68 at gmail.com> wrote:

> I want to plot a straight line where y=m*x+1 (where x varying from -5
> to +5) and and m will change from 0.5 to 5. All the straight lines
> needs to be overlaid.
> Thanks
> Parth
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From saptarshi.guha at gmail.com  Mon Mar 16 23:08:35 2015
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Mon, 16 Mar 2015 15:08:35 -0700
Subject: [R] Returning to parent function
Message-ID: <CAJDot1o7eiHpT9DSRVqkMc69v3Bj2f4zcy+hE_rZfEDvN156dQ@mail.gmail.com>

Hello,

I would like a function X to return to the place that called the
function XParent that called this function X.

Y calls XParent
Y = function(){
  XParent()
  print("hello")
}

XParent calls X

XParent = function(){
   X()
   print("H")
}

X returns to the point just after the call to XParent. Hence
print("H") is not called, but instead "hello" is printed.

An example of what i'm going for is this

continueIfTrue <- function(filterExp, grpname, subname,n=1){
    y <- substitute(filterExp)
    res <- isn(eval(y, envir=parent.frame()),FALSE)
    ## if res is FALSE, I would like to return from telemStats
}

telemStats <- function(a,b){
    b <- c(10,12)
    continueIfTrue( {    length(b) >=10 }, "progStats","00")
    print("Since the above condition failed, I would not like this
message to be printed")
}

I looked into callCC and signals but dont think i understood correctly.
Any hints would be appreciated

Kind Regards
Saptarshi


From dwinsemius at comcast.net  Tue Mar 17 00:02:58 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 16 Mar 2015 16:02:58 -0700
Subject: [R] Returning to parent function
In-Reply-To: <CAJDot1o7eiHpT9DSRVqkMc69v3Bj2f4zcy+hE_rZfEDvN156dQ@mail.gmail.com>
References: <CAJDot1o7eiHpT9DSRVqkMc69v3Bj2f4zcy+hE_rZfEDvN156dQ@mail.gmail.com>
Message-ID: <469EB8B8-78B7-4FA1-9872-5B26D7DF83B3@comcast.net>


On Mar 16, 2015, at 3:08 PM, Saptarshi Guha wrote:

> Hello,
> 
> I would like a function X to return to the place that called the
> function XParent that called this function X.
> 
> Y calls XParent
> Y = function(){
>  XParent()
>  print("hello")
> }
> 
> XParent calls X
> 
> XParent = function(){
>   X()
>   print("H")
> }
> 
> X returns to the point just after the call to XParent. Hence
> print("H") is not called, but instead "hello" is printed.

?sys.call # my second reading of your question makes me think this wasn't what was requested.

?return  # this would do what was asked for

> XParent = function(){
+   return(sys.call())
+   print("H")
+ }
> Y()
[1] "hello"

# Success
# now to show that a value could be returned if desired

> Y = function(){
+  print(XParent())
+  print("hello")
+ }
> XParent = function(){
+   return(sys.call())
+   print("H")
+ }
> Y()
XParent()
[1] "hello"


> 
> X returns to the point just after the call to XParent. Hence
> print("H") is not called, but instead "hello" is printed.
> 
> An example of what i'm going for is this
> 
> continueIfTrue <- function(filterExp, grpname, subname,n=1){
>    y <- substitute(filterExp)
>    res <- isn(eval(y, envir=parent.frame()),FALSE)
>    ## if res is FALSE, I would like to return from telemStats
> }
> 
> telemStats <- function(a,b){
>    b <- c(10,12)
>    continueIfTrue( {    length(b) >=10 }, "progStats","00")
>    print("Since the above condition failed, I would not like this
> message to be printed")
> }

I'm afraid there were too many undefined objects to make much sense of that example.

> 
> I looked into callCC and signals but dont think i understood correctly.
> Any hints would be appreciated
> 
> Kind Regards
> Saptarshi
> 
-- 

David Winsemius
Alameda, CA, USA


From saptarshi.guha at gmail.com  Tue Mar 17 01:05:57 2015
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Mon, 16 Mar 2015 17:05:57 -0700
Subject: [R] Returning to parent function
In-Reply-To: <469EB8B8-78B7-4FA1-9872-5B26D7DF83B3@comcast.net>
References: <CAJDot1o7eiHpT9DSRVqkMc69v3Bj2f4zcy+hE_rZfEDvN156dQ@mail.gmail.com>
	<469EB8B8-78B7-4FA1-9872-5B26D7DF83B3@comcast.net>
Message-ID: <CAJDot1rYHbGM741ga9=tjiSuji1e7LjNUrXW+Rc2iisfERuY0w@mail.gmail.com>

Example was complicated, but here is a simpler form

continueIfTrue <- function(mm=return()){
    eval(mm)
}
telemStats <- function(){
    y <- substitute(return())
    continueIfTrue(y)
    print("I would not like this message to be printed")
}
telemStats()


Ideally, calling telemStats() should return to the prompt and the
print in telemStats should not appear


On Mon, Mar 16, 2015 at 4:02 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Mar 16, 2015, at 3:08 PM, Saptarshi Guha wrote:
>
>> Hello,
>>
>> I would like a function X to return to the place that called the
>> function XParent that called this function X.
>>
>> Y calls XParent
>> Y = function(){
>>  XParent()
>>  print("hello")
>> }
>>
>> XParent calls X
>>
>> XParent = function(){
>>   X()
>>   print("H")
>> }
>>
>> X returns to the point just after the call to XParent. Hence
>> print("H") is not called, but instead "hello" is printed.
>
> ?sys.call # my second reading of your question makes me think this wasn't what was requested.
>
> ?return  # this would do what was asked for
>
>> XParent = function(){
> +   return(sys.call())
> +   print("H")
> + }
>> Y()
> [1] "hello"
>
> # Success
> # now to show that a value could be returned if desired
>
>> Y = function(){
> +  print(XParent())
> +  print("hello")
> + }
>> XParent = function(){
> +   return(sys.call())
> +   print("H")
> + }
>> Y()
> XParent()
> [1] "hello"
>
>
>>
>> X returns to the point just after the call to XParent. Hence
>> print("H") is not called, but instead "hello" is printed.
>>
>> An example of what i'm going for is this
>>
>> continueIfTrue <- function(filterExp, grpname, subname,n=1){
>>    y <- substitute(filterExp)
>>    res <- isn(eval(y, envir=parent.frame()),FALSE)
>>    ## if res is FALSE, I would like to return from telemStats
>> }
>>
>> telemStats <- function(a,b){
>>    b <- c(10,12)
>>    continueIfTrue( {    length(b) >=10 }, "progStats","00")
>>    print("Since the above condition failed, I would not like this
>> message to be printed")
>> }
>
> I'm afraid there were too many undefined objects to make much sense of that example.
>
>>
>> I looked into callCC and signals but dont think i understood correctly.
>> Any hints would be appreciated
>>
>> Kind Regards
>> Saptarshi
>>
> --
>
> David Winsemius
> Alameda, CA, USA
>


From varinsacha at yahoo.fr  Tue Mar 17 01:34:18 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Tue, 17 Mar 2015 00:34:18 +0000 (UTC)
Subject: [R] Add the Gauss curve on histogram
Message-ID: <1061184749.1286523.1426552458969.JavaMail.yahoo@mail.yahoo.com>

Dear R-Experts,

I can easily plot an histogram and its density curve. But when I try to add the Gauss curve on the histogram with the following Rcode here below, I don't get it. What is wrong ? Or what is missing in my code ?

##Plot an histogram
h=hist(newdata$math.test, prob=TRUE, col="blue", border="white", xlab="Note test math", ylab="Densit?", main="Test math") 

##Add the density curve on the histogram
lines(density(newdata$math.test,na.rm=TRUE),lwd=2,col="orange") 

##Add the Gauss curve on the histogram
x <- seq(from = min(newdata$math.test, na.rm=TRUE), to = max(newdata$math.test, na.rm=TRUE), lines(x, dnorm(x, mean(newdata$math.test, na.rm = TRUE), sd(newdata$math.test, na.rm = TRUE))) 


Best, thanks for your time.


From jdnewmil at dcn.davis.CA.us  Tue Mar 17 02:30:54 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 16 Mar 2015 18:30:54 -0700
Subject: [R] Add the Gauss curve on histogram
In-Reply-To: <1061184749.1286523.1426552458969.JavaMail.yahoo@mail.yahoo.com>
References: <1061184749.1286523.1426552458969.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <2F5C70F7-F159-4C9D-94A1-97E520CF0022@dcn.davis.CA.us>

Not reproducible (sample data missing).

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 16, 2015 5:34:18 PM PDT, varin sacha <varinsacha at yahoo.fr> wrote:
>Dear R-Experts,
>
>I can easily plot an histogram and its density curve. But when I try to
>add the Gauss curve on the histogram with the following Rcode here
>below, I don't get it. What is wrong ? Or what is missing in my code ?
>
>##Plot an histogram
>h=hist(newdata$math.test, prob=TRUE, col="blue", border="white",
>xlab="Note test math", ylab="Densit?", main="Test math") 
>
>##Add the density curve on the histogram
>lines(density(newdata$math.test,na.rm=TRUE),lwd=2,col="orange") 
>
>##Add the Gauss curve on the histogram
>x <- seq(from = min(newdata$math.test, na.rm=TRUE), to =
>max(newdata$math.test, na.rm=TRUE), lines(x, dnorm(x,
>mean(newdata$math.test, na.rm = TRUE), sd(newdata$math.test, na.rm =
>TRUE))) 
>
>
>Best, thanks for your time.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lawrence.michael at gene.com  Tue Mar 17 04:01:21 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Mon, 16 Mar 2015 20:01:21 -0700
Subject: [R] How to filter data using sets generated by flattening with
 dcast, when I can't store those sets in a data frame
In-Reply-To: <alpine.LRH.2.02.1503120748540.25235@sphinx.mythic-beasts.com>
References: <alpine.LRH.2.02.1503120748540.25235@sphinx.mythic-beasts.com>
Message-ID: <CAOQ5NyeJSZ+KN1zgyGjXqtjDzDDWfcuboC30RR=F4f5iV6+b8g@mail.gmail.com>

The data structures you mention are complex, and too much of their
complexity leaks into client code. Instead, aim to use higher level code
constructs on simpler data structures. In R, the most convenient operations
are those that are statistical in nature.

For example, one might solve your problem by saying: restrict to the subset
of the important days (1, 4, 7), and count the occurrences of each patient
in that subset to find those patients with the sufficient number of
important measurements.

criticalDays <- c(1, 4, 8)
criticalDf <- subset(df, Day %in% criticalDays)
keepPatients <- table(criticalDf$ID) == length(criticalDays)
df[keepPatients[df$ID],]

Note that the code above assumes that the ID variable is a factor, which it
should be.

Michael

On Thu, Mar 12, 2015 at 12:55 AM, Jocelyn Ireson-Paine <popx at j-paine.org>
wrote:

> This is a fairly long question. It's about a problem that's easy to
> specify in terms of sets, but that I found hard to solve in R by using
> them, because of the strange design of R data structures. In explaining it,
> I'm going to touch on the reshape2 library, dcast, sets, and the
> non-orthogonality of R.
>
> My problem stems from some drug-trial data that I've been analysing for
> the Oxford Pain Research Unit. Here's an example. Imagine a data frame
> representing patients in a trial of pain-relief drugs. The trial lasts for
> ten days. Each patient's pain is measured once a day, and the values are
> recorded in a data frame, one row per patient per day. Like this:
>
>   ID  Day  Pain
>    1    1  10
>    1    2   9
>    1    4   7
>    1    7   2
>    2    2   8
>    2    3   7
>    3    1  10
>    3    3   6
>    3    4   6
>    3    8   2
>
> Unfortunately, many patients have measurements missing. Thus, in the
> example above, patient 1 was only observed on days 1, 2, 4, and 7, rather
> than on the full ten days. But a patient's measurements are only useful to
> us if that patient has a certain minimum set of days, so I need to check
> for patients who lack those days. Let's assume that these days are numbers
> 1, 4, and 9.
>
> Such a question is trivial to state in terms of sets. Let D(i) denote the
> set of days on which patient i was measured: then I want to find out which
> patients p, or how many patients p, have a D(p) that contains the set
> {1,4,9}.
>
> The obvious way to solve this is to write a function that tells me whether
> one set is a superset of another. Then flatten my data frame so that it
> looks like this:
>
>   ID  Days
>    1  {1,2,4,7}
>    2  {2,3}
>    3  {1,3,4,8}
>
> And finally, filter it by some R translation of
>
>   flattened[ includes( flattened$Days, {1,4,9} ), ]
>
> I started with the built-in functions that operate on sets represented as
> vectors. These are described in
>  https://stat.ethz.ch/R-manual/R-devel/library/base/html/sets.html ,
> "Set Operations". For example:
>
>   > union( c(1,2,3), c(2,4,6) )
>   [1] 1 2 3 4 6
>   > intersect( c(1,2,3), c(2,4,6) )
>   [1] 2
>
> So I first wrote a set-inclusion function:
>
>   # True if vector a is a superset of vector b.
>   #
>   includes <- function( a, b )
>   {
>     return( setequal( union( a, b ), a ) )
>   }
>
> Here are some sample calls:
>
>   > includes( c(1), c() )
>   [1] TRUE
>   > includes( c(1), c(1) )
>   [1] TRUE
>   > includes( c(1), c(1,2) )
>   [1] FALSE
>   > includes( c(2,1), c(1,2) )
>   [1] TRUE
>   > includes( c(2,1,3), c(1,2) )
>   [1] TRUE
>   > includes( c(2,1,3), c(4,1,2) )
>   [1] FALSE
>
> I then made myself a variable holding my sample data frame:
>
>   df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
>                   , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
>                   )
>
> And I tried flattening it, using dcast and an aggregator function as
> described in (amongst many other places) http://seananderson.ca/2013/
> 10/19/reshape.html , "An Introduction to reshape2" by Sean C. Anderson.
>
> The idea behind this is that (for my data) dcast will call the aggregator
> function once per patient ID, passing it all the Day values for the
> patient. The aggregator must combine them in some way, and dcast puts its
> results into a new column. For example, here's an aggregator that merely
> sums its arguments:
>
>   aggregator_making_sum <- function( ... )
>   {
>     return( sum( ... ) )
>   }
>
> If I call it, I get this:
>
>   >  dcast( df, ID~. , fun.aggregate=aggregator_making_sum )
>   Using Day as value column: use value.var to override.
>     ID  .
>   1  1 14
>   2  2  5
>   3  3 16
>
> And here's an aggregator that converts the argument list to a string:
>
>   aggregator_making_string <- function( ... )
>   {
>     return( toString( ... ) )
>   }
>
> Calling it gives this:
>
>   >  dcast( df, ID~. , fun.aggregate=aggregator_making_string )
>   Using Day as value column: use value.var to override.
>     ID          .
>   1  1 1, 2, 4, 7
>   2  2       2, 3
>   3  3 1, 3, 4, 8
>
> In both of these, the three dots denote all arguments to the aggregator,
> as explained in Burns Statistics's http://www.burns-stat.com/the-
> three-dots-construct-in-r/ . My first aggregator sums them; my second
> converts them to a string. Both uses of dcast generate a data frame with a
> column named "." , which contains the aggregates. In the second data frame,
> that may not be so clear: the first column of numbers is row numbers; the
> second column of numbers are the IDs; and the remaining columns form the
> strings, belonging to "." .
>
> But what I want is neither a sum nor a string but a set. Specifically, a
> set that's compatible with the R set operations I called in my 'includes'
> function. Since these sets are vectors, my aggregator should just pack its
> arguments into a vector:
>
>   aggregator_making_set <- function( ... )
>   {
>     return( c( ... ) )
>   }
>
> But when I tried it, I got an error:
>
>   > dcast( df, ID~. , fun.aggregate=aggregator_making_set )
>   Using Day as value column: use value.var to override.
>   Error in vapply(indices, fun, .default) : values must be length 0,
>    but FUN(X[[1]]) result is length 4
>
> It's not an informative error message, because it expects me to know how
> dcast is coded. And I'm surprised that values need to be length 0: length 1
> would seem more appropriate. But perhaps it's trying to say that 'c'
> doesn't work on three-dots argument lists. Let's test that hypothesis:
>
>   test_c_on_three_dots <- function( ... )
>   {
>     return( c( ... ) )
>   }
>
>   >   test_c_on_three_dots( 1 )
>   [1] 1
>   >   test_c_on_three_dots( 1, 2 )
>   [1] 1 2
>   >   test_c_on_three_dots( 1, 2, 3 )
>   [1] 1 2 3
>
> So 'c' does indeed work on three-dots argument lists. The error must have
> been caused by something else. Let's try making a set and putting it into a
> data frame directly:
>
>   > df <- data.frame( col1=c(1,2), col2=c(3,4) )
>   > df
>     col1 col2
>   1    1    3
>   2    2    4
>   > set <- union( c(5,6), c(6,7) )
>   > set
>   [1] 5 6 7
>   > df[ 1, ]$col1 <- set
>   Error in `$<-.data.frame`(`*tmp*`, "col1", value = c(5, 6, 7)) :
>     replacement has 3 rows, data has 1
>
> So that's the problem. Already in 1968, there was a language named Algol68
> which had arrays and, in order to make things easy for its programmers,
> allowed you to create arrays of every data type the language provided. You
> could have arrays of Booleans, arrays of integers, arrays of records,
> arrays of discriminated unions, arrays of procedures, arrays of I/O
> formats, arrays of pointers, and arrays of arrays. The idea was
> "orthogonality" (see for example http://stackoverflow.com/
> questions/1527393/what-is-orthogonality ): that the programmer does not
> have to think about unexpected interactions between the concept of array
> and the concept of the element type, because there are none. If you have a
> data type, you can make arrays of that type. Pop-2 (1970), Snobol4 (1966),
> and Lisp (1958) were similarly generous. But R (1993) isn't. It wants to
> make life hard by forcing me to use different kinds of container for
> different kinds of element. And by providing a nice implementation of sets
> and then not letting me store them.
>
> So I thought about the kinds of data that I _can_ store in a data frame
> and generate by flattening. Strings! So I decided to use my
> aggregator_making_string function to make a string representation of the
> set of days, and to write a set-inclusion function that compared these sets
> against sets represented as vectors:
>
>   includes2 <- function( a_as_string, b )
>   {
>     a <- as.numeric( unlist( strsplit( a_as_string, split="," ) ) )
>     return( setequal( union( a, b ), a ) )
>   }
>
> Here are some example calls:
>
>   > includes2( '1,2,3', c(1) )
>   [1] TRUE
>   > includes2( '1,2,3', c(1,2) )
>   [1] TRUE
>   > includes2( '1,2,3', c(1,2,4) )
>   [1] FALSE
>   > includes2( '1,2,3', c(3) )
>   [1] TRUE
>   > includes2( '1,2,3', c(0,3) )
>   [1] FALSE
>   >
>
> I then tried using it:
>
>   df <- data.frame( ID = c( 1, 1, 1, 1, 2, 2, 3, 3, 3, 3 )
>                   , Day = c( 1, 2, 4, 7, 2, 3, 1, 3, 4, 8 )
>                   )
>
>   aggregator_making_string <- function( ... )
>   {
>     return( toString( ... ) )
>   }
>
>   flattened <- dcast( df, ID~. , fun.aggregate=aggregator_making_string )
>
>   # Which patients have a day 1?
>   flattened[ includes2( flattened$. , c(1) ), ]
>
> Unfortunately, that didn't work. The final statement selected every row of
> 'flattened'. I eventually realised that I had to vectorise 'includes2':
>
>   includes3 <- Vectorize( includes2, "a_as_string" )
>
> And that did work:
>
>   >   flattened[ includes3( flattened$. , c(1) ), ]
>     ID          .
>   1  1 1, 2, 4, 7
>   3  3 1, 3, 4, 8
>   >   flattened[ includes3( flattened$. , c(1,2) ), ]
>     ID          .
>   1  1 1, 2, 4, 7
>   >   flattened[ includes3( flattened$. , c(1,3) ), ]
>     ID          .
>   3  3 1, 3, 4, 8
>   >   flattened[ includes3( flattened$. , c(2) ), ]
>     ID          .
>   1  1 1, 2, 4, 7
>   2  2       2, 3
>
> The moral of this email tale is that sets are really useful for filtering
> data, and dcast ought to be really useful for generating sets, but R
> refuses to let me store them in the data frame that dcast generates. I can
> fudge it by representing the sets as strings, but is there a cleaner way to
> solve the problem?
>
> Cheers,
>
> Jocelyn Ireson-Paine
> 07768 534 091
> http://www.jocelyns-cartoons.uk
> http://www.j-paine.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Mar 17 05:02:52 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 17 Mar 2015 17:02:52 +1300
Subject: [R] Add the Gauss curve on histogram
In-Reply-To: <1061184749.1286523.1426552458969.JavaMail.yahoo@mail.yahoo.com>
References: <1061184749.1286523.1426552458969.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <5507A76C.8080508@auckland.ac.nz>

On 17/03/15 13:34, varin sacha wrote:
> Dear R-Experts,
>
> I can easily plot an histogram and its density curve. But when I try
> to add the Gauss curve on the histogram with the following Rcode here
> below, I don't get it. What is wrong ? Or what is missing in my code
> ?

Coherency and appropriate checking of syntax.

* Your call to lines() is *inside* the call to seq(), whence it gets 
ignored.

* Your call to seq() should specify some reasonable values for "length" 
or "by", otherwise "x" has far too few values and you get a very jagged 
curve.

* You should not jumble a whole lot of commands together.  This leads to 
the sort of mistakes that you made.  Do one thing at a time.  Keep your 
commands brief.  You will then have far less tendency to make mistakes 
and a far easier time in detecting where mistakes have been made if you 
do make them.

* There is no such thing as "the" Gauss curve.  There is an uncountably 
infinite number of Gauss curves.

* As Jeff Newmiller told you, *do* provide a *reproducible* example when 
you ask a question.  (Nobody but *you* has the data set "newdata".)
Neither R nor the members of this list can mind-read.

cheers,

Rolf Turner

>
> ##Plot an histogram h=hist(newdata$math.test, prob=TRUE, col="blue",
> border="white", xlab="Note test math", ylab="Densit?", main="Test
> math")
>
> ##Add the density curve on the histogram
> lines(density(newdata$math.test,na.rm=TRUE),lwd=2,col="orange")
>
> ##Add the Gauss curve on the histogram x <- seq(from =
> min(newdata$math.test, na.rm=TRUE), to = max(newdata$math.test,
> na.rm=TRUE), lines(x, dnorm(x, mean(newdata$math.test, na.rm = TRUE),
> sd(newdata$math.test, na.rm = TRUE)))
-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From bhh at xs4all.nl  Tue Mar 17 07:27:12 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 17 Mar 2015 07:27:12 +0100
Subject: [R] Returning to parent function
In-Reply-To: <CAJDot1o7eiHpT9DSRVqkMc69v3Bj2f4zcy+hE_rZfEDvN156dQ@mail.gmail.com>
References: <CAJDot1o7eiHpT9DSRVqkMc69v3Bj2f4zcy+hE_rZfEDvN156dQ@mail.gmail.com>
Message-ID: <EC40FD84-3E7D-42A1-966C-6518DECAED7B@xs4all.nl>


> On 16-03-2015, at 23:08, Saptarshi Guha <saptarshi.guha at gmail.com> wrote:
> 
> Hello,
> 
> I would like a function X to return to the place that called the
> function XParent that called this function X.
> 
> Y calls XParent
> Y = function(){
>  XParent()
>  print("hello")
> }
> 
> XParent calls X
> 
> XParent = function(){
>   X()
>   print("H")
> }
> 
> X returns to the point just after the call to XParent. Hence
> print("H") is not called, but instead "hello" is printed.
> 


I do not understand what you are saying or implying here.
Take this R code:

####<code>
Y <- function(){
 XParent()
 print("hello")
}

XParent <- function(){
  X()
  print("H")
}

X <- function() { print("In function X") }

Y()
####</code>

and this is the output:

[1] "In function X"
[1] "H"
[1] "hello"


Implying that everything you seem to want printed is acually printed.

Berend


From sri4mailing at gmail.com  Tue Mar 17 08:26:22 2015
From: sri4mailing at gmail.com (Srikanth Gumma)
Date: Tue, 17 Mar 2015 07:26:22 +0000
Subject: [R] Unsupported Fortran 90 compiler or Fortran 90
In-Reply-To: <5506BCAF.2010309@stats.ox.ac.uk>
References: <CACSaa1VXnUiQgwT4duA8RwNW+ZgsS68WPSupV=T7P_HWJ8=itg@mail.gmail.com>
	<5506BCAF.2010309@stats.ox.ac.uk>
Message-ID: <CACSaa1Uc7wLAYNwsStWMN0AVHTZLax4xE+GN2c5UihfeoThkpw@mail.gmail.com>

Thank you Prof. Brian Ripley. I'm writing a mail to glasso maintainer. Let
me see if I could get some help from them.

Regards
Srikanth.

On Mon, 16 Mar 2015 at 19:21 Prof Brian Ripley <ripley at stats.ox.ac.uk>
wrote:

> On 16/03/2015 10:38, Srikanth Gumma wrote:
> > Hi,
> >
> > I'm trying to install diveRsity package in our R installation. however it
> > always fails with the error message "Unsupported Fortran 90 compiler or
> > Fortran 90". Below is the full output. Appreciate any help.
>
> Ask the maintainer of the package concerned (glasso).  Its way of
> detecting the complier is flaky (and does not meet current CRAN
> requirements on cross-platform portability).
>
> >
> > R
> >
> > R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
> > Copyright (C) 2014 The R Foundation for Statistical Computing
> > Platform: x86_64-unknown-linux-gnu (64-bit)
> >
> > R is free software and comes with ABSOLUTELY NO WARRANTY.
> > You are welcome to redistribute it under certain conditions.
> > Type 'license()' or 'licence()' for distribution details.
> >
> >    Natural language support but running in an English locale
> >
> > R is a collaborative project with many contributors.
> > Type 'contributors()' for more information and
> > 'citation()' on how to cite R or R packages in publications.
> >
> > Type 'demo()' for some demos, 'help()' for on-line help, or
> > 'help.start()' for an HTML browser interface to help.
> > Type 'q()' to quit R.
> >
> >> install.packages("diversity")
> > --- Please select a CRAN mirror for use in this session ---
> > Warning messages:
> > 1: package ?diversity? is not available (for R version 3.1.2)
> > 2: Perhaps you meant ?diveRsity? ?
> >> install.packages("diveRsity")
> > also installing the dependencies ?glasso?, ?qgraph?
> >
> > trying URL 'http://cran.rstudio.com/src/contrib/glasso_1.8.tar.gz'
> > Content type 'application/x-gzip' length 41768 bytes (40 Kb)
> > opened URL
> > ==================================================
> > downloaded 40 Kb
> >
> > trying URL 'http://cran.rstudio.com/src/contrib/qgraph_1.3.1.tar.gz'
> > Content type 'application/x-gzip' length 211062 bytes (206 Kb)
> > opened URL
> > ==================================================
> > downloaded 206 Kb
> >
> > trying URL 'http://cran.rstudio.com/src/contrib/diveRsity_1.9.73.tar.gz'
> > Content type 'application/x-gzip' length 1330144 bytes (1.3 Mb)
> > opened URL
> > ==================================================
> > downloaded 1.3 Mb
> >
> > * installing *source* package ?glasso? ...
> > ** package ?glasso? successfully unpacked and MD5 sums checked
> >   This package requires a fortran 90 compiler. We assume
> >   that your fortran 90 environment is set up appropriately.
> >   Reference: Section on 'Using F95 code' in R-exts manual.
> >   R_HOME is /app1/centos6.3/gnu/apps/R-3.1.2/lib64/R
> >      Unsupported Fortran 90 compiler or Fortran 90
> >      compilers unavailable! Stop!
> > ERROR: configuration failed for package ?glasso?
> > * removing ?/nfs/app1/centos6.3/gnu/apps/R-3.1.2/lib64/R/library/glasso?
> > ERROR: dependency ?glasso? is not available for package ?qgraph?
> > * removing ?/nfs/app1/centos6.3/gnu/apps/R-3.1.2/lib64/R/library/qgraph?
> > ERROR: dependency ?qgraph? is not available for package ?diveRsity?
> > * removing ?/nfs/app1/centos6.3/gnu/apps/R-3.1.2/lib64/R/library/
> diveRsity?
> >
> > The downloaded source packages are in
> >          ?/tmp/Rtmp2IAilr/downloaded_packages?
> > Warning messages:
> > 1: In install.packages("diveRsity") :
> >    installation of package ?glasso? had non-zero exit status
> > 2: In install.packages("diveRsity") :
> >    installation of package ?qgraph? had non-zero exit status
> > 3: In install.packages("diveRsity") :
> >    installation of package ?diveRsity? had non-zero exit status
> >
> > Regards
> > Srikanth.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Mar 17 09:42:59 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Mar 2015 09:42:59 +0100
Subject: [R] lme random interactions
In-Reply-To: <DB5PR04MB1064D2FAC085F235A64069DBF6020@DB5PR04MB1064.eurprd04.prod.outlook.com>
References: <DB5PR04MB1064D2FAC085F235A64069DBF6020@DB5PR04MB1064.eurprd04.prod.outlook.com>
Message-ID: <CAJuCY5yU2Fka+MSZGDA74nrSJQnq6ef_pt27=VtdZRi=HR_KiA@mail.gmail.com>

Dear Brian,

You want

data$CompLab <- interaction(data$Compound, data$Lab)
lme ( data=data, Resp ~ Lab * Compound,
   random = list(CombLab = ~ 1, Date = pdIdent(~0 + Lab)) ,
    weights = varIdent(form=~1|Lab)
)

Note that this is untested since you didn't provide a reproducible example.

However, you have only very few levels of Date. See "Should I treat factor
xxx as fixed or random?" on http://glmm.wikidot.com/faq
Furthermore, you are estimating a lot of parameters. Make you that you have
enough data.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-16 11:10 GMT+01:00 Middleton, Brian J <
Brian.Middleton at astrazeneca.com>:

> I have a method comparison problem, comparing Labs where a set of
> compounds are assayed on 3 different dates for each lab. Both labs will be
> used to assess compounds in the future, so the scientists will potentially
> contrast a compound at assayed at Lab A with one assayed at Lab B, This
> implies I ought to regard the Lab*Compound interaction as random. I also
> have the date within Lab as a random term and the Compound*date as random
> (and as separate variances for each Lab).
>
> If I regard the Compound*Lab effect as fixed this code works
>
> lme.out <- lme ( data=data, Resp ~ Lab + Compound + Compound:Lab,
>    random = pdIdent(~Lab-1|Date)  ,
>     weights = varIdent(form=~1|Lab)
> )
>
> The trouble is when I try to regard it as random, eg.
>
> lme2.out <- lme ( data=data, Resp ~ Lab + Compound,
>    random = list( ~Compound:Lab,  pdIdent(~Lab-1|Date)  ),
>     weights = varIdent(form=~1|Lab)
>   )
>
> It appears as if the random interaction is not allowed ... Is this right ?
> Is there a way to fit the interaction as random together with the other
> random terms ?
>
> I have tried lme4 but note that "lme4 does not currently implement nlme's
> features for modeling heteroscedasticity" but "does implement crossed
> random effects". No joy in my hands though. Nor with lmer ...
>
> Any help gratefully received, thanks,
>
> Brian (trying to convert from SAS !)
>
>
>
> ________________________________
>
> AstraZeneca UK Limited is a company incorporated in Engl...{{dropped:26}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From varinsacha at yahoo.fr  Tue Mar 17 12:11:54 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Tue, 17 Mar 2015 11:11:54 +0000 (UTC)
Subject: [R] Add the Gauss curve on histogram
In-Reply-To: <2F5C70F7-F159-4C9D-94A1-97E520CF0022@dcn.davis.CA.us>
References: <2F5C70F7-F159-4C9D-94A1-97E520CF0022@dcn.davis.CA.us>
Message-ID: <1229422045.1671635.1426590714793.JavaMail.yahoo@mail.yahoo.com>

Hi Jeff,
Here is I hope a reproducible code.
My R code gives something but not what I am expecting. Indeed, I am expecting a gauss curve and I get a straight line.
I have followed the advices of Rolf as well but I still don't get a gauss curve...
Thanks for your time

Dataset <- read.table("/Users/Caro/Desktop/Mesures d'association using R/test.txt", header=TRUE, sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
newdata=na.omit(Dataset) 

h <-hist(newdata$math.test, prob=TRUE, col="blue", border="white", xlab="Note test math", ylab="Densit?", main="Test math")

x <- seq(from = min(newdata$math.test, na.rm=TRUE), to = max(newdata$math.test, na.rm=TRUE, length=100)) 
lines(x, dnorm(x, mean(newdata$math.test, na.rm = TRUE), sd(newdata$math.test, na.rm = TRUE))) 




----- Mail original -----
De : Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
? : varin sacha <varinsacha at yahoo.fr>; "r-help at r-project.org" <r-help at r-project.org>
Cc : 
Envoy? le : Mardi 17 mars 2015 2h30
Objet : Re: [R] Add the Gauss curve on histogram

Not reproducible (sample data missing).

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.



>Dear R-Experts,
>
>I can easily plot an histogram and its density curve. But when I try to
>add the Gauss curve on the histogram with the following Rcode here
>below, I don't get it. What is wrong ? Or what is missing in my code ?
>
>##Plot an histogram
>h=hist(newdata$math.test, prob=TRUE, col="blue", border="white",
>xlab="Note test math", ylab="Densit?", main="Test math") 
>
>##Add the density curve on the histogram
>lines(density(newdata$math.test,na.rm=TRUE),lwd=2,col="orange") 
>
>##Add the Gauss curve on the histogram
>x <- seq(from = min(newdata$math.test, na.rm=TRUE), to =
>max(newdata$math.test, na.rm=TRUE), lines(x, dnorm(x,
>mean(newdata$math.test, na.rm = TRUE), sd(newdata$math.test, na.rm =
>TRUE))) 
>
>
>Best, thanks for your time.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Tue Mar 17 12:40:00 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 18 Mar 2015 00:40:00 +1300
Subject: [R] Add the Gauss curve on histogram
In-Reply-To: <1298974712.1684383.1426590910502.JavaMail.yahoo@mail.yahoo.com>
References: <5507A76C.8080508@auckland.ac.nz>
	<1298974712.1684383.1426590910502.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <55081290.5010502@auckland.ac.nz>



Please keep your replies on-list.  I am not your private consultant. 
Not, at least, until you start paying me!!!

Again your example is not reproducible.  WTF makes you think I have 
access to the file

    "/Users/Caro/Desktop/Mesures d'association using R/test.txt"   ???

I have no idea what your problem is.  The following simulated example 
works just fine:

# ------------------------------------------------------------
set.seed(59631)
simdat <- rnorm(300,0,2)

hist(simdat, prob=TRUE, col="blue", border="white",
      xlab="x", ylab="y", main="Simulated data")

x <- seq(min(simdat),max(simdat),length=100)
muhat <- mean(simdat)
sigmahat <- sd(simdat)
y <- dnorm(x,muhat,sigmahat)

lines(x,y)
# ------------------------------------------------------------

Imitate it.

cheers,

Rolf Turner

On 18/03/15 00:15, varin sacha wrote:
> Hi Rolf,
> Many thanks for all your advices.
>
> I get a straight line but not a gauss curve as i am expecting ! I have tried as well another Rcode to get a gauss curve. I don't get any error message but my other Rcode doesn't give anything. Strange !!
>
>
> Dataset <- read.table("/Users/Caro/Desktop/Mesures d'association using R/test.txt", header=TRUE, sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
> newdata=na.omit(Dataset)
>
> h <-hist(newdata$math.test, prob=TRUE, col="blue", border="white", xlab="Note test math", ylab="Densit?", main="Test math")
>
> x <- seq(from = min(newdata$math.test, na.rm=TRUE), to = max(newdata$math.test, na.rm=TRUE, length=100))
> lines(x, dnorm(x, mean(newdata$math.test, na.rm = TRUE), sd(newdata$math.test, na.rm = TRUE)))
> OR
>
>
> x <- seq(from = min(newdata$math.test, na.rm=TRUE), to = max(newdata$math.test, na.rm=TRUE, length=100))
> lines(x, dnorm(x, mean(newdata$math.test, na.rm = TRUE), sd(newdata$math.test, na.rm = TRUE)))
>
>
>
> ----- Mail original -----
> De : Rolf Turner <r.turner at auckland.ac.nz>
> ? : varin sacha <varinsacha at yahoo.fr>; "r-help at r-project.org" <r-help at r-project.org>
> Cc :
> Envoy? le : Mardi 17 mars 2015 5h02
> Objet : Re: [R] Add the Gauss curve on histogram
>
> On 17/03/15 13:34, varin sacha wrote:
>> Dear R-Experts,
>>
>> I can easily plot an histogram and its density curve. But when I try
>> to add the Gauss curve on the histogram with the following Rcode here
>> below, I don't get it. What is wrong ? Or what is missing in my code
>> ?
>
> Coherency and appropriate checking of syntax.
>
> * Your call to lines() is *inside* the call to seq(), whence it gets
> ignored.
>
> * Your call to seq() should specify some reasonable values for "length"
> or "by", otherwise "x" has far too few values and you get a very jagged
> curve.
>
> * You should not jumble a whole lot of commands together.  This leads to
> the sort of mistakes that you made.  Do one thing at a time.  Keep your
> commands brief.  You will then have far less tendency to make mistakes
> and a far easier time in detecting where mistakes have been made if you
> do make them.
>
> * There is no such thing as "the" Gauss curve.  There is an uncountably
> infinite number of Gauss curves.
>
> * As Jeff Newmiller told you, *do* provide a *reproducible* example when
> you ask a question.  (Nobody but *you* has the data set "newdata".)
> Neither R nor the members of this list can mind-read.
>
> cheers,
>
> Rolf Turner
>
>
>>
>> ##Plot an histogram h=hist(newdata$math.test, prob=TRUE, col="blue",
>> border="white", xlab="Note test math", ylab="Densit?", main="Test
>> math")
>>
>> ##Add the density curve on the histogram
>> lines(density(newdata$math.test,na.rm=TRUE),lwd=2,col="orange")
>>
>> ##Add the Gauss curve on the histogram x <- seq(from =
>> min(newdata$math.test, na.rm=TRUE), to = max(newdata$math.test,
>> na.rm=TRUE), lines(x, dnorm(x, mean(newdata$math.test, na.rm = TRUE),
>> sd(newdata$math.test, na.rm = TRUE)))


-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From varinsacha at yahoo.fr  Tue Mar 17 13:30:28 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Tue, 17 Mar 2015 12:30:28 +0000 (UTC)
Subject: [R] Add the Gauss curve on histogram
In-Reply-To: <55081290.5010502@auckland.ac.nz>
References: <55081290.5010502@auckland.ac.nz>
Message-ID: <550441646.1767635.1426595428298.JavaMail.yahoo@mail.yahoo.com>

Sorry for that Rolf,

Yes, it perfectly works. 

Many thanks. Cheers,



----- Mail original -----
De : Rolf Turner <r.turner at auckland.ac.nz>
? : varin sacha <varinsacha at yahoo.fr>
Cc : R help <R-help at r-project.org>
Envoy? le : Mardi 17 mars 2015 12h40
Objet : Re: [R] Add the Gauss curve on histogram



Please keep your replies on-list.  I am not your private consultant. 
Not, at least, until you start paying me!!!

Again your example is not reproducible.  WTF makes you think I have 
access to the file

    "/Users/Caro/Desktop/Mesures d'association using R/test.txt"   ???

I have no idea what your problem is.  The following simulated example 
works just fine:

# ------------------------------------------------------------
set.seed(59631)
simdat <- rnorm(300,0,2)

hist(simdat, prob=TRUE, col="blue", border="white",
      xlab="x", ylab="y", main="Simulated data")

x <- seq(min(simdat),max(simdat),length=100)
muhat <- mean(simdat)
sigmahat <- sd(simdat)
y <- dnorm(x,muhat,sigmahat)

lines(x,y)
# ------------------------------------------------------------

Imitate it.

cheers,

Rolf Turner


On 18/03/15 00:15, varin sacha wrote:
> Hi Rolf,
> Many thanks for all your advices.
>
> I get a straight line but not a gauss curve as i am expecting ! I have tried as well another Rcode to get a gauss curve. I don't get any error message but my other Rcode doesn't give anything. Strange !!
>
>
> Dataset <- read.table("/Users/Caro/Desktop/Mesures d'association using R/test.txt", header=TRUE, sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
> newdata=na.omit(Dataset)
>
> h <-hist(newdata$math.test, prob=TRUE, col="blue", border="white", xlab="Note test math", ylab="Densit?", main="Test math")
>
> x <- seq(from = min(newdata$math.test, na.rm=TRUE), to = max(newdata$math.test, na.rm=TRUE, length=100))
> lines(x, dnorm(x, mean(newdata$math.test, na.rm = TRUE), sd(newdata$math.test, na.rm = TRUE)))
> OR
>
>
> x <- seq(from = min(newdata$math.test, na.rm=TRUE), to = max(newdata$math.test, na.rm=TRUE, length=100))
> lines(x, dnorm(x, mean(newdata$math.test, na.rm = TRUE), sd(newdata$math.test, na.rm = TRUE)))
>
>
>
> ----- Mail original -----
> De : Rolf Turner <r.turner at auckland.ac.nz>
> ? : varin sacha <varinsacha at yahoo.fr>; "r-help at r-project.org" <r-help at r-project.org>
> Cc :
> Envoy? le : Mardi 17 mars 2015 5h02
> Objet : Re: [R] Add the Gauss curve on histogram
>
> On 17/03/15 13:34, varin sacha wrote:
>> Dear R-Experts,
>>
>> I can easily plot an histogram and its density curve. But when I try
>> to add the Gauss curve on the histogram with the following Rcode here
>> below, I don't get it. What is wrong ? Or what is missing in my code
>> ?
>
> Coherency and appropriate checking of syntax.
>
> * Your call to lines() is *inside* the call to seq(), whence it gets
> ignored.
>
> * Your call to seq() should specify some reasonable values for "length"
> or "by", otherwise "x" has far too few values and you get a very jagged
> curve.
>
> * You should not jumble a whole lot of commands together.  This leads to
> the sort of mistakes that you made.  Do one thing at a time.  Keep your
> commands brief.  You will then have far less tendency to make mistakes
> and a far easier time in detecting where mistakes have been made if you
> do make them.
>
> * There is no such thing as "the" Gauss curve.  There is an uncountably
> infinite number of Gauss curves.
>
> * As Jeff Newmiller told you, *do* provide a *reproducible* example when
> you ask a question.  (Nobody but *you* has the data set "newdata".)
> Neither R nor the members of this list can mind-read.
>
> cheers,
>
> Rolf Turner
>
>
>>
>> ##Plot an histogram h=hist(newdata$math.test, prob=TRUE, col="blue",
>> border="white", xlab="Note test math", ylab="Densit?", main="Test
>> math")
>>
>> ##Add the density curve on the histogram
>> lines(density(newdata$math.test,na.rm=TRUE),lwd=2,col="orange")
>>
>> ##Add the Gauss curve on the histogram x <- seq(from =
>> min(newdata$math.test, na.rm=TRUE), to = max(newdata$math.test,
>> na.rm=TRUE), lines(x, dnorm(x, mean(newdata$math.test, na.rm = TRUE),
>> sd(newdata$math.test, na.rm = TRUE)))


-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From bsmith030465 at gmail.com  Tue Mar 17 15:04:21 2015
From: bsmith030465 at gmail.com (Brian Smith)
Date: Tue, 17 Mar 2015 10:04:21 -0400
Subject: [R] ggplot2 boxplot points (size,color,shape)
Message-ID: <CAEQKoCGUEtibYCk8M5gAaqfkPk5A+TzRLuhZCFR3LYfyLqKfaQ@mail.gmail.com>

Hi,

I am trying to create a boxplot (with geom_jitter) such that the points
from one set of values are shown as circles, and the second set of points
also as circles, but with no fill. In other words, how can I control the
shape and color for the points appearing in this boxplot?

=======
library(ggplot2)

myvect1 <- rnorm(100)
myvect2 <- rnorm(100)

fill1 <- rep('solid',100)
fill2 <- rep('solid',100)

myvect <- c(myvect1,myvect2)
myfill <- c(fill1,fill2)

mydat <- data.frame(myvect,myfill)

## How can I control the shape, color of the points in the boxplot based on
the values of myfill?
ggplot(data=mydat,aes(x='test',y=myvect)) + geom_boxplot() + geom_jitter()

==========

thanks!!

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Mar 17 15:28:23 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Mar 2015 15:28:23 +0100
Subject: [R] ggplot2 boxplot points (size,color,shape)
In-Reply-To: <CAEQKoCGUEtibYCk8M5gAaqfkPk5A+TzRLuhZCFR3LYfyLqKfaQ@mail.gmail.com>
References: <CAEQKoCGUEtibYCk8M5gAaqfkPk5A+TzRLuhZCFR3LYfyLqKfaQ@mail.gmail.com>
Message-ID: <CAJuCY5zFn0Kxj07X4afW0-bSxHWVUVASL_6YKDAgYvUC2rZOow@mail.gmail.com>

You need to set the shape manually

library(ggplot2)
n <- 200
dataset <- data.frame(
  Type = sample(c("A", "B"), n, replace = TRUE),
  Value = rnorm(n)
)
ggplot(dataset, aes(x = Type, y = Value)) + geom_boxplot() +
geom_jitter(aes(shape = Type)) + scale_shape_manual(values = c(1, 19))


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-17 15:04 GMT+01:00 Brian Smith <bsmith030465 at gmail.com>:

> Hi,
>
> I am trying to create a boxplot (with geom_jitter) such that the points
> from one set of values are shown as circles, and the second set of points
> also as circles, but with no fill. In other words, how can I control the
> shape and color for the points appearing in this boxplot?
>
> =======
> library(ggplot2)
>
> myvect1 <- rnorm(100)
> myvect2 <- rnorm(100)
>
> fill1 <- rep('solid',100)
> fill2 <- rep('solid',100)
>
> myvect <- c(myvect1,myvect2)
> myfill <- c(fill1,fill2)
>
> mydat <- data.frame(myvect,myfill)
>
> ## How can I control the shape, color of the points in the boxplot based on
> the values of myfill?
> ggplot(data=mydat,aes(x='test',y=myvect)) + geom_boxplot() + geom_jitter()
>
> ==========
>
> thanks!!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Mar 17 18:01:32 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 17 Mar 2015 10:01:32 -0700
Subject: [R] Returning to parent function
In-Reply-To: <CAJDot1rYHbGM741ga9=tjiSuji1e7LjNUrXW+Rc2iisfERuY0w@mail.gmail.com>
References: <CAJDot1o7eiHpT9DSRVqkMc69v3Bj2f4zcy+hE_rZfEDvN156dQ@mail.gmail.com>
	<469EB8B8-78B7-4FA1-9872-5B26D7DF83B3@comcast.net>
	<CAJDot1rYHbGM741ga9=tjiSuji1e7LjNUrXW+Rc2iisfERuY0w@mail.gmail.com>
Message-ID: <1343CA06-3D6A-4822-84FE-3A5062947071@comcast.net>


On Mar 16, 2015, at 5:05 PM, Saptarshi Guha wrote:

> Example was complicated, but here is a simpler form
> 
> continueIfTrue <- function(mm=return()){
>    eval(mm)
> }

What are you trying to accomplish by passing `return()` to a formal parameter?


> telemStats <- function(){
>    y <- substitute(return())

That last bit of code doesn't make a lot of sense either. The `substitute` function is specifically designed to NOT evaluate the first argument but rather to return an unevaluated call. If you wanted to actually "return" from that function you would assuredly not use `return` within the substitute argument.

You need to explain what you want to accomplish  rather than posting failed code.

-- 
David.


>    continueIfTrue(y)
>    print("I would not like this message to be printed")
> }
> telemStats()
> 
> 
> Ideally, calling telemStats() should return to the prompt and the
> print in telemStats should not appear
> 
> 
> On Mon, Mar 16, 2015 at 4:02 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Mar 16, 2015, at 3:08 PM, Saptarshi Guha wrote:
>> 
>>> Hello,
>>> 
>>> I would like a function X to return to the place that called the
>>> function XParent that called this function X.
>>> 
>>> Y calls XParent
>>> Y = function(){
>>> XParent()
>>> print("hello")
>>> }
>>> 
>>> XParent calls X
>>> 
>>> XParent = function(){
>>>  X()
>>>  print("H")
>>> }
>>> 
>>> X returns to the point just after the call to XParent. Hence
>>> print("H") is not called, but instead "hello" is printed.
>> 
>> ?sys.call # my second reading of your question makes me think this wasn't what was requested.
>> 
>> ?return  # this would do what was asked for
>> 
>>> XParent = function(){
>> +   return(sys.call())
>> +   print("H")
>> + }
>>> Y()
>> [1] "hello"
>> 
>> # Success
>> # now to show that a value could be returned if desired
>> 
>>> Y = function(){
>> +  print(XParent())
>> +  print("hello")
>> + }
>>> XParent = function(){
>> +   return(sys.call())
>> +   print("H")
>> + }
>>> Y()
>> XParent()
>> [1] "hello"
>> 
>> 
>>> 
>>> X returns to the point just after the call to XParent. Hence
>>> print("H") is not called, but instead "hello" is printed.
>>> 
>>> An example of what i'm going for is this
>>> 
>>> continueIfTrue <- function(filterExp, grpname, subname,n=1){
>>>   y <- substitute(filterExp)
>>>   res <- isn(eval(y, envir=parent.frame()),FALSE)
>>>   ## if res is FALSE, I would like to return from telemStats
>>> }
>>> 
>>> telemStats <- function(a,b){
>>>   b <- c(10,12)
>>>   continueIfTrue( {    length(b) >=10 }, "progStats","00")
>>>   print("Since the above condition failed, I would not like this
>>> message to be printed")
>>> }
>> 
>> I'm afraid there were too many undefined objects to make much sense of that example.
>> 
>>> 
>>> I looked into callCC and signals but dont think i understood correctly.
>>> Any hints would be appreciated
>>> 
>>> Kind Regards
>>> Saptarshi
>>> 
>> --
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From pertsou at gmail.com  Tue Mar 17 18:52:42 2015
From: pertsou at gmail.com (Endy BlackEndy)
Date: Tue, 17 Mar 2015 19:52:42 +0200
Subject: [R] Problem with paxckage "survMisc"
Message-ID: <CAGpBJKQM79N+5Ukc2W8mPf2BtVTBY0Aopgbg37Vd=HDKJnfjJg@mail.gmail.com>

Hi R users. I would like your help on the following strange, to me,
behavior of the package "survMisc".
I have a simple routine, the following:
 proc<-function(){
  rm(list=ls())
  library(survMisc)
  d<-read.table("C:\\Program
Files\\R\\Data\\Survival\\HosmLem.txt",fill=TRUE,header=TRUE)
  d4<-as.factor(d[,4])
  s<-survfit(Surv(d[,2], d[,5])~d4)
  ctest<-comp(s)$tests
  print(ctest)
}
When I run it as a routine I am  getting the following message:
Error in Surv(d[, 2], d[, 5]) : object 'd' not found
When I run it command-by-command the program works OK.
Any suggestion what it is going wrong?

The first six lines of the data used are

 id Time Age Drug Censor    entdate    enddate
1  1    5  46    0      1 05/15/1990 10/14/1990
2  2    6  35    1      0 09/19/1989 03/20/1990
3  3    8  30    1      1 04/21/1991 12/20/1991
4  4    3  30    1      1 01/03/1991 04/04/1991
5  5   22  36    0      1 09/18/1989 07/19/1991
6  6    1  32    1      0 03/18/1991 04/17/1991

The full data set can be obtained using the command
 d<-read.table("http://www.ats.ucla.edu/stat/r/examples/asa/hmohiv.csv",
sep=",", header = TRUE)

Many thanks
Endy

	[[alternative HTML version deleted]]


From spencer.graves at prodsyse.com  Tue Mar 17 18:39:06 2015
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 17 Mar 2015 10:39:06 -0700
Subject: [R] Returning to parent function
In-Reply-To: <1343CA06-3D6A-4822-84FE-3A5062947071@comcast.net>
References: <CAJDot1o7eiHpT9DSRVqkMc69v3Bj2f4zcy+hE_rZfEDvN156dQ@mail.gmail.com>	<469EB8B8-78B7-4FA1-9872-5B26D7DF83B3@comcast.net>	<CAJDot1rYHbGM741ga9=tjiSuji1e7LjNUrXW+Rc2iisfERuY0w@mail.gmail.com>
	<1343CA06-3D6A-4822-84FE-3A5062947071@comcast.net>
Message-ID: <550866BA.9010704@prodsyse.com>



On 3/17/2015 10:01 AM, David Winsemius wrote:
> On Mar 16, 2015, at 5:05 PM, Saptarshi Guha wrote:
>
>> Example was complicated, but here is a simpler form
>>
>> continueIfTrue <- function(mm=return()){
>>     eval(mm)
>> }
> What are you trying to accomplish by passing `return()` to a formal parameter?


       Might returning a logical serve your purpose?  Then you could say 
"if(!continueIfTrue(...))return(...)".  Will this do what you want?


       Spencer
>
>> telemStats <- function(){
>>     y <- substitute(return())
> That last bit of code doesn't make a lot of sense either. The `substitute` function is specifically designed to NOT evaluate the first argument but rather to return an unevaluated call. If you wanted to actually "return" from that function you would assuredly not use `return` within the substitute argument.
>
> You need to explain what you want to accomplish  rather than posting failed code.
>


From acefix at rocketmail.com  Tue Mar 17 20:06:16 2015
From: acefix at rocketmail.com (Fix Ace)
Date: Tue, 17 Mar 2015 19:06:16 +0000 (UTC)
Subject: [R] density plot not smooth
In-Reply-To: <599978862.149354.1426609555997.JavaMail.yahoo@mail.yahoo.com>
References: <599978862.149354.1426609555997.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <682643192.200221.1426619176732.JavaMail.yahoo@mail.yahoo.com>



 I have a dataset with 6187 elements, ranged from 3 to 104028. When I tried to examine only small range of data, I found that the plot was not smooth (as shown below):
plot(density(test$V2), xlim=c(0,1000))


?Is there away to make it smoother?
Thanks a lot!!

?


?



  
-------------- next part --------------
A non-text attachment was scrubbed...
Name: datauri-file.png
Type: image/png
Size: 26793 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150317/d2c4d84b/attachment.png>

From wdunlap at tibco.com  Tue Mar 17 22:06:13 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 17 Mar 2015 14:06:13 -0700
Subject: [R] density plot not smooth
In-Reply-To: <682643192.200221.1426619176732.JavaMail.yahoo@mail.yahoo.com>
References: <599978862.149354.1426609555997.JavaMail.yahoo@mail.yahoo.com>
	<682643192.200221.1426619176732.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAF8bMcYeV2S3EFiSP-n_heTbmux8dgNYjmWqrkEwLUWvVVXomA@mail.gmail.com>

Increasing the value of 'n' given to density will give an estimate at more
points so it will look smoother.  Try n=2^18.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Mar 17, 2015 at 12:06 PM, Fix Ace <acefix at rocketmail.com> wrote:

>
>
>  I have a dataset with 6187 elements, ranged from 3 to 104028. When I
> tried to examine only small range of data, I found that the plot was not
> smooth (as shown below):
> plot(density(test$V2), xlim=c(0,1000))
>
>
>  Is there away to make it smoother?
> Thanks a lot!!
>
>
>
>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Wed Mar 18 01:22:46 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 17 Mar 2015 17:22:46 -0700
Subject: [R] Returning to parent function
In-Reply-To: <550866BA.9010704@prodsyse.com>
References: <CAJDot1o7eiHpT9DSRVqkMc69v3Bj2f4zcy+hE_rZfEDvN156dQ@mail.gmail.com>
	<469EB8B8-78B7-4FA1-9872-5B26D7DF83B3@comcast.net>
	<CAJDot1rYHbGM741ga9=tjiSuji1e7LjNUrXW+Rc2iisfERuY0w@mail.gmail.com>
	<1343CA06-3D6A-4822-84FE-3A5062947071@comcast.net>
	<550866BA.9010704@prodsyse.com>
Message-ID: <CACk-te2n0RiHOcyyXA6U7fLqDBUue+zq4nbU6A0J6Q5dzZyOeg@mail.gmail.com>

With all due respect:

I don't think much respect is due. I doubt that the OP has made much of an
effort to learn R and is merely trying to slap on some prior CS class
concepts onto R. Ergo the confusion and nonsensical post.


http://www.jabberwocky.com/carroll/jabber/jabberwocky.html

seems relevant here.

Cheers,

Bert


On Tuesday, March 17, 2015, Spencer Graves <spencer.graves at prodsyse.com>
wrote:

>
>
> On 3/17/2015 10:01 AM, David Winsemius wrote:
>
>> On Mar 16, 2015, at 5:05 PM, Saptarshi Guha wrote:
>>
>>  Example was complicated, but here is a simpler form
>>>
>>> continueIfTrue <- function(mm=return()){
>>>     eval(mm)
>>> }
>>>
>> What are you trying to accomplish by passing `return()` to a formal
>> parameter?
>>
>
>
>       Might returning a logical serve your purpose?  Then you could say
> "if(!continueIfTrue(...))return(...)".  Will this do what you want?
>
>
>       Spencer
>
>>
>>  telemStats <- function(){
>>>     y <- substitute(return())
>>>
>> That last bit of code doesn't make a lot of sense either. The
>> `substitute` function is specifically designed to NOT evaluate the first
>> argument but rather to return an unevaluated call. If you wanted to
>> actually "return" from that function you would assuredly not use `return`
>> within the substitute argument.
>>
>> You need to explain what you want to accomplish  rather than posting
>> failed code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
Clifford Stoll

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Mar 18 01:38:07 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 17 Mar 2015 17:38:07 -0700
Subject: [R] Returning to parent function
In-Reply-To: <CAJDot1o7eiHpT9DSRVqkMc69v3Bj2f4zcy+hE_rZfEDvN156dQ@mail.gmail.com>
References: <CAJDot1o7eiHpT9DSRVqkMc69v3Bj2f4zcy+hE_rZfEDvN156dQ@mail.gmail.com>
Message-ID: <3784CF83-0848-4490-9CFD-F71EAF91855D@dcn.davis.CA.us>

Perhaps read ?try
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 16, 2015 3:08:35 PM PDT, Saptarshi Guha <saptarshi.guha at gmail.com> wrote:
>Hello,
>
>I would like a function X to return to the place that called the
>function XParent that called this function X.
>
>Y calls XParent
>Y = function(){
>  XParent()
>  print("hello")
>}
>
>XParent calls X
>
>XParent = function(){
>   X()
>   print("H")
>}
>
>X returns to the point just after the call to XParent. Hence
>print("H") is not called, but instead "hello" is printed.
>
>An example of what i'm going for is this
>
>continueIfTrue <- function(filterExp, grpname, subname,n=1){
>    y <- substitute(filterExp)
>    res <- isn(eval(y, envir=parent.frame()),FALSE)
>    ## if res is FALSE, I would like to return from telemStats
>}
>
>telemStats <- function(a,b){
>    b <- c(10,12)
>    continueIfTrue( {    length(b) >=10 }, "progStats","00")
>    print("Since the above condition failed, I would not like this
>message to be printed")
>}
>
>I looked into callCC and signals but dont think i understood correctly.
>Any hints would be appreciated
>
>Kind Regards
>Saptarshi
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Mar 18 01:42:59 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 18 Mar 2015 13:42:59 +1300
Subject: [R] Returning to parent function
In-Reply-To: <CACk-te2n0RiHOcyyXA6U7fLqDBUue+zq4nbU6A0J6Q5dzZyOeg@mail.gmail.com>
References: <CAJDot1o7eiHpT9DSRVqkMc69v3Bj2f4zcy+hE_rZfEDvN156dQ@mail.gmail.com>	<469EB8B8-78B7-4FA1-9872-5B26D7DF83B3@comcast.net>	<CAJDot1rYHbGM741ga9=tjiSuji1e7LjNUrXW+Rc2iisfERuY0w@mail.gmail.com>	<1343CA06-3D6A-4822-84FE-3A5062947071@comcast.net>	<550866BA.9010704@prodsyse.com>
	<CACk-te2n0RiHOcyyXA6U7fLqDBUue+zq4nbU6A0J6Q5dzZyOeg@mail.gmail.com>
Message-ID: <5508CA13.3010702@auckland.ac.nz>


On 18/03/15 13:22, Bert Gunter wrote:

> With all due respect:
>
> I don't think much respect is due.

<SNIP>


Fortune nomination!

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From mtmorgan at fredhutch.org  Wed Mar 18 02:15:18 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Tue, 17 Mar 2015 18:15:18 -0700
Subject: [R] Returning to parent function
In-Reply-To: <CAJDot1rYHbGM741ga9=tjiSuji1e7LjNUrXW+Rc2iisfERuY0w@mail.gmail.com>
References: <CAJDot1o7eiHpT9DSRVqkMc69v3Bj2f4zcy+hE_rZfEDvN156dQ@mail.gmail.com>	<469EB8B8-78B7-4FA1-9872-5B26D7DF83B3@comcast.net>
	<CAJDot1rYHbGM741ga9=tjiSuji1e7LjNUrXW+Rc2iisfERuY0w@mail.gmail.com>
Message-ID: <5508D1A6.70308@fredhutch.org>

On 03/16/2015 05:05 PM, Saptarshi Guha wrote:
> Example was complicated, but here is a simpler form
>
> continueIfTrue <- function(mm=return()){
>      eval(mm)
> }
> telemStats <- function(){
>      y <- substitute(return())
>      continueIfTrue(y)
>      print("I would not like this message to be printed")
> }
> telemStats()
>
>
> Ideally, calling telemStats() should return to the prompt and the
> print in telemStats should not appear

here's one way to implement your original example -- signal and handle, via 
tryCatch(), a custom condition created (modelled after simpleCondition()) as an 
S3 class with linear inheritance.

X <- function() {
     print("I'm saying...")
     signalCondition(structure(list(), class=c("my", "condition")))
     print("X")
}

Y <- function(){
     tryCatch(XParent(), my=function(...) NULL)
     print("hello")
}

XParent <- function(){
     X()
     print("H")
}

leading to

   > Y()
   [1] "I'm saying..."
   [1] "hello"

callCC() is tricky for me to grasp, but I'll write Y to accept an argument X, 
which will be a function. It'll call XParent with that function, and XParent 
will use the function.

Y <- function(X){
     XParent(X)
     print("hello")
}

XParent <- function(X){
     X("fun")
     print("H")
}

then we've got

   > Y(X)
   Error in XParent(X) (from tmp.R!4361C1Y#2) : object 'X' not found
   > Y(function(x) print("X"))
   [1] "X"
   [1] "H"
   [1] "hello"

but more interestingly the long jump to the top (where callCC was invoked)

   > callCC(function(X) { Y(X) })
   [1] "fun"

or in a function

   y <- function() {
       value <- callCC(function(X) {
           Y(X)
       })
       print(value)
       print("done")
   }

Hope that helps and is not too misleading. Excellent question.

Martin

>
>
> On Mon, Mar 16, 2015 at 4:02 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>> On Mar 16, 2015, at 3:08 PM, Saptarshi Guha wrote:
>>
>>> Hello,
>>>
>>> I would like a function X to return to the place that called the
>>> function XParent that called this function X.
>>>
>>> Y calls XParent
>>> Y = function(){
>>>   XParent()
>>>   print("hello")
>>> }
>>>
>>> XParent calls X
>>>
>>> XParent = function(){
>>>    X()
>>>    print("H")
>>> }
>>>
>>> X returns to the point just after the call to XParent. Hence
>>> print("H") is not called, but instead "hello" is printed.
>>
>> ?sys.call # my second reading of your question makes me think this wasn't what was requested.
>>
>> ?return  # this would do what was asked for
>>
>>> XParent = function(){
>> +   return(sys.call())
>> +   print("H")
>> + }
>>> Y()
>> [1] "hello"
>>
>> # Success
>> # now to show that a value could be returned if desired
>>
>>> Y = function(){
>> +  print(XParent())
>> +  print("hello")
>> + }
>>> XParent = function(){
>> +   return(sys.call())
>> +   print("H")
>> + }
>>> Y()
>> XParent()
>> [1] "hello"
>>
>>
>>>
>>> X returns to the point just after the call to XParent. Hence
>>> print("H") is not called, but instead "hello" is printed.
>>>
>>> An example of what i'm going for is this
>>>
>>> continueIfTrue <- function(filterExp, grpname, subname,n=1){
>>>     y <- substitute(filterExp)
>>>     res <- isn(eval(y, envir=parent.frame()),FALSE)
>>>     ## if res is FALSE, I would like to return from telemStats
>>> }
>>>
>>> telemStats <- function(a,b){
>>>     b <- c(10,12)
>>>     continueIfTrue( {    length(b) >=10 }, "progStats","00")
>>>     print("Since the above condition failed, I would not like this
>>> message to be printed")
>>> }
>>
>> I'm afraid there were too many undefined objects to make much sense of that example.
>>
>>>
>>> I looked into callCC and signals but dont think i understood correctly.
>>> Any hints would be appreciated
>>>
>>> Kind Regards
>>> Saptarshi
>>>
>> --
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From miaojpm at gmail.com  Wed Mar 18 02:16:08 2015
From: miaojpm at gmail.com (jpm miao)
Date: Wed, 18 Mar 2015 09:16:08 +0800
Subject: [R] Segmented (piecewise linear) regression/cointegration
Message-ID: <CABcx46AaLbShh=EQkOaqApU+aHd1y1ZxnSKH3eESGVcDU3hgvQ@mail.gmail.com>

Hi,

   If the relation between y and x is piecewise linear, the package
"segmented" can be used to model it. It works pretty well.

   My situation is a little different: y and x are both I(1). Is there an
R-package dealing with this situation? If not, is there an econometrics
paper on this issue? Some papers deal with the case in which the relation
between x and y changes at a certain time point, but my case is different-
the relation between x and y changes when x exceeds some break point.



Thanks!

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Mar 18 03:26:18 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 17 Mar 2015 19:26:18 -0700
Subject: [R] density plot not smooth
In-Reply-To: <1682107333.291149.1426644156470.JavaMail.yahoo@mail.yahoo.com>
References: <CAF8bMcYeV2S3EFiSP-n_heTbmux8dgNYjmWqrkEwLUWvVVXomA@mail.gmail.com>
	<1682107333.291149.1426644156470.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAF8bMcaSTPHroy+1N7LN-Cs5W7JuoQucvcQfekTn5edYJQEHVg@mail.gmail.com>

Fix Ace wrote
    What is the default "n"?

512:
   > length(density(rnorm(10^6))$x)
   [1] 512
   > args(density.default)
   function (x, bw = "nrd0", adjust = 1, kernel = c("gaussian",
       "epanechnikov", "rectangular", "triangular", "biweight",
       "cosine", "optcosine"), weights = NULL, window = kernel,
       width, give.Rkern = FALSE, n = 512, from, to, cut = 3, na.rm =
FALSE,
       ...)
   NULL
   > ?density # or ?density.default, should also tell you about its meaning


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Mar 17, 2015 at 7:02 PM, Fix Ace <acefix at rocketmail.com> wrote:

> Thank you for the email.
>
> What is the default "n"?
>
> Thanks!
>
>
>
>   On Tuesday, March 17, 2015 4:06 PM, William Dunlap <wdunlap at tibco.com>
> wrote:
>
>
> Increasing the value of 'n' given to density will give an estimate at more
> points so it will look smoother.  Try n=2^18.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Mar 17, 2015 at 12:06 PM, Fix Ace <acefix at rocketmail.com> wrote:
>
>
>
>  I have a dataset with 6187 elements, ranged from 3 to 104028. When I
> tried to examine only small range of data, I found that the plot was not
> smooth (as shown below):
> plot(density(test$V2), xlim=c(0,1000))
>
>
>  Is there away to make it smoother?
> Thanks a lot!!
>
>
>
>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From YBODIEN at partners.org  Wed Mar 18 00:00:57 2015
From: YBODIEN at partners.org (Bodien, Yelena Guller)
Date: Tue, 17 Mar 2015 23:00:57 +0000
Subject: [R] Sensitivity calculations and ROC curves
Message-ID: <9FE62033-6726-4ACF-96AB-9211D80DE7C7@PARTNERS.ORG>

Dear R gurus,

I have some data that require sensitivity and specificity calculation and generation of an ROC curve. I first calculated the sensitivity and specificity in Excel using generic formulas (true positives/(true positive+false negative) etc. To make the ROC curves I switched to R and used the pROC package. However, the sensitivity and specificity values that the data berate through pROC are not the same as excel. I have tried the different "methods" in pROC and checked that the data are correctly represented in R. Is the R calculation different from the traditional calculations of true positive and true negative rate?

Thanks in advance for your help!

Y 


Sent from a mobile device.


The information in this e-mail is intended only for the ...{{dropped:11}}


From glennmschultz at me.com  Wed Mar 18 02:07:54 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Wed, 18 Mar 2015 01:07:54 +0000 (GMT)
Subject: [R] ggplot2 recycle color palette
Message-ID: <43c56325-37c5-452f-a9e0-a6c314706b73@me.com>

Hello All,?

I have a custom color palette as illustrated below. ? I have more than 8 variables. ?In the case of more than 8 variables I would simply like to recycle the color. ?Has anyone done this or know of a way to have to colors recycle if there are more than 8 variables.

Best Regards,
Glenn
cbbPalette <- c("#E69F00",?
? ? ? ? ? ? ? ? "#56B4E9",?
? ? ? ? ? ? ? ? "#009E73",?
? ? ? ? ? ? ? ? "#F0E442",?
? ? ? ? ? ? ? ? "#0072B2",?
? ? ? ? ? ? ? ? "#D55E00",?
? ? ? ? ? ? ? ? "#CC79A7",?
? ? ? ? ? ? ? ? "#000000")

From juliosergio at gmail.com  Wed Mar 18 02:41:35 2015
From: juliosergio at gmail.com (Julio Sergio Santana)
Date: Wed, 18 Mar 2015 01:41:35 +0000
Subject: [R] Using split.screen with a definition matrix of the screens
	seems to be a mess. I don't understand!
Message-ID: <loom.20150318T022620-475@post.gmane.org>

I have a particular need to divide the device space to draw different plots
and texts, so I decided to use split.screen using a matrix to define the
different space partitions. 

My code and explanation is as follows:

# ------ START OF R CODE ----

dirGraf <- "TEST/" # A directory to put the result

nc <- 4 # number of data screens

tit <- "My title"
righttext <- "right text"
lefttext <- "left text"

# To ensure there are no graphics devices on:
graphics.off()

# I want to create 7 plotting windows (screens) with the following 
# arrangement
# I'm supposing the NDC coordinates are such that the lower-left corner
# is at (0,0) and the upper-right corner is at (1,1). Am I right?
#
#       +-----------------------------------+ (1,1)
#       |                 5    h=0.5/5.5    |
#       +--+-----------------------------+--+
#       |  |              1    h=1.0/5.5 |  |
#       |  +-----------------------------+  |
#       |  |              2    h=1.0/5.5 |  |
#       |  +-----------------------------+  |
#       |  |              3    h=1.0/5.5 |  |
#       |6 +-----------------------------+ 7|
#       |  |                             |  |
#       |  |              4    h=2.0/5.5 |  |
#       |  |                             |  |
#       +--+-----------------------------+--+
#    (0,0)
#
# I want 4 information (central) windows, from 1 to 4. However these windows
# must vary in their heights, because window 4 is twice the 
# height the others.
# I want an upper window to put a title to the whole plot, and two 
# lateral windows to add some texts.
#
# So I will build a four-column matrix, as instructed by the split.screen 
# documentation. Each column correspond in order to the following 
# characteristics, of each window (represented by each row), namely:
# 1. left, 2. right, 3. bottom, 4. top.
#

# First I will create a vector with the first four windows heights
Yinc <- c(2, rep(1,3))/5.5 
# To have the NDC device coordinates (?) I will accumulate:
Yinc <- Reduce('+', Yinc, accumulate=T)
# To put this information in the right window order I invert the vector
Yinc <- Yinc[4:1] 
# Then I will build the matrix for the first four windows:
Mm <- cbind(left=1/6, right=5/6, bottom=c(Yinc[2:4],0), top=Yinc)
# Now, let's add upper and lateral windows (screens 5 to 7)
Mm <- rbind(Mm, 
            # +--------+--------+--------+--------+
            # | left   | right  | bottom |   top  |
            # +--------+--------+--------+--------+
            c(   0    ,   1    , Yinc[1],    1   ),
            c(   0    ,  1/6   ,   0    , Yinc[1]),
            c(  5/6   ,   1    ,   0    , Yinc[1])
)

# margins for most of the cases
gpar <- list(mar=c(0,2.1,0,0))

# the device name (a pdf file)
gname <- paste0(dirGraf, "Test.pdf") 

# Test table to plot, just a line from (0,0) to (1,1)
tt <- data.frame(x=c(0,1), y=c(0,1))
# Let's open the device:
pdf(gname, width=7, height=9.11) 
# Let's split the device space (I think this is the default, isn't it?)
split.screen(Mm)

# Let's put a title in the upper window
screen(5)
par(gpar)
plot(c(0,1), c(0,1), ylab="", axes=F, type="n")
text(0.5, 0.5, tit, cex=1.5)

# For each "data" window
for (ii in 1:nc) { 
    screen(ii) # select screen 1 to 4
    par(gpar)
 
    plot(tt, ylab=LETTERS[ii], xlab="", type="l", xaxt="n")   
}
# A text in the left window
screen(6)
par(mar=c(0.1,0.1,0.1,0.1))
plot(c(0,1), c(0,1), axes=F, type="n")
text(0.5, 0.5, lefttext, srt=90, cex=1.2)
# A text in the right window
screen(7)
par(mar=c(0.1,0.1,0.1,0.1))
plot(c(0,1), c(0,1), axes=F, type="n")
text(0.5, 0.5, righttext, srt=90, cex=1.2)
# close graphics
graphics.off()

# ------ END OF R CODE ----------------

At the end I have a totally messy pdf file with the four main windows
at the top and with no difference in their heights, and the other windows
in any place R (not me) chose to put them.

Furthermore the R interpreter issues a message:

 "In par(new = TRUE) : call par(new=TRUE) without graphic"

Do you have any comments on this?

Thanks a lot!
  -Sergio.


From acefix at rocketmail.com  Wed Mar 18 03:02:36 2015
From: acefix at rocketmail.com (Fix Ace)
Date: Wed, 18 Mar 2015 02:02:36 +0000 (UTC)
Subject: [R] density plot not smooth
In-Reply-To: <CAF8bMcYeV2S3EFiSP-n_heTbmux8dgNYjmWqrkEwLUWvVVXomA@mail.gmail.com>
References: <CAF8bMcYeV2S3EFiSP-n_heTbmux8dgNYjmWqrkEwLUWvVVXomA@mail.gmail.com>
Message-ID: <1682107333.291149.1426644156470.JavaMail.yahoo@mail.yahoo.com>

Thank you for the email.
What is the default "n"?
Thanks! 


     On Tuesday, March 17, 2015 4:06 PM, William Dunlap <wdunlap at tibco.com> wrote:
   

 Increasing the value of 'n' given to density will give an estimate at more points so it will look smoother.? Try n=2^18.
Bill Dunlap
TIBCO Software
wdunlap tibco.com
On Tue, Mar 17, 2015 at 12:06 PM, Fix Ace <acefix at rocketmail.com> wrote:



?I have a dataset with 6187 elements, ranged from 3 to 104028. When I tried to examine only small range of data, I found that the plot was not smooth (as shown below):
plot(density(test$V2), xlim=c(0,1000))


?Is there away to make it smoother?
Thanks a lot!!

?


?



? 
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




  
	[[alternative HTML version deleted]]


From lucam1968 at gmail.com  Wed Mar 18 07:17:32 2015
From: lucam1968 at gmail.com (Luca Meyer)
Date: Wed, 18 Mar 2015 07:17:32 +0100
Subject: [R] Joining two datasets - recursive procedure?
Message-ID: <CABQyo84Jm3w7-ZuFf2snJsQXJO1j1oyPDpthx9ADbqNxYm7=Fg@mail.gmail.com>

Hello,

I am facing a quite challenging task (at least to me) and I was wondering
if someone could advise how R could assist me to speed the task up.

I am dealing with a dataset with 3 discrete variables and one continuous
variable. The discrete variables are:

V1: 8 modalities
V2: 13 modalities
V3: 13 modalities

The continuous variable V4 is a decimal number always greater than zero in
the marginals of each of the 3 variables but it is sometimes equal to zero
(and sometimes negative) in the joint tables.

I have got 2 files:

=> one with distribution of all possible combinations of V1xV2 (some of
which are zero or neagtive) and
=> one with the marginal distribution of V3.

I am trying to build the long and narrow dataset V1xV2xV3 in such a way
that each V1xV2 cell does not get modified and V3 fits as closely as
possible to its marginal distribution. Does it make sense?

To be even more specific, my 2 input files look like the following.

FILE 1
V1,V2,V4
A, A, 24.251
A, B, 1.065
(...)
B, C, 0.294
B, D, 2.731
(...)
H, L, 0.345
H, M, 0.000

FILE 2
V3, V4
A, 1.575
B, 4.294
C, 10.044
(...)
L, 5.123
M, 3.334

What I need to achieve is a file such as the following

FILE 3
V1, V2, V3, V4
A, A, A, ???
A, A, B, ???
(...)
D, D, E, ???
D, D, F, ???
(...)
H, M, L, ???
H, M, M, ???

Please notice that FILE 3 need to be such that if I aggregate on V1+V2 I
recover exactly FILE 1 and that if I aggregate on V3 I can recover a file
as close as possible to FILE 3 (ideally the same file).

Can anyone suggest how I could do that with R?

Thank you very much indeed for any assistance you are able to provide.

Kind regards,

Luca

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Wed Mar 18 09:01:18 2015
From: miaojpm at gmail.com (jpm miao)
Date: Wed, 18 Mar 2015 16:01:18 +0800
Subject: [R] An easy question on package building/installation
Message-ID: <CABcx46Ct-mACp+sGxeXBMLtu2TxYJ+c3y08LLz=rOTkRq6xKEQ@mail.gmail.com>

Hi,

   I try to build a package myself on RStudio. The command
"package.skeleton" is successfully run, but the command "build" is not. In
my case, the username and the package name are both "abcd".

   Error message:

> R CMD build abcd

Error: unexpected symbol in "R CMD"

>

    Could someone help me to write a correct "build" command?

    Thanks! Full log:


> setwd("D:/0B/R/pkg-abcd")

> setwd("D:/0B/R/pkg-abcd")

> package.skeleton(name="abcd")

Creating directories ...

Creating DESCRIPTION ...

Creating NAMESPACE ...

Creating Read-and-delete-me ...

Saving functions and data ...

Making help files ...

Done.

Further steps are described in './abcd/Read-and-delete-me'.

  > setwd("D:/0B/R/pkg-abcd/abcd")

> dir()

[1] "data"               "DESCRIPTION"        "man"

[4] "NAMESPACE"          "R"                  "Read-and-delete-me"

>



> .libPaths()

[1] "C:/Users/abcd/Documents/R/win-library/3.0"

[2] "C:/Program Files/R/R-3.0.1/library"

>



> R CMD build abcd

Error: unexpected symbol in "R CMD"

> R CMD build C:\Users\abcd\Documents\R\win-library\3.0

Error: unexpected symbol in "R CMD"

> R CMD INSTALL -1 C:/Users/abcd/Documents/R/win-library/3.0 abcd

Error: unexpected symbol in "R CMD

	[[alternative HTML version deleted]]


From abhinabaroy09 at gmail.com  Wed Mar 18 09:23:25 2015
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Wed, 18 Mar 2015 13:53:25 +0530
Subject: [R] Identification of QRS complex from ECG data
Message-ID: <CANtKHPW3mLEAcZH1DhNXkZWy3q-uUEq-nAmtkcx5mDfE=hVKoA@mail.gmail.com>

Hi R helpers,

I was going through some documents, which explains a few algorithms (e.g.,
Pan Tomkins algo) for identification of QRS complex and how it is
implemented in R. Also the logic used is not very clear.

Could you please provide me with an R code to identify the QRS complex?

Any help is much appreciated

Regards,
Novice R User

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Mar 18 10:02:05 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 18 Mar 2015 20:02:05 +1100
Subject: [R] Using split.screen with a definition matrix of the screens
 seems to be a mess. I don't understand!
In-Reply-To: <loom.20150318T022620-475@post.gmane.org>
References: <loom.20150318T022620-475@post.gmane.org>
Message-ID: <CA+8X3fX96zgWZwvr0J96x2k-nWoy9VRNL5wuR=TM+STFq6=4NA@mail.gmail.com>

Hi Sergio,
In order to get this configuration you will have to do multiple splits. Try
this to see how you get what you want, and notice that screens 2 and 4 are
now unusable as they have been split to make more screens.

split.screen(figs=matrix(c(0,1,0.91,1,0,1,0,0.91),nrow=2,byrow=TRUE))
split.screen(figs=matrix(c(0,0.09,0,1,0.09,0.91,0,1,0.91,1,0,1),nrow=3,
 byrow=TRUE),screen=2)
split.screen(figs=matrix(c(0,1,0.8,1,0,1,0.6,0.8,0,1,0.4,0.6,0,1,0,0.4),
 nrow=4,byrow=TRUE),screen=4)
screen(1)
par(mar=c(0,0,0,0))
plot(1:2,type="n",axes=FALSE)
box()
text(1.5,1.5,1)
screen(3)
par(mar=c(0,0,0,0))
plot(1:2,type="n",axes=FALSE)
box()
text(1.5,1.5,3)
screen(5)
par(mar=c(0,0,0,0))
plot(1:2,type="n",axes=FALSE)
box()
text(1.5,1.5,5)
screen(6)
par(mar=c(0,0,0,0))
plot(1:2,type="n",axes=FALSE)
box()
text(1.5,1.5,6)
screen(7)
par(mar=c(0,0,0,0))
plot(1:2,type="n",axes=FALSE)
box()
text(1.5,1.5,7)
screen(8)
par(mar=c(0,0,0,0))
plot(1:2,type="n",axes=FALSE)
box()
text(1.5,1.5,8)
screen(9)
par(mar=c(0,0,0,0))
plot(1:2,type="n",axes=FALSE)
box()
text(1.5,1.5,9)

Jim


On Wed, Mar 18, 2015 at 12:41 PM, Julio Sergio Santana <
juliosergio at gmail.com> wrote:

> I have a particular need to divide the device space to draw different plots
> and texts, so I decided to use split.screen using a matrix to define the
> different space partitions.
>
> My code and explanation is as follows:
>
> # ------ START OF R CODE ----
>
> dirGraf <- "TEST/" # A directory to put the result
>
> nc <- 4 # number of data screens
>
> tit <- "My title"
> righttext <- "right text"
> lefttext <- "left text"
>
> # To ensure there are no graphics devices on:
> graphics.off()
>
> # I want to create 7 plotting windows (screens) with the following
> # arrangement
> # I'm supposing the NDC coordinates are such that the lower-left corner
> # is at (0,0) and the upper-right corner is at (1,1). Am I right?
> #
> #       +-----------------------------------+ (1,1)
> #       |                 5    h=0.5/5.5    |
> #       +--+-----------------------------+--+
> #       |  |              1    h=1.0/5.5 |  |
> #       |  +-----------------------------+  |
> #       |  |              2    h=1.0/5.5 |  |
> #       |  +-----------------------------+  |
> #       |  |              3    h=1.0/5.5 |  |
> #       |6 +-----------------------------+ 7|
> #       |  |                             |  |
> #       |  |              4    h=2.0/5.5 |  |
> #       |  |                             |  |
> #       +--+-----------------------------+--+
> #    (0,0)
> #
> # I want 4 information (central) windows, from 1 to 4. However these
> windows
> # must vary in their heights, because window 4 is twice the
> # height the others.
> # I want an upper window to put a title to the whole plot, and two
> # lateral windows to add some texts.
> #
> # So I will build a four-column matrix, as instructed by the split.screen
> # documentation. Each column correspond in order to the following
> # characteristics, of each window (represented by each row), namely:
> # 1. left, 2. right, 3. bottom, 4. top.
> #
>
> # First I will create a vector with the first four windows heights
> Yinc <- c(2, rep(1,3))/5.5
> # To have the NDC device coordinates (?) I will accumulate:
> Yinc <- Reduce('+', Yinc, accumulate=T)
> # To put this information in the right window order I invert the vector
> Yinc <- Yinc[4:1]
> # Then I will build the matrix for the first four windows:
> Mm <- cbind(left=1/6, right=5/6, bottom=c(Yinc[2:4],0), top=Yinc)
> # Now, let's add upper and lateral windows (screens 5 to 7)
> Mm <- rbind(Mm,
>             # +--------+--------+--------+--------+
>             # | left   | right  | bottom |   top  |
>             # +--------+--------+--------+--------+
>             c(   0    ,   1    , Yinc[1],    1   ),
>             c(   0    ,  1/6   ,   0    , Yinc[1]),
>             c(  5/6   ,   1    ,   0    , Yinc[1])
> )
>
> # margins for most of the cases
> gpar <- list(mar=c(0,2.1,0,0))
>
> # the device name (a pdf file)
> gname <- paste0(dirGraf, "Test.pdf")
>
> # Test table to plot, just a line from (0,0) to (1,1)
> tt <- data.frame(x=c(0,1), y=c(0,1))
> # Let's open the device:
> pdf(gname, width=7, height=9.11)
> # Let's split the device space (I think this is the default, isn't it?)
> split.screen(Mm)
>
> # Let's put a title in the upper window
> screen(5)
> par(gpar)
> plot(c(0,1), c(0,1), ylab="", axes=F, type="n")
> text(0.5, 0.5, tit, cex=1.5)
>
> # For each "data" window
> for (ii in 1:nc) {
>     screen(ii) # select screen 1 to 4
>     par(gpar)
>
>     plot(tt, ylab=LETTERS[ii], xlab="", type="l", xaxt="n")
> }
> # A text in the left window
> screen(6)
> par(mar=c(0.1,0.1,0.1,0.1))
> plot(c(0,1), c(0,1), axes=F, type="n")
> text(0.5, 0.5, lefttext, srt=90, cex=1.2)
> # A text in the right window
> screen(7)
> par(mar=c(0.1,0.1,0.1,0.1))
> plot(c(0,1), c(0,1), axes=F, type="n")
> text(0.5, 0.5, righttext, srt=90, cex=1.2)
> # close graphics
> graphics.off()
>
> # ------ END OF R CODE ----------------
>
> At the end I have a totally messy pdf file with the four main windows
> at the top and with no difference in their heights, and the other windows
> in any place R (not me) chose to put them.
>
> Furthermore the R interpreter issues a message:
>
>  "In par(new = TRUE) : call par(new=TRUE) without graphic"
>
> Do you have any comments on this?
>
> Thanks a lot!
>   -Sergio.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Mar 18 10:05:03 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 18 Mar 2015 20:05:03 +1100
Subject: [R] ggplot2 recycle color palette
In-Reply-To: <43c56325-37c5-452f-a9e0-a6c314706b73@me.com>
References: <43c56325-37c5-452f-a9e0-a6c314706b73@me.com>
Message-ID: <CA+8X3fVv10NYq2_qmz5N5_XPU_pyW11a7oxtSi4i39dLysBqBw@mail.gmail.com>

Hi Glenn,
An easy way is to replicate the colors to the correct length yourself. If
the number of variables is "nvar", then

newPalette<-rep(cbbPalette,length.out=nvar)

Jim

On Wed, Mar 18, 2015 at 12:07 PM, Glenn Schultz <glennmschultz at me.com>
wrote:

> Hello All,
>
> I have a custom color palette as illustrated below.   I have more than 8
> variables.  In the case of more than 8 variables I would simply like to
> recycle the color.  Has anyone done this or know of a way to have to colors
> recycle if there are more than 8 variables.
>
> Best Regards,
> Glenn
> cbbPalette <- c("#E69F00",
>                 "#56B4E9",
>                 "#009E73",
>                 "#F0E442",
>                 "#0072B2",
>                 "#D55E00",
>                 "#CC79A7",
>                 "#000000")
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Wed Mar 18 11:14:02 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 18 Mar 2015 10:14:02 +0000
Subject: [R] density plot not smooth
In-Reply-To: <682643192.200221.1426619176732.JavaMail.yahoo@mail.yahoo.com>
References: <599978862.149354.1426609555997.JavaMail.yahoo@mail.yahoo.com>
	<682643192.200221.1426619176732.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED672B239B24@GOLD.corp.lgc-group.com>

>  I have a dataset with 6187 elements, ranged from 3 to 104028. When I tried to
> examine only small range of data, I found that the plot was not smooth (as
> shown below):
> plot(density(test$V2), xlim=c(0,1000))
> 
> 
> ?Is there away to make it smoother?

For small ranges, use 'from' and 'to' in density() to restrict the range over which the density is calculated rather than increasing the number of points.

for example

plot(density(test$V2, from=0, to=1000))

This should produce a 512-point density plot for the region of interest only - though you may not find it very interesting for such a small range.... 

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From highstat at highstat.com  Wed Mar 18 12:14:27 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 18 Mar 2015 11:14:27 +0000
Subject: [R] Bayesian course + GLMM course
Message-ID: <55095E13.2020701@highstat.com>

Apologies for cross-posting


There are a few remaining seats on the following two (combined) courses:

Course 1 (3 days): Introduction to Bayesian statistics and MCMC
When: 8-10 April 2015
Where: University of Southampton, Southampton, UK
Course flyer: 
http://www.highstat.com/Courses/Flyer2015_04Southampton_Course2.pdf
URL: http://www.highstat.com/statscourse.htm


Course 2 (5 days): Introduction to Linear Mixed Effects Models and GLMM 
with R
When: 13-17 April 2015
Where: University of Southampton, Southampton, UK
Course flyer: 
http://www.highstat.com/Courses/Flyer2015_04Southampton_Course3.pdf
URL: http://www.highstat.com/statscourse.htm



Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From friendly at yorku.ca  Wed Mar 18 13:10:48 2015
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 18 Mar 2015 08:10:48 -0400
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <CABQyo84Jm3w7-ZuFf2snJsQXJO1j1oyPDpthx9ADbqNxYm7=Fg@mail.gmail.com>
References: <CABQyo84Jm3w7-ZuFf2snJsQXJO1j1oyPDpthx9ADbqNxYm7=Fg@mail.gmail.com>
Message-ID: <55096B48.8000608@yorku.ca>

I'm not sure I understand completely what you want to do, but
if the data were frequencies, it sounds like task for fitting a 
loglinear model with the model formula

~ V1*V2 + V3

On 3/18/2015 2:17 AM, Luca Meyer wrote:
> Hello,
>
> I am facing a quite challenging task (at least to me) and I was wondering
> if someone could advise how R could assist me to speed the task up.
>
> I am dealing with a dataset with 3 discrete variables and one continuous
> variable. The discrete variables are:
>
> V1: 8 modalities
> V2: 13 modalities
> V3: 13 modalities
>
> The continuous variable V4 is a decimal number always greater than zero in
> the marginals of each of the 3 variables but it is sometimes equal to zero
> (and sometimes negative) in the joint tables.
>
> I have got 2 files:
>
> => one with distribution of all possible combinations of V1xV2 (some of
> which are zero or neagtive) and
> => one with the marginal distribution of V3.
>
> I am trying to build the long and narrow dataset V1xV2xV3 in such a way
> that each V1xV2 cell does not get modified and V3 fits as closely as
> possible to its marginal distribution. Does it make sense?
>
> To be even more specific, my 2 input files look like the following.
>
> FILE 1
> V1,V2,V4
> A, A, 24.251
> A, B, 1.065
> (...)
> B, C, 0.294
> B, D, 2.731
> (...)
> H, L, 0.345
> H, M, 0.000
>
> FILE 2
> V3, V4
> A, 1.575
> B, 4.294
> C, 10.044
> (...)
> L, 5.123
> M, 3.334
>
> What I need to achieve is a file such as the following
>
> FILE 3
> V1, V2, V3, V4
> A, A, A, ???
> A, A, B, ???
> (...)
> D, D, E, ???
> D, D, F, ???
> (...)
> H, M, L, ???
> H, M, M, ???
>
> Please notice that FILE 3 need to be such that if I aggregate on V1+V2 I
> recover exactly FILE 1 and that if I aggregate on V3 I can recover a file
> as close as possible to FILE 3 (ideally the same file).
>
> Can anyone suggest how I could do that with R?
>
> Thank you very much indeed for any assistance you are able to provide.
>
> Kind regards,
>
> Luca
>
> 	[[alternative HTML version deleted]]
>


From friendly at yorku.ca  Wed Mar 18 13:10:48 2015
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 18 Mar 2015 08:10:48 -0400
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <CABQyo84Jm3w7-ZuFf2snJsQXJO1j1oyPDpthx9ADbqNxYm7=Fg@mail.gmail.com>
References: <CABQyo84Jm3w7-ZuFf2snJsQXJO1j1oyPDpthx9ADbqNxYm7=Fg@mail.gmail.com>
Message-ID: <55096B48.8000608@yorku.ca>

I'm not sure I understand completely what you want to do, but
if the data were frequencies, it sounds like task for fitting a 
loglinear model with the model formula

~ V1*V2 + V3

On 3/18/2015 2:17 AM, Luca Meyer wrote:
> Hello,
>
> I am facing a quite challenging task (at least to me) and I was wondering
> if someone could advise how R could assist me to speed the task up.
>
> I am dealing with a dataset with 3 discrete variables and one continuous
> variable. The discrete variables are:
>
> V1: 8 modalities
> V2: 13 modalities
> V3: 13 modalities
>
> The continuous variable V4 is a decimal number always greater than zero in
> the marginals of each of the 3 variables but it is sometimes equal to zero
> (and sometimes negative) in the joint tables.
>
> I have got 2 files:
>
> => one with distribution of all possible combinations of V1xV2 (some of
> which are zero or neagtive) and
> => one with the marginal distribution of V3.
>
> I am trying to build the long and narrow dataset V1xV2xV3 in such a way
> that each V1xV2 cell does not get modified and V3 fits as closely as
> possible to its marginal distribution. Does it make sense?
>
> To be even more specific, my 2 input files look like the following.
>
> FILE 1
> V1,V2,V4
> A, A, 24.251
> A, B, 1.065
> (...)
> B, C, 0.294
> B, D, 2.731
> (...)
> H, L, 0.345
> H, M, 0.000
>
> FILE 2
> V3, V4
> A, 1.575
> B, 4.294
> C, 10.044
> (...)
> L, 5.123
> M, 3.334
>
> What I need to achieve is a file such as the following
>
> FILE 3
> V1, V2, V3, V4
> A, A, A, ???
> A, A, B, ???
> (...)
> D, D, E, ???
> D, D, F, ???
> (...)
> H, M, L, ???
> H, M, M, ???
>
> Please notice that FILE 3 need to be such that if I aggregate on V1+V2 I
> recover exactly FILE 1 and that if I aggregate on V3 I can recover a file
> as close as possible to FILE 3 (ideally the same file).
>
> Can anyone suggest how I could do that with R?
>
> Thank you very much indeed for any assistance you are able to provide.
>
> Kind regards,
>
> Luca
>
> 	[[alternative HTML version deleted]]
>


From vito.muggeo at unipa.it  Wed Mar 18 13:38:46 2015
From: vito.muggeo at unipa.it (Vito M. R. Muggeo)
Date: Wed, 18 Mar 2015 13:38:46 +0100
Subject: [R] Segmented (piecewise linear) regression/cointegration
In-Reply-To: <CABcx46AaLbShh=EQkOaqApU+aHd1y1ZxnSKH3eESGVcDU3hgvQ@mail.gmail.com>
References: <CABcx46AaLbShh=EQkOaqApU+aHd1y1ZxnSKH3eESGVcDU3hgvQ@mail.gmail.com>
Message-ID: <550971D6.8090209@unipa.it>

dear jpm,
segmented can't deal with I(1) regression.. However the segmented 
default method could be used on objects fitted by any function which 
fits I(1) *linear* regression,

Please contact me off list for details,
best,
vito



Il 18/03/2015 2.16, jpm miao ha scritto:
> Hi,
>
>     If the relation between y and x is piecewise linear, the package
> "segmented" can be used to model it. It works pretty well.
>
>     My situation is a little different: y and x are both I(1). Is there an
> R-package dealing with this situation? If not, is there an econometrics
> paper on this issue? Some papers deal with the case in which the relation
> between x and y changes at a certain time point, but my case is different-
> the relation between x and y changes when x exceeds some break point.
>
>
>
> Thanks!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
==============================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 23895240
fax: 091 485726
http://dssm.unipa.it/vmuggeo

28th IWSM
International Workshop on Statistical Modelling
July 8-12, 2013, Palermo
http://iwsm2013.unipa.it


From jdnewmil at dcn.davis.CA.us  Wed Mar 18 13:50:35 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 18 Mar 2015 05:50:35 -0700
Subject: [R] An easy question on package building/installation
In-Reply-To: <CABcx46Ct-mACp+sGxeXBMLtu2TxYJ+c3y08LLz=rOTkRq6xKEQ@mail.gmail.com>
References: <CABcx46Ct-mACp+sGxeXBMLtu2TxYJ+c3y08LLz=rOTkRq6xKEQ@mail.gmail.com>
Message-ID: <CA81867F-883F-44E8-A31E-097C51F1F11F@dcn.davis.CA.us>

You appear to be entering that command at the R prompt when it is intended to be entered at the operating system command line. There is a whole document "Writing R Extensions" that you really should be reading no matter what IDE you are using.

Also, details of using RStudio are off topic here, but there is a button/menu item that will execute these commands for you in the GUI of that program. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 18, 2015 1:01:18 AM PDT, jpm miao <miaojpm at gmail.com> wrote:
>Hi,
>
>   I try to build a package myself on RStudio. The command
>"package.skeleton" is successfully run, but the command "build" is not.
>In
>my case, the username and the package name are both "abcd".
>
>   Error message:
>
>> R CMD build abcd
>
>Error: unexpected symbol in "R CMD"
>
>>
>
>    Could someone help me to write a correct "build" command?
>
>    Thanks! Full log:
>
>
>> setwd("D:/0B/R/pkg-abcd")
>
>> setwd("D:/0B/R/pkg-abcd")
>
>> package.skeleton(name="abcd")
>
>Creating directories ...
>
>Creating DESCRIPTION ...
>
>Creating NAMESPACE ...
>
>Creating Read-and-delete-me ...
>
>Saving functions and data ...
>
>Making help files ...
>
>Done.
>
>Further steps are described in './abcd/Read-and-delete-me'.
>
>  > setwd("D:/0B/R/pkg-abcd/abcd")
>
>> dir()
>
>[1] "data"               "DESCRIPTION"        "man"
>
>[4] "NAMESPACE"          "R"                  "Read-and-delete-me"
>
>>
>
>
>
>> .libPaths()
>
>[1] "C:/Users/abcd/Documents/R/win-library/3.0"
>
>[2] "C:/Program Files/R/R-3.0.1/library"
>
>>
>
>
>
>> R CMD build abcd
>
>Error: unexpected symbol in "R CMD"
>
>> R CMD build C:\Users\abcd\Documents\R\win-library\3.0
>
>Error: unexpected symbol in "R CMD"
>
>> R CMD INSTALL -1 C:/Users/abcd/Documents/R/win-library/3.0 abcd
>
>Error: unexpected symbol in "R CMD
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From annalisaorenti at libero.it  Wed Mar 18 15:11:58 2015
From: annalisaorenti at libero.it (Annalisa Orenti)
Date: Wed, 18 Mar 2015 15:11:58 +0100 (CET)
Subject: [R] lqs function for S-estimator
Message-ID: <252791950.5189981426687918449.JavaMail.httpd@webmail-53.iol.local>

Dear R-Users,
I need to fit a regression by means of S-estimator, but I found an 
inconsistency in lqs function in MASS package.
When recalling coefficient estimates two discordant answers are obtained by 
coef() function and by $coef object:
As an example I report here the results of fitting regression S-estimator on 
stackloss data:

library(MASS)
Sestim<-lqs(stack.loss ~ Air.Flow + Water.Temp + Acid.Conc., data = stackloss, 
method = "S")
coef(Sestim)
 (Intercept)            Air.Flow   Water.Temp   Acid.Conc. 
-35.37610619   0.82522124   0.44247788  -0.07964602 
Sestim$coef
                           Air.Flow   Water.Temp   Acid.Conc. 
-36.92530315   0.84957479   0.43047554  -0.07354065 

Do you have any suggestions?
Thank you for your help.
Best regards.
Annalisa


From pdalgd at gmail.com  Wed Mar 18 16:38:45 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 18 Mar 2015 16:38:45 +0100
Subject: [R] lqs function for S-estimator
In-Reply-To: <252791950.5189981426687918449.JavaMail.httpd@webmail-53.iol.local>
References: <252791950.5189981426687918449.JavaMail.httpd@webmail-53.iol.local>
Message-ID: <739A7C2A-8698-427B-8711-34D7CCF4E366@gmail.com>


On 18 Mar 2015, at 15:11 , Annalisa Orenti <annalisaorenti at libero.it> wrote:

> Dear R-Users,
> I need to fit a regression by means of S-estimator, but I found an 
> inconsistency in lqs function in MASS package.
> When recalling coefficient estimates two discordant answers are obtained by 
> coef() function and by $coef object:
> As an example I report here the results of fitting regression S-estimator on 
> stackloss data:
> 
> library(MASS)
> Sestim<-lqs(stack.loss ~ Air.Flow + Water.Temp + Acid.Conc., data = stackloss, 
> method = "S")
> coef(Sestim)
> (Intercept)            Air.Flow   Water.Temp   Acid.Conc. 
> -35.37610619   0.82522124   0.44247788  -0.07964602 
> Sestim$coef
>                           Air.Flow   Water.Temp   Acid.Conc. 
> -36.92530315   0.84957479   0.43047554  -0.07354065 
> 
> Do you have any suggestions?


The immediate reason is that Sestim contains both $coef and $coefficients and coef() extracts the latter. 

Why this is so escapes me. It looks like it might be a blunder, but the package author isn't usually prone to blundering...

-pd

> Thank you for your help.
> Best regards.
> Annalisa
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From lucam1968 at gmail.com  Wed Mar 18 17:05:37 2015
From: lucam1968 at gmail.com (Luca Meyer)
Date: Wed, 18 Mar 2015 17:05:37 +0100
Subject: [R]  Joining two datasets - recursive procedure?
Message-ID: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>

Thanks for you input Michael,

The continuous variable I have measures quantities (down to the 3rd
decimal level) so unfortunately are not frequencies.

Any more specific suggestions on how that could be tackled?

Thanks & kind regards,

Luca


===

Michael Friendly wrote:
I'm not sure I understand completely what you want to do, but
if the data were frequencies, it sounds like task for fitting a
loglinear model with the model formula

~ V1*V2 + V3

On 3/18/2015 2:17 AM, Luca Meyer wrote:
>* Hello,
*>>* I am facing a quite challenging task (at least to me) and I was wondering
*>* if someone could advise how R could assist me to speed the task up.
*>>* I am dealing with a dataset with 3 discrete variables and one continuous
*>* variable. The discrete variables are:
*>>* V1: 8 modalities
*>* V2: 13 modalities
*>* V3: 13 modalities
*>>* The continuous variable V4 is a decimal number always greater than zero in
*>* the marginals of each of the 3 variables but it is sometimes equal to zero
*>* (and sometimes negative) in the joint tables.
*>>* I have got 2 files:
*>>* => one with distribution of all possible combinations of V1xV2 (some of
*>* which are zero or neagtive) and
*>* => one with the marginal distribution of V3.
*>>* I am trying to build the long and narrow dataset V1xV2xV3 in such a way
*>* that each V1xV2 cell does not get modified and V3 fits as closely as
*>* possible to its marginal distribution. Does it make sense?
*>>* To be even more specific, my 2 input files look like the following.
*>>* FILE 1
*>* V1,V2,V4
*>* A, A, 24.251
*>* A, B, 1.065
*>* (...)
*>* B, C, 0.294
*>* B, D, 2.731
*>* (...)
*>* H, L, 0.345
*>* H, M, 0.000
*>>* FILE 2
*>* V3, V4
*>* A, 1.575
*>* B, 4.294
*>* C, 10.044
*>* (...)
*>* L, 5.123
*>* M, 3.334
*>>* What I need to achieve is a file such as the following
*>>* FILE 3
*>* V1, V2, V3, V4
*>* A, A, A, ???
*>* A, A, B, ???
*>* (...)
*>* D, D, E, ???
*>* D, D, F, ???
*>* (...)
*>* H, M, L, ???
*>* H, M, M, ???
*>>* Please notice that FILE 3 need to be such that if I aggregate on V1+V2 I
*>* recover exactly FILE 1 and that if I aggregate on V3 I can recover a file
*>* as close as possible to FILE 3 (ideally the same file).
*>>* Can anyone suggest how I could do that with R?
*>>* Thank you very much indeed for any assistance you are able to provide.
*>>* Kind regards,
*>>* Luca*

	[[alternative HTML version deleted]]


From thanoon.younis80 at gmail.com  Wed Mar 18 18:12:53 2015
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Wed, 18 Mar 2015 20:12:53 +0300
Subject: [R] r help
Message-ID: <CABLo8nH1rR2ozmPZhGjkHa0nj9oHUKx-on2yE0j-4OXV1HOJcg@mail.gmail.com>

Dear all members

I have error with the following code

#Input data set
     thd <- as.matrix(read.table("C:/Users/hp/Desktop/thd.txt"))

    #Input data set
    data<-list(N1=2000,N2=2000,P=9,R=Ro,z1=yo1,z2=yo2,thd)

and the the matrix

-200.000 -2.517 -1.245 -0.444  0.848 200.000
-200.000 -1.447 -0.420  0.119  1.245 200.000
-200.000 -1.671 -0.869 -0.194  0.679 200.000
-200.000 -1.642 -0.869 -0.293  0.332 200.000
-200.000 -1.671 -0.827  0.052  0.756 200.000

thd matrix saved as a text file, i have the following errors

In read.table("C:/Users/hp/Desktop/thd.txt") :
 incomplete final line found by readTableHeader on
'C:/Users/hp/Desktop/thd.txt'

The thd matrix didn't appear in the results, so i hope anyone can help me
to solve this problem.

Many thanks in advance

-- 
Thanoon Y. Thanoon
PhD Candidate
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Wed Mar 18 18:27:10 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 18 Mar 2015 17:27:10 +0000
Subject: [R] lqs function for S-estimator
In-Reply-To: <739A7C2A-8698-427B-8711-34D7CCF4E366@gmail.com>
References: <252791950.5189981426687918449.JavaMail.httpd@webmail-53.iol.local>
	<739A7C2A-8698-427B-8711-34D7CCF4E366@gmail.com>
Message-ID: <5509B56E.4060409@stats.ox.ac.uk>

On 18/03/2015 15:38, peter dalgaard wrote:
>
> On 18 Mar 2015, at 15:11 , Annalisa Orenti <annalisaorenti at libero.it> wrote:
>
>> Dear R-Users,
>> I need to fit a regression by means of S-estimator, but I found an
>> inconsistency in lqs function in MASS package.
>> When recalling coefficient estimates two discordant answers are obtained by
>> coef() function and by $coef object:
>> As an example I report here the results of fitting regression S-estimator on
>> stackloss data:
>>
>> library(MASS)
>> Sestim<-lqs(stack.loss ~ Air.Flow + Water.Temp + Acid.Conc., data = stackloss,
>> method = "S")
>> coef(Sestim)
>> (Intercept)            Air.Flow   Water.Temp   Acid.Conc.
>> -35.37610619   0.82522124   0.44247788  -0.07964602
>> Sestim$coef
>>                            Air.Flow   Water.Temp   Acid.Conc.
>> -36.92530315   0.84957479   0.43047554  -0.07354065
>>
>> Do you have any suggestions?
>
>
> The immediate reason is that Sestim contains both $coef and $coefficients and coef() extracts the latter.
>
> Why this is so escapes me. It looks like it might be a blunder, but the package author isn't usually prone to blundering...

It is a side-effect of changes in R since the code was written (for S). 
Use Sestim$coef until MASS is updated (which will be before 3.2.0 is 
released).

> -pd
>
>> Thank you for your help.
>> Best regards.
>> Annalisa
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From jholtman at gmail.com  Wed Mar 18 18:30:40 2015
From: jholtman at gmail.com (jim holtman)
Date: Wed, 18 Mar 2015 13:30:40 -0400
Subject: [R] r help
In-Reply-To: <CABLo8nH1rR2ozmPZhGjkHa0nj9oHUKx-on2yE0j-4OXV1HOJcg@mail.gmail.com>
References: <CABLo8nH1rR2ozmPZhGjkHa0nj9oHUKx-on2yE0j-4OXV1HOJcg@mail.gmail.com>
Message-ID: <CAAxdm-5_t6kmyV_k4bFnRKUoiAQ83QOwD6-X8qs0aVNdgsebjw@mail.gmail.com>

Works fine for me.  The error message just means that the last line did not
end with a 'new line' character:


> x <- as.matrix(read.table("/temp/td.txt"))
Warning message:
In read.table("/temp/td.txt") :
  incomplete final line found by readTableHeader on '/temp/td.txt'
>   data<-list(N1=2000,N2=2000,P=9,x)
>
> data
$N1
[1] 2000

$N2
[1] 2000

$P
[1] 9

[[4]]
       V1     V2     V3     V4    V5  V6
[1,] -200 -2.517 -1.245 -0.444 0.848 200
[2,] -200 -1.447 -0.420  0.119 1.245 200
[3,] -200 -1.671 -0.869 -0.194 0.679 200
[4,] -200 -1.642 -0.869 -0.293 0.332 200
[5,] -200 -1.671 -0.827  0.052 0.756 200



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Mar 18, 2015 at 1:12 PM, thanoon younis <thanoon.younis80 at gmail.com>
wrote:

> Dear all members
>
> I have error with the following code
>
> #Input data set
>      thd <- as.matrix(read.table("C:/Users/hp/Desktop/thd.txt"))
>
>     #Input data set
>     data<-list(N1=2000,N2=2000,P=9,R=Ro,z1=yo1,z2=yo2,thd)
>
> and the the matrix
>
> -200.000 -2.517 -1.245 -0.444  0.848 200.000
> -200.000 -1.447 -0.420  0.119  1.245 200.000
> -200.000 -1.671 -0.869 -0.194  0.679 200.000
> -200.000 -1.642 -0.869 -0.293  0.332 200.000
> -200.000 -1.671 -0.827  0.052  0.756 200.000
>
> thd matrix saved as a text file, i have the following errors
>
> In read.table("C:/Users/hp/Desktop/thd.txt") :
>  incomplete final line found by readTableHeader on
> 'C:/Users/hp/Desktop/thd.txt'
>
> The thd matrix didn't appear in the results, so i hope anyone can help me
> to solve this problem.
>
> Many thanks in advance
>
> --
> Thanoon Y. Thanoon
> PhD Candidate
> Department of Mathematical Sciences
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Wed Mar 18 18:33:39 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 18 Mar 2015 09:33:39 -0800
Subject: [R] r help
In-Reply-To: <CABLo8nH1rR2ozmPZhGjkHa0nj9oHUKx-on2yE0j-4OXV1HOJcg@mail.gmail.com>
Message-ID: <F75C03AC206.000016E5jrkrideau@inbox.com>

I don't think there is any way we can help with a data set that appears to be sitting on your hard drive.

On  a wild guess, however, there probaby is a problem with the final line terminator.  Open the file in a text editor, go to the last item in the file, place the cursor after it, hit return and save the file.

We might be able to help if we had the file.

Otherwise please  read https://github.com/hadley/devtools/wiki/Reproducibility and/ or http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Otherwise please read


John Kane
Kingston ON Canada


> -----Original Message-----
> From: thanoon.younis80 at gmail.com
> Sent: Wed, 18 Mar 2015 20:12:53 +0300
> To: r-help at r-project.org
> Subject: [R] r help
> 
> Dear all members
> 
> I have error with the following code
> 
> #Input data set
>      thd <- as.matrix(read.table("C:/Users/hp/Desktop/thd.txt"))
> 
>     #Input data set
>     data<-list(N1=2000,N2=2000,P=9,R=Ro,z1=yo1,z2=yo2,thd)
> 
> and the the matrix
> 
> -200.000 -2.517 -1.245 -0.444  0.848 200.000
> -200.000 -1.447 -0.420  0.119  1.245 200.000
> -200.000 -1.671 -0.869 -0.194  0.679 200.000
> -200.000 -1.642 -0.869 -0.293  0.332 200.000
> -200.000 -1.671 -0.827  0.052  0.756 200.000
> 
> thd matrix saved as a text file, i have the following errors
> 
> In read.table("C:/Users/hp/Desktop/thd.txt") :
>  incomplete final line found by readTableHeader on
> 'C:/Users/hp/Desktop/thd.txt'
> 
> The thd matrix didn't appear in the results, so i hope anyone can help me
> to solve this problem.
> 
> Many thanks in advance
> 
> --
> Thanoon Y. Thanoon
> PhD Candidate
> Department of Mathematical Sciences
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From tom at maladmin.com  Wed Mar 18 20:37:56 2015
From: tom at maladmin.com (Tom Wright)
Date: Wed, 18 Mar 2015 15:37:56 -0400
Subject: [R] reading multiple text files from web
In-Reply-To: <CAORW=u44SbDxe=3yEpc=RUC-2rJQ7J+Mq_Wcpj_y6Oeo1_bm0Q@mail.gmail.com>
References: <CAORW=u44SbDxe=3yEpc=RUC-2rJQ7J+Mq_Wcpj_y6Oeo1_bm0Q@mail.gmail.com>
Message-ID: <1426707476.1950.25.camel@maladmin.com>

I think you need to use a loop to iterate through each of the items in
getlinks

for(link in getlinks)
	{
	url<-paste0('http://spec.org/jEnterprise2010/results/',link)
	output<-readfiles(url)
	}

You're probably also going to need to add some error handling when your
search string doesn't exist.

On Wed, 2015-03-11 at 23:08 -0700, Kruti Pandya wrote:
> readfiles=function(x) { a<-readLines(x)
> 
> 
> sm <- "Java EE AppServer & Database Server HW (SUT
> hardware)"
> 
> 
> s<-grep(sm, a, fixed=TRUE)
> 
> 
> e<-grep("^\\S", a[-(1:s)])[1]
> 
> 
> grep("OS Vendor", a[(s+1):(s+e-1)], fixed=T, value=T)[1]
> 
> grep("OS Name", a[(s+1):(s+e-1)], fixed=T,
> value=T)[1]
> 
> }


From tom at maladmin.com  Wed Mar 18 20:54:10 2015
From: tom at maladmin.com (Tom Wright)
Date: Wed, 18 Mar 2015 15:54:10 -0400
Subject: [R] summary.formula()
In-Reply-To: <69CBB581-C1B8-4F0C-913D-1AC453236CAD@gmail.com>
References: <69CBB581-C1B8-4F0C-913D-1AC453236CAD@gmail.com>
Message-ID: <1426708450.1950.29.camel@maladmin.com>


First you need to make the data pbc available, perhaps by:
data(pbc, package="survival")

Then the line:
sf2<-summary(...

looks wrong, usually you would use the summary() function to look at the
output from a function, seems to me you are missing the function here. I
have no idea what this function could be.


On Wed, 2015-03-04 at 09:45 -0500, Hua Liang wrote:
> uT<-function(a,b){
>         j<-t.test(a)
>         p<-list(P=j$p.value,stat=j$statistic,
>             df=j$parameter,testname=j$method,statname="")
>         return(p)
>         }
>  
> pbcset<- na.omit(pbc[,c("trt","chol","copper","platelet")])
>  
> sf2 <- summary(trt~chol
> +platelet,data=pbc,test=T,method="reverse",conTest=uT)
> print(sf2, prtest = "P")


From amango at gmail.com  Wed Mar 18 21:47:18 2015
From: amango at gmail.com (Aman Gill)
Date: Wed, 18 Mar 2015 16:47:18 -0400
Subject: [R] Help with error: arguments imply differing number of rows
In-Reply-To: <CCBC4993-634E-4822-B47A-34F1633398B5@utoronto.ca>
References: <CAKXkWh3GQ2vgF=4SvF1jLb19uFeKBY7eDttAd919RU_CTTFcTg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C23D2F@SRVEXCHMBX.precheza.cz>
	<CAKXkWh0eg2P2UDgOZw-Mt+Ncr=WQeG=c-2a3wJjNHQA6vo_4xg@mail.gmail.com>
	<CCBC4993-634E-4822-B47A-34F1633398B5@utoronto.ca>
Message-ID: <CAKXkWh3qRdVsCG8BK86SrnRrrq79DajtrAu7xog+gLac=94LUw@mail.gmail.com>

I did notice those differences, but I presumed they reflected different
values in each of the two objects, rather than a difference in the
structure of the objects, which I assume to be the cause of the error. For
example, the "tip.label" structure for each object is the same [1:9]
although each has different values (plant tribe names).

Would you mind explaining how these differences might pertain to the error
of "arguments imply differing number of rows"? I am not a very experienced
R user so I may be missing something here.

On Sat, Mar 14, 2015 at 11:44 AM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> Not the same. Read carefully...
>
> > $ edge       : int [1:15, 1:2] 10 11 12 13 14 14 13 12 15 15 ...
> > $ edge       : int [1:15, 1:2] 10 11 12 13 14 15 15 14 16 16 ...
>                                                 ^^... etc
>
> B.
>
>
> On Mar 14, 2015, at 11:34 AM, Aman Gill <amango at gmail.com> wrote:
>
> > Thanks for the reply. The results of str() are indeed the same. Is there
> > anything else I can check that might explain the difference?
> >
> >> str(phyl_tree)
> > List of 4
> > $ edge       : int [1:15, 1:2] 10 11 12 13 14 14 13 12 15 15 ...
> > $ Nnode      : int 7
> > $ tip.label  : chr [1:9] "Heliantheae" "Eupatorieae" "Helenieae"
> > "Gnaphalieae" ...
> > $ edge.length: num [1:15] 1 1 1 1 1 1 2 1 2 1 ...
> > - attr(*, "class")= chr "phylo"
> > - attr(*, "order")= chr "cladewise"
> >>
> >> str(chem_tree)
> > List of 4
> > $ edge       : int [1:15, 1:2] 10 11 12 13 14 15 15 14 16 16 ...
> > $ Nnode      : int 7
> > $ tip.label  : chr [1:9] "Heliantheae" "Helenieae" "Eupatorieae"
> > "Astereae" ...
> > $ edge.length: num [1:15] 1 2 1 1 1 1 1 1 1 1 ...
> > - attr(*, "class")= chr "phylo"
> > - attr(*, "order")= chr "cladewise"
> >
> >> str(phyl_data)
> > int [1:35, 1:9] 0 0 0 1 0 0 0 0 0 1 ...
> > - attr(*, "dimnames")=List of 2
> >  ..$ : chr [1:35] "Uroleucon_aeneum" "Uroleucon_aff_atripes"
> > "Uroleucon_amamianum" "Uroleucon_ambrosiae" ...
> >  ..$ : chr [1:9] "Heliantheae" "Eupatorieae" "Helenieae" "Gnaphalieae"
> ...
> >>
> >> str(chem_data)
> > int [1:35, 1:9] 0 0 0 1 0 0 0 0 0 1 ...
> > - attr(*, "dimnames")=List of 2
> >  ..$ : chr [1:35] "Uroleucon_aeneum" "Uroleucon_aff_atripes"
> > "Uroleucon_amamianum" "Uroleucon_ambrosiae" ...
> >  ..$ : chr [1:9] "Heliantheae" "Helenieae" "Eupatorieae" "Astereae" ...
> >
> >
> > On Fri, Mar 13, 2015 at 7:31 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> >
> >> Hi
> >>
> >> Without further information you probably do not get answers. Everything
> >> seems to be same so the only reason can be that the objects seems to be
> >> same but they have some inner distinctions, maybe type of variables.
> >>
> >> Are results of
> >>
> >> str(your.objects)
> >>
> >> same in equivalent objects?
> >>
> >> Cheers
> >> Petr
> >>
> >>> -----Original Message-----
> >>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Aman
> >>> Gill
> >>> Sent: Thursday, March 12, 2015 6:08 PM
> >>> To: r-help at r-project.org
> >>> Subject: [R] Help with error: arguments imply differing number of rows
> >>>
> >>> Hello,
> >>>
> >>> I am stuck trying to run an analysis using the package picante. I am
> >>> running two very similar analyses. One works as expected, but when I
> >>> try
> >>> the other, I get the error:
> >>>
> >>> Error in data.frame(PD = PDs, SR = SR) :
> >>>  arguments imply differing number of rows: 34, 35
> >>>
> >>> This is strange to me since the data matrix is the same for both
> >>> analyses
> >>> (numbers of rows and columns are the same; the only difference is the
> >>> order
> >>> of the columns). Each analyses requires a phylogenetic tree (.tre
> >>> file),
> >>> and each tree is very similar. Any thoughts as to what's causing this
> >>> problem? The problem may be specific to the function I'm using [pd()],
> >>> but
> >>> since the error is a data.frame error I thought I'd ask here. Here is
> >>> the
> >>> code I'm using:
> >>>
> >>> This works:
> >>> phyl_tree <- read.nexus("phyl.tre")
> >>> phyl_data <- as.matrix(read.table("phyl_matrix.txt"), header=TRUE, sep
> >>> =
> >>> "\t")
> >>> pd.result <- pd(phyl_data, phyl_tree, include.root = TRUE)
> >>>
> >>> This fails (this matrix.txt file is the same as above, except that
> >>> columns
> >>> are ordered to match the tree; I have also used the above matrix.txt
> >>> file)
> >>> chem_tree <- read.nexus("chem.tre")
> >>> chem_data <- as.matrix(read.table("chem_matrix.txt"), header=TRUE, sep
> >>> =
> >>> "\t")
> >>> pd_chem.result <- pd(chem_data, chem_tree, include.root = TRUE)
> >>>
> >>> ERROR:
> >>> Error in data.frame(PD = PDs, SR = SR) :
> >>>  arguments imply differing number of rows: 34, 35
> >>>
> >>>
> >>> To illustrate that the data for each run are very similar (row and
> >>> column
> >>> names are also the same in both data files):
> >>>
> >>>> phyl_tree
> >>>
> >>> Phylogenetic tree with 9 tips and 7 internal nodes.
> >>>
> >>> Tip labels:
> >>> Heliantheae, Eupatorieae, Helenieae, Gnaphalieae, Anthemideae,
> >>> Astereae, ...
> >>> Node labels:
> >>> root, minCyn, minCic, HelEurHel, HelEur, GnaAnthAst, ...
> >>>
> >>> Rooted; includes branch lengths.
> >>>
> >>>> nrow(phyl_data)
> >>> [1] 35
> >>>> ncol(phyl_data)
> >>> [1] 9
> >>>> class(phyl_data)
> >>> [1] "matrix"
> >>>
> >>>
> >>>> chem_tree
> >>>
> >>> Phylogenetic tree with 9 tips and 7 internal nodes.
> >>>
> >>> Tip labels:
> >>> Heliantheae, Helenieae, Eupatorieae, Astereae, Gnaphlieae, Senecioneae,
> >>> ...
> >>> Node labels:
> >>> root, minC, minAnth, minSen, minGna, HelHel, ...
> >>>
> >>> Rooted; includes branch lengths.
> >>>
> >>>> nrow(chem_data)
> >>> [1] 35
> >>>> ncol(chem_data)
> >>> [1] 9
> >>>> class(chem_data)
> >>> [1] "matrix"
> >>>
> >>>      [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-
> >>> guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ________________________________
> >> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> >> ur?eny pouze jeho adres?t?m.
> >> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> >> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie
> >> vyma?te ze sv?ho syst?mu.
> >> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email
> >> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> >> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi
> >> ?i zpo?d?n?m p?enosu e-mailu.
> >>
> >> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> >> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> >> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> >> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout;
> >> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> >> p??jemce s dodatkem ?i odchylkou.
> >> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> >> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> >> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> >> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n
> >> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
> tohoto
> >> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> >> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >>
> >> This e-mail and any documents attached to it may be confidential and are
> >> intended only for its intended recipients.
> >> If you received this e-mail by mistake, please immediately inform its
> >> sender. Delete the contents of this e-mail with all attachments and its
> >> copies from your system.
> >> If you are not the intended recipient of this e-mail, you are not
> >> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> >> The sender of this e-mail shall not be liable for any possible damage
> >> caused by modifications of the e-mail or by delay with transfer of the
> >> email.
> >>
> >> In case that this e-mail forms part of business dealings:
> >> - the sender reserves the right to end negotiations about entering into
> a
> >> contract in any time, for any reason, and without stating any reasoning.
> >> - if the e-mail contains an offer, the recipient is entitled to
> >> immediately accept such offer; The sender of this e-mail (offer)
> excludes
> >> any acceptance of the offer on the part of the recipient containing any
> >> amendment or variation.
> >> - the sender insists on that the respective contract is concluded only
> >> upon an express mutual agreement on all its aspects.
> >> - the sender of this e-mail informs that he/she is not authorized to
> enter
> >> into any contracts on behalf of the company except for cases in which
> >> he/she is expressly authorized to do so in writing, and such
> authorization
> >> or power of attorney is submitted to the recipient or the person
> >> represented by the recipient, or the existence of such authorization is
> >> known to the recipient of the person represented by the recipient.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From c.danyluck at gmail.com  Wed Mar 18 21:59:59 2015
From: c.danyluck at gmail.com (Chad Danyluck)
Date: Wed, 18 Mar 2015 16:59:59 -0400
Subject: [R] Trouble Clearing Environment
Message-ID: <CA+_f+RFAb7HO92K1qavX=FecUbWyPSbAknE0xaZKt4Y7Gd8gBA@mail.gmail.com>

I use R Studio (Version 0.98.994 on Mac) and R version 3.1.1 (2014-07-10).
I find that whenever I clear my environment the environment does not
completely clear, even when I check "Include Hidden Objects (the
environment appears cleared, but I can rerun a section of my syntax and,
for example print a table with the created variable and one from the same
data set that has not yet been reloaded to the environment). I'd like to
know how to fully clear my workspace and have a check in place to ensure I
have cleared it completely. Has anyone else run into this problem before?
This seems like a basic problem but I've not found any info on it in the
help archives.

Kind regards,

Chad

-- 
Chad M. Danyluck, MA
PhD Candidate, Psychology
University of Toronto



?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]


From acefix at rocketmail.com  Wed Mar 18 22:52:29 2015
From: acefix at rocketmail.com (Fix Ace)
Date: Wed, 18 Mar 2015 21:52:29 +0000 (UTC)
Subject: [R] density plot not smooth
In-Reply-To: <CAF8bMcaSTPHroy+1N7LN-Cs5W7JuoQucvcQfekTn5edYJQEHVg@mail.gmail.com>
References: <CAF8bMcaSTPHroy+1N7LN-Cs5W7JuoQucvcQfekTn5edYJQEHVg@mail.gmail.com>
Message-ID: <1185792158.20460.1426715549992.JavaMail.yahoo@mail.yahoo.com>

Thank you very much!
I do need to learn more about R!! 


     On Tuesday, March 17, 2015 9:26 PM, William Dunlap <wdunlap at tibco.com> wrote:
   

 Fix Ace wrote?? ?What is the default "n"?
512:? ?> length(density(rnorm(10^6))$x)? ?[1] 512? ?> args(density.default)? ?function (x, bw = "nrd0", adjust = 1, kernel = c("gaussian",?? ? ? ?"epanechnikov", "rectangular", "triangular", "biweight",?? ? ? ?"cosine", "optcosine"), weights = NULL, window = kernel,?? ? ? ?width, give.Rkern = FALSE, n = 512, from, to, cut = 3, na.rm = FALSE,?? ? ? ?...)? ?NULL? ?> ?density # or ?density.default, should also tell you about its meaning

Bill Dunlap
TIBCO Software
wdunlap tibco.com
On Tue, Mar 17, 2015 at 7:02 PM, Fix Ace <acefix at rocketmail.com> wrote:

Thank you for the email.
What is the default "n"?
Thanks! 


     On Tuesday, March 17, 2015 4:06 PM, William Dunlap <wdunlap at tibco.com> wrote:
   

 Increasing the value of 'n' given to density will give an estimate at more points so it will look smoother.? Try n=2^18.
Bill Dunlap
TIBCO Software
wdunlap tibco.com
On Tue, Mar 17, 2015 at 12:06 PM, Fix Ace <acefix at rocketmail.com> wrote:



?I have a dataset with 6187 elements, ranged from 3 to 104028. When I tried to examine only small range of data, I found that the plot was not smooth (as shown below):
plot(density(test$V2), xlim=c(0,1000))


?Is there away to make it smoother?
Thanks a lot!!

?


?



? 
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




   



  
	[[alternative HTML version deleted]]


From ngnikhilgoyal at gmail.com  Wed Mar 18 21:31:37 2015
From: ngnikhilgoyal at gmail.com (Nikhil Goyal)
Date: Wed, 18 Mar 2015 16:31:37 -0400
Subject: [R] Using lapply on term document matrix to calculate word frequency
Message-ID: <CABHDEKxOOpcKEDBgh-jjA4yyqHEAkp9FLUaz6cQ=5D5tY0PN+g@mail.gmail.com>

Given three TermDocumentMatrix, text1, text2 and text3, I'd like to
calculate word frequency for each of them into a data frame and rbind all
the data frames. Three are sample - I have hundreds in reality so I need to
functionalize this.

It's easy to calculate word freq for one TDM:

    apply(x, 1, sum)

or

    rowSums(as.matrix(x))

I want to make a list of TDMs:

    tdm_list <- Filter(function(x) is(x, "TermDocumentMatrix"), mget(ls()))

and calculate word freq for each and put it in a data frame:

    data.frame(lapply(tdm_list, sum)) # this is wrong. it simply sums
frequency of all words instead of frequency by each word.

and then rbind it all:

    do.call(rbind, df_list)

I can't figure out how to use lapply on a TDM to calculate word frequency.

Adding sample Data to play around with :

    require(tm)
    text1 <- c("apple" , "love", "crazy", "peaches", "cool", "coke",
"batman", "joker")
    text2 <- c("omg", "#rstats" , "crazy", "cool", "bananas", "functions",
"apple")
    text3 <- c("Playing", "rstats", "football", "data", "coke", "caffeine",
"peaches", "cool")

    tdm1 <- TermDocumentMatrix(Corpus(VectorSource(text1)))
    tdm2 <- TermDocumentMatrix(Corpus(VectorSource(text2)))
    tdm3 <- TermDocumentMatrix(Corpus(VectorSource(text3)))

thanks.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Mar 18 23:00:30 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 18 Mar 2015 18:00:30 -0400
Subject: [R] Trouble Clearing Environment
In-Reply-To: <CA+_f+RFAb7HO92K1qavX=FecUbWyPSbAknE0xaZKt4Y7Gd8gBA@mail.gmail.com>
References: <CA+_f+RFAb7HO92K1qavX=FecUbWyPSbAknE0xaZKt4Y7Gd8gBA@mail.gmail.com>
Message-ID: <5509F57E.7080308@gmail.com>

You seem to be talking about something in the RStudio front end, not in
R, which means you're writing to the wrong place.  They have their own
support forums.

Duncan Murdoch

On 18/03/2015 4:59 PM, Chad Danyluck wrote:
> I use R Studio (Version 0.98.994 on Mac) and R version 3.1.1 (2014-07-10).
> I find that whenever I clear my environment the environment does not
> completely clear, even when I check "Include Hidden Objects (the
> environment appears cleared, but I can rerun a section of my syntax and,
> for example print a table with the created variable and one from the same
> data set that has not yet been reloaded to the environment). I'd like to
> know how to fully clear my workspace and have a check in place to ensure I
> have cleared it completely. Has anyone else run into this problem before?
> This seems like a basic problem but I've not found any info on it in the
> help archives.
> 
> Kind regards,
> 
> Chad
>


From macqueen1 at llnl.gov  Wed Mar 18 23:00:12 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 18 Mar 2015 22:00:12 +0000
Subject: [R] Help with error: arguments imply differing number of rows
In-Reply-To: <CAKXkWh3GQ2vgF=4SvF1jLb19uFeKBY7eDttAd919RU_CTTFcTg@mail.gmail.com>
References: <CAKXkWh3GQ2vgF=4SvF1jLb19uFeKBY7eDttAd919RU_CTTFcTg@mail.gmail.com>
Message-ID: <D12F40B5.122B22%macqueen1@llnl.gov>

If this error had happened to me, then immediately after receiving that
error I would type
   traceback()
at the R prompt. Hopefully, that will provide some information about what
happened.

Based on:

Error in data.frame(PD = PDs, SR = SR) :
  arguments imply differing number of rows: 34, 35

It appears that PDs and SR, whatever they are (referring to the versions
on the right hand side of the equals sign), have or imply different
numbers of rows. For example, PDs could be a vector of length 34 and SR a
vector of length 35. Your task is to figure out how they got constructed
inside the pd() function, which will lead to why they are different. This
will require some understanding of what happens inside the pd() function,
and there, unfortunately, I can't help you.

Typing
  pd
at the R prompt might reveal the entire definition of the pd() function,
from which you might be able to trace the calculations.


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/12/15, 10:07 AM, "Aman Gill" <amango at gmail.com> wrote:

>Hello,
>
>I am stuck trying to run an analysis using the package picante. I am
>running two very similar analyses. One works as expected, but when I try
>the other, I get the error:
>
>Error in data.frame(PD = PDs, SR = SR) :
>  arguments imply differing number of rows: 34, 35
>
>This is strange to me since the data matrix is the same for both analyses
>(numbers of rows and columns are the same; the only difference is the
>order
>of the columns). Each analyses requires a phylogenetic tree (.tre file),
>and each tree is very similar. Any thoughts as to what's causing this
>problem? The problem may be specific to the function I'm using [pd()], but
>since the error is a data.frame error I thought I'd ask here. Here is the
>code I'm using:
>
>This works:
>phyl_tree <- read.nexus("phyl.tre")
>phyl_data <- as.matrix(read.table("phyl_matrix.txt"), header=TRUE, sep =
>"\t")
>pd.result <- pd(phyl_data, phyl_tree, include.root = TRUE)
>
>This fails (this matrix.txt file is the same as above, except that columns
>are ordered to match the tree; I have also used the above matrix.txt file)
>chem_tree <- read.nexus("chem.tre")
>chem_data <- as.matrix(read.table("chem_matrix.txt"), header=TRUE, sep =
>"\t")
>pd_chem.result <- pd(chem_data, chem_tree, include.root = TRUE)
>
>ERROR:
>Error in data.frame(PD = PDs, SR = SR) :
>  arguments imply differing number of rows: 34, 35
>
>
>To illustrate that the data for each run are very similar (row and column
>names are also the same in both data files):
>
>> phyl_tree
>
>Phylogenetic tree with 9 tips and 7 internal nodes.
>
>Tip labels:
>Heliantheae, Eupatorieae, Helenieae, Gnaphalieae, Anthemideae, Astereae,
>...
>Node labels:
>root, minCyn, minCic, HelEurHel, HelEur, GnaAnthAst, ...
>
>Rooted; includes branch lengths.
>
>> nrow(phyl_data)
>[1] 35
>> ncol(phyl_data)
>[1] 9
>> class(phyl_data)
>[1] "matrix"
>
>
>> chem_tree
>
>Phylogenetic tree with 9 tips and 7 internal nodes.
>
>Tip labels:
>Heliantheae, Helenieae, Eupatorieae, Astereae, Gnaphlieae, Senecioneae,
>...
>Node labels:
>root, minC, minAnth, minSen, minGna, HelHel, ...
>
>Rooted; includes branch lengths.
>
>> nrow(chem_data)
>[1] 35
>> ncol(chem_data)
>[1] 9
>> class(chem_data)
>[1] "matrix"
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From c.danyluck at gmail.com  Wed Mar 18 23:22:23 2015
From: c.danyluck at gmail.com (Chad Danyluck)
Date: Wed, 18 Mar 2015 18:22:23 -0400
Subject: [R] Trouble Clearing Environment
In-Reply-To: <5509F57E.7080308@gmail.com>
References: <CA+_f+RFAb7HO92K1qavX=FecUbWyPSbAknE0xaZKt4Y7Gd8gBA@mail.gmail.com>
	<5509F57E.7080308@gmail.com>
Message-ID: <CA+_f+RF6-J13iCEWgQkHARDGCzSmXZi5JP_fTdcU+_+C+s8=dQ@mail.gmail.com>

Thanks for pointing me in the right direction.

Best,

Chad

On Wed, Mar 18, 2015 at 6:00 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> You seem to be talking about something in the RStudio front end, not in
> R, which means you're writing to the wrong place.  They have their own
> support forums.
>
> Duncan Murdoch
>
> On 18/03/2015 4:59 PM, Chad Danyluck wrote:
> > I use R Studio (Version 0.98.994 on Mac) and R version 3.1.1
> (2014-07-10).
> > I find that whenever I clear my environment the environment does not
> > completely clear, even when I check "Include Hidden Objects (the
> > environment appears cleared, but I can rerun a section of my syntax and,
> > for example print a table with the created variable and one from the same
> > data set that has not yet been reloaded to the environment). I'd like to
> > know how to fully clear my workspace and have a check in place to ensure
> I
> > have cleared it completely. Has anyone else run into this problem before?
> > This seems like a basic problem but I've not found any info on it in the
> > help archives.
> >
> > Kind regards,
> >
> > Chad
> >
>
>


-- 
Chad M. Danyluck, MA
PhD Candidate, Psychology
University of Toronto



?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Mar 19 02:38:26 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 18 Mar 2015 18:38:26 -0700
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
Message-ID: <A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>

I don't understand your description. The standard practice on this list is to provide a reproducible R example [1] of the kind of data you are working with (and any code you have tried) to go along with your description. In this case, that would be two dputs of your input data frames and a dput of an output data frame (generated by hand from your input data frame). (Probably best to not use the full number of input values just to keep the size down.) We could then make an attempt to generate code that goes from input to output.

Of course, if you post that hard work using HTML then it will get corrupted (much like the text below from your earlier emails) and we won't be able to use it. Please learn to post from your email software using plain text when corresponding with this mailing list.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 18, 2015 9:05:37 AM PDT, Luca Meyer <lucam1968 at gmail.com> wrote:
>Thanks for you input Michael,
>
>The continuous variable I have measures quantities (down to the 3rd
>decimal level) so unfortunately are not frequencies.
>
>Any more specific suggestions on how that could be tackled?
>
>Thanks & kind regards,
>
>Luca
>
>
>===
>
>Michael Friendly wrote:
>I'm not sure I understand completely what you want to do, but
>if the data were frequencies, it sounds like task for fitting a
>loglinear model with the model formula
>
>~ V1*V2 + V3
>
>On 3/18/2015 2:17 AM, Luca Meyer wrote:
>>* Hello,
>*>>* I am facing a quite challenging task (at least to me) and I was
>wondering
>*>* if someone could advise how R could assist me to speed the task up.
>*>>* I am dealing with a dataset with 3 discrete variables and one
>continuous
>*>* variable. The discrete variables are:
>*>>* V1: 8 modalities
>*>* V2: 13 modalities
>*>* V3: 13 modalities
>*>>* The continuous variable V4 is a decimal number always greater than
>zero in
>*>* the marginals of each of the 3 variables but it is sometimes equal
>to zero
>*>* (and sometimes negative) in the joint tables.
>*>>* I have got 2 files:
>*>>* => one with distribution of all possible combinations of V1xV2
>(some of
>*>* which are zero or neagtive) and
>*>* => one with the marginal distribution of V3.
>*>>* I am trying to build the long and narrow dataset V1xV2xV3 in such
>a way
>*>* that each V1xV2 cell does not get modified and V3 fits as closely
>as
>*>* possible to its marginal distribution. Does it make sense?
>*>>* To be even more specific, my 2 input files look like the
>following.
>*>>* FILE 1
>*>* V1,V2,V4
>*>* A, A, 24.251
>*>* A, B, 1.065
>*>* (...)
>*>* B, C, 0.294
>*>* B, D, 2.731
>*>* (...)
>*>* H, L, 0.345
>*>* H, M, 0.000
>*>>* FILE 2
>*>* V3, V4
>*>* A, 1.575
>*>* B, 4.294
>*>* C, 10.044
>*>* (...)
>*>* L, 5.123
>*>* M, 3.334
>*>>* What I need to achieve is a file such as the following
>*>>* FILE 3
>*>* V1, V2, V3, V4
>*>* A, A, A, ???
>*>* A, A, B, ???
>*>* (...)
>*>* D, D, E, ???
>*>* D, D, F, ???
>*>* (...)
>*>* H, M, L, ???
>*>* H, M, M, ???
>*>>* Please notice that FILE 3 need to be such that if I aggregate on
>V1+V2 I
>*>* recover exactly FILE 1 and that if I aggregate on V3 I can recover
>a file
>*>* as close as possible to FILE 3 (ideally the same file).
>*>>* Can anyone suggest how I could do that with R?
>*>>* Thank you very much indeed for any assistance you are able to
>provide.
>*>>* Kind regards,
>*>>* Luca*
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From miaojpm at gmail.com  Thu Mar 19 08:56:37 2015
From: miaojpm at gmail.com (jpm miao)
Date: Thu, 19 Mar 2015 15:56:37 +0800
Subject: [R] Which is better: Modifying an existing package or creating a
	new one?
Message-ID: <CABcx46ACdfYZ4sHdwFkinXFop-vRtB=8+ZRBYDVk9cceTS_DWg@mail.gmail.com>

Hi,

   Given that I frequently use A, B, C, D, E packages.
   In each of the 5 packages, I intend to modify one of the functions.
   Two ways:

1st: Modify A, B, C, D, E to A', B', C', D', E'
   Then I will use library(A') ..... library(E') instead of A, B, C, D, E.
   or Just keep the names A, B, C, D, E but modify the content

2nd: create a package F and add the five functions to the F package. For
each of the 5 functions, a line "library(A)"... or "library(E)" is required.

    Then I will need "library(F)" when I create a new program.

   Which is a better way in terms of time consumption and code portability?
If I move the codes to a new computer, which way will be easier?

   Any suggestion?

   Thanks,

Miao

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Mar 19 09:39:51 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 19 Mar 2015 09:39:51 +0100
Subject: [R] Which is better: Modifying an existing package or creating
 a new one?
In-Reply-To: <CABcx46ACdfYZ4sHdwFkinXFop-vRtB=8+ZRBYDVk9cceTS_DWg@mail.gmail.com>
References: <CABcx46ACdfYZ4sHdwFkinXFop-vRtB=8+ZRBYDVk9cceTS_DWg@mail.gmail.com>
Message-ID: <CAJuCY5zeNFdnQ=jPBNHjWnZ8e8BS_by84BagHJWcyPJLkW7zUQ@mail.gmail.com>

I would consider a third option: suggest the changes to the package
authors. The authors might include your modifications to the original
package if they feel that it would improve their package.

Otherwise go for option 2. Option 1 will be harder to maintain if you want
benefit from the updates on the packages A, B, C, D, E.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-19 8:56 GMT+01:00 jpm miao <miaojpm at gmail.com>:

> Hi,
>
>    Given that I frequently use A, B, C, D, E packages.
>    In each of the 5 packages, I intend to modify one of the functions.
>    Two ways:
>
> 1st: Modify A, B, C, D, E to A', B', C', D', E'
>    Then I will use library(A') ..... library(E') instead of A, B, C, D, E.
>    or Just keep the names A, B, C, D, E but modify the content
>
> 2nd: create a package F and add the five functions to the F package. For
> each of the 5 functions, a line "library(A)"... or "library(E)" is
> required.
>
>     Then I will need "library(F)" when I create a new program.
>
>    Which is a better way in terms of time consumption and code portability?
> If I move the codes to a new computer, which way will be easier?
>
>    Any suggestion?
>
>    Thanks,
>
> Miao
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chirleu at gmail.com  Thu Mar 19 09:48:53 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Thu, 19 Mar 2015 09:48:53 +0100
Subject: [R] Timestamp of exported files not updated when the file name is
 overwritten (ggsave)
Message-ID: <CALC46t_-a1SWF2whuYtdnhPn3Niz385EX69vaCwMFf7aU-uZKg@mail.gmail.com>

Hi.
I have a script in which I export some plots to a folder in my PC. The
plots are exported with the function ggsave (in ggplot2).
Whenever I re-run the code and export updated plots, the name of the
exported file is overwritten (as expected) but the timestamp is not updated
what turns it very difficult to locate them, sometimes.

Any thought or solution for this issue?

Thanks,

David

	[[alternative HTML version deleted]]


From michael.eisenring at agroscope.admin.ch  Thu Mar 19 10:06:28 2015
From: michael.eisenring at agroscope.admin.ch (michael.eisenring at agroscope.admin.ch)
Date: Thu, 19 Mar 2015 09:06:28 +0000
Subject: [R] Order Bars in ggplot2 bar graph
Message-ID: <9EFCA4A987B0494CBFFB5CD071756D0035B3ABDC@WBF-C7001.bk.evdad.admin.ch>

Dear experts,
I am trying to make a bar graph using ggplot2. I would like to define the order of my bars independently of alphabetical or numerical order.
How can I do that.
Here a simplified example of my code and comments(#) describing my problem:


#Code start


library(ggplot2)

bar<-ggplot(data,aes(Leaf,Av_Glands_cor,fill=Damage))



# The column "Leaf"  contains the variable C_1, C_2 and C_Cot. R always plots the bars in the following orders : C_1 (closest to the y-axis), C_2, C_Cot

# How do I have to modify my code that the order of the bars is: C_Cot, C_2, C_1?



bar+stat_summary(fun.y=mean,geom="bar",position="dodge",colour="black")+

  theme_bw()+

  theme(text = element_text(size=15),

        axis.text.x = element_text(angle=90, vjust=1))+

stat_summary(fun.data=mean_cl_normal,geom="errorbar",position=position_dodge(width=0.9),width=0.4,colour="gray65")+

labs(x="Leaf",y="Average nr. glands corrected for leaf sz.",fill="Damage")+

  scale_fill_manual(values=c("gray95", "gray75", "gray45", "black"))

#Code end


Thank you very much,
Michael Eisenring

Eisenring Michael, Msc.
PhD Student

Federal Department of Economic Affairs, Education and Research
EAER
Institute of Sustainability Sciences ISS
Biosafety

Reckenholzstrasse 191, CH-8046 Z?rich
Tel. +41 44 37 77181
Fax +41 44 37 77201
michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>
www.agroscope.ch<http://www.agroscope.ch/>


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Mar 19 10:27:29 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 19 Mar 2015 10:27:29 +0100
Subject: [R] Order Bars in ggplot2 bar graph
In-Reply-To: <9EFCA4A987B0494CBFFB5CD071756D0035B3ABDC@WBF-C7001.bk.evdad.admin.ch>
References: <9EFCA4A987B0494CBFFB5CD071756D0035B3ABDC@WBF-C7001.bk.evdad.admin.ch>
Message-ID: <CAJuCY5yMsiJBFzKVhPLaW37LEyYXEuFaS0frdJttsrT3V9nNsw@mail.gmail.com>

You need to set the levels of the factor in the required order.

data$Leaf <- factor(data$Leaf, levels = c("C_Cot", "C_2", "C_1"))

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-19 10:06 GMT+01:00 <michael.eisenring at agroscope.admin.ch>:

> Dear experts,
> I am trying to make a bar graph using ggplot2. I would like to define the
> order of my bars independently of alphabetical or numerical order.
> How can I do that.
> Here a simplified example of my code and comments(#) describing my problem:
>
>
> #Code start
>
>
> library(ggplot2)
>
> bar<-ggplot(data,aes(Leaf,Av_Glands_cor,fill=Damage))
>
>
>
> # The column "Leaf"  contains the variable C_1, C_2 and C_Cot. R always
> plots the bars in the following orders : C_1 (closest to the y-axis), C_2,
> C_Cot
>
> # How do I have to modify my code that the order of the bars is: C_Cot,
> C_2, C_1?
>
>
>
> bar+stat_summary(fun.y=mean,geom="bar",position="dodge",colour="black")+
>
>   theme_bw()+
>
>   theme(text = element_text(size=15),
>
>         axis.text.x = element_text(angle=90, vjust=1))+
>
>
> stat_summary(fun.data=mean_cl_normal,geom="errorbar",position=position_dodge(width=0.9),width=0.4,colour="gray65")+
>
> labs(x="Leaf",y="Average nr. glands corrected for leaf sz.",fill="Damage")+
>
>   scale_fill_manual(values=c("gray95", "gray75", "gray45", "black"))
>
> #Code end
>
>
> Thank you very much,
> Michael Eisenring
>
> Eisenring Michael, Msc.
> PhD Student
>
> Federal Department of Economic Affairs, Education and Research
> EAER
> Institute of Sustainability Sciences ISS
> Biosafety
>
> Reckenholzstrasse 191, CH-8046 Z?rich
> Tel. +41 44 37 77181
> Fax +41 44 37 77201
> michael.eisenring at agroscope.admin.ch<mailto:
> michael.eisenring at agroscope.admin.ch>
> www.agroscope.ch<http://www.agroscope.ch/>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Shannon.Bros at sjsu.edu  Thu Mar 19 07:02:03 2015
From: Shannon.Bros at sjsu.edu (smb123)
Date: Wed, 18 Mar 2015 23:02:03 -0700 (PDT)
Subject: [R] how to get coefficient and scores of Principal component
 analysis in R?
In-Reply-To: <AD482C282436254DB0ED22BA4B2E7DA1013152CC3C@EX-MB07.ohsu.edu>
References: <AD482C282436254DB0ED22BA4B2E7DA1013152CC3C@EX-MB07.ohsu.edu>
Message-ID: <1426744923643-4704832.post@n4.nabble.com>

Actually, the loadings are quite different from the coefficients.  The
loadings are simply correlations of the original values to the scores for a
PCA factor.  The coefficients, on the other hand, allow one to compute the
scores.  There is a coefficient for each variable.  The coefficient is
multiplied with the standardized variable and then added to the next
coefficient multiplied by its standardized variable ets.  The general
formula 

<http://r.789695.n4.nabble.com/file/n4704832/PCA_formula.jpg> 



--
View this message in context: http://r.789695.n4.nabble.com/how-to-get-coefficient-and-scores-of-Principal-component-analysis-in-R-tp3245198p4704832.html
Sent from the R help mailing list archive at Nabble.com.


From stan.aggerwal at gmail.com  Thu Mar 19 10:13:59 2015
From: stan.aggerwal at gmail.com (Stanislav Aggerwal)
Date: Thu, 19 Mar 2015 09:13:59 +0000
Subject: [R] glm in hdlm?
Message-ID: <CAOZp1o=m7vVVKjVr=aE2LvopFsnvCZ1AT-Z1COrZZHDYQJR6NA@mail.gmail.com>

I am following the example in the vignette for hdlm (p. 19), but I cannot
get it to to fit a logistic. For those who don't know the package, it
allows one to fit high dimensional data where the number of variables may
exceed the number of cases.

library(hdlm)

LMFUN <- function(x,y) return(glm(y ~ x, family=binomial(link=logit)))
FUNCVFIT <- function(x,y) return(cv.glmnet(x, y, family='binomial'))

set.seed(1234)
xx<-matrix(runif(20*4),20,4)  #20 cases, 4 variables
xx[,1]<-xx[,1]+1:20
yy<-c(0,0,0,1,0,1,1,0,1,0,1,0,1,0,1,1,1,1,1,1)

#ordinary glms are fitted with no problems with yy either factor or numeric
fit1<-glm(as.factor(yy)~xx,family=binomial)
fit2<-glm(yy~xx,family=binomial)

fit3<-hdlm(as.factor(yy) ~ xx, LMFUN = LMFUN, FUNCVFIT = FUNCVFIT)

This produces the error:
========
Error in { :
  task 1 failed - "(list) object cannot be coerced to type 'double'"
In addition: There were 11 warnings (use warnings() to see them)
=========

fit4<-hdlm(yy ~ xx, LMFUN = LMFUN, FUNCVFIT = FUNCVFIT)

This produces:
============
Error in { :
  task 1 failed - "(list) object cannot be coerced to type 'double'"
In addition: Warning messages:
1: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per
fold
2: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per
fold
3: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per
fold
4: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per
fold
5: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per
fold
6: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per
fold
7: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per
fold
8: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per
fold
9: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per
fold
10: Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per
fold
=============

Please tell me how to fit the glm in hdlm. Thanks very much for any help.

Stan

	[[alternative HTML version deleted]]


From markseeto at gmail.com  Thu Mar 19 11:38:18 2015
From: markseeto at gmail.com (Mark Seeto)
Date: Thu, 19 Mar 2015 21:38:18 +1100
Subject: [R] glmnet: converting coefficients back to original scale
Message-ID: <CAK2mLtNNEC6b+5OhszfLpC9SRvZvf-v1KBwPRYMLFQWYzDikzw@mail.gmail.com>

Dear R-help,

I'm having trouble understanding how glmnet converts its coefficient
estimates back to the original scale. Here's an example with ridge
regression:

########################################################################
library(glmnet)
set.seed(1)

n <- 20  # sample size

d <- data.frame(x1 = rnorm(n, 1, 1), x2 = rnorm(n, 10, 2), y = rnorm(n, 1, 2))

# Sample means
mx1 <- mean(d$x1)
mx2 <- mean(d$x2)
my <- mean(d$y)

# Scaling factors ("1/n standard deviations")
sx1 <- sd(d$x1)*sqrt((n - 1)/n)
sx2 <- sd(d$x2)*sqrt((n - 1)/n)
sy <- sd(d$y)*sqrt((n - 1)/n)

# Scaled variables
d$x1s <- (d$x1 - mx1)/sx1
d$x2s <- (d$x2 - mx2)/sx2
d$ys <- (d$y - my)/sy

lam <- 0.5  # lambda value

# Using scaled variables (same result for standardize=TRUE and
standardize=FALSE)
glmnet1 <- glmnet(as.matrix(d[, c("x1s", "x2s")]), d$ys, alpha=0, lambda = lam)

# Using unscaled variables
glmnet2 <- glmnet(as.matrix(d[, c("x1", "x2")]), d$y, alpha=0, lambda=lam)

coef(glmnet2)
##                     s0
## (Intercept)  2.5658491
## x1           0.3471199
## x2          -0.1703715

# I want to calculate the glmnet2 coef estimates from the glmnet1 coef
estimates.
# The following attempts are based on rearrangement of
# (y - my)/sy = beta1*(x1 - mx1)/sx1 + beta2*(x2 - mx2)/sx2

my - coef(glmnet1)["x1s", "s0"]*mx1*sy/sx1 - coef(glmnet1)["x2s",
"s0"]*mx2*sy/sx2
# 2.430971
# Not the same as coef(glmnet2)["(Intercept)", "s0"]

coef(glmnet1)["x1s", "s0"]*sy/sx1
# 0.3096897
# Not the same as coef(glmnet2)["x1", "s0"]

coef(glmnet1)["x2s", "s0"]*sy/sx2
# -0.1524043
# Not the same as coef(glmnet2)["x2", "s0"]

######################################################################

I can apply a similar method (with centring of y instead of
standardisation) to successfully get the coefficient estimates on the
original scale given by lm.ridge in the MASS package. I would
appreciate any help anyone can give on where I'm going wrong with
glmnet.

Thanks,
Mark


From unwin at math.uni-augsburg.de  Thu Mar 19 12:55:17 2015
From: unwin at math.uni-augsburg.de (Antony Unwin)
Date: Thu, 19 Mar 2015 12:55:17 +0100
Subject: [R] R Course in Dublin (April 15-17)
Message-ID: <0A25DCEC-BF6C-409C-8D26-E793D8445586@math.uni-augsburg.de>

Details at  

http://insightsc.ie/training/r-statistical-software/

Antony Unwin
University of Augsburg, Germany and Insight Statistical Consulting, Dublin, Ireland

From lindnerw at t-online.de  Thu Mar 19 13:21:34 2015
From: lindnerw at t-online.de (Dr. Wolfgang Lindner)
Date: Thu, 19 Mar 2015 13:21:34 +0100
Subject: [R] Tele_R - first experiences
Message-ID: <9A93A01584A6484FA7BF1EA4E1258932@Petra>

Dear R community,

some days ago Enric Cervera Mateu has installed an R client
with instant messaging, which is usable very simple via the
public name @Tele_R in the messenger Telegram.

I have tested Tele_R and e.g. tried most of the examples from
[1] W.N. Venables, D.M. Smith, R Core Team. "An Introduction to R." R Core 
Team. iBooks.
and of ?1 of
[2] B. Everitt, T. Hothorn. "An R and S-plus Companion to Multivariate 
Analysis. Springer.
All is working very good in this environment.

I am very impressed. I like the possibility to use R without installation
complications with my iPhone, iPad or HTC One.
The answers are send very fast, the idea to use a chat for mathematics
communication seems to be especially suited to beginners:
direct dive in, OS as you like, working anywhere, talking over distance,
communicate with your peers or students (share code or
examples etc even during a lesson - if a beamer is not available) etc.

I would like to thank Enric for his valuable work to make the great work of
the R team accessible to smartphones and tablets.
I think that Tele_R is a very comfortable tool for teaching and learning R
at an undergraduate level.

And I would like to hear about the experiences, opinions or ideas of other
members of the R community with respect of the use of Tele_R.

I hope that this is not the wrong list to say these words.

Best,
Wolfgang Lindner
Leichlingen, Germany


From wickedpuppy at gmail.com  Thu Mar 19 15:55:31 2015
From: wickedpuppy at gmail.com (billy am)
Date: Thu, 19 Mar 2015 22:55:31 +0800
Subject: [R] Which is better: Modifying an existing package or creating
 a new one?
In-Reply-To: <CAJuCY5zeNFdnQ=jPBNHjWnZ8e8BS_by84BagHJWcyPJLkW7zUQ@mail.gmail.com>
References: <CABcx46ACdfYZ4sHdwFkinXFop-vRtB=8+ZRBYDVk9cceTS_DWg@mail.gmail.com>
	<CAJuCY5zeNFdnQ=jPBNHjWnZ8e8BS_by84BagHJWcyPJLkW7zUQ@mail.gmail.com>
Message-ID: <CAJ_FNV7093PqduwNuWTfbvx8uj9J7hrO3wd3-Gqqoe-cEtZwtQ@mail.gmail.com>

I would second that.

----------------------------------------------------------------------------------
|

http://billyam.com  || http://use-r.com  || http://shinyserver.com (BETA)

SAS Certified Base Programmer for SAS 9
Oracle SQL Expert(11g)



On Thu, Mar 19, 2015 at 4:39 PM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
> I would consider a third option: suggest the changes to the package
> authors. The authors might include your modifications to the original
> package if they feel that it would improve their package.
>
> Otherwise go for option 2. Option 1 will be harder to maintain if you want
> benefit from the updates on the packages A, B, C, D, E.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-03-19 8:56 GMT+01:00 jpm miao <miaojpm at gmail.com>:
>
>> Hi,
>>
>>    Given that I frequently use A, B, C, D, E packages.
>>    In each of the 5 packages, I intend to modify one of the functions.
>>    Two ways:
>>
>> 1st: Modify A, B, C, D, E to A', B', C', D', E'
>>    Then I will use library(A') ..... library(E') instead of A, B, C, D, E.
>>    or Just keep the names A, B, C, D, E but modify the content
>>
>> 2nd: create a package F and add the five functions to the F package. For
>> each of the 5 functions, a line "library(A)"... or "library(E)" is
>> required.
>>
>>     Then I will need "library(F)" when I create a new program.
>>
>>    Which is a better way in terms of time consumption and code portability?
>> If I move the codes to a new computer, which way will be easier?
>>
>>    Any suggestion?
>>
>>    Thanks,
>>
>> Miao
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Thu Mar 19 17:21:20 2015
From: jholtman at gmail.com (jim holtman)
Date: Thu, 19 Mar 2015 12:21:20 -0400
Subject: [R] Timestamp of exported files not updated when the file name
 is overwritten (ggsave)
In-Reply-To: <CALC46t_-a1SWF2whuYtdnhPn3Niz385EX69vaCwMFf7aU-uZKg@mail.gmail.com>
References: <CALC46t_-a1SWF2whuYtdnhPn3Niz385EX69vaCwMFf7aU-uZKg@mail.gmail.com>
Message-ID: <CAAxdm-6UM763NpozOMSH1oXMbXAi852GU4rjht3u3Mqzzh_E4w@mail.gmail.com>

I just tried the example for 'ggsave' and waited a minute between each run,
and the time modified for the file name was correct in that it showed a
different time when run the second time.  Please post the code you  are
running, the system you are using and then an example of what the times
are.  Are you looking at the time 'modified' or 'created'; this will make a
difference.  So a few more particulars about your problem would be
helpful.  Try running the example for ggsave as I did and see if the times
change.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Thu, Mar 19, 2015 at 4:48 AM, David Villegas R?os <chirleu at gmail.com>
wrote:

> Hi.
> I have a script in which I export some plots to a folder in my PC. The
> plots are exported with the function ggsave (in ggplot2).
> Whenever I re-run the code and export updated plots, the name of the
> exported file is overwritten (as expected) but the timestamp is not updated
> what turns it very difficult to locate them, sometimes.
>
> Any thought or solution for this issue?
>
> Thanks,
>
> David
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rpagliari at appcomsci.com  Thu Mar 19 16:06:30 2015
From: rpagliari at appcomsci.com (Pagliari, Roberto)
Date: Thu, 19 Mar 2015 15:06:30 +0000
Subject: [R] remove outliers with scatterplotMatrix
Message-ID: <7F8B451E34FCDB459E934B4F50451096861BF8@rrc-ats-exmb2.ats.atsinnovate.com>

outliers may sometimes make a scatter plot less understandable.

when using scatterplotMatrix, is it possible to automatically remove them?


	[[alternative HTML version deleted]]


From johnwoodill at gmail.com  Thu Mar 19 18:36:31 2015
From: johnwoodill at gmail.com (A. John Woodill)
Date: Thu, 19 Mar 2015 07:36:31 -1000
Subject: [R] Multicollinearity, plm, and omitting variables
Message-ID: <CABr942pfmZ8TT4vi4ty2htBV=u3j0XrTH3iv_V_AkpzFqUjY3w@mail.gmail.com>

I'm fitting a fixed effect model with plm and know that I'm dealing with
multi-collinearity between two of the independent variables. I working on
identifying multicolliearity in models as a practice and have identified
the variable with alias(), then verified with vif(). I was also able to use
kappa() to show a very large conditional number verifying the
multicollinearity.

My question is why does plm() omit this multicolliearity variable from the
coefficients? There is no output clarifying why and I couldn't find
anything in the documentation. Stata automatically omits this variable and
I'm curious if plm() does a check and then omits.  Does plm() run through
checks when fitting a fixed effect model that checks for collinearity or
any other problems before running the model?  Why is dfmfd98 variable being
omitted in the example below?

Stack Exchange Post :
http://stats.stackexchange.com/questions/141684/multicollinearity-plm-and-omitting-variables

Multicollinearity variable dfmfd98

Reproducible example :

dput :

data <- structure(list(lexptot = c(8.28377505197124, 9.1595012302023,
8.14707583238833,
9.86330744180814, 8.21391453619232, 8.92372556833205, 7.77219149815994,
8.58202430280175, 8.34096828565733, 10.1133857229336, 8.56482997492403,
8.09468633074053, 8.27040804817704, 8.69834992618814, 8.03086333985764,
8.89644392254136, 8.20990433577082, 8.82621293136669, 7.79379981225575,
8.16139809188569, 8.25549748271241, 8.57464947213076, 8.2714431846277,
8.72374048671495, 7.98522888221012, 8.56460042433047, 8.22778847721461,
9.15431416391622, 8.25261818916933, 8.88033778695326), year = c(0L, 1L, 0L,
1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L,
0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L), dfmfdyr = c(0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0), dfmfd98 = c(1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
0, 0, 0), nh = c(11054L, 11054L, 11061L, 11061L, 11081L, 11081L, 11101L,
11101L, 12021L, 12021L, 12035L, 12035L, 12051L, 12051L, 12054L, 12054L,
12081L, 12081L, 12121L, 12121L, 13014L, 13014L, 13015L, 13015L, 13021L,
13021L, 13025L, 13025L, 13035L, 13035L)), .Names = c("lexptot", "year",
"dfmfdyr", "dfmfd98", "nh"), class = c("tbl_df", "data.frame"), row.names =
c(NA, -30L))

Regression Code :

library(plm)

lm <- plm(lexptot ~ year + dfmfdyr + dfmfd98 + nh, data = data, model =
"within", index = "nh")

summary(lm)

Output :

Oneway (individual) effect Within Model

Call:

plm(formula = lexptot ~ year + dfmfdyr + dfmfd98 + nh, data = data,

    model = "within", index = "nh")

Balanced Panel: n=15, T=2, N=30

Residuals :

     Min.   1st Qu.    Median   3rd Qu.      Max.

-4.75e-01 -1.69e-01  4.44e-16  1.69e-01  4.75e-01

Coefficients :

        Estimate Std. Error t-value Pr(>|t|)

year     0.47552    0.23830  1.9955  0.06738 .

dfmfdyr  0.34635    0.29185  1.1867  0.25657

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Total Sum of Squares:    5.7882

Residual Sum of Squares: 1.8455

R-Squared      :  0.68116

      Adj. R-Squared :  0.29517

F-statistic: 13.8864 on 2 and 13 DF, p-value: 0.00059322

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Thu Mar 19 19:08:46 2015
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 19 Mar 2015 14:08:46 -0400
Subject: [R] remove outliers with scatterplotMatrix
In-Reply-To: <7F8B451E34FCDB459E934B4F50451096861BF8@rrc-ats-exmb2.ats.atsinnovate.com>
References: <7F8B451E34FCDB459E934B4F50451096861BF8@rrc-ats-exmb2.ats.atsinnovate.com>
Message-ID: <002801d0626f$bed64630$3c82d290$@mcmaster.ca>

Dear Roberto,

This is, I assume, the scatterplotMatrix() function in the car package.

There is no option for automatically removing outliers, although the various
options for labeling points should help you identify them. If you want to
remove outliers once identified, you could use the subset argument to
scatterplotMatrix(), much as you would for a statistical modeling function,
as long as the variables in the scatterplot matrix are specified in a
formula. 

For example,

	scatterplotMatrix(~ income + education + prestige, data=Duncan,
id.n=2)

identifies the two most noteworthy points in each panel (as explained in
?scatterplotMatrix), while

	scatterplotMatrix(~ income + education + prestige, data=Duncan,
subset= -c(6, 16))

removes cases 6 and 16.

I hope this helps,
 John

-------------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Pagliari,
> Roberto
> Sent: March-19-15 11:07 AM
> To: r-help at r-project.org
> Subject: [R] remove outliers with scatterplotMatrix
> 
> outliers may sometimes make a scatter plot less understandable.
> 
> when using scatterplotMatrix, is it possible to automatically remove them?
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


---
This email has been checked for viruses by Avast antivirus software.
http://www.avast.com


From andrejfavia at ml1.net  Thu Mar 19 19:26:59 2015
From: andrejfavia at ml1.net (andrejfavia at ml1.net)
Date: Thu, 19 Mar 2015 14:26:59 -0400
Subject: [R] Why do my posts not get accepted to the mailing list?
Message-ID: <1426789619.2750836.242667613.340DB8AC@webmail.messagingengine.com>

Greetings.
I was told to email my question.

Why do my posts not get accepted to the mailing list?

Example:
http://r.789695.n4.nabble.com/How-do-I-move-the-horizontal-axis-in-a-plot-so-that-it-starts-at-the-zero-of-the-vertical-axis-td4696935.html

I don't understand why I always have this problem when I post and try to
subscribe and I still haven't found a solution after three years.


From rpagliari at appcomsci.com  Thu Mar 19 19:32:33 2015
From: rpagliari at appcomsci.com (Pagliari, Roberto)
Date: Thu, 19 Mar 2015 18:32:33 +0000
Subject: [R] remove outliers with scatterplotMatrix
In-Reply-To: <002801d0626f$bed64630$3c82d290$@mcmaster.ca>
References: <7F8B451E34FCDB459E934B4F50451096861BF8@rrc-ats-exmb2.ats.atsinnovate.com>,
	<002801d0626f$bed64630$3c82d290$@mcmaster.ca>
Message-ID: <7F8B451E34FCDB459E934B4F50451096861C66@rrc-ats-exmb2.ats.atsinnovate.com>

Thank you John,
I will try that one. 

Bob, 

________________________________________
From: John Fox [jfox at mcmaster.ca]
Sent: Thursday, March 19, 2015 2:08 PM
To: Pagliari, Roberto
Cc: r-help at r-project.org
Subject: RE: [R] remove outliers with scatterplotMatrix

Dear Roberto,

This is, I assume, the scatterplotMatrix() function in the car package.

There is no option for automatically removing outliers, although the various
options for labeling points should help you identify them. If you want to
remove outliers once identified, you could use the subset argument to
scatterplotMatrix(), much as you would for a statistical modeling function,
as long as the variables in the scatterplot matrix are specified in a
formula.

For example,

        scatterplotMatrix(~ income + education + prestige, data=Duncan,
id.n=2)

identifies the two most noteworthy points in each panel (as explained in
?scatterplotMatrix), while

        scatterplotMatrix(~ income + education + prestige, data=Duncan,
subset= -c(6, 16))

removes cases 6 and 16.

I hope this helps,
 John

-------------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Pagliari,
> Roberto
> Sent: March-19-15 11:07 AM
> To: r-help at r-project.org
> Subject: [R] remove outliers with scatterplotMatrix
>
> outliers may sometimes make a scatter plot less understandable.
>
> when using scatterplotMatrix, is it possible to automatically remove them?
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


---
This email has been checked for viruses by Avast antivirus software.
http://www.avast.com



From dwinsemius at comcast.net  Thu Mar 19 19:46:01 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Mar 2015 11:46:01 -0700
Subject: [R] remove outliers with scatterplotMatrix
In-Reply-To: <7F8B451E34FCDB459E934B4F50451096861BF8@rrc-ats-exmb2.ats.atsinnovate.com>
References: <7F8B451E34FCDB459E934B4F50451096861BF8@rrc-ats-exmb2.ats.atsinnovate.com>
Message-ID: <A3CFB9AA-95A6-4F3F-AF6E-1FB2C4D6699B@comcast.net>


On Mar 19, 2015, at 8:06 AM, Pagliari, Roberto wrote:

> outliers may sometimes make a scatter plot less understandable.
> 
> when using scatterplotMatrix, is it possible to automatically remove them?

I've known people who set values to NA that are outside some predefined threshold such as less than the .05th percentile (the .0005th quantile) and the 99.95th percentile at the high end. I'm not so eager to "erase" values at either end, but there would be automated ways of doing that on a copy of the data. Post a better description of the data problem.
> 
> 
> 	[[alternative HTML version deleted]]

And learn to configure your email client to post in plain text. and read the material mentioned below.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Thu Mar 19 19:48:16 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 19 Mar 2015 14:48:16 -0400
Subject: [R] Why do my posts not get accepted to the mailing list?
In-Reply-To: <1426789619.2750836.242667613.340DB8AC@webmail.messagingengine.com>
References: <1426789619.2750836.242667613.340DB8AC@webmail.messagingengine.com>
Message-ID: <550B19F0.1070301@gmail.com>

On 19/03/2015 2:26 PM, andrejfavia at ml1.net wrote:
> Greetings.
> I was told to email my question.
>
> Why do my posts not get accepted to the mailing list?
>
> Example:
> http://r.789695.n4.nabble.com/How-do-I-move-the-horizontal-axis-in-a-plot-so-that-it-starts-at-the-zero-of-the-vertical-axis-td4696935.html
>
> I don't understand why I always have this problem when I post and try to
> subscribe and I still haven't found a solution after three years.

This post *did* appear on the mailing list.  Do what you just did.

I would not have seen your earlier posts, because I don't read posts 
from nabble; perhaps they are now banned completely.

Duncan Murdoch


From nicole.ford at me.com  Thu Mar 19 20:00:18 2015
From: nicole.ford at me.com (Nicole Ford)
Date: Thu, 19 Mar 2015 15:00:18 -0400
Subject: [R] not a Stata version 5-12 .dta file
Message-ID: <8D0727FB-BD9E-4EA1-AEC8-7CC11E192810@me.com>

Hello,

I recently updated to the newest version of R and I am encountering issues.  Please find my error and session info below.  My data are attached.  I have tried the readstata13 package just in case to no avail.  Unless I am missing something, google isn?t helping.



Thank you in advance.



error:
> dat <- read.dta(file.choose())
Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously satisfy constraints:
(
    "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&- H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80 )>",
    "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&- H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80 )>",
    "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&- H:|-(0)-[FIFinderView:0x600000363a80]   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
    "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&- H:[FIFinderView:0x600000363a80]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
    "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
    "<NSLayoutConstraint:0x600000482d50 H:|-(0)-[NSView:0x60000012e380]   (Names: '|':NSView:0x60000012eba0 )>",
    "<NSLayoutConstraint:0x600000482da0 H:[NSView:0x60000012e380]-(0)-|   (Names: '|':NSView:0x60000012eba0 )>",
    "<NSLayoutConstraint:0x6000004816d0 H:[FILocationPopUp:0x6000001f2800(207)]>",
    "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX == FILocationPopUp:0x6000001f2800.centerX>",
    "<NSLayoutConstraint:0x6000004825d0 H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
    "<NSLayoutConstraint:0x600000482b70 H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names: '|':NSView:0x60000012e380 )>",
    "<NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>"
)

Will attempt to recover by breaking constraint 
<NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>

Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
> sessionInfo()

Session Info:
R version 3.1.3 (2015-03-09)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.1 (Yosemite)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2     Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25     

loaded via a namespace (and not attached):
 [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9      
[10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3  

~n







From nicole.ford at me.com  Thu Mar 19 20:00:18 2015
From: nicole.ford at me.com (Nicole Ford)
Date: Thu, 19 Mar 2015 15:00:18 -0400
Subject: [R] not a Stata version 5-12 .dta file
Message-ID: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>

Hello,

I recently updated to the newest version of R and I am encountering issues.  Please find my error and session info below.  My data are attached.  I have tried the readstata13 package just in case to no avail.  Unless I am missing something, google isn?t helping.



Thank you in advance.



error:
> dat <- read.dta(file.choose())
Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously satisfy constraints:
(
    "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&- H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80 )>",
    "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&- H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80 )>",
    "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&- H:|-(0)-[FIFinderView:0x600000363a80]   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
    "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&- H:[FIFinderView:0x600000363a80]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
    "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
    "<NSLayoutConstraint:0x600000482d50 H:|-(0)-[NSView:0x60000012e380]   (Names: '|':NSView:0x60000012eba0 )>",
    "<NSLayoutConstraint:0x600000482da0 H:[NSView:0x60000012e380]-(0)-|   (Names: '|':NSView:0x60000012eba0 )>",
    "<NSLayoutConstraint:0x6000004816d0 H:[FILocationPopUp:0x6000001f2800(207)]>",
    "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX == FILocationPopUp:0x6000001f2800.centerX>",
    "<NSLayoutConstraint:0x6000004825d0 H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
    "<NSLayoutConstraint:0x600000482b70 H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names: '|':NSView:0x60000012e380 )>",
    "<NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>"
)

Will attempt to recover by breaking constraint 
<NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>

Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
> sessionInfo()

Session Info:
R version 3.1.3 (2015-03-09)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.1 (Yosemite)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2     Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25     

loaded via a namespace (and not attached):
 [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9      
[10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3  

~n







From fli at teraproc.com  Thu Mar 19 20:24:55 2015
From: fli at teraproc.com (Feng Li)
Date: Thu, 19 Mar 2015 19:24:55 +0000
Subject: [R] Use BatchJobs package to submit Rmpi job
Message-ID: <BLUPR10MB0081D4CB53B5A229251382F7DA010@BLUPR10MB0081.namprd10.prod.outlook.com>

Hi,
BatchJobs package is popular to submit R batch jobs on various job scheduler. Now we are facing the question is to submit a Rmpi jobs. So we want to know how we can leverage BatchJobs to do so. After a bit investigation/enhancement, we tested below approach on OpenLava job scheduler. we want to get some inputs from the group to see how this makes sense to you. thanks,

1. R script that submit a Rmpi job using BatchJobs:
library(BatchJobs)
conf = BatchJobs:::getBatchJobsConf()
conf$cluster.functions = makeClusterFunctionsOpenLava("/home/clusteradmin/rmpi.tmpl")      <-- specify job template file that includes "mpirun" to start R job.
reg = makeRegistry(id = "RMPIJobsExample")
f = function(x) {                                                <-- RMPI algorithm function. This is the normal Rmpi R script.
                library("Rmpi")
                ...
                mpi.spawn.Rslaves(nslaves=slaveno)
                                                                ...
                mpi.remote.exec(paste("I am",mpi.comm.rank(),"of",mpi.comm.size()))
                ...
}
batchMap(reg, f, 1)                                       <-- specify 1 Rmpi job
submitJobs(reg, np=2)                                  <-- specify number of processors to use
showStatus(reg)
waitForJobs(reg)
                                            showStatus(reg)

2. the job template: rmpi.tmpl
                                            #BSUB -q mpi_job_queue
                                            /opt/openlava/bin/openmpi-mpirun -np 1 R CMD BATCH "<%= rscript %>"


Please let us know your comments,

Thanks,
Feng Li
Teraproc Inc.


	[[alternative HTML version deleted]]


From istazahn at gmail.com  Thu Mar 19 21:41:49 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 19 Mar 2015 16:41:49 -0400
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
Message-ID: <CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>

Hi Nicole,

Is it a stata 13 data file? If so your best bet is to open it in Stata
and use the "saveold" command to save it as a stata 12 file.

Best,
Ista

On Thu, Mar 19, 2015 at 3:00 PM, Nicole Ford <nicole.ford at me.com> wrote:
> Hello,
>
> I recently updated to the newest version of R and I am encountering issues.  Please find my error and session info below.  My data are attached.  I have tried the readstata13 package just in case to no avail.  Unless I am missing something, google isn?t helping.
>
>
>
> Thank you in advance.
>
>
>
> error:
>> dat <- read.dta(file.choose())
> Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
> 2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously satisfy constraints:
> (
>     "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&- H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80 )>",
>     "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&- H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80 )>",
>     "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&- H:|-(0)-[FIFinderView:0x600000363a80]   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>     "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&- H:[FIFinderView:0x600000363a80]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>     "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
>     "<NSLayoutConstraint:0x600000482d50 H:|-(0)-[NSView:0x60000012e380]   (Names: '|':NSView:0x60000012eba0 )>",
>     "<NSLayoutConstraint:0x600000482da0 H:[NSView:0x60000012e380]-(0)-|   (Names: '|':NSView:0x60000012eba0 )>",
>     "<NSLayoutConstraint:0x6000004816d0 H:[FILocationPopUp:0x6000001f2800(207)]>",
>     "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX == FILocationPopUp:0x6000001f2800.centerX>",
>     "<NSLayoutConstraint:0x6000004825d0 H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
>     "<NSLayoutConstraint:0x600000482b70 H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names: '|':NSView:0x60000012e380 )>",
>     "<NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>"
> )
>
> Will attempt to recover by breaking constraint
> <NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>
>
> Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
>> sessionInfo()
>
> Session Info:
> R version 3.1.3 (2015-03-09)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.10.1 (Yosemite)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2     Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25
>
> loaded via a namespace (and not attached):
>  [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9
> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3
>
> ~n
>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nicole.ford at me.com  Thu Mar 19 21:46:49 2015
From: nicole.ford at me.com (Nicole Ford)
Date: Thu, 19 Mar 2015 16:46:49 -0400
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
	<CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>
Message-ID: <7BEE39E2-30E6-4282-8F40-B13D0A5036E7@me.com>

Hello, Ista.  

Honestly, I am uncertain.  I don't have STATA -- I downloaded this from the data source website.

I can't imagine it is 13 because the data are old (2006).  

I tried package readstata13 out of desperation, but didn't think it would resolve.

Thanks for the suggestion!

Sent from my iPhone

> On Mar 19, 2015, at 4:41 PM, Ista Zahn <istazahn at gmail.com> wrote:
> 
> Hi Nicole,
> 
> Is it a stata 13 data file? If so your best bet is to open it in Stata
> and use the "saveold" command to save it as a stata 12 file.
> 
> Best,
> Ista
> 
>> On Thu, Mar 19, 2015 at 3:00 PM, Nicole Ford <nicole.ford at me.com> wrote:
>> Hello,
>> 
>> I recently updated to the newest version of R and I am encountering issues.  Please find my error and session info below.  My data are attached.  I have tried the readstata13 package just in case to no avail.  Unless I am missing something, google isn?t helping.
>> 
>> 
>> 
>> Thank you in advance.
>> 
>> 
>> 
>> error:
>>> dat <- read.dta(file.choose())
>> Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
>> 2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously satisfy constraints:
>> (
>>    "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&- H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80 )>",
>>    "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&- H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80 )>",
>>    "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&- H:|-(0)-[FIFinderView:0x600000363a80]   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>>    "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&- H:[FIFinderView:0x600000363a80]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>>    "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
>>    "<NSLayoutConstraint:0x600000482d50 H:|-(0)-[NSView:0x60000012e380]   (Names: '|':NSView:0x60000012eba0 )>",
>>    "<NSLayoutConstraint:0x600000482da0 H:[NSView:0x60000012e380]-(0)-|   (Names: '|':NSView:0x60000012eba0 )>",
>>    "<NSLayoutConstraint:0x6000004816d0 H:[FILocationPopUp:0x6000001f2800(207)]>",
>>    "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX == FILocationPopUp:0x6000001f2800.centerX>",
>>    "<NSLayoutConstraint:0x6000004825d0 H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
>>    "<NSLayoutConstraint:0x600000482b70 H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names: '|':NSView:0x60000012e380 )>",
>>    "<NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>"
>> )
>> 
>> Will attempt to recover by breaking constraint
>> <NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>
>> 
>> Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
>>> sessionInfo()
>> 
>> Session Info:
>> R version 3.1.3 (2015-03-09)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: OS X 10.10.1 (Yosemite)
>> 
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2     Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25
>> 
>> loaded via a namespace (and not attached):
>> [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9
>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3
>> 
>> ~n
>> 
>> 
>> 
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Mar 19 21:57:14 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 19 Mar 2015 16:57:14 -0400
Subject: [R] Tele_R - first experiences
In-Reply-To: <9A93A01584A6484FA7BF1EA4E1258932@Petra>
References: <9A93A01584A6484FA7BF1EA4E1258932@Petra>
Message-ID: <CA+vqiLFDdDSuMpVYxLVQ+Hj5RaUzy_mPCwa_NNxcXMH9eUaPWQ@mail.gmail.com>

Hey that's really nice. I'm not sure how practical it is, but it works
surprisingly well.

Best,
Ista

On Thu, Mar 19, 2015 at 8:21 AM, Dr. Wolfgang Lindner
<lindnerw at t-online.de> wrote:
> Dear R community,
>
> some days ago Enric Cervera Mateu has installed an R client
> with instant messaging, which is usable very simple via the
> public name @Tele_R in the messenger Telegram.
>
> I have tested Tele_R and e.g. tried most of the examples from
> [1] W.N. Venables, D.M. Smith, R Core Team. "An Introduction to R." R Core
> Team. iBooks.
> and of ?1 of
> [2] B. Everitt, T. Hothorn. "An R and S-plus Companion to Multivariate
> Analysis. Springer.
> All is working very good in this environment.
>
> I am very impressed. I like the possibility to use R without installation
> complications with my iPhone, iPad or HTC One.
> The answers are send very fast, the idea to use a chat for mathematics
> communication seems to be especially suited to beginners:
> direct dive in, OS as you like, working anywhere, talking over distance,
> communicate with your peers or students (share code or
> examples etc even during a lesson - if a beamer is not available) etc.
>
> I would like to thank Enric for his valuable work to make the great work of
> the R team accessible to smartphones and tablets.
> I think that Tele_R is a very comfortable tool for teaching and learning R
> at an undergraduate level.
>
> And I would like to hear about the experiences, opinions or ideas of other
> members of the R community with respect of the use of Tele_R.
>
> I hope that this is not the wrong list to say these words.
>
> Best,
> Wolfgang Lindner
> Leichlingen, Germany
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Mar 19 21:59:38 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 19 Mar 2015 16:59:38 -0400
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <7BEE39E2-30E6-4282-8F40-B13D0A5036E7@me.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
	<CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>
	<7BEE39E2-30E6-4282-8F40-B13D0A5036E7@me.com>
Message-ID: <CA+vqiLEbX=rmHw8YM0wWOHnAg6N_AVHht2Do-BWPRrmFDeRTDw@mail.gmail.com>

Is the file publicly available? What is the URL?

Best,
Ista

On Thu, Mar 19, 2015 at 4:46 PM, Nicole Ford <nicole.ford at me.com> wrote:
> Hello, Ista.
>
> Honestly, I am uncertain.  I don't have STATA -- I downloaded this from the data source website.
>
> I can't imagine it is 13 because the data are old (2006).
>
> I tried package readstata13 out of desperation, but didn't think it would resolve.
>
> Thanks for the suggestion!
>
> Sent from my iPhone
>
>> On Mar 19, 2015, at 4:41 PM, Ista Zahn <istazahn at gmail.com> wrote:
>>
>> Hi Nicole,
>>
>> Is it a stata 13 data file? If so your best bet is to open it in Stata
>> and use the "saveold" command to save it as a stata 12 file.
>>
>> Best,
>> Ista
>>
>>> On Thu, Mar 19, 2015 at 3:00 PM, Nicole Ford <nicole.ford at me.com> wrote:
>>> Hello,
>>>
>>> I recently updated to the newest version of R and I am encountering issues.  Please find my error and session info below.  My data are attached.  I have tried the readstata13 package just in case to no avail.  Unless I am missing something, google isn?t helping.
>>>
>>>
>>>
>>> Thank you in advance.
>>>
>>>
>>>
>>> error:
>>>> dat <- read.dta(file.choose())
>>> Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
>>> 2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously satisfy constraints:
>>> (
>>>    "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&- H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80 )>",
>>>    "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&- H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80 )>",
>>>    "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&- H:|-(0)-[FIFinderView:0x600000363a80]   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>>>    "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&- H:[FIFinderView:0x600000363a80]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>>>    "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
>>>    "<NSLayoutConstraint:0x600000482d50 H:|-(0)-[NSView:0x60000012e380]   (Names: '|':NSView:0x60000012eba0 )>",
>>>    "<NSLayoutConstraint:0x600000482da0 H:[NSView:0x60000012e380]-(0)-|   (Names: '|':NSView:0x60000012eba0 )>",
>>>    "<NSLayoutConstraint:0x6000004816d0 H:[FILocationPopUp:0x6000001f2800(207)]>",
>>>    "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX == FILocationPopUp:0x6000001f2800.centerX>",
>>>    "<NSLayoutConstraint:0x6000004825d0 H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
>>>    "<NSLayoutConstraint:0x600000482b70 H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names: '|':NSView:0x60000012e380 )>",
>>>    "<NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>"
>>> )
>>>
>>> Will attempt to recover by breaking constraint
>>> <NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>
>>>
>>> Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
>>>> sessionInfo()
>>>
>>> Session Info:
>>> R version 3.1.3 (2015-03-09)
>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>> Running under: OS X 10.10.1 (Yosemite)
>>>
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2     Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25
>>>
>>> loaded via a namespace (and not attached):
>>> [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9
>>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3
>>>
>>> ~n
>>>
>>>
>>>
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From nicole.ford at me.com  Thu Mar 19 22:08:44 2015
From: nicole.ford at me.com (Nicole Ford)
Date: Thu, 19 Mar 2015 17:08:44 -0400
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <CA+vqiLEbX=rmHw8YM0wWOHnAg6N_AVHht2Do-BWPRrmFDeRTDw@mail.gmail.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
	<CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>
	<7BEE39E2-30E6-4282-8F40-B13D0A5036E7@me.com>
	<CA+vqiLEbX=rmHw8YM0wWOHnAg6N_AVHht2Do-BWPRrmFDeRTDw@mail.gmail.com>
Message-ID: <380610A2-C626-4FB7-A706-B051B6510104@me.com>

Ista,

I am pulling multiple countries and multiple waves, but here is one country in one wave.  I know if I can get one to work, I can get them all to work.  I have used WVS data in the past and never encountered any issues, so I am at a loss here.  Thanks again!

http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp <http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp>


~Nicole






> On Mar 19, 2015, at 4:59 PM, Ista Zahn <istazahn at gmail.com> wrote:
> 
> Is the file publicly available? What is the URL?
> 
> Best,
> Ista
> 
> On Thu, Mar 19, 2015 at 4:46 PM, Nicole Ford <nicole.ford at me.com> wrote:
>> Hello, Ista.
>> 
>> Honestly, I am uncertain.  I don't have STATA -- I downloaded this from the data source website.
>> 
>> I can't imagine it is 13 because the data are old (2006).
>> 
>> I tried package readstata13 out of desperation, but didn't think it would resolve.
>> 
>> Thanks for the suggestion!
>> 
>> Sent from my iPhone
>> 
>>> On Mar 19, 2015, at 4:41 PM, Ista Zahn <istazahn at gmail.com> wrote:
>>> 
>>> Hi Nicole,
>>> 
>>> Is it a stata 13 data file? If so your best bet is to open it in Stata
>>> and use the "saveold" command to save it as a stata 12 file.
>>> 
>>> Best,
>>> Ista
>>> 
>>>> On Thu, Mar 19, 2015 at 3:00 PM, Nicole Ford <nicole.ford at me.com> wrote:
>>>> Hello,
>>>> 
>>>> I recently updated to the newest version of R and I am encountering issues.  Please find my error and session info below.  My data are attached.  I have tried the readstata13 package just in case to no avail.  Unless I am missing something, google isn?t helping.
>>>> 
>>>> 
>>>> 
>>>> Thank you in advance.
>>>> 
>>>> 
>>>> 
>>>> error:
>>>>> dat <- read.dta(file.choose())
>>>> Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
>>>> 2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously satisfy constraints:
>>>> (
>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&- H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80 )>",
>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&- H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80 )>",
>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&- H:|-(0)-[FIFinderView:0x600000363a80]   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&- H:[FIFinderView:0x600000363a80]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
>>>>   "<NSLayoutConstraint:0x600000482d50 H:|-(0)-[NSView:0x60000012e380]   (Names: '|':NSView:0x60000012eba0 )>",
>>>>   "<NSLayoutConstraint:0x600000482da0 H:[NSView:0x60000012e380]-(0)-|   (Names: '|':NSView:0x60000012eba0 )>",
>>>>   "<NSLayoutConstraint:0x6000004816d0 H:[FILocationPopUp:0x6000001f2800(207)]>",
>>>>   "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX == FILocationPopUp:0x6000001f2800.centerX>",
>>>>   "<NSLayoutConstraint:0x6000004825d0 H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
>>>>   "<NSLayoutConstraint:0x600000482b70 H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names: '|':NSView:0x60000012e380 )>",
>>>>   "<NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>"
>>>> )
>>>> 
>>>> Will attempt to recover by breaking constraint
>>>> <NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>
>>>> 
>>>> Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
>>>>> sessionInfo()
>>>> 
>>>> Session Info:
>>>> R version 3.1.3 (2015-03-09)
>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>> Running under: OS X 10.10.1 (Yosemite)
>>>> 
>>>> locale:
>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>> 
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>> 
>>>> other attached packages:
>>>> [1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2     Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25
>>>> 
>>>> loaded via a namespace (and not attached):
>>>> [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9
>>>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3
>>>> 
>>>> ~n
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From nicole.ford at me.com  Thu Mar 19 22:59:58 2015
From: nicole.ford at me.com (Nicole Ford)
Date: Thu, 19 Mar 2015 17:59:58 -0400
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <CA+vqiLEbX=rmHw8YM0wWOHnAg6N_AVHht2Do-BWPRrmFDeRTDw@mail.gmail.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
	<CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>
	<7BEE39E2-30E6-4282-8F40-B13D0A5036E7@me.com>
	<CA+vqiLEbX=rmHw8YM0wWOHnAg6N_AVHht2Do-BWPRrmFDeRTDw@mail.gmail.com>
Message-ID: <9FB067BE-5B15-45FE-9B75-5CBFDBC8FFF5@me.com>

 <https://www.icloud.com/attachment/?u=https%3A%2F%2Fms-us-bnx-101-prod.digitalhub.com%2FB%2FAYGiFiulFB2COHtRCU-_sQRlI29CAW_sHDofsKDQThnmmGMRJ-U31uHc%2F%24%7Bf%7D%3Fo%3DAssHSsJnuvs2xSKr9RbahRH8uL2dMLrQZ74X4K5mJvMu%26v%3D1%26x%3D3%26a%3DBcO0mGWsa3VAA0h-KgEA_wHIAP8gEr-c%26e%3D1429394397%26k%3D%24%7Buk%7D%26r%3D7D4FAE4C-D12E-4998-8153-C319E1A27CDF-1%26ckc%3Dcom.apple.largeattachment%26ckz%3D1F23936F-50D9-4B6F-AEB2-6C9A3F72ACB8%26z%3Dhttps%253A%252F%252Fp03-content.icloud.com%253A443%26s%3Ds0BPmPeuYYpZ24XTa4YdvCExEHg&uk=mdLWla1AWgDRCxhPQhZ8GQ&f=WV3_Data_rdata_v_2014_09_21.rdata&sz=54048483>
>  <mailto:istazahn at gmail.com> <mailto:nicole.ford at me.com> <mailto:istazahn at gmail.com> <mailto:nicole.ford at me.com> <mailto:R-help at r-project.org> <https://stat.ethz.ch/mailman/listinfo/r-help>
	[[alternative HTML version deleted]]


From nicole.ford at me.com  Thu Mar 19 23:09:11 2015
From: nicole.ford at me.com (Nicole Ford)
Date: Thu, 19 Mar 2015 18:09:11 -0400
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <380610A2-C626-4FB7-A706-B051B6510104@me.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
	<CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>
	<7BEE39E2-30E6-4282-8F40-B13D0A5036E7@me.com>
	<CA+vqiLEbX=rmHw8YM0wWOHnAg6N_AVHht2Do-BWPRrmFDeRTDw@mail.gmail.com>
	<380610A2-C626-4FB7-A706-B051B6510104@me.com>
Message-ID: <B026B0FB-B870-4AAA-B956-2E51BC9660E1@me.com>

the text  didn?t send for the R data file erros.  sorry about that.


2015-03-19 17:41:38.544 R[398:5728] Unable to simultaneously satisfy constraints:
(
    "<NSAutoresizingMaskLayoutConstraint:0x6000018966c0 h=-&- v=-&- H:|-(0)-[NSView:0x60000032da20]   (Names: '|':FIFinderView:0x6080003612c0 )>",
    "<NSAutoresizingMaskLayoutConstraint:0x6000012881b0 h=-&- v=-&- H:[NSView:0x60000032da20]-(0)-|   (Names: '|':FIFinderView:0x6080003612c0 )>",
    "<NSAutoresizingMaskLayoutConstraint:0x600000a8c710 h=-&- v=-&- H:|-(0)-[FIFinderView:0x6080003612c0]   (Names: '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
    "<NSAutoresizingMaskLayoutConstraint:0x60000128eb50 h=-&- v=-&- H:[FIFinderView:0x6080003612c0]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
    "<NSAutoresizingMaskLayoutConstraint:0x600000c93fb0 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000375fc0(585)]>",
    "<NSLayoutConstraint:0x60000149d740 H:|-(0)-[NSView:0x600000133ec0]   (Names: '|':NSView:0x60000032da20 )>",
    "<NSLayoutConstraint:0x600001489880 H:[NSView:0x600000133ec0]-(0)-|   (Names: '|':NSView:0x60000032da20 )>",
    "<NSLayoutConstraint:0x60000109e280 H:[FILocationPopUp:0x6000003fda00(207)]>",
    "<NSLayoutConstraint:0x600000a82760 NSView:0x600000133ec0.centerX == FILocationPopUp:0x6000003fda00.centerX>",
    "<NSLayoutConstraint:0x600000e835c0 H:[FILocationPopUp:0x6000003fda00]-(>=10)-[SGTSearchField:0x6000003bf800]>",
    "<NSLayoutConstraint:0x60000069f2c0 H:[SGTSearchField:0x6000003bf800]-(11)-|   (Names: '|':NSView:0x600000133ec0 )>",
    "<NSLayoutConstraint:0x6000006801e0 H:[SGTSearchField:0x6000003bf800(>=218)]>"
)

Will attempt to recover by breaking constraint 
<NSLayoutConstraint:0x6000006801e0 H:[SGTSearchField:0x6000003bf800(>=218)]>

Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
> str(dat)
 chr [1:2] ".Traceback" "WV3_Data_rdata_v_2014_09_21"
> ls(dat)
Error in as.environment(pos) : 
  no item called ".Traceback" on the search list
> dat
[1] ".Traceback"                  "WV3_Data_rdata_v_2014_09_21"
> sessionInfo()
R version 3.1.3 (2015-03-09)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.1 (Yosemite)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] readstata13_0.5-3 effects_3.0-3     lattice_0.20-30   lme4_1.1-7        Rcpp_0.11.2       Matrix_1.1-5      runjags_1.2.1-0   sm_2.2-5.4       
 [9] foreign_0.8-63    car_2.0-25       

loaded via a namespace (and not attached):
 [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9      
[10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3     
> 




> On Mar 19, 2015, at 5:08 PM, Nicole Ford <nicole.ford at me.com> wrote:
> 
> Ista,
> 
> I am pulling multiple countries and multiple waves, but here is one country in one wave.  I know if I can get one to work, I can get them all to work.  I have used WVS data in the past and never encountered any issues, so I am at a loss here.  Thanks again!
> 
> http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp <http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp>
> 
> 
> ~Nicole
> 
> 
> 
> 
> 
> 
>> On Mar 19, 2015, at 4:59 PM, Ista Zahn <istazahn at gmail.com <mailto:istazahn at gmail.com>> wrote:
>> 
>> Is the file publicly available? What is the URL?
>> 
>> Best,
>> Ista
>> 
>> On Thu, Mar 19, 2015 at 4:46 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com>> wrote:
>>> Hello, Ista.
>>> 
>>> Honestly, I am uncertain.  I don't have STATA -- I downloaded this from the data source website.
>>> 
>>> I can't imagine it is 13 because the data are old (2006).
>>> 
>>> I tried package readstata13 out of desperation, but didn't think it would resolve.
>>> 
>>> Thanks for the suggestion!
>>> 
>>> Sent from my iPhone
>>> 
>>>> On Mar 19, 2015, at 4:41 PM, Ista Zahn <istazahn at gmail.com <mailto:istazahn at gmail.com>> wrote:
>>>> 
>>>> Hi Nicole,
>>>> 
>>>> Is it a stata 13 data file? If so your best bet is to open it in Stata
>>>> and use the "saveold" command to save it as a stata 12 file.
>>>> 
>>>> Best,
>>>> Ista
>>>> 
>>>>> On Thu, Mar 19, 2015 at 3:00 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com>> wrote:
>>>>> Hello,
>>>>> 
>>>>> I recently updated to the newest version of R and I am encountering issues.  Please find my error and session info below.  My data are attached.  I have tried the readstata13 package just in case to no avail.  Unless I am missing something, google isn?t helping.
>>>>> 
>>>>> 
>>>>> 
>>>>> Thank you in advance.
>>>>> 
>>>>> 
>>>>> 
>>>>> error:
>>>>>> dat <- read.dta(file.choose())
>>>>> Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
>>>>> 2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously satisfy constraints:
>>>>> (
>>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&- H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80 )>",
>>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&- H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80 )>",
>>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&- H:|-(0)-[FIFinderView:0x600000363a80]   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&- H:[FIFinderView:0x600000363a80]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
>>>>>   "<NSLayoutConstraint:0x600000482d50 H:|-(0)-[NSView:0x60000012e380]   (Names: '|':NSView:0x60000012eba0 )>",
>>>>>   "<NSLayoutConstraint:0x600000482da0 H:[NSView:0x60000012e380]-(0)-|   (Names: '|':NSView:0x60000012eba0 )>",
>>>>>   "<NSLayoutConstraint:0x6000004816d0 H:[FILocationPopUp:0x6000001f2800(207)]>",
>>>>>   "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX == FILocationPopUp:0x6000001f2800.centerX>",
>>>>>   "<NSLayoutConstraint:0x6000004825d0 H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
>>>>>   "<NSLayoutConstraint:0x600000482b70 H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names: '|':NSView:0x60000012e380 )>",
>>>>>   "<NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>"
>>>>> )
>>>>> 
>>>>> Will attempt to recover by breaking constraint
>>>>> <NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>
>>>>> 
>>>>> Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
>>>>>> sessionInfo()
>>>>> 
>>>>> Session Info:
>>>>> R version 3.1.3 (2015-03-09)
>>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>>> Running under: OS X 10.10.1 (Yosemite)
>>>>> 
>>>>> locale:
>>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>> 
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>> 
>>>>> other attached packages:
>>>>> [1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2     Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25
>>>>> 
>>>>> loaded via a namespace (and not attached):
>>>>> [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9
>>>>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3
>>>>> 
>>>>> ~n
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
> 


	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Fri Mar 20 02:09:09 2015
From: ajdamico at gmail.com (Anthony Damico)
Date: Thu, 19 Mar 2015 21:09:09 -0400
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <B026B0FB-B870-4AAA-B956-2E51BC9660E1@me.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
	<CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>
	<7BEE39E2-30E6-4282-8F40-B13D0A5036E7@me.com>
	<CA+vqiLEbX=rmHw8YM0wWOHnAg6N_AVHht2Do-BWPRrmFDeRTDw@mail.gmail.com>
	<380610A2-C626-4FB7-A706-B051B6510104@me.com>
	<B026B0FB-B870-4AAA-B956-2E51BC9660E1@me.com>
Message-ID: <CAOwvMDzTnPABddRKgFUQc4j_i-+eEhN7joQ4HzC6XZ6vfWGp1Q@mail.gmail.com>

hi nicole, i have published easy to reproduce, well-documented code to
download and then analyze every file from every wave of the world values
survey here.  the download automation script should solve your problem, or
at least work around it  :)

http://www.asdfree.com/search/label/world%20values%20survey%20%28wvs%29





On Thu, Mar 19, 2015 at 6:09 PM, Nicole Ford <nicole.ford at me.com> wrote:

> the text  didn?t send for the R data file erros.  sorry about that.
>
>
> 2015-03-19 17:41:38.544 R[398:5728] Unable to simultaneously satisfy
> constraints:
> (
>     "<NSAutoresizingMaskLayoutConstraint:0x6000018966c0 h=-&- v=-&-
> H:|-(0)-[NSView:0x60000032da20]   (Names: '|':FIFinderView:0x6080003612c0
> )>",
>     "<NSAutoresizingMaskLayoutConstraint:0x6000012881b0 h=-&- v=-&-
> H:[NSView:0x60000032da20]-(0)-|   (Names: '|':FIFinderView:0x6080003612c0
> )>",
>     "<NSAutoresizingMaskLayoutConstraint:0x600000a8c710 h=-&- v=-&-
> H:|-(0)-[FIFinderView:0x6080003612c0]   (Names:
> '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>     "<NSAutoresizingMaskLayoutConstraint:0x60000128eb50 h=-&- v=-&-
> H:[FIFinderView:0x6080003612c0]-(0)-|   (Names:
> '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>     "<NSAutoresizingMaskLayoutConstraint:0x600000c93fb0 h=--& v=--&
> H:[NSNavFinderViewFileBrowser:0x608000375fc0(585)]>",
>     "<NSLayoutConstraint:0x60000149d740 H:|-(0)-[NSView:0x600000133ec0]
>  (Names: '|':NSView:0x60000032da20 )>",
>     "<NSLayoutConstraint:0x600001489880 H:[NSView:0x600000133ec0]-(0)-|
>  (Names: '|':NSView:0x60000032da20 )>",
>     "<NSLayoutConstraint:0x60000109e280
> H:[FILocationPopUp:0x6000003fda00(207)]>",
>     "<NSLayoutConstraint:0x600000a82760 NSView:0x600000133ec0.centerX ==
> FILocationPopUp:0x6000003fda00.centerX>",
>     "<NSLayoutConstraint:0x600000e835c0
> H:[FILocationPopUp:0x6000003fda00]-(>=10)-[SGTSearchField:0x6000003bf800]>",
>     "<NSLayoutConstraint:0x60000069f2c0
> H:[SGTSearchField:0x6000003bf800]-(11)-|   (Names:
> '|':NSView:0x600000133ec0 )>",
>     "<NSLayoutConstraint:0x6000006801e0
> H:[SGTSearchField:0x6000003bf800(>=218)]>"
> )
>
> Will attempt to recover by breaking constraint
> <NSLayoutConstraint:0x6000006801e0
> H:[SGTSearchField:0x6000003bf800(>=218)]>
>
> Set the NSUserDefault
> NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have
> -[NSWindow visualizeConstraints:] automatically called when this happens.
> And/or, break on objc_exception_throw to catch this in the debugger.
> > str(dat)
>  chr [1:2] ".Traceback" "WV3_Data_rdata_v_2014_09_21"
> > ls(dat)
> Error in as.environment(pos) :
>   no item called ".Traceback" on the search list
> > dat
> [1] ".Traceback"                  "WV3_Data_rdata_v_2014_09_21"
> > sessionInfo()
> R version 3.1.3 (2015-03-09)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.10.1 (Yosemite)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>  [1] readstata13_0.5-3 effects_3.0-3     lattice_0.20-30   lme4_1.1-7
>   Rcpp_0.11.2       Matrix_1.1-5      runjags_1.2.1-0   sm_2.2-5.4
>  [9] foreign_0.8-63    car_2.0-25
>
> loaded via a namespace (and not attached):
>  [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39
> mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0
>  nnet_7.3-9
> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6
> splines_3.1.3    tools_3.1.3
> >
>
>
>
>
> > On Mar 19, 2015, at 5:08 PM, Nicole Ford <nicole.ford at me.com> wrote:
> >
> > Ista,
> >
> > I am pulling multiple countries and multiple waves, but here is one
> country in one wave.  I know if I can get one to work, I can get them all
> to work.  I have used WVS data in the past and never encountered any
> issues, so I am at a loss here.  Thanks again!
> >
> > http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp <
> http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp>
> >
> >
> > ~Nicole
> >
> >
> >
> >
> >
> >
> >> On Mar 19, 2015, at 4:59 PM, Ista Zahn <istazahn at gmail.com <mailto:
> istazahn at gmail.com>> wrote:
> >>
> >> Is the file publicly available? What is the URL?
> >>
> >> Best,
> >> Ista
> >>
> >> On Thu, Mar 19, 2015 at 4:46 PM, Nicole Ford <nicole.ford at me.com
> <mailto:nicole.ford at me.com>> wrote:
> >>> Hello, Ista.
> >>>
> >>> Honestly, I am uncertain.  I don't have STATA -- I downloaded this
> from the data source website.
> >>>
> >>> I can't imagine it is 13 because the data are old (2006).
> >>>
> >>> I tried package readstata13 out of desperation, but didn't think it
> would resolve.
> >>>
> >>> Thanks for the suggestion!
> >>>
> >>> Sent from my iPhone
> >>>
> >>>> On Mar 19, 2015, at 4:41 PM, Ista Zahn <istazahn at gmail.com <mailto:
> istazahn at gmail.com>> wrote:
> >>>>
> >>>> Hi Nicole,
> >>>>
> >>>> Is it a stata 13 data file? If so your best bet is to open it in Stata
> >>>> and use the "saveold" command to save it as a stata 12 file.
> >>>>
> >>>> Best,
> >>>> Ista
> >>>>
> >>>>> On Thu, Mar 19, 2015 at 3:00 PM, Nicole Ford <nicole.ford at me.com
> <mailto:nicole.ford at me.com>> wrote:
> >>>>> Hello,
> >>>>>
> >>>>> I recently updated to the newest version of R and I am encountering
> issues.  Please find my error and session info below.  My data are
> attached.  I have tried the readstata13 package just in case to no avail.
> Unless I am missing something, google isn?t helping.
> >>>>>
> >>>>>
> >>>>>
> >>>>> Thank you in advance.
> >>>>>
> >>>>>
> >>>>>
> >>>>> error:
> >>>>>> dat <- read.dta(file.choose())
> >>>>> Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
> >>>>> 2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously satisfy
> constraints:
> >>>>> (
> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&-
> H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80
> )>",
> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&-
> H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80
> )>",
> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&-
> H:|-(0)-[FIFinderView:0x600000363a80]   (Names:
> '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&-
> H:[FIFinderView:0x600000363a80]-(0)-|   (Names:
> '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--&
> H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
> >>>>>   "<NSLayoutConstraint:0x600000482d50
> H:|-(0)-[NSView:0x60000012e380]   (Names: '|':NSView:0x60000012eba0 )>",
> >>>>>   "<NSLayoutConstraint:0x600000482da0
> H:[NSView:0x60000012e380]-(0)-|   (Names: '|':NSView:0x60000012eba0 )>",
> >>>>>   "<NSLayoutConstraint:0x6000004816d0
> H:[FILocationPopUp:0x6000001f2800(207)]>",
> >>>>>   "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX
> == FILocationPopUp:0x6000001f2800.centerX>",
> >>>>>   "<NSLayoutConstraint:0x6000004825d0
> H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
> >>>>>   "<NSLayoutConstraint:0x600000482b70
> H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names:
> '|':NSView:0x60000012e380 )>",
> >>>>>   "<NSLayoutConstraint:0x6000004814f0
> H:[SGTSearchField:0x6000003a5160(>=218)]>"
> >>>>> )
> >>>>>
> >>>>> Will attempt to recover by breaking constraint
> >>>>> <NSLayoutConstraint:0x6000004814f0
> H:[SGTSearchField:0x6000003a5160(>=218)]>
> >>>>>
> >>>>> Set the NSUserDefault
> NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have
> -[NSWindow visualizeConstraints:] automatically called when this happens.
> And/or, break on objc_exception_throw to catch this in the debugger.
> >>>>>> sessionInfo()
> >>>>>
> >>>>> Session Info:
> >>>>> R version 3.1.3 (2015-03-09)
> >>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> >>>>> Running under: OS X 10.10.1 (Yosemite)
> >>>>>
> >>>>> locale:
> >>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >>>>>
> >>>>> attached base packages:
> >>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>>>>
> >>>>> other attached packages:
> >>>>> [1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2
>  Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25
> >>>>>
> >>>>> loaded via a namespace (and not attached):
> >>>>> [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39
>     mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0
>  nnet_7.3-9
> >>>>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6
>     splines_3.1.3    tools_3.1.3
> >>>>>
> >>>>> ~n
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help>
> >>>>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Fri Mar 20 03:10:31 2015
From: miaojpm at gmail.com (jpm miao)
Date: Fri, 20 Mar 2015 10:10:31 +0800
Subject: [R] r2wd (Write R to Word) in Chinese
Message-ID: <CABcx46Cwc3z1LLPD6zj=i6e4D6XZkYuNB2TBJbYDEJd_M_HXdg@mail.gmail.com>

Hi,

   The package "r2wd" is good at writing MS Word document from R.

   Can Chinese be written into MS Word by this package or any other method
from R? Are Chinese fonts (e.g., Kai ??) available in r2wd?

Thanks!

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Fri Mar 20 03:31:12 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 19 Mar 2015 22:31:12 -0400
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <F4E449EC-2A65-46A2-9245-FFE23C70C0E6@me.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
	<CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>
	<7BEE39E2-30E6-4282-8F40-B13D0A5036E7@me.com>
	<CA+vqiLEbX=rmHw8YM0wWOHnAg6N_AVHht2Do-BWPRrmFDeRTDw@mail.gmail.com>
	<380610A2-C626-4FB7-A706-B051B6510104@me.com>
	<B026B0FB-B870-4AAA-B956-2E51BC9660E1@me.com>
	<541141CA-0069-4C30-9F78-2C6EAA48AF83@me.com>
	<CA+vqiLFJ2ttgyxL7xTA9+5xFQ822O4mcZ-e-RO=D++LXdBxwDQ@mail.gmail.com>
	<F4E449EC-2A65-46A2-9245-FFE23C70C0E6@me.com>
Message-ID: <CA+vqiLGJ7wf_4a7z+1wuyKYgmFvd7efXkS-ePZh1GVmRzRbcCw@mail.gmail.com>

That is not a Stata data file, but a plain text data file. You can try
reading it into R like

x <- read.table("WV3_Data_Russia_1995_stata_v_2014_04_28.dat",
fill = TRUE)

but you won't know what anything is. The metadata is in the .dct file,
in a format only Stata can love...

Best,
Ista

On Thu, Mar 19, 2015 at 9:50 PM, Nicole Ford <nicole.ford at me.com> wrote:
> It seems the problem I am having is actually on the WVS end. The files I am
> downloading seem to have incorrect endings?  for example:
>
> WV3_Data_Russia_1995_stata_v_2014_04_28.dat
>
> I have emailed them and let them know.
> ~Nicole Ford
> Ph.D. Candidate/ Instructor
> University of South Florida
> Government and International Affairs
> Visitor, University of Rochester
> office: Gavett 303P
> e: nicole.ford at me.com
> http://usf.academia.edu/NicoleFord
>
>
>
>
>
>
> On Mar 19, 2015, at 8:53 PM, Ista Zahn <istazahn at gmail.com> wrote:
>
> Does
>
> /Users/nicoleford/Desktop/Russia2006.dta
>
> exist? What does
>
> list.files("/Users/nicoleford/Desktop", pattern = "\\.dta")
>
> say?
>
> On Thu, Mar 19, 2015 at 8:35 PM, Nicole Ford <nicole.ford at me.com> wrote:
>
> ok so after another restart- I got rid of some of the errors.  But I am
> still unable to load and R is telling me it is not a stata13 file.
>
> dat <- read.dta13(file.choose())
>
> Error: First byte: Not a version 13 dta-file.
>
> options(useFancyQuotes=F)
> dat <- read.dta(file.choose())
>
> Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
>
> options(useFancyQuotes=F)
> dat <- read.dta('/Users/nicoleford/Desktop/Russia2006.dta')
>
> Error in read.dta("/Users/nicoleford/Desktop/Russia2006.dta") :
>  unable to open file: 'No such file or directory'
>
> dat <- read.dta(file='/Users/nicoleford/Desktop/Russia2006.dta')
>
> Error in read.dta(file = "/Users/nicoleford/Desktop/Russia2006.dta") :
>  unable to open file: 'No such file or directory?
>
> I?m really at a loss.
> ~Nicole Ford
> Ph.D. Candidate/ Instructor
> University of South Florida
> Government and International Affairs
> Visitor, University of Rochester
> office: Gavett 303P
> e: nford5 at ur.rochester.edu
> http://usf.academia.edu/NicoleFord
>
>
>
>
>
>
> On Mar 19, 2015, at 6:09 PM, Nicole Ford <nicole.ford at me.com> wrote:
>
> the text  didn?t send for the R data file erros.  sorry about that.
>
>
> 2015-03-19 17:41:38.544 R[398:5728] Unable to simultaneously satisfy
> constraints:
> (
>    "<NSAutoresizingMaskLayoutConstraint:0x6000018966c0 h=-&- v=-&-
> H:|-(0)-[NSView:0x60000032da20]   (Names: '|':FIFinderView:0x6080003612c0
> )>",
>    "<NSAutoresizingMaskLayoutConstraint:0x6000012881b0 h=-&- v=-&-
> H:[NSView:0x60000032da20]-(0)-|   (Names: '|':FIFinderView:0x6080003612c0
> )>",
>    "<NSAutoresizingMaskLayoutConstraint:0x600000a8c710 h=-&- v=-&-
> H:|-(0)-[FIFinderView:0x6080003612c0]   (Names:
> '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>    "<NSAutoresizingMaskLayoutConstraint:0x60000128eb50 h=-&- v=-&-
> H:[FIFinderView:0x6080003612c0]-(0)-|   (Names:
> '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>    "<NSAutoresizingMaskLayoutConstraint:0x600000c93fb0 h=--& v=--&
> H:[NSNavFinderViewFileBrowser:0x608000375fc0(585)]>",
>    "<NSLayoutConstraint:0x60000149d740 H:|-(0)-[NSView:0x600000133ec0]
> (Names: '|':NSView:0x60000032da20 )>",
>    "<NSLayoutConstraint:0x600001489880 H:[NSView:0x600000133ec0]-(0)-|
> (Names: '|':NSView:0x60000032da20 )>",
>    "<NSLayoutConstraint:0x60000109e280
> H:[FILocationPopUp:0x6000003fda00(207)]>",
>    "<NSLayoutConstraint:0x600000a82760 NSView:0x600000133ec0.centerX ==
> FILocationPopUp:0x6000003fda00.centerX>",
>    "<NSLayoutConstraint:0x600000e835c0
> H:[FILocationPopUp:0x6000003fda00]-(>=10)-[SGTSearchField:0x6000003bf800]>",
>    "<NSLayoutConstraint:0x60000069f2c0
> H:[SGTSearchField:0x6000003bf800]-(11)-|   (Names: '|':NSView:0x600000133ec0
> )>",
>    "<NSLayoutConstraint:0x6000006801e0
> H:[SGTSearchField:0x6000003bf800(>=218)]>"
> )
>
> Will attempt to recover by breaking constraint
> <NSLayoutConstraint:0x6000006801e0 H:[SGTSearchField:0x6000003bf800(>=218)]>
>
> Set the NSUserDefault
> NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have
> -[NSWindow visualizeConstraints:] automatically called when this happens.
> And/or, break on objc_exception_throw to catch this in the debugger.
>
> str(dat)
>
> chr [1:2] ".Traceback" "WV3_Data_rdata_v_2014_09_21"
>
> ls(dat)
>
> Error in as.environment(pos) :
>  no item called ".Traceback" on the search list
>
> dat
>
> [1] ".Traceback"                  "WV3_Data_rdata_v_2014_09_21"
>
> sessionInfo()
>
> R version 3.1.3 (2015-03-09)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.10.1 (Yosemite)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] readstata13_0.5-3 effects_3.0-3     lattice_0.20-30   lme4_1.1-7
> Rcpp_0.11.2       Matrix_1.1-5      runjags_1.2.1-0   sm_2.2-5.4
> [9] foreign_0.8-63    car_2.0-25
>
> loaded via a namespace (and not attached):
> [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39
> mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0
> nnet_7.3-9
> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6
> splines_3.1.3    tools_3.1.3
>
>
>
>
>
>
> On Mar 19, 2015, at 5:08 PM, Nicole Ford <nicole.ford at me.com> wrote:
>
> Ista,
>
> I am pulling multiple countries and multiple waves, but here is one country
> in one wave.  I know if I can get one to work, I can get them all to work.
> I have used WVS data in the past and never encountered any issues, so I am
> at a loss here.  Thanks again!
>
> http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp
>
>
> ~Nicole
>
>
>
>
>
>
> On Mar 19, 2015, at 4:59 PM, Ista Zahn <istazahn at gmail.com> wrote:
>
> Is the file publicly available? What is the URL?
>
> Best,
> Ista
>
> On Thu, Mar 19, 2015 at 4:46 PM, Nicole Ford <nicole.ford at me.com> wrote:
>
> Hello, Ista.
>
> Honestly, I am uncertain.  I don't have STATA -- I downloaded this from the
> data source website.
>
> I can't imagine it is 13 because the data are old (2006).
>
> I tried package readstata13 out of desperation, but didn't think it would
> resolve.
>
> Thanks for the suggestion!
>
> Sent from my iPhone
>
> On Mar 19, 2015, at 4:41 PM, Ista Zahn <istazahn at gmail.com> wrote:
>
> Hi Nicole,
>
> Is it a stata 13 data file? If so your best bet is to open it in Stata
> and use the "saveold" command to save it as a stata 12 file.
>
> Best,
> Ista
>
> On Thu, Mar 19, 2015 at 3:00 PM, Nicole Ford <nicole.ford at me.com> wrote:
> Hello,
>
> I recently updated to the newest version of R and I am encountering issues.
> Please find my error and session info below.  My data are attached.  I have
> tried the readstata13 package just in case to no avail.  Unless I am missing
> something, google isn?t helping.
>
>
>
> Thank you in advance.
>
>
>
> error:
>
> dat <- read.dta(file.choose())
>
> Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
> 2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously satisfy
> constraints:
> (
>  "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&-
> H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80
> )>",
>  "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&-
> H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80
> )>",
>  "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&-
> H:|-(0)-[FIFinderView:0x600000363a80]   (Names:
> '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>  "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&-
> H:[FIFinderView:0x600000363a80]-(0)-|   (Names:
> '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>  "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--&
> H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
>  "<NSLayoutConstraint:0x600000482d50 H:|-(0)-[NSView:0x60000012e380]
> (Names: '|':NSView:0x60000012eba0 )>",
>  "<NSLayoutConstraint:0x600000482da0 H:[NSView:0x60000012e380]-(0)-|
> (Names: '|':NSView:0x60000012eba0 )>",
>  "<NSLayoutConstraint:0x6000004816d0
> H:[FILocationPopUp:0x6000001f2800(207)]>",
>  "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX ==
> FILocationPopUp:0x6000001f2800.centerX>",
>  "<NSLayoutConstraint:0x6000004825d0
> H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
>  "<NSLayoutConstraint:0x600000482b70
> H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names: '|':NSView:0x60000012e380
> )>",
>  "<NSLayoutConstraint:0x6000004814f0
> H:[SGTSearchField:0x6000003a5160(>=218)]>"
> )
>
> Will attempt to recover by breaking constraint
> <NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>
>
> Set the NSUserDefault
> NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have
> -[NSWindow visualizeConstraints:] automatically called when this happens.
> And/or, break on objc_exception_throw to catch this in the debugger.
>
> sessionInfo()
>
>
> Session Info:
> R version 3.1.3 (2015-03-09)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.10.1 (Yosemite)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2
> Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25
>
> loaded via a namespace (and not attached):
> [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39
> mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0
> nnet_7.3-9
> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6
> splines_3.1.3    tools_3.1.3
>
> ~n
>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>


From nicole.ford at me.com  Fri Mar 20 05:04:40 2015
From: nicole.ford at me.com (Nicole Ford)
Date: Fri, 20 Mar 2015 00:04:40 -0400
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <CAOwvMDzTnPABddRKgFUQc4j_i-+eEhN7joQ4HzC6XZ6vfWGp1Q@mail.gmail.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
	<CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>
	<7BEE39E2-30E6-4282-8F40-B13D0A5036E7@me.com>
	<CA+vqiLEbX=rmHw8YM0wWOHnAg6N_AVHht2Do-BWPRrmFDeRTDw@mail.gmail.com>
	<380610A2-C626-4FB7-A706-B051B6510104@me.com>
	<B026B0FB-B870-4AAA-B956-2E51BC9660E1@me.com>
	<CAOwvMDzTnPABddRKgFUQc4j_i-+eEhN7joQ4HzC6XZ6vfWGp1Q@mail.gmail.com>
Message-ID: <FCB331C2-088F-4B9D-BA8E-BF9189D0652E@me.com>

Anthony,

Thanks for this.  The issue I am having is WVS didn?t save all of their stata files, it seems, as .dta.  Further, the .rdata files are not loading correctly, either, giving me .Traceback or crashes R when I try to source it.  I will poke around your link to see if it can provide any insight.

~n







> On Mar 19, 2015, at 9:09 PM, Anthony Damico <ajdamico at gmail.com> wrote:
> 
> hi nicole, i have published easy to reproduce, well-documented code to download and then analyze every file from every wave of the world values survey here.  the download automation script should solve your problem, or at least work around it  :)
> 
> http://www.asdfree.com/search/label/world%20values%20survey%20%28wvs%29 <http://www.asdfree.com/search/label/world%20values%20survey%20%28wvs%29>
> 
> 
> 
> 
> 
> On Thu, Mar 19, 2015 at 6:09 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com>> wrote:
> the text  didn?t send for the R data file erros.  sorry about that.
> 
> 
> 2015-03-19 17:41:38.544 R[398:5728] Unable to simultaneously satisfy constraints:
> (
>     "<NSAutoresizingMaskLayoutConstraint:0x6000018966c0 h=-&- v=-&- H:|-(0)-[NSView:0x60000032da20]   (Names: '|':FIFinderView:0x6080003612c0 )>",
>     "<NSAutoresizingMaskLayoutConstraint:0x6000012881b0 h=-&- v=-&- H:[NSView:0x60000032da20]-(0)-|   (Names: '|':FIFinderView:0x6080003612c0 )>",
>     "<NSAutoresizingMaskLayoutConstraint:0x600000a8c710 h=-&- v=-&- H:|-(0)-[FIFinderView:0x6080003612c0]   (Names: '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>     "<NSAutoresizingMaskLayoutConstraint:0x60000128eb50 h=-&- v=-&- H:[FIFinderView:0x6080003612c0]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>     "<NSAutoresizingMaskLayoutConstraint:0x600000c93fb0 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000375fc0(585)]>",
>     "<NSLayoutConstraint:0x60000149d740 H:|-(0)-[NSView:0x600000133ec0]   (Names: '|':NSView:0x60000032da20 )>",
>     "<NSLayoutConstraint:0x600001489880 H:[NSView:0x600000133ec0]-(0)-|   (Names: '|':NSView:0x60000032da20 )>",
>     "<NSLayoutConstraint:0x60000109e280 H:[FILocationPopUp:0x6000003fda00(207)]>",
>     "<NSLayoutConstraint:0x600000a82760 NSView:0x600000133ec0.centerX == FILocationPopUp:0x6000003fda00.centerX>",
>     "<NSLayoutConstraint:0x600000e835c0 H:[FILocationPopUp:0x6000003fda00]-(>=10)-[SGTSearchField:0x6000003bf800]>",
>     "<NSLayoutConstraint:0x60000069f2c0 H:[SGTSearchField:0x6000003bf800]-(11)-|   (Names: '|':NSView:0x600000133ec0 )>",
>     "<NSLayoutConstraint:0x6000006801e0 H:[SGTSearchField:0x6000003bf800(>=218)]>"
> )
> 
> Will attempt to recover by breaking constraint
> <NSLayoutConstraint:0x6000006801e0 H:[SGTSearchField:0x6000003bf800(>=218)]>
> 
> Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
> > str(dat)
>  chr [1:2] ".Traceback" "WV3_Data_rdata_v_2014_09_21"
> > ls(dat)
> Error in as.environment(pos) :
>   no item called ".Traceback" on the search list
> > dat
> [1] ".Traceback"                  "WV3_Data_rdata_v_2014_09_21"
> > sessionInfo()
> R version 3.1.3 (2015-03-09)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.10.1 (Yosemite)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
>  [1] readstata13_0.5-3 effects_3.0-3     lattice_0.20-30   lme4_1.1-7        Rcpp_0.11.2       Matrix_1.1-5      runjags_1.2.1-0   sm_2.2-5.4
>  [9] foreign_0.8-63    car_2.0-25
> 
> loaded via a namespace (and not attached):
>  [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9
> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3
> >
> 
> 
> 
> 
> > On Mar 19, 2015, at 5:08 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com>> wrote:
> >
> > Ista,
> >
> > I am pulling multiple countries and multiple waves, but here is one country in one wave.  I know if I can get one to work, I can get them all to work.  I have used WVS data in the past and never encountered any issues, so I am at a loss here.  Thanks again!
> >
> > http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp <http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp><http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp <http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp>>
> >
> >
> > ~Nicole
> >
> >
> >
> >
> >
> >
> >> On Mar 19, 2015, at 4:59 PM, Ista Zahn <istazahn at gmail.com <mailto:istazahn at gmail.com> <mailto:istazahn at gmail.com <mailto:istazahn at gmail.com>>> wrote:
> >>
> >> Is the file publicly available? What is the URL?
> >>
> >> Best,
> >> Ista
> >>
> >> On Thu, Mar 19, 2015 at 4:46 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com> <mailto:nicole.ford at me.com <mailto:nicole.ford at me.com>>> wrote:
> >>> Hello, Ista.
> >>>
> >>> Honestly, I am uncertain.  I don't have STATA -- I downloaded this from the data source website.
> >>>
> >>> I can't imagine it is 13 because the data are old (2006).
> >>>
> >>> I tried package readstata13 out of desperation, but didn't think it would resolve.
> >>>
> >>> Thanks for the suggestion!
> >>>
> >>> Sent from my iPhone
> >>>
> >>>> On Mar 19, 2015, at 4:41 PM, Ista Zahn <istazahn at gmail.com <mailto:istazahn at gmail.com> <mailto:istazahn at gmail.com <mailto:istazahn at gmail.com>>> wrote:
> >>>>
> >>>> Hi Nicole,
> >>>>
> >>>> Is it a stata 13 data file? If so your best bet is to open it in Stata
> >>>> and use the "saveold" command to save it as a stata 12 file.
> >>>>
> >>>> Best,
> >>>> Ista
> >>>>
> >>>>> On Thu, Mar 19, 2015 at 3:00 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com> <mailto:nicole.ford at me.com <mailto:nicole.ford at me.com>>> wrote:
> >>>>> Hello,
> >>>>>
> >>>>> I recently updated to the newest version of R and I am encountering issues.  Please find my error and session info below.  My data are attached.  I have tried the readstata13 package just in case to no avail.  Unless I am missing something, google isn?t helping.
> >>>>>
> >>>>>
> >>>>>
> >>>>> Thank you in advance.
> >>>>>
> >>>>>
> >>>>>
> >>>>> error:
> >>>>>> dat <- read.dta(file.choose())
> >>>>> Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
> >>>>> 2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously satisfy constraints:
> >>>>> (
> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&- H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80 )>",
> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&- H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80 )>",
> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&- H:|-(0)-[FIFinderView:0x600000363a80]   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&- H:[FIFinderView:0x600000363a80]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
> >>>>>   "<NSLayoutConstraint:0x600000482d50 H:|-(0)-[NSView:0x60000012e380]   (Names: '|':NSView:0x60000012eba0 )>",
> >>>>>   "<NSLayoutConstraint:0x600000482da0 H:[NSView:0x60000012e380]-(0)-|   (Names: '|':NSView:0x60000012eba0 )>",
> >>>>>   "<NSLayoutConstraint:0x6000004816d0 H:[FILocationPopUp:0x6000001f2800(207)]>",
> >>>>>   "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX == FILocationPopUp:0x6000001f2800.centerX>",
> >>>>>   "<NSLayoutConstraint:0x6000004825d0 H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
> >>>>>   "<NSLayoutConstraint:0x600000482b70 H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names: '|':NSView:0x60000012e380 )>",
> >>>>>   "<NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>"
> >>>>> )
> >>>>>
> >>>>> Will attempt to recover by breaking constraint
> >>>>> <NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>
> >>>>>
> >>>>> Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
> >>>>>> sessionInfo()
> >>>>>
> >>>>> Session Info:
> >>>>> R version 3.1.3 (2015-03-09)
> >>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> >>>>> Running under: OS X 10.10.1 (Yosemite)
> >>>>>
> >>>>> locale:
> >>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >>>>>
> >>>>> attached base packages:
> >>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>>>>
> >>>>> other attached packages:
> >>>>> [1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2     Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25
> >>>>>
> >>>>> loaded via a namespace (and not attached):
> >>>>> [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9
> >>>>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3
> >>>>>
> >>>>> ~n
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help> <https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
> >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Fri Mar 20 05:09:40 2015
From: ajdamico at gmail.com (Anthony Damico)
Date: Fri, 20 Mar 2015 00:09:40 -0400
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <FCB331C2-088F-4B9D-BA8E-BF9189D0652E@me.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
	<CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>
	<7BEE39E2-30E6-4282-8F40-B13D0A5036E7@me.com>
	<CA+vqiLEbX=rmHw8YM0wWOHnAg6N_AVHht2Do-BWPRrmFDeRTDw@mail.gmail.com>
	<380610A2-C626-4FB7-A706-B051B6510104@me.com>
	<B026B0FB-B870-4AAA-B956-2E51BC9660E1@me.com>
	<CAOwvMDzTnPABddRKgFUQc4j_i-+eEhN7joQ4HzC6XZ6vfWGp1Q@mail.gmail.com>
	<FCB331C2-088F-4B9D-BA8E-BF9189D0652E@me.com>
Message-ID: <CAOwvMDzP1x8hACphEayrN=WTjc7=MrTD0uJUEjtpHPUR6FtPaA@mail.gmail.com>

doesn't just running this solve your problem?

https://github.com/ajdamico/usgsd/blob/master/World%20Values%20Survey/download%20all%20microdata.R


On Fri, Mar 20, 2015 at 12:04 AM, Nicole Ford <nicole.ford at me.com> wrote:

> Anthony,
>
> Thanks for this.  The issue I am having is WVS didn?t save all of their
> stata files, it seems, as .dta.  Further, the .rdata files are not loading
> correctly, either, giving me .Traceback or crashes R when I try to source
> it.  I will poke around your link to see if it can provide any insight.
>
> ~n
>
>
>
>
>
>
>
> On Mar 19, 2015, at 9:09 PM, Anthony Damico <ajdamico at gmail.com> wrote:
>
> hi nicole, i have published easy to reproduce, well-documented code to
> download and then analyze every file from every wave of the world values
> survey here.  the download automation script should solve your problem, or
> at least work around it  :)
>
> http://www.asdfree.com/search/label/world%20values%20survey%20%28wvs%29
>
>
>
>
>
> On Thu, Mar 19, 2015 at 6:09 PM, Nicole Ford <nicole.ford at me.com> wrote:
>
>> the text  didn?t send for the R data file erros.  sorry about that.
>>
>>
>> 2015-03-19 17:41:38.544 R[398:5728] Unable to simultaneously satisfy
>> constraints:
>> (
>>     "<NSAutoresizingMaskLayoutConstraint:0x6000018966c0 h=-&- v=-&-
>> H:|-(0)-[NSView:0x60000032da20]   (Names: '|':FIFinderView:0x6080003612c0
>> )>",
>>     "<NSAutoresizingMaskLayoutConstraint:0x6000012881b0 h=-&- v=-&-
>> H:[NSView:0x60000032da20]-(0)-|   (Names: '|':FIFinderView:0x6080003612c0
>> )>",
>>     "<NSAutoresizingMaskLayoutConstraint:0x600000a8c710 h=-&- v=-&-
>> H:|-(0)-[FIFinderView:0x6080003612c0]   (Names:
>> '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>>     "<NSAutoresizingMaskLayoutConstraint:0x60000128eb50 h=-&- v=-&-
>> H:[FIFinderView:0x6080003612c0]-(0)-|   (Names:
>> '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>>     "<NSAutoresizingMaskLayoutConstraint:0x600000c93fb0 h=--& v=--&
>> H:[NSNavFinderViewFileBrowser:0x608000375fc0(585)]>",
>>     "<NSLayoutConstraint:0x60000149d740 H:|-(0)-[NSView:0x600000133ec0]
>>  (Names: '|':NSView:0x60000032da20 )>",
>>     "<NSLayoutConstraint:0x600001489880 H:[NSView:0x600000133ec0]-(0)-|
>>  (Names: '|':NSView:0x60000032da20 )>",
>>     "<NSLayoutConstraint:0x60000109e280
>> H:[FILocationPopUp:0x6000003fda00(207)]>",
>>     "<NSLayoutConstraint:0x600000a82760 NSView:0x600000133ec0.centerX ==
>> FILocationPopUp:0x6000003fda00.centerX>",
>>     "<NSLayoutConstraint:0x600000e835c0
>> H:[FILocationPopUp:0x6000003fda00]-(>=10)-[SGTSearchField:0x6000003bf800]>",
>>     "<NSLayoutConstraint:0x60000069f2c0
>> H:[SGTSearchField:0x6000003bf800]-(11)-|   (Names:
>> '|':NSView:0x600000133ec0 )>",
>>     "<NSLayoutConstraint:0x6000006801e0
>> H:[SGTSearchField:0x6000003bf800(>=218)]>"
>> )
>>
>> Will attempt to recover by breaking constraint
>> <NSLayoutConstraint:0x6000006801e0
>> H:[SGTSearchField:0x6000003bf800(>=218)]>
>>
>> Set the NSUserDefault
>> NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have
>> -[NSWindow visualizeConstraints:] automatically called when this happens.
>> And/or, break on objc_exception_throw to catch this in the debugger.
>> > str(dat)
>>  chr [1:2] ".Traceback" "WV3_Data_rdata_v_2014_09_21"
>> > ls(dat)
>> Error in as.environment(pos) :
>>   no item called ".Traceback" on the search list
>> > dat
>> [1] ".Traceback"                  "WV3_Data_rdata_v_2014_09_21"
>> > sessionInfo()
>> R version 3.1.3 (2015-03-09)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: OS X 10.10.1 (Yosemite)
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>>  [1] readstata13_0.5-3 effects_3.0-3     lattice_0.20-30   lme4_1.1-7
>>     Rcpp_0.11.2       Matrix_1.1-5      runjags_1.2.1-0   sm_2.2-5.4
>>  [9] foreign_0.8-63    car_2.0-25
>>
>> loaded via a namespace (and not attached):
>>  [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39
>> mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0
>>  nnet_7.3-9
>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6
>> splines_3.1.3    tools_3.1.3
>> >
>>
>>
>>
>>
>> > On Mar 19, 2015, at 5:08 PM, Nicole Ford <nicole.ford at me.com> wrote:
>> >
>> > Ista,
>> >
>> > I am pulling multiple countries and multiple waves, but here is one
>> country in one wave.  I know if I can get one to work, I can get them all
>> to work.  I have used WVS data in the past and never encountered any
>> issues, so I am at a loss here.  Thanks again!
>> >
>> > http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp<
>> http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp>
>> >
>> >
>> > ~Nicole
>> >
>> >
>> >
>> >
>> >
>> >
>> >> On Mar 19, 2015, at 4:59 PM, Ista Zahn <istazahn at gmail.com <mailto:
>> istazahn at gmail.com>> wrote:
>> >>
>> >> Is the file publicly available? What is the URL?
>> >>
>> >> Best,
>> >> Ista
>> >>
>> >> On Thu, Mar 19, 2015 at 4:46 PM, Nicole Ford <nicole.ford at me.com
>> <mailto:nicole.ford at me.com>> wrote:
>> >>> Hello, Ista.
>> >>>
>> >>> Honestly, I am uncertain.  I don't have STATA -- I downloaded this
>> from the data source website.
>> >>>
>> >>> I can't imagine it is 13 because the data are old (2006).
>> >>>
>> >>> I tried package readstata13 out of desperation, but didn't think it
>> would resolve.
>> >>>
>> >>> Thanks for the suggestion!
>> >>>
>> >>> Sent from my iPhone
>> >>>
>> >>>> On Mar 19, 2015, at 4:41 PM, Ista Zahn <istazahn at gmail.com <mailto:
>> istazahn at gmail.com>> wrote:
>> >>>>
>> >>>> Hi Nicole,
>> >>>>
>> >>>> Is it a stata 13 data file? If so your best bet is to open it in
>> Stata
>> >>>> and use the "saveold" command to save it as a stata 12 file.
>> >>>>
>> >>>> Best,
>> >>>> Ista
>> >>>>
>> >>>>> On Thu, Mar 19, 2015 at 3:00 PM, Nicole Ford <nicole.ford at me.com
>> <mailto:nicole.ford at me.com>> wrote:
>> >>>>> Hello,
>> >>>>>
>> >>>>> I recently updated to the newest version of R and I am encountering
>> issues.  Please find my error and session info below.  My data are
>> attached.  I have tried the readstata13 package just in case to no avail.
>> Unless I am missing something, google isn?t helping.
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>> Thank you in advance.
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>> error:
>> >>>>>> dat <- read.dta(file.choose())
>> >>>>> Error in read.dta(file.choose()) : not a Stata version 5-12 .dta
>> file
>> >>>>> 2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously
>> satisfy constraints:
>> >>>>> (
>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&-
>> H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80
>> )>",
>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&-
>> H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80
>> )>",
>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&-
>> H:|-(0)-[FIFinderView:0x600000363a80]   (Names:
>> '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&-
>> H:[FIFinderView:0x600000363a80]-(0)-|   (Names:
>> '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--&
>> H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
>> >>>>>   "<NSLayoutConstraint:0x600000482d50
>> H:|-(0)-[NSView:0x60000012e380]   (Names: '|':NSView:0x60000012eba0 )>",
>> >>>>>   "<NSLayoutConstraint:0x600000482da0
>> H:[NSView:0x60000012e380]-(0)-|   (Names: '|':NSView:0x60000012eba0 )>",
>> >>>>>   "<NSLayoutConstraint:0x6000004816d0
>> H:[FILocationPopUp:0x6000001f2800(207)]>",
>> >>>>>   "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX
>> == FILocationPopUp:0x6000001f2800.centerX>",
>> >>>>>   "<NSLayoutConstraint:0x6000004825d0
>> H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
>> >>>>>   "<NSLayoutConstraint:0x600000482b70
>> H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names:
>> '|':NSView:0x60000012e380 )>",
>> >>>>>   "<NSLayoutConstraint:0x6000004814f0
>> H:[SGTSearchField:0x6000003a5160(>=218)]>"
>> >>>>> )
>> >>>>>
>> >>>>> Will attempt to recover by breaking constraint
>> >>>>> <NSLayoutConstraint:0x6000004814f0
>> H:[SGTSearchField:0x6000003a5160(>=218)]>
>> >>>>>
>> >>>>> Set the NSUserDefault
>> NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have
>> -[NSWindow visualizeConstraints:] automatically called when this happens.
>> And/or, break on objc_exception_throw to catch this in the debugger.
>> >>>>>> sessionInfo()
>> >>>>>
>> >>>>> Session Info:
>> >>>>> R version 3.1.3 (2015-03-09)
>> >>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> >>>>> Running under: OS X 10.10.1 (Yosemite)
>> >>>>>
>> >>>>> locale:
>> >>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> >>>>>
>> >>>>> attached base packages:
>> >>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> >>>>>
>> >>>>> other attached packages:
>> >>>>> [1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2
>>  Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25
>> >>>>>
>> >>>>> loaded via a namespace (and not attached):
>> >>>>> [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39
>>     mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0
>>  nnet_7.3-9
>> >>>>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11
>> SparseM_1.6      splines_3.1.3    tools_3.1.3
>> >>>>>
>> >>>>> ~n
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>> To UNSUBSCRIBE and more, see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help <
>> https://stat.ethz.ch/mailman/listinfo/r-help>
>> >>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From nicole.ford at me.com  Fri Mar 20 05:30:29 2015
From: nicole.ford at me.com (Nicole Ford)
Date: Fri, 20 Mar 2015 00:30:29 -0400
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <CAOwvMDzP1x8hACphEayrN=WTjc7=MrTD0uJUEjtpHPUR6FtPaA@mail.gmail.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
	<CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>
	<7BEE39E2-30E6-4282-8F40-B13D0A5036E7@me.com>
	<CA+vqiLEbX=rmHw8YM0wWOHnAg6N_AVHht2Do-BWPRrmFDeRTDw@mail.gmail.com>
	<380610A2-C626-4FB7-A706-B051B6510104@me.com>
	<B026B0FB-B870-4AAA-B956-2E51BC9660E1@me.com>
	<CAOwvMDzTnPABddRKgFUQc4j_i-+eEhN7joQ4HzC6XZ6vfWGp1Q@mail.gmail.com>
	<FCB331C2-088F-4B9D-BA8E-BF9189D0652E@me.com>
	<CAOwvMDzP1x8hACphEayrN=WTjc7=MrTD0uJUEjtpHPUR6FtPaA@mail.gmail.com>
Message-ID: <D992B87E-3548-430D-A064-AB195B1B2910@me.com>

I am trying it now? it is downloading currently.  I will let you know of any success in the morning.    Thanks!




> On Mar 20, 2015, at 12:09 AM, Anthony Damico <ajdamico at gmail.com> wrote:
> 
> doesn't just running this solve your problem?
> 
> https://github.com/ajdamico/usgsd/blob/master/World%20Values%20Survey/download%20all%20microdata.R <https://github.com/ajdamico/usgsd/blob/master/World%20Values%20Survey/download%20all%20microdata.R>
> 
> 
> On Fri, Mar 20, 2015 at 12:04 AM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com>> wrote:
> Anthony,
> 
> Thanks for this.  The issue I am having is WVS didn?t save all of their stata files, it seems, as .dta.  Further, the .rdata files are not loading correctly, either, giving me .Traceback or crashes R when I try to source it.  I will poke around your link to see if it can provide any insight.
> 
> ~n
> 
> 
> 
> 
> 
> 
> 
>> On Mar 19, 2015, at 9:09 PM, Anthony Damico <ajdamico at gmail.com <mailto:ajdamico at gmail.com>> wrote:
>> 
>> hi nicole, i have published easy to reproduce, well-documented code to download and then analyze every file from every wave of the world values survey here.  the download automation script should solve your problem, or at least work around it  :)
>> 
>> http://www.asdfree.com/search/label/world%20values%20survey%20%28wvs%29 <http://www.asdfree.com/search/label/world%20values%20survey%20%28wvs%29>
>> 
>> 
>> 
>> 
>> 
>> On Thu, Mar 19, 2015 at 6:09 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com>> wrote:
>> the text  didn?t send for the R data file erros.  sorry about that.
>> 
>> 
>> 2015-03-19 17:41:38.544 R[398:5728] Unable to simultaneously satisfy constraints:
>> (
>>     "<NSAutoresizingMaskLayoutConstraint:0x6000018966c0 h=-&- v=-&- H:|-(0)-[NSView:0x60000032da20]   (Names: '|':FIFinderView:0x6080003612c0 )>",
>>     "<NSAutoresizingMaskLayoutConstraint:0x6000012881b0 h=-&- v=-&- H:[NSView:0x60000032da20]-(0)-|   (Names: '|':FIFinderView:0x6080003612c0 )>",
>>     "<NSAutoresizingMaskLayoutConstraint:0x600000a8c710 h=-&- v=-&- H:|-(0)-[FIFinderView:0x6080003612c0]   (Names: '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>>     "<NSAutoresizingMaskLayoutConstraint:0x60000128eb50 h=-&- v=-&- H:[FIFinderView:0x6080003612c0]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>>     "<NSAutoresizingMaskLayoutConstraint:0x600000c93fb0 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000375fc0(585)]>",
>>     "<NSLayoutConstraint:0x60000149d740 H:|-(0)-[NSView:0x600000133ec0]   (Names: '|':NSView:0x60000032da20 )>",
>>     "<NSLayoutConstraint:0x600001489880 H:[NSView:0x600000133ec0]-(0)-|   (Names: '|':NSView:0x60000032da20 )>",
>>     "<NSLayoutConstraint:0x60000109e280 H:[FILocationPopUp:0x6000003fda00(207)]>",
>>     "<NSLayoutConstraint:0x600000a82760 NSView:0x600000133ec0.centerX == FILocationPopUp:0x6000003fda00.centerX>",
>>     "<NSLayoutConstraint:0x600000e835c0 H:[FILocationPopUp:0x6000003fda00]-(>=10)-[SGTSearchField:0x6000003bf800]>",
>>     "<NSLayoutConstraint:0x60000069f2c0 H:[SGTSearchField:0x6000003bf800]-(11)-|   (Names: '|':NSView:0x600000133ec0 )>",
>>     "<NSLayoutConstraint:0x6000006801e0 H:[SGTSearchField:0x6000003bf800(>=218)]>"
>> )
>> 
>> Will attempt to recover by breaking constraint
>> <NSLayoutConstraint:0x6000006801e0 H:[SGTSearchField:0x6000003bf800(>=218)]>
>> 
>> Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
>> > str(dat)
>>  chr [1:2] ".Traceback" "WV3_Data_rdata_v_2014_09_21"
>> > ls(dat)
>> Error in as.environment(pos) :
>>   no item called ".Traceback" on the search list
>> > dat
>> [1] ".Traceback"                  "WV3_Data_rdata_v_2014_09_21"
>> > sessionInfo()
>> R version 3.1.3 (2015-03-09)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: OS X 10.10.1 (Yosemite)
>> 
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>>  [1] readstata13_0.5-3 effects_3.0-3     lattice_0.20-30   lme4_1.1-7        Rcpp_0.11.2       Matrix_1.1-5      runjags_1.2.1-0   sm_2.2-5.4
>>  [9] foreign_0.8-63    car_2.0-25
>> 
>> loaded via a namespace (and not attached):
>>  [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9
>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3
>> >
>> 
>> 
>> 
>> 
>> > On Mar 19, 2015, at 5:08 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com>> wrote:
>> >
>> > Ista,
>> >
>> > I am pulling multiple countries and multiple waves, but here is one country in one wave.  I know if I can get one to work, I can get them all to work.  I have used WVS data in the past and never encountered any issues, so I am at a loss here.  Thanks again!
>> >
>> > http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp <http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp><http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp <http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp>>
>> >
>> >
>> > ~Nicole
>> >
>> >
>> >
>> >
>> >
>> >
>> >> On Mar 19, 2015, at 4:59 PM, Ista Zahn <istazahn at gmail.com <mailto:istazahn at gmail.com> <mailto:istazahn at gmail.com <mailto:istazahn at gmail.com>>> wrote:
>> >>
>> >> Is the file publicly available? What is the URL?
>> >>
>> >> Best,
>> >> Ista
>> >>
>> >> On Thu, Mar 19, 2015 at 4:46 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com> <mailto:nicole.ford at me.com <mailto:nicole.ford at me.com>>> wrote:
>> >>> Hello, Ista.
>> >>>
>> >>> Honestly, I am uncertain.  I don't have STATA -- I downloaded this from the data source website.
>> >>>
>> >>> I can't imagine it is 13 because the data are old (2006).
>> >>>
>> >>> I tried package readstata13 out of desperation, but didn't think it would resolve.
>> >>>
>> >>> Thanks for the suggestion!
>> >>>
>> >>> Sent from my iPhone
>> >>>
>> >>>> On Mar 19, 2015, at 4:41 PM, Ista Zahn <istazahn at gmail.com <mailto:istazahn at gmail.com> <mailto:istazahn at gmail.com <mailto:istazahn at gmail.com>>> wrote:
>> >>>>
>> >>>> Hi Nicole,
>> >>>>
>> >>>> Is it a stata 13 data file? If so your best bet is to open it in Stata
>> >>>> and use the "saveold" command to save it as a stata 12 file.
>> >>>>
>> >>>> Best,
>> >>>> Ista
>> >>>>
>> >>>>> On Thu, Mar 19, 2015 at 3:00 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com> <mailto:nicole.ford at me.com <mailto:nicole.ford at me.com>>> wrote:
>> >>>>> Hello,
>> >>>>>
>> >>>>> I recently updated to the newest version of R and I am encountering issues.  Please find my error and session info below.  My data are attached.  I have tried the readstata13 package just in case to no avail.  Unless I am missing something, google isn?t helping.
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>> Thank you in advance.
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>> error:
>> >>>>>> dat <- read.dta(file.choose())
>> >>>>> Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
>> >>>>> 2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously satisfy constraints:
>> >>>>> (
>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&- H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80 )>",
>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&- H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80 )>",
>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&- H:|-(0)-[FIFinderView:0x600000363a80]   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&- H:[FIFinderView:0x600000363a80]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
>> >>>>>   "<NSLayoutConstraint:0x600000482d50 H:|-(0)-[NSView:0x60000012e380]   (Names: '|':NSView:0x60000012eba0 )>",
>> >>>>>   "<NSLayoutConstraint:0x600000482da0 H:[NSView:0x60000012e380]-(0)-|   (Names: '|':NSView:0x60000012eba0 )>",
>> >>>>>   "<NSLayoutConstraint:0x6000004816d0 H:[FILocationPopUp:0x6000001f2800(207)]>",
>> >>>>>   "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX == FILocationPopUp:0x6000001f2800.centerX>",
>> >>>>>   "<NSLayoutConstraint:0x6000004825d0 H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
>> >>>>>   "<NSLayoutConstraint:0x600000482b70 H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names: '|':NSView:0x60000012e380 )>",
>> >>>>>   "<NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>"
>> >>>>> )
>> >>>>>
>> >>>>> Will attempt to recover by breaking constraint
>> >>>>> <NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>
>> >>>>>
>> >>>>> Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
>> >>>>>> sessionInfo()
>> >>>>>
>> >>>>> Session Info:
>> >>>>> R version 3.1.3 (2015-03-09)
>> >>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> >>>>> Running under: OS X 10.10.1 (Yosemite)
>> >>>>>
>> >>>>> locale:
>> >>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> >>>>>
>> >>>>> attached base packages:
>> >>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> >>>>>
>> >>>>> other attached packages:
>> >>>>> [1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2     Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25
>> >>>>>
>> >>>>> loaded via a namespace (and not attached):
>> >>>>> [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9
>> >>>>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3
>> >>>>>
>> >>>>> ~n
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help> <https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>> >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >
>> 
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From notification at securemail-valueoptions.com  Thu Mar 19 21:04:36 2015
From: notification at securemail-valueoptions.com (Feyerharm, Robert)
Date: Thu, 19 Mar 2015 15:04:36 CDT
Subject: [R] no variable removal when running glmnet on diabetes dataset
 with alpha=1, lambda=.1
Message-ID: <201503192004.t2JK4fMS024980@hypatia.math.ethz.ch>

New ZixCorp secure email message from ValueOptions Secure Email

To view the secure message, click on the link below or copy and paste the link into your Internet browser address bar.

https://securemail-valueoptions.com/s/e?m=ABC5UVsyBkxRSfS2UXb8k64p&c=ABDfgFbxA3h2RUXHIPdWEiCw&em=R%2dhelp%40r%2dproject%2eorg

You are reading the plaintext version of this message.  For a better user experience, change your email settings to enable the viewing of HTML.

Do not reply to this notification message; this message was auto-generated by the sender's security system. To reply to the sender, click on the link above.

The secure message expires on Sep 15, 2015 @ 08:04 PM (GMT).

Want to send and receive secure email messages transparently? http://www.zixcorp.com/info/zixmail_ZMC



	[[alternative HTML version deleted]]


From Lenaig.Hemery at oregonstate.edu  Fri Mar 20 01:29:52 2015
From: Lenaig.Hemery at oregonstate.edu (Hemery, Lenaig)
Date: Fri, 20 Mar 2015 00:29:52 +0000
Subject: [R] Problem with "different" proj4string that are actually identical
Message-ID: <7D3B4F8ADC4D0E47B3351BBF6AD32EB34F7ABA7B@EX1.oregonstate.edu>

Dear everybody
I am trying to run an Ecological Niche Factor Analysis (enfa) with the package "adehabitatHS" but before I do so, I want to test the significance of its parameters marginality and tolerance, by using the function niche.test() that runs a Monte Carlo test. I used to do that with the old package "adehabitat" that is now deprecated so I updated all my codes. Everything I want to do seems to work fine except the niche.test() function and I get the error message here below.

> testCro<-niche.test(paramdf, spCro, nrep = 999, o.include = TRUE)
Error in join(pts, ta) : different proj4string in x and xy

I checked the proj4string for x (paramdf) and xy (spCro) and there are exactly identical (see below). 

> summary(spCro)
Object of class SpatialPoints
Coordinates:
              min     max
longitude -124.91 -124.13
latitude    39.86   46.95
Is projected: FALSE
proj4string :
[+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0]
Number of points: 84

> summary(paramdf)
Object of class SpatialPixelsDataFrame
Coordinates:
         min       max
x -125.50000 -123.7998
y   39.50384   47.0000
Is projected: FALSE
proj4string :
[+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0]
Number of points: 108237
Grid attributes:
  cellcentre.offset cellsize cells.dim
x        -125.49517  0.00966       176
y          39.50867  0.00966       776
Data attributes:
      bath              slope              rugo               sumT      
 Min.   :-3611.83   Min.   : 0.0000   Min.   :0.000000   Min.   : 1.184 
 1st Qu.:-1885.11   1st Qu.: 0.5271   1st Qu.:0.008044   1st Qu.: 2.150 
 Median : -894.61   Median : 1.4974   Median :0.036921   Median : 3.978 
 Mean   :-1157.85   Mean   : 3.4237   Mean   :0.147369   Mean   : 4.794 
 3rd Qu.: -150.85   3rd Qu.: 4.1152   3rd Qu.:0.197974   3rd Qu.: 7.388 
 Max.   :   -0.05   Max.   :61.3592   Max.   :0.992856   Max.   :14.436 
[...]

I think I looked for all the help I could find on the internet and didn't find any solution so here is my last chance.
Does anybody have an idea on how to solve this problem?
By the way, I use the R version 3.1.3 and up-to-date "adehabitatHS", "ade4", "sp" and other packages.
Thanks a lot,
Lenaig

???? ><)))?> <?(((>< ????
Lena?g Hemery, Ph. D.
Research Associate - post-doc
Hatfield Marine Science Center
Oregon State University
2030 S.E. Marine Science Drive, Newport, OR 97365, USA
Cell:+1-541-272-7196

From lindnerw at t-online.de  Fri Mar 20 07:35:35 2015
From: lindnerw at t-online.de (Dr. Wolfgang Lindner)
Date: Fri, 20 Mar 2015 07:35:35 +0100
Subject: [R] Tele_R - first experiences
In-Reply-To: <CA+vqiLFDdDSuMpVYxLVQ+Hj5RaUzy_mPCwa_NNxcXMH9eUaPWQ@mail.gmail.com>
References: <9A93A01584A6484FA7BF1EA4E1258932@Petra>
	<CA+vqiLFDdDSuMpVYxLVQ+Hj5RaUzy_mPCwa_NNxcXMH9eUaPWQ@mail.gmail.com>
Message-ID: <C9A048C5-4073-453C-ACED-E02CA5927C48@t-online.de>

Some R users asked offlist for the link to Tele_R. Sorry, here it is:

[3]   http://telemath.altervista.org/

--
Best, Wolfgang Lindner

Am 19.03.2015 um 21:57 schrieb Ista Zahn <istazahn at gmail.com>:

> Hey that's really nice. I'm not sure how practical it is, but it works
> surprisingly well.
> 
> Best,
> Ista
> 
> On Thu, Mar 19, 2015 at 8:21 AM, Dr. Wolfgang Lindner
> <lindnerw at t-online.de> wrote:
>> Dear R community,
>> 
>> some days ago Enric Cervera Mateu has installed an R client
>> with instant messaging, which is usable very simple via the
>> public name @Tele_R in the messenger Telegram.
>> 
>> I have tested Tele_R and e.g. tried most of the examples from
>> [1] W.N. Venables, D.M. Smith, R Core Team. "An Introduction to R." R Core
>> Team. iBooks.
>> and of ?1 of
>> [2] B. Everitt, T. Hothorn. "An R and S-plus Companion to Multivariate
>> Analysis. Springer.
>> All is working very good in this environment.
>> 
>> I am very impressed. I like the possibility to use R without installation
>> complications with my iPhone, iPad or HTC One.
>> The answers are send very fast, the idea to use a chat for mathematics
>> communication seems to be especially suited to beginners:
>> direct dive in, OS as you like, working anywhere, talking over distance,
>> communicate with your peers or students (share code or
>> examples etc even during a lesson - if a beamer is not available) etc.
>> 
>> I would like to thank Enric for his valuable work to make the great work of
>> the R team accessible to smartphones and tablets.
>> I think that Tele_R is a very comfortable tool for teaching and learning R
>> at an undergraduate level.
>> 
>> And I would like to hear about the experiences, opinions or ideas of other
>> members of the R community with respect of the use of Tele_R.
>> 
>> I hope that this is not the wrong list to say these words.
>> 
>> Best,
>> Wolfgang Lindner
>> Leichlingen, Germany
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jwd at surewest.net  Fri Mar 20 09:37:48 2015
From: jwd at surewest.net (jwd)
Date: Fri, 20 Mar 2015 01:37:48 -0700
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
Message-ID: <20150320013748.170ddfea@Draco.site>

On Thu, 19 Mar 2015 15:00:18 -0400
Nicole Ford <nicole.ford at me.com> wrote:

> Hello,
> 
> I recently updated to the newest version of R and I am encountering
> issues.  Please find my error and session info below.  My data are
> attached.  I have tried the readstata13 package just in case to no
> avail.  Unless I am missing something, google isn?t helping.
> 
It would not hurt to type in:

>?read.dta 

and read the result.

JWDougherty


From kurt_helf at nps.gov  Fri Mar 20 14:32:02 2015
From: kurt_helf at nps.gov (Helf, Kurt)
Date: Fri, 20 Mar 2015 08:32:02 -0500
Subject: [R] .dtf files
Message-ID: <CACRFZ0NXYBVNK=abJJv1WoE5=jJtRTL0ao2NhYBsahGaMKAwOw@mail.gmail.com>

All
     Is R able to read ".dtf" files, such as data downloaded from HOBO
dataloggers, or do the files need to be converted to ".txt" or ".csv"
format?
Cheers
Kurt

-- 

***************************************************************
Kurt Lewis Helf, Ph.D.
Ecologist
EEO Counselor/Mediator
National Park Service
Cumberland Piedmont Network
P.O. Box 8
OR
NPS Warehouse
61 Maintenance Rd.
Mammoth Cave, KY 42259
Ph: 270-758-2163
Lab: 270-758-2151
Fax: 270-758-2609
Cumberland Piedmont Network (CUPN) Homepage <http://bit.ly/1yxYw3E>

CUPN Cave Cricket Monitoring Website <http://bit.ly/YMY5C3>

CUPN Cave Aquatic Biota Monitoring Website <http://bit.ly/1sLPWvN>

CUPN Invasive Species Early Detection (ISED) Website <http://bit.ly/1mLyFjH>

***************************************************************
Science, in constantly seeking real explanations, reveals the true majesty
of our world in all its complexity.
-Richard Dawkins

[Scientific] theories are passed on not as dogmas but rather with the
challenge to discuss them and improve upon them.
-Karl Popper

...consider yourself a guest in the home of other creatures as significant
as yourself.
-Wayside at Wilderness Threshold in McKittrick Canyon, Guadalupe Mountains
National Park, TX

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Fri Mar 20 14:42:51 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 20 Mar 2015 05:42:51 -0800
Subject: [R] Why do my posts not get accepted to the mailing list?
In-Reply-To: <1426789619.2750836.242667613.340DB8AC@webmail.messagingengine.com>
Message-ID: <0E7D6C6F4C9.00000683jrkrideau@inbox.com>

Perhaps post directly to the R-help list and don't use nabble?

John Kane
Kingston ON Canada


> -----Original Message-----
> From: andrejfavia at ml1.net
> Sent: Thu, 19 Mar 2015 14:26:59 -0400
> To: r-help at r-project.org
> Subject: [R] Why do my posts not get accepted to the mailing list?
> 
> Greetings.
> I was told to email my question.
> 
> Why do my posts not get accepted to the mailing list?
> 
> Example:
> http://r.789695.n4.nabble.com/How-do-I-move-the-horizontal-axis-in-a-plot-so-that-it-starts-at-the-zero-of-the-vertical-axis-td4696935.html
> 
> I don't understand why I always have this problem when I post and try to
> subscribe and I still haven't found a solution after three years.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From mikhail.zvagelsky at axibase.com  Tue Mar 17 16:39:25 2015
From: mikhail.zvagelsky at axibase.com (mikhail.zvagelsky at axibase.com)
Date: Tue, 17 Mar 2015 10:39:25 -0500
Subject: [R] [R-pkgs] The 'atsd' package released.
Message-ID: <59164.1426606765@axibase.com>

Dear R users,

I would like to announce the release of the "atsd" R package on CRAN, 
which offers functions for retrieving time-series and related meta-data 
such as entities, metrics, and tags from Axibase Time Series Database (ATSD).

http://cran.r-project.org/web/packages/atsd/index.html

ATSD runs on top of HBase to collect, analyze and visualize time series data at scale. 
ATSD capabilities include optimized storage schema, built-in rule engine, forecasting 
algorithms include Holt-Winters, ARIMA and graphics designed for high-frequency data. 
Primary use case: IT infrastructure resource monitoring.

The main focus of "atsd" R package is to simplify data retrieval. This package eliminates 
the need to manually retrieve historical data and forecasts, before any advanced analysis 
is executed. The "atsd" R package fetches data and tags from ATSD, and converts them into 
a data frame object which can be readily consumed by other R packages.

Key supported functions for retrieving data:

? query() -- get historical data and forecasts from ATSD. 
             This function supports aggregation: COUNT, MIN, MAX, AVG, WAvg, WTAvg, SUM, 
             PERCENTILES (50%, 75%, 90%, 95%, 99%, 99.5%, 99.9%), STANDARD_DEVIATION. 
             The function also supports interpolation: NONE, STEP, LINEAR.

? get_metrics() -- get information about the metrics collected by ATSD.

? get_entities() -- get information about the entities collected by ATSD.

? to_zoo() -- converts a time-series data frame to 'zoo' object for manipulating irregular 
              time-series with built-in functions in zoo package.

The github page can be found here:

https://github.com/axibase/atsd-api-r

Comments and contributions are welcome.


Best Regards,
Mikhail Zvagelsky.

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From nicole.ford at me.com  Fri Mar 20 15:39:48 2015
From: nicole.ford at me.com (Nicole Ford)
Date: Fri, 20 Mar 2015 10:39:48 -0400
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <CAOwvMDzP1x8hACphEayrN=WTjc7=MrTD0uJUEjtpHPUR6FtPaA@mail.gmail.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
	<CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>
	<7BEE39E2-30E6-4282-8F40-B13D0A5036E7@me.com>
	<CA+vqiLEbX=rmHw8YM0wWOHnAg6N_AVHht2Do-BWPRrmFDeRTDw@mail.gmail.com>
	<380610A2-C626-4FB7-A706-B051B6510104@me.com>
	<B026B0FB-B870-4AAA-B956-2E51BC9660E1@me.com>
	<CAOwvMDzTnPABddRKgFUQc4j_i-+eEhN7joQ4HzC6XZ6vfWGp1Q@mail.gmail.com>
	<FCB331C2-088F-4B9D-BA8E-BF9189D0652E@me.com>
	<CAOwvMDzP1x8hACphEayrN=WTjc7=MrTD0uJUEjtpHPUR6FtPaA@mail.gmail.com>
Message-ID: <713BFD9F-68DA-40C4-8DCA-5527567BDB4B@me.com>

Anthony,  I was able to d/l all of the files over night.  I will let you know off-list of any issues.  Thanks!

~Nicole Ford


Sent from my iPhone

> On Mar 20, 2015, at 12:09 AM, Anthony Damico <ajdamico at gmail.com> wrote:
> 
> doesn't just running this solve your problem?
> 
> https://github.com/ajdamico/usgsd/blob/master/World%20Values%20Survey/download%20all%20microdata.R
> 
> 
>> On Fri, Mar 20, 2015 at 12:04 AM, Nicole Ford <nicole.ford at me.com> wrote:
>> Anthony,
>> 
>> Thanks for this.  The issue I am having is WVS didn?t save all of their stata files, it seems, as .dta.  Further, the .rdata files are not loading correctly, either, giving me .Traceback or crashes R when I try to source it.  I will poke around your link to see if it can provide any insight.
>> 
>> ~n
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>>> On Mar 19, 2015, at 9:09 PM, Anthony Damico <ajdamico at gmail.com> wrote:
>>> 
>>> hi nicole, i have published easy to reproduce, well-documented code to download and then analyze every file from every wave of the world values survey here.  the download automation script should solve your problem, or at least work around it  :)
>>> 
>>> http://www.asdfree.com/search/label/world%20values%20survey%20%28wvs%29
>>> 
>>> 
>>> 
>>> 
>>> 
>>>> On Thu, Mar 19, 2015 at 6:09 PM, Nicole Ford <nicole.ford at me.com> wrote:
>>>> the text  didn?t send for the R data file erros.  sorry about that.
>>>> 
>>>> 
>>>> 2015-03-19 17:41:38.544 R[398:5728] Unable to simultaneously satisfy constraints:
>>>> (
>>>>     "<NSAutoresizingMaskLayoutConstraint:0x6000018966c0 h=-&- v=-&- H:|-(0)-[NSView:0x60000032da20]   (Names: '|':FIFinderView:0x6080003612c0 )>",
>>>>     "<NSAutoresizingMaskLayoutConstraint:0x6000012881b0 h=-&- v=-&- H:[NSView:0x60000032da20]-(0)-|   (Names: '|':FIFinderView:0x6080003612c0 )>",
>>>>     "<NSAutoresizingMaskLayoutConstraint:0x600000a8c710 h=-&- v=-&- H:|-(0)-[FIFinderView:0x6080003612c0]   (Names: '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>>>>     "<NSAutoresizingMaskLayoutConstraint:0x60000128eb50 h=-&- v=-&- H:[FIFinderView:0x6080003612c0]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>>>>     "<NSAutoresizingMaskLayoutConstraint:0x600000c93fb0 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000375fc0(585)]>",
>>>>     "<NSLayoutConstraint:0x60000149d740 H:|-(0)-[NSView:0x600000133ec0]   (Names: '|':NSView:0x60000032da20 )>",
>>>>     "<NSLayoutConstraint:0x600001489880 H:[NSView:0x600000133ec0]-(0)-|   (Names: '|':NSView:0x60000032da20 )>",
>>>>     "<NSLayoutConstraint:0x60000109e280 H:[FILocationPopUp:0x6000003fda00(207)]>",
>>>>     "<NSLayoutConstraint:0x600000a82760 NSView:0x600000133ec0.centerX == FILocationPopUp:0x6000003fda00.centerX>",
>>>>     "<NSLayoutConstraint:0x600000e835c0 H:[FILocationPopUp:0x6000003fda00]-(>=10)-[SGTSearchField:0x6000003bf800]>",
>>>>     "<NSLayoutConstraint:0x60000069f2c0 H:[SGTSearchField:0x6000003bf800]-(11)-|   (Names: '|':NSView:0x600000133ec0 )>",
>>>>     "<NSLayoutConstraint:0x6000006801e0 H:[SGTSearchField:0x6000003bf800(>=218)]>"
>>>> )
>>>> 
>>>> Will attempt to recover by breaking constraint
>>>> <NSLayoutConstraint:0x6000006801e0 H:[SGTSearchField:0x6000003bf800(>=218)]>
>>>> 
>>>> Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
>>>> > str(dat)
>>>>  chr [1:2] ".Traceback" "WV3_Data_rdata_v_2014_09_21"
>>>> > ls(dat)
>>>> Error in as.environment(pos) :
>>>>   no item called ".Traceback" on the search list
>>>> > dat
>>>> [1] ".Traceback"                  "WV3_Data_rdata_v_2014_09_21"
>>>> > sessionInfo()
>>>> R version 3.1.3 (2015-03-09)
>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>> Running under: OS X 10.10.1 (Yosemite)
>>>> 
>>>> locale:
>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>> 
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>> 
>>>> other attached packages:
>>>>  [1] readstata13_0.5-3 effects_3.0-3     lattice_0.20-30   lme4_1.1-7        Rcpp_0.11.2       Matrix_1.1-5      runjags_1.2.1-0   sm_2.2-5.4
>>>>  [9] foreign_0.8-63    car_2.0-25
>>>> 
>>>> loaded via a namespace (and not attached):
>>>>  [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9
>>>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3
>>>> >
>>>> 
>>>> 
>>>> 
>>>> 
>>>> > On Mar 19, 2015, at 5:08 PM, Nicole Ford <nicole.ford at me.com> wrote:
>>>> >
>>>> > Ista,
>>>> >
>>>> > I am pulling multiple countries and multiple waves, but here is one country in one wave.  I know if I can get one to work, I can get them all to work.  I have used WVS data in the past and never encountered any issues, so I am at a loss here.  Thanks again!
>>>> >
>>>> > http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp<http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp>
>>>> >
>>>> >
>>>> > ~Nicole
>>>> >
>>>> >
>>>> >
>>>> >
>>>> >
>>>> >
>>>> >> On Mar 19, 2015, at 4:59 PM, Ista Zahn <istazahn at gmail.com <mailto:istazahn at gmail.com>> wrote:
>>>> >>
>>>> >> Is the file publicly available? What is the URL?
>>>> >>
>>>> >> Best,
>>>> >> Ista
>>>> >>
>>>> >> On Thu, Mar 19, 2015 at 4:46 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com>> wrote:
>>>> >>> Hello, Ista.
>>>> >>>
>>>> >>> Honestly, I am uncertain.  I don't have STATA -- I downloaded this from the data source website.
>>>> >>>
>>>> >>> I can't imagine it is 13 because the data are old (2006).
>>>> >>>
>>>> >>> I tried package readstata13 out of desperation, but didn't think it would resolve.
>>>> >>>
>>>> >>> Thanks for the suggestion!
>>>> >>>
>>>> >>> Sent from my iPhone
>>>> >>>
>>>> >>>> On Mar 19, 2015, at 4:41 PM, Ista Zahn <istazahn at gmail.com <mailto:istazahn at gmail.com>> wrote:
>>>> >>>>
>>>> >>>> Hi Nicole,
>>>> >>>>
>>>> >>>> Is it a stata 13 data file? If so your best bet is to open it in Stata
>>>> >>>> and use the "saveold" command to save it as a stata 12 file.
>>>> >>>>
>>>> >>>> Best,
>>>> >>>> Ista
>>>> >>>>
>>>> >>>>> On Thu, Mar 19, 2015 at 3:00 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com>> wrote:
>>>> >>>>> Hello,
>>>> >>>>>
>>>> >>>>> I recently updated to the newest version of R and I am encountering issues.  Please find my error and session info below.  My data are attached.  I have tried the readstata13 package just in case to no avail.  Unless I am missing something, google isn?t helping.
>>>> >>>>>
>>>> >>>>>
>>>> >>>>>
>>>> >>>>> Thank you in advance.
>>>> >>>>>
>>>> >>>>>
>>>> >>>>>
>>>> >>>>> error:
>>>> >>>>>> dat <- read.dta(file.choose())
>>>> >>>>> Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
>>>> >>>>> 2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously satisfy constraints:
>>>> >>>>> (
>>>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&- H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80 )>",
>>>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&- H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80 )>",
>>>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&- H:|-(0)-[FIFinderView:0x600000363a80]   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>>>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&- H:[FIFinderView:0x600000363a80]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>>>> >>>>>   "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
>>>> >>>>>   "<NSLayoutConstraint:0x600000482d50 H:|-(0)-[NSView:0x60000012e380]   (Names: '|':NSView:0x60000012eba0 )>",
>>>> >>>>>   "<NSLayoutConstraint:0x600000482da0 H:[NSView:0x60000012e380]-(0)-|   (Names: '|':NSView:0x60000012eba0 )>",
>>>> >>>>>   "<NSLayoutConstraint:0x6000004816d0 H:[FILocationPopUp:0x6000001f2800(207)]>",
>>>> >>>>>   "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX == FILocationPopUp:0x6000001f2800.centerX>",
>>>> >>>>>   "<NSLayoutConstraint:0x6000004825d0 H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
>>>> >>>>>   "<NSLayoutConstraint:0x600000482b70 H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names: '|':NSView:0x60000012e380 )>",
>>>> >>>>>   "<NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>"
>>>> >>>>> )
>>>> >>>>>
>>>> >>>>> Will attempt to recover by breaking constraint
>>>> >>>>> <NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>
>>>> >>>>>
>>>> >>>>> Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
>>>> >>>>>> sessionInfo()
>>>> >>>>>
>>>> >>>>> Session Info:
>>>> >>>>> R version 3.1.3 (2015-03-09)
>>>> >>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>> >>>>> Running under: OS X 10.10.1 (Yosemite)
>>>> >>>>>
>>>> >>>>> locale:
>>>> >>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>> >>>>>
>>>> >>>>> attached base packages:
>>>> >>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>> >>>>>
>>>> >>>>> other attached packages:
>>>> >>>>> [1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2     Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25
>>>> >>>>>
>>>> >>>>> loaded via a namespace (and not attached):
>>>> >>>>> [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9
>>>> >>>>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3
>>>> >>>>>
>>>> >>>>> ~n
>>>> >>>>>
>>>> >>>>>
>>>> >>>>>
>>>> >>>>>
>>>> >>>>>
>>>> >>>>>
>>>> >>>>> ______________________________________________
>>>> >>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>> >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> >
>>>> 
>>>> 
>>>>         [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]


From benjamin.hofner at fau.de  Fri Mar 20 16:06:17 2015
From: benjamin.hofner at fau.de (Benjamin Hofner)
Date: Fri, 20 Mar 2015 16:06:17 +0100
Subject: [R] mboost: Proportional odds boosting model - how to specify
 the offset?
Message-ID: <550C3769.5000701@fau.de>

Dear Madlene,

the problem that you observed was twofold.

First, mboost expects the offset to be a scalar or a vector with length
equal to the number of observations. However, fitted(p.iris) is a 
matrix. In PropOdds(), the linear or additive predictor is shared among 
all outcome categories and the thresholds are treated as nuisance 
parameter. What you need to supply as offset is the result of the linear 
or additive predictor (i.e., x'beta) instead of the fitted class 
probabilities.

Second, there was a bug in mboost. I fixed it on R-forge [1]. If the 
package was successfully built use
   install.packages("mboost", repos="http://R-Forge.R-project.org")
to install it. You can also email to me off list. Then I will send you 
the package sources directly.

Your nuisance parameters (which represent the class thresholds) can be
extracted via nuisance(mlp). More details are given in the example below.

Best,
Benjamin

[1] http://r-forge.r-project.org/projects/mboost/

---- Example code ----

library(MASS)
library(mboost)

data(iris)
iris$Species <- factor(iris$Species, ordered = T)
p.iris <- polr(Species  ~ Sepal.Length, data = iris)
p.iris

lm.iris <- glmboost(Species  ~ Sepal.Length, data = iris,
                     family = PropOdds(nuirange = c(-0.5, 3)))
lm.iris[1000]
## thresholds:
nuisance(lm.iris)

## to make these comparable to p.iris use
nuisance(lm.iris) - coef(lm.iris)["(Intercept)"] -
     attr(coef(lm.iris), "offset")

## now use linear predictor as offset:
mlp <- gamboost(Species ~ bols(Sepal.Length) + bols(Sepal.Width),
                 data = iris, family = PropOdds(nuirange = c(0, 1)),
                 offset = fitted(lm.iris))




Nussbaum  Madlene wrote
> Dear R team
>
> The package mboost allows for boosting of proportional odds models.
> However, I would like to include an offset for every observation.
> This produces an error - no matter how I put the offset (as response
> probabilities or as response link).
>
> Fitting gamboost-models with offset works satisfactory with family =
> Gaussian() or Multinomial().
>
> Questions: 1) How do I need to specify the offset with family =
> PropOdds()?
>
> 2) Where in the mboost-object do I find the Theta's (response
> category dependent intercept)?
 >
 >
 >
 > # --- minimal example with iris data ---
 >
 > library(MASS)
 > library(mboost)
 >
 > data(iris)
 > iris$Species <- factor(iris$Species, ordered = T)
 > p.iris <- polr(Species  ~ Sepal.Length, data = iris)
 > mlp <- gamboost(Species ~ bols(Sepal.Length) + bols(Sepal.Width),
 >                data = iris, family = PropOdds(),
 > 	      offset = fitted(p.iris) )
 >
 > Error in tmp[[i]] : subscript out of bounds
 >
 >
 > Thank you
 > M. Nussbaum
 >
 > --
 >
 > ETH Z?rich
 > Madlene Nussbaum
 > Institut f?r Terrestrische ?kosysteme
 > Boden- und Terrestrische Umweltphysik
 > CHN E 37.2
 > Universit?tstrasse 16
 > CH-8092 Z?rich
 >
 > Telefon + 44 632 73 21
 > Mobile  + 79 761 34 66
 > madlene.nussbaum at .ethz
 > www.step.ethz.ch


From macqueen1 at llnl.gov  Fri Mar 20 16:23:44 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 20 Mar 2015 15:23:44 +0000
Subject: [R] Problem with "different" proj4string that are actually
 identical
Message-ID: <D1318894.122E1F%macqueen1@llnl.gov>

This question would be better asked on r-sig-geo.

Here are some things to try (type at the R prompt):

  proj4string(spCro) == proj4string(paramdf)

Does it return TRUE or FALSE?

Or, instead of using summary(), directly inspect the proj4strings:

  proj4string(spCro)
  proj4string(paramdf)

If there still appears to be no difference between them,
try forcing them to be identical
  proj4string(spCro) <- proj4string(paramdf)

then repeat your niche.test()


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/19/15, 5:29 PM, "Hemery, Lenaig" <Lenaig.Hemery at oregonstate.edu>
wrote:

>Dear everybody
>I am trying to run an Ecological Niche Factor Analysis (enfa) with the
>package "adehabitatHS" but before I do so, I want to test the
>significance of its parameters marginality and tolerance, by using the
>function niche.test() that runs a Monte Carlo test. I used to do that
>with the old package "adehabitat" that is now deprecated so I updated all
>my codes. Everything I want to do seems to work fine except the
>niche.test() function and I get the error message here below.
>
>> testCro<-niche.test(paramdf, spCro, nrep = 999, o.include = TRUE)
>Error in join(pts, ta) : different proj4string in x and xy
>
>I checked the proj4string for x (paramdf) and xy (spCro) and there are
>exactly identical (see below).
>
>> summary(spCro)
>Object of class SpatialPoints
>Coordinates:
>              min     max
>longitude -124.91 -124.13
>latitude    39.86   46.95
>Is projected: FALSE
>proj4string :
>[+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0]
>Number of points: 84
>
>> summary(paramdf)
>Object of class SpatialPixelsDataFrame
>Coordinates:
>         min       max
>x -125.50000 -123.7998
>y   39.50384   47.0000
>Is projected: FALSE
>proj4string :
>[+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0]
>Number of points: 108237
>Grid attributes:
>  cellcentre.offset cellsize cells.dim
>x        -125.49517  0.00966       176
>y          39.50867  0.00966       776
>Data attributes:
>      bath              slope              rugo               sumT
> Min.   :-3611.83   Min.   : 0.0000   Min.   :0.000000   Min.   : 1.184
> 1st Qu.:-1885.11   1st Qu.: 0.5271   1st Qu.:0.008044   1st Qu.: 2.150
> Median : -894.61   Median : 1.4974   Median :0.036921   Median : 3.978
> Mean   :-1157.85   Mean   : 3.4237   Mean   :0.147369   Mean   : 4.794
> 3rd Qu.: -150.85   3rd Qu.: 4.1152   3rd Qu.:0.197974   3rd Qu.: 7.388
> Max.   :   -0.05   Max.   :61.3592   Max.   :0.992856   Max.   :14.436
>[...]
>
>I think I looked for all the help I could find on the internet and didn't
>find any solution so here is my last chance.
>Does anybody have an idea on how to solve this problem?
>By the way, I use the R version 3.1.3 and up-to-date "adehabitatHS",
>"ade4", "sp" and other packages.
>Thanks a lot,
>Lenaig
>
>???? ><)))?> <?(((>< ????
>Lena?g Hemery, Ph. D.
>Research Associate - post-doc
>Hatfield Marine Science Center
>Oregon State University
>2030 S.E. Marine Science Drive, Newport, OR 97365, USA
>Cell:+1-541-272-7196
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From aolinto.lst at gmail.com  Fri Mar 20 22:20:39 2015
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Fri, 20 Mar 2015 18:20:39 -0300
Subject: [R] ordering a boxplot
Message-ID: <CAE8g1gPFm__Q8t5wnxusAfmARBB7S55AY2eJAf+GKFfgKvm8-g@mail.gmail.com>

Hello

I'm using a dataframe (mydata) where row names are sampling points and
column names are species in a multivariate analysis.

If I write boxplot(mydata) I'll have boxplots for each species abundance in
alphabetical order.

How to get the boxes orderer by the median?

Usually for this I write
boxplot(value~category,at=rank(tapply(mydata$value,mydata$category,median)))
but for this to work I need a column for the categories and another column
for the values.

Thanks in advance, best regards.

Antonio Olinto

	[[alternative HTML version deleted]]


From nicole.ford at me.com  Fri Mar 20 23:01:37 2015
From: nicole.ford at me.com (Nicole Ford)
Date: Fri, 20 Mar 2015 18:01:37 -0400
Subject: [R] not a Stata version 5-12 .dta file
In-Reply-To: <713BFD9F-68DA-40C4-8DCA-5527567BDB4B@me.com>
References: <B74478FC-65B8-47E3-8BA0-F08870CD8513@me.com>
	<CA+vqiLFOnw1WD32Nsr3iNcUGW7MdG_odpsJS-GO66+MjvA+k2w@mail.gmail.com>
	<7BEE39E2-30E6-4282-8F40-B13D0A5036E7@me.com>
	<CA+vqiLEbX=rmHw8YM0wWOHnAg6N_AVHht2Do-BWPRrmFDeRTDw@mail.gmail.com>
	<380610A2-C626-4FB7-A706-B051B6510104@me.com>
	<B026B0FB-B870-4AAA-B956-2E51BC9660E1@me.com>
	<CAOwvMDzTnPABddRKgFUQc4j_i-+eEhN7joQ4HzC6XZ6vfWGp1Q@mail.gmail.com>
	<FCB331C2-088F-4B9D-BA8E-BF9189D0652E@me.com>
	<CAOwvMDzP1x8hACphEayrN=WTjc7=MrTD0uJUEjtpHPUR6FtPaA@mail.gmail.com>
	<713BFD9F-68DA-40C4-8DCA-5527567BDB4B@me.com>
Message-ID: <AC4B7C9F-0DA3-4CE1-8318-40B47EB4DEFF@me.com>

Everything is perfect and working as it should-- thanks, Anthony!

>>> 
>>> 
>>> 
>>> 
>>> 
>>>> On Mar 19, 2015, at 9:09 PM, Anthony Damico <ajdamico at gmail.com> wrote:
>>>> 
>>>> hi nicole, i have published easy to reproduce, well-documented code to download and then analyze every file from every wave of the world values survey here.  the download automation script should solve your problem, or at least work around it  :)
>>>> 
>>>> http://www.asdfree.com/search/label/world%20values%20survey%20%28wvs%29
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>>> On Thu, Mar 19, 2015 at 6:09 PM, Nicole Ford <nicole.ford at me.com> wrote:
>>>>> the text  didn?t send for the R data file erros.  sorry about that.
>>>>> 
>>>>> 
>>>>> 2015-03-19 17:41:38.544 R[398:5728] Unable to simultaneously satisfy constraints:
>>>>> (
>>>>>    "<NSAutoresizingMaskLayoutConstraint:0x6000018966c0 h=-&- v=-&- H:|-(0)-[NSView:0x60000032da20]   (Names: '|':FIFinderView:0x6080003612c0 )>",
>>>>>    "<NSAutoresizingMaskLayoutConstraint:0x6000012881b0 h=-&- v=-&- H:[NSView:0x60000032da20]-(0)-|   (Names: '|':FIFinderView:0x6080003612c0 )>",
>>>>>    "<NSAutoresizingMaskLayoutConstraint:0x600000a8c710 h=-&- v=-&- H:|-(0)-[FIFinderView:0x6080003612c0]   (Names: '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>>>>>    "<NSAutoresizingMaskLayoutConstraint:0x60000128eb50 h=-&- v=-&- H:[FIFinderView:0x6080003612c0]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000375fc0 )>",
>>>>>    "<NSAutoresizingMaskLayoutConstraint:0x600000c93fb0 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000375fc0(585)]>",
>>>>>    "<NSLayoutConstraint:0x60000149d740 H:|-(0)-[NSView:0x600000133ec0]   (Names: '|':NSView:0x60000032da20 )>",
>>>>>    "<NSLayoutConstraint:0x600001489880 H:[NSView:0x600000133ec0]-(0)-|   (Names: '|':NSView:0x60000032da20 )>",
>>>>>    "<NSLayoutConstraint:0x60000109e280 H:[FILocationPopUp:0x6000003fda00(207)]>",
>>>>>    "<NSLayoutConstraint:0x600000a82760 NSView:0x600000133ec0.centerX == FILocationPopUp:0x6000003fda00.centerX>",
>>>>>    "<NSLayoutConstraint:0x600000e835c0 H:[FILocationPopUp:0x6000003fda00]-(>=10)-[SGTSearchField:0x6000003bf800]>",
>>>>>    "<NSLayoutConstraint:0x60000069f2c0 H:[SGTSearchField:0x6000003bf800]-(11)-|   (Names: '|':NSView:0x600000133ec0 )>",
>>>>>    "<NSLayoutConstraint:0x6000006801e0 H:[SGTSearchField:0x6000003bf800(>=218)]>"
>>>>> )
>>>>> 
>>>>> Will attempt to recover by breaking constraint
>>>>> <NSLayoutConstraint:0x6000006801e0 H:[SGTSearchField:0x6000003bf800(>=218)]>
>>>>> 
>>>>> Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
>>>>>> str(dat)
>>>>> chr [1:2] ".Traceback" "WV3_Data_rdata_v_2014_09_21"
>>>>>> ls(dat)
>>>>> Error in as.environment(pos) :
>>>>>  no item called ".Traceback" on the search list
>>>>>> dat
>>>>> [1] ".Traceback"                  "WV3_Data_rdata_v_2014_09_21"
>>>>>> sessionInfo()
>>>>> R version 3.1.3 (2015-03-09)
>>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>>> Running under: OS X 10.10.1 (Yosemite)
>>>>> 
>>>>> locale:
>>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>> 
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>> 
>>>>> other attached packages:
>>>>> [1] readstata13_0.5-3 effects_3.0-3     lattice_0.20-30   lme4_1.1-7        Rcpp_0.11.2       Matrix_1.1-5      runjags_1.2.1-0   sm_2.2-5.4
>>>>> [9] foreign_0.8-63    car_2.0-25
>>>>> 
>>>>> loaded via a namespace (and not attached):
>>>>> [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9
>>>>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>>> On Mar 19, 2015, at 5:08 PM, Nicole Ford <nicole.ford at me.com> wrote:
>>>>>> 
>>>>>> Ista,
>>>>>> 
>>>>>> I am pulling multiple countries and multiple waves, but here is one country in one wave.  I know if I can get one to work, I can get them all to work.  I have used WVS data in the past and never encountered any issues, so I am at a loss here.  Thanks again!
>>>>>> 
>>>>>> http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp<http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp>
>>>>>> 
>>>>>> 
>>>>>> ~Nicole
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>>> On Mar 19, 2015, at 4:59 PM, Ista Zahn <istazahn at gmail.com <mailto:istazahn at gmail.com>> wrote:
>>>>>>> 
>>>>>>> Is the file publicly available? What is the URL?
>>>>>>> 
>>>>>>> Best,
>>>>>>> Ista
>>>>>>> 
>>>>>>>> On Thu, Mar 19, 2015 at 4:46 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com>> wrote:
>>>>>>>> Hello, Ista.
>>>>>>>> 
>>>>>>>> Honestly, I am uncertain.  I don't have STATA -- I downloaded this from the data source website.
>>>>>>>> 
>>>>>>>> I can't imagine it is 13 because the data are old (2006).
>>>>>>>> 
>>>>>>>> I tried package readstata13 out of desperation, but didn't think it would resolve.
>>>>>>>> 
>>>>>>>> Thanks for the suggestion!
>>>>>>>> 
>>>>>>>> Sent from my iPhone
>>>>>>>> 
>>>>>>>>> On Mar 19, 2015, at 4:41 PM, Ista Zahn <istazahn at gmail.com <mailto:istazahn at gmail.com>> wrote:
>>>>>>>>> 
>>>>>>>>> Hi Nicole,
>>>>>>>>> 
>>>>>>>>> Is it a stata 13 data file? If so your best bet is to open it in Stata
>>>>>>>>> and use the "saveold" command to save it as a stata 12 file.
>>>>>>>>> 
>>>>>>>>> Best,
>>>>>>>>> Ista
>>>>>>>>> 
>>>>>>>>>> On Thu, Mar 19, 2015 at 3:00 PM, Nicole Ford <nicole.ford at me.com <mailto:nicole.ford at me.com>> wrote:
>>>>>>>>>> Hello,
>>>>>>>>>> 
>>>>>>>>>> I recently updated to the newest version of R and I am encountering issues.  Please find my error and session info below.  My data are attached.  I have tried the readstata13 package just in case to no avail.  Unless I am missing something, google isn?t helping.
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Thank you in advance.
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> error:
>>>>>>>>>>> dat <- read.dta(file.choose())
>>>>>>>>>> Error in read.dta(file.choose()) : not a Stata version 5-12 .dta file
>>>>>>>>>> 2015-03-19 14:14:21.445 R[398:5728] Unable to simultaneously satisfy constraints:
>>>>>>>>>> (
>>>>>>>>>>  "<NSAutoresizingMaskLayoutConstraint:0x608000490bd0 h=-&- v=-&- H:|-(0)-[NSView:0x60000012eba0]   (Names: '|':FIFinderView:0x600000363a80 )>",
>>>>>>>>>>  "<NSAutoresizingMaskLayoutConstraint:0x608000490e50 h=-&- v=-&- H:[NSView:0x60000012eba0]-(0)-|   (Names: '|':FIFinderView:0x600000363a80 )>",
>>>>>>>>>>  "<NSAutoresizingMaskLayoutConstraint:0x608000491120 h=-&- v=-&- H:|-(0)-[FIFinderView:0x600000363a80]   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>>>>>>>>>>  "<NSAutoresizingMaskLayoutConstraint:0x608000491170 h=-&- v=-&- H:[FIFinderView:0x600000363a80]-(0)-|   (Names: '|':NSNavFinderViewFileBrowser:0x608000377400 )>",
>>>>>>>>>>  "<NSAutoresizingMaskLayoutConstraint:0x608000491350 h=--& v=--& H:[NSNavFinderViewFileBrowser:0x608000377400(585)]>",
>>>>>>>>>>  "<NSLayoutConstraint:0x600000482d50 H:|-(0)-[NSView:0x60000012e380]   (Names: '|':NSView:0x60000012eba0 )>",
>>>>>>>>>>  "<NSLayoutConstraint:0x600000482da0 H:[NSView:0x60000012e380]-(0)-|   (Names: '|':NSView:0x60000012eba0 )>",
>>>>>>>>>>  "<NSLayoutConstraint:0x6000004816d0 H:[FILocationPopUp:0x6000001f2800(207)]>",
>>>>>>>>>>  "<NSLayoutConstraint:0x600000482a30 NSView:0x60000012e380.centerX == FILocationPopUp:0x6000001f2800.centerX>",
>>>>>>>>>>  "<NSLayoutConstraint:0x6000004825d0 H:[FILocationPopUp:0x6000001f2800]-(>=10)-[SGTSearchField:0x6000003a5160]>",
>>>>>>>>>>  "<NSLayoutConstraint:0x600000482b70 H:[SGTSearchField:0x6000003a5160]-(11)-|   (Names: '|':NSView:0x60000012e380 )>",
>>>>>>>>>>  "<NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>"
>>>>>>>>>> )
>>>>>>>>>> 
>>>>>>>>>> Will attempt to recover by breaking constraint
>>>>>>>>>> <NSLayoutConstraint:0x6000004814f0 H:[SGTSearchField:0x6000003a5160(>=218)]>
>>>>>>>>>> 
>>>>>>>>>> Set the NSUserDefault NSConstraintBasedLayoutVisualizeMutuallyExclusiveConstraints to YES to have -[NSWindow visualizeConstraints:] automatically called when this happens.  And/or, break on objc_exception_throw to catch this in the debugger.
>>>>>>>>>>> sessionInfo()
>>>>>>>>>> 
>>>>>>>>>> Session Info:
>>>>>>>>>> R version 3.1.3 (2015-03-09)
>>>>>>>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>>>>>>>> Running under: OS X 10.10.1 (Yosemite)
>>>>>>>>>> 
>>>>>>>>>> locale:
>>>>>>>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>>>>>>> 
>>>>>>>>>> attached base packages:
>>>>>>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>>>>>> 
>>>>>>>>>> other attached packages:
>>>>>>>>>> [1] effects_3.0-3   lattice_0.20-30 lme4_1.1-7      Rcpp_0.11.2     Matrix_1.1-5    runjags_1.2.1-0 sm_2.2-5.4      foreign_0.8-63  car_2.0-25
>>>>>>>>>> 
>>>>>>>>>> loaded via a namespace (and not attached):
>>>>>>>>>> [1] coda_0.16-1      colorspace_1.2-4 grid_3.1.3       MASS_7.3-39      mgcv_1.8-4       minqa_1.2.3      nlme_3.1-120     nloptr_1.0.0     nnet_7.3-9
>>>>>>>>>> [10] parallel_3.1.3   pbkrtest_0.4-2   quantreg_5.11    SparseM_1.6      splines_3.1.3    tools_3.1.3
>>>>>>>>>> 
>>>>>>>>>> ~n
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> 
>>>>>        [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Lenaig.Hemery at oregonstate.edu  Fri Mar 20 19:24:42 2015
From: Lenaig.Hemery at oregonstate.edu (Hemery, Lenaig)
Date: Fri, 20 Mar 2015 18:24:42 +0000
Subject: [R] Problem with "different" proj4string that are actually
 identical
In-Reply-To: <D1318894.122E1F%macqueen1@llnl.gov>
References: <D1318894.122E1F%macqueen1@llnl.gov>
Message-ID: <7D3B4F8ADC4D0E47B3351BBF6AD32EB34F7ABACD@EX1.oregonstate.edu>

Dear Don,
Thanks for your answer. 
proj4string(spCro) == proj4string(paramdf), as well as identical(proj4string(spCro), proj4string(paramdf)), returns a TRUE so I forced them to be identical as you suggested, and repeated the niche.test(), but I got the same error message.
Would you have any other ideas?
Thanks a lot,
Lenaig
________________________________________
From: MacQueen, Don [macqueen1 at llnl.gov]
Sent: Friday, March 20, 2015 8:23 AM
To: Hemery, Lenaig; r-help at R-project.org
Subject: Re: [R] Problem with "different" proj4string that are actually identical

This question would be better asked on r-sig-geo.

Here are some things to try (type at the R prompt):

  proj4string(spCro) == proj4string(paramdf)

Does it return TRUE or FALSE?

Or, instead of using summary(), directly inspect the proj4strings:

  proj4string(spCro)
  proj4string(paramdf)

If there still appears to be no difference between them,
try forcing them to be identical
  proj4string(spCro) <- proj4string(paramdf)

then repeat your niche.test()


--
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/19/15, 5:29 PM, "Hemery, Lenaig" <Lenaig.Hemery at oregonstate.edu>
wrote:

>Dear everybody
>I am trying to run an Ecological Niche Factor Analysis (enfa) with the
>package "adehabitatHS" but before I do so, I want to test the
>significance of its parameters marginality and tolerance, by using the
>function niche.test() that runs a Monte Carlo test. I used to do that
>with the old package "adehabitat" that is now deprecated so I updated all
>my codes. Everything I want to do seems to work fine except the
>niche.test() function and I get the error message here below.
>
>> testCro<-niche.test(paramdf, spCro, nrep = 999, o.include = TRUE)
>Error in join(pts, ta) : different proj4string in x and xy
>
>I checked the proj4string for x (paramdf) and xy (spCro) and there are
>exactly identical (see below).
>
>> summary(spCro)
>Object of class SpatialPoints
>Coordinates:
>              min     max
>longitude -124.91 -124.13
>latitude    39.86   46.95
>Is projected: FALSE
>proj4string :
>[+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0]
>Number of points: 84
>
>> summary(paramdf)
>Object of class SpatialPixelsDataFrame
>Coordinates:
>         min       max
>x -125.50000 -123.7998
>y   39.50384   47.0000
>Is projected: FALSE
>proj4string :
>[+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0]
>Number of points: 108237
>Grid attributes:
>  cellcentre.offset cellsize cells.dim
>x        -125.49517  0.00966       176
>y          39.50867  0.00966       776
>Data attributes:
>      bath              slope              rugo               sumT
> Min.   :-3611.83   Min.   : 0.0000   Min.   :0.000000   Min.   : 1.184
> 1st Qu.:-1885.11   1st Qu.: 0.5271   1st Qu.:0.008044   1st Qu.: 2.150
> Median : -894.61   Median : 1.4974   Median :0.036921   Median : 3.978
> Mean   :-1157.85   Mean   : 3.4237   Mean   :0.147369   Mean   : 4.794
> 3rd Qu.: -150.85   3rd Qu.: 4.1152   3rd Qu.:0.197974   3rd Qu.: 7.388
> Max.   :   -0.05   Max.   :61.3592   Max.   :0.992856   Max.   :14.436
>[...]
>
>I think I looked for all the help I could find on the internet and didn't
>find any solution so here is my last chance.
>Does anybody have an idea on how to solve this problem?
>By the way, I use the R version 3.1.3 and up-to-date "adehabitatHS",
>"ade4", "sp" and other packages.
>Thanks a lot,
>Lenaig
>
>???? ><)))?> <?(((>< ????
>Lena?g Hemery, Ph. D.
>Research Associate - post-doc
>Hatfield Marine Science Center
>Oregon State University
>2030 S.E. Marine Science Drive, Newport, OR 97365, USA
>Cell:+1-541-272-7196
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From macqueen1 at llnl.gov  Sat Mar 21 00:18:03 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 20 Mar 2015 23:18:03 +0000
Subject: [R] Problem with "different" proj4string that are actually
 identical
In-Reply-To: <7D3B4F8ADC4D0E47B3351BBF6AD32EB34F7ABACD@EX1.oregonstate.edu>
References: <D1318894.122E1F%macqueen1@llnl.gov>
	<7D3B4F8ADC4D0E47B3351BBF6AD32EB34F7ABACD@EX1.oregonstate.edu>
Message-ID: <D131F738.1232DD%macqueen1@llnl.gov>

Hmm, that does complicate things. Since the error message references
"join(pts, ta)" I think you're going to have to find out more about this
join() function and how niche.test() constructs the arguments that it
passes to join().

Starting with
  traceback() 
immediately after getting the error might help.

If you move this question over to r-sig-geo your chances of getting help
from someone familiar with niche.test() and/or join() is better.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/20/15, 11:24 AM, "Hemery, Lenaig" <Lenaig.Hemery at oregonstate.edu>
wrote:

>Dear Don,
>Thanks for your answer.
>proj4string(spCro) == proj4string(paramdf), as well as
>identical(proj4string(spCro), proj4string(paramdf)), returns a TRUE so I
>forced them to be identical as you suggested, and repeated the
>niche.test(), but I got the same error message.
>Would you have any other ideas?
>Thanks a lot,
>Lenaig
>________________________________________
>From: MacQueen, Don [macqueen1 at llnl.gov]
>Sent: Friday, March 20, 2015 8:23 AM
>To: Hemery, Lenaig; r-help at R-project.org
>Subject: Re: [R] Problem with "different" proj4string that are actually
>identical
>
>This question would be better asked on r-sig-geo.
>
>Here are some things to try (type at the R prompt):
>
>  proj4string(spCro) == proj4string(paramdf)
>
>Does it return TRUE or FALSE?
>
>Or, instead of using summary(), directly inspect the proj4strings:
>
>  proj4string(spCro)
>  proj4string(paramdf)
>
>If there still appears to be no difference between them,
>try forcing them to be identical
>  proj4string(spCro) <- proj4string(paramdf)
>
>then repeat your niche.test()
>
>
>--
>Don MacQueen
>
>Lawrence Livermore National Laboratory
>7000 East Ave., L-627
>Livermore, CA 94550
>925-423-1062
>
>
>
>
>
>On 3/19/15, 5:29 PM, "Hemery, Lenaig" <Lenaig.Hemery at oregonstate.edu>
>wrote:
>
>>Dear everybody
>>I am trying to run an Ecological Niche Factor Analysis (enfa) with the
>>package "adehabitatHS" but before I do so, I want to test the
>>significance of its parameters marginality and tolerance, by using the
>>function niche.test() that runs a Monte Carlo test. I used to do that
>>with the old package "adehabitat" that is now deprecated so I updated all
>>my codes. Everything I want to do seems to work fine except the
>>niche.test() function and I get the error message here below.
>>
>>> testCro<-niche.test(paramdf, spCro, nrep = 999, o.include = TRUE)
>>Error in join(pts, ta) : different proj4string in x and xy
>>
>>I checked the proj4string for x (paramdf) and xy (spCro) and there are
>>exactly identical (see below).
>>
>>> summary(spCro)
>>Object of class SpatialPoints
>>Coordinates:
>>              min     max
>>longitude -124.91 -124.13
>>latitude    39.86   46.95
>>Is projected: FALSE
>>proj4string :
>>[+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0]
>>Number of points: 84
>>
>>> summary(paramdf)
>>Object of class SpatialPixelsDataFrame
>>Coordinates:
>>         min       max
>>x -125.50000 -123.7998
>>y   39.50384   47.0000
>>Is projected: FALSE
>>proj4string :
>>[+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0]
>>Number of points: 108237
>>Grid attributes:
>>  cellcentre.offset cellsize cells.dim
>>x        -125.49517  0.00966       176
>>y          39.50867  0.00966       776
>>Data attributes:
>>      bath              slope              rugo               sumT
>> Min.   :-3611.83   Min.   : 0.0000   Min.   :0.000000   Min.   : 1.184
>> 1st Qu.:-1885.11   1st Qu.: 0.5271   1st Qu.:0.008044   1st Qu.: 2.150
>> Median : -894.61   Median : 1.4974   Median :0.036921   Median : 3.978
>> Mean   :-1157.85   Mean   : 3.4237   Mean   :0.147369   Mean   : 4.794
>> 3rd Qu.: -150.85   3rd Qu.: 4.1152   3rd Qu.:0.197974   3rd Qu.: 7.388
>> Max.   :   -0.05   Max.   :61.3592   Max.   :0.992856   Max.   :14.436
>>[...]
>>
>>I think I looked for all the help I could find on the internet and didn't
>>find any solution so here is my last chance.
>>Does anybody have an idea on how to solve this problem?
>>By the way, I use the R version 3.1.3 and up-to-date "adehabitatHS",
>>"ade4", "sp" and other packages.
>>Thanks a lot,
>>Lenaig
>>
>>???? ><)))?> <?(((>< ????
>>Lena?g Hemery, Ph. D.
>>Research Associate - post-doc
>>Hatfield Marine Science Center
>>Oregon State University
>>2030 S.E. Marine Science Drive, Newport, OR 97365, USA
>>Cell:+1-541-272-7196
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From Jean.Coursol at math.u-psud.fr  Sat Mar 21 12:04:00 2015
From: Jean.Coursol at math.u-psud.fr (Jean.Coursol at math.u-psud.fr)
Date: Sat, 21 Mar 2015 12:04:00 +0100
Subject: [R] automatic coercicion
Message-ID: <1a8d5bca9250faf20c5f1f735822dc01.squirrel@fiara.math.u-psud.fr>

My question must be a trivial one.

There is automatic coercicion to vector when extracting only one line of a
matrix.
# example
A = matrix(1:12,3,4)
rownames(A) = c('a1','a2','a3')

i = 1:2
A[i,]
#    [,1] [,2] [,3] [,4]
# a1    1    4    7   10    matrix
# a2    2    5    8   11

i = 1
A[i,]
# [1]  1  4  7 10           vector !!!

# to get the rowname, it is necessary to do
rownames(A)[i]
# [1] "a1"

Is it possible to get a (1,4)-matrix (without testing length(i) ) ? I see
nothing in options()...

Jean Coursol


From jvadams at usgs.gov  Sat Mar 21 12:15:17 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Sat, 21 Mar 2015 06:15:17 -0500
Subject: [R] automatic coercicion
In-Reply-To: <1a8d5bca9250faf20c5f1f735822dc01.squirrel@fiara.math.u-psud.fr>
References: <1a8d5bca9250faf20c5f1f735822dc01.squirrel@fiara.math.u-psud.fr>
Message-ID: <CAN5YmCEwnYHRtRmZEad6RJ+EEF0miYjF1bmcseBxjL821_gRrQ@mail.gmail.com>

>From one Jean to another ... A[i, , drop=FALSE]

On Sat, Mar 21, 2015 at 6:04 AM, <Jean.Coursol at math.u-psud.fr> wrote:

> My question must be a trivial one.
>
> There is automatic coercicion to vector when extracting only one line of a
> matrix.
> # example
> A = matrix(1:12,3,4)
> rownames(A) = c('a1','a2','a3')
>
> i = 1:2
> A[i,]
> #    [,1] [,2] [,3] [,4]
> # a1    1    4    7   10    matrix
> # a2    2    5    8   11
>
> i = 1
> A[i,]
> # [1]  1  4  7 10           vector !!!
>
> # to get the rowname, it is necessary to do
> rownames(A)[i]
> # [1] "a1"
>
> Is it possible to get a (1,4)-matrix (without testing length(i) ) ? I see
> nothing in options()...
>
> Jean Coursol
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lucam1968 at gmail.com  Sat Mar 21 12:53:04 2015
From: lucam1968 at gmail.com (Luca Meyer)
Date: Sat, 21 Mar 2015 12:53:04 +0100
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
Message-ID: <CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>

Hi Jeff & other R-experts,

Thank you for your note. I have tried myself to solve the issue without
success.

Following your suggestion, I am providing a sample of the dataset I am
using below (also downloadble in plain text from
https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):

#this is an extract of the overall dataset (n=1200 cases)
f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
"B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
"B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
"B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835, 3.43806581506388,
0.002733567617055, 1.42917483425029, 1.05786640463504,
0.000420548864162308,
2.37232740842861, 3.01835841813241, 0, 1.13430282139936, 0.928725667117666,
0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names =
c(2L,
9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))

I need to find a automated procedure that allows me to adjust v3 marginals
while maintaining v1xv2 marginals unchanged.

That is: modify the v4 values you can find by running:

aggregate(f1[,c("v4")],list(f1$v3),sum)

while maintaining costant the values you can find by running:

aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)

Now does it make sense?

Please notice I have tried to build some syntax that tries to modify values
within each v1xv2 combination by computing sum of v4, row percentage in
terms of v4, and there is where my effort is blocked. Not really sure how I
should proceed. Any suggestion?

Thanks,

Luca


2015-03-19 2:38 GMT+01:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> I don't understand your description. The standard practice on this list is
> to provide a reproducible R example [1] of the kind of data you are working
> with (and any code you have tried) to go along with your description. In
> this case, that would be two dputs of your input data frames and a dput of
> an output data frame (generated by hand from your input data frame).
> (Probably best to not use the full number of input values just to keep the
> size down.) We could then make an attempt to generate code that goes from
> input to output.
>
> Of course, if you post that hard work using HTML then it will get
> corrupted (much like the text below from your earlier emails) and we won't
> be able to use it. Please learn to post from your email software using
> plain text when corresponding with this mailing list.
>
> [1]
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <lucam1968 at gmail.com> wrote:
> >Thanks for you input Michael,
> >
> >The continuous variable I have measures quantities (down to the 3rd
> >decimal level) so unfortunately are not frequencies.
> >
> >Any more specific suggestions on how that could be tackled?
> >
> >Thanks & kind regards,
> >
> >Luca
> >
> >
> >===
> >
> >Michael Friendly wrote:
> >I'm not sure I understand completely what you want to do, but
> >if the data were frequencies, it sounds like task for fitting a
> >loglinear model with the model formula
> >
> >~ V1*V2 + V3
> >
> >On 3/18/2015 2:17 AM, Luca Meyer wrote:
> >>* Hello,
> >*>>* I am facing a quite challenging task (at least to me) and I was
> >wondering
> >*>* if someone could advise how R could assist me to speed the task up.
> >*>>* I am dealing with a dataset with 3 discrete variables and one
> >continuous
> >*>* variable. The discrete variables are:
> >*>>* V1: 8 modalities
> >*>* V2: 13 modalities
> >*>* V3: 13 modalities
> >*>>* The continuous variable V4 is a decimal number always greater than
> >zero in
> >*>* the marginals of each of the 3 variables but it is sometimes equal
> >to zero
> >*>* (and sometimes negative) in the joint tables.
> >*>>* I have got 2 files:
> >*>>* => one with distribution of all possible combinations of V1xV2
> >(some of
> >*>* which are zero or neagtive) and
> >*>* => one with the marginal distribution of V3.
> >*>>* I am trying to build the long and narrow dataset V1xV2xV3 in such
> >a way
> >*>* that each V1xV2 cell does not get modified and V3 fits as closely
> >as
> >*>* possible to its marginal distribution. Does it make sense?
> >*>>* To be even more specific, my 2 input files look like the
> >following.
> >*>>* FILE 1
> >*>* V1,V2,V4
> >*>* A, A, 24.251
> >*>* A, B, 1.065
> >*>* (...)
> >*>* B, C, 0.294
> >*>* B, D, 2.731
> >*>* (...)
> >*>* H, L, 0.345
> >*>* H, M, 0.000
> >*>>* FILE 2
> >*>* V3, V4
> >*>* A, 1.575
> >*>* B, 4.294
> >*>* C, 10.044
> >*>* (...)
> >*>* L, 5.123
> >*>* M, 3.334
> >*>>* What I need to achieve is a file such as the following
> >*>>* FILE 3
> >*>* V1, V2, V3, V4
> >*>* A, A, A, ???
> >*>* A, A, B, ???
> >*>* (...)
> >*>* D, D, E, ???
> >*>* D, D, F, ???
> >*>* (...)
> >*>* H, M, L, ???
> >*>* H, M, M, ???
> >*>>* Please notice that FILE 3 need to be such that if I aggregate on
> >V1+V2 I
> >*>* recover exactly FILE 1 and that if I aggregate on V3 I can recover
> >a file
> >*>* as close as possible to FILE 3 (ideally the same file).
> >*>>* Can anyone suggest how I could do that with R?
> >*>>* Thank you very much indeed for any assistance you are able to
> >provide.
> >*>>* Kind regards,
> >*>>* Luca*
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sat Mar 21 13:18:29 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 21 Mar 2015 05:18:29 -0700
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
Message-ID: <CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>

1. Still not sure what you mean, but maybe look at ?ave and ?tapply,
for which ave() is a wrapper.

2. You still need to heed the rest of Jeff's advice.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
> Hi Jeff & other R-experts,
>
> Thank you for your note. I have tried myself to solve the issue without
> success.
>
> Following your suggestion, I am providing a sample of the dataset I am
> using below (also downloadble in plain text from
> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
>
> #this is an extract of the overall dataset (n=1200 cases)
> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835, 3.43806581506388,
> 0.002733567617055, 1.42917483425029, 1.05786640463504,
> 0.000420548864162308,
> 2.37232740842861, 3.01835841813241, 0, 1.13430282139936, 0.928725667117666,
> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names =
> c(2L,
> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>
> I need to find a automated procedure that allows me to adjust v3 marginals
> while maintaining v1xv2 marginals unchanged.
>
> That is: modify the v4 values you can find by running:
>
> aggregate(f1[,c("v4")],list(f1$v3),sum)
>
> while maintaining costant the values you can find by running:
>
> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>
> Now does it make sense?
>
> Please notice I have tried to build some syntax that tries to modify values
> within each v1xv2 combination by computing sum of v4, row percentage in
> terms of v4, and there is where my effort is blocked. Not really sure how I
> should proceed. Any suggestion?
>
> Thanks,
>
> Luca
>
>
> 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>
>> I don't understand your description. The standard practice on this list is
>> to provide a reproducible R example [1] of the kind of data you are working
>> with (and any code you have tried) to go along with your description. In
>> this case, that would be two dputs of your input data frames and a dput of
>> an output data frame (generated by hand from your input data frame).
>> (Probably best to not use the full number of input values just to keep the
>> size down.) We could then make an attempt to generate code that goes from
>> input to output.
>>
>> Of course, if you post that hard work using HTML then it will get
>> corrupted (much like the text below from your earlier emails) and we won't
>> be able to use it. Please learn to post from your email software using
>> plain text when corresponding with this mailing list.
>>
>> [1]
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <lucam1968 at gmail.com> wrote:
>> >Thanks for you input Michael,
>> >
>> >The continuous variable I have measures quantities (down to the 3rd
>> >decimal level) so unfortunately are not frequencies.
>> >
>> >Any more specific suggestions on how that could be tackled?
>> >
>> >Thanks & kind regards,
>> >
>> >Luca
>> >
>> >
>> >===
>> >
>> >Michael Friendly wrote:
>> >I'm not sure I understand completely what you want to do, but
>> >if the data were frequencies, it sounds like task for fitting a
>> >loglinear model with the model formula
>> >
>> >~ V1*V2 + V3
>> >
>> >On 3/18/2015 2:17 AM, Luca Meyer wrote:
>> >>* Hello,
>> >*>>* I am facing a quite challenging task (at least to me) and I was
>> >wondering
>> >*>* if someone could advise how R could assist me to speed the task up.
>> >*>>* I am dealing with a dataset with 3 discrete variables and one
>> >continuous
>> >*>* variable. The discrete variables are:
>> >*>>* V1: 8 modalities
>> >*>* V2: 13 modalities
>> >*>* V3: 13 modalities
>> >*>>* The continuous variable V4 is a decimal number always greater than
>> >zero in
>> >*>* the marginals of each of the 3 variables but it is sometimes equal
>> >to zero
>> >*>* (and sometimes negative) in the joint tables.
>> >*>>* I have got 2 files:
>> >*>>* => one with distribution of all possible combinations of V1xV2
>> >(some of
>> >*>* which are zero or neagtive) and
>> >*>* => one with the marginal distribution of V3.
>> >*>>* I am trying to build the long and narrow dataset V1xV2xV3 in such
>> >a way
>> >*>* that each V1xV2 cell does not get modified and V3 fits as closely
>> >as
>> >*>* possible to its marginal distribution. Does it make sense?
>> >*>>* To be even more specific, my 2 input files look like the
>> >following.
>> >*>>* FILE 1
>> >*>* V1,V2,V4
>> >*>* A, A, 24.251
>> >*>* A, B, 1.065
>> >*>* (...)
>> >*>* B, C, 0.294
>> >*>* B, D, 2.731
>> >*>* (...)
>> >*>* H, L, 0.345
>> >*>* H, M, 0.000
>> >*>>* FILE 2
>> >*>* V3, V4
>> >*>* A, 1.575
>> >*>* B, 4.294
>> >*>* C, 10.044
>> >*>* (...)
>> >*>* L, 5.123
>> >*>* M, 3.334
>> >*>>* What I need to achieve is a file such as the following
>> >*>>* FILE 3
>> >*>* V1, V2, V3, V4
>> >*>* A, A, A, ???
>> >*>* A, A, B, ???
>> >*>* (...)
>> >*>* D, D, E, ???
>> >*>* D, D, F, ???
>> >*>* (...)
>> >*>* H, M, L, ???
>> >*>* H, M, M, ???
>> >*>>* Please notice that FILE 3 need to be such that if I aggregate on
>> >V1+V2 I
>> >*>* recover exactly FILE 1 and that if I aggregate on V3 I can recover
>> >a file
>> >*>* as close as possible to FILE 3 (ideally the same file).
>> >*>>* Can anyone suggest how I could do that with R?
>> >*>>* Thank you very much indeed for any assistance you are able to
>> >provide.
>> >*>>* Kind regards,
>> >*>>* Luca*
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From johannesradinger at gmail.com  Sat Mar 21 14:05:34 2015
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Sat, 21 Mar 2015 14:05:34 +0100
Subject: [R] Optimization to fit data to custom density distribution
Message-ID: <CABsGe_w0UP2WeqcsGXb2qaegZZAGKUhwpk+jCaxo0oCOcZLKjw@mail.gmail.com>

Hi,

I am looking for a way to fit data (vector of values) to a density function
using an optimization (ordinary least squares or maximum likelihood fit).
For example if I have a vector of 100 values generated with rnorm:

rnorm(n=100,mean=500,sd=50)

How can I fit these data to a Gaussian density function to extract the mean
and sd value of the underlying normal distribution. So the result should
roughly meet the parameters of the normal distribution used to generate the
data. The results will ideally be closer the true parameters the more data
(n) are used to optimize the density function.

Any suggestions?

/Johannes

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Sat Mar 21 14:16:40 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 21 Mar 2015 13:16:40 +0000
Subject: [R] Optimization to fit data to custom density distribution
In-Reply-To: <CABsGe_w0UP2WeqcsGXb2qaegZZAGKUhwpk+jCaxo0oCOcZLKjw@mail.gmail.com>
References: <CABsGe_w0UP2WeqcsGXb2qaegZZAGKUhwpk+jCaxo0oCOcZLKjw@mail.gmail.com>
Message-ID: <550D6F38.5000406@stats.ox.ac.uk>

One way using the standard R distribution:

library(MASS)
?fitdistr

No optimization is needed to fit a normal distribution, though.

On 21/03/2015 13:05, Johannes Radinger wrote:
> Hi,
>
> I am looking for a way to fit data (vector of values) to a density function
> using an optimization (ordinary least squares or maximum likelihood fit).
> For example if I have a vector of 100 values generated with rnorm:
>
> rnorm(n=100,mean=500,sd=50)
>
> How can I fit these data to a Gaussian density function to extract the mean
> and sd value of the underlying normal distribution. So the result should
> roughly meet the parameters of the normal distribution used to generate the
> data. The results will ideally be closer the true parameters the more data
> (n) are used to optimize the density function.

That's a concept called 'consistency' from the statistical theory of 
estimation.  If you skipped that course, time to read up (but it is 
off-topic here).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From lucam1968 at gmail.com  Sat Mar 21 14:49:26 2015
From: lucam1968 at gmail.com (Luca Meyer)
Date: Sat, 21 Mar 2015 14:49:26 +0100
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
	<CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
Message-ID: <CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>

Hi Bert,

Thank you for your message. I am looking into ave() and tapply() as you
suggested but at the same time I have prepared a example of input and
output files, just in case you or someone else would like to make an
attempt to generate a code that goes from input to output.

Please see below or download it from
https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0

# this is (an extract of) the INPUT file I have:
f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
"B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
"B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
"B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917,
1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names =
c(2L,
9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))

# this is (an extract of) the OUTPUT file I would like to obtain:
f2 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
"B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
"B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
"B", "B", "B", "C", "C", "C"), v4 = c(17.83529, 3.43806,0.00295, 1.77918,
1.05786, 0.0002, 2.37232, 3.01835, 0, 1.13430, 0.92872,
0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names =
c(2L,
9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))

# please notice that while the aggregated v4 on v3 has changed ?
aggregate(f1[,c("v4")],list(f1$v3),sum)
aggregate(f2[,c("v4")],list(f2$v3),sum)

# ? the aggregated v4 over v1xv2 has remained unchanged:
aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
aggregate(f2[,c("v4")],list(f2$v1,f2$v2),sum)

Thank you very much in advance for your assitance.

Luca

2015-03-21 13:18 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:

> 1. Still not sure what you mean, but maybe look at ?ave and ?tapply,
> for which ave() is a wrapper.
>
> 2. You still need to heed the rest of Jeff's advice.
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
> > Hi Jeff & other R-experts,
> >
> > Thank you for your note. I have tried myself to solve the issue without
> > success.
> >
> > Following your suggestion, I am providing a sample of the dataset I am
> > using below (also downloadble in plain text from
> > https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
> >
> > #this is an extract of the overall dataset (n=1200 cases)
> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> > "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> > "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> > "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835, 3.43806581506388,
> > 0.002733567617055, 1.42917483425029, 1.05786640463504,
> > 0.000420548864162308,
> > 2.37232740842861, 3.01835841813241, 0, 1.13430282139936,
> 0.928725667117666,
> > 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names
> =
> > c(2L,
> > 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >
> > I need to find a automated procedure that allows me to adjust v3
> marginals
> > while maintaining v1xv2 marginals unchanged.
> >
> > That is: modify the v4 values you can find by running:
> >
> > aggregate(f1[,c("v4")],list(f1$v3),sum)
> >
> > while maintaining costant the values you can find by running:
> >
> > aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
> >
> > Now does it make sense?
> >
> > Please notice I have tried to build some syntax that tries to modify
> values
> > within each v1xv2 combination by computing sum of v4, row percentage in
> > terms of v4, and there is where my effort is blocked. Not really sure
> how I
> > should proceed. Any suggestion?
> >
> > Thanks,
> >
> > Luca
> >
> >
> > 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
> >
> >> I don't understand your description. The standard practice on this list
> is
> >> to provide a reproducible R example [1] of the kind of data you are
> working
> >> with (and any code you have tried) to go along with your description. In
> >> this case, that would be two dputs of your input data frames and a dput
> of
> >> an output data frame (generated by hand from your input data frame).
> >> (Probably best to not use the full number of input values just to keep
> the
> >> size down.) We could then make an attempt to generate code that goes
> from
> >> input to output.
> >>
> >> Of course, if you post that hard work using HTML then it will get
> >> corrupted (much like the text below from your earlier emails) and we
> won't
> >> be able to use it. Please learn to post from your email software using
> >> plain text when corresponding with this mailing list.
> >>
> >> [1]
> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >>
> ---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go
> Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >> Go...
> >>                                       Live:   OO#.. Dead: OO#..  Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> >>
> ---------------------------------------------------------------------------
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <lucam1968 at gmail.com>
> wrote:
> >> >Thanks for you input Michael,
> >> >
> >> >The continuous variable I have measures quantities (down to the 3rd
> >> >decimal level) so unfortunately are not frequencies.
> >> >
> >> >Any more specific suggestions on how that could be tackled?
> >> >
> >> >Thanks & kind regards,
> >> >
> >> >Luca
> >> >
> >> >
> >> >===
> >> >
> >> >Michael Friendly wrote:
> >> >I'm not sure I understand completely what you want to do, but
> >> >if the data were frequencies, it sounds like task for fitting a
> >> >loglinear model with the model formula
> >> >
> >> >~ V1*V2 + V3
> >> >
> >> >On 3/18/2015 2:17 AM, Luca Meyer wrote:
> >> >>* Hello,
> >> >*>>* I am facing a quite challenging task (at least to me) and I was
> >> >wondering
> >> >*>* if someone could advise how R could assist me to speed the task up.
> >> >*>>* I am dealing with a dataset with 3 discrete variables and one
> >> >continuous
> >> >*>* variable. The discrete variables are:
> >> >*>>* V1: 8 modalities
> >> >*>* V2: 13 modalities
> >> >*>* V3: 13 modalities
> >> >*>>* The continuous variable V4 is a decimal number always greater than
> >> >zero in
> >> >*>* the marginals of each of the 3 variables but it is sometimes equal
> >> >to zero
> >> >*>* (and sometimes negative) in the joint tables.
> >> >*>>* I have got 2 files:
> >> >*>>* => one with distribution of all possible combinations of V1xV2
> >> >(some of
> >> >*>* which are zero or neagtive) and
> >> >*>* => one with the marginal distribution of V3.
> >> >*>>* I am trying to build the long and narrow dataset V1xV2xV3 in such
> >> >a way
> >> >*>* that each V1xV2 cell does not get modified and V3 fits as closely
> >> >as
> >> >*>* possible to its marginal distribution. Does it make sense?
> >> >*>>* To be even more specific, my 2 input files look like the
> >> >following.
> >> >*>>* FILE 1
> >> >*>* V1,V2,V4
> >> >*>* A, A, 24.251
> >> >*>* A, B, 1.065
> >> >*>* (...)
> >> >*>* B, C, 0.294
> >> >*>* B, D, 2.731
> >> >*>* (...)
> >> >*>* H, L, 0.345
> >> >*>* H, M, 0.000
> >> >*>>* FILE 2
> >> >*>* V3, V4
> >> >*>* A, 1.575
> >> >*>* B, 4.294
> >> >*>* C, 10.044
> >> >*>* (...)
> >> >*>* L, 5.123
> >> >*>* M, 3.334
> >> >*>>* What I need to achieve is a file such as the following
> >> >*>>* FILE 3
> >> >*>* V1, V2, V3, V4
> >> >*>* A, A, A, ???
> >> >*>* A, A, B, ???
> >> >*>* (...)
> >> >*>* D, D, E, ???
> >> >*>* D, D, F, ???
> >> >*>* (...)
> >> >*>* H, M, L, ???
> >> >*>* H, M, M, ???
> >> >*>>* Please notice that FILE 3 need to be such that if I aggregate on
> >> >V1+V2 I
> >> >*>* recover exactly FILE 1 and that if I aggregate on V3 I can recover
> >> >a file
> >> >*>* as close as possible to FILE 3 (ideally the same file).
> >> >*>>* Can anyone suggest how I could do that with R?
> >> >*>>* Thank you very much indeed for any assistance you are able to
> >> >provide.
> >> >*>>* Kind regards,
> >> >*>>* Luca*
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From johannesradinger at gmail.com  Sat Mar 21 15:27:25 2015
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Sat, 21 Mar 2015 15:27:25 +0100
Subject: [R] Optimization to fit data to custom density distribution
In-Reply-To: <550D6F38.5000406@stats.ox.ac.uk>
References: <CABsGe_w0UP2WeqcsGXb2qaegZZAGKUhwpk+jCaxo0oCOcZLKjw@mail.gmail.com>
	<550D6F38.5000406@stats.ox.ac.uk>
Message-ID: <CABsGe_yrHCpz2-0fwJp+PS4PpM849ZFuGQMiDNx-YqCUGXA0Zw@mail.gmail.com>

Thanks for the fast response. The fitdistr() function works well for the
predefined density functions. However, what is the recommended approach to
optimize/fit a density function described by two superimposed normal
distributions? In my case it is N1(mean=0,sd1)*p+N2(mean=0,sd2)*(1-p). With
fitdistr one can only choose among the 15 distributions. Probably this
needs an approach using optim()? However I am so far unfamiliar with these
packages. So any suggestion ist welcome. :)

/Johannes

On Sat, Mar 21, 2015 at 2:16 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk>
wrote:

> One way using the standard R distribution:
>
> library(MASS)
> ?fitdistr
>
> No optimization is needed to fit a normal distribution, though.
>
>
> On 21/03/2015 13:05, Johannes Radinger wrote:
>
>> Hi,
>>
>> I am looking for a way to fit data (vector of values) to a density
>> function
>> using an optimization (ordinary least squares or maximum likelihood fit).
>> For example if I have a vector of 100 values generated with rnorm:
>>
>> rnorm(n=100,mean=500,sd=50)
>>
>> How can I fit these data to a Gaussian density function to extract the
>> mean
>> and sd value of the underlying normal distribution. So the result should
>> roughly meet the parameters of the normal distribution used to generate
>> the
>> data. The results will ideally be closer the true parameters the more data
>> (n) are used to optimize the density function.
>>
>
> That's a concept called 'consistency' from the statistical theory of
> estimation.  If you skipped that course, time to read up (but it is
> off-topic here).
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Sat Mar 21 15:41:07 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 21 Mar 2015 14:41:07 +0000
Subject: [R] Optimization to fit data to custom density distribution
In-Reply-To: <CABsGe_yrHCpz2-0fwJp+PS4PpM849ZFuGQMiDNx-YqCUGXA0Zw@mail.gmail.com>
References: <CABsGe_w0UP2WeqcsGXb2qaegZZAGKUhwpk+jCaxo0oCOcZLKjw@mail.gmail.com>	<550D6F38.5000406@stats.ox.ac.uk>
	<CABsGe_yrHCpz2-0fwJp+PS4PpM849ZFuGQMiDNx-YqCUGXA0Zw@mail.gmail.com>
Message-ID: <550D8303.1060204@stats.ox.ac.uk>

On 21/03/2015 14:27, Johannes Radinger wrote:
> Thanks for the fast response. The fitdistr() function works well for the
> predefined density functions. However, what is the recommended approach
> to optimize/fit a density function described by two superimposed normal
> distributions? In my case it is N1(mean=0,sd1)*p+N2(mean=0,sd2)*(1-p).
> With fitdistr one can only choose among the 15 distributions. Probably

That is simply not true.  The help says

densfun: Either a character string or a function returning a density
           evaluated at its first argument.

and the second alternative is used in the examples.

> this needs an approach using optim()? However I am so far unfamiliar
> with these packages. So any suggestion ist welcome. :)

There are examples of that in MASS (the book), chapter 16.

>
> /Johannes
>
> On Sat, Mar 21, 2015 at 2:16 PM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk <mailto:ripley at stats.ox.ac.uk>> wrote:
>
>     One way using the standard R distribution:
>
>     library(MASS)
>     ?fitdistr
>
>     No optimization is needed to fit a normal distribution, though.
>
>
>     On 21/03/2015 13:05, Johannes Radinger wrote:
>
>         Hi,
>
>         I am looking for a way to fit data (vector of values) to a
>         density function
>         using an optimization (ordinary least squares or maximum
>         likelihood fit).
>         For example if I have a vector of 100 values generated with rnorm:
>
>         rnorm(n=100,mean=500,sd=50)
>
>         How can I fit these data to a Gaussian density function to
>         extract the mean
>         and sd value of the underlying normal distribution. So the
>         result should
>         roughly meet the parameters of the normal distribution used to
>         generate the
>         data. The results will ideally be closer the true parameters the
>         more data
>         (n) are used to optimize the density function.
>
>
>     That's a concept called 'consistency' from the statistical theory of
>     estimation.  If you skipped that course, time to read up (but it is
>     off-topic here).
>
>     --
>     Brian D. Ripley, ripley at stats.ox.ac.uk <mailto:ripley at stats.ox.ac.uk>
>     Emeritus Professor of Applied Statistics, University of Oxford
>     1 South Parks Road, Oxford OX1 3TG, UK
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From gunter.berton at gene.com  Sat Mar 21 15:53:14 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 21 Mar 2015 07:53:14 -0700
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
	<CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
	<CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>
Message-ID: <CACk-te2CBQXFGJ-Vhr+kpdY6uccbn0Rp286ca+2YvKO=iHUogg@mail.gmail.com>

z <- rnorm(nrow(f1)) ## or anything you want
z1 <- f1$v4 + z - with(f1,ave(z,v1,v2,FUN=mean))


aggregate(v4~v1,f1,sum)
aggregate(z1~v1,f1,sum)
aggregate(v4~v2,f1,sum)
aggregate(z1~v2,f1,sum)
aggregate(v4~v3,f1,sum)
aggregate(z1~v3,f1,sum)


Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Mar 21, 2015 at 6:49 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
> Hi Bert,
>
> Thank you for your message. I am looking into ave() and tapply() as you
> suggested but at the same time I have prepared a example of input and output
> files, just in case you or someone else would like to make an attempt to
> generate a code that goes from input to output.
>
> Please see below or download it from
> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
>
> # this is (an extract of) the INPUT file I have:
> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917,
> 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names =
> c(2L,
> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>
> # this is (an extract of) the OUTPUT file I would like to obtain:
> f2 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> "B", "B", "B", "C", "C", "C"), v4 = c(17.83529, 3.43806,0.00295, 1.77918,
> 1.05786, 0.0002, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names =
> c(2L,
> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>
> # please notice that while the aggregated v4 on v3 has changed ?
> aggregate(f1[,c("v4")],list(f1$v3),sum)
> aggregate(f2[,c("v4")],list(f2$v3),sum)
>
> # ? the aggregated v4 over v1xv2 has remained unchanged:
> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
> aggregate(f2[,c("v4")],list(f2$v1,f2$v2),sum)
>
> Thank you very much in advance for your assitance.
>
> Luca
>
> 2015-03-21 13:18 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>>
>> 1. Still not sure what you mean, but maybe look at ?ave and ?tapply,
>> for which ave() is a wrapper.
>>
>> 2. You still need to heed the rest of Jeff's advice.
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
>> > Hi Jeff & other R-experts,
>> >
>> > Thank you for your note. I have tried myself to solve the issue without
>> > success.
>> >
>> > Following your suggestion, I am providing a sample of the dataset I am
>> > using below (also downloadble in plain text from
>> > https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
>> >
>> > #this is an extract of the overall dataset (n=1200 cases)
>> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>> > "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>> > "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>> > "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835,
>> > 3.43806581506388,
>> > 0.002733567617055, 1.42917483425029, 1.05786640463504,
>> > 0.000420548864162308,
>> > 2.37232740842861, 3.01835841813241, 0, 1.13430282139936,
>> > 0.928725667117666,
>> > 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names
>> > =
>> > c(2L,
>> > 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>> >
>> > I need to find a automated procedure that allows me to adjust v3
>> > marginals
>> > while maintaining v1xv2 marginals unchanged.
>> >
>> > That is: modify the v4 values you can find by running:
>> >
>> > aggregate(f1[,c("v4")],list(f1$v3),sum)
>> >
>> > while maintaining costant the values you can find by running:
>> >
>> > aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>> >
>> > Now does it make sense?
>> >
>> > Please notice I have tried to build some syntax that tries to modify
>> > values
>> > within each v1xv2 combination by computing sum of v4, row percentage in
>> > terms of v4, and there is where my effort is blocked. Not really sure
>> > how I
>> > should proceed. Any suggestion?
>> >
>> > Thanks,
>> >
>> > Luca
>> >
>> >
>> > 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>> >
>> >> I don't understand your description. The standard practice on this list
>> >> is
>> >> to provide a reproducible R example [1] of the kind of data you are
>> >> working
>> >> with (and any code you have tried) to go along with your description.
>> >> In
>> >> this case, that would be two dputs of your input data frames and a dput
>> >> of
>> >> an output data frame (generated by hand from your input data frame).
>> >> (Probably best to not use the full number of input values just to keep
>> >> the
>> >> size down.) We could then make an attempt to generate code that goes
>> >> from
>> >> input to output.
>> >>
>> >> Of course, if you post that hard work using HTML then it will get
>> >> corrupted (much like the text below from your earlier emails) and we
>> >> won't
>> >> be able to use it. Please learn to post from your email software using
>> >> plain text when corresponding with this mailing list.
>> >>
>> >> [1]
>> >>
>> >> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> >>
>> >> ---------------------------------------------------------------------------
>> >> Jeff Newmiller                        The     .....       .....  Go
>> >> Live...
>> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> >> Go...
>> >>                                       Live:   OO#.. Dead: OO#..
>> >> Playing
>> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> >> /Software/Embedded Controllers)               .OO#.       .OO#.
>> >> rocks...1k
>> >>
>> >> ---------------------------------------------------------------------------
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>> >> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <lucam1968 at gmail.com>
>> >> wrote:
>> >> >Thanks for you input Michael,
>> >> >
>> >> >The continuous variable I have measures quantities (down to the 3rd
>> >> >decimal level) so unfortunately are not frequencies.
>> >> >
>> >> >Any more specific suggestions on how that could be tackled?
>> >> >
>> >> >Thanks & kind regards,
>> >> >
>> >> >Luca
>> >> >
>> >> >
>> >> >===
>> >> >
>> >> >Michael Friendly wrote:
>> >> >I'm not sure I understand completely what you want to do, but
>> >> >if the data were frequencies, it sounds like task for fitting a
>> >> >loglinear model with the model formula
>> >> >
>> >> >~ V1*V2 + V3
>> >> >
>> >> >On 3/18/2015 2:17 AM, Luca Meyer wrote:
>> >> >>* Hello,
>> >> >*>>* I am facing a quite challenging task (at least to me) and I was
>> >> >wondering
>> >> >*>* if someone could advise how R could assist me to speed the task
>> >> > up.
>> >> >*>>* I am dealing with a dataset with 3 discrete variables and one
>> >> >continuous
>> >> >*>* variable. The discrete variables are:
>> >> >*>>* V1: 8 modalities
>> >> >*>* V2: 13 modalities
>> >> >*>* V3: 13 modalities
>> >> >*>>* The continuous variable V4 is a decimal number always greater
>> >> > than
>> >> >zero in
>> >> >*>* the marginals of each of the 3 variables but it is sometimes equal
>> >> >to zero
>> >> >*>* (and sometimes negative) in the joint tables.
>> >> >*>>* I have got 2 files:
>> >> >*>>* => one with distribution of all possible combinations of V1xV2
>> >> >(some of
>> >> >*>* which are zero or neagtive) and
>> >> >*>* => one with the marginal distribution of V3.
>> >> >*>>* I am trying to build the long and narrow dataset V1xV2xV3 in such
>> >> >a way
>> >> >*>* that each V1xV2 cell does not get modified and V3 fits as closely
>> >> >as
>> >> >*>* possible to its marginal distribution. Does it make sense?
>> >> >*>>* To be even more specific, my 2 input files look like the
>> >> >following.
>> >> >*>>* FILE 1
>> >> >*>* V1,V2,V4
>> >> >*>* A, A, 24.251
>> >> >*>* A, B, 1.065
>> >> >*>* (...)
>> >> >*>* B, C, 0.294
>> >> >*>* B, D, 2.731
>> >> >*>* (...)
>> >> >*>* H, L, 0.345
>> >> >*>* H, M, 0.000
>> >> >*>>* FILE 2
>> >> >*>* V3, V4
>> >> >*>* A, 1.575
>> >> >*>* B, 4.294
>> >> >*>* C, 10.044
>> >> >*>* (...)
>> >> >*>* L, 5.123
>> >> >*>* M, 3.334
>> >> >*>>* What I need to achieve is a file such as the following
>> >> >*>>* FILE 3
>> >> >*>* V1, V2, V3, V4
>> >> >*>* A, A, A, ???
>> >> >*>* A, A, B, ???
>> >> >*>* (...)
>> >> >*>* D, D, E, ???
>> >> >*>* D, D, F, ???
>> >> >*>* (...)
>> >> >*>* H, M, L, ???
>> >> >*>* H, M, M, ???
>> >> >*>>* Please notice that FILE 3 need to be such that if I aggregate on
>> >> >V1+V2 I
>> >> >*>* recover exactly FILE 1 and that if I aggregate on V3 I can recover
>> >> >a file
>> >> >*>* as close as possible to FILE 3 (ideally the same file).
>> >> >*>>* Can anyone suggest how I could do that with R?
>> >> >*>>* Thank you very much indeed for any assistance you are able to
>> >> >provide.
>> >> >*>>* Kind regards,
>> >> >*>>* Luca*
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> >______________________________________________
>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >PLEASE do read the posting guide
>> >> >http://www.R-project.org/posting-guide.html
>> >> >and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From gunter.berton at gene.com  Sat Mar 21 18:13:19 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 21 Mar 2015 10:13:19 -0700
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <CACk-te2CBQXFGJ-Vhr+kpdY6uccbn0Rp286ca+2YvKO=iHUogg@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
	<CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
	<CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>
	<CACk-te2CBQXFGJ-Vhr+kpdY6uccbn0Rp286ca+2YvKO=iHUogg@mail.gmail.com>
Message-ID: <CACk-te0sTVt5pPb9f-ELgTt8L0Bbaz2NCQ9S4ZsB5e122vdYYA@mail.gmail.com>

... or cleaner:

z1 <- with(f1,v4 + z -ave(z,v1,v2,FUN=mean))


Just for curiosity, was this homework? (in which case I should
probably have not provided you an answer -- that is, assuming that I
HAVE provided an answer).

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Mar 21, 2015 at 7:53 AM, Bert Gunter <bgunter at gene.com> wrote:
> z <- rnorm(nrow(f1)) ## or anything you want
> z1 <- f1$v4 + z - with(f1,ave(z,v1,v2,FUN=mean))
>
>
> aggregate(v4~v1,f1,sum)
> aggregate(z1~v1,f1,sum)
> aggregate(v4~v2,f1,sum)
> aggregate(z1~v2,f1,sum)
> aggregate(v4~v3,f1,sum)
> aggregate(z1~v3,f1,sum)
>
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sat, Mar 21, 2015 at 6:49 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
>> Hi Bert,
>>
>> Thank you for your message. I am looking into ave() and tapply() as you
>> suggested but at the same time I have prepared a example of input and output
>> files, just in case you or someone else would like to make an attempt to
>> generate a code that goes from input to output.
>>
>> Please see below or download it from
>> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
>>
>> # this is (an extract of) the INPUT file I have:
>> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>> "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917,
>> 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
>> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names =
>> c(2L,
>> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>>
>> # this is (an extract of) the OUTPUT file I would like to obtain:
>> f2 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>> "B", "B", "B", "C", "C", "C"), v4 = c(17.83529, 3.43806,0.00295, 1.77918,
>> 1.05786, 0.0002, 2.37232, 3.01835, 0, 1.13430, 0.92872,
>> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names =
>> c(2L,
>> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>>
>> # please notice that while the aggregated v4 on v3 has changed ?
>> aggregate(f1[,c("v4")],list(f1$v3),sum)
>> aggregate(f2[,c("v4")],list(f2$v3),sum)
>>
>> # ? the aggregated v4 over v1xv2 has remained unchanged:
>> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>> aggregate(f2[,c("v4")],list(f2$v1,f2$v2),sum)
>>
>> Thank you very much in advance for your assitance.
>>
>> Luca
>>
>> 2015-03-21 13:18 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>>>
>>> 1. Still not sure what you mean, but maybe look at ?ave and ?tapply,
>>> for which ave() is a wrapper.
>>>
>>> 2. You still need to heed the rest of Jeff's advice.
>>>
>>> Cheers,
>>> Bert
>>>
>>> Bert Gunter
>>> Genentech Nonclinical Biostatistics
>>> (650) 467-7374
>>>
>>> "Data is not information. Information is not knowledge. And knowledge
>>> is certainly not wisdom."
>>> Clifford Stoll
>>>
>>>
>>>
>>>
>>> On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
>>> > Hi Jeff & other R-experts,
>>> >
>>> > Thank you for your note. I have tried myself to solve the issue without
>>> > success.
>>> >
>>> > Following your suggestion, I am providing a sample of the dataset I am
>>> > using below (also downloadble in plain text from
>>> > https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
>>> >
>>> > #this is an extract of the overall dataset (n=1200 cases)
>>> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>>> > "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>>> > "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>>> > "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835,
>>> > 3.43806581506388,
>>> > 0.002733567617055, 1.42917483425029, 1.05786640463504,
>>> > 0.000420548864162308,
>>> > 2.37232740842861, 3.01835841813241, 0, 1.13430282139936,
>>> > 0.928725667117666,
>>> > 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names
>>> > =
>>> > c(2L,
>>> > 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>>> >
>>> > I need to find a automated procedure that allows me to adjust v3
>>> > marginals
>>> > while maintaining v1xv2 marginals unchanged.
>>> >
>>> > That is: modify the v4 values you can find by running:
>>> >
>>> > aggregate(f1[,c("v4")],list(f1$v3),sum)
>>> >
>>> > while maintaining costant the values you can find by running:
>>> >
>>> > aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>>> >
>>> > Now does it make sense?
>>> >
>>> > Please notice I have tried to build some syntax that tries to modify
>>> > values
>>> > within each v1xv2 combination by computing sum of v4, row percentage in
>>> > terms of v4, and there is where my effort is blocked. Not really sure
>>> > how I
>>> > should proceed. Any suggestion?
>>> >
>>> > Thanks,
>>> >
>>> > Luca
>>> >
>>> >
>>> > 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>>> >
>>> >> I don't understand your description. The standard practice on this list
>>> >> is
>>> >> to provide a reproducible R example [1] of the kind of data you are
>>> >> working
>>> >> with (and any code you have tried) to go along with your description.
>>> >> In
>>> >> this case, that would be two dputs of your input data frames and a dput
>>> >> of
>>> >> an output data frame (generated by hand from your input data frame).
>>> >> (Probably best to not use the full number of input values just to keep
>>> >> the
>>> >> size down.) We could then make an attempt to generate code that goes
>>> >> from
>>> >> input to output.
>>> >>
>>> >> Of course, if you post that hard work using HTML then it will get
>>> >> corrupted (much like the text below from your earlier emails) and we
>>> >> won't
>>> >> be able to use it. Please learn to post from your email software using
>>> >> plain text when corresponding with this mailing list.
>>> >>
>>> >> [1]
>>> >>
>>> >> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>> >>
>>> >> ---------------------------------------------------------------------------
>>> >> Jeff Newmiller                        The     .....       .....  Go
>>> >> Live...
>>> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> >> Go...
>>> >>                                       Live:   OO#.. Dead: OO#..
>>> >> Playing
>>> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> >> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> >> rocks...1k
>>> >>
>>> >> ---------------------------------------------------------------------------
>>> >> Sent from my phone. Please excuse my brevity.
>>> >>
>>> >> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <lucam1968 at gmail.com>
>>> >> wrote:
>>> >> >Thanks for you input Michael,
>>> >> >
>>> >> >The continuous variable I have measures quantities (down to the 3rd
>>> >> >decimal level) so unfortunately are not frequencies.
>>> >> >
>>> >> >Any more specific suggestions on how that could be tackled?
>>> >> >
>>> >> >Thanks & kind regards,
>>> >> >
>>> >> >Luca
>>> >> >
>>> >> >
>>> >> >===
>>> >> >
>>> >> >Michael Friendly wrote:
>>> >> >I'm not sure I understand completely what you want to do, but
>>> >> >if the data were frequencies, it sounds like task for fitting a
>>> >> >loglinear model with the model formula
>>> >> >
>>> >> >~ V1*V2 + V3
>>> >> >
>>> >> >On 3/18/2015 2:17 AM, Luca Meyer wrote:
>>> >> >>* Hello,
>>> >> >*>>* I am facing a quite challenging task (at least to me) and I was
>>> >> >wondering
>>> >> >*>* if someone could advise how R could assist me to speed the task
>>> >> > up.
>>> >> >*>>* I am dealing with a dataset with 3 discrete variables and one
>>> >> >continuous
>>> >> >*>* variable. The discrete variables are:
>>> >> >*>>* V1: 8 modalities
>>> >> >*>* V2: 13 modalities
>>> >> >*>* V3: 13 modalities
>>> >> >*>>* The continuous variable V4 is a decimal number always greater
>>> >> > than
>>> >> >zero in
>>> >> >*>* the marginals of each of the 3 variables but it is sometimes equal
>>> >> >to zero
>>> >> >*>* (and sometimes negative) in the joint tables.
>>> >> >*>>* I have got 2 files:
>>> >> >*>>* => one with distribution of all possible combinations of V1xV2
>>> >> >(some of
>>> >> >*>* which are zero or neagtive) and
>>> >> >*>* => one with the marginal distribution of V3.
>>> >> >*>>* I am trying to build the long and narrow dataset V1xV2xV3 in such
>>> >> >a way
>>> >> >*>* that each V1xV2 cell does not get modified and V3 fits as closely
>>> >> >as
>>> >> >*>* possible to its marginal distribution. Does it make sense?
>>> >> >*>>* To be even more specific, my 2 input files look like the
>>> >> >following.
>>> >> >*>>* FILE 1
>>> >> >*>* V1,V2,V4
>>> >> >*>* A, A, 24.251
>>> >> >*>* A, B, 1.065
>>> >> >*>* (...)
>>> >> >*>* B, C, 0.294
>>> >> >*>* B, D, 2.731
>>> >> >*>* (...)
>>> >> >*>* H, L, 0.345
>>> >> >*>* H, M, 0.000
>>> >> >*>>* FILE 2
>>> >> >*>* V3, V4
>>> >> >*>* A, 1.575
>>> >> >*>* B, 4.294
>>> >> >*>* C, 10.044
>>> >> >*>* (...)
>>> >> >*>* L, 5.123
>>> >> >*>* M, 3.334
>>> >> >*>>* What I need to achieve is a file such as the following
>>> >> >*>>* FILE 3
>>> >> >*>* V1, V2, V3, V4
>>> >> >*>* A, A, A, ???
>>> >> >*>* A, A, B, ???
>>> >> >*>* (...)
>>> >> >*>* D, D, E, ???
>>> >> >*>* D, D, F, ???
>>> >> >*>* (...)
>>> >> >*>* H, M, L, ???
>>> >> >*>* H, M, M, ???
>>> >> >*>>* Please notice that FILE 3 need to be such that if I aggregate on
>>> >> >V1+V2 I
>>> >> >*>* recover exactly FILE 1 and that if I aggregate on V3 I can recover
>>> >> >a file
>>> >> >*>* as close as possible to FILE 3 (ideally the same file).
>>> >> >*>>* Can anyone suggest how I could do that with R?
>>> >> >*>>* Thank you very much indeed for any assistance you are able to
>>> >> >provide.
>>> >> >*>>* Kind regards,
>>> >> >*>>* Luca*
>>> >> >
>>> >> >       [[alternative HTML version deleted]]
>>> >> >
>>> >> >______________________________________________
>>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> >PLEASE do read the posting guide
>>> >> >http://www.R-project.org/posting-guide.html
>>> >> >and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >>
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>


From dwinsemius at comcast.net  Sat Mar 21 18:43:08 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 21 Mar 2015 10:43:08 -0700
Subject: [R] ordering a boxplot
In-Reply-To: <CAE8g1gPFm__Q8t5wnxusAfmARBB7S55AY2eJAf+GKFfgKvm8-g@mail.gmail.com>
References: <CAE8g1gPFm__Q8t5wnxusAfmARBB7S55AY2eJAf+GKFfgKvm8-g@mail.gmail.com>
Message-ID: <A28475EC-1F5B-4197-B820-4505C22B7E28@comcast.net>


On Mar 20, 2015, at 2:20 PM, Antonio Silva wrote:

> Hello
> 
> I'm using a dataframe (mydata) where row names are sampling points and
> column names are species in a multivariate analysis.
> 
> If I write boxplot(mydata) I'll have boxplots for each species abundance in
> alphabetical order.
> 
> How to get the boxes orderer by the median?
> 
> Usually for this I write
> boxplot(value~category,at=rank(tapply(mydata$value,mydata$category,median)))

I would not have expected that to succeed. The usual approach is to change the order of factor levels before the call to boxplot.


> but for this to work I need a column for the categories and another column
> for the values.

Yes. That is the usual situation. Since you provide no data we cannot tell what is different about your case.

> 
> Thanks in advance, best regards.
> 
> Antonio Olinto
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Sat Mar 21 19:13:01 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 21 Mar 2015 11:13:01 -0700
Subject: [R] ordering a boxplot
In-Reply-To: <CAE8g1gPFm__Q8t5wnxusAfmARBB7S55AY2eJAf+GKFfgKvm8-g@mail.gmail.com>
References: <CAE8g1gPFm__Q8t5wnxusAfmARBB7S55AY2eJAf+GKFfgKvm8-g@mail.gmail.com>
Message-ID: <CAF8bMcYfqZDtBPOfvgnCO3k2uenKhVDqEDfbaQf21k3efp2sCA@mail.gmail.com>

You can use the reorder() function to reorder the grouping vector's
factor levels according to a function of the data in each group.  E.g.,
compare the following two plots:

   d <- data.frame(Response=cos(1:15), Group=rep(c("A","B","C"),c(6,5,4)))
   par(mfrow=c(1,2))
   boxplot(Response ~ Group, data=d)
   boxplot(Response ~ reorder(Group, X=Response, FUN=median), data=d)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Mar 20, 2015 at 2:20 PM, Antonio Silva <aolinto.lst at gmail.com>
wrote:

> Hello
>
> I'm using a dataframe (mydata) where row names are sampling points and
> column names are species in a multivariate analysis.
>
> If I write boxplot(mydata) I'll have boxplots for each species abundance in
> alphabetical order.
>
> How to get the boxes orderer by the median?
>
> Usually for this I write
>
> boxplot(value~category,at=rank(tapply(mydata$value,mydata$category,median)))
> but for this to work I need a column for the categories and another column
> for the values.
>
> Thanks in advance, best regards.
>
> Antonio Olinto
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From aolinto.lst at gmail.com  Sat Mar 21 23:49:01 2015
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Sat, 21 Mar 2015 19:49:01 -0300
Subject: [R] ordering a boxplot
In-Reply-To: <CAF8bMcYfqZDtBPOfvgnCO3k2uenKhVDqEDfbaQf21k3efp2sCA@mail.gmail.com>
References: <CAE8g1gPFm__Q8t5wnxusAfmARBB7S55AY2eJAf+GKFfgKvm8-g@mail.gmail.com>
	<CAF8bMcYfqZDtBPOfvgnCO3k2uenKhVDqEDfbaQf21k3efp2sCA@mail.gmail.com>
Message-ID: <CAE8g1gNtXRBGKHbxvd2sr9vciROzP5u-8+o6WEHzC95bhW3+tg@mail.gmail.com>

Thanks Bill and David

Here goes an example

SP1<-c(9,6,7,8,5,8,7,5,9,7)
SP2<-c(1,3,4,2,4,2,5,3,2,1)
SP3<-c(4,6,7,5,7,8,7,6,5,4)
SP4<-c(5,4,3,5,2,3,4,3,4,2)
mydata<-data.frame(SP1,SP2,SP3,SP4)
rownames(mydata)<-c("ST1","ST2","ST3","ST4","ST5","ST6","ST7","ST8","ST9","ST10")
mydata
boxplot(mydata)

Note that this data frame does not have the format Response ~ Group. In my
real matrix I have up to 40 species.

Is there any way to have the species ordered by their median abundance (or
other parameter?)

The desired order is given by names(sort(apply(mydata,2,median)))

Thanks once more,

Antonio Olinto
Fisheries Institute
Sao Paulo, Brazil

2015-03-21 15:13 GMT-03:00 William Dunlap <wdunlap at tibco.com>:

> You can use the reorder() function to reorder the grouping vector's
> factor levels according to a function of the data in each group.  E.g.,
> compare the following two plots:
>
>    d <- data.frame(Response=cos(1:15), Group=rep(c("A","B","C"),c(6,5,4)))
>    par(mfrow=c(1,2))
>    boxplot(Response ~ Group, data=d)
>    boxplot(Response ~ reorder(Group, X=Response, FUN=median), data=d)
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Mar 20, 2015 at 2:20 PM, Antonio Silva <aolinto.lst at gmail.com>
> wrote:
>
>> Hello
>>
>> I'm using a dataframe (mydata) where row names are sampling points and
>> column names are species in a multivariate analysis.
>>
>> If I write boxplot(mydata) I'll have boxplots for each species abundance
>> in
>> alphabetical order.
>>
>> How to get the boxes orderer by the median?
>>
>> Usually for this I write
>>
>> boxplot(value~category,at=rank(tapply(mydata$value,mydata$category,median)))
>> but for this to work I need a column for the categories and another column
>> for the values.
>>
>> Thanks in advance, best regards.
>>
>> Antonio Olinto
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sun Mar 22 00:04:56 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 21 Mar 2015 19:04:56 -0400
Subject: [R] ordering a boxplot
In-Reply-To: <CAE8g1gNtXRBGKHbxvd2sr9vciROzP5u-8+o6WEHzC95bhW3+tg@mail.gmail.com>
References: <CAE8g1gPFm__Q8t5wnxusAfmARBB7S55AY2eJAf+GKFfgKvm8-g@mail.gmail.com>
	<CAF8bMcYfqZDtBPOfvgnCO3k2uenKhVDqEDfbaQf21k3efp2sCA@mail.gmail.com>
	<CAE8g1gNtXRBGKHbxvd2sr9vciROzP5u-8+o6WEHzC95bhW3+tg@mail.gmail.com>
Message-ID: <787CFEFC-A05F-4101-99C1-896FF4751B8B@utoronto.ca>

There may be more concise ways to do this - but you are 99% there with your approach:
try:

boxplot(mydata[,names(sort(apply(mydata,2,median)))])

B.


On Mar 21, 2015, at 6:49 PM, Antonio Silva <aolinto.lst at gmail.com> wrote:

> Thanks Bill and David
> 
> Here goes an example
> 
> SP1<-c(9,6,7,8,5,8,7,5,9,7)
> SP2<-c(1,3,4,2,4,2,5,3,2,1)
> SP3<-c(4,6,7,5,7,8,7,6,5,4)
> SP4<-c(5,4,3,5,2,3,4,3,4,2)
> mydata<-data.frame(SP1,SP2,SP3,SP4)
> rownames(mydata)<-c("ST1","ST2","ST3","ST4","ST5","ST6","ST7","ST8","ST9","ST10")
> mydata
> boxplot(mydata)
> 
> Note that this data frame does not have the format Response ~ Group. In my
> real matrix I have up to 40 species.
> 
> Is there any way to have the species ordered by their median abundance (or
> other parameter?)
> 
> The desired order is given by names(sort(apply(mydata,2,median)))
> 
> Thanks once more,
> 
> Antonio Olinto
> Fisheries Institute
> Sao Paulo, Brazil
> 
> 2015-03-21 15:13 GMT-03:00 William Dunlap <wdunlap at tibco.com>:
> 
>> You can use the reorder() function to reorder the grouping vector's
>> factor levels according to a function of the data in each group.  E.g.,
>> compare the following two plots:
>> 
>>   d <- data.frame(Response=cos(1:15), Group=rep(c("A","B","C"),c(6,5,4)))
>>   par(mfrow=c(1,2))
>>   boxplot(Response ~ Group, data=d)
>>   boxplot(Response ~ reorder(Group, X=Response, FUN=median), data=d)
>> 
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> On Fri, Mar 20, 2015 at 2:20 PM, Antonio Silva <aolinto.lst at gmail.com>
>> wrote:
>> 
>>> Hello
>>> 
>>> I'm using a dataframe (mydata) where row names are sampling points and
>>> column names are species in a multivariate analysis.
>>> 
>>> If I write boxplot(mydata) I'll have boxplots for each species abundance
>>> in
>>> alphabetical order.
>>> 
>>> How to get the boxes orderer by the median?
>>> 
>>> Usually for this I write
>>> 
>>> boxplot(value~category,at=rank(tapply(mydata$value,mydata$category,median)))
>>> but for this to work I need a column for the categories and another column
>>> for the values.
>>> 
>>> Thanks in advance, best regards.
>>> 
>>> Antonio Olinto
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jmhannon.ucdavis at gmail.com  Sun Mar 22 00:31:41 2015
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Sat, 21 Mar 2015 16:31:41 -0700
Subject: [R] Dealing with NA in "tbl_df"?
Message-ID: <CACdH2Zb8ciGMN8om3ZyTypZZwrCGc88o=4OxiKQOJG-dJ9XWUw@mail.gmail.com>

Greetings.  I was reading through the vignette for "tidy-data" (from the
"tidyr" package) and came across something that puzzled me.

One of the examples in the vignette uses a data set related to tuberculosis,
originally from the World Health Organization, but also available at:

  https://github.com/hadley/tidy-data/blob/master/data/tb.csv

Here's the code:

+++++

> library(dplyr)  #### for tbl_df
> library(tidyr)  #### for gather
> tb <- tbl_df(read.csv("tb.csv", stringsAsFactors=FALSE))

> tb2 <- tb %>%
+     gather(demo, n, -iso2, -year, na.rm=TRUE)

> str(tb2)
Classes ?tbl_df?, ?tbl? and 'data.frame': 35750 obs. of  4 variables:
 $ iso2: chr  "AD" "AD" "AD" "AE" ...
 $ year: int  2005 2006 2008 2006 2007 2008 2007 2005 2006 2007 ...
 $ demo: Factor w/ 20 levels "m04","m514","m014",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ n   : int  0 0 0 0 0 0 0 0 1 0 ...
>

-----

I thought it might be interesting to see how to do this using the "reshape2"
package.  Here's the code for that:

+++++

library(reshape2)

tb2a <- tb %>%
    melt(
        id.vars=c("iso2", "year"),
        variable.name="demo",
        value.name="n",
        na.rm=TRUE)
tb2a <- tbl_df(tb2a)

> str(tb2a)
Classes ?tbl_df?, ?tbl? and 'data.frame': 35750 obs. of  4 variables:
 $ iso2: chr  "AD" "AD" "AD" "AE" ...
 $ year: int  2005 2006 2008 2006 2007 2008 2007 2005 2006 2007 ...
 $ demo: Factor w/ 20 levels "m04","m514","m014",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ n   : int  0 0 0 0 0 0 0 0 1 0 ...
>

-----


The "str" results make it appear that I'm on the right track, but it's always
good to double check:

+++++

> all.equal(tb2, tb2a)
[1] "Rows in x but not y: 34659, 34658, 34656, 34655, 34651, 34650, 34649,
34648, 34647, 34646, 32264[...]Rows in y but not x: 35663, 34658, 34657,
34656, 34655, 34652, 34651, 34650, 34649, 32265, 32264[...]"
>

-----

Hmm.  Not what I'd hoped for, but all the simple, visual tests I did did not
show any differences.  After a little trial and error, I found the place where
the results differ:

+++++

> ROWS <- 2356
> all.equal(tb2[1:ROWS, ], tb2a[1:ROWS, ])
[1] TRUE
> ROWS <- 2357
> all.equal(tb2[1:ROWS, ], tb2a[1:ROWS, ])
[1] "Rows in x but not y: 2357Rows in y but not x: 2357"

-----

OK, let's have a look at the spot where things go off the rails:

+++++

> tb2[2357, ]
Source: local data frame [1 x 4]

  iso2 year demo n
1   NA 1995 m014 0
> tb2a[2357, ]
Source: local data frame [1 x 4]

  iso2 year demo n
1   NA 1995 m014 0
>

-----

Things certainly *look* the same, but:

+++++

> all.equal(tb2[2357, ], tb2a[2357, ])
[1] "Rows in x but not y: 1Rows in y but not x: 1"
>

-----

If you guessed that it's the NA that's the source of the problem, you're
evidently correct:

+++++

> head(which(is.na(tb2[ , "iso2"])))
[1] 2357 2358 2359 2360 2361 2362
>

-----

But I don't understand what the problem is.  The "all.equal" function does
appear to deal appropriately with NA's.  Here's a trivial example:

+++++

> library(pryr)

Attaching package: ?pryr?

The following object is masked from ?package:dplyr?:

    %.%

> foo <- c(3, NA, 7)
> bar <- c(3, NA, 7)
> address(foo)  #### note that foo and bar are distinct objects
[1] "0x422c278"
> address(bar)
[1] "0x4953188"
> all.equal(foo, bar)  #### but they're still equal, even with NA
[1] TRUE
>

-----

And just to be sure, I checked that these really are NA's in foo and bar:

+++++

> any(is.na(foo))
[1] TRUE
> any(is.na(bar))
[1] TRUE
>

-----

It finally occurred to me to strip off the extra class attributes and do the
comparison:

+++++

> all.equal(data.frame(tb2), data.frame(tb2a))
[1] TRUE
>

-----

So this is evidently a "solution" to the problem, but I don't know what the
moral of the story is.  If you have any insights, please pass 'em along.

Thanks.

-- Mike


From boris.steipe at utoronto.ca  Sun Mar 22 01:09:55 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 21 Mar 2015 20:09:55 -0400
Subject: [R] ordering a boxplot
In-Reply-To: <787CFEFC-A05F-4101-99C1-896FF4751B8B@utoronto.ca>
References: <CAE8g1gPFm__Q8t5wnxusAfmARBB7S55AY2eJAf+GKFfgKvm8-g@mail.gmail.com>
	<CAF8bMcYfqZDtBPOfvgnCO3k2uenKhVDqEDfbaQf21k3efp2sCA@mail.gmail.com>
	<CAE8g1gNtXRBGKHbxvd2sr9vciROzP5u-8+o6WEHzC95bhW3+tg@mail.gmail.com>
	<787CFEFC-A05F-4101-99C1-896FF4751B8B@utoronto.ca>
Message-ID: <6999198E-C2B3-406C-9AC4-4DF8E862A9FE@utoronto.ca>

... just for completeness - the more concise way: (no need to go through names()).

boxplot(mydata[,order(apply(mydata,2,median))])

... or descending
boxplot(mydata[,order(-apply(mydata,2,median))])




B.



On Mar 21, 2015, at 7:04 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> There may be more concise ways to do this - but you are 99% there with your approach:
> try:
> 
> boxplot(mydata[,names(sort(apply(mydata,2,median)))])
> 
> B.
> 
> 
> On Mar 21, 2015, at 6:49 PM, Antonio Silva <aolinto.lst at gmail.com> wrote:
> 
>> Thanks Bill and David
>> 
>> Here goes an example
>> 
>> SP1<-c(9,6,7,8,5,8,7,5,9,7)
>> SP2<-c(1,3,4,2,4,2,5,3,2,1)
>> SP3<-c(4,6,7,5,7,8,7,6,5,4)
>> SP4<-c(5,4,3,5,2,3,4,3,4,2)
>> mydata<-data.frame(SP1,SP2,SP3,SP4)
>> rownames(mydata)<-c("ST1","ST2","ST3","ST4","ST5","ST6","ST7","ST8","ST9","ST10")
>> mydata
>> boxplot(mydata)
>> 
>> Note that this data frame does not have the format Response ~ Group. In my
>> real matrix I have up to 40 species.
>> 
>> Is there any way to have the species ordered by their median abundance (or
>> other parameter?)
>> 
>> The desired order is given by names(sort(apply(mydata,2,median)))
>> 
>> Thanks once more,
>> 
>> Antonio Olinto
>> Fisheries Institute
>> Sao Paulo, Brazil
>> 
>> 2015-03-21 15:13 GMT-03:00 William Dunlap <wdunlap at tibco.com>:
>> 
>>> You can use the reorder() function to reorder the grouping vector's
>>> factor levels according to a function of the data in each group.  E.g.,
>>> compare the following two plots:
>>> 
>>>  d <- data.frame(Response=cos(1:15), Group=rep(c("A","B","C"),c(6,5,4)))
>>>  par(mfrow=c(1,2))
>>>  boxplot(Response ~ Group, data=d)
>>>  boxplot(Response ~ reorder(Group, X=Response, FUN=median), data=d)
>>> 
>>> 
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>> 
>>> On Fri, Mar 20, 2015 at 2:20 PM, Antonio Silva <aolinto.lst at gmail.com>
>>> wrote:
>>> 
>>>> Hello
>>>> 
>>>> I'm using a dataframe (mydata) where row names are sampling points and
>>>> column names are species in a multivariate analysis.
>>>> 
>>>> If I write boxplot(mydata) I'll have boxplots for each species abundance
>>>> in
>>>> alphabetical order.
>>>> 
>>>> How to get the boxes orderer by the median?
>>>> 
>>>> Usually for this I write
>>>> 
>>>> boxplot(value~category,at=rank(tapply(mydata$value,mydata$category,median)))
>>>> but for this to work I need a column for the categories and another column
>>>> for the values.
>>>> 
>>>> Thanks in advance, best regards.
>>>> 
>>>> Antonio Olinto
>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From imdb.subscribe at gmail.com  Sat Mar 21 19:19:03 2015
From: imdb.subscribe at gmail.com (im db)
Date: Sat, 21 Mar 2015 18:19:03 +0000 (UTC)
Subject: [R] WG: Questions about neural networks in  RSNNS
In-Reply-To: <mailman.2129.1426954247.3183.r-help@r-project.org>
References: <mailman.2129.1426954247.3183.r-help@r-project.org>
Message-ID: <1998004832.2021482.1426961943927.JavaMail.yahoo@mail.yahoo.com>

 Dear All,I'm using RSNNS package in R, for Elman Neural Network. Now I have some question.s1- How can i set the weight range for the Elman Netwrok in RSNNS Package? At the end my goal is to have activation value range between 0 and 1.2- How can i use Softmax activation function for the elman network?3- Is it possible to add more hidden layers? if yes, how?Thank you in advance. 
	[[alternative HTML version deleted]]


From robertsonburns at btinternet.com  Sat Mar 21 13:10:23 2015
From: robertsonburns at btinternet.com (J Robertson-Burns)
Date: Sat, 21 Mar 2015 12:10:23 +0000
Subject: [R] automatic coercicion
In-Reply-To: <1a8d5bca9250faf20c5f1f735822dc01.squirrel@fiara.math.u-psud.fr>
References: <1a8d5bca9250faf20c5f1f735822dc01.squirrel@fiara.math.u-psud.fr>
Message-ID: <550D5FAF.6080102@btinternet.com>

This is Circle 8.1.44 of 'The R Inferno'.

http://www.burns-stat.com/documents/books/the-r-inferno/

Pat

On 21/03/2015 11:04, Jean.Coursol at math.u-psud.fr wrote:
> My question must be a trivial one.
>
> There is automatic coercicion to vector when extracting only one line of a
> matrix.
> # example
> A = matrix(1:12,3,4)
> rownames(A) = c('a1','a2','a3')
>
> i = 1:2
> A[i,]
> #    [,1] [,2] [,3] [,4]
> # a1    1    4    7   10    matrix
> # a2    2    5    8   11
>
> i = 1
> A[i,]
> # [1]  1  4  7 10           vector !!!
>
> # to get the rowname, it is necessary to do
> rownames(A)[i]
> # [1] "a1"
>
> Is it possible to get a (1,4)-matrix (without testing length(i) ) ? I see
> nothing in options()...
>
> Jean Coursol
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mytekmail at gmail.com  Sat Mar 21 14:45:36 2015
From: mytekmail at gmail.com (brendon wolff-piggott)
Date: Sat, 21 Mar 2015 15:45:36 +0200
Subject: [R] RSQLite will not install in R 2.15.0
Message-ID: <CABOCA2mhZ2odhLkp3-8ZjCzyBWN4_RP_g5RAsLjRPyW+mWoP-Q@mail.gmail.com>

I'm trying to install RSQLite on the way to installing RQDA.  I have
installed DBI, and RSQLite compiles but will not install.

Running  install.packages("RSQLite") fails with the following messages:
...
** preparing package for lazy loading
Error in setClass("SQLiteConnection", contains = "DBIConnection", slots =
list(Id = "externalptr",  :
  unused argument(s) (slots = list(Id = "externalptr", dbname =
"character", loadable.extensions = "logical", flags = "integer", vfs =
"character"))
Error : unable to load R code in package ?RSQLite?
ERROR: lazy loading failed for package ?RSQLite?

	[[alternative HTML version deleted]]


From 06slchen at gmail.com  Sat Mar 21 15:28:11 2015
From: 06slchen at gmail.com (Shenglin Chen)
Date: Sat, 21 Mar 2015 09:28:11 -0500
Subject: [R] UNSUBCRIBE
Message-ID: <CAAzBC_H5X1vZDBBX_jMy_X0rA9s84eN-3HEPGK35yJ_7QH=oPQ@mail.gmail.com>



	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Mar 22 03:29:37 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 21 Mar 2015 19:29:37 -0700
Subject: [R] RSQLite will not install in R 2.15.0
In-Reply-To: <CABOCA2mhZ2odhLkp3-8ZjCzyBWN4_RP_g5RAsLjRPyW+mWoP-Q@mail.gmail.com>
References: <CABOCA2mhZ2odhLkp3-8ZjCzyBWN4_RP_g5RAsLjRPyW+mWoP-Q@mail.gmail.com>
Message-ID: <CED1EC24-45FD-40B0-BBF8-276209C4FAD8@dcn.davis.CA.us>

The posting guide warns you that this list is only for questions regarding the current version of R. You probably need to be sure to use versions of packages that were current as of the time that version of R was current... anything else is a wild ride for you.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 21, 2015 6:45:36 AM PDT, brendon wolff-piggott <mytekmail at gmail.com> wrote:
>I'm trying to install RSQLite on the way to installing RQDA.  I have
>installed DBI, and RSQLite compiles but will not install.
>
>Running  install.packages("RSQLite") fails with the following messages:
>...
>** preparing package for lazy loading
>Error in setClass("SQLiteConnection", contains = "DBIConnection", slots
>=
>list(Id = "externalptr",  :
>  unused argument(s) (slots = list(Id = "externalptr", dbname =
>"character", loadable.extensions = "logical", flags = "integer", vfs =
>"character"))
>Error : unable to load R code in package ?RSQLite?
>ERROR: lazy loading failed for package ?RSQLite?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Sun Mar 22 03:40:15 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 21 Mar 2015 22:40:15 -0400
Subject: [R] automatic coercicion
In-Reply-To: <550D5FAF.6080102@btinternet.com>
References: <1a8d5bca9250faf20c5f1f735822dc01.squirrel@fiara.math.u-psud.fr>
	<550D5FAF.6080102@btinternet.com>
Message-ID: <7061BF3E-CCCA-409B-AD71-0777272954EB@utoronto.ca>

See the help page for the "[" operator ...
?"["

... and use the drop parameter as in:
A[1,,drop=FALSE]

   [,1] [,2] [,3] [,4]
a1    1    4    7   10



B.

On Mar 21, 2015, at 8:10 AM, J Robertson-Burns <robertsonburns at btinternet.com> wrote:

> This is Circle 8.1.44 of 'The R Inferno'.
> 
> http://www.burns-stat.com/documents/books/the-r-inferno/
> 
> Pat
> 
> On 21/03/2015 11:04, Jean.Coursol at math.u-psud.fr wrote:
>> My question must be a trivial one.
>> 
>> There is automatic coercicion to vector when extracting only one line of a
>> matrix.
>> # example
>> A = matrix(1:12,3,4)
>> rownames(A) = c('a1','a2','a3')
>> 
>> i = 1:2
>> A[i,]
>> #    [,1] [,2] [,3] [,4]
>> # a1    1    4    7   10    matrix
>> # a2    2    5    8   11
>> 
>> i = 1
>> A[i,]
>> # [1]  1  4  7 10           vector !!!
>> 
>> # to get the rowname, it is necessary to do
>> rownames(A)[i]
>> # [1] "a1"
>> 
>> Is it possible to get a (1,4)-matrix (without testing length(i) ) ? I see
>> nothing in options()...
>> 
>> Jean Coursol
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wickedpuppy at gmail.com  Sun Mar 22 04:05:57 2015
From: wickedpuppy at gmail.com (billy am)
Date: Sun, 22 Mar 2015 11:05:57 +0800
Subject: [R] RSQLite will not install in R 2.15.0
In-Reply-To: <CED1EC24-45FD-40B0-BBF8-276209C4FAD8@dcn.davis.CA.us>
References: <CABOCA2mhZ2odhLkp3-8ZjCzyBWN4_RP_g5RAsLjRPyW+mWoP-Q@mail.gmail.com>
	<CED1EC24-45FD-40B0-BBF8-276209C4FAD8@dcn.davis.CA.us>
Message-ID: <CAJ_FNV4L=DDhhkdA_UE_Bwys31h-PGWXxxfbHYtzwbuAJ+Z5Mw@mail.gmail.com>

Hi Brendon ,

Pls download and install the latest R version and try again.

> version
               _
platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          3
minor          1.3
year           2015
month          03
day            09
svn rev        67962
language       R
version.string R version 3.1.3 (2015-03-09)
nickname       Smooth Sidewalk
> nstall.packages("RSQLite")
Error: could not find function "nstall.packages"
> install.packages("RSQLite")
Installing package into ?C:/Users/billy/Documents/R/win-library/3.1?
(as ?lib? is unspecified)
trying URL 'http://cran.rstudio.com/bin/windows/contrib/3.1/RSQLite_1.0.0.zip'
Content type 'application/zip' length 1211262 bytes (1.2 MB)
opened URL
downloaded 1.2 MB

package ?RSQLite? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
C:\Users\billy\AppData\Local\Temp\RtmpI7oOTu\downloaded_packages

Regards
Billy

----------------------------------------------------------------------------------
|

http://billyam.com  || http://use-r.com  || http://shinyserver.com (BETA)

SAS Certified Base Programmer for SAS 9
Oracle SQL Expert(11g)



On Sun, Mar 22, 2015 at 10:29 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> The posting guide warns you that this list is only for questions regarding the current version of R. You probably need to be sure to use versions of packages that were current as of the time that version of R was current... anything else is a wild ride for you.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On March 21, 2015 6:45:36 AM PDT, brendon wolff-piggott <mytekmail at gmail.com> wrote:
>>I'm trying to install RSQLite on the way to installing RQDA.  I have
>>installed DBI, and RSQLite compiles but will not install.
>>
>>Running  install.packages("RSQLite") fails with the following messages:
>>...
>>** preparing package for lazy loading
>>Error in setClass("SQLiteConnection", contains = "DBIConnection", slots
>>=
>>list(Id = "externalptr",  :
>>  unused argument(s) (slots = list(Id = "externalptr", dbname =
>>"character", loadable.extensions = "logical", flags = "integer", vfs =
>>"character"))
>>Error : unable to load R code in package ?RSQLite?
>>ERROR: lazy loading failed for package ?RSQLite?
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Mar 22 06:30:43 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 21 Mar 2015 22:30:43 -0700
Subject: [R] UNSUBCRIBE
In-Reply-To: <CAAzBC_H5X1vZDBBX_jMy_X0rA9s84eN-3HEPGK35yJ_7QH=oPQ@mail.gmail.com>
References: <CAAzBC_H5X1vZDBBX_jMy_X0rA9s84eN-3HEPGK35yJ_7QH=oPQ@mail.gmail.com>
Message-ID: <C5B4C97D-8FD4-4A59-9C38-F00C378CECF8@comcast.net>

Nope. Wrong address for an automated efforts at changing subscription preferences, and it would not have worked anyway because you did not provide your password. Most people who started using the Internet in the last 20 years will need to use the web interface at the address in the message footer. If you still want to use the classic manner of communicating with a mail server you need to use this address:

r-help-request at r-project.org

If the subject line is ?help? (without quotes) you should get a message entitled "The results of your email commands?  which you need to follow precisely. (But most people will still fail with this approach.)



> On Mar 21, 2015, at 7:28 AM, Shenglin Chen <06slchen at gmail.com> wrote:
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From lucam1968 at gmail.com  Sun Mar 22 10:00:47 2015
From: lucam1968 at gmail.com (Luca Meyer)
Date: Sun, 22 Mar 2015 10:00:47 +0100
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <CACk-te0sTVt5pPb9f-ELgTt8L0Bbaz2NCQ9S4ZsB5e122vdYYA@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
	<CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
	<CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>
	<CACk-te2CBQXFGJ-Vhr+kpdY6uccbn0Rp286ca+2YvKO=iHUogg@mail.gmail.com>
	<CACk-te0sTVt5pPb9f-ELgTt8L0Bbaz2NCQ9S4ZsB5e122vdYYA@mail.gmail.com>
Message-ID: <CABQyo86dF4UQH94v1Q-rFMBV=JRmwc3V9SFgG=ZiwtGatKTwPg@mail.gmail.com>

Hi Bert, hello R-experts,

I am close to a solution but I still need one hint w.r.t. the following
procedure (available also from
https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0)

rm(list=ls())

# this is (an extract of) the INPUT file I have:
f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B", "B",
"B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A", "B", "C", "A",
"B", "C"), v3 = c("B", "B", "B", "C", "C", "C", "B", "B", "B", "C", "C",
"C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917, 1.05786, 0.00042, 2.37232,
3.01835, 0, 1.13430, 0.92872, 0)), .Names = c("v1", "v2", "v3", "v4"),
class = "data.frame", row.names = c(2L, 9L, 11L, 41L, 48L, 50L, 158L, 165L,
167L, 197L, 204L, 206L))

# this is the procedure that Bert suggested (slightly adjusted):
z <- rnorm(nrow(f1)) ## or anything you want
z1 <- round(with(f1,v4 + z -ave(z,v1,v2,FUN=mean)), digits=5)
aggregate(v4~v1*v2,f1,sum)
aggregate(z1~v1*v2,f1,sum)
aggregate(v4~v3,f1,sum)
aggregate(z1~v3,f1,sum)

My question to you is: how can I set z so that I can obtain specific values
for z1-v4 in the v3 aggregation?
In other words, how can I configure the procedure so that e.g. B=29 and
C=2.56723 after running the procedure:
aggregate(z1~v3,f1,sum)

Thank you,

Luca

PS: to avoid any doubts you might have about who I am the following is my
web page: http://lucameyer.wordpress.com/


2015-03-21 18:13 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:

> ... or cleaner:
>
> z1 <- with(f1,v4 + z -ave(z,v1,v2,FUN=mean))
>
>
> Just for curiosity, was this homework? (in which case I should
> probably have not provided you an answer -- that is, assuming that I
> HAVE provided an answer).
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sat, Mar 21, 2015 at 7:53 AM, Bert Gunter <bgunter at gene.com> wrote:
> > z <- rnorm(nrow(f1)) ## or anything you want
> > z1 <- f1$v4 + z - with(f1,ave(z,v1,v2,FUN=mean))
> >
> >
> > aggregate(v4~v1,f1,sum)
> > aggregate(z1~v1,f1,sum)
> > aggregate(v4~v2,f1,sum)
> > aggregate(z1~v2,f1,sum)
> > aggregate(v4~v3,f1,sum)
> > aggregate(z1~v3,f1,sum)
> >
> >
> > Cheers,
> > Bert
> >
> > Bert Gunter
> > Genentech Nonclinical Biostatistics
> > (650) 467-7374
> >
> > "Data is not information. Information is not knowledge. And knowledge
> > is certainly not wisdom."
> > Clifford Stoll
> >
> >
> >
> >
> > On Sat, Mar 21, 2015 at 6:49 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
> >> Hi Bert,
> >>
> >> Thank you for your message. I am looking into ave() and tapply() as you
> >> suggested but at the same time I have prepared a example of input and
> output
> >> files, just in case you or someone else would like to make an attempt to
> >> generate a code that goes from input to output.
> >>
> >> Please see below or download it from
> >> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
> >>
> >> # this is (an extract of) the INPUT file I have:
> >> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >> "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273,
> 1.42917,
> >> 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> row.names =
> >> c(2L,
> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >>
> >> # this is (an extract of) the OUTPUT file I would like to obtain:
> >> f2 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >> "B", "B", "B", "C", "C", "C"), v4 = c(17.83529, 3.43806,0.00295,
> 1.77918,
> >> 1.05786, 0.0002, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> row.names =
> >> c(2L,
> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >>
> >> # please notice that while the aggregated v4 on v3 has changed ?
> >> aggregate(f1[,c("v4")],list(f1$v3),sum)
> >> aggregate(f2[,c("v4")],list(f2$v3),sum)
> >>
> >> # ? the aggregated v4 over v1xv2 has remained unchanged:
> >> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
> >> aggregate(f2[,c("v4")],list(f2$v1,f2$v2),sum)
> >>
> >> Thank you very much in advance for your assitance.
> >>
> >> Luca
> >>
> >> 2015-03-21 13:18 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
> >>>
> >>> 1. Still not sure what you mean, but maybe look at ?ave and ?tapply,
> >>> for which ave() is a wrapper.
> >>>
> >>> 2. You still need to heed the rest of Jeff's advice.
> >>>
> >>> Cheers,
> >>> Bert
> >>>
> >>> Bert Gunter
> >>> Genentech Nonclinical Biostatistics
> >>> (650) 467-7374
> >>>
> >>> "Data is not information. Information is not knowledge. And knowledge
> >>> is certainly not wisdom."
> >>> Clifford Stoll
> >>>
> >>>
> >>>
> >>>
> >>> On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <lucam1968 at gmail.com>
> wrote:
> >>> > Hi Jeff & other R-experts,
> >>> >
> >>> > Thank you for your note. I have tried myself to solve the issue
> without
> >>> > success.
> >>> >
> >>> > Following your suggestion, I am providing a sample of the dataset I
> am
> >>> > using below (also downloadble in plain text from
> >>> > https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
> >>> >
> >>> > #this is an extract of the overall dataset (n=1200 cases)
> >>> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> >>> > "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >>> > "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >>> > "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835,
> >>> > 3.43806581506388,
> >>> > 0.002733567617055, 1.42917483425029, 1.05786640463504,
> >>> > 0.000420548864162308,
> >>> > 2.37232740842861, 3.01835841813241, 0, 1.13430282139936,
> >>> > 0.928725667117666,
> >>> > 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> row.names
> >>> > =
> >>> > c(2L,
> >>> > 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >>> >
> >>> > I need to find a automated procedure that allows me to adjust v3
> >>> > marginals
> >>> > while maintaining v1xv2 marginals unchanged.
> >>> >
> >>> > That is: modify the v4 values you can find by running:
> >>> >
> >>> > aggregate(f1[,c("v4")],list(f1$v3),sum)
> >>> >
> >>> > while maintaining costant the values you can find by running:
> >>> >
> >>> > aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
> >>> >
> >>> > Now does it make sense?
> >>> >
> >>> > Please notice I have tried to build some syntax that tries to modify
> >>> > values
> >>> > within each v1xv2 combination by computing sum of v4, row percentage
> in
> >>> > terms of v4, and there is where my effort is blocked. Not really sure
> >>> > how I
> >>> > should proceed. Any suggestion?
> >>> >
> >>> > Thanks,
> >>> >
> >>> > Luca
> >>> >
> >>> >
> >>> > 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
> >>> >
> >>> >> I don't understand your description. The standard practice on this
> list
> >>> >> is
> >>> >> to provide a reproducible R example [1] of the kind of data you are
> >>> >> working
> >>> >> with (and any code you have tried) to go along with your
> description.
> >>> >> In
> >>> >> this case, that would be two dputs of your input data frames and a
> dput
> >>> >> of
> >>> >> an output data frame (generated by hand from your input data frame).
> >>> >> (Probably best to not use the full number of input values just to
> keep
> >>> >> the
> >>> >> size down.) We could then make an attempt to generate code that goes
> >>> >> from
> >>> >> input to output.
> >>> >>
> >>> >> Of course, if you post that hard work using HTML then it will get
> >>> >> corrupted (much like the text below from your earlier emails) and we
> >>> >> won't
> >>> >> be able to use it. Please learn to post from your email software
> using
> >>> >> plain text when corresponding with this mailing list.
> >>> >>
> >>> >> [1]
> >>> >>
> >>> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >>> >>
> >>> >>
> ---------------------------------------------------------------------------
> >>> >> Jeff Newmiller                        The     .....       .....  Go
> >>> >> Live...
> >>> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
> Live
> >>> >> Go...
> >>> >>                                       Live:   OO#.. Dead: OO#..
> >>> >> Playing
> >>> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.
> with
> >>> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >>> >> rocks...1k
> >>> >>
> >>> >>
> ---------------------------------------------------------------------------
> >>> >> Sent from my phone. Please excuse my brevity.
> >>> >>
> >>> >> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <lucam1968 at gmail.com>
> >>> >> wrote:
> >>> >> >Thanks for you input Michael,
> >>> >> >
> >>> >> >The continuous variable I have measures quantities (down to the 3rd
> >>> >> >decimal level) so unfortunately are not frequencies.
> >>> >> >
> >>> >> >Any more specific suggestions on how that could be tackled?
> >>> >> >
> >>> >> >Thanks & kind regards,
> >>> >> >
> >>> >> >Luca
> >>> >> >
> >>> >> >
> >>> >> >===
> >>> >> >
> >>> >> >Michael Friendly wrote:
> >>> >> >I'm not sure I understand completely what you want to do, but
> >>> >> >if the data were frequencies, it sounds like task for fitting a
> >>> >> >loglinear model with the model formula
> >>> >> >
> >>> >> >~ V1*V2 + V3
> >>> >> >
> >>> >> >On 3/18/2015 2:17 AM, Luca Meyer wrote:
> >>> >> >>* Hello,
> >>> >> >*>>* I am facing a quite challenging task (at least to me) and I
> was
> >>> >> >wondering
> >>> >> >*>* if someone could advise how R could assist me to speed the task
> >>> >> > up.
> >>> >> >*>>* I am dealing with a dataset with 3 discrete variables and one
> >>> >> >continuous
> >>> >> >*>* variable. The discrete variables are:
> >>> >> >*>>* V1: 8 modalities
> >>> >> >*>* V2: 13 modalities
> >>> >> >*>* V3: 13 modalities
> >>> >> >*>>* The continuous variable V4 is a decimal number always greater
> >>> >> > than
> >>> >> >zero in
> >>> >> >*>* the marginals of each of the 3 variables but it is sometimes
> equal
> >>> >> >to zero
> >>> >> >*>* (and sometimes negative) in the joint tables.
> >>> >> >*>>* I have got 2 files:
> >>> >> >*>>* => one with distribution of all possible combinations of V1xV2
> >>> >> >(some of
> >>> >> >*>* which are zero or neagtive) and
> >>> >> >*>* => one with the marginal distribution of V3.
> >>> >> >*>>* I am trying to build the long and narrow dataset V1xV2xV3 in
> such
> >>> >> >a way
> >>> >> >*>* that each V1xV2 cell does not get modified and V3 fits as
> closely
> >>> >> >as
> >>> >> >*>* possible to its marginal distribution. Does it make sense?
> >>> >> >*>>* To be even more specific, my 2 input files look like the
> >>> >> >following.
> >>> >> >*>>* FILE 1
> >>> >> >*>* V1,V2,V4
> >>> >> >*>* A, A, 24.251
> >>> >> >*>* A, B, 1.065
> >>> >> >*>* (...)
> >>> >> >*>* B, C, 0.294
> >>> >> >*>* B, D, 2.731
> >>> >> >*>* (...)
> >>> >> >*>* H, L, 0.345
> >>> >> >*>* H, M, 0.000
> >>> >> >*>>* FILE 2
> >>> >> >*>* V3, V4
> >>> >> >*>* A, 1.575
> >>> >> >*>* B, 4.294
> >>> >> >*>* C, 10.044
> >>> >> >*>* (...)
> >>> >> >*>* L, 5.123
> >>> >> >*>* M, 3.334
> >>> >> >*>>* What I need to achieve is a file such as the following
> >>> >> >*>>* FILE 3
> >>> >> >*>* V1, V2, V3, V4
> >>> >> >*>* A, A, A, ???
> >>> >> >*>* A, A, B, ???
> >>> >> >*>* (...)
> >>> >> >*>* D, D, E, ???
> >>> >> >*>* D, D, F, ???
> >>> >> >*>* (...)
> >>> >> >*>* H, M, L, ???
> >>> >> >*>* H, M, M, ???
> >>> >> >*>>* Please notice that FILE 3 need to be such that if I aggregate
> on
> >>> >> >V1+V2 I
> >>> >> >*>* recover exactly FILE 1 and that if I aggregate on V3 I can
> recover
> >>> >> >a file
> >>> >> >*>* as close as possible to FILE 3 (ideally the same file).
> >>> >> >*>>* Can anyone suggest how I could do that with R?
> >>> >> >*>>* Thank you very much indeed for any assistance you are able to
> >>> >> >provide.
> >>> >> >*>>* Kind regards,
> >>> >> >*>>* Luca*
> >>> >> >
> >>> >> >       [[alternative HTML version deleted]]
> >>> >> >
> >>> >> >______________________________________________
> >>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >> >PLEASE do read the posting guide
> >>> >> >http://www.R-project.org/posting-guide.html
> >>> >> >and provide commented, minimal, self-contained, reproducible code.
> >>> >>
> >>> >>
> >>> >
> >>> >         [[alternative HTML version deleted]]
> >>> >
> >>> > ______________________________________________
> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > PLEASE do read the posting guide
> >>> > http://www.R-project.org/posting-guide.html
> >>> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
>

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sun Mar 22 15:55:14 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 22 Mar 2015 07:55:14 -0700
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <CABQyo86dF4UQH94v1Q-rFMBV=JRmwc3V9SFgG=ZiwtGatKTwPg@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
	<CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
	<CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>
	<CACk-te2CBQXFGJ-Vhr+kpdY6uccbn0Rp286ca+2YvKO=iHUogg@mail.gmail.com>
	<CACk-te0sTVt5pPb9f-ELgTt8L0Bbaz2NCQ9S4ZsB5e122vdYYA@mail.gmail.com>
	<CABQyo86dF4UQH94v1Q-rFMBV=JRmwc3V9SFgG=ZiwtGatKTwPg@mail.gmail.com>
Message-ID: <CACk-te3xkirW755s1WSETEEj0wvS=d=FneZw4r=dS=jK3RHNcQ@mail.gmail.com>

I would have thought that this is straightforward given my previous email...

Just set z to what you want -- e,g, all B values to 29/number of B's,
and all C values to 2.567/number of C's (etc. for more categories).

A slick but sort of cheat way to do this programmatically -- in the
sense that it relies on the implementation of factor() rather than its
API -- is:

y <- f1$v3  ## to simplify the notation; could be done using with()
z <- (c(29,2.567)/table(y))[c(y)]

Then proceed to z1 as I previously described

-- Bert


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Mar 22, 2015 at 2:00 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
> Hi Bert, hello R-experts,
>
> I am close to a solution but I still need one hint w.r.t. the following
> procedure (available also from
> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0)
>
> rm(list=ls())
>
> # this is (an extract of) the INPUT file I have:
> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B", "B",
> "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A", "B", "C", "A",
> "B", "C"), v3 = c("B", "B", "B", "C", "C", "C", "B", "B", "B", "C", "C",
> "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917, 1.05786, 0.00042, 2.37232,
> 3.01835, 0, 1.13430, 0.92872, 0)), .Names = c("v1", "v2", "v3", "v4"), class
> = "data.frame", row.names = c(2L, 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L,
> 197L, 204L, 206L))
>
> # this is the procedure that Bert suggested (slightly adjusted):
> z <- rnorm(nrow(f1)) ## or anything you want
> z1 <- round(with(f1,v4 + z -ave(z,v1,v2,FUN=mean)), digits=5)
> aggregate(v4~v1*v2,f1,sum)
> aggregate(z1~v1*v2,f1,sum)
> aggregate(v4~v3,f1,sum)
> aggregate(z1~v3,f1,sum)
>
> My question to you is: how can I set z so that I can obtain specific values
> for z1-v4 in the v3 aggregation?
> In other words, how can I configure the procedure so that e.g. B=29 and
> C=2.56723 after running the procedure:
> aggregate(z1~v3,f1,sum)
>
> Thank you,
>
> Luca
>
> PS: to avoid any doubts you might have about who I am the following is my
> web page: http://lucameyer.wordpress.com/
>
>
> 2015-03-21 18:13 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>>
>> ... or cleaner:
>>
>> z1 <- with(f1,v4 + z -ave(z,v1,v2,FUN=mean))
>>
>>
>> Just for curiosity, was this homework? (in which case I should
>> probably have not provided you an answer -- that is, assuming that I
>> HAVE provided an answer).
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Sat, Mar 21, 2015 at 7:53 AM, Bert Gunter <bgunter at gene.com> wrote:
>> > z <- rnorm(nrow(f1)) ## or anything you want
>> > z1 <- f1$v4 + z - with(f1,ave(z,v1,v2,FUN=mean))
>> >
>> >
>> > aggregate(v4~v1,f1,sum)
>> > aggregate(z1~v1,f1,sum)
>> > aggregate(v4~v2,f1,sum)
>> > aggregate(z1~v2,f1,sum)
>> > aggregate(v4~v3,f1,sum)
>> > aggregate(z1~v3,f1,sum)
>> >
>> >
>> > Cheers,
>> > Bert
>> >
>> > Bert Gunter
>> > Genentech Nonclinical Biostatistics
>> > (650) 467-7374
>> >
>> > "Data is not information. Information is not knowledge. And knowledge
>> > is certainly not wisdom."
>> > Clifford Stoll
>> >
>> >
>> >
>> >
>> > On Sat, Mar 21, 2015 at 6:49 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
>> >> Hi Bert,
>> >>
>> >> Thank you for your message. I am looking into ave() and tapply() as you
>> >> suggested but at the same time I have prepared a example of input and
>> >> output
>> >> files, just in case you or someone else would like to make an attempt
>> >> to
>> >> generate a code that goes from input to output.
>> >>
>> >> Please see below or download it from
>> >> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
>> >>
>> >> # this is (an extract of) the INPUT file I have:
>> >> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>> >> "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273,
>> >> 1.42917,
>> >> 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
>> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>> >> row.names =
>> >> c(2L,
>> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>> >>
>> >> # this is (an extract of) the OUTPUT file I would like to obtain:
>> >> f2 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>> >> "B", "B", "B", "C", "C", "C"), v4 = c(17.83529, 3.43806,0.00295,
>> >> 1.77918,
>> >> 1.05786, 0.0002, 2.37232, 3.01835, 0, 1.13430, 0.92872,
>> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>> >> row.names =
>> >> c(2L,
>> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>> >>
>> >> # please notice that while the aggregated v4 on v3 has changed ?
>> >> aggregate(f1[,c("v4")],list(f1$v3),sum)
>> >> aggregate(f2[,c("v4")],list(f2$v3),sum)
>> >>
>> >> # ? the aggregated v4 over v1xv2 has remained unchanged:
>> >> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>> >> aggregate(f2[,c("v4")],list(f2$v1,f2$v2),sum)
>> >>
>> >> Thank you very much in advance for your assitance.
>> >>
>> >> Luca
>> >>
>> >> 2015-03-21 13:18 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>> >>>
>> >>> 1. Still not sure what you mean, but maybe look at ?ave and ?tapply,
>> >>> for which ave() is a wrapper.
>> >>>
>> >>> 2. You still need to heed the rest of Jeff's advice.
>> >>>
>> >>> Cheers,
>> >>> Bert
>> >>>
>> >>> Bert Gunter
>> >>> Genentech Nonclinical Biostatistics
>> >>> (650) 467-7374
>> >>>
>> >>> "Data is not information. Information is not knowledge. And knowledge
>> >>> is certainly not wisdom."
>> >>> Clifford Stoll
>> >>>
>> >>>
>> >>>
>> >>>
>> >>> On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <lucam1968 at gmail.com>
>> >>> wrote:
>> >>> > Hi Jeff & other R-experts,
>> >>> >
>> >>> > Thank you for your note. I have tried myself to solve the issue
>> >>> > without
>> >>> > success.
>> >>> >
>> >>> > Following your suggestion, I am providing a sample of the dataset I
>> >>> > am
>> >>> > using below (also downloadble in plain text from
>> >>> > https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
>> >>> >
>> >>> > #this is an extract of the overall dataset (n=1200 cases)
>> >>> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>> >>> > "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>> >>> > "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>> >>> > "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835,
>> >>> > 3.43806581506388,
>> >>> > 0.002733567617055, 1.42917483425029, 1.05786640463504,
>> >>> > 0.000420548864162308,
>> >>> > 2.37232740842861, 3.01835841813241, 0, 1.13430282139936,
>> >>> > 0.928725667117666,
>> >>> > 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>> >>> > row.names
>> >>> > =
>> >>> > c(2L,
>> >>> > 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>> >>> >
>> >>> > I need to find a automated procedure that allows me to adjust v3
>> >>> > marginals
>> >>> > while maintaining v1xv2 marginals unchanged.
>> >>> >
>> >>> > That is: modify the v4 values you can find by running:
>> >>> >
>> >>> > aggregate(f1[,c("v4")],list(f1$v3),sum)
>> >>> >
>> >>> > while maintaining costant the values you can find by running:
>> >>> >
>> >>> > aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>> >>> >
>> >>> > Now does it make sense?
>> >>> >
>> >>> > Please notice I have tried to build some syntax that tries to modify
>> >>> > values
>> >>> > within each v1xv2 combination by computing sum of v4, row percentage
>> >>> > in
>> >>> > terms of v4, and there is where my effort is blocked. Not really
>> >>> > sure
>> >>> > how I
>> >>> > should proceed. Any suggestion?
>> >>> >
>> >>> > Thanks,
>> >>> >
>> >>> > Luca
>> >>> >
>> >>> >
>> >>> > 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>> >>> >
>> >>> >> I don't understand your description. The standard practice on this
>> >>> >> list
>> >>> >> is
>> >>> >> to provide a reproducible R example [1] of the kind of data you are
>> >>> >> working
>> >>> >> with (and any code you have tried) to go along with your
>> >>> >> description.
>> >>> >> In
>> >>> >> this case, that would be two dputs of your input data frames and a
>> >>> >> dput
>> >>> >> of
>> >>> >> an output data frame (generated by hand from your input data
>> >>> >> frame).
>> >>> >> (Probably best to not use the full number of input values just to
>> >>> >> keep
>> >>> >> the
>> >>> >> size down.) We could then make an attempt to generate code that
>> >>> >> goes
>> >>> >> from
>> >>> >> input to output.
>> >>> >>
>> >>> >> Of course, if you post that hard work using HTML then it will get
>> >>> >> corrupted (much like the text below from your earlier emails) and
>> >>> >> we
>> >>> >> won't
>> >>> >> be able to use it. Please learn to post from your email software
>> >>> >> using
>> >>> >> plain text when corresponding with this mailing list.
>> >>> >>
>> >>> >> [1]
>> >>> >>
>> >>> >>
>> >>> >> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> >>> >>
>> >>> >>
>> >>> >> ---------------------------------------------------------------------------
>> >>> >> Jeff Newmiller                        The     .....       .....  Go
>> >>> >> Live...
>> >>> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
>> >>> >> Live
>> >>> >> Go...
>> >>> >>                                       Live:   OO#.. Dead: OO#..
>> >>> >> Playing
>> >>> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.
>> >>> >> with
>> >>> >> /Software/Embedded Controllers)               .OO#.       .OO#.
>> >>> >> rocks...1k
>> >>> >>
>> >>> >>
>> >>> >> ---------------------------------------------------------------------------
>> >>> >> Sent from my phone. Please excuse my brevity.
>> >>> >>
>> >>> >> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <lucam1968 at gmail.com>
>> >>> >> wrote:
>> >>> >> >Thanks for you input Michael,
>> >>> >> >
>> >>> >> >The continuous variable I have measures quantities (down to the
>> >>> >> > 3rd
>> >>> >> >decimal level) so unfortunately are not frequencies.
>> >>> >> >
>> >>> >> >Any more specific suggestions on how that could be tackled?
>> >>> >> >
>> >>> >> >Thanks & kind regards,
>> >>> >> >
>> >>> >> >Luca
>> >>> >> >
>> >>> >> >
>> >>> >> >===
>> >>> >> >
>> >>> >> >Michael Friendly wrote:
>> >>> >> >I'm not sure I understand completely what you want to do, but
>> >>> >> >if the data were frequencies, it sounds like task for fitting a
>> >>> >> >loglinear model with the model formula
>> >>> >> >
>> >>> >> >~ V1*V2 + V3
>> >>> >> >
>> >>> >> >On 3/18/2015 2:17 AM, Luca Meyer wrote:
>> >>> >> >>* Hello,
>> >>> >> >*>>* I am facing a quite challenging task (at least to me) and I
>> >>> >> > was
>> >>> >> >wondering
>> >>> >> >*>* if someone could advise how R could assist me to speed the
>> >>> >> > task
>> >>> >> > up.
>> >>> >> >*>>* I am dealing with a dataset with 3 discrete variables and one
>> >>> >> >continuous
>> >>> >> >*>* variable. The discrete variables are:
>> >>> >> >*>>* V1: 8 modalities
>> >>> >> >*>* V2: 13 modalities
>> >>> >> >*>* V3: 13 modalities
>> >>> >> >*>>* The continuous variable V4 is a decimal number always greater
>> >>> >> > than
>> >>> >> >zero in
>> >>> >> >*>* the marginals of each of the 3 variables but it is sometimes
>> >>> >> > equal
>> >>> >> >to zero
>> >>> >> >*>* (and sometimes negative) in the joint tables.
>> >>> >> >*>>* I have got 2 files:
>> >>> >> >*>>* => one with distribution of all possible combinations of
>> >>> >> > V1xV2
>> >>> >> >(some of
>> >>> >> >*>* which are zero or neagtive) and
>> >>> >> >*>* => one with the marginal distribution of V3.
>> >>> >> >*>>* I am trying to build the long and narrow dataset V1xV2xV3 in
>> >>> >> > such
>> >>> >> >a way
>> >>> >> >*>* that each V1xV2 cell does not get modified and V3 fits as
>> >>> >> > closely
>> >>> >> >as
>> >>> >> >*>* possible to its marginal distribution. Does it make sense?
>> >>> >> >*>>* To be even more specific, my 2 input files look like the
>> >>> >> >following.
>> >>> >> >*>>* FILE 1
>> >>> >> >*>* V1,V2,V4
>> >>> >> >*>* A, A, 24.251
>> >>> >> >*>* A, B, 1.065
>> >>> >> >*>* (...)
>> >>> >> >*>* B, C, 0.294
>> >>> >> >*>* B, D, 2.731
>> >>> >> >*>* (...)
>> >>> >> >*>* H, L, 0.345
>> >>> >> >*>* H, M, 0.000
>> >>> >> >*>>* FILE 2
>> >>> >> >*>* V3, V4
>> >>> >> >*>* A, 1.575
>> >>> >> >*>* B, 4.294
>> >>> >> >*>* C, 10.044
>> >>> >> >*>* (...)
>> >>> >> >*>* L, 5.123
>> >>> >> >*>* M, 3.334
>> >>> >> >*>>* What I need to achieve is a file such as the following
>> >>> >> >*>>* FILE 3
>> >>> >> >*>* V1, V2, V3, V4
>> >>> >> >*>* A, A, A, ???
>> >>> >> >*>* A, A, B, ???
>> >>> >> >*>* (...)
>> >>> >> >*>* D, D, E, ???
>> >>> >> >*>* D, D, F, ???
>> >>> >> >*>* (...)
>> >>> >> >*>* H, M, L, ???
>> >>> >> >*>* H, M, M, ???
>> >>> >> >*>>* Please notice that FILE 3 need to be such that if I aggregate
>> >>> >> > on
>> >>> >> >V1+V2 I
>> >>> >> >*>* recover exactly FILE 1 and that if I aggregate on V3 I can
>> >>> >> > recover
>> >>> >> >a file
>> >>> >> >*>* as close as possible to FILE 3 (ideally the same file).
>> >>> >> >*>>* Can anyone suggest how I could do that with R?
>> >>> >> >*>>* Thank you very much indeed for any assistance you are able to
>> >>> >> >provide.
>> >>> >> >*>>* Kind regards,
>> >>> >> >*>>* Luca*
>> >>> >> >
>> >>> >> >       [[alternative HTML version deleted]]
>> >>> >> >
>> >>> >> >______________________________________________
>> >>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> >> >PLEASE do read the posting guide
>> >>> >> >http://www.R-project.org/posting-guide.html
>> >>> >> >and provide commented, minimal, self-contained, reproducible code.
>> >>> >>
>> >>> >>
>> >>> >
>> >>> >         [[alternative HTML version deleted]]
>> >>> >
>> >>> > ______________________________________________
>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> > PLEASE do read the posting guide
>> >>> > http://www.R-project.org/posting-guide.html
>> >>> > and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>
>


From yoursurrogategod at gmail.com  Sun Mar 22 15:39:03 2015
From: yoursurrogategod at gmail.com (Yves S. Garret)
Date: Sun, 22 Mar 2015 10:39:03 -0400
Subject: [R] Why can't I access this type?
Message-ID: <CAJ=2b04qLmoA8W--=dsv2vqMHkG1Y7Tv_QQx_9D78oopJku+Yg@mail.gmail.com>

Hi, I'm just learning my way around R.  I got a bunch of states and would
like to access to get all of the ones where it's cold.  But when I do the
following, I will get the following error:

> all.states <- as.data.frame(state.x77)
> cold.states <- all.states[all.states$Frost > 150, c("Name", "Frost")]
Error in `[.data.frame`(all.states, all.states$Frost > 150, c("Name",  :
  undefined columns selected

I don't get it.  When I look at all.states, this is what I see:

> str(all.states)
'data.frame':   50 obs. of  8 variables:
 $ Population: num  3615 365 2212 2110 21198 ...
 $ Income    : num  3624 6315 4530 3378 5114 ...
 $ Illiteracy: num  2.1 1.5 1.8 1.9 1.1 0.7 1.1 0.9 1.3 2 ...
 $ Life Exp  : num  69 69.3 70.5 70.7 71.7 ...
 $ Murder    : num  15.1 11.3 7.8 10.1 10.3 6.8 3.1 6.2 10.7 13.9 ...
 $ HS Grad   : num  41.3 66.7 58.1 39.9 62.6 63.9 56 54.6 52.6 40.6 ...
 $ Frost     : num  20 152 15 65 20 166 139 103 11 60 ...
 $ Area      : num  50708 566432 113417 51945 156361 ...

What am I messing up?

	[[alternative HTML version deleted]]


From adeela.uaf at gmail.com  Sun Mar 22 10:11:29 2015
From: adeela.uaf at gmail.com (adeela uaf)
Date: Sun, 22 Mar 2015 14:11:29 +0500
Subject: [R] My R stopped working
In-Reply-To: <CABGg3O6ptTPTjWkMD9UyJdtCs=eZf_VhS15bNf2CA_gNCS57Bg@mail.gmail.com>
References: <CABGg3O6ptTPTjWkMD9UyJdtCs=eZf_VhS15bNf2CA_gNCS57Bg@mail.gmail.com>
Message-ID: <CABGg3O5ToUPWnp-8v-rpACAaOcQZ_78uyig_ZDmLLnMnfCTPNQ@mail.gmail.com>

Hi,
I was downloading some shape files in R then I use the package lsmeans in R
but I received the message "R for winfows GUI front end has stopped working
" . What I have to do to overcome this problem

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Sun Mar 22 15:11:09 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Sun, 22 Mar 2015 14:11:09 +0000 (GMT)
Subject: [R] Package build help - thanks
Message-ID: <21e15fca-bc9a-4985-9f2e-d63e689bc7eb@me.com>

Hello All,

I have finally addressed all the cmd issues with my package build "bondlab." ?I would like to thank everyone that took the time to answer my questions. ?I have the following question: ?Currently the package has a non-standard directory/folder structure. ?The non-standard folders are listed below. ?I use connections to open and close directories during an analysis run. ?I don't think having these directories in the bondlab directory is a long term viable option as the number of mortgage and REMIC cusips is well over 2 million. ?My question is two parts:

First part, what do you believe is the best way to store these objects as blobs (everything is serialized) in a database or in a folder?structure?residing on the local machine.
In the event I first start with a folder structure on a local machine. ?Is it possible to?instruct R to create the directory and move the examples to the appropriate folder? ?For example, could I create a folder data and then move each of the below folders to data and on install move the "data folders"?to say a bondlabdata folder?
Best Regards,
Glenn

Non Standard Folders are below
BondData - bond objects (S4) identified by cusip with structural information: coupon, payment dates, etc...
Groups - collateral group data: (S4) identifies the underlying collateral group of a mortgage REMIC
PrepaymentModel - S4 object which holds mortgage prepayment model tuning parameters
RatesData - holds swap rate curve history
RDME - REMIC Disclosure Month End (S4): updated REMIC information?
REMICData - REMIC structures (S4)?
Scenario - Interest rate scenarios (S4) for total return analysis
Schedules - structure elements (S4) for REMIC (PAC Schedules, etc)
Tranches - Tranches for REMIC structure tool (S4)
Waterfall - source - cash allocation rules for REMIC cash flow



From gunter.berton at gene.com  Sun Mar 22 16:05:42 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 22 Mar 2015 08:05:42 -0700
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <CACk-te3xkirW755s1WSETEEj0wvS=d=FneZw4r=dS=jK3RHNcQ@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
	<CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
	<CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>
	<CACk-te2CBQXFGJ-Vhr+kpdY6uccbn0Rp286ca+2YvKO=iHUogg@mail.gmail.com>
	<CACk-te0sTVt5pPb9f-ELgTt8L0Bbaz2NCQ9S4ZsB5e122vdYYA@mail.gmail.com>
	<CABQyo86dF4UQH94v1Q-rFMBV=JRmwc3V9SFgG=ZiwtGatKTwPg@mail.gmail.com>
	<CACk-te3xkirW755s1WSETEEj0wvS=d=FneZw4r=dS=jK3RHNcQ@mail.gmail.com>
Message-ID: <CACk-te22ZaM5p5H7Wz1ivN24S5zog-FY=AvdHQEbdz2O7AL2gA@mail.gmail.com>

Oh, wait a minute ...

You still want the marginals for the other columns to be as originally?

If so, then this is impossible in general as the sum of all the values
must be what they were originally and you cannot therefore choose your
values for V3 arbitrarily.

Or at least, that seems to be what you are trying to do.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Mar 22, 2015 at 7:55 AM, Bert Gunter <bgunter at gene.com> wrote:
> I would have thought that this is straightforward given my previous email...
>
> Just set z to what you want -- e,g, all B values to 29/number of B's,
> and all C values to 2.567/number of C's (etc. for more categories).
>
> A slick but sort of cheat way to do this programmatically -- in the
> sense that it relies on the implementation of factor() rather than its
> API -- is:
>
> y <- f1$v3  ## to simplify the notation; could be done using with()
> z <- (c(29,2.567)/table(y))[c(y)]
>
> Then proceed to z1 as I previously described
>
> -- Bert
>
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sun, Mar 22, 2015 at 2:00 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
>> Hi Bert, hello R-experts,
>>
>> I am close to a solution but I still need one hint w.r.t. the following
>> procedure (available also from
>> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0)
>>
>> rm(list=ls())
>>
>> # this is (an extract of) the INPUT file I have:
>> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B", "B",
>> "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A", "B", "C", "A",
>> "B", "C"), v3 = c("B", "B", "B", "C", "C", "C", "B", "B", "B", "C", "C",
>> "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917, 1.05786, 0.00042, 2.37232,
>> 3.01835, 0, 1.13430, 0.92872, 0)), .Names = c("v1", "v2", "v3", "v4"), class
>> = "data.frame", row.names = c(2L, 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L,
>> 197L, 204L, 206L))
>>
>> # this is the procedure that Bert suggested (slightly adjusted):
>> z <- rnorm(nrow(f1)) ## or anything you want
>> z1 <- round(with(f1,v4 + z -ave(z,v1,v2,FUN=mean)), digits=5)
>> aggregate(v4~v1*v2,f1,sum)
>> aggregate(z1~v1*v2,f1,sum)
>> aggregate(v4~v3,f1,sum)
>> aggregate(z1~v3,f1,sum)
>>
>> My question to you is: how can I set z so that I can obtain specific values
>> for z1-v4 in the v3 aggregation?
>> In other words, how can I configure the procedure so that e.g. B=29 and
>> C=2.56723 after running the procedure:
>> aggregate(z1~v3,f1,sum)
>>
>> Thank you,
>>
>> Luca
>>
>> PS: to avoid any doubts you might have about who I am the following is my
>> web page: http://lucameyer.wordpress.com/
>>
>>
>> 2015-03-21 18:13 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>>>
>>> ... or cleaner:
>>>
>>> z1 <- with(f1,v4 + z -ave(z,v1,v2,FUN=mean))
>>>
>>>
>>> Just for curiosity, was this homework? (in which case I should
>>> probably have not provided you an answer -- that is, assuming that I
>>> HAVE provided an answer).
>>>
>>> Cheers,
>>> Bert
>>>
>>> Bert Gunter
>>> Genentech Nonclinical Biostatistics
>>> (650) 467-7374
>>>
>>> "Data is not information. Information is not knowledge. And knowledge
>>> is certainly not wisdom."
>>> Clifford Stoll
>>>
>>>
>>>
>>>
>>> On Sat, Mar 21, 2015 at 7:53 AM, Bert Gunter <bgunter at gene.com> wrote:
>>> > z <- rnorm(nrow(f1)) ## or anything you want
>>> > z1 <- f1$v4 + z - with(f1,ave(z,v1,v2,FUN=mean))
>>> >
>>> >
>>> > aggregate(v4~v1,f1,sum)
>>> > aggregate(z1~v1,f1,sum)
>>> > aggregate(v4~v2,f1,sum)
>>> > aggregate(z1~v2,f1,sum)
>>> > aggregate(v4~v3,f1,sum)
>>> > aggregate(z1~v3,f1,sum)
>>> >
>>> >
>>> > Cheers,
>>> > Bert
>>> >
>>> > Bert Gunter
>>> > Genentech Nonclinical Biostatistics
>>> > (650) 467-7374
>>> >
>>> > "Data is not information. Information is not knowledge. And knowledge
>>> > is certainly not wisdom."
>>> > Clifford Stoll
>>> >
>>> >
>>> >
>>> >
>>> > On Sat, Mar 21, 2015 at 6:49 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
>>> >> Hi Bert,
>>> >>
>>> >> Thank you for your message. I am looking into ave() and tapply() as you
>>> >> suggested but at the same time I have prepared a example of input and
>>> >> output
>>> >> files, just in case you or someone else would like to make an attempt
>>> >> to
>>> >> generate a code that goes from input to output.
>>> >>
>>> >> Please see below or download it from
>>> >> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
>>> >>
>>> >> # this is (an extract of) the INPUT file I have:
>>> >> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>>> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>>> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>>> >> "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273,
>>> >> 1.42917,
>>> >> 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
>>> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>>> >> row.names =
>>> >> c(2L,
>>> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>>> >>
>>> >> # this is (an extract of) the OUTPUT file I would like to obtain:
>>> >> f2 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>>> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>>> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>>> >> "B", "B", "B", "C", "C", "C"), v4 = c(17.83529, 3.43806,0.00295,
>>> >> 1.77918,
>>> >> 1.05786, 0.0002, 2.37232, 3.01835, 0, 1.13430, 0.92872,
>>> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>>> >> row.names =
>>> >> c(2L,
>>> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>>> >>
>>> >> # please notice that while the aggregated v4 on v3 has changed ?
>>> >> aggregate(f1[,c("v4")],list(f1$v3),sum)
>>> >> aggregate(f2[,c("v4")],list(f2$v3),sum)
>>> >>
>>> >> # ? the aggregated v4 over v1xv2 has remained unchanged:
>>> >> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>>> >> aggregate(f2[,c("v4")],list(f2$v1,f2$v2),sum)
>>> >>
>>> >> Thank you very much in advance for your assitance.
>>> >>
>>> >> Luca
>>> >>
>>> >> 2015-03-21 13:18 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>>> >>>
>>> >>> 1. Still not sure what you mean, but maybe look at ?ave and ?tapply,
>>> >>> for which ave() is a wrapper.
>>> >>>
>>> >>> 2. You still need to heed the rest of Jeff's advice.
>>> >>>
>>> >>> Cheers,
>>> >>> Bert
>>> >>>
>>> >>> Bert Gunter
>>> >>> Genentech Nonclinical Biostatistics
>>> >>> (650) 467-7374
>>> >>>
>>> >>> "Data is not information. Information is not knowledge. And knowledge
>>> >>> is certainly not wisdom."
>>> >>> Clifford Stoll
>>> >>>
>>> >>>
>>> >>>
>>> >>>
>>> >>> On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <lucam1968 at gmail.com>
>>> >>> wrote:
>>> >>> > Hi Jeff & other R-experts,
>>> >>> >
>>> >>> > Thank you for your note. I have tried myself to solve the issue
>>> >>> > without
>>> >>> > success.
>>> >>> >
>>> >>> > Following your suggestion, I am providing a sample of the dataset I
>>> >>> > am
>>> >>> > using below (also downloadble in plain text from
>>> >>> > https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
>>> >>> >
>>> >>> > #this is an extract of the overall dataset (n=1200 cases)
>>> >>> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>>> >>> > "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>>> >>> > "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>>> >>> > "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835,
>>> >>> > 3.43806581506388,
>>> >>> > 0.002733567617055, 1.42917483425029, 1.05786640463504,
>>> >>> > 0.000420548864162308,
>>> >>> > 2.37232740842861, 3.01835841813241, 0, 1.13430282139936,
>>> >>> > 0.928725667117666,
>>> >>> > 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>>> >>> > row.names
>>> >>> > =
>>> >>> > c(2L,
>>> >>> > 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>>> >>> >
>>> >>> > I need to find a automated procedure that allows me to adjust v3
>>> >>> > marginals
>>> >>> > while maintaining v1xv2 marginals unchanged.
>>> >>> >
>>> >>> > That is: modify the v4 values you can find by running:
>>> >>> >
>>> >>> > aggregate(f1[,c("v4")],list(f1$v3),sum)
>>> >>> >
>>> >>> > while maintaining costant the values you can find by running:
>>> >>> >
>>> >>> > aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>>> >>> >
>>> >>> > Now does it make sense?
>>> >>> >
>>> >>> > Please notice I have tried to build some syntax that tries to modify
>>> >>> > values
>>> >>> > within each v1xv2 combination by computing sum of v4, row percentage
>>> >>> > in
>>> >>> > terms of v4, and there is where my effort is blocked. Not really
>>> >>> > sure
>>> >>> > how I
>>> >>> > should proceed. Any suggestion?
>>> >>> >
>>> >>> > Thanks,
>>> >>> >
>>> >>> > Luca
>>> >>> >
>>> >>> >
>>> >>> > 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>>> >>> >
>>> >>> >> I don't understand your description. The standard practice on this
>>> >>> >> list
>>> >>> >> is
>>> >>> >> to provide a reproducible R example [1] of the kind of data you are
>>> >>> >> working
>>> >>> >> with (and any code you have tried) to go along with your
>>> >>> >> description.
>>> >>> >> In
>>> >>> >> this case, that would be two dputs of your input data frames and a
>>> >>> >> dput
>>> >>> >> of
>>> >>> >> an output data frame (generated by hand from your input data
>>> >>> >> frame).
>>> >>> >> (Probably best to not use the full number of input values just to
>>> >>> >> keep
>>> >>> >> the
>>> >>> >> size down.) We could then make an attempt to generate code that
>>> >>> >> goes
>>> >>> >> from
>>> >>> >> input to output.
>>> >>> >>
>>> >>> >> Of course, if you post that hard work using HTML then it will get
>>> >>> >> corrupted (much like the text below from your earlier emails) and
>>> >>> >> we
>>> >>> >> won't
>>> >>> >> be able to use it. Please learn to post from your email software
>>> >>> >> using
>>> >>> >> plain text when corresponding with this mailing list.
>>> >>> >>
>>> >>> >> [1]
>>> >>> >>
>>> >>> >>
>>> >>> >> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>> >>> >>
>>> >>> >>
>>> >>> >> ---------------------------------------------------------------------------
>>> >>> >> Jeff Newmiller                        The     .....       .....  Go
>>> >>> >> Live...
>>> >>> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
>>> >>> >> Live
>>> >>> >> Go...
>>> >>> >>                                       Live:   OO#.. Dead: OO#..
>>> >>> >> Playing
>>> >>> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.
>>> >>> >> with
>>> >>> >> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> >>> >> rocks...1k
>>> >>> >>
>>> >>> >>
>>> >>> >> ---------------------------------------------------------------------------
>>> >>> >> Sent from my phone. Please excuse my brevity.
>>> >>> >>
>>> >>> >> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <lucam1968 at gmail.com>
>>> >>> >> wrote:
>>> >>> >> >Thanks for you input Michael,
>>> >>> >> >
>>> >>> >> >The continuous variable I have measures quantities (down to the
>>> >>> >> > 3rd
>>> >>> >> >decimal level) so unfortunately are not frequencies.
>>> >>> >> >
>>> >>> >> >Any more specific suggestions on how that could be tackled?
>>> >>> >> >
>>> >>> >> >Thanks & kind regards,
>>> >>> >> >
>>> >>> >> >Luca
>>> >>> >> >
>>> >>> >> >
>>> >>> >> >===
>>> >>> >> >
>>> >>> >> >Michael Friendly wrote:
>>> >>> >> >I'm not sure I understand completely what you want to do, but
>>> >>> >> >if the data were frequencies, it sounds like task for fitting a
>>> >>> >> >loglinear model with the model formula
>>> >>> >> >
>>> >>> >> >~ V1*V2 + V3
>>> >>> >> >
>>> >>> >> >On 3/18/2015 2:17 AM, Luca Meyer wrote:
>>> >>> >> >>* Hello,
>>> >>> >> >*>>* I am facing a quite challenging task (at least to me) and I
>>> >>> >> > was
>>> >>> >> >wondering
>>> >>> >> >*>* if someone could advise how R could assist me to speed the
>>> >>> >> > task
>>> >>> >> > up.
>>> >>> >> >*>>* I am dealing with a dataset with 3 discrete variables and one
>>> >>> >> >continuous
>>> >>> >> >*>* variable. The discrete variables are:
>>> >>> >> >*>>* V1: 8 modalities
>>> >>> >> >*>* V2: 13 modalities
>>> >>> >> >*>* V3: 13 modalities
>>> >>> >> >*>>* The continuous variable V4 is a decimal number always greater
>>> >>> >> > than
>>> >>> >> >zero in
>>> >>> >> >*>* the marginals of each of the 3 variables but it is sometimes
>>> >>> >> > equal
>>> >>> >> >to zero
>>> >>> >> >*>* (and sometimes negative) in the joint tables.
>>> >>> >> >*>>* I have got 2 files:
>>> >>> >> >*>>* => one with distribution of all possible combinations of
>>> >>> >> > V1xV2
>>> >>> >> >(some of
>>> >>> >> >*>* which are zero or neagtive) and
>>> >>> >> >*>* => one with the marginal distribution of V3.
>>> >>> >> >*>>* I am trying to build the long and narrow dataset V1xV2xV3 in
>>> >>> >> > such
>>> >>> >> >a way
>>> >>> >> >*>* that each V1xV2 cell does not get modified and V3 fits as
>>> >>> >> > closely
>>> >>> >> >as
>>> >>> >> >*>* possible to its marginal distribution. Does it make sense?
>>> >>> >> >*>>* To be even more specific, my 2 input files look like the
>>> >>> >> >following.
>>> >>> >> >*>>* FILE 1
>>> >>> >> >*>* V1,V2,V4
>>> >>> >> >*>* A, A, 24.251
>>> >>> >> >*>* A, B, 1.065
>>> >>> >> >*>* (...)
>>> >>> >> >*>* B, C, 0.294
>>> >>> >> >*>* B, D, 2.731
>>> >>> >> >*>* (...)
>>> >>> >> >*>* H, L, 0.345
>>> >>> >> >*>* H, M, 0.000
>>> >>> >> >*>>* FILE 2
>>> >>> >> >*>* V3, V4
>>> >>> >> >*>* A, 1.575
>>> >>> >> >*>* B, 4.294
>>> >>> >> >*>* C, 10.044
>>> >>> >> >*>* (...)
>>> >>> >> >*>* L, 5.123
>>> >>> >> >*>* M, 3.334
>>> >>> >> >*>>* What I need to achieve is a file such as the following
>>> >>> >> >*>>* FILE 3
>>> >>> >> >*>* V1, V2, V3, V4
>>> >>> >> >*>* A, A, A, ???
>>> >>> >> >*>* A, A, B, ???
>>> >>> >> >*>* (...)
>>> >>> >> >*>* D, D, E, ???
>>> >>> >> >*>* D, D, F, ???
>>> >>> >> >*>* (...)
>>> >>> >> >*>* H, M, L, ???
>>> >>> >> >*>* H, M, M, ???
>>> >>> >> >*>>* Please notice that FILE 3 need to be such that if I aggregate
>>> >>> >> > on
>>> >>> >> >V1+V2 I
>>> >>> >> >*>* recover exactly FILE 1 and that if I aggregate on V3 I can
>>> >>> >> > recover
>>> >>> >> >a file
>>> >>> >> >*>* as close as possible to FILE 3 (ideally the same file).
>>> >>> >> >*>>* Can anyone suggest how I could do that with R?
>>> >>> >> >*>>* Thank you very much indeed for any assistance you are able to
>>> >>> >> >provide.
>>> >>> >> >*>>* Kind regards,
>>> >>> >> >*>>* Luca*
>>> >>> >> >
>>> >>> >> >       [[alternative HTML version deleted]]
>>> >>> >> >
>>> >>> >> >______________________________________________
>>> >>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>> >> >PLEASE do read the posting guide
>>> >>> >> >http://www.R-project.org/posting-guide.html
>>> >>> >> >and provide commented, minimal, self-contained, reproducible code.
>>> >>> >>
>>> >>> >>
>>> >>> >
>>> >>> >         [[alternative HTML version deleted]]
>>> >>> >
>>> >>> > ______________________________________________
>>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>> > PLEASE do read the posting guide
>>> >>> > http://www.R-project.org/posting-guide.html
>>> >>> > and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >>
>>
>>


From gunter.berton at gene.com  Sun Mar 22 16:15:03 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 22 Mar 2015 08:15:03 -0700
Subject: [R] Why can't I access this type?
In-Reply-To: <CAJ=2b04qLmoA8W--=dsv2vqMHkG1Y7Tv_QQx_9D78oopJku+Yg@mail.gmail.com>
References: <CAJ=2b04qLmoA8W--=dsv2vqMHkG1Y7Tv_QQx_9D78oopJku+Yg@mail.gmail.com>
Message-ID: <CACk-te1tD_Dce8xmUW9NPY6Ua0JvUKcgN7Eb2G76Q1WV+pECrA@mail.gmail.com>

Your data frame contains no column named "Name" .

Maybe what you want is

rownames(all.states)[all.state$Frost>150]

However, what you clearly need to do is stop posting until you have
done your homework by spending some time with one of the many good R
tutorials that are out there (possibly Intro to R, which ships with R,
though it's getting a bit dated now). This appears to be a very basic
question. If you are going through a tutorial and got stuck here, then
note that row names are an attribute of the data frame, not a column
name of one of its columns. See ?rownames and the links therein for
more info.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Mar 22, 2015 at 7:39 AM, Yves S. Garret
<yoursurrogategod at gmail.com> wrote:
> Hi, I'm just learning my way around R.  I got a bunch of states and would
> like to access to get all of the ones where it's cold.  But when I do the
> following, I will get the following error:
>
>> all.states <- as.data.frame(state.x77)
>> cold.states <- all.states[all.states$Frost > 150, c("Name", "Frost")]
> Error in `[.data.frame`(all.states, all.states$Frost > 150, c("Name",  :
>   undefined columns selected
>
> I don't get it.  When I look at all.states, this is what I see:
>
>> str(all.states)
> 'data.frame':   50 obs. of  8 variables:
>  $ Population: num  3615 365 2212 2110 21198 ...
>  $ Income    : num  3624 6315 4530 3378 5114 ...
>  $ Illiteracy: num  2.1 1.5 1.8 1.9 1.1 0.7 1.1 0.9 1.3 2 ...
>  $ Life Exp  : num  69 69.3 70.5 70.7 71.7 ...
>  $ Murder    : num  15.1 11.3 7.8 10.1 10.3 6.8 3.1 6.2 10.7 13.9 ...
>  $ HS Grad   : num  41.3 66.7 58.1 39.9 62.6 63.9 56 54.6 52.6 40.6 ...
>  $ Frost     : num  20 152 15 65 20 166 139 103 11 60 ...
>  $ Area      : num  50708 566432 113417 51945 156361 ...
>
> What am I messing up?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sun Mar 22 16:16:13 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 22 Mar 2015 08:16:13 -0700
Subject: [R] My R stopped working
In-Reply-To: <CABGg3O5ToUPWnp-8v-rpACAaOcQZ_78uyig_ZDmLLnMnfCTPNQ@mail.gmail.com>
References: <CABGg3O6ptTPTjWkMD9UyJdtCs=eZf_VhS15bNf2CA_gNCS57Bg@mail.gmail.com>
	<CABGg3O5ToUPWnp-8v-rpACAaOcQZ_78uyig_ZDmLLnMnfCTPNQ@mail.gmail.com>
Message-ID: <CACk-te2oSdAxtRHCbr-O1KRxG8jF44AvaPeEozwim9XRdDPhRA@mail.gmail.com>

restart R.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Mar 22, 2015 at 2:11 AM, adeela uaf <adeela.uaf at gmail.com> wrote:
> Hi,
> I was downloading some shape files in R then I use the package lsmeans in R
> but I received the message "R for winfows GUI front end has stopped working
> " . What I have to do to overcome this problem
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lucam1968 at gmail.com  Sun Mar 22 16:21:13 2015
From: lucam1968 at gmail.com (Luca Meyer)
Date: Sun, 22 Mar 2015 16:21:13 +0100
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <CACk-te3xkirW755s1WSETEEj0wvS=d=FneZw4r=dS=jK3RHNcQ@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
	<CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
	<CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>
	<CACk-te2CBQXFGJ-Vhr+kpdY6uccbn0Rp286ca+2YvKO=iHUogg@mail.gmail.com>
	<CACk-te0sTVt5pPb9f-ELgTt8L0Bbaz2NCQ9S4ZsB5e122vdYYA@mail.gmail.com>
	<CABQyo86dF4UQH94v1Q-rFMBV=JRmwc3V9SFgG=ZiwtGatKTwPg@mail.gmail.com>
	<CACk-te3xkirW755s1WSETEEj0wvS=d=FneZw4r=dS=jK3RHNcQ@mail.gmail.com>
Message-ID: <CABQyo86=oq-MNUJ=Q2FiFYpmeHVxb6hNZYpUvp+H=cUt5V6j1A@mail.gmail.com>

Hi Bert,

Thanks again for your assistance.

Unfortunately when I apply the additional code you suggest I get B=40.23326
& C=-8.66603 and not  B=29 & C=2.56723. Any idea why that might be
happening?

Please see below or on
https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0 the code I
am running:

rm(list=ls())

# this is (an extract of) the INPUT file I have:
f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
"B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
"B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
"B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917,
1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names =
c(2L,
9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))

# this is the procedure that Bert suggested (slightly adjusted):

y <- f1$v3  ## to simplify the notation; could be done using with()
z <- (c(29,2.567)/table(y))[c(y)]
# z <- rnorm(nrow(f1)) ## or anything you want
z1 <- round(with(f1,v4 + z -ave(z,v1,v2,FUN=mean)), digits=5)
aggregate(v4~v1*v2,f1,sum)
aggregate(z1~v1*v2,f1,sum)
aggregate(v4~v3,f1,sum)
aggregate(z1~v3,f1,sum)

Thanks again,

Luca


2015-03-22 15:55 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:

> I would have thought that this is straightforward given my previous
> email...
>
> Just set z to what you want -- e,g, all B values to 29/number of B's,
> and all C values to 2.567/number of C's (etc. for more categories).
>
> A slick but sort of cheat way to do this programmatically -- in the
> sense that it relies on the implementation of factor() rather than its
> API -- is:
>
> y <- f1$v3  ## to simplify the notation; could be done using with()
> z <- (c(29,2.567)/table(y))[c(y)]
>
> Then proceed to z1 as I previously described
>
> -- Bert
>
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sun, Mar 22, 2015 at 2:00 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
> > Hi Bert, hello R-experts,
> >
> > I am close to a solution but I still need one hint w.r.t. the following
> > procedure (available also from
> > https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0)
> >
> > rm(list=ls())
> >
> > # this is (an extract of) the INPUT file I have:
> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B", "B",
> > "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A", "B", "C", "A",
> > "B", "C"), v3 = c("B", "B", "B", "C", "C", "C", "B", "B", "B", "C", "C",
> > "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917, 1.05786, 0.00042,
> 2.37232,
> > 3.01835, 0, 1.13430, 0.92872, 0)), .Names = c("v1", "v2", "v3", "v4"),
> class
> > = "data.frame", row.names = c(2L, 9L, 11L, 41L, 48L, 50L, 158L, 165L,
> 167L,
> > 197L, 204L, 206L))
> >
> > # this is the procedure that Bert suggested (slightly adjusted):
> > z <- rnorm(nrow(f1)) ## or anything you want
> > z1 <- round(with(f1,v4 + z -ave(z,v1,v2,FUN=mean)), digits=5)
> > aggregate(v4~v1*v2,f1,sum)
> > aggregate(z1~v1*v2,f1,sum)
> > aggregate(v4~v3,f1,sum)
> > aggregate(z1~v3,f1,sum)
> >
> > My question to you is: how can I set z so that I can obtain specific
> values
> > for z1-v4 in the v3 aggregation?
> > In other words, how can I configure the procedure so that e.g. B=29 and
> > C=2.56723 after running the procedure:
> > aggregate(z1~v3,f1,sum)
> >
> > Thank you,
> >
> > Luca
> >
> > PS: to avoid any doubts you might have about who I am the following is my
> > web page: http://lucameyer.wordpress.com/
> >
> >
> > 2015-03-21 18:13 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
> >>
> >> ... or cleaner:
> >>
> >> z1 <- with(f1,v4 + z -ave(z,v1,v2,FUN=mean))
> >>
> >>
> >> Just for curiosity, was this homework? (in which case I should
> >> probably have not provided you an answer -- that is, assuming that I
> >> HAVE provided an answer).
> >>
> >> Cheers,
> >> Bert
> >>
> >> Bert Gunter
> >> Genentech Nonclinical Biostatistics
> >> (650) 467-7374
> >>
> >> "Data is not information. Information is not knowledge. And knowledge
> >> is certainly not wisdom."
> >> Clifford Stoll
> >>
> >>
> >>
> >>
> >> On Sat, Mar 21, 2015 at 7:53 AM, Bert Gunter <bgunter at gene.com> wrote:
> >> > z <- rnorm(nrow(f1)) ## or anything you want
> >> > z1 <- f1$v4 + z - with(f1,ave(z,v1,v2,FUN=mean))
> >> >
> >> >
> >> > aggregate(v4~v1,f1,sum)
> >> > aggregate(z1~v1,f1,sum)
> >> > aggregate(v4~v2,f1,sum)
> >> > aggregate(z1~v2,f1,sum)
> >> > aggregate(v4~v3,f1,sum)
> >> > aggregate(z1~v3,f1,sum)
> >> >
> >> >
> >> > Cheers,
> >> > Bert
> >> >
> >> > Bert Gunter
> >> > Genentech Nonclinical Biostatistics
> >> > (650) 467-7374
> >> >
> >> > "Data is not information. Information is not knowledge. And knowledge
> >> > is certainly not wisdom."
> >> > Clifford Stoll
> >> >
> >> >
> >> >
> >> >
> >> > On Sat, Mar 21, 2015 at 6:49 AM, Luca Meyer <lucam1968 at gmail.com>
> wrote:
> >> >> Hi Bert,
> >> >>
> >> >> Thank you for your message. I am looking into ave() and tapply() as
> you
> >> >> suggested but at the same time I have prepared a example of input and
> >> >> output
> >> >> files, just in case you or someone else would like to make an attempt
> >> >> to
> >> >> generate a code that goes from input to output.
> >> >>
> >> >> Please see below or download it from
> >> >> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
> >> >>
> >> >> # this is (an extract of) the INPUT file I have:
> >> >> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> >> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >> >> "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273,
> >> >> 1.42917,
> >> >> 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> >> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> >> >> row.names =
> >> >> c(2L,
> >> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >> >>
> >> >> # this is (an extract of) the OUTPUT file I would like to obtain:
> >> >> f2 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> >> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >> >> "B", "B", "B", "C", "C", "C"), v4 = c(17.83529, 3.43806,0.00295,
> >> >> 1.77918,
> >> >> 1.05786, 0.0002, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> >> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> >> >> row.names =
> >> >> c(2L,
> >> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >> >>
> >> >> # please notice that while the aggregated v4 on v3 has changed ?
> >> >> aggregate(f1[,c("v4")],list(f1$v3),sum)
> >> >> aggregate(f2[,c("v4")],list(f2$v3),sum)
> >> >>
> >> >> # ? the aggregated v4 over v1xv2 has remained unchanged:
> >> >> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
> >> >> aggregate(f2[,c("v4")],list(f2$v1,f2$v2),sum)
> >> >>
> >> >> Thank you very much in advance for your assitance.
> >> >>
> >> >> Luca
> >> >>
> >> >> 2015-03-21 13:18 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
> >> >>>
> >> >>> 1. Still not sure what you mean, but maybe look at ?ave and ?tapply,
> >> >>> for which ave() is a wrapper.
> >> >>>
> >> >>> 2. You still need to heed the rest of Jeff's advice.
> >> >>>
> >> >>> Cheers,
> >> >>> Bert
> >> >>>
> >> >>> Bert Gunter
> >> >>> Genentech Nonclinical Biostatistics
> >> >>> (650) 467-7374
> >> >>>
> >> >>> "Data is not information. Information is not knowledge. And
> knowledge
> >> >>> is certainly not wisdom."
> >> >>> Clifford Stoll
> >> >>>
> >> >>>
> >> >>>
> >> >>>
> >> >>> On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <lucam1968 at gmail.com>
> >> >>> wrote:
> >> >>> > Hi Jeff & other R-experts,
> >> >>> >
> >> >>> > Thank you for your note. I have tried myself to solve the issue
> >> >>> > without
> >> >>> > success.
> >> >>> >
> >> >>> > Following your suggestion, I am providing a sample of the dataset
> I
> >> >>> > am
> >> >>> > using below (also downloadble in plain text from
> >> >>> > https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
> >> >>> >
> >> >>> > #this is an extract of the overall dataset (n=1200 cases)
> >> >>> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
> "B",
> >> >>> > "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >> >>> > "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >> >>> > "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835,
> >> >>> > 3.43806581506388,
> >> >>> > 0.002733567617055, 1.42917483425029, 1.05786640463504,
> >> >>> > 0.000420548864162308,
> >> >>> > 2.37232740842861, 3.01835841813241, 0, 1.13430282139936,
> >> >>> > 0.928725667117666,
> >> >>> > 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> >> >>> > row.names
> >> >>> > =
> >> >>> > c(2L,
> >> >>> > 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >> >>> >
> >> >>> > I need to find a automated procedure that allows me to adjust v3
> >> >>> > marginals
> >> >>> > while maintaining v1xv2 marginals unchanged.
> >> >>> >
> >> >>> > That is: modify the v4 values you can find by running:
> >> >>> >
> >> >>> > aggregate(f1[,c("v4")],list(f1$v3),sum)
> >> >>> >
> >> >>> > while maintaining costant the values you can find by running:
> >> >>> >
> >> >>> > aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
> >> >>> >
> >> >>> > Now does it make sense?
> >> >>> >
> >> >>> > Please notice I have tried to build some syntax that tries to
> modify
> >> >>> > values
> >> >>> > within each v1xv2 combination by computing sum of v4, row
> percentage
> >> >>> > in
> >> >>> > terms of v4, and there is where my effort is blocked. Not really
> >> >>> > sure
> >> >>> > how I
> >> >>> > should proceed. Any suggestion?
> >> >>> >
> >> >>> > Thanks,
> >> >>> >
> >> >>> > Luca
> >> >>> >
> >> >>> >
> >> >>> > 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us>:
> >> >>> >
> >> >>> >> I don't understand your description. The standard practice on
> this
> >> >>> >> list
> >> >>> >> is
> >> >>> >> to provide a reproducible R example [1] of the kind of data you
> are
> >> >>> >> working
> >> >>> >> with (and any code you have tried) to go along with your
> >> >>> >> description.
> >> >>> >> In
> >> >>> >> this case, that would be two dputs of your input data frames and
> a
> >> >>> >> dput
> >> >>> >> of
> >> >>> >> an output data frame (generated by hand from your input data
> >> >>> >> frame).
> >> >>> >> (Probably best to not use the full number of input values just to
> >> >>> >> keep
> >> >>> >> the
> >> >>> >> size down.) We could then make an attempt to generate code that
> >> >>> >> goes
> >> >>> >> from
> >> >>> >> input to output.
> >> >>> >>
> >> >>> >> Of course, if you post that hard work using HTML then it will get
> >> >>> >> corrupted (much like the text below from your earlier emails) and
> >> >>> >> we
> >> >>> >> won't
> >> >>> >> be able to use it. Please learn to post from your email software
> >> >>> >> using
> >> >>> >> plain text when corresponding with this mailing list.
> >> >>> >>
> >> >>> >> [1]
> >> >>> >>
> >> >>> >>
> >> >>> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >> >>> >>
> >> >>> >>
> >> >>> >>
> ---------------------------------------------------------------------------
> >> >>> >> Jeff Newmiller                        The     .....       .....
> Go
> >> >>> >> Live...
> >> >>> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
> >> >>> >> Live
> >> >>> >> Go...
> >> >>> >>                                       Live:   OO#.. Dead: OO#..
> >> >>> >> Playing
> >> >>> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.
> >> >>> >> with
> >> >>> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >> >>> >> rocks...1k
> >> >>> >>
> >> >>> >>
> >> >>> >>
> ---------------------------------------------------------------------------
> >> >>> >> Sent from my phone. Please excuse my brevity.
> >> >>> >>
> >> >>> >> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <
> lucam1968 at gmail.com>
> >> >>> >> wrote:
> >> >>> >> >Thanks for you input Michael,
> >> >>> >> >
> >> >>> >> >The continuous variable I have measures quantities (down to the
> >> >>> >> > 3rd
> >> >>> >> >decimal level) so unfortunately are not frequencies.
> >> >>> >> >
> >> >>> >> >Any more specific suggestions on how that could be tackled?
> >> >>> >> >
> >> >>> >> >Thanks & kind regards,
> >> >>> >> >
> >> >>> >> >Luca
> >> >>> >> >
> >> >>> >> >
> >> >>> >> >===
> >> >>> >> >
> >> >>> >> >Michael Friendly wrote:
> >> >>> >> >I'm not sure I understand completely what you want to do, but
> >> >>> >> >if the data were frequencies, it sounds like task for fitting a
> >> >>> >> >loglinear model with the model formula
> >> >>> >> >
> >> >>> >> >~ V1*V2 + V3
> >> >>> >> >
> >> >>> >> >On 3/18/2015 2:17 AM, Luca Meyer wrote:
> >> >>> >> >>* Hello,
> >> >>> >> >*>>* I am facing a quite challenging task (at least to me) and I
> >> >>> >> > was
> >> >>> >> >wondering
> >> >>> >> >*>* if someone could advise how R could assist me to speed the
> >> >>> >> > task
> >> >>> >> > up.
> >> >>> >> >*>>* I am dealing with a dataset with 3 discrete variables and
> one
> >> >>> >> >continuous
> >> >>> >> >*>* variable. The discrete variables are:
> >> >>> >> >*>>* V1: 8 modalities
> >> >>> >> >*>* V2: 13 modalities
> >> >>> >> >*>* V3: 13 modalities
> >> >>> >> >*>>* The continuous variable V4 is a decimal number always
> greater
> >> >>> >> > than
> >> >>> >> >zero in
> >> >>> >> >*>* the marginals of each of the 3 variables but it is sometimes
> >> >>> >> > equal
> >> >>> >> >to zero
> >> >>> >> >*>* (and sometimes negative) in the joint tables.
> >> >>> >> >*>>* I have got 2 files:
> >> >>> >> >*>>* => one with distribution of all possible combinations of
> >> >>> >> > V1xV2
> >> >>> >> >(some of
> >> >>> >> >*>* which are zero or neagtive) and
> >> >>> >> >*>* => one with the marginal distribution of V3.
> >> >>> >> >*>>* I am trying to build the long and narrow dataset V1xV2xV3
> in
> >> >>> >> > such
> >> >>> >> >a way
> >> >>> >> >*>* that each V1xV2 cell does not get modified and V3 fits as
> >> >>> >> > closely
> >> >>> >> >as
> >> >>> >> >*>* possible to its marginal distribution. Does it make sense?
> >> >>> >> >*>>* To be even more specific, my 2 input files look like the
> >> >>> >> >following.
> >> >>> >> >*>>* FILE 1
> >> >>> >> >*>* V1,V2,V4
> >> >>> >> >*>* A, A, 24.251
> >> >>> >> >*>* A, B, 1.065
> >> >>> >> >*>* (...)
> >> >>> >> >*>* B, C, 0.294
> >> >>> >> >*>* B, D, 2.731
> >> >>> >> >*>* (...)
> >> >>> >> >*>* H, L, 0.345
> >> >>> >> >*>* H, M, 0.000
> >> >>> >> >*>>* FILE 2
> >> >>> >> >*>* V3, V4
> >> >>> >> >*>* A, 1.575
> >> >>> >> >*>* B, 4.294
> >> >>> >> >*>* C, 10.044
> >> >>> >> >*>* (...)
> >> >>> >> >*>* L, 5.123
> >> >>> >> >*>* M, 3.334
> >> >>> >> >*>>* What I need to achieve is a file such as the following
> >> >>> >> >*>>* FILE 3
> >> >>> >> >*>* V1, V2, V3, V4
> >> >>> >> >*>* A, A, A, ???
> >> >>> >> >*>* A, A, B, ???
> >> >>> >> >*>* (...)
> >> >>> >> >*>* D, D, E, ???
> >> >>> >> >*>* D, D, F, ???
> >> >>> >> >*>* (...)
> >> >>> >> >*>* H, M, L, ???
> >> >>> >> >*>* H, M, M, ???
> >> >>> >> >*>>* Please notice that FILE 3 need to be such that if I
> aggregate
> >> >>> >> > on
> >> >>> >> >V1+V2 I
> >> >>> >> >*>* recover exactly FILE 1 and that if I aggregate on V3 I can
> >> >>> >> > recover
> >> >>> >> >a file
> >> >>> >> >*>* as close as possible to FILE 3 (ideally the same file).
> >> >>> >> >*>>* Can anyone suggest how I could do that with R?
> >> >>> >> >*>>* Thank you very much indeed for any assistance you are able
> to
> >> >>> >> >provide.
> >> >>> >> >*>>* Kind regards,
> >> >>> >> >*>>* Luca*
> >> >>> >> >
> >> >>> >> >       [[alternative HTML version deleted]]
> >> >>> >> >
> >> >>> >> >______________________________________________
> >> >>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >> >>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> >> >PLEASE do read the posting guide
> >> >>> >> >http://www.R-project.org/posting-guide.html
> >> >>> >> >and provide commented, minimal, self-contained, reproducible
> code.
> >> >>> >>
> >> >>> >>
> >> >>> >
> >> >>> >         [[alternative HTML version deleted]]
> >> >>> >
> >> >>> > ______________________________________________
> >> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> > PLEASE do read the posting guide
> >> >>> > http://www.R-project.org/posting-guide.html
> >> >>> > and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >>
> >
> >
>

	[[alternative HTML version deleted]]


From lucam1968 at gmail.com  Sun Mar 22 16:28:41 2015
From: lucam1968 at gmail.com (Luca Meyer)
Date: Sun, 22 Mar 2015 16:28:41 +0100
Subject: [R] Fwd:  Joining two datasets - recursive procedure?
In-Reply-To: <CABQyo864GFSgDAEgRrf-0TQhrYLufNv96v2q00-YAb4nsVWYyw@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
	<CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
	<CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>
	<CACk-te2CBQXFGJ-Vhr+kpdY6uccbn0Rp286ca+2YvKO=iHUogg@mail.gmail.com>
	<CACk-te0sTVt5pPb9f-ELgTt8L0Bbaz2NCQ9S4ZsB5e122vdYYA@mail.gmail.com>
	<CABQyo86dF4UQH94v1Q-rFMBV=JRmwc3V9SFgG=ZiwtGatKTwPg@mail.gmail.com>
	<CACk-te3xkirW755s1WSETEEj0wvS=d=FneZw4r=dS=jK3RHNcQ@mail.gmail.com>
	<CACk-te22ZaM5p5H7Wz1ivN24S5zog-FY=AvdHQEbdz2O7AL2gA@mail.gmail.com>
	<CABQyo864GFSgDAEgRrf-0TQhrYLufNv96v2q00-YAb4nsVWYyw@mail.gmail.com>
Message-ID: <CABQyo86r0h_6R2u8cm3Amg0pPnC7b+Tuy9t3zOiNFqmsTa2DEA@mail.gmail.com>

Sorry forgot to keep the rest of the group in the loop - Luca
---------- Forwarded message ----------
From: Luca Meyer <lucam1968 at gmail.com>
Date: 2015-03-22 16:27 GMT+01:00
Subject: Re: [R] Joining two datasets - recursive procedure?
To: Bert Gunter <gunter.berton at gene.com>


Hi Bert,

That is exactly what I am trying to achieve. Please notice that negative v4
values are allowed. I have done a similar task in the past manually by
recursively alterating v4 distribution across v3 categories within fix each
v1&v2 combination so I am quite positive it can be achieved but honestly I
took me forever to do it manually and since this is likely to be an
exercise I need to repeat from time to time I wish I could learn how to do
it programmatically....

Thanks again for any further suggestion you might have,

Luca


2015-03-22 16:05 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:

> Oh, wait a minute ...
>
> You still want the marginals for the other columns to be as originally?
>
> If so, then this is impossible in general as the sum of all the values
> must be what they were originally and you cannot therefore choose your
> values for V3 arbitrarily.
>
> Or at least, that seems to be what you are trying to do.
>
> -- Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sun, Mar 22, 2015 at 7:55 AM, Bert Gunter <bgunter at gene.com> wrote:
> > I would have thought that this is straightforward given my previous
> email...
> >
> > Just set z to what you want -- e,g, all B values to 29/number of B's,
> > and all C values to 2.567/number of C's (etc. for more categories).
> >
> > A slick but sort of cheat way to do this programmatically -- in the
> > sense that it relies on the implementation of factor() rather than its
> > API -- is:
> >
> > y <- f1$v3  ## to simplify the notation; could be done using with()
> > z <- (c(29,2.567)/table(y))[c(y)]
> >
> > Then proceed to z1 as I previously described
> >
> > -- Bert
> >
> >
> > Bert Gunter
> > Genentech Nonclinical Biostatistics
> > (650) 467-7374
> >
> > "Data is not information. Information is not knowledge. And knowledge
> > is certainly not wisdom."
> > Clifford Stoll
> >
> >
> >
> >
> > On Sun, Mar 22, 2015 at 2:00 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
> >> Hi Bert, hello R-experts,
> >>
> >> I am close to a solution but I still need one hint w.r.t. the following
> >> procedure (available also from
> >> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0)
> >>
> >> rm(list=ls())
> >>
> >> # this is (an extract of) the INPUT file I have:
> >> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B", "B",
> >> "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A", "B", "C", "A",
> >> "B", "C"), v3 = c("B", "B", "B", "C", "C", "C", "B", "B", "B", "C", "C",
> >> "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917, 1.05786, 0.00042,
> 2.37232,
> >> 3.01835, 0, 1.13430, 0.92872, 0)), .Names = c("v1", "v2", "v3", "v4"),
> class
> >> = "data.frame", row.names = c(2L, 9L, 11L, 41L, 48L, 50L, 158L, 165L,
> 167L,
> >> 197L, 204L, 206L))
> >>
> >> # this is the procedure that Bert suggested (slightly adjusted):
> >> z <- rnorm(nrow(f1)) ## or anything you want
> >> z1 <- round(with(f1,v4 + z -ave(z,v1,v2,FUN=mean)), digits=5)
> >> aggregate(v4~v1*v2,f1,sum)
> >> aggregate(z1~v1*v2,f1,sum)
> >> aggregate(v4~v3,f1,sum)
> >> aggregate(z1~v3,f1,sum)
> >>
> >> My question to you is: how can I set z so that I can obtain specific
> values
> >> for z1-v4 in the v3 aggregation?
> >> In other words, how can I configure the procedure so that e.g. B=29 and
> >> C=2.56723 after running the procedure:
> >> aggregate(z1~v3,f1,sum)
> >>
> >> Thank you,
> >>
> >> Luca
> >>
> >> PS: to avoid any doubts you might have about who I am the following is
> my
> >> web page: http://lucameyer.wordpress.com/
> >>
> >>
> >> 2015-03-21 18:13 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
> >>>
> >>> ... or cleaner:
> >>>
> >>> z1 <- with(f1,v4 + z -ave(z,v1,v2,FUN=mean))
> >>>
> >>>
> >>> Just for curiosity, was this homework? (in which case I should
> >>> probably have not provided you an answer -- that is, assuming that I
> >>> HAVE provided an answer).
> >>>
> >>> Cheers,
> >>> Bert
> >>>
> >>> Bert Gunter
> >>> Genentech Nonclinical Biostatistics
> >>> (650) 467-7374
> >>>
> >>> "Data is not information. Information is not knowledge. And knowledge
> >>> is certainly not wisdom."
> >>> Clifford Stoll
> >>>
> >>>
> >>>
> >>>
> >>> On Sat, Mar 21, 2015 at 7:53 AM, Bert Gunter <bgunter at gene.com> wrote:
> >>> > z <- rnorm(nrow(f1)) ## or anything you want
> >>> > z1 <- f1$v4 + z - with(f1,ave(z,v1,v2,FUN=mean))
> >>> >
> >>> >
> >>> > aggregate(v4~v1,f1,sum)
> >>> > aggregate(z1~v1,f1,sum)
> >>> > aggregate(v4~v2,f1,sum)
> >>> > aggregate(z1~v2,f1,sum)
> >>> > aggregate(v4~v3,f1,sum)
> >>> > aggregate(z1~v3,f1,sum)
> >>> >
> >>> >
> >>> > Cheers,
> >>> > Bert
> >>> >
> >>> > Bert Gunter
> >>> > Genentech Nonclinical Biostatistics
> >>> > (650) 467-7374
> >>> >
> >>> > "Data is not information. Information is not knowledge. And knowledge
> >>> > is certainly not wisdom."
> >>> > Clifford Stoll
> >>> >
> >>> >
> >>> >
> >>> >
> >>> > On Sat, Mar 21, 2015 at 6:49 AM, Luca Meyer <lucam1968 at gmail.com>
> wrote:
> >>> >> Hi Bert,
> >>> >>
> >>> >> Thank you for your message. I am looking into ave() and tapply() as
> you
> >>> >> suggested but at the same time I have prepared a example of input
> and
> >>> >> output
> >>> >> files, just in case you or someone else would like to make an
> attempt
> >>> >> to
> >>> >> generate a code that goes from input to output.
> >>> >>
> >>> >> Please see below or download it from
> >>> >> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
> >>> >>
> >>> >> # this is (an extract of) the INPUT file I have:
> >>> >> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> >>> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >>> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >>> >> "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273,
> >>> >> 1.42917,
> >>> >> 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> >>> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> >>> >> row.names =
> >>> >> c(2L,
> >>> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >>> >>
> >>> >> # this is (an extract of) the OUTPUT file I would like to obtain:
> >>> >> f2 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> >>> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >>> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >>> >> "B", "B", "B", "C", "C", "C"), v4 = c(17.83529, 3.43806,0.00295,
> >>> >> 1.77918,
> >>> >> 1.05786, 0.0002, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> >>> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> >>> >> row.names =
> >>> >> c(2L,
> >>> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >>> >>
> >>> >> # please notice that while the aggregated v4 on v3 has changed ?
> >>> >> aggregate(f1[,c("v4")],list(f1$v3),sum)
> >>> >> aggregate(f2[,c("v4")],list(f2$v3),sum)
> >>> >>
> >>> >> # ? the aggregated v4 over v1xv2 has remained unchanged:
> >>> >> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
> >>> >> aggregate(f2[,c("v4")],list(f2$v1,f2$v2),sum)
> >>> >>
> >>> >> Thank you very much in advance for your assitance.
> >>> >>
> >>> >> Luca
> >>> >>
> >>> >> 2015-03-21 13:18 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
> >>> >>>
> >>> >>> 1. Still not sure what you mean, but maybe look at ?ave and
> ?tapply,
> >>> >>> for which ave() is a wrapper.
> >>> >>>
> >>> >>> 2. You still need to heed the rest of Jeff's advice.
> >>> >>>
> >>> >>> Cheers,
> >>> >>> Bert
> >>> >>>
> >>> >>> Bert Gunter
> >>> >>> Genentech Nonclinical Biostatistics
> >>> >>> (650) 467-7374
> >>> >>>
> >>> >>> "Data is not information. Information is not knowledge. And
> knowledge
> >>> >>> is certainly not wisdom."
> >>> >>> Clifford Stoll
> >>> >>>
> >>> >>>
> >>> >>>
> >>> >>>
> >>> >>> On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <lucam1968 at gmail.com>
> >>> >>> wrote:
> >>> >>> > Hi Jeff & other R-experts,
> >>> >>> >
> >>> >>> > Thank you for your note. I have tried myself to solve the issue
> >>> >>> > without
> >>> >>> > success.
> >>> >>> >
> >>> >>> > Following your suggestion, I am providing a sample of the
> dataset I
> >>> >>> > am
> >>> >>> > using below (also downloadble in plain text from
> >>> >>> > https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
> >>> >>> >
> >>> >>> > #this is an extract of the overall dataset (n=1200 cases)
> >>> >>> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
> "B",
> >>> >>> > "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >>> >>> > "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >>> >>> > "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835,
> >>> >>> > 3.43806581506388,
> >>> >>> > 0.002733567617055, 1.42917483425029, 1.05786640463504,
> >>> >>> > 0.000420548864162308,
> >>> >>> > 2.37232740842861, 3.01835841813241, 0, 1.13430282139936,
> >>> >>> > 0.928725667117666,
> >>> >>> > 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> >>> >>> > row.names
> >>> >>> > =
> >>> >>> > c(2L,
> >>> >>> > 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >>> >>> >
> >>> >>> > I need to find a automated procedure that allows me to adjust v3
> >>> >>> > marginals
> >>> >>> > while maintaining v1xv2 marginals unchanged.
> >>> >>> >
> >>> >>> > That is: modify the v4 values you can find by running:
> >>> >>> >
> >>> >>> > aggregate(f1[,c("v4")],list(f1$v3),sum)
> >>> >>> >
> >>> >>> > while maintaining costant the values you can find by running:
> >>> >>> >
> >>> >>> > aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
> >>> >>> >
> >>> >>> > Now does it make sense?
> >>> >>> >
> >>> >>> > Please notice I have tried to build some syntax that tries to
> modify
> >>> >>> > values
> >>> >>> > within each v1xv2 combination by computing sum of v4, row
> percentage
> >>> >>> > in
> >>> >>> > terms of v4, and there is where my effort is blocked. Not really
> >>> >>> > sure
> >>> >>> > how I
> >>> >>> > should proceed. Any suggestion?
> >>> >>> >
> >>> >>> > Thanks,
> >>> >>> >
> >>> >>> > Luca
> >>> >>> >
> >>> >>> >
> >>> >>> > 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us>:
> >>> >>> >
> >>> >>> >> I don't understand your description. The standard practice on
> this
> >>> >>> >> list
> >>> >>> >> is
> >>> >>> >> to provide a reproducible R example [1] of the kind of data you
> are
> >>> >>> >> working
> >>> >>> >> with (and any code you have tried) to go along with your
> >>> >>> >> description.
> >>> >>> >> In
> >>> >>> >> this case, that would be two dputs of your input data frames
> and a
> >>> >>> >> dput
> >>> >>> >> of
> >>> >>> >> an output data frame (generated by hand from your input data
> >>> >>> >> frame).
> >>> >>> >> (Probably best to not use the full number of input values just
> to
> >>> >>> >> keep
> >>> >>> >> the
> >>> >>> >> size down.) We could then make an attempt to generate code that
> >>> >>> >> goes
> >>> >>> >> from
> >>> >>> >> input to output.
> >>> >>> >>
> >>> >>> >> Of course, if you post that hard work using HTML then it will
> get
> >>> >>> >> corrupted (much like the text below from your earlier emails)
> and
> >>> >>> >> we
> >>> >>> >> won't
> >>> >>> >> be able to use it. Please learn to post from your email software
> >>> >>> >> using
> >>> >>> >> plain text when corresponding with this mailing list.
> >>> >>> >>
> >>> >>> >> [1]
> >>> >>> >>
> >>> >>> >>
> >>> >>> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >>> >>> >>
> >>> >>> >>
> >>> >>> >>
> ---------------------------------------------------------------------------
> >>> >>> >> Jeff Newmiller                        The     .....
>  .....  Go
> >>> >>> >> Live...
> >>> >>> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
> >>> >>> >> Live
> >>> >>> >> Go...
> >>> >>> >>                                       Live:   OO#.. Dead: OO#..
> >>> >>> >> Playing
> >>> >>> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.
> >>> >>> >> with
> >>> >>> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >>> >>> >> rocks...1k
> >>> >>> >>
> >>> >>> >>
> >>> >>> >>
> ---------------------------------------------------------------------------
> >>> >>> >> Sent from my phone. Please excuse my brevity.
> >>> >>> >>
> >>> >>> >> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <
> lucam1968 at gmail.com>
> >>> >>> >> wrote:
> >>> >>> >> >Thanks for you input Michael,
> >>> >>> >> >
> >>> >>> >> >The continuous variable I have measures quantities (down to the
> >>> >>> >> > 3rd
> >>> >>> >> >decimal level) so unfortunately are not frequencies.
> >>> >>> >> >
> >>> >>> >> >Any more specific suggestions on how that could be tackled?
> >>> >>> >> >
> >>> >>> >> >Thanks & kind regards,
> >>> >>> >> >
> >>> >>> >> >Luca
> >>> >>> >> >
> >>> >>> >> >
> >>> >>> >> >===
> >>> >>> >> >
> >>> >>> >> >Michael Friendly wrote:
> >>> >>> >> >I'm not sure I understand completely what you want to do, but
> >>> >>> >> >if the data were frequencies, it sounds like task for fitting a
> >>> >>> >> >loglinear model with the model formula
> >>> >>> >> >
> >>> >>> >> >~ V1*V2 + V3
> >>> >>> >> >
> >>> >>> >> >On 3/18/2015 2:17 AM, Luca Meyer wrote:
> >>> >>> >> >>* Hello,
> >>> >>> >> >*>>* I am facing a quite challenging task (at least to me) and
> I
> >>> >>> >> > was
> >>> >>> >> >wondering
> >>> >>> >> >*>* if someone could advise how R could assist me to speed the
> >>> >>> >> > task
> >>> >>> >> > up.
> >>> >>> >> >*>>* I am dealing with a dataset with 3 discrete variables and
> one
> >>> >>> >> >continuous
> >>> >>> >> >*>* variable. The discrete variables are:
> >>> >>> >> >*>>* V1: 8 modalities
> >>> >>> >> >*>* V2: 13 modalities
> >>> >>> >> >*>* V3: 13 modalities
> >>> >>> >> >*>>* The continuous variable V4 is a decimal number always
> greater
> >>> >>> >> > than
> >>> >>> >> >zero in
> >>> >>> >> >*>* the marginals of each of the 3 variables but it is
> sometimes
> >>> >>> >> > equal
> >>> >>> >> >to zero
> >>> >>> >> >*>* (and sometimes negative) in the joint tables.
> >>> >>> >> >*>>* I have got 2 files:
> >>> >>> >> >*>>* => one with distribution of all possible combinations of
> >>> >>> >> > V1xV2
> >>> >>> >> >(some of
> >>> >>> >> >*>* which are zero or neagtive) and
> >>> >>> >> >*>* => one with the marginal distribution of V3.
> >>> >>> >> >*>>* I am trying to build the long and narrow dataset V1xV2xV3
> in
> >>> >>> >> > such
> >>> >>> >> >a way
> >>> >>> >> >*>* that each V1xV2 cell does not get modified and V3 fits as
> >>> >>> >> > closely
> >>> >>> >> >as
> >>> >>> >> >*>* possible to its marginal distribution. Does it make sense?
> >>> >>> >> >*>>* To be even more specific, my 2 input files look like the
> >>> >>> >> >following.
> >>> >>> >> >*>>* FILE 1
> >>> >>> >> >*>* V1,V2,V4
> >>> >>> >> >*>* A, A, 24.251
> >>> >>> >> >*>* A, B, 1.065
> >>> >>> >> >*>* (...)
> >>> >>> >> >*>* B, C, 0.294
> >>> >>> >> >*>* B, D, 2.731
> >>> >>> >> >*>* (...)
> >>> >>> >> >*>* H, L, 0.345
> >>> >>> >> >*>* H, M, 0.000
> >>> >>> >> >*>>* FILE 2
> >>> >>> >> >*>* V3, V4
> >>> >>> >> >*>* A, 1.575
> >>> >>> >> >*>* B, 4.294
> >>> >>> >> >*>* C, 10.044
> >>> >>> >> >*>* (...)
> >>> >>> >> >*>* L, 5.123
> >>> >>> >> >*>* M, 3.334
> >>> >>> >> >*>>* What I need to achieve is a file such as the following
> >>> >>> >> >*>>* FILE 3
> >>> >>> >> >*>* V1, V2, V3, V4
> >>> >>> >> >*>* A, A, A, ???
> >>> >>> >> >*>* A, A, B, ???
> >>> >>> >> >*>* (...)
> >>> >>> >> >*>* D, D, E, ???
> >>> >>> >> >*>* D, D, F, ???
> >>> >>> >> >*>* (...)
> >>> >>> >> >*>* H, M, L, ???
> >>> >>> >> >*>* H, M, M, ???
> >>> >>> >> >*>>* Please notice that FILE 3 need to be such that if I
> aggregate
> >>> >>> >> > on
> >>> >>> >> >V1+V2 I
> >>> >>> >> >*>* recover exactly FILE 1 and that if I aggregate on V3 I can
> >>> >>> >> > recover
> >>> >>> >> >a file
> >>> >>> >> >*>* as close as possible to FILE 3 (ideally the same file).
> >>> >>> >> >*>>* Can anyone suggest how I could do that with R?
> >>> >>> >> >*>>* Thank you very much indeed for any assistance you are
> able to
> >>> >>> >> >provide.
> >>> >>> >> >*>>* Kind regards,
> >>> >>> >> >*>>* Luca*
> >>> >>> >> >
> >>> >>> >> >       [[alternative HTML version deleted]]
> >>> >>> >> >
> >>> >>> >> >______________________________________________
> >>> >>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >>> >>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >>> >> >PLEASE do read the posting guide
> >>> >>> >> >http://www.R-project.org/posting-guide.html
> >>> >>> >> >and provide commented, minimal, self-contained, reproducible
> code.
> >>> >>> >>
> >>> >>> >>
> >>> >>> >
> >>> >>> >         [[alternative HTML version deleted]]
> >>> >>> >
> >>> >>> > ______________________________________________
> >>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >>> > PLEASE do read the posting guide
> >>> >>> > http://www.R-project.org/posting-guide.html
> >>> >>> > and provide commented, minimal, self-contained, reproducible
> code.
> >>> >>
> >>> >>
> >>
> >>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Mar 22 16:41:43 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 22 Mar 2015 08:41:43 -0700
Subject: [R] My R stopped working
In-Reply-To: <CABGg3O5ToUPWnp-8v-rpACAaOcQZ_78uyig_ZDmLLnMnfCTPNQ@mail.gmail.com>
References: <CABGg3O6ptTPTjWkMD9UyJdtCs=eZf_VhS15bNf2CA_gNCS57Bg@mail.gmail.com>
	<CABGg3O5ToUPWnp-8v-rpACAaOcQZ_78uyig_ZDmLLnMnfCTPNQ@mail.gmail.com>
Message-ID: <669D4055-3495-406B-A34F-58AB7DB89EA0@dcn.davis.CA.us>

You could use a search engine to find other people's solutions to this problem. Or you could just try again.

Unfortunately, if you want help here, your explanation is simply too brief. The normal expectation here is that you provide a reproducible example. Since R works by accepting text commands, that means give us the sequence of commands you used starting from a freshly opened R session that lead to the problem. Also give us an abbreviated amount of data to work with. Please post using plain text email, since the HTML you used to post this question usually messes up the R code by the time it gets to us.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 22, 2015 2:11:29 AM PDT, adeela uaf <adeela.uaf at gmail.com> wrote:
>Hi,
>I was downloading some shape files in R then I use the package lsmeans
>in R
>but I received the message "R for winfows GUI front end has stopped
>working
>" . What I have to do to overcome this problem
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sun Mar 22 17:06:10 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 22 Mar 2015 08:06:10 -0800
Subject: [R] Why can't I access this type?
In-Reply-To: <CAJ=2b04qLmoA8W--=dsv2vqMHkG1Y7Tv_QQx_9D78oopJku+Yg@mail.gmail.com>
Message-ID: <28E315E85F1.00000296jrkrideau@inbox.com>

Well, first off, you have no variable called "Name".  You have lost the state names as they are rownames in the matrix state.x77 and not a variable.

Try this. It's ugly and I have no idea why I had to do a cbind() but it seems to work. Personally I find subset easier to read than the indexing approach.

state  <-  rownames(state.x77)
all.states <- as.data.frame(state.x77)
all.states  <-  cbind(state, all.states) ### ?????

coldstates  <-   subset(all.states, all.states$Frost > 50, 
                        select = c("state","Frost") )


John Kane
Kingston ON Canada


> -----Original Message-----
> From: yoursurrogategod at gmail.com
> Sent: Sun, 22 Mar 2015 10:39:03 -0400
> To: r-help at r-project.org
> Subject: [R] Why can't I access this type?
> 
> Hi, I'm just learning my way around R.  I got a bunch of states and would
> like to access to get all of the ones where it's cold.  But when I do the
> following, I will get the following error:
> 
>> all.states <- as.data.frame(state.x77)
>> cold.states <- all.states[all.states$Frost > 150, c("Name", "Frost")]
> Error in `[.data.frame`(all.states, all.states$Frost > 150, c("Name",  :
>   undefined columns selected
> 
> I don't get it.  When I look at all.states, this is what I see:
> 
>> str(all.states)
> 'data.frame':   50 obs. of  8 variables:
>  $ Population: num  3615 365 2212 2110 21198 ...
>  $ Income    : num  3624 6315 4530 3378 5114 ...
>  $ Illiteracy: num  2.1 1.5 1.8 1.9 1.1 0.7 1.1 0.9 1.3 2 ...
>  $ Life Exp  : num  69 69.3 70.5 70.7 71.7 ...
>  $ Murder    : num  15.1 11.3 7.8 10.1 10.3 6.8 3.1 6.2 10.7 13.9 ...
>  $ HS Grad   : num  41.3 66.7 58.1 39.9 62.6 63.9 56 54.6 52.6 40.6 ...
>  $ Frost     : num  20 152 15 65 20 166 139 103 11 60 ...
>  $ Area      : num  50708 566432 113417 51945 156361 ...
> 
> What am I messing up?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From gunter.berton at gene.com  Sun Mar 22 18:32:13 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 22 Mar 2015 10:32:13 -0700
Subject: [R] Fwd: Joining two datasets - recursive procedure?
In-Reply-To: <CABQyo86r0h_6R2u8cm3Amg0pPnC7b+Tuy9t3zOiNFqmsTa2DEA@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
	<CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
	<CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>
	<CACk-te2CBQXFGJ-Vhr+kpdY6uccbn0Rp286ca+2YvKO=iHUogg@mail.gmail.com>
	<CACk-te0sTVt5pPb9f-ELgTt8L0Bbaz2NCQ9S4ZsB5e122vdYYA@mail.gmail.com>
	<CABQyo86dF4UQH94v1Q-rFMBV=JRmwc3V9SFgG=ZiwtGatKTwPg@mail.gmail.com>
	<CACk-te3xkirW755s1WSETEEj0wvS=d=FneZw4r=dS=jK3RHNcQ@mail.gmail.com>
	<CACk-te22ZaM5p5H7Wz1ivN24S5zog-FY=AvdHQEbdz2O7AL2gA@mail.gmail.com>
	<CABQyo864GFSgDAEgRrf-0TQhrYLufNv96v2q00-YAb4nsVWYyw@mail.gmail.com>
	<CABQyo86r0h_6R2u8cm3Amg0pPnC7b+Tuy9t3zOiNFqmsTa2DEA@mail.gmail.com>
Message-ID: <CACk-te1p_PeLO-rbzxo3MBMYWYfWHTf7FkoNhJ+8XafD6mh2ng@mail.gmail.com>

Nonsense. You are not telling us something or I have failed to
understand something.

Consider:

v1 = c("a","b")
v2 = "c("a","a")

It is not possible to change the value of a sum of values
corresponding to v2="a" without also changing that for v1, which is
not supposed to change according to my understanding of your
specification.

So I'm done.

-- Bert


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Mar 22, 2015 at 8:28 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
> Sorry forgot to keep the rest of the group in the loop - Luca
> ---------- Forwarded message ----------
> From: Luca Meyer <lucam1968 at gmail.com>
> Date: 2015-03-22 16:27 GMT+01:00
> Subject: Re: [R] Joining two datasets - recursive procedure?
> To: Bert Gunter <gunter.berton at gene.com>
>
>
> Hi Bert,
>
> That is exactly what I am trying to achieve. Please notice that negative v4
> values are allowed. I have done a similar task in the past manually by
> recursively alterating v4 distribution across v3 categories within fix each
> v1&v2 combination so I am quite positive it can be achieved but honestly I
> took me forever to do it manually and since this is likely to be an
> exercise I need to repeat from time to time I wish I could learn how to do
> it programmatically....
>
> Thanks again for any further suggestion you might have,
>
> Luca
>
>
> 2015-03-22 16:05 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>
>> Oh, wait a minute ...
>>
>> You still want the marginals for the other columns to be as originally?
>>
>> If so, then this is impossible in general as the sum of all the values
>> must be what they were originally and you cannot therefore choose your
>> values for V3 arbitrarily.
>>
>> Or at least, that seems to be what you are trying to do.
>>
>> -- Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Sun, Mar 22, 2015 at 7:55 AM, Bert Gunter <bgunter at gene.com> wrote:
>> > I would have thought that this is straightforward given my previous
>> email...
>> >
>> > Just set z to what you want -- e,g, all B values to 29/number of B's,
>> > and all C values to 2.567/number of C's (etc. for more categories).
>> >
>> > A slick but sort of cheat way to do this programmatically -- in the
>> > sense that it relies on the implementation of factor() rather than its
>> > API -- is:
>> >
>> > y <- f1$v3  ## to simplify the notation; could be done using with()
>> > z <- (c(29,2.567)/table(y))[c(y)]
>> >
>> > Then proceed to z1 as I previously described
>> >
>> > -- Bert
>> >
>> >
>> > Bert Gunter
>> > Genentech Nonclinical Biostatistics
>> > (650) 467-7374
>> >
>> > "Data is not information. Information is not knowledge. And knowledge
>> > is certainly not wisdom."
>> > Clifford Stoll
>> >
>> >
>> >
>> >
>> > On Sun, Mar 22, 2015 at 2:00 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
>> >> Hi Bert, hello R-experts,
>> >>
>> >> I am close to a solution but I still need one hint w.r.t. the following
>> >> procedure (available also from
>> >> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0)
>> >>
>> >> rm(list=ls())
>> >>
>> >> # this is (an extract of) the INPUT file I have:
>> >> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B", "B",
>> >> "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A", "B", "C", "A",
>> >> "B", "C"), v3 = c("B", "B", "B", "C", "C", "C", "B", "B", "B", "C", "C",
>> >> "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917, 1.05786, 0.00042,
>> 2.37232,
>> >> 3.01835, 0, 1.13430, 0.92872, 0)), .Names = c("v1", "v2", "v3", "v4"),
>> class
>> >> = "data.frame", row.names = c(2L, 9L, 11L, 41L, 48L, 50L, 158L, 165L,
>> 167L,
>> >> 197L, 204L, 206L))
>> >>
>> >> # this is the procedure that Bert suggested (slightly adjusted):
>> >> z <- rnorm(nrow(f1)) ## or anything you want
>> >> z1 <- round(with(f1,v4 + z -ave(z,v1,v2,FUN=mean)), digits=5)
>> >> aggregate(v4~v1*v2,f1,sum)
>> >> aggregate(z1~v1*v2,f1,sum)
>> >> aggregate(v4~v3,f1,sum)
>> >> aggregate(z1~v3,f1,sum)
>> >>
>> >> My question to you is: how can I set z so that I can obtain specific
>> values
>> >> for z1-v4 in the v3 aggregation?
>> >> In other words, how can I configure the procedure so that e.g. B=29 and
>> >> C=2.56723 after running the procedure:
>> >> aggregate(z1~v3,f1,sum)
>> >>
>> >> Thank you,
>> >>
>> >> Luca
>> >>
>> >> PS: to avoid any doubts you might have about who I am the following is
>> my
>> >> web page: http://lucameyer.wordpress.com/
>> >>
>> >>
>> >> 2015-03-21 18:13 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>> >>>
>> >>> ... or cleaner:
>> >>>
>> >>> z1 <- with(f1,v4 + z -ave(z,v1,v2,FUN=mean))
>> >>>
>> >>>
>> >>> Just for curiosity, was this homework? (in which case I should
>> >>> probably have not provided you an answer -- that is, assuming that I
>> >>> HAVE provided an answer).
>> >>>
>> >>> Cheers,
>> >>> Bert
>> >>>
>> >>> Bert Gunter
>> >>> Genentech Nonclinical Biostatistics
>> >>> (650) 467-7374
>> >>>
>> >>> "Data is not information. Information is not knowledge. And knowledge
>> >>> is certainly not wisdom."
>> >>> Clifford Stoll
>> >>>
>> >>>
>> >>>
>> >>>
>> >>> On Sat, Mar 21, 2015 at 7:53 AM, Bert Gunter <bgunter at gene.com> wrote:
>> >>> > z <- rnorm(nrow(f1)) ## or anything you want
>> >>> > z1 <- f1$v4 + z - with(f1,ave(z,v1,v2,FUN=mean))
>> >>> >
>> >>> >
>> >>> > aggregate(v4~v1,f1,sum)
>> >>> > aggregate(z1~v1,f1,sum)
>> >>> > aggregate(v4~v2,f1,sum)
>> >>> > aggregate(z1~v2,f1,sum)
>> >>> > aggregate(v4~v3,f1,sum)
>> >>> > aggregate(z1~v3,f1,sum)
>> >>> >
>> >>> >
>> >>> > Cheers,
>> >>> > Bert
>> >>> >
>> >>> > Bert Gunter
>> >>> > Genentech Nonclinical Biostatistics
>> >>> > (650) 467-7374
>> >>> >
>> >>> > "Data is not information. Information is not knowledge. And knowledge
>> >>> > is certainly not wisdom."
>> >>> > Clifford Stoll
>> >>> >
>> >>> >
>> >>> >
>> >>> >
>> >>> > On Sat, Mar 21, 2015 at 6:49 AM, Luca Meyer <lucam1968 at gmail.com>
>> wrote:
>> >>> >> Hi Bert,
>> >>> >>
>> >>> >> Thank you for your message. I am looking into ave() and tapply() as
>> you
>> >>> >> suggested but at the same time I have prepared a example of input
>> and
>> >>> >> output
>> >>> >> files, just in case you or someone else would like to make an
>> attempt
>> >>> >> to
>> >>> >> generate a code that goes from input to output.
>> >>> >>
>> >>> >> Please see below or download it from
>> >>> >> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
>> >>> >>
>> >>> >> # this is (an extract of) the INPUT file I have:
>> >>> >> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>> >>> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>> >>> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>> >>> >> "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273,
>> >>> >> 1.42917,
>> >>> >> 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
>> >>> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>> >>> >> row.names =
>> >>> >> c(2L,
>> >>> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>> >>> >>
>> >>> >> # this is (an extract of) the OUTPUT file I would like to obtain:
>> >>> >> f2 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>> >>> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>> >>> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>> >>> >> "B", "B", "B", "C", "C", "C"), v4 = c(17.83529, 3.43806,0.00295,
>> >>> >> 1.77918,
>> >>> >> 1.05786, 0.0002, 2.37232, 3.01835, 0, 1.13430, 0.92872,
>> >>> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>> >>> >> row.names =
>> >>> >> c(2L,
>> >>> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>> >>> >>
>> >>> >> # please notice that while the aggregated v4 on v3 has changed ?
>> >>> >> aggregate(f1[,c("v4")],list(f1$v3),sum)
>> >>> >> aggregate(f2[,c("v4")],list(f2$v3),sum)
>> >>> >>
>> >>> >> # ? the aggregated v4 over v1xv2 has remained unchanged:
>> >>> >> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>> >>> >> aggregate(f2[,c("v4")],list(f2$v1,f2$v2),sum)
>> >>> >>
>> >>> >> Thank you very much in advance for your assitance.
>> >>> >>
>> >>> >> Luca
>> >>> >>
>> >>> >> 2015-03-21 13:18 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>> >>> >>>
>> >>> >>> 1. Still not sure what you mean, but maybe look at ?ave and
>> ?tapply,
>> >>> >>> for which ave() is a wrapper.
>> >>> >>>
>> >>> >>> 2. You still need to heed the rest of Jeff's advice.
>> >>> >>>
>> >>> >>> Cheers,
>> >>> >>> Bert
>> >>> >>>
>> >>> >>> Bert Gunter
>> >>> >>> Genentech Nonclinical Biostatistics
>> >>> >>> (650) 467-7374
>> >>> >>>
>> >>> >>> "Data is not information. Information is not knowledge. And
>> knowledge
>> >>> >>> is certainly not wisdom."
>> >>> >>> Clifford Stoll
>> >>> >>>
>> >>> >>>
>> >>> >>>
>> >>> >>>
>> >>> >>> On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <lucam1968 at gmail.com>
>> >>> >>> wrote:
>> >>> >>> > Hi Jeff & other R-experts,
>> >>> >>> >
>> >>> >>> > Thank you for your note. I have tried myself to solve the issue
>> >>> >>> > without
>> >>> >>> > success.
>> >>> >>> >
>> >>> >>> > Following your suggestion, I am providing a sample of the
>> dataset I
>> >>> >>> > am
>> >>> >>> > using below (also downloadble in plain text from
>> >>> >>> > https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
>> >>> >>> >
>> >>> >>> > #this is an extract of the overall dataset (n=1200 cases)
>> >>> >>> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
>> "B",
>> >>> >>> > "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>> >>> >>> > "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>> >>> >>> > "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835,
>> >>> >>> > 3.43806581506388,
>> >>> >>> > 0.002733567617055, 1.42917483425029, 1.05786640463504,
>> >>> >>> > 0.000420548864162308,
>> >>> >>> > 2.37232740842861, 3.01835841813241, 0, 1.13430282139936,
>> >>> >>> > 0.928725667117666,
>> >>> >>> > 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>> >>> >>> > row.names
>> >>> >>> > =
>> >>> >>> > c(2L,
>> >>> >>> > 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>> >>> >>> >
>> >>> >>> > I need to find a automated procedure that allows me to adjust v3
>> >>> >>> > marginals
>> >>> >>> > while maintaining v1xv2 marginals unchanged.
>> >>> >>> >
>> >>> >>> > That is: modify the v4 values you can find by running:
>> >>> >>> >
>> >>> >>> > aggregate(f1[,c("v4")],list(f1$v3),sum)
>> >>> >>> >
>> >>> >>> > while maintaining costant the values you can find by running:
>> >>> >>> >
>> >>> >>> > aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>> >>> >>> >
>> >>> >>> > Now does it make sense?
>> >>> >>> >
>> >>> >>> > Please notice I have tried to build some syntax that tries to
>> modify
>> >>> >>> > values
>> >>> >>> > within each v1xv2 combination by computing sum of v4, row
>> percentage
>> >>> >>> > in
>> >>> >>> > terms of v4, and there is where my effort is blocked. Not really
>> >>> >>> > sure
>> >>> >>> > how I
>> >>> >>> > should proceed. Any suggestion?
>> >>> >>> >
>> >>> >>> > Thanks,
>> >>> >>> >
>> >>> >>> > Luca
>> >>> >>> >
>> >>> >>> >
>> >>> >>> > 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <
>> jdnewmil at dcn.davis.ca.us>:
>> >>> >>> >
>> >>> >>> >> I don't understand your description. The standard practice on
>> this
>> >>> >>> >> list
>> >>> >>> >> is
>> >>> >>> >> to provide a reproducible R example [1] of the kind of data you
>> are
>> >>> >>> >> working
>> >>> >>> >> with (and any code you have tried) to go along with your
>> >>> >>> >> description.
>> >>> >>> >> In
>> >>> >>> >> this case, that would be two dputs of your input data frames
>> and a
>> >>> >>> >> dput
>> >>> >>> >> of
>> >>> >>> >> an output data frame (generated by hand from your input data
>> >>> >>> >> frame).
>> >>> >>> >> (Probably best to not use the full number of input values just
>> to
>> >>> >>> >> keep
>> >>> >>> >> the
>> >>> >>> >> size down.) We could then make an attempt to generate code that
>> >>> >>> >> goes
>> >>> >>> >> from
>> >>> >>> >> input to output.
>> >>> >>> >>
>> >>> >>> >> Of course, if you post that hard work using HTML then it will
>> get
>> >>> >>> >> corrupted (much like the text below from your earlier emails)
>> and
>> >>> >>> >> we
>> >>> >>> >> won't
>> >>> >>> >> be able to use it. Please learn to post from your email software
>> >>> >>> >> using
>> >>> >>> >> plain text when corresponding with this mailing list.
>> >>> >>> >>
>> >>> >>> >> [1]
>> >>> >>> >>
>> >>> >>> >>
>> >>> >>> >>
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> >>> >>> >>
>> >>> >>> >>
>> >>> >>> >>
>> ---------------------------------------------------------------------------
>> >>> >>> >> Jeff Newmiller                        The     .....
>>  .....  Go
>> >>> >>> >> Live...
>> >>> >>> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
>> >>> >>> >> Live
>> >>> >>> >> Go...
>> >>> >>> >>                                       Live:   OO#.. Dead: OO#..
>> >>> >>> >> Playing
>> >>> >>> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.
>> >>> >>> >> with
>> >>> >>> >> /Software/Embedded Controllers)               .OO#.       .OO#.
>> >>> >>> >> rocks...1k
>> >>> >>> >>
>> >>> >>> >>
>> >>> >>> >>
>> ---------------------------------------------------------------------------
>> >>> >>> >> Sent from my phone. Please excuse my brevity.
>> >>> >>> >>
>> >>> >>> >> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <
>> lucam1968 at gmail.com>
>> >>> >>> >> wrote:
>> >>> >>> >> >Thanks for you input Michael,
>> >>> >>> >> >
>> >>> >>> >> >The continuous variable I have measures quantities (down to the
>> >>> >>> >> > 3rd
>> >>> >>> >> >decimal level) so unfortunately are not frequencies.
>> >>> >>> >> >
>> >>> >>> >> >Any more specific suggestions on how that could be tackled?
>> >>> >>> >> >
>> >>> >>> >> >Thanks & kind regards,
>> >>> >>> >> >
>> >>> >>> >> >Luca
>> >>> >>> >> >
>> >>> >>> >> >
>> >>> >>> >> >===
>> >>> >>> >> >
>> >>> >>> >> >Michael Friendly wrote:
>> >>> >>> >> >I'm not sure I understand completely what you want to do, but
>> >>> >>> >> >if the data were frequencies, it sounds like task for fitting a
>> >>> >>> >> >loglinear model with the model formula
>> >>> >>> >> >
>> >>> >>> >> >~ V1*V2 + V3
>> >>> >>> >> >
>> >>> >>> >> >On 3/18/2015 2:17 AM, Luca Meyer wrote:
>> >>> >>> >> >>* Hello,
>> >>> >>> >> >*>>* I am facing a quite challenging task (at least to me) and
>> I
>> >>> >>> >> > was
>> >>> >>> >> >wondering
>> >>> >>> >> >*>* if someone could advise how R could assist me to speed the
>> >>> >>> >> > task
>> >>> >>> >> > up.
>> >>> >>> >> >*>>* I am dealing with a dataset with 3 discrete variables and
>> one
>> >>> >>> >> >continuous
>> >>> >>> >> >*>* variable. The discrete variables are:
>> >>> >>> >> >*>>* V1: 8 modalities
>> >>> >>> >> >*>* V2: 13 modalities
>> >>> >>> >> >*>* V3: 13 modalities
>> >>> >>> >> >*>>* The continuous variable V4 is a decimal number always
>> greater
>> >>> >>> >> > than
>> >>> >>> >> >zero in
>> >>> >>> >> >*>* the marginals of each of the 3 variables but it is
>> sometimes
>> >>> >>> >> > equal
>> >>> >>> >> >to zero
>> >>> >>> >> >*>* (and sometimes negative) in the joint tables.
>> >>> >>> >> >*>>* I have got 2 files:
>> >>> >>> >> >*>>* => one with distribution of all possible combinations of
>> >>> >>> >> > V1xV2
>> >>> >>> >> >(some of
>> >>> >>> >> >*>* which are zero or neagtive) and
>> >>> >>> >> >*>* => one with the marginal distribution of V3.
>> >>> >>> >> >*>>* I am trying to build the long and narrow dataset V1xV2xV3
>> in
>> >>> >>> >> > such
>> >>> >>> >> >a way
>> >>> >>> >> >*>* that each V1xV2 cell does not get modified and V3 fits as
>> >>> >>> >> > closely
>> >>> >>> >> >as
>> >>> >>> >> >*>* possible to its marginal distribution. Does it make sense?
>> >>> >>> >> >*>>* To be even more specific, my 2 input files look like the
>> >>> >>> >> >following.
>> >>> >>> >> >*>>* FILE 1
>> >>> >>> >> >*>* V1,V2,V4
>> >>> >>> >> >*>* A, A, 24.251
>> >>> >>> >> >*>* A, B, 1.065
>> >>> >>> >> >*>* (...)
>> >>> >>> >> >*>* B, C, 0.294
>> >>> >>> >> >*>* B, D, 2.731
>> >>> >>> >> >*>* (...)
>> >>> >>> >> >*>* H, L, 0.345
>> >>> >>> >> >*>* H, M, 0.000
>> >>> >>> >> >*>>* FILE 2
>> >>> >>> >> >*>* V3, V4
>> >>> >>> >> >*>* A, 1.575
>> >>> >>> >> >*>* B, 4.294
>> >>> >>> >> >*>* C, 10.044
>> >>> >>> >> >*>* (...)
>> >>> >>> >> >*>* L, 5.123
>> >>> >>> >> >*>* M, 3.334
>> >>> >>> >> >*>>* What I need to achieve is a file such as the following
>> >>> >>> >> >*>>* FILE 3
>> >>> >>> >> >*>* V1, V2, V3, V4
>> >>> >>> >> >*>* A, A, A, ???
>> >>> >>> >> >*>* A, A, B, ???
>> >>> >>> >> >*>* (...)
>> >>> >>> >> >*>* D, D, E, ???
>> >>> >>> >> >*>* D, D, F, ???
>> >>> >>> >> >*>* (...)
>> >>> >>> >> >*>* H, M, L, ???
>> >>> >>> >> >*>* H, M, M, ???
>> >>> >>> >> >*>>* Please notice that FILE 3 need to be such that if I
>> aggregate
>> >>> >>> >> > on
>> >>> >>> >> >V1+V2 I
>> >>> >>> >> >*>* recover exactly FILE 1 and that if I aggregate on V3 I can
>> >>> >>> >> > recover
>> >>> >>> >> >a file
>> >>> >>> >> >*>* as close as possible to FILE 3 (ideally the same file).
>> >>> >>> >> >*>>* Can anyone suggest how I could do that with R?
>> >>> >>> >> >*>>* Thank you very much indeed for any assistance you are
>> able to
>> >>> >>> >> >provide.
>> >>> >>> >> >*>>* Kind regards,
>> >>> >>> >> >*>>* Luca*
>> >>> >>> >> >
>> >>> >>> >> >       [[alternative HTML version deleted]]
>> >>> >>> >> >
>> >>> >>> >> >______________________________________________
>> >>> >>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> >>> >>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> >>> >> >PLEASE do read the posting guide
>> >>> >>> >> >http://www.R-project.org/posting-guide.html
>> >>> >>> >> >and provide commented, minimal, self-contained, reproducible
>> code.
>> >>> >>> >>
>> >>> >>> >>
>> >>> >>> >
>> >>> >>> >         [[alternative HTML version deleted]]
>> >>> >>> >
>> >>> >>> > ______________________________________________
>> >>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> >>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> >>> > PLEASE do read the posting guide
>> >>> >>> > http://www.R-project.org/posting-guide.html
>> >>> >>> > and provide commented, minimal, self-contained, reproducible
>> code.
>> >>> >>
>> >>> >>
>> >>
>> >>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lucam1968 at gmail.com  Sun Mar 22 21:12:45 2015
From: lucam1968 at gmail.com (Luca Meyer)
Date: Sun, 22 Mar 2015 21:12:45 +0100
Subject: [R] Fwd: Joining two datasets - recursive procedure?
In-Reply-To: <CACk-te1p_PeLO-rbzxo3MBMYWYfWHTf7FkoNhJ+8XafD6mh2ng@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
	<CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
	<CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>
	<CACk-te2CBQXFGJ-Vhr+kpdY6uccbn0Rp286ca+2YvKO=iHUogg@mail.gmail.com>
	<CACk-te0sTVt5pPb9f-ELgTt8L0Bbaz2NCQ9S4ZsB5e122vdYYA@mail.gmail.com>
	<CABQyo86dF4UQH94v1Q-rFMBV=JRmwc3V9SFgG=ZiwtGatKTwPg@mail.gmail.com>
	<CACk-te3xkirW755s1WSETEEj0wvS=d=FneZw4r=dS=jK3RHNcQ@mail.gmail.com>
	<CACk-te22ZaM5p5H7Wz1ivN24S5zog-FY=AvdHQEbdz2O7AL2gA@mail.gmail.com>
	<CABQyo864GFSgDAEgRrf-0TQhrYLufNv96v2q00-YAb4nsVWYyw@mail.gmail.com>
	<CABQyo86r0h_6R2u8cm3Amg0pPnC7b+Tuy9t3zOiNFqmsTa2DEA@mail.gmail.com>
	<CACk-te1p_PeLO-rbzxo3MBMYWYfWHTf7FkoNhJ+8XafD6mh2ng@mail.gmail.com>
Message-ID: <CABQyo85jd5xyecoBncF6QesE+YgHLTiv6xHAiVmziWVxY=Oijw@mail.gmail.com>

Hi Bert,

Maybe I did not explain myself clearly enough. But let me show you with a
manual example that indeed what I would like to do is feasible.

The following is also available for download from
https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0

rm(list=ls())

This is usual (an extract of) the INPUT file I have:

f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
"B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
"B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
"B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917,
1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names =
c(2L,
9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))

This are the initial marginal distributions

aggregate(v4~v1*v2,f1,sum)
aggregate(v4~v3,f1,sum)

First I order the file such that I have nicely listed 6 distinct v1xv2
combinations.

f1 <- f1[order(f1$v1,f1$v2),]

Then I compute (manually) the relative importance of each v1xv2 combination:

tAA <-
(18.18530+1.42917)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
# this is for combination v1=A & v2=A
tAB <-
(3.43806+1.05786)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
# this is for combination v1=A & v2=B
tAC <-
(0.00273+0.00042)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
# this is for combination v1=A & v2=C
tBA <-
(2.37232+1.13430)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
# this is for combination v1=B & v2=A
tBB <-
(3.01835+0.92872)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
# this is for combination v1=B & v2=B
tBC <-
(0.00000+0.00000)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
# this is for combination v1=B & v2=C
# and just to make sure I have not made mistakes the following should be
equal to 1
tAA+tAB+tAC+tBA+tBB+tBC

Next, I know I need to increase v4 any time v3=B and the total increase I
need to have over the whole dataset is 29-27.01676=1.98324. In turn, I need
to dimish v4 any time V3=C by the same amount (4.55047-2.56723=1.98324).
This aspect was perhaps not clear at first. I need to move v4 across v3
categories, but the totals will always remain unchanged.

Since I want the data alteration to be proportional to the v1xv2
combinations I do the following:

f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="A" & f1$v3=="B", f1$v4+(tAA*1.98324),
f1$v4)
f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="A" & f1$v3=="C", f1$v4-(tAA*1.98324),
f1$v4)
f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="B" & f1$v3=="B", f1$v4+(tAB*1.98324),
f1$v4)
f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="B" & f1$v3=="C", f1$v4-(tAB*1.98324),
f1$v4)
f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="C" & f1$v3=="B", f1$v4+(tAC*1.98324),
f1$v4)
f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="C" & f1$v3=="C", f1$v4-(tAC*1.98324),
f1$v4)
f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="A" & f1$v3=="B", f1$v4+(tBA*1.98324),
f1$v4)
f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="A" & f1$v3=="C", f1$v4-(tBA*1.98324),
f1$v4)
f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="B" & f1$v3=="B", f1$v4+(tBB*1.98324),
f1$v4)
f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="B" & f1$v3=="C", f1$v4-(tBB*1.98324),
f1$v4)
f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="C" & f1$v3=="B", f1$v4+(tBC*1.98324),
f1$v4)
f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="C" & f1$v3=="C", f1$v4-(tBC*1.98324),
f1$v4)

This are the final marginal distributions:

aggregate(v4~v1*v2,f1,sum)
aggregate(v4~v3,f1,sum)

Can this procedure be made programmatic so that I can run it on the
(8x13x13) categories matrix? if so, how would you do it? I have really hard
time to do it with some (semi)automatic procedure.

Thank you very much indeed once more :)

Luca


2015-03-22 18:32 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:

> Nonsense. You are not telling us something or I have failed to
> understand something.
>
> Consider:
>
> v1 = c("a","b")
> v2 = "c("a","a")
>
> It is not possible to change the value of a sum of values
> corresponding to v2="a" without also changing that for v1, which is
> not supposed to change according to my understanding of your
> specification.
>
> So I'm done.
>
> -- Bert
>
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sun, Mar 22, 2015 at 8:28 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
> > Sorry forgot to keep the rest of the group in the loop - Luca
> > ---------- Forwarded message ----------
> > From: Luca Meyer <lucam1968 at gmail.com>
> > Date: 2015-03-22 16:27 GMT+01:00
> > Subject: Re: [R] Joining two datasets - recursive procedure?
> > To: Bert Gunter <gunter.berton at gene.com>
> >
> >
> > Hi Bert,
> >
> > That is exactly what I am trying to achieve. Please notice that negative
> v4
> > values are allowed. I have done a similar task in the past manually by
> > recursively alterating v4 distribution across v3 categories within fix
> each
> > v1&v2 combination so I am quite positive it can be achieved but honestly
> I
> > took me forever to do it manually and since this is likely to be an
> > exercise I need to repeat from time to time I wish I could learn how to
> do
> > it programmatically....
> >
> > Thanks again for any further suggestion you might have,
> >
> > Luca
> >
> >
> > 2015-03-22 16:05 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
> >
> >> Oh, wait a minute ...
> >>
> >> You still want the marginals for the other columns to be as originally?
> >>
> >> If so, then this is impossible in general as the sum of all the values
> >> must be what they were originally and you cannot therefore choose your
> >> values for V3 arbitrarily.
> >>
> >> Or at least, that seems to be what you are trying to do.
> >>
> >> -- Bert
> >>
> >> Bert Gunter
> >> Genentech Nonclinical Biostatistics
> >> (650) 467-7374
> >>
> >> "Data is not information. Information is not knowledge. And knowledge
> >> is certainly not wisdom."
> >> Clifford Stoll
> >>
> >>
> >>
> >>
> >> On Sun, Mar 22, 2015 at 7:55 AM, Bert Gunter <bgunter at gene.com> wrote:
> >> > I would have thought that this is straightforward given my previous
> >> email...
> >> >
> >> > Just set z to what you want -- e,g, all B values to 29/number of B's,
> >> > and all C values to 2.567/number of C's (etc. for more categories).
> >> >
> >> > A slick but sort of cheat way to do this programmatically -- in the
> >> > sense that it relies on the implementation of factor() rather than its
> >> > API -- is:
> >> >
> >> > y <- f1$v3  ## to simplify the notation; could be done using with()
> >> > z <- (c(29,2.567)/table(y))[c(y)]
> >> >
> >> > Then proceed to z1 as I previously described
> >> >
> >> > -- Bert
> >> >
> >> >
> >> > Bert Gunter
> >> > Genentech Nonclinical Biostatistics
> >> > (650) 467-7374
> >> >
> >> > "Data is not information. Information is not knowledge. And knowledge
> >> > is certainly not wisdom."
> >> > Clifford Stoll
> >> >
> >> >
> >> >
> >> >
> >> > On Sun, Mar 22, 2015 at 2:00 AM, Luca Meyer <lucam1968 at gmail.com>
> wrote:
> >> >> Hi Bert, hello R-experts,
> >> >>
> >> >> I am close to a solution but I still need one hint w.r.t. the
> following
> >> >> procedure (available also from
> >> >> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0)
> >> >>
> >> >> rm(list=ls())
> >> >>
> >> >> # this is (an extract of) the INPUT file I have:
> >> >> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> "B",
> >> >> "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A", "B", "C",
> "A",
> >> >> "B", "C"), v3 = c("B", "B", "B", "C", "C", "C", "B", "B", "B", "C",
> "C",
> >> >> "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917, 1.05786, 0.00042,
> >> 2.37232,
> >> >> 3.01835, 0, 1.13430, 0.92872, 0)), .Names = c("v1", "v2", "v3",
> "v4"),
> >> class
> >> >> = "data.frame", row.names = c(2L, 9L, 11L, 41L, 48L, 50L, 158L, 165L,
> >> 167L,
> >> >> 197L, 204L, 206L))
> >> >>
> >> >> # this is the procedure that Bert suggested (slightly adjusted):
> >> >> z <- rnorm(nrow(f1)) ## or anything you want
> >> >> z1 <- round(with(f1,v4 + z -ave(z,v1,v2,FUN=mean)), digits=5)
> >> >> aggregate(v4~v1*v2,f1,sum)
> >> >> aggregate(z1~v1*v2,f1,sum)
> >> >> aggregate(v4~v3,f1,sum)
> >> >> aggregate(z1~v3,f1,sum)
> >> >>
> >> >> My question to you is: how can I set z so that I can obtain specific
> >> values
> >> >> for z1-v4 in the v3 aggregation?
> >> >> In other words, how can I configure the procedure so that e.g. B=29
> and
> >> >> C=2.56723 after running the procedure:
> >> >> aggregate(z1~v3,f1,sum)
> >> >>
> >> >> Thank you,
> >> >>
> >> >> Luca
> >> >>
> >> >> PS: to avoid any doubts you might have about who I am the following
> is
> >> my
> >> >> web page: http://lucameyer.wordpress.com/
> >> >>
> >> >>
> >> >> 2015-03-21 18:13 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
> >> >>>
> >> >>> ... or cleaner:
> >> >>>
> >> >>> z1 <- with(f1,v4 + z -ave(z,v1,v2,FUN=mean))
> >> >>>
> >> >>>
> >> >>> Just for curiosity, was this homework? (in which case I should
> >> >>> probably have not provided you an answer -- that is, assuming that I
> >> >>> HAVE provided an answer).
> >> >>>
> >> >>> Cheers,
> >> >>> Bert
> >> >>>
> >> >>> Bert Gunter
> >> >>> Genentech Nonclinical Biostatistics
> >> >>> (650) 467-7374
> >> >>>
> >> >>> "Data is not information. Information is not knowledge. And
> knowledge
> >> >>> is certainly not wisdom."
> >> >>> Clifford Stoll
> >> >>>
> >> >>>
> >> >>>
> >> >>>
> >> >>> On Sat, Mar 21, 2015 at 7:53 AM, Bert Gunter <bgunter at gene.com>
> wrote:
> >> >>> > z <- rnorm(nrow(f1)) ## or anything you want
> >> >>> > z1 <- f1$v4 + z - with(f1,ave(z,v1,v2,FUN=mean))
> >> >>> >
> >> >>> >
> >> >>> > aggregate(v4~v1,f1,sum)
> >> >>> > aggregate(z1~v1,f1,sum)
> >> >>> > aggregate(v4~v2,f1,sum)
> >> >>> > aggregate(z1~v2,f1,sum)
> >> >>> > aggregate(v4~v3,f1,sum)
> >> >>> > aggregate(z1~v3,f1,sum)
> >> >>> >
> >> >>> >
> >> >>> > Cheers,
> >> >>> > Bert
> >> >>> >
> >> >>> > Bert Gunter
> >> >>> > Genentech Nonclinical Biostatistics
> >> >>> > (650) 467-7374
> >> >>> >
> >> >>> > "Data is not information. Information is not knowledge. And
> knowledge
> >> >>> > is certainly not wisdom."
> >> >>> > Clifford Stoll
> >> >>> >
> >> >>> >
> >> >>> >
> >> >>> >
> >> >>> > On Sat, Mar 21, 2015 at 6:49 AM, Luca Meyer <lucam1968 at gmail.com>
> >> wrote:
> >> >>> >> Hi Bert,
> >> >>> >>
> >> >>> >> Thank you for your message. I am looking into ave() and tapply()
> as
> >> you
> >> >>> >> suggested but at the same time I have prepared a example of input
> >> and
> >> >>> >> output
> >> >>> >> files, just in case you or someone else would like to make an
> >> attempt
> >> >>> >> to
> >> >>> >> generate a code that goes from input to output.
> >> >>> >>
> >> >>> >> Please see below or download it from
> >> >>> >> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
> >> >>> >>
> >> >>> >> # this is (an extract of) the INPUT file I have:
> >> >>> >> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
> "B",
> >> >>> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >> >>> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >> >>> >> "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273,
> >> >>> >> 1.42917,
> >> >>> >> 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> >> >>> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> >> >>> >> row.names =
> >> >>> >> c(2L,
> >> >>> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >> >>> >>
> >> >>> >> # this is (an extract of) the OUTPUT file I would like to obtain:
> >> >>> >> f2 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
> "B",
> >> >>> >> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >> >>> >> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >> >>> >> "B", "B", "B", "C", "C", "C"), v4 = c(17.83529, 3.43806,0.00295,
> >> >>> >> 1.77918,
> >> >>> >> 1.05786, 0.0002, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> >> >>> >> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> >> >>> >> row.names =
> >> >>> >> c(2L,
> >> >>> >> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >> >>> >>
> >> >>> >> # please notice that while the aggregated v4 on v3 has changed ?
> >> >>> >> aggregate(f1[,c("v4")],list(f1$v3),sum)
> >> >>> >> aggregate(f2[,c("v4")],list(f2$v3),sum)
> >> >>> >>
> >> >>> >> # ? the aggregated v4 over v1xv2 has remained unchanged:
> >> >>> >> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
> >> >>> >> aggregate(f2[,c("v4")],list(f2$v1,f2$v2),sum)
> >> >>> >>
> >> >>> >> Thank you very much in advance for your assitance.
> >> >>> >>
> >> >>> >> Luca
> >> >>> >>
> >> >>> >> 2015-03-21 13:18 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
> >> >>> >>>
> >> >>> >>> 1. Still not sure what you mean, but maybe look at ?ave and
> >> ?tapply,
> >> >>> >>> for which ave() is a wrapper.
> >> >>> >>>
> >> >>> >>> 2. You still need to heed the rest of Jeff's advice.
> >> >>> >>>
> >> >>> >>> Cheers,
> >> >>> >>> Bert
> >> >>> >>>
> >> >>> >>> Bert Gunter
> >> >>> >>> Genentech Nonclinical Biostatistics
> >> >>> >>> (650) 467-7374
> >> >>> >>>
> >> >>> >>> "Data is not information. Information is not knowledge. And
> >> knowledge
> >> >>> >>> is certainly not wisdom."
> >> >>> >>> Clifford Stoll
> >> >>> >>>
> >> >>> >>>
> >> >>> >>>
> >> >>> >>>
> >> >>> >>> On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <
> lucam1968 at gmail.com>
> >> >>> >>> wrote:
> >> >>> >>> > Hi Jeff & other R-experts,
> >> >>> >>> >
> >> >>> >>> > Thank you for your note. I have tried myself to solve the
> issue
> >> >>> >>> > without
> >> >>> >>> > success.
> >> >>> >>> >
> >> >>> >>> > Following your suggestion, I am providing a sample of the
> >> dataset I
> >> >>> >>> > am
> >> >>> >>> > using below (also downloadble in plain text from
> >> >>> >>> >
> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
> >> >>> >>> >
> >> >>> >>> > #this is an extract of the overall dataset (n=1200 cases)
> >> >>> >>> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
> >> "B",
> >> >>> >>> > "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >> >>> >>> > "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >> >>> >>> > "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835,
> >> >>> >>> > 3.43806581506388,
> >> >>> >>> > 0.002733567617055, 1.42917483425029, 1.05786640463504,
> >> >>> >>> > 0.000420548864162308,
> >> >>> >>> > 2.37232740842861, 3.01835841813241, 0, 1.13430282139936,
> >> >>> >>> > 0.928725667117666,
> >> >>> >>> > 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> >> >>> >>> > row.names
> >> >>> >>> > =
> >> >>> >>> > c(2L,
> >> >>> >>> > 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >> >>> >>> >
> >> >>> >>> > I need to find a automated procedure that allows me to adjust
> v3
> >> >>> >>> > marginals
> >> >>> >>> > while maintaining v1xv2 marginals unchanged.
> >> >>> >>> >
> >> >>> >>> > That is: modify the v4 values you can find by running:
> >> >>> >>> >
> >> >>> >>> > aggregate(f1[,c("v4")],list(f1$v3),sum)
> >> >>> >>> >
> >> >>> >>> > while maintaining costant the values you can find by running:
> >> >>> >>> >
> >> >>> >>> > aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
> >> >>> >>> >
> >> >>> >>> > Now does it make sense?
> >> >>> >>> >
> >> >>> >>> > Please notice I have tried to build some syntax that tries to
> >> modify
> >> >>> >>> > values
> >> >>> >>> > within each v1xv2 combination by computing sum of v4, row
> >> percentage
> >> >>> >>> > in
> >> >>> >>> > terms of v4, and there is where my effort is blocked. Not
> really
> >> >>> >>> > sure
> >> >>> >>> > how I
> >> >>> >>> > should proceed. Any suggestion?
> >> >>> >>> >
> >> >>> >>> > Thanks,
> >> >>> >>> >
> >> >>> >>> > Luca
> >> >>> >>> >
> >> >>> >>> >
> >> >>> >>> > 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <
> >> jdnewmil at dcn.davis.ca.us>:
> >> >>> >>> >
> >> >>> >>> >> I don't understand your description. The standard practice on
> >> this
> >> >>> >>> >> list
> >> >>> >>> >> is
> >> >>> >>> >> to provide a reproducible R example [1] of the kind of data
> you
> >> are
> >> >>> >>> >> working
> >> >>> >>> >> with (and any code you have tried) to go along with your
> >> >>> >>> >> description.
> >> >>> >>> >> In
> >> >>> >>> >> this case, that would be two dputs of your input data frames
> >> and a
> >> >>> >>> >> dput
> >> >>> >>> >> of
> >> >>> >>> >> an output data frame (generated by hand from your input data
> >> >>> >>> >> frame).
> >> >>> >>> >> (Probably best to not use the full number of input values
> just
> >> to
> >> >>> >>> >> keep
> >> >>> >>> >> the
> >> >>> >>> >> size down.) We could then make an attempt to generate code
> that
> >> >>> >>> >> goes
> >> >>> >>> >> from
> >> >>> >>> >> input to output.
> >> >>> >>> >>
> >> >>> >>> >> Of course, if you post that hard work using HTML then it will
> >> get
> >> >>> >>> >> corrupted (much like the text below from your earlier emails)
> >> and
> >> >>> >>> >> we
> >> >>> >>> >> won't
> >> >>> >>> >> be able to use it. Please learn to post from your email
> software
> >> >>> >>> >> using
> >> >>> >>> >> plain text when corresponding with this mailing list.
> >> >>> >>> >>
> >> >>> >>> >> [1]
> >> >>> >>> >>
> >> >>> >>> >>
> >> >>> >>> >>
> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >> >>> >>> >>
> >> >>> >>> >>
> >> >>> >>> >>
> >>
> ---------------------------------------------------------------------------
> >> >>> >>> >> Jeff Newmiller                        The     .....
> >>  .....  Go
> >> >>> >>> >> Live...
> >> >>> >>> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.
>  ##.#.
> >> >>> >>> >> Live
> >> >>> >>> >> Go...
> >> >>> >>> >>                                       Live:   OO#.. Dead:
> OO#..
> >> >>> >>> >> Playing
> >> >>> >>> >> Research Engineer (Solar/Batteries            O.O#.
>  #.O#.
> >> >>> >>> >> with
> >> >>> >>> >> /Software/Embedded Controllers)               .OO#.
>  .OO#.
> >> >>> >>> >> rocks...1k
> >> >>> >>> >>
> >> >>> >>> >>
> >> >>> >>> >>
> >>
> ---------------------------------------------------------------------------
> >> >>> >>> >> Sent from my phone. Please excuse my brevity.
> >> >>> >>> >>
> >> >>> >>> >> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <
> >> lucam1968 at gmail.com>
> >> >>> >>> >> wrote:
> >> >>> >>> >> >Thanks for you input Michael,
> >> >>> >>> >> >
> >> >>> >>> >> >The continuous variable I have measures quantities (down to
> the
> >> >>> >>> >> > 3rd
> >> >>> >>> >> >decimal level) so unfortunately are not frequencies.
> >> >>> >>> >> >
> >> >>> >>> >> >Any more specific suggestions on how that could be tackled?
> >> >>> >>> >> >
> >> >>> >>> >> >Thanks & kind regards,
> >> >>> >>> >> >
> >> >>> >>> >> >Luca
> >> >>> >>> >> >
> >> >>> >>> >> >
> >> >>> >>> >> >===
> >> >>> >>> >> >
> >> >>> >>> >> >Michael Friendly wrote:
> >> >>> >>> >> >I'm not sure I understand completely what you want to do,
> but
> >> >>> >>> >> >if the data were frequencies, it sounds like task for
> fitting a
> >> >>> >>> >> >loglinear model with the model formula
> >> >>> >>> >> >
> >> >>> >>> >> >~ V1*V2 + V3
> >> >>> >>> >> >
> >> >>> >>> >> >On 3/18/2015 2:17 AM, Luca Meyer wrote:
> >> >>> >>> >> >>* Hello,
> >> >>> >>> >> >*>>* I am facing a quite challenging task (at least to me)
> and
> >> I
> >> >>> >>> >> > was
> >> >>> >>> >> >wondering
> >> >>> >>> >> >*>* if someone could advise how R could assist me to speed
> the
> >> >>> >>> >> > task
> >> >>> >>> >> > up.
> >> >>> >>> >> >*>>* I am dealing with a dataset with 3 discrete variables
> and
> >> one
> >> >>> >>> >> >continuous
> >> >>> >>> >> >*>* variable. The discrete variables are:
> >> >>> >>> >> >*>>* V1: 8 modalities
> >> >>> >>> >> >*>* V2: 13 modalities
> >> >>> >>> >> >*>* V3: 13 modalities
> >> >>> >>> >> >*>>* The continuous variable V4 is a decimal number always
> >> greater
> >> >>> >>> >> > than
> >> >>> >>> >> >zero in
> >> >>> >>> >> >*>* the marginals of each of the 3 variables but it is
> >> sometimes
> >> >>> >>> >> > equal
> >> >>> >>> >> >to zero
> >> >>> >>> >> >*>* (and sometimes negative) in the joint tables.
> >> >>> >>> >> >*>>* I have got 2 files:
> >> >>> >>> >> >*>>* => one with distribution of all possible combinations
> of
> >> >>> >>> >> > V1xV2
> >> >>> >>> >> >(some of
> >> >>> >>> >> >*>* which are zero or neagtive) and
> >> >>> >>> >> >*>* => one with the marginal distribution of V3.
> >> >>> >>> >> >*>>* I am trying to build the long and narrow dataset
> V1xV2xV3
> >> in
> >> >>> >>> >> > such
> >> >>> >>> >> >a way
> >> >>> >>> >> >*>* that each V1xV2 cell does not get modified and V3 fits
> as
> >> >>> >>> >> > closely
> >> >>> >>> >> >as
> >> >>> >>> >> >*>* possible to its marginal distribution. Does it make
> sense?
> >> >>> >>> >> >*>>* To be even more specific, my 2 input files look like
> the
> >> >>> >>> >> >following.
> >> >>> >>> >> >*>>* FILE 1
> >> >>> >>> >> >*>* V1,V2,V4
> >> >>> >>> >> >*>* A, A, 24.251
> >> >>> >>> >> >*>* A, B, 1.065
> >> >>> >>> >> >*>* (...)
> >> >>> >>> >> >*>* B, C, 0.294
> >> >>> >>> >> >*>* B, D, 2.731
> >> >>> >>> >> >*>* (...)
> >> >>> >>> >> >*>* H, L, 0.345
> >> >>> >>> >> >*>* H, M, 0.000
> >> >>> >>> >> >*>>* FILE 2
> >> >>> >>> >> >*>* V3, V4
> >> >>> >>> >> >*>* A, 1.575
> >> >>> >>> >> >*>* B, 4.294
> >> >>> >>> >> >*>* C, 10.044
> >> >>> >>> >> >*>* (...)
> >> >>> >>> >> >*>* L, 5.123
> >> >>> >>> >> >*>* M, 3.334
> >> >>> >>> >> >*>>* What I need to achieve is a file such as the following
> >> >>> >>> >> >*>>* FILE 3
> >> >>> >>> >> >*>* V1, V2, V3, V4
> >> >>> >>> >> >*>* A, A, A, ???
> >> >>> >>> >> >*>* A, A, B, ???
> >> >>> >>> >> >*>* (...)
> >> >>> >>> >> >*>* D, D, E, ???
> >> >>> >>> >> >*>* D, D, F, ???
> >> >>> >>> >> >*>* (...)
> >> >>> >>> >> >*>* H, M, L, ???
> >> >>> >>> >> >*>* H, M, M, ???
> >> >>> >>> >> >*>>* Please notice that FILE 3 need to be such that if I
> >> aggregate
> >> >>> >>> >> > on
> >> >>> >>> >> >V1+V2 I
> >> >>> >>> >> >*>* recover exactly FILE 1 and that if I aggregate on V3 I
> can
> >> >>> >>> >> > recover
> >> >>> >>> >> >a file
> >> >>> >>> >> >*>* as close as possible to FILE 3 (ideally the same file).
> >> >>> >>> >> >*>>* Can anyone suggest how I could do that with R?
> >> >>> >>> >> >*>>* Thank you very much indeed for any assistance you are
> >> able to
> >> >>> >>> >> >provide.
> >> >>> >>> >> >*>>* Kind regards,
> >> >>> >>> >> >*>>* Luca*
> >> >>> >>> >> >
> >> >>> >>> >> >       [[alternative HTML version deleted]]
> >> >>> >>> >> >
> >> >>> >>> >> >______________________________________________
> >> >>> >>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> more,
> >> see
> >> >>> >>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> >>> >> >PLEASE do read the posting guide
> >> >>> >>> >> >http://www.R-project.org/posting-guide.html
> >> >>> >>> >> >and provide commented, minimal, self-contained, reproducible
> >> code.
> >> >>> >>> >>
> >> >>> >>> >>
> >> >>> >>> >
> >> >>> >>> >         [[alternative HTML version deleted]]
> >> >>> >>> >
> >> >>> >>> > ______________________________________________
> >> >>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >> see
> >> >>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> >>> > PLEASE do read the posting guide
> >> >>> >>> > http://www.R-project.org/posting-guide.html
> >> >>> >>> > and provide commented, minimal, self-contained, reproducible
> >> code.
> >> >>> >>
> >> >>> >>
> >> >>
> >> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Mar 22 22:11:51 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 22 Mar 2015 14:11:51 -0700
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <CABQyo85jd5xyecoBncF6QesE+YgHLTiv6xHAiVmziWVxY=Oijw@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
	<CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
	<CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>
	<CACk-te2CBQXFGJ-Vhr+kpdY6uccbn0Rp286ca+2YvKO=iHUogg@mail.gmail.com>
	<CACk-te0sTVt5pPb9f-ELgTt8L0Bbaz2NCQ9S4ZsB5e122vdYYA@mail.gmail.com>
	<CABQyo86dF4UQH94v1Q-rFMBV=JRmwc3V9SFgG=ZiwtGatKTwPg@mail.gmail.com>
	<CACk-te3xkirW755s1WSETEEj0wvS=d=FneZw4r=dS=jK3RHNcQ@mail.gmail.com>
	<CACk-te22ZaM5p5H7Wz1ivN24S5zog-FY=AvdHQEbdz2O7AL2gA@mail.gmail.com>
	<CABQyo864GFSgDAEgRrf-0TQhrYLufNv96v2q00-YAb4nsVWYyw@mail.gmail.com>
	<CABQyo86r0h_6R2u8cm3Amg0pPnC7b+Tuy9t3zOiNFqmsTa2DEA@mail.gmail.com>
	<CACk-te1p_PeLO-rbzxo3MBMYWYfWHTf7FkoNhJ+8XafD6mh2ng@mail.gmail.com>
	<CABQyo85jd5xyecoBncF6QesE+YgHLTiv6xHAiVmziWVxY=Oijw@mail.gmail.com>
Message-ID: <E8907230-83F6-4489-ABBF-6CD2A59EFD9D@comcast.net>


On Mar 22, 2015, at 1:12 PM, Luca Meyer wrote:

> Hi Bert,
> 
> Maybe I did not explain myself clearly enough. But let me show you with a
> manual example that indeed what I would like to do is feasible.
> 
> The following is also available for download from
> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
> 
> rm(list=ls())
> 
> This is usual (an extract of) the INPUT file I have:
> 
> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917,
> 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names =
> c(2L,
> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> 
> This are the initial marginal distributions
> 
> aggregate(v4~v1*v2,f1,sum)
> aggregate(v4~v3,f1,sum)
> 
> First I order the file such that I have nicely listed 6 distinct v1xv2
> combinations.
> 
> f1 <- f1[order(f1$v1,f1$v2),]
> 
> Then I compute (manually) the relative importance of each v1xv2 combination:
> 
> tAA <-
> (18.18530+1.42917)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> # this is for combination v1=A & v2=A
> tAB <-
> (3.43806+1.05786)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> # this is for combination v1=A & v2=B
> tAC <-
> (0.00273+0.00042)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> # this is for combination v1=A & v2=C
> tBA <-
> (2.37232+1.13430)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> # this is for combination v1=B & v2=A
> tBB <-
> (3.01835+0.92872)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> # this is for combination v1=B & v2=B
> tBC <-
> (0.00000+0.00000)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> # this is for combination v1=B & v2=C
> # and just to make sure I have not made mistakes the following should be
> equal to 1
> tAA+tAB+tAC+tBA+tBB+tBC
> 
> Next, I know I need to increase v4 any time v3=B and the total increase I
> need to have over the whole dataset is 29-27.01676=1.98324. In turn, I need
> to dimish v4 any time V3=C by the same amount (4.55047-2.56723=1.98324).
> This aspect was perhaps not clear at first. I need to move v4 across v3
> categories, but the totals will always remain unchanged.
> 
> Since I want the data alteration to be proportional to the v1xv2
> combinations I do the following:
> 
> f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="A" & f1$v3=="B", f1$v4+(tAA*1.98324),
> f1$v4)
> f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="A" & f1$v3=="C", f1$v4-(tAA*1.98324),
> f1$v4)
> f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="B" & f1$v3=="B", f1$v4+(tAB*1.98324),
> f1$v4)
> f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="B" & f1$v3=="C", f1$v4-(tAB*1.98324),
> f1$v4)
> f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="C" & f1$v3=="B", f1$v4+(tAC*1.98324),
> f1$v4)
> f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="C" & f1$v3=="C", f1$v4-(tAC*1.98324),
> f1$v4)
> f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="A" & f1$v3=="B", f1$v4+(tBA*1.98324),
> f1$v4)
> f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="A" & f1$v3=="C", f1$v4-(tBA*1.98324),
> f1$v4)
> f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="B" & f1$v3=="B", f1$v4+(tBB*1.98324),
> f1$v4)
> f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="B" & f1$v3=="C", f1$v4-(tBB*1.98324),
> f1$v4)
> f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="C" & f1$v3=="B", f1$v4+(tBC*1.98324),
> f1$v4)
> f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="C" & f1$v3=="C", f1$v4-(tBC*1.98324),
> f1$v4)
> 

Seems that this could be done a lot more simply with a lookup matrix and ordinary indexing

> lookarr <- array(NA, dim=c(length(unique(f1$v1)),length(unique(f1$v2)),length(unique(f1$v3)) ) , dimnames=list( unique(f1$v1), unique(f1$v2), unique(f1$v3) ) )
> lookarr[] <- c(tAA,tAA,tAB,tAB,tAC,tAC,tBA,tBA,
                 tBB, tBB, tBC, tBC)

> lookarr[ "A","B","C"]
[1] 0.1250369

> lookarr[ with(f1, cbind(v1, v2, v3)) ]
 [1] 6.213554e-01 1.110842e-01 1.424236e-01 1.250369e-01 9.978703e-05
 [6] 0.000000e+00 6.213554e-01 1.110842e-01 1.424236e-01 1.250369e-01
[11] 9.978703e-05 0.000000e+00
> f1$v4mod <- f1$v4*lookarr[ with(f1, cbind(v1,v2,v3)) ]
> f1
    v1 v2 v3       v4        v4mod
2    A  A  B 18.18530 1.129954e+01
41   A  A  C  1.42917 1.587582e-01
9    A  B  B  3.43806 4.896610e-01
48   A  B  C  1.05786 1.322716e-01
11   A  C  B  0.00273 2.724186e-07
50   A  C  C  0.00042 0.000000e+00
158  B  A  B  2.37232 1.474054e+00
197  B  A  C  1.13430 1.260028e-01
165  B  B  B  3.01835 4.298844e-01
204  B  B  C  0.92872 1.161243e-01
167  B  C  B  0.00000 0.000000e+00
206  B  C  C  0.00000 0.000000e+00

-- 
david.


> This are the final marginal distributions:
> 
> aggregate(v4~v1*v2,f1,sum)
> aggregate(v4~v3,f1,sum)
> 
> Can this procedure be made programmatic so that I can run it on the
> (8x13x13) categories matrix? if so, how would you do it? I have really hard
> time to do it with some (semi)automatic procedure.
> 
> Thank you very much indeed once more :)
> 
> Luca
> 
> 
> 2015-03-22 18:32 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
> 
>> Nonsense. You are not telling us something or I have failed to
>> understand something.
>> 
>> Consider:
>> 
>> v1 = c("a","b")
>> v2 = "c("a","a")
>> 
>> It is not possible to change the value of a sum of values
>> corresponding to v2="a" without also changing that for v1, which is
>> not supposed to change according to my understanding of your
>> specification.
>> 
>> So I'm done.
>> 
>> -- Bert
>> 
>> 
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>> 
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>> 
>> 
>> 
>> 
>> On Sun, Mar 22, 2015 at 8:28 AM, Luca Meyer <lucam1968 at gmail.com> wrote:
>>> Sorry forgot to keep the rest of the group in the loop - Luca
>>> ---------- Forwarded message ----------
>>> From: Luca Meyer <lucam1968 at gmail.com>
>>> Date: 2015-03-22 16:27 GMT+01:00
>>> Subject: Re: [R] Joining two datasets - recursive procedure?
>>> To: Bert Gunter <gunter.berton at gene.com>
>>> 
>>> 
>>> Hi Bert,
>>> 
>>> That is exactly what I am trying to achieve. Please notice that negative
>> v4
>>> values are allowed. I have done a similar task in the past manually by
>>> recursively alterating v4 distribution across v3 categories within fix
>> each
>>> v1&v2 combination so I am quite positive it can be achieved but honestly
>> I
>>> took me forever to do it manually and since this is likely to be an
>>> exercise I need to repeat from time to time I wish I could learn how to
>> do
>>> it programmatically....
>>> 
>>> Thanks again for any further suggestion you might have,
>>> 
>>> Luca
>>> 
>>> 
>>> 2015-03-22 16:05 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>>> 
>>>> Oh, wait a minute ...
>>>> 
>>>> You still want the marginals for the other columns to be as originally?
>>>> 
>>>> If so, then this is impossible in general as the sum of all the values
>>>> must be what they were originally and you cannot therefore choose your
>>>> values for V3 arbitrarily.
>>>> 
>>>> Or at least, that seems to be what you are trying to do.
>>>> 
>>>> -- Bert
>>>> 
>>>> Bert Gunter
>>>> Genentech Nonclinical Biostatistics
>>>> (650) 467-7374
>>>> 
>>>> "Data is not information. Information is not knowledge. And knowledge
>>>> is certainly not wisdom."
>>>> Clifford Stoll
>>>> 
>>>> 
>>>> 
>>>> 
>>>> On Sun, Mar 22, 2015 at 7:55 AM, Bert Gunter <bgunter at gene.com> wrote:
>>>>> I would have thought that this is straightforward given my previous
>>>> email...
>>>>> 
>>>>> Just set z to what you want -- e,g, all B values to 29/number of B's,
>>>>> and all C values to 2.567/number of C's (etc. for more categories).
>>>>> 
>>>>> A slick but sort of cheat way to do this programmatically -- in the
>>>>> sense that it relies on the implementation of factor() rather than its
>>>>> API -- is:
>>>>> 
>>>>> y <- f1$v3  ## to simplify the notation; could be done using with()
>>>>> z <- (c(29,2.567)/table(y))[c(y)]
>>>>> 
>>>>> Then proceed to z1 as I previously described
>>>>> 
>>>>> -- Bert
>>>>> 
>>>>> 
>>>>> Bert Gunter
>>>>> Genentech Nonclinical Biostatistics
>>>>> (650) 467-7374
>>>>> 
>>>>> "Data is not information. Information is not knowledge. And knowledge
>>>>> is certainly not wisdom."
>>>>> Clifford Stoll
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> On Sun, Mar 22, 2015 at 2:00 AM, Luca Meyer <lucam1968 at gmail.com>
>> wrote:
>>>>>> Hi Bert, hello R-experts,
>>>>>> 
>>>>>> I am close to a solution but I still need one hint w.r.t. the
>> following
>>>>>> procedure (available also from
>>>>>> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0)
>>>>>> 
>>>>>> rm(list=ls())
>>>>>> 
>>>>>> # this is (an extract of) the INPUT file I have:
>>>>>> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>> "B",
>>>>>> "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A", "B", "C",
>> "A",
>>>>>> "B", "C"), v3 = c("B", "B", "B", "C", "C", "C", "B", "B", "B", "C",
>> "C",
>>>>>> "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917, 1.05786, 0.00042,
>>>> 2.37232,
>>>>>> 3.01835, 0, 1.13430, 0.92872, 0)), .Names = c("v1", "v2", "v3",
>> "v4"),
>>>> class
>>>>>> = "data.frame", row.names = c(2L, 9L, 11L, 41L, 48L, 50L, 158L, 165L,
>>>> 167L,
>>>>>> 197L, 204L, 206L))
>>>>>> 
>>>>>> # this is the procedure that Bert suggested (slightly adjusted):
>>>>>> z <- rnorm(nrow(f1)) ## or anything you want
>>>>>> z1 <- round(with(f1,v4 + z -ave(z,v1,v2,FUN=mean)), digits=5)
>>>>>> aggregate(v4~v1*v2,f1,sum)
>>>>>> aggregate(z1~v1*v2,f1,sum)
>>>>>> aggregate(v4~v3,f1,sum)
>>>>>> aggregate(z1~v3,f1,sum)
>>>>>> 
>>>>>> My question to you is: how can I set z so that I can obtain specific
>>>> values
>>>>>> for z1-v4 in the v3 aggregation?
>>>>>> In other words, how can I configure the procedure so that e.g. B=29
>> and
>>>>>> C=2.56723 after running the procedure:
>>>>>> aggregate(z1~v3,f1,sum)
>>>>>> 
>>>>>> Thank you,
>>>>>> 
>>>>>> Luca
>>>>>> 
>>>>>> PS: to avoid any doubts you might have about who I am the following
>> is
>>>> my
>>>>>> web page: http://lucameyer.wordpress.com/
>>>>>> 
>>>>>> 
>>>>>> 2015-03-21 18:13 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>>>>>>> 
>>>>>>> ... or cleaner:
>>>>>>> 
>>>>>>> z1 <- with(f1,v4 + z -ave(z,v1,v2,FUN=mean))
>>>>>>> 
>>>>>>> 
>>>>>>> Just for curiosity, was this homework? (in which case I should
>>>>>>> probably have not provided you an answer -- that is, assuming that I
>>>>>>> HAVE provided an answer).
>>>>>>> 
>>>>>>> Cheers,
>>>>>>> Bert
>>>>>>> 
>>>>>>> Bert Gunter
>>>>>>> Genentech Nonclinical Biostatistics
>>>>>>> (650) 467-7374
>>>>>>> 
>>>>>>> "Data is not information. Information is not knowledge. And
>> knowledge
>>>>>>> is certainly not wisdom."
>>>>>>> Clifford Stoll
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> On Sat, Mar 21, 2015 at 7:53 AM, Bert Gunter <bgunter at gene.com>
>> wrote:
>>>>>>>> z <- rnorm(nrow(f1)) ## or anything you want
>>>>>>>> z1 <- f1$v4 + z - with(f1,ave(z,v1,v2,FUN=mean))
>>>>>>>> 
>>>>>>>> 
>>>>>>>> aggregate(v4~v1,f1,sum)
>>>>>>>> aggregate(z1~v1,f1,sum)
>>>>>>>> aggregate(v4~v2,f1,sum)
>>>>>>>> aggregate(z1~v2,f1,sum)
>>>>>>>> aggregate(v4~v3,f1,sum)
>>>>>>>> aggregate(z1~v3,f1,sum)
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Cheers,
>>>>>>>> Bert
>>>>>>>> 
>>>>>>>> Bert Gunter
>>>>>>>> Genentech Nonclinical Biostatistics
>>>>>>>> (650) 467-7374
>>>>>>>> 
>>>>>>>> "Data is not information. Information is not knowledge. And
>> knowledge
>>>>>>>> is certainly not wisdom."
>>>>>>>> Clifford Stoll
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> On Sat, Mar 21, 2015 at 6:49 AM, Luca Meyer <lucam1968 at gmail.com>
>>>> wrote:
>>>>>>>>> Hi Bert,
>>>>>>>>> 
>>>>>>>>> Thank you for your message. I am looking into ave() and tapply()
>> as
>>>> you
>>>>>>>>> suggested but at the same time I have prepared a example of input
>>>> and
>>>>>>>>> output
>>>>>>>>> files, just in case you or someone else would like to make an
>>>> attempt
>>>>>>>>> to
>>>>>>>>> generate a code that goes from input to output.
>>>>>>>>> 
>>>>>>>>> Please see below or download it from
>>>>>>>>> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
>>>>>>>>> 
>>>>>>>>> # this is (an extract of) the INPUT file I have:
>>>>>>>>> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
>> "B",
>>>>>>>>> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>>>>>>>>> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>>>>>>>>> "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273,
>>>>>>>>> 1.42917,
>>>>>>>>> 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
>>>>>>>>> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>>>>>>>>> row.names =
>>>>>>>>> c(2L,
>>>>>>>>> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>>>>>>>>> 
>>>>>>>>> # this is (an extract of) the OUTPUT file I would like to obtain:
>>>>>>>>> f2 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
>> "B",
>>>>>>>>> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>>>>>>>>> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>>>>>>>>> "B", "B", "B", "C", "C", "C"), v4 = c(17.83529, 3.43806,0.00295,
>>>>>>>>> 1.77918,
>>>>>>>>> 1.05786, 0.0002, 2.37232, 3.01835, 0, 1.13430, 0.92872,
>>>>>>>>> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>>>>>>>>> row.names =
>>>>>>>>> c(2L,
>>>>>>>>> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>>>>>>>>> 
>>>>>>>>> # please notice that while the aggregated v4 on v3 has changed ?
>>>>>>>>> aggregate(f1[,c("v4")],list(f1$v3),sum)
>>>>>>>>> aggregate(f2[,c("v4")],list(f2$v3),sum)
>>>>>>>>> 
>>>>>>>>> # ? the aggregated v4 over v1xv2 has remained unchanged:
>>>>>>>>> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>>>>>>>>> aggregate(f2[,c("v4")],list(f2$v1,f2$v2),sum)
>>>>>>>>> 
>>>>>>>>> Thank you very much in advance for your assitance.
>>>>>>>>> 
>>>>>>>>> Luca
>>>>>>>>> 
>>>>>>>>> 2015-03-21 13:18 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>>>>>>>>>> 
>>>>>>>>>> 1. Still not sure what you mean, but maybe look at ?ave and
>>>> ?tapply,
>>>>>>>>>> for which ave() is a wrapper.
>>>>>>>>>> 
>>>>>>>>>> 2. You still need to heed the rest of Jeff's advice.
>>>>>>>>>> 
>>>>>>>>>> Cheers,
>>>>>>>>>> Bert
>>>>>>>>>> 
>>>>>>>>>> Bert Gunter
>>>>>>>>>> Genentech Nonclinical Biostatistics
>>>>>>>>>> (650) 467-7374
>>>>>>>>>> 
>>>>>>>>>> "Data is not information. Information is not knowledge. And
>>>> knowledge
>>>>>>>>>> is certainly not wisdom."
>>>>>>>>>> Clifford Stoll
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <
>> lucam1968 at gmail.com>
>>>>>>>>>> wrote:
>>>>>>>>>>> Hi Jeff & other R-experts,
>>>>>>>>>>> 
>>>>>>>>>>> Thank you for your note. I have tried myself to solve the
>> issue
>>>>>>>>>>> without
>>>>>>>>>>> success.
>>>>>>>>>>> 
>>>>>>>>>>> Following your suggestion, I am providing a sample of the
>>>> dataset I
>>>>>>>>>>> am
>>>>>>>>>>> using below (also downloadble in plain text from
>>>>>>>>>>> 
>> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
>>>>>>>>>>> 
>>>>>>>>>>> #this is an extract of the overall dataset (n=1200 cases)
>>>>>>>>>>> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
>>>> "B",
>>>>>>>>>>> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>>>>>>>>>>> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>>>>>>>>>>> "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835,
>>>>>>>>>>> 3.43806581506388,
>>>>>>>>>>> 0.002733567617055, 1.42917483425029, 1.05786640463504,
>>>>>>>>>>> 0.000420548864162308,
>>>>>>>>>>> 2.37232740842861, 3.01835841813241, 0, 1.13430282139936,
>>>>>>>>>>> 0.928725667117666,
>>>>>>>>>>> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>>>>>>>>>>> row.names
>>>>>>>>>>> =
>>>>>>>>>>> c(2L,
>>>>>>>>>>> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>>>>>>>>>>> 
>>>>>>>>>>> I need to find a automated procedure that allows me to adjust
>> v3
>>>>>>>>>>> marginals
>>>>>>>>>>> while maintaining v1xv2 marginals unchanged.
>>>>>>>>>>> 
>>>>>>>>>>> That is: modify the v4 values you can find by running:
>>>>>>>>>>> 
>>>>>>>>>>> aggregate(f1[,c("v4")],list(f1$v3),sum)
>>>>>>>>>>> 
>>>>>>>>>>> while maintaining costant the values you can find by running:
>>>>>>>>>>> 
>>>>>>>>>>> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>>>>>>>>>>> 
>>>>>>>>>>> Now does it make sense?
>>>>>>>>>>> 
>>>>>>>>>>> Please notice I have tried to build some syntax that tries to
>>>> modify
>>>>>>>>>>> values
>>>>>>>>>>> within each v1xv2 combination by computing sum of v4, row
>>>> percentage
>>>>>>>>>>> in
>>>>>>>>>>> terms of v4, and there is where my effort is blocked. Not
>> really
>>>>>>>>>>> sure
>>>>>>>>>>> how I
>>>>>>>>>>> should proceed. Any suggestion?
>>>>>>>>>>> 
>>>>>>>>>>> Thanks,
>>>>>>>>>>> 
>>>>>>>>>>> Luca
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <
>>>> jdnewmil at dcn.davis.ca.us>:
>>>>>>>>>>> 
>>>>>>>>>>>> I don't understand your description. The standard practice on
>>>> this
>>>>>>>>>>>> list
>>>>>>>>>>>> is
>>>>>>>>>>>> to provide a reproducible R example [1] of the kind of data
>> you
>>>> are
>>>>>>>>>>>> working
>>>>>>>>>>>> with (and any code you have tried) to go along with your
>>>>>>>>>>>> description.
>>>>>>>>>>>> In
>>>>>>>>>>>> this case, that would be two dputs of your input data frames
>>>> and a
>>>>>>>>>>>> dput
>>>>>>>>>>>> of
>>>>>>>>>>>> an output data frame (generated by hand from your input data
>>>>>>>>>>>> frame).
>>>>>>>>>>>> (Probably best to not use the full number of input values
>> just
>>>> to
>>>>>>>>>>>> keep
>>>>>>>>>>>> the
>>>>>>>>>>>> size down.) We could then make an attempt to generate code
>> that
>>>>>>>>>>>> goes
>>>>>>>>>>>> from
>>>>>>>>>>>> input to output.
>>>>>>>>>>>> 
>>>>>>>>>>>> Of course, if you post that hard work using HTML then it will
>>>> get
>>>>>>>>>>>> corrupted (much like the text below from your earlier emails)
>>>> and
>>>>>>>>>>>> we
>>>>>>>>>>>> won't
>>>>>>>>>>>> be able to use it. Please learn to post from your email
>> software
>>>>>>>>>>>> using
>>>>>>>>>>>> plain text when corresponding with this mailing list.
>>>>>>>>>>>> 
>>>>>>>>>>>> [1]
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>> 
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>> 
>> ---------------------------------------------------------------------------
>>>>>>>>>>>> Jeff Newmiller                        The     .....
>>>> .....  Go
>>>>>>>>>>>> Live...
>>>>>>>>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.
>> ##.#.
>>>>>>>>>>>> Live
>>>>>>>>>>>> Go...
>>>>>>>>>>>>                                      Live:   OO#.. Dead:
>> OO#..
>>>>>>>>>>>> Playing
>>>>>>>>>>>> Research Engineer (Solar/Batteries            O.O#.
>> #.O#.
>>>>>>>>>>>> with
>>>>>>>>>>>> /Software/Embedded Controllers)               .OO#.
>> .OO#.
>>>>>>>>>>>> rocks...1k
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>> 
>> ---------------------------------------------------------------------------
>>>>>>>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>>>>>>>> 
>>>>>>>>>>>> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <
>>>> lucam1968 at gmail.com>
>>>>>>>>>>>> wrote:
>>>>>>>>>>>>> Thanks for you input Michael,
>>>>>>>>>>>>> 
>>>>>>>>>>>>> The continuous variable I have measures quantities (down to
>> the
>>>>>>>>>>>>> 3rd
>>>>>>>>>>>>> decimal level) so unfortunately are not frequencies.
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Any more specific suggestions on how that could be tackled?
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Thanks & kind regards,
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Luca
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> ===
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Michael Friendly wrote:
>>>>>>>>>>>>> I'm not sure I understand completely what you want to do,
>> but
>>>>>>>>>>>>> if the data were frequencies, it sounds like task for
>> fitting a
>>>>>>>>>>>>> loglinear model with the model formula
>>>>>>>>>>>>> 
>>>>>>>>>>>>> ~ V1*V2 + V3
>>>>>>>>>>>>> 
>>>>>>>>>>>>> On 3/18/2015 2:17 AM, Luca Meyer wrote:
>>>>>>>>>>>>>> * Hello,
>>>>>>>>>>>>> *>>* I am facing a quite challenging task (at least to me)
>> and
>>>> I
>>>>>>>>>>>>> was
>>>>>>>>>>>>> wondering
>>>>>>>>>>>>> *>* if someone could advise how R could assist me to speed
>> the
>>>>>>>>>>>>> task
>>>>>>>>>>>>> up.
>>>>>>>>>>>>> *>>* I am dealing with a dataset with 3 discrete variables
>> and
>>>> one
>>>>>>>>>>>>> continuous
>>>>>>>>>>>>> *>* variable. The discrete variables are:
>>>>>>>>>>>>> *>>* V1: 8 modalities
>>>>>>>>>>>>> *>* V2: 13 modalities
>>>>>>>>>>>>> *>* V3: 13 modalities
>>>>>>>>>>>>> *>>* The continuous variable V4 is a decimal number always
>>>> greater
>>>>>>>>>>>>> than
>>>>>>>>>>>>> zero in
>>>>>>>>>>>>> *>* the marginals of each of the 3 variables but it is
>>>> sometimes
>>>>>>>>>>>>> equal
>>>>>>>>>>>>> to zero
>>>>>>>>>>>>> *>* (and sometimes negative) in the joint tables.
>>>>>>>>>>>>> *>>* I have got 2 files:
>>>>>>>>>>>>> *>>* => one with distribution of all possible combinations
>> of
>>>>>>>>>>>>> V1xV2
>>>>>>>>>>>>> (some of
>>>>>>>>>>>>> *>* which are zero or neagtive) and
>>>>>>>>>>>>> *>* => one with the marginal distribution of V3.
>>>>>>>>>>>>> *>>* I am trying to build the long and narrow dataset
>> V1xV2xV3
>>>> in
>>>>>>>>>>>>> such
>>>>>>>>>>>>> a way
>>>>>>>>>>>>> *>* that each V1xV2 cell does not get modified and V3 fits
>> as
>>>>>>>>>>>>> closely
>>>>>>>>>>>>> as
>>>>>>>>>>>>> *>* possible to its marginal distribution. Does it make
>> sense?
>>>>>>>>>>>>> *>>* To be even more specific, my 2 input files look like
>> the
>>>>>>>>>>>>> following.
>>>>>>>>>>>>> *>>* FILE 1
>>>>>>>>>>>>> *>* V1,V2,V4
>>>>>>>>>>>>> *>* A, A, 24.251
>>>>>>>>>>>>> *>* A, B, 1.065
>>>>>>>>>>>>> *>* (...)
>>>>>>>>>>>>> *>* B, C, 0.294
>>>>>>>>>>>>> *>* B, D, 2.731
>>>>>>>>>>>>> *>* (...)
>>>>>>>>>>>>> *>* H, L, 0.345
>>>>>>>>>>>>> *>* H, M, 0.000
>>>>>>>>>>>>> *>>* FILE 2
>>>>>>>>>>>>> *>* V3, V4
>>>>>>>>>>>>> *>* A, 1.575
>>>>>>>>>>>>> *>* B, 4.294
>>>>>>>>>>>>> *>* C, 10.044
>>>>>>>>>>>>> *>* (...)
>>>>>>>>>>>>> *>* L, 5.123
>>>>>>>>>>>>> *>* M, 3.334
>>>>>>>>>>>>> *>>* What I need to achieve is a file such as the following
>>>>>>>>>>>>> *>>* FILE 3
>>>>>>>>>>>>> *>* V1, V2, V3, V4
>>>>>>>>>>>>> *>* A, A, A, ???
>>>>>>>>>>>>> *>* A, A, B, ???
>>>>>>>>>>>>> *>* (...)
>>>>>>>>>>>>> *>* D, D, E, ???
>>>>>>>>>>>>> *>* D, D, F, ???
>>>>>>>>>>>>> *>* (...)
>>>>>>>>>>>>> *>* H, M, L, ???
>>>>>>>>>>>>> *>* H, M, M, ???
>>>>>>>>>>>>> *>>* Please notice that FILE 3 need to be such that if I
>>>> aggregate
>>>>>>>>>>>>> on
>>>>>>>>>>>>> V1+V2 I
>>>>>>>>>>>>> *>* recover exactly FILE 1 and that if I aggregate on V3 I
>> can
>>>>>>>>>>>>> recover
>>>>>>>>>>>>> a file
>>>>>>>>>>>>> *>* as close as possible to FILE 3 (ideally the same file).
>>>>>>>>>>>>> *>>* Can anyone suggest how I could do that with R?
>>>>>>>>>>>>> *>>* Thank you very much indeed for any assistance you are
>>>> able to
>>>>>>>>>>>>> provide.
>>>>>>>>>>>>> *>>* Kind regards,
>>>>>>>>>>>>> *>>* Luca*
>>>>>>>>>>>>> 
>>>>>>>>>>>>>      [[alternative HTML version deleted]]


David Winsemius
Alameda, CA, USA


From aolinto.lst at gmail.com  Sun Mar 22 23:01:00 2015
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Sun, 22 Mar 2015 19:01:00 -0300
Subject: [R] ordering a boxplot
In-Reply-To: <6999198E-C2B3-406C-9AC4-4DF8E862A9FE@utoronto.ca>
References: <CAE8g1gPFm__Q8t5wnxusAfmARBB7S55AY2eJAf+GKFfgKvm8-g@mail.gmail.com>
	<CAF8bMcYfqZDtBPOfvgnCO3k2uenKhVDqEDfbaQf21k3efp2sCA@mail.gmail.com>
	<CAE8g1gNtXRBGKHbxvd2sr9vciROzP5u-8+o6WEHzC95bhW3+tg@mail.gmail.com>
	<787CFEFC-A05F-4101-99C1-896FF4751B8B@utoronto.ca>
	<6999198E-C2B3-406C-9AC4-4DF8E862A9FE@utoronto.ca>
Message-ID: <CAE8g1gOG0_a6=hfsQh=R=AEZzLwqqMiWqSvatAC1k5MLWShJew@mail.gmail.com>

Dear Boris,

Thanks very much, have a great week.

Best regards

Ant?nio Olinto
Fisheries Institute
S?o Paulo, Brasil



2015-03-21 21:09 GMT-03:00 Boris Steipe <boris.steipe at utoronto.ca>:

> ... just for completeness - the more concise way: (no need to go through
> names()).
>
> boxplot(mydata[,order(apply(mydata,2,median))])
>
> ... or descending
> boxplot(mydata[,order(-apply(mydata,2,median))])
>
>
>
>
> B.
>
>
>
> On Mar 21, 2015, at 7:04 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
>
> > There may be more concise ways to do this - but you are 99% there with
> your approach:
> > try:
> >
> > boxplot(mydata[,names(sort(apply(mydata,2,median)))])
> >
> > B.
> >
> >
> > On Mar 21, 2015, at 6:49 PM, Antonio Silva <aolinto.lst at gmail.com>
> wrote:
> >
> >> Thanks Bill and David
> >>
> >> Here goes an example
> >>
> >> SP1<-c(9,6,7,8,5,8,7,5,9,7)
> >> SP2<-c(1,3,4,2,4,2,5,3,2,1)
> >> SP3<-c(4,6,7,5,7,8,7,6,5,4)
> >> SP4<-c(5,4,3,5,2,3,4,3,4,2)
> >> mydata<-data.frame(SP1,SP2,SP3,SP4)
> >>
> rownames(mydata)<-c("ST1","ST2","ST3","ST4","ST5","ST6","ST7","ST8","ST9","ST10")
> >> mydata
> >> boxplot(mydata)
> >>
> >> Note that this data frame does not have the format Response ~ Group. In
> my
> >> real matrix I have up to 40 species.
> >>
> >> Is there any way to have the species ordered by their median abundance
> (or
> >> other parameter?)
> >>
> >> The desired order is given by names(sort(apply(mydata,2,median)))
> >>
> >> Thanks once more,
> >>
> >> Antonio Olinto
> >> Fisheries Institute
> >> Sao Paulo, Brazil
> >>
> >> 2015-03-21 15:13 GMT-03:00 William Dunlap <wdunlap at tibco.com>:
> >>
> >>> You can use the reorder() function to reorder the grouping vector's
> >>> factor levels according to a function of the data in each group.  E.g.,
> >>> compare the following two plots:
> >>>
> >>>  d <- data.frame(Response=cos(1:15),
> Group=rep(c("A","B","C"),c(6,5,4)))
> >>>  par(mfrow=c(1,2))
> >>>  boxplot(Response ~ Group, data=d)
> >>>  boxplot(Response ~ reorder(Group, X=Response, FUN=median), data=d)
> >>>
> >>>
> >>> Bill Dunlap
> >>> TIBCO Software
> >>> wdunlap tibco.com
> >>>
> >>> On Fri, Mar 20, 2015 at 2:20 PM, Antonio Silva <aolinto.lst at gmail.com>
> >>> wrote:
> >>>
> >>>> Hello
> >>>>
> >>>> I'm using a dataframe (mydata) where row names are sampling points and
> >>>> column names are species in a multivariate analysis.
> >>>>
> >>>> If I write boxplot(mydata) I'll have boxplots for each species
> abundance
> >>>> in
> >>>> alphabetical order.
> >>>>
> >>>> How to get the boxes orderer by the median?
> >>>>
> >>>> Usually for this I write
> >>>>
> >>>>
> boxplot(value~category,at=rank(tapply(mydata$value,mydata$category,median)))
> >>>> but for this to work I need a column for the categories and another
> column
> >>>> for the values.
> >>>>
> >>>> Thanks in advance, best regards.
> >>>>
> >>>> Antonio Olinto
> >>>>
> >>>>       [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From memilanuk at gmail.com  Mon Mar 23 02:21:55 2015
From: memilanuk at gmail.com (memilanuk)
Date: Sun, 22 Mar 2015 18:21:55 -0700
Subject: [R] 1st script
Message-ID: <menprj$5t8$1@ger.gmane.org>

So... wrote my first script, rather than just using the interactive 
console.  I think I got everything working more or less the way I want, 
but I'm sure there's a ton of room for improvement.  Specifically in the 
way of automation - but thats where I kind of ran out of steam.  Any 
suggestions would be much appreciated.

case_data.r

# Import CSV file into a data frame.
case_weights <- read.csv(file = "case_weights.csv")

# For each row, take the number in the Weight column and replicate it
# as many times as there are in each count column.
LC09 <- rep(case_weights$Weight, case_weights$LC09)
LC10 <- rep(case_weights$Weight, case_weights$LC10)
LP14b1 <- rep(case_weights$Weight, case_weights$LP14b1)
LP14b2 <- rep(case_weights$Weight, case_weights$LP14b2)

# Determine the longest vector, to help with the next step.
max.len <- max(length(LC09), length(LC10), length(LP14b1),
		length(LP14b2))

# Pad each vector with NA so they are all the same length and will
# go in a data frame.
LC09 <- c(LC09, rep(NA, max.len - length(LC09)))
LC10 <- c(LC10, rep(NA, max.len - length(LC10)))
LP14b1 <- c(LP14b1, rep(NA, max.len - length(LP14b1)))
LP14b2 <- c(LP14b2, rep(NA, max.len - length(LP14b2)))

# Stick everything back into one data frame.
case_dat <- data.frame(LC09)
case_dat$LC10 <- LC10
case_dat$LP14b1 <- LP14b1
case_dat$LP14b2 <- LP14b2

# Stuff said data frame back into a CSV for use elsewhere (plot.ly).
write.csv(case_dat, file = "expanded_case_weights.csv")

# Boxplot it
boxplot(case_dat, varwidth = TRUE, notch = TRUE, horizontal = TRUE,
         main = "Case Weights", xlab = "Weight (grains)",
         ylab = "Batch", las = 1, names = c("LC09", "LC10", "LP14b1",
	"LP14b2"))



-- 
Shiny!  Let's be bad guys.

Reach me @ memilanuk (at) gmail dot com


From vindoggy at hotmail.com  Mon Mar 23 04:20:35 2015
From: vindoggy at hotmail.com (Vindoggy !)
Date: Mon, 23 Mar 2015 03:20:35 +0000
Subject: [R] R Freezes (Mac) using file.choose()
Message-ID: <COL127-W39C7DD80E2DA259D8E7767CC0D0@phx.gbl>

I'm using a mac with OSX Yosemite (10.10.2), running the latest version of R (3.1.3). But I've been having this same issue since Mavericks came out, using all of  the different versions of R that have come out since Mavericks.

Often (approximately 15% of the time I would say), whenever I use a function in R that pulls up a mac finder window, R will freeze and I am left with the spinning beach ball until I force-quit R. This happens most frequently when using "file.choose()" to open a file, but has happened to me when changing the working directory through the "Misc" tab as well:

Misc-> Change Working Directory


This has happened on at least three different Mac machines of varying ages, so I don't think this is a computer specific issue. And as much of the scripts I have written use "file.choose()", this happens on a regular basis.

Have other people run into this same issue? If so, is there a fix for it?
 		 	   		  
	[[alternative HTML version deleted]]


From alemu.tadesse at gmail.com  Mon Mar 23 05:18:41 2015
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Sun, 22 Mar 2015 22:18:41 -0600
Subject: [R] average wind direction calculation
Message-ID: <CACGkHRPJXk7VEFnaZ0QNbPvnf+0T6g9cDhfed_NM+8GkyHM-WQ@mail.gmail.com>

Dear All,

I am wondering if you have an R script or know an R package for an average
wind direction

Best,

Alemu

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Mar 23 06:24:17 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 22 Mar 2015 22:24:17 -0700
Subject: [R] average wind direction calculation
In-Reply-To: <CACGkHRPJXk7VEFnaZ0QNbPvnf+0T6g9cDhfed_NM+8GkyHM-WQ@mail.gmail.com>
References: <CACGkHRPJXk7VEFnaZ0QNbPvnf+0T6g9cDhfed_NM+8GkyHM-WQ@mail.gmail.com>
Message-ID: <920A91B9-E02E-43B1-BA2E-F4E9AF8ED67A@comcast.net>


> On Mar 22, 2015, at 9:18 PM, Alemu Tadesse <alemu.tadesse at gmail.com> wrote:
> 
> Dear All,
> 
> I am wondering if you have an R script or know an R package for an average
> wind direction
> 

pkg:circular

> Best,
> 
> Alemu
> 
> 	[[alternative HTML version deleted]]

R is a plain text mailing list.
? 

David Winsemius, MD
Alameda, CA, USA


From petr.pikal at precheza.cz  Mon Mar 23 06:58:52 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 23 Mar 2015 05:58:52 +0000
Subject: [R] 1st script
In-Reply-To: <menprj$5t8$1@ger.gmane.org>
References: <menprj$5t8$1@ger.gmane.org>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C24CF4@SRVEXCHMBX.precheza.cz>

Hi

use list and numeric indexing. As you did not provide reproducibe example here is possible way.

dat <- data.frame(w=abs(rnorm(10)), LC09=round(runif(10)*10), LC10=round(runif(10)*10))
lll <- vector("list", 2)
k=0
for(i in 2:3) {
k=k+1
lll[[k]] <- rep(dat$w, dat[,i])
}
names(lll)<-names(dat[,2:3])
boxplot(lll)

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> memilanuk
> Sent: Monday, March 23, 2015 2:22 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] 1st script
>
> So... wrote my first script, rather than just using the interactive
> console.  I think I got everything working more or less the way I want,
> but I'm sure there's a ton of room for improvement.  Specifically in
> the
> way of automation - but thats where I kind of ran out of steam.  Any
> suggestions would be much appreciated.
>
> case_data.r
>
> # Import CSV file into a data frame.
> case_weights <- read.csv(file = "case_weights.csv")
>
> # For each row, take the number in the Weight column and replicate it
> # as many times as there are in each count column.
> LC09 <- rep(case_weights$Weight, case_weights$LC09)
> LC10 <- rep(case_weights$Weight, case_weights$LC10)
> LP14b1 <- rep(case_weights$Weight, case_weights$LP14b1)
> LP14b2 <- rep(case_weights$Weight, case_weights$LP14b2)
>
> # Determine the longest vector, to help with the next step.
> max.len <- max(length(LC09), length(LC10), length(LP14b1),
>               length(LP14b2))
>
> # Pad each vector with NA so they are all the same length and will
> # go in a data frame.
> LC09 <- c(LC09, rep(NA, max.len - length(LC09)))
> LC10 <- c(LC10, rep(NA, max.len - length(LC10)))
> LP14b1 <- c(LP14b1, rep(NA, max.len - length(LP14b1)))
> LP14b2 <- c(LP14b2, rep(NA, max.len - length(LP14b2)))
>
> # Stick everything back into one data frame.
> case_dat <- data.frame(LC09)
> case_dat$LC10 <- LC10
> case_dat$LP14b1 <- LP14b1
> case_dat$LP14b2 <- LP14b2
>
> # Stuff said data frame back into a CSV for use elsewhere (plot.ly).
> write.csv(case_dat, file = "expanded_case_weights.csv")
>
> # Boxplot it
> boxplot(case_dat, varwidth = TRUE, notch = TRUE, horizontal = TRUE,
>          main = "Case Weights", xlab = "Weight (grains)",
>          ylab = "Batch", las = 1, names = c("LC09", "LC10", "LP14b1",
>       "LP14b2"))
>
>
>
> --
> Shiny!  Let's be bad guys.
>
> Reach me @ memilanuk (at) gmail dot com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From memilanuk at gmail.com  Mon Mar 23 08:40:47 2015
From: memilanuk at gmail.com (memilanuk)
Date: Mon, 23 Mar 2015 00:40:47 -0700
Subject: [R] 1st script
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C24CF4@SRVEXCHMBX.precheza.cz>
References: <menprj$5t8$1@ger.gmane.org>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C24CF4@SRVEXCHMBX.precheza.cz>
Message-ID: <meog20$ter$1@ger.gmane.org>

On 03/22/2015 10:58 PM, PIKAL Petr wrote:

> use list and numeric indexing. As you did not provide reproducibe example here is possible way.
>
> dat <- data.frame(w=abs(rnorm(10)), LC09=round(runif(10)*10), LC10=round(runif(10)*10))
> lll <- vector("list", 2)
> k=0
> for(i in 2:3) {
> k=k+1
> lll[[k]] <- rep(dat$w, dat[,i])
> }
> names(lll)<-names(dat[,2:3])
> boxplot(lll)
>

I don't suppose you have a commented version of that...?  What may be 
blindingly obvious to you is... not so much for me.

Is this what you need for a reproducible example?

Sample of case_weights.csv:

Weight,LC09,LC10,LP14b1,LP14b2
171.0,0,0,0,0
171.1,0,0,3,0
171.2,0,0,19,0
171.3,0,0,44,0
171.4,0,0,52,0
171.5,0,0,56,1
171.6,0,0,42,1
171.7,0,0,17,5
171.8,0,0,15,29
171.9,0,0,2,46
172.0,0,0,0,37
172.1,0,0,0,39
172.2,0,0,0,33
172.3,0,0,0,48
172.4,0,0,0,26
172.5,0,0,0,48
172.6,0,0,0,31
172.7,0,0,0,47
172.8,0,0,0,17
172.9,0,0,0,19
173.0,0,0,0,7
173.1,0,0,0,10
173.2,0,0,0,12
173.3,0,0,0,17
173.4,0,0,0,10
173.5,0,0,0,6
173.6,0,0,0,6
173.7,0,0,0,2
173.8,0,0,0,1
176.3,3,0,0,0
176.4,1,0,0,0
176.5,0,0,0,0
176.6,4,0,0,0
176.7,2,0,0,0
176.8,6,0,0,0
176.9,4,0,0,0
177.0,9,0,0,0
177.1,16,0,0,0
177.2,24,0,0,0
177.3,27,0,0,0
177.4,43,0,0,0
177.5,40,0,0,0
177.6,56,0,0,0
177.7,41,0,0,0
177.8,58,0,0,0
177.9,55,0,0,0
178.0,48,0,0,0
178.1,37,0,0,0
178.2,23,0,0,0
178.3,30,0,0,0
178.4,14,0,0,0
178.5,16,0,0,0
178.6,9,0,0,0
178.7,11,0,0,0
178.8,9,0,0,0
178.9,7,0,0,0

Thanks,

Monte


-- 
Shiny!  Let's be bad guys.

Reach me @ memilanuk (at) gmail dot com


From petr.pikal at precheza.cz  Mon Mar 23 09:25:46 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 23 Mar 2015 08:25:46 +0000
Subject: [R] 1st script
In-Reply-To: <meog20$ter$1@ger.gmane.org>
References: <menprj$5t8$1@ger.gmane.org>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C24CF4@SRVEXCHMBX.precheza.cz>
	<meog20$ter$1@ger.gmane.org>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C24E74@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> memilanuk
> Sent: Monday, March 23, 2015 8:41 AM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] 1st script
>
> On 03/22/2015 10:58 PM, PIKAL Petr wrote:
>
> > use list and numeric indexing. As you did not provide reproducibe
> example here is possible way.
> >
> > dat <- data.frame(w=abs(rnorm(10)), LC09=round(runif(10)*10),
> LC10=round(runif(10)*10))
> > lll <- vector("list", 2)
> > k=0
> > for(i in 2:3) {
> > k=k+1
> > lll[[k]] <- rep(dat$w, dat[,i])
> > }
> > names(lll)<-names(dat[,2:3])
> > boxplot(lll)
> >
>
> I don't suppose you have a commented version of that...?  What may be
> blindingly obvious to you is... not so much for me.

Hm. R comes with pretty good help pages and I actually did not use (except of list and for commands) anything different from you.

>
> Is this what you need for a reproducible example?

More or less. Better is to use coppied output from dput(some data). I named your data frame dat.

dat<-read.table("clipboard", sep=",", header=T)

> dput(dat)
structure(list(Weight = c(171, 171.1, 171.2, 171.3, 171.4, 171.5,
171.6, 171.7, 171.8, 171.9, 172, 172.1, 172.2, 172.3, 172.4,
172.5, 172.6, 172.7, 172.8, 172.9, 173, 173.1, 173.2, 173.3,
173.4, 173.5, 173.6, 173.7, 173.8, 176.3, 176.4, 176.5, 176.6,
176.7, 176.8, 176.9, 177, 177.1, 177.2, 177.3, 177.4, 177.5,
177.6, 177.7, 177.8, 177.9, 178, 178.1, 178.2, 178.3, 178.4,
178.5, 178.6, 178.7, 178.8, 178.9), LC09 = c(0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 3L, 1L, 0L, 4L, 2L, 6L, 4L,
9L, 16L, 24L, 27L, 43L, 40L, 56L, 41L, 58L, 55L, 48L, 37L, 23L,
30L, 14L, 16L, 9L, 11L, 9L, 7L), LC10 = c(0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L), LP14b1 = c(0L, 3L, 19L, 44L, 52L, 56L, 42L, 17L,
15L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L), LP14b2 = c(0L, 0L, 0L, 0L, 0L, 1L, 1L, 5L, 29L, 46L, 37L,
39L, 33L, 48L, 26L, 48L, 31L, 47L, 17L, 19L, 7L, 10L, 12L, 17L,
10L, 6L, 6L, 2L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L)), .Names = c("Weight", "LC09", "LC10", "LP14b1", "LP14b2"
), class = "data.frame", row.names = c(NA, -56L))

# creating empty list

lll <- vector("list", 4)

#just a counter
k=0

#simple cycle

for(i in 2:5) {
k=k+1

#populate list
lll[[k]] <- rep(dat$Weight, dat[,i])
}

# put names to list
names(lll)<-names(dat[,2:5])

# make boxplot
boxplot(lll)

If you need some fancy boxplot you can use your own code, which I do not have as you did not keep track of your previous mail.

Cheers
Petr


>
> Sample of case_weights.csv:
>
> Weight,LC09,LC10,LP14b1,LP14b2
> 171.0,0,0,0,0
> 171.1,0,0,3,0
> 171.2,0,0,19,0
> 171.3,0,0,44,0
> 171.4,0,0,52,0
> 171.5,0,0,56,1
> 171.6,0,0,42,1
> 171.7,0,0,17,5
> 171.8,0,0,15,29
> 171.9,0,0,2,46
> 172.0,0,0,0,37
> 172.1,0,0,0,39
> 172.2,0,0,0,33
> 172.3,0,0,0,48
> 172.4,0,0,0,26
> 172.5,0,0,0,48
> 172.6,0,0,0,31
> 172.7,0,0,0,47
> 172.8,0,0,0,17
> 172.9,0,0,0,19
> 173.0,0,0,0,7
> 173.1,0,0,0,10
> 173.2,0,0,0,12
> 173.3,0,0,0,17
> 173.4,0,0,0,10
> 173.5,0,0,0,6
> 173.6,0,0,0,6
> 173.7,0,0,0,2
> 173.8,0,0,0,1
> 176.3,3,0,0,0
> 176.4,1,0,0,0
> 176.5,0,0,0,0
> 176.6,4,0,0,0
> 176.7,2,0,0,0
> 176.8,6,0,0,0
> 176.9,4,0,0,0
> 177.0,9,0,0,0
> 177.1,16,0,0,0
> 177.2,24,0,0,0
> 177.3,27,0,0,0
> 177.4,43,0,0,0
> 177.5,40,0,0,0
> 177.6,56,0,0,0
> 177.7,41,0,0,0
> 177.8,58,0,0,0
> 177.9,55,0,0,0
> 178.0,48,0,0,0
> 178.1,37,0,0,0
> 178.2,23,0,0,0
> 178.3,30,0,0,0
> 178.4,14,0,0,0
> 178.5,16,0,0,0
> 178.6,9,0,0,0
> 178.7,11,0,0,0
> 178.8,9,0,0,0
> 178.9,7,0,0,0
>
> Thanks,
>
> Monte
>
>
> --
> Shiny!  Let's be bad guys.
>
> Reach me @ memilanuk (at) gmail dot com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From lindnerw at t-online.de  Mon Mar 23 09:50:13 2015
From: lindnerw at t-online.de (Dr. Wolfgang Lindner)
Date: Mon, 23 Mar 2015 09:50:13 +0100
Subject: [R] the making of _R_ eBooks
Message-ID: <48E60F6FD5CD45C0A7AA320694FB1F8E@Petra>

Dear list members,

I like the look and feel of the eBook versions of the R manuals very much.
So I would like to generate eBooks (teaching material etc) in that look.

Q1: is there a description how the _R_ ebooks have been produced?
Q2: which (free) software was used for them?
Q3: any other recommendations?

Seaching the internet gives me e.g.
[1] 
https://sites.google.com/site/richardbyrnepdsite/ebooks-and-audiobooks/create-your-own-ebooks
[2]  opensource.com/life/13/8/how-create-ebook-open-source-way
[3] 
http://scottnesbitt.net/ubuntublog/creating-a-ebook-with-libreoffice-writer/

but I m not sure, if there are better possibilities..

Thanks for any hint or link by expert R users.

Wolfgang Lindner
Leichlingen, Germany


From ripley at stats.ox.ac.uk  Mon Mar 23 13:13:21 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 23 Mar 2015 12:13:21 +0000
Subject: [R] the making of _R_ eBooks
In-Reply-To: <48E60F6FD5CD45C0A7AA320694FB1F8E@Petra>
References: <48E60F6FD5CD45C0A7AA320694FB1F8E@Petra>
Message-ID: <55100361.9010603@stats.ox.ac.uk>

On 23/03/2015 08:50, Dr. Wolfgang Lindner wrote:
> Dear list members,
>
> I like the look and feel of the eBook versions of the R manuals very much.
> So I would like to generate eBooks (teaching material etc) in that look.
>
> Q1: is there a description how the _R_ ebooks have been produced?
> Q2: which (free) software was used for them?
> Q3: any other recommendations?

fortunes::fortune(14) applies.  In this case TM is
http://cran.r-project.org/doc/manuals/r-release/R-admin.html#Making-the-manuals 
.

>
> Seaching the internet gives me e.g.
> [1]
> https://sites.google.com/site/richardbyrnepdsite/ebooks-and-audiobooks/create-your-own-ebooks
> [2]  opensource.com/life/13/8/how-create-ebook-open-source-way
> [3]
> http://scottnesbitt.net/ubuntublog/creating-a-ebook-with-libreoffice-writer/
>
> but I m not sure, if there are better possibilities..
>
> Thanks for any hint or link by expert R users.
>
> Wolfgang Lindner
> Leichlingen, Germany

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

PLEASE do!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From john.archie.mckown at gmail.com  Mon Mar 23 13:36:38 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 23 Mar 2015 07:36:38 -0500
Subject: [R] the making of _R_ eBooks
In-Reply-To: <48E60F6FD5CD45C0A7AA320694FB1F8E@Petra>
References: <48E60F6FD5CD45C0A7AA320694FB1F8E@Petra>
Message-ID: <CAAJSdjjb+NjvFKm7tLpSQj_AjGO2YoiAY-8HQ9rcdCvhN3WQjQ@mail.gmail.com>

On Mon, Mar 23, 2015 at 3:50 AM, Dr. Wolfgang Lindner
<lindnerw at t-online.de> wrote:
> Dear list members,
>
> I like the look and feel of the eBook versions of the R manuals very much.
> So I would like to generate eBooks (teaching material etc) in that look.

I am not an expert. But I have looked at the source, so I can give you
some information.

>
> Q1: is there a description how the _R_ ebooks have been produced?

Looking at the source, it appears that the source manuals are in a
document markup language called "GNU Texinfo".
https://www.gnu.org/software/texinfo/
You can think of this as something akin to, but different from, HTML
or "markdown" encoding. Texinfo is an evolution by the system first
designed by Richard Stallman of MIT. He is the driving force behind
the GPL and most of the GNU software which forms the basis of the user
space commands for Linux and the *BSD operating systems. Texinfo is
then converted to TeX. TeX is the typesetting language designed by Dr.
Donald Knuth. TeX, nominally, is converted into a DVI printer control
language (DeVice Independent). But in the case of creating a PDF file,
there is a processor called "pdftex",
http://en.wikipedia.org/wiki/PdfTeX, which produces a PDF file as
output . A good site for TeX is https://tug.org/

Texinfo has the plus of also having processor which will convert it to
UNIX "man" (manual) pages and HTML web pages. So one "source" document
can generate three different types of output document file types.

Most people use a enhanced TeX called LaTeX instead of "plain TeX"
when using TeX. LaTeX can be read up on here:
http://www.latex-project.org/ A good TeX document processor is
TeXstudio at http://texstudio.sourceforge.net/ . I use this one myself
(which is not necessary a strong endorsement because I'm nobody
special).

I feel the need to warn you that TeX is very powerful and, at least to
me, quite difficult, with a fairly step learning curve. Which may be
why the R project uses Texinfo because it is quite a bit easier to
learn.


> Q2: which (free) software was used for them?

See the links above. On Fedora Linux, I get the TeX oriented software
from a bunch of packages which start with "texlive". More information,
including the processors for Linux, Windows, and Mac are at
https://www.tug.org/texlive/

> Q3: any other recommendations?

You might consider LyX.
http://www.lyx.org/
LyX is a document processor. It would likely be easier to use than the
above if you are used to MS Word or other word processing system. It
is cross platform: Linux, Windows, and Mac. It stores files in its own
textual format, which is somewhat human readable. LyX, like Texinfo,
translates its format into TeX as an intermediate on its way to its
ultimate destination. I am still learning LyX, but I personally like
it.

Your mention of LibreOffice is also a fairly good one. I, personally,
use LibreOffice. But I don't use it for big documents. I have a
learned aversion for word processors because it is so easy for them to
be misused. In my opinion, a good document needs good metadata in it
as well as just "looking pretty". Word processor users tend to focus
on the format and not the content. That's just my opinion, based on
what I've seen where I work.

>
> Seaching the internet gives me e.g.
> [1]
> https://sites.google.com/site/richardbyrnepdsite/ebooks-and-audiobooks/create-your-own-ebooks
> [2]  opensource.com/life/13/8/how-create-ebook-open-source-way
> [3] http://scottnesbitt.net/ubuntublog/creating-a-ebook-with-libreoffice-writer/
>
> but I m not sure, if there are better possibilities..
>
> Thanks for any hint or link by expert R users.

Oh, well, that excludes me. I'm not an expert. But maybe it was helpful anyway.

>
> Wolfgang Lindner
> Leichlingen, Germany

-- 
If you sent twitter messages while exploring, are you on a textpedition?

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown


From aron.lindberg at case.edu  Mon Mar 23 13:54:49 2015
From: aron.lindberg at case.edu (Aron Lindberg)
Date: Mon, 23 Mar 2015 05:54:49 -0700 (PDT)
Subject: [R] Rate limiting question on SO
Message-ID: <1427115288307.6bbbb528@Nodemailer>

Hi All,


I have been trying to write a ?manual? API rate limiting function for the rgithub package, but I?m not quite sure if I have succeeded or not. I need to figure out?a) how can I find out if my function actually does rate-limiting, and b) if not, how can I rewrite it so that it actually does rate limiting?


I have posted it as a question on SO, with a +50 bounty on it, but need some more comprehensive answers:
http://stackoverflow.com/questions/28770297/manual-api-rate-limiting



Does anyone have experience in this area and could offer some advice?


Best,
Aron

--?
Aron Lindberg


Doctoral Candidate,?Information Systems
Weatherhead School of Management?
Case Western Reserve University
aronlindberg.github.io
	[[alternative HTML version deleted]]


From pollaroid at gmail.com  Mon Mar 23 13:58:59 2015
From: pollaroid at gmail.com (Kuma Raj)
Date: Mon, 23 Mar 2015 13:58:59 +0100
Subject: [R] Replace a column value on condition
Message-ID: <CAAC1QdAHk5TEj7ivCxtceUgQwHjBt6BA+ZZjtP_eZzPJGNncUA@mail.gmail.com>

I want to replace column c3 with values from column c2 whenever values
of column Id are 2. In stata I could use replace c3 = c2 if id ==2.
How could I do that in R?

Thanks


Sample data found below:

> dput(df4)
structure(list(c2 = c(42L, 42L, 47L, 47L, 55L, 55L, 36L, 36L,
61L, 61L), c3 = c(68L, 59L, 68L, 50L, 62L, 50L, 63L, 45L, 65L,
45L), id = c(1, 2, 1, 2, 1, 2, 1, 2, 1, 2)), datalabel = "Written by
R.              ", time.stamp = "23 Mar 2015 13:54", .Names = c("c2",
"c3", "id"), formats = c("%9.0g", "%9.0g", "%9.0g"), types = c(253L,
253L, 255L), val.labels = c("", "", ""), var.labels = c("", "",
""), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
"10"), version = 12L, class = "data.frame")


From bhh at xs4all.nl  Mon Mar 23 14:44:16 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 23 Mar 2015 14:44:16 +0100
Subject: [R] Replace a column value on condition
In-Reply-To: <CAAC1QdAHk5TEj7ivCxtceUgQwHjBt6BA+ZZjtP_eZzPJGNncUA@mail.gmail.com>
References: <CAAC1QdAHk5TEj7ivCxtceUgQwHjBt6BA+ZZjtP_eZzPJGNncUA@mail.gmail.com>
Message-ID: <C0AC57F4-A39B-4AED-B578-0EAFA1C6DAA9@xs4all.nl>


> On 23-03-2015, at 13:58, Kuma Raj <pollaroid at gmail.com> wrote:
> 
> I want to replace column c3 with values from column c2 whenever values
> of column Id are 2. In stata I could use replace c3 = c2 if id ==2.
> How could I do that in R?
> 


k <- which(df4$id==2)
df4[k,"c3"] <- df4[k,"c2?]

Berend

> Thanks
> 
> 
> Sample data found below:
> 
>> dput(df4)
> structure(list(c2 = c(42L, 42L, 47L, 47L, 55L, 55L, 36L, 36L,
> 61L, 61L), c3 = c(68L, 59L, 68L, 50L, 62L, 50L, 63L, 45L, 65L,
> 45L), id = c(1, 2, 1, 2, 1, 2, 1, 2, 1, 2)), datalabel = "Written by
> R.              ", time.stamp = "23 Mar 2015 13:54", .Names = c("c2",
> "c3", "id"), formats = c("%9.0g", "%9.0g", "%9.0g"), types = c(253L,
> 253L, 255L), val.labels = c("", "", ""), var.labels = c("", "",
> ""), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
> "10"), version = 12L, class = "data.frame")
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Mar 23 14:59:29 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 23 Mar 2015 13:59:29 +0000
Subject: [R] Replace a column value on condition
In-Reply-To: <CAAC1QdAHk5TEj7ivCxtceUgQwHjBt6BA+ZZjtP_eZzPJGNncUA@mail.gmail.com>
References: <CAAC1QdAHk5TEj7ivCxtceUgQwHjBt6BA+ZZjtP_eZzPJGNncUA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C24FA1@SRVEXCHMBX.precheza.cz>

Hi

Thanks for data

df4$c3[df4$id==2] <- df4$c2[df4$id==2]

is one option

df4$c3 <- ifelse(df4$id==2, df4$c2, df4$c3)

If you have NA values you shall use which like in

sel <- which(df4$id==2)
df4$c3[sel] <- df4$c2[sel]

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kuma
> Raj
> Sent: Monday, March 23, 2015 1:59 PM
> To: r-help at r-project.org
> Subject: [R] Replace a column value on condition
>
> I want to replace column c3 with values from column c2 whenever values
> of column Id are 2. In stata I could use replace c3 = c2 if id ==2.
> How could I do that in R?
>
> Thanks
>
>
> Sample data found below:
>
> > dput(df4)
> structure(list(c2 = c(42L, 42L, 47L, 47L, 55L, 55L, 36L, 36L, 61L,
> 61L), c3 = c(68L, 59L, 68L, 50L, 62L, 50L, 63L, 45L, 65L, 45L), id =
> c(1, 2, 1, 2, 1, 2, 1, 2, 1, 2)), datalabel = "Written by
> R.              ", time.stamp = "23 Mar 2015 13:54", .Names = c("c2",
> "c3", "id"), formats = c("%9.0g", "%9.0g", "%9.0g"), types = c(253L,
> 253L, 255L), val.labels = c("", "", ""), var.labels = c("", "", ""),
> row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"),
> version = 12L, class = "data.frame")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From emammendes at gmail.com  Mon Mar 23 15:51:01 2015
From: emammendes at gmail.com (Eduardo M. A. M.Mendes)
Date: Mon, 23 Mar 2015 11:51:01 -0300
Subject: [R] Date as numeric
Message-ID: <FD4FCA4F-8343-459F-8EC8-CEA47B7C1F57@gmail.com>

Hello

I wonder what the formula behind as.numeric("2012-11-11 19:05:00 UTC?) is.

Many thanks

Ed


From abhinabaroy09 at gmail.com  Mon Mar 23 16:10:33 2015
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Mon, 23 Mar 2015 20:40:33 +0530
Subject: [R] Conversion of Matlab code to an R code
Message-ID: <CANtKHPVsOBRRMhtQ4EaLJ-pQ8MJb9niU9M37Mm-EykgSNw3O5A@mail.gmail.com>

Hi,

Can a Matlab code be converted to R code?

I am finding it difficult to do so.

Could you please help me out with it.

Your help will be highly appreciated.

Here comes the Matlab code
##############
if ~isvector(ecg)
  error('ecg must be a row or column vector');
end


if nargin < 3
    gr = 1;   % on default the function always plots
end
ecg = ecg(:); % vectorize

%% Initialize
qrs_c =[]; %amplitude of R
qrs_i =[]; %index
SIG_LEV = 0;
nois_c =[];
nois_i =[];
delay = 0;
skip = 0; % becomes one when a T wave is detected
not_nois = 0; % it is not noise when not_nois = 1
selected_RR =[]; % Selected RR intervals
m_selected_RR = 0;
mean_RR = 0;
qrs_i_raw =[];
qrs_amp_raw=[];
ser_back = 0;
test_m = 0;
SIGL_buf = [];
NOISL_buf = [];
THRS_buf = [];
SIGL_buf1 = [];
NOISL_buf1 = [];
THRS_buf1 = [];


%% Plot differently based on filtering settings
if gr
 if fs == 200
  figure,  ax(1)=subplot(321);plot(ecg);axis tight;title('Raw ECG Signal');
 else
  figure,  ax(1)=subplot(3,2,[1 2]);plot(ecg);axis tight;title('Raw ECG
Signal');
 end
end
%% Noise cancelation(Filtering) % Filters (Filter in between 5-15 Hz)
if fs == 200
%% Low Pass Filter  H(z) = ((1 - z^(-6))^2)/(1 - z^(-1))^2
b = [1 0 0 0 0 0 -2 0 0 0 0 0 1];
a = [1 -2 1];
h_l = filter(b,a,[1 zeros(1,12)]);
ecg_l = conv (ecg ,h_l);
ecg_l = ecg_l/ max( abs(ecg_l));
delay = 6; %based on the paper
if gr
ax(2)=subplot(322);plot(ecg_l);axis tight;title('Low pass filtered');
end
%% High Pass filter H(z) = (-1+32z^(-16)+z^(-32))/(1+z^(-1))
b = [-1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 32 -32 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1];
a = [1 -1];
h_h = filter(b,a,[1 zeros(1,32)]);
ecg_h = conv (ecg_l ,h_h);
ecg_h = ecg_h/ max( abs(ecg_h));
delay = delay + 16; % 16 samples for highpass filtering
if gr
ax(3)=subplot(323);plot(ecg_h);axis tight;title('High Pass Filtered');
end
else
%% bandpass filter for Noise cancelation of other sampling
frequencies(Filtering)
f1=5; %cuttoff low frequency to get rid of baseline wander
f2=15; %cuttoff frequency to discard high frequency noise
Wn=[f1 f2]*2/fs; % cutt off based on fs
N = 3; % order of 3 less processing
[a,b] = butter(N,Wn); %bandpass filtering
ecg_h = filtfilt(a,b,ecg);
ecg_h = ecg_h/ max( abs(ecg_h));
if gr
ax(3)=subplot(323);plot(ecg_h);axis tight;title('Band Pass Filtered');
end
end
%% derivative filter H(z) = (1/8T)(-z^(-2) - 2z^(-1) + 2z + z^(2))
h_d = [-1 -2 0 2 1]*(1/8);%1/8*fs
ecg_d = conv (ecg_h ,h_d);
ecg_d = ecg_d/max(ecg_d);
delay = delay + 2; % delay of derivative filter 2 samples
if gr
ax(4)=subplot(324);plot(ecg_d);axis tight;title('Filtered with the
derivative filter');
end
%% Squaring nonlinearly enhance the dominant peaks
ecg_s = ecg_d.^2;
if gr
ax(5)=subplot(325);plot(ecg_s);axis tight;title('Squared');
end



%% Moving average Y(nt) = (1/N)[x(nT-(N - 1)T)+ x(nT - (N - 2)T)+...+x(nT)]
ecg_m = conv(ecg_s ,ones(1 ,round(0.150*fs))/round(0.150*fs));
delay = delay + 15;

if gr
ax(6)=subplot(326);plot(ecg_m);axis tight;title('Averaged with 30 samples
length,Black noise,Green Adaptive Threshold,RED Sig Level,Red circles QRS
adaptive threshold');
axis tight;
end

%% Fiducial Mark
% Note : a minimum distance of 40 samples is considered between each R wave
% since in physiological point of view no RR wave can occur in less than
% 200 msec distance
[pks,locs] = findpeaks(ecg_m,'MINPEAKDISTANCE',round(0.2*fs));




%% initialize the training phase (2 seconds of the signal) to determine the
THR_SIG and THR_NOISE
THR_SIG = max(ecg_m(1:2*fs))*1/3; % 0.25 of the max amplitude
THR_NOISE = mean(ecg_m(1:2*fs))*1/2; % 0.5 of the mean signal is considered
to be noise
SIG_LEV= THR_SIG;
NOISE_LEV = THR_NOISE;


%% Initialize bandpath filter threshold(2 seconds of the bandpass signal)
THR_SIG1 = max(ecg_h(1:2*fs))*1/3; % 0.25 of the max amplitude
THR_NOISE1 = mean(ecg_h(1:2*fs))*1/2; %
SIG_LEV1 = THR_SIG1; % Signal level in Bandpassed filter
NOISE_LEV1 = THR_NOISE1; % Noise level in Bandpassed filter
%% Thresholding and online desicion rule

for i = 1 : length(pks)

   %% locate the corresponding peak in the filtered signal
    if locs(i)-round(0.150*fs)>= 1 && locs(i)<= length(ecg_h)
          [y_i x_i] = max(ecg_h(locs(i)-round(0.150*fs):locs(i)));
       else
          if i == 1
            [y_i x_i] = max(ecg_h(1:locs(i)));
            ser_back = 1;
          elseif locs(i)>= length(ecg_h)
            [y_i x_i] = max(ecg_h(locs(i)-round(0.150*fs):end));
          end

     end


  %% update the heart_rate (Two heart rate means one the moste recent and
the other selected)
    if length(qrs_c) >= 9

        diffRR = diff(qrs_i(end-8:end)); %calculate RR interval
        mean_RR = mean(diffRR); % calculate the mean of 8 previous R waves
interval
        comp =qrs_i(end)-qrs_i(end-1); %latest RR
        if comp <= 0.92*mean_RR || comp >= 1.16*mean_RR
            % lower down thresholds to detect better in MVI
                THR_SIG = 0.5*(THR_SIG);
                %THR_NOISE = 0.5*(THR_SIG);
               % lower down thresholds to detect better in Bandpass
filtered
                THR_SIG1 = 0.5*(THR_SIG1);
                %THR_NOISE1 = 0.5*(THR_SIG1);

        else
            m_selected_RR = mean_RR; %the latest regular beats mean
        end

    end

      %% calculate the mean of the last 8 R waves to make sure that QRS is
not
       % missing(If no R detected , trigger a search back) 1.66*mean

       if m_selected_RR
           test_m = m_selected_RR; %if the regular RR availabe use it
       elseif mean_RR && m_selected_RR == 0
           test_m = mean_RR;
       else
           test_m = 0;
       end

    if test_m
          if (locs(i) - qrs_i(end)) >= round(1.66*test_m)% it shows a QRS
is missed
              [pks_temp,locs_temp] = max(ecg_m(qrs_i(end)+
round(0.200*fs):locs(i)-round(0.200*fs))); % search back and locate the max
in this interval
              locs_temp = qrs_i(end)+ round(0.200*fs) + locs_temp -1;
%location

              if pks_temp > THR_NOISE
               qrs_c = [qrs_c pks_temp];
               qrs_i = [qrs_i locs_temp];

               % find the location in filtered sig
               if locs_temp <= length(ecg_h)
                [y_i_t x_i_t] =
max(ecg_h(locs_temp-round(0.150*fs):locs_temp));
               else
                [y_i_t x_i_t] = max(ecg_h(locs_temp-round(0.150*fs):end));
               end
               % take care of bandpass signal threshold
               if y_i_t > THR_NOISE1

                      qrs_i_raw = [qrs_i_raw locs_temp-round(0.150*fs)+
(x_i_t - 1)];% save index of bandpass
                      qrs_amp_raw =[qrs_amp_raw y_i_t]; %save amplitude of
bandpass
                      SIG_LEV1 = 0.25*y_i_t + 0.75*SIG_LEV1; %when found
with the second thres
               end

               not_nois = 1;
               SIG_LEV = 0.25*pks_temp + 0.75*SIG_LEV ;  %when found with
the second threshold
             end

          else
              not_nois = 0;

          end
    end




    %%  find noise and QRS peaks
    if pks(i) >= THR_SIG

                 % if a QRS candidate occurs within 360ms of the previous
QRS
                 % ,the algorithm determines if its T wave or QRS
                 if length(qrs_c) >= 3
                      if (locs(i)-qrs_i(end)) <= round(0.3600*fs)
                        Slope1 =
mean(diff(ecg_m(locs(i)-round(0.075*fs):locs(i)))); %mean slope of the
waveform at that position
                        Slope2 =
mean(diff(ecg_m(qrs_i(end)-round(0.075*fs):qrs_i(end)))); %mean slope of
previous R wave
                             if abs(Slope1) <= abs(0.5*(Slope2))  % slope
less then 0.5 of previous R
                                 nois_c = [nois_c pks(i)];
                                 nois_i = [nois_i locs(i)];
                                 skip = 1; % T wave identification
                                 % adjust noise level in both filtered and
                                 % MVI
                                 NOISE_LEV1 = 0.125*y_i + 0.875*NOISE_LEV1;
                                 NOISE_LEV = 0.125*pks(i) +
0.875*NOISE_LEV;
                             else
                                 skip = 0;
                             end

                      end
                 end

        if skip == 0  % skip is 1 when a T wave is detected
        qrs_c = [qrs_c pks(i)];
        qrs_i = [qrs_i locs(i)];

        % bandpass filter check threshold
         if y_i >= THR_SIG1
                        if ser_back
                           qrs_i_raw = [qrs_i_raw x_i];  % save index of
bandpass
                        else
                           qrs_i_raw = [qrs_i_raw locs(i)-round(0.150*fs)+
(x_i - 1)];% save index of bandpass
                        end
                           qrs_amp_raw =[qrs_amp_raw y_i];% save amplitude
of bandpass
          SIG_LEV1 = 0.125*y_i + 0.875*SIG_LEV1;% adjust threshold for
bandpass filtered sig
         end

        % adjust Signal level
        SIG_LEV = 0.125*pks(i) + 0.875*SIG_LEV ;
        end


    elseif THR_NOISE <= pks(i) && pks(i)<THR_SIG

         %adjust Noise level in filtered sig
         NOISE_LEV1 = 0.125*y_i + 0.875*NOISE_LEV1;
         %adjust Noise level in MVI
         NOISE_LEV = 0.125*pks(i) + 0.875*NOISE_LEV;



    elseif pks(i) < THR_NOISE
        nois_c = [nois_c pks(i)];
        nois_i = [nois_i locs(i)];

        % noise level in filtered signal
        NOISE_LEV1 = 0.125*y_i + 0.875*NOISE_LEV1;
        %end

         %adjust Noise level in MVI
        NOISE_LEV = 0.125*pks(i) + 0.875*NOISE_LEV;


    end





    %% adjust the threshold with SNR
    if NOISE_LEV ~= 0 || SIG_LEV ~= 0
        THR_SIG = NOISE_LEV + 0.25*(abs(SIG_LEV - NOISE_LEV));
        THR_NOISE = 0.5*(THR_SIG);
    end

    % adjust the threshold with SNR for bandpassed signal
    if NOISE_LEV1 ~= 0 || SIG_LEV1 ~= 0
        THR_SIG1 = NOISE_LEV1 + 0.25*(abs(SIG_LEV1 - NOISE_LEV1));
        THR_NOISE1 = 0.5*(THR_SIG1);
    end


% take a track of thresholds of smoothed signal
SIGL_buf = [SIGL_buf SIG_LEV];
NOISL_buf = [NOISL_buf NOISE_LEV];
THRS_buf = [THRS_buf THR_SIG];

% take a track of thresholds of filtered signal
SIGL_buf1 = [SIGL_buf1 SIG_LEV1];
NOISL_buf1 = [NOISL_buf1 NOISE_LEV1];
THRS_buf1 = [THRS_buf1 THR_SIG1];




 skip = 0; %reset parameters
 not_nois = 0; %reset parameters
 ser_back = 0;  %reset bandpass param
end

if gr
hold on,scatter(qrs_i,qrs_c,'m');
hold on,plot(locs,NOISL_buf,'--k','LineWidth',2);
hold on,plot(locs,SIGL_buf,'--r','LineWidth',2);
hold on,plot(locs,THRS_buf,'--g','LineWidth',2);
if ax(:)
linkaxes(ax,'x');
zoom on;
end
end




%% overlay on the signals
if gr
figure,az(1)=subplot(311);plot(ecg_h);title('QRS on Filtered Signal');axis
tight;
hold on,scatter(qrs_i_raw,qrs_amp_raw,'m');
hold on,plot(locs,NOISL_buf1,'LineWidth',2,'Linestyle','--','color','k');
hold on,plot(locs,SIGL_buf1,'LineWidth',2,'Linestyle','-.','color','r');
hold on,plot(locs,THRS_buf1,'LineWidth',2,'Linestyle','-.','color','g');
az(2)=subplot(312);plot(ecg_m);title('QRS on MVI signal and Noise
level(black),Signal Level (red) and Adaptive Threshold(green)');axis tight;
hold on,scatter(qrs_i,qrs_c,'m');
hold on,plot(locs,NOISL_buf,'LineWidth',2,'Linestyle','--','color','k');
hold on,plot(locs,SIGL_buf,'LineWidth',2,'Linestyle','-.','color','r');
hold on,plot(locs,THRS_buf,'LineWidth',2,'Linestyle','-.','color','g');
az(3)=subplot(313);plot(ecg-mean(ecg));title('Pulse train of the found QRS
on ECG signal');axis tight;
line(repmat(qrs_i_raw,[2 1]),repmat([min(ecg-mean(ecg))/2;
max(ecg-mean(ecg))/2],size(qrs_i_raw)),'LineWidth',2.5,'LineStyle','-.','Color','r');
linkaxes(az,'x');
zoom on;
end
##############

Regards

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Mon Mar 23 16:20:40 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 23 Mar 2015 15:20:40 +0000
Subject: [R] Date as numeric
In-Reply-To: <FD4FCA4F-8343-459F-8EC8-CEA47B7C1F57@gmail.com>
References: <FD4FCA4F-8343-459F-8EC8-CEA47B7C1F57@gmail.com>
Message-ID: <D1357BF8.12357D%macqueen1@llnl.gov>

No formula behind that:

> as.numeric("2012-11-11 19:05:00 UTC")
[1] NA
Warning message:
NAs introduced by coercion

If a character string is recognizable as a number, you get that number.
For example:

> as.numeric('3')
[1] 3


But your character string isn't recognizable as a number, so you get NA,
meaning a missing value. For another example:
> as.numeric( c('3','a','4') )
[1]  3 NA  4
Warning message:

NAs introduced by coercion



However,
> as.numeric(as.POSIXct("2012-11-11 19:05:00 UTC"))
[1] 1352689500
 
See
 > ?DateTimeClasses

for more information.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/23/15, 7:51 AM, "Eduardo M. A. M.Mendes" <emammendes at gmail.com> wrote:

>Hello
>
>I wonder what the formula behind as.numeric("2012-11-11 19:05:00 UTC?) is.
>
>Many thanks
>
>Ed
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Mon Mar 23 16:23:48 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 23 Mar 2015 08:23:48 -0700
Subject: [R] Conversion of Matlab code to an R code
In-Reply-To: <CANtKHPVsOBRRMhtQ4EaLJ-pQ8MJb9niU9M37Mm-EykgSNw3O5A@mail.gmail.com>
References: <CANtKHPVsOBRRMhtQ4EaLJ-pQ8MJb9niU9M37Mm-EykgSNw3O5A@mail.gmail.com>
Message-ID: <CACk-te1JnHNeDWK7OfTQ5dRGAkeFKAfxqcWbjhU3fuLOsHCsiQ@mail.gmail.com>

1. Yes. Both are Turing complete .

2. Someone here may be willing to help you if you're lucky, but the
standard recommendation is: Do your homework and learn R!  (There are
many good tutorials and resources available).

3. In future, post in plain text, not HTML, as the posting guide asks.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Mar 23, 2015 at 8:10 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> Hi,
>
> Can a Matlab code be converted to R code?
>
> I am finding it difficult to do so.
>
> Could you please help me out with it.
>
> Your help will be highly appreciated.
>
> Here comes the Matlab code
> ##############
> if ~isvector(ecg)
>   error('ecg must be a row or column vector');
> end
>
>
> if nargin < 3
>     gr = 1;   % on default the function always plots
> end
> ecg = ecg(:); % vectorize
>
> %% Initialize
> qrs_c =[]; %amplitude of R
> qrs_i =[]; %index
> SIG_LEV = 0;
> nois_c =[];
> nois_i =[];
> delay = 0;
> skip = 0; % becomes one when a T wave is detected
> not_nois = 0; % it is not noise when not_nois = 1
> selected_RR =[]; % Selected RR intervals
> m_selected_RR = 0;
> mean_RR = 0;
> qrs_i_raw =[];
> qrs_amp_raw=[];
> ser_back = 0;
> test_m = 0;
> SIGL_buf = [];
> NOISL_buf = [];
> THRS_buf = [];
> SIGL_buf1 = [];
> NOISL_buf1 = [];
> THRS_buf1 = [];
>
>
> %% Plot differently based on filtering settings
> if gr
>  if fs == 200
>   figure,  ax(1)=subplot(321);plot(ecg);axis tight;title('Raw ECG Signal');
>  else
>   figure,  ax(1)=subplot(3,2,[1 2]);plot(ecg);axis tight;title('Raw ECG
> Signal');
>  end
> end
> %% Noise cancelation(Filtering) % Filters (Filter in between 5-15 Hz)
> if fs == 200
> %% Low Pass Filter  H(z) = ((1 - z^(-6))^2)/(1 - z^(-1))^2
> b = [1 0 0 0 0 0 -2 0 0 0 0 0 1];
> a = [1 -2 1];
> h_l = filter(b,a,[1 zeros(1,12)]);
> ecg_l = conv (ecg ,h_l);
> ecg_l = ecg_l/ max( abs(ecg_l));
> delay = 6; %based on the paper
> if gr
> ax(2)=subplot(322);plot(ecg_l);axis tight;title('Low pass filtered');
> end
> %% High Pass filter H(z) = (-1+32z^(-16)+z^(-32))/(1+z^(-1))
> b = [-1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 32 -32 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1];
> a = [1 -1];
> h_h = filter(b,a,[1 zeros(1,32)]);
> ecg_h = conv (ecg_l ,h_h);
> ecg_h = ecg_h/ max( abs(ecg_h));
> delay = delay + 16; % 16 samples for highpass filtering
> if gr
> ax(3)=subplot(323);plot(ecg_h);axis tight;title('High Pass Filtered');
> end
> else
> %% bandpass filter for Noise cancelation of other sampling
> frequencies(Filtering)
> f1=5; %cuttoff low frequency to get rid of baseline wander
> f2=15; %cuttoff frequency to discard high frequency noise
> Wn=[f1 f2]*2/fs; % cutt off based on fs
> N = 3; % order of 3 less processing
> [a,b] = butter(N,Wn); %bandpass filtering
> ecg_h = filtfilt(a,b,ecg);
> ecg_h = ecg_h/ max( abs(ecg_h));
> if gr
> ax(3)=subplot(323);plot(ecg_h);axis tight;title('Band Pass Filtered');
> end
> end
> %% derivative filter H(z) = (1/8T)(-z^(-2) - 2z^(-1) + 2z + z^(2))
> h_d = [-1 -2 0 2 1]*(1/8);%1/8*fs
> ecg_d = conv (ecg_h ,h_d);
> ecg_d = ecg_d/max(ecg_d);
> delay = delay + 2; % delay of derivative filter 2 samples
> if gr
> ax(4)=subplot(324);plot(ecg_d);axis tight;title('Filtered with the
> derivative filter');
> end
> %% Squaring nonlinearly enhance the dominant peaks
> ecg_s = ecg_d.^2;
> if gr
> ax(5)=subplot(325);plot(ecg_s);axis tight;title('Squared');
> end
>
>
>
> %% Moving average Y(nt) = (1/N)[x(nT-(N - 1)T)+ x(nT - (N - 2)T)+...+x(nT)]
> ecg_m = conv(ecg_s ,ones(1 ,round(0.150*fs))/round(0.150*fs));
> delay = delay + 15;
>
> if gr
> ax(6)=subplot(326);plot(ecg_m);axis tight;title('Averaged with 30 samples
> length,Black noise,Green Adaptive Threshold,RED Sig Level,Red circles QRS
> adaptive threshold');
> axis tight;
> end
>
> %% Fiducial Mark
> % Note : a minimum distance of 40 samples is considered between each R wave
> % since in physiological point of view no RR wave can occur in less than
> % 200 msec distance
> [pks,locs] = findpeaks(ecg_m,'MINPEAKDISTANCE',round(0.2*fs));
>
>
>
>
> %% initialize the training phase (2 seconds of the signal) to determine the
> THR_SIG and THR_NOISE
> THR_SIG = max(ecg_m(1:2*fs))*1/3; % 0.25 of the max amplitude
> THR_NOISE = mean(ecg_m(1:2*fs))*1/2; % 0.5 of the mean signal is considered
> to be noise
> SIG_LEV= THR_SIG;
> NOISE_LEV = THR_NOISE;
>
>
> %% Initialize bandpath filter threshold(2 seconds of the bandpass signal)
> THR_SIG1 = max(ecg_h(1:2*fs))*1/3; % 0.25 of the max amplitude
> THR_NOISE1 = mean(ecg_h(1:2*fs))*1/2; %
> SIG_LEV1 = THR_SIG1; % Signal level in Bandpassed filter
> NOISE_LEV1 = THR_NOISE1; % Noise level in Bandpassed filter
> %% Thresholding and online desicion rule
>
> for i = 1 : length(pks)
>
>    %% locate the corresponding peak in the filtered signal
>     if locs(i)-round(0.150*fs)>= 1 && locs(i)<= length(ecg_h)
>           [y_i x_i] = max(ecg_h(locs(i)-round(0.150*fs):locs(i)));
>        else
>           if i == 1
>             [y_i x_i] = max(ecg_h(1:locs(i)));
>             ser_back = 1;
>           elseif locs(i)>= length(ecg_h)
>             [y_i x_i] = max(ecg_h(locs(i)-round(0.150*fs):end));
>           end
>
>      end
>
>
>   %% update the heart_rate (Two heart rate means one the moste recent and
> the other selected)
>     if length(qrs_c) >= 9
>
>         diffRR = diff(qrs_i(end-8:end)); %calculate RR interval
>         mean_RR = mean(diffRR); % calculate the mean of 8 previous R waves
> interval
>         comp =qrs_i(end)-qrs_i(end-1); %latest RR
>         if comp <= 0.92*mean_RR || comp >= 1.16*mean_RR
>             % lower down thresholds to detect better in MVI
>                 THR_SIG = 0.5*(THR_SIG);
>                 %THR_NOISE = 0.5*(THR_SIG);
>                % lower down thresholds to detect better in Bandpass
> filtered
>                 THR_SIG1 = 0.5*(THR_SIG1);
>                 %THR_NOISE1 = 0.5*(THR_SIG1);
>
>         else
>             m_selected_RR = mean_RR; %the latest regular beats mean
>         end
>
>     end
>
>       %% calculate the mean of the last 8 R waves to make sure that QRS is
> not
>        % missing(If no R detected , trigger a search back) 1.66*mean
>
>        if m_selected_RR
>            test_m = m_selected_RR; %if the regular RR availabe use it
>        elseif mean_RR && m_selected_RR == 0
>            test_m = mean_RR;
>        else
>            test_m = 0;
>        end
>
>     if test_m
>           if (locs(i) - qrs_i(end)) >= round(1.66*test_m)% it shows a QRS
> is missed
>               [pks_temp,locs_temp] = max(ecg_m(qrs_i(end)+
> round(0.200*fs):locs(i)-round(0.200*fs))); % search back and locate the max
> in this interval
>               locs_temp = qrs_i(end)+ round(0.200*fs) + locs_temp -1;
> %location
>
>               if pks_temp > THR_NOISE
>                qrs_c = [qrs_c pks_temp];
>                qrs_i = [qrs_i locs_temp];
>
>                % find the location in filtered sig
>                if locs_temp <= length(ecg_h)
>                 [y_i_t x_i_t] =
> max(ecg_h(locs_temp-round(0.150*fs):locs_temp));
>                else
>                 [y_i_t x_i_t] = max(ecg_h(locs_temp-round(0.150*fs):end));
>                end
>                % take care of bandpass signal threshold
>                if y_i_t > THR_NOISE1
>
>                       qrs_i_raw = [qrs_i_raw locs_temp-round(0.150*fs)+
> (x_i_t - 1)];% save index of bandpass
>                       qrs_amp_raw =[qrs_amp_raw y_i_t]; %save amplitude of
> bandpass
>                       SIG_LEV1 = 0.25*y_i_t + 0.75*SIG_LEV1; %when found
> with the second thres
>                end
>
>                not_nois = 1;
>                SIG_LEV = 0.25*pks_temp + 0.75*SIG_LEV ;  %when found with
> the second threshold
>              end
>
>           else
>               not_nois = 0;
>
>           end
>     end
>
>
>
>
>     %%  find noise and QRS peaks
>     if pks(i) >= THR_SIG
>
>                  % if a QRS candidate occurs within 360ms of the previous
> QRS
>                  % ,the algorithm determines if its T wave or QRS
>                  if length(qrs_c) >= 3
>                       if (locs(i)-qrs_i(end)) <= round(0.3600*fs)
>                         Slope1 =
> mean(diff(ecg_m(locs(i)-round(0.075*fs):locs(i)))); %mean slope of the
> waveform at that position
>                         Slope2 =
> mean(diff(ecg_m(qrs_i(end)-round(0.075*fs):qrs_i(end)))); %mean slope of
> previous R wave
>                              if abs(Slope1) <= abs(0.5*(Slope2))  % slope
> less then 0.5 of previous R
>                                  nois_c = [nois_c pks(i)];
>                                  nois_i = [nois_i locs(i)];
>                                  skip = 1; % T wave identification
>                                  % adjust noise level in both filtered and
>                                  % MVI
>                                  NOISE_LEV1 = 0.125*y_i + 0.875*NOISE_LEV1;
>                                  NOISE_LEV = 0.125*pks(i) +
> 0.875*NOISE_LEV;
>                              else
>                                  skip = 0;
>                              end
>
>                       end
>                  end
>
>         if skip == 0  % skip is 1 when a T wave is detected
>         qrs_c = [qrs_c pks(i)];
>         qrs_i = [qrs_i locs(i)];
>
>         % bandpass filter check threshold
>          if y_i >= THR_SIG1
>                         if ser_back
>                            qrs_i_raw = [qrs_i_raw x_i];  % save index of
> bandpass
>                         else
>                            qrs_i_raw = [qrs_i_raw locs(i)-round(0.150*fs)+
> (x_i - 1)];% save index of bandpass
>                         end
>                            qrs_amp_raw =[qrs_amp_raw y_i];% save amplitude
> of bandpass
>           SIG_LEV1 = 0.125*y_i + 0.875*SIG_LEV1;% adjust threshold for
> bandpass filtered sig
>          end
>
>         % adjust Signal level
>         SIG_LEV = 0.125*pks(i) + 0.875*SIG_LEV ;
>         end
>
>
>     elseif THR_NOISE <= pks(i) && pks(i)<THR_SIG
>
>          %adjust Noise level in filtered sig
>          NOISE_LEV1 = 0.125*y_i + 0.875*NOISE_LEV1;
>          %adjust Noise level in MVI
>          NOISE_LEV = 0.125*pks(i) + 0.875*NOISE_LEV;
>
>
>
>     elseif pks(i) < THR_NOISE
>         nois_c = [nois_c pks(i)];
>         nois_i = [nois_i locs(i)];
>
>         % noise level in filtered signal
>         NOISE_LEV1 = 0.125*y_i + 0.875*NOISE_LEV1;
>         %end
>
>          %adjust Noise level in MVI
>         NOISE_LEV = 0.125*pks(i) + 0.875*NOISE_LEV;
>
>
>     end
>
>
>
>
>
>     %% adjust the threshold with SNR
>     if NOISE_LEV ~= 0 || SIG_LEV ~= 0
>         THR_SIG = NOISE_LEV + 0.25*(abs(SIG_LEV - NOISE_LEV));
>         THR_NOISE = 0.5*(THR_SIG);
>     end
>
>     % adjust the threshold with SNR for bandpassed signal
>     if NOISE_LEV1 ~= 0 || SIG_LEV1 ~= 0
>         THR_SIG1 = NOISE_LEV1 + 0.25*(abs(SIG_LEV1 - NOISE_LEV1));
>         THR_NOISE1 = 0.5*(THR_SIG1);
>     end
>
>
> % take a track of thresholds of smoothed signal
> SIGL_buf = [SIGL_buf SIG_LEV];
> NOISL_buf = [NOISL_buf NOISE_LEV];
> THRS_buf = [THRS_buf THR_SIG];
>
> % take a track of thresholds of filtered signal
> SIGL_buf1 = [SIGL_buf1 SIG_LEV1];
> NOISL_buf1 = [NOISL_buf1 NOISE_LEV1];
> THRS_buf1 = [THRS_buf1 THR_SIG1];
>
>
>
>
>  skip = 0; %reset parameters
>  not_nois = 0; %reset parameters
>  ser_back = 0;  %reset bandpass param
> end
>
> if gr
> hold on,scatter(qrs_i,qrs_c,'m');
> hold on,plot(locs,NOISL_buf,'--k','LineWidth',2);
> hold on,plot(locs,SIGL_buf,'--r','LineWidth',2);
> hold on,plot(locs,THRS_buf,'--g','LineWidth',2);
> if ax(:)
> linkaxes(ax,'x');
> zoom on;
> end
> end
>
>
>
>
> %% overlay on the signals
> if gr
> figure,az(1)=subplot(311);plot(ecg_h);title('QRS on Filtered Signal');axis
> tight;
> hold on,scatter(qrs_i_raw,qrs_amp_raw,'m');
> hold on,plot(locs,NOISL_buf1,'LineWidth',2,'Linestyle','--','color','k');
> hold on,plot(locs,SIGL_buf1,'LineWidth',2,'Linestyle','-.','color','r');
> hold on,plot(locs,THRS_buf1,'LineWidth',2,'Linestyle','-.','color','g');
> az(2)=subplot(312);plot(ecg_m);title('QRS on MVI signal and Noise
> level(black),Signal Level (red) and Adaptive Threshold(green)');axis tight;
> hold on,scatter(qrs_i,qrs_c,'m');
> hold on,plot(locs,NOISL_buf,'LineWidth',2,'Linestyle','--','color','k');
> hold on,plot(locs,SIGL_buf,'LineWidth',2,'Linestyle','-.','color','r');
> hold on,plot(locs,THRS_buf,'LineWidth',2,'Linestyle','-.','color','g');
> az(3)=subplot(313);plot(ecg-mean(ecg));title('Pulse train of the found QRS
> on ECG signal');axis tight;
> line(repmat(qrs_i_raw,[2 1]),repmat([min(ecg-mean(ecg))/2;
> max(ecg-mean(ecg))/2],size(qrs_i_raw)),'LineWidth',2.5,'LineStyle','-.','Color','r');
> linkaxes(az,'x');
> zoom on;
> end
> ##############
>
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Mon Mar 23 16:30:17 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 23 Mar 2015 10:30:17 -0500
Subject: [R] Conversion of Matlab code to an R code
In-Reply-To: <CANtKHPVsOBRRMhtQ4EaLJ-pQ8MJb9niU9M37Mm-EykgSNw3O5A@mail.gmail.com>
References: <CANtKHPVsOBRRMhtQ4EaLJ-pQ8MJb9niU9M37Mm-EykgSNw3O5A@mail.gmail.com>
Message-ID: <D9D45843-457B-4674-A6A4-5FC4C41999B7@me.com>


> On Mar 23, 2015, at 10:10 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> 
> Hi,
> 
> Can a Matlab code be converted to R code?
> 
> I am finding it difficult to do so.
> 
> Could you please help me out with it.
> 
> Your help will be highly appreciated.
> 
> Here comes the Matlab code

<snip of code>


Hi,

Not do the conversion automatically, certainly.

I don't know that anyone will volunteer here to convert such a large volume of code, though I could be wrong of course.

That being said, there are two R/Matlab references that you should leverage, if you have not already:

  http://www.math.umaine.edu/~hiebeler/comp/matlabR.pdf

  http://mathesaurus.sourceforge.net/octave-r.html


That might make your job a bit easier.

Regards,

Marc Schwartz


From roy.mendelssohn at noaa.gov  Mon Mar 23 16:31:52 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 23 Mar 2015 08:31:52 -0700
Subject: [R] Conversion of Matlab code to an R code
In-Reply-To: <CANtKHPVsOBRRMhtQ4EaLJ-pQ8MJb9niU9M37Mm-EykgSNw3O5A@mail.gmail.com>
References: <CANtKHPVsOBRRMhtQ4EaLJ-pQ8MJb9niU9M37Mm-EykgSNw3O5A@mail.gmail.com>
Message-ID: <BA126693-62E7-4309-B0D9-F0D8C527613B@noaa.gov>


On Mar 23, 2015, at 8:10 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:

> Hi,
> 
> Can a Matlab code be converted to R code?
> 
> I am finding it difficult to do so.
> 
> Could you please help me out with it.
> 
> Your help will be highly appreciated.
<snip>

If you mean something that can do an automatic conversion I am unaware of any such program.  However, if you Google, say:

?Matlab R comparison?

you will find many links, such as ?R For Matlab Users"

http://mathesaurus.sourceforge.net/octave-r.html:

which can guide you through converting the code.

HTH,

-Roy


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From varinsacha at yahoo.fr  Mon Mar 23 16:54:37 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Mon, 23 Mar 2015 15:54:37 +0000 (UTC)
Subject: [R] Superimposing 2 curves on the same graph with par(new=TRUE)
Message-ID: <1221930182.1466416.1427126077785.JavaMail.yahoo@mail.yahoo.com>

Dear R-Experts,

I try to superimpose/present 2 curves/plots on the same graph. I would like the result/graph to be readable.
For that, I use the par(new=TRUE) argument but on the Y-axis there is a superposition of writings and the Y-axis becomes unreadable.
How can I solve this problem ?

Here is a reproducible example :
Date<-c(1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010)
 
MORTSFr<-c(16445,17671,18113,17043,14738,14355,15028,14283,13229,13603,13672,13547,13527,13021,12737,11388,11947,10742,11497,11476,11215,10483,9900,9568,9019,8891,8541,8444,8918,8487,8079,8160,7655,6058,5593,5318,4709,4620,4275,4273,3992)
 
MORTSBu<-c(838,889,934,946,960,1030,1021,1040,1153,1149,1199,1219,1229,1123,1119,1113,1070,1153,1153,1280,1567,1114,1299,1307,1390,1264,1014,915,1003,1047,1012,1011,959,960,943,957,1043,1006,1061,901,776)
 
plot(Date,MORTSFr,type="l")
par(new=TRUE)

plot(Date,MORTSBu,lwd=2,lty="dashed")

Thanks for your time.
Best,
S


From wdunlap at tibco.com  Mon Mar 23 16:59:04 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 23 Mar 2015 08:59:04 -0700
Subject: [R] 1st script
In-Reply-To: <menprj$5t8$1@ger.gmane.org>
References: <menprj$5t8$1@ger.gmane.org>
Message-ID: <CAF8bMcZbOCq=6FfsZX839WiRDv6JNnAhHFQL5Zsnw_DCO41cfw@mail.gmail.com>

> # Import CSV file into a data frame.
> case_weights <- read.csv(file = "case_weights.csv")
>
> # For each row, take the number in the Weight column and replicate it
> # as many times as there are in each count column.
> LC09 <- rep(case_weights$Weight, case_weights$LC09)
> LC10 <- rep(case_weights$Weight, case_weights$LC10)

My stock advice is to add code that checks that the
stuff you read from the file has the expected format.
Do this right after the read.csv.

The stopifnot function gives a quick way to code the checks and it
helps to write helper functions when checks must be repeated.   E.g.
    allNonNegIntegers <- function(x) is.numeric(x) && all(!is.na(x) & x >=
0 & x%%1==0)
    stopifnot(
        all(c("Weight", "LC09", "LC10") %in% names(case_weights)),
        is.numeric(case_weights$Weight),
        allNonNegIntegers(case_weights$LC09),
        allNonNegIntegers(case_weights$LC10),
        <... more comma-separated check expressions>)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Mar 22, 2015 at 6:21 PM, memilanuk <memilanuk at gmail.com> wrote:

> So... wrote my first script, rather than just using the interactive
> console.  I think I got everything working more or less the way I want, but
> I'm sure there's a ton of room for improvement.  Specifically in the way of
> automation - but thats where I kind of ran out of steam.  Any suggestions
> would be much appreciated.
>
> case_data.r
>
> # Import CSV file into a data frame.
> case_weights <- read.csv(file = "case_weights.csv")
>
> # For each row, take the number in the Weight column and replicate it
> # as many times as there are in each count column.
> LC09 <- rep(case_weights$Weight, case_weights$LC09)
> LC10 <- rep(case_weights$Weight, case_weights$LC10)
> LP14b1 <- rep(case_weights$Weight, case_weights$LP14b1)
> LP14b2 <- rep(case_weights$Weight, case_weights$LP14b2)
>
> # Determine the longest vector, to help with the next step.
> max.len <- max(length(LC09), length(LC10), length(LP14b1),
>                 length(LP14b2))
>
> # Pad each vector with NA so they are all the same length and will
> # go in a data frame.
> LC09 <- c(LC09, rep(NA, max.len - length(LC09)))
> LC10 <- c(LC10, rep(NA, max.len - length(LC10)))
> LP14b1 <- c(LP14b1, rep(NA, max.len - length(LP14b1)))
> LP14b2 <- c(LP14b2, rep(NA, max.len - length(LP14b2)))
>
> # Stick everything back into one data frame.
> case_dat <- data.frame(LC09)
> case_dat$LC10 <- LC10
> case_dat$LP14b1 <- LP14b1
> case_dat$LP14b2 <- LP14b2
>
> # Stuff said data frame back into a CSV for use elsewhere (plot.ly).
> write.csv(case_dat, file = "expanded_case_weights.csv")
>
> # Boxplot it
> boxplot(case_dat, varwidth = TRUE, notch = TRUE, horizontal = TRUE,
>         main = "Case Weights", xlab = "Weight (grains)",
>         ylab = "Batch", las = 1, names = c("LC09", "LC10", "LP14b1",
>         "LP14b2"))
>
>
>
> --
> Shiny!  Let's be bad guys.
>
> Reach me @ memilanuk (at) gmail dot com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Mar 23 17:18:47 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 23 Mar 2015 12:18:47 -0400
Subject: [R] Superimposing 2 curves on the same graph with par(new=TRUE)
In-Reply-To: <1221930182.1466416.1427126077785.JavaMail.yahoo@mail.yahoo.com>
References: <1221930182.1466416.1427126077785.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <62C683E9-0EC3-4344-9531-84A417F49973@utoronto.ca>

Here is how:

plot(Date,MORTSFr,type="l", ylim=c(0,max(MORTSFr)))
points(Date,MORTSBu,type="l",lty=2)


If you don't use the same scale for the two plots, you are probably misrepresenting the data. If you want to plot relative change, normalize the data before plotting.

norm <- function(x) {(x - min(x))/(max(x) - min(x))}
plot(Date,norm(MORTSFr),ylab=c("Relative Change"),type="l")
points(Date,norm(MORTSBu),type="l",lty=2)


B.

On Mar 23, 2015, at 11:54 AM, varin sacha <varinsacha at yahoo.fr> wrote:

> Dear R-Experts,
> 
> I try to superimpose/present 2 curves/plots on the same graph. I would like the result/graph to be readable.
> For that, I use the par(new=TRUE) argument but on the Y-axis there is a superposition of writings and the Y-axis becomes unreadable.
> How can I solve this problem ?
> 
> Here is a reproducible example :
> Date<-c(1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010)
> 
> MORTSFr<-c(16445,17671,18113,17043,14738,14355,15028,14283,13229,13603,13672,13547,13527,13021,12737,11388,11947,10742,11497,11476,11215,10483,9900,9568,9019,8891,8541,8444,8918,8487,8079,8160,7655,6058,5593,5318,4709,4620,4275,4273,3992)
> 
> MORTSBu<-c(838,889,934,946,960,1030,1021,1040,1153,1149,1199,1219,1229,1123,1119,1113,1070,1153,1153,1280,1567,1114,1299,1307,1390,1264,1014,915,1003,1047,1012,1011,959,960,943,957,1043,1006,1061,901,776)
> 
> plot(Date,MORTSFr,type="l")
> par(new=TRUE)
> 
> plot(Date,MORTSBu,lwd=2,lty="dashed")
> 
> Thanks for your time.
> Best,
> S
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From clint at ecy.wa.gov  Mon Mar 23 17:34:42 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Mon, 23 Mar 2015 09:34:42 -0700 (PDT)
Subject: [R] Superimposing 2 curves on the same graph with par(new=TRUE)
In-Reply-To: <1221930182.1466416.1427126077785.JavaMail.yahoo@mail.yahoo.com>
References: <1221930182.1466416.1427126077785.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <alpine.LRH.2.11.1503230930210.19659@aeolus.ecy.wa.gov>

Try:
plot(Date,MORTSBu,lwd=2,lty="dashed",axes=F,xlab="",ylab="")



Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Mon, 23 Mar 2015, varin sacha wrote:

> Dear R-Experts,
>
> I try to superimpose/present 2 curves/plots on the same graph. I would like the result/graph to be readable.
> For that, I use the par(new=TRUE) argument but on the Y-axis there is a superposition of writings and the Y-axis becomes unreadable.
> How can I solve this problem ?
>
> Here is a reproducible example :
> Date<-c(1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010)
>
> MORTSFr<-c(16445,17671,18113,17043,14738,14355,15028,14283,13229,13603,13672,13547,13527,13021,12737,11388,11947,10742,11497,11476,11215,10483,9900,9568,9019,8891,8541,8444,8918,8487,8079,8160,7655,6058,5593,5318,4709,4620,4275,4273,3992)
>
> MORTSBu<-c(838,889,934,946,960,1030,1021,1040,1153,1149,1199,1219,1229,1123,1119,1113,1070,1153,1153,1280,1567,1114,1299,1307,1390,1264,1014,915,1003,1047,1012,1011,959,960,943,957,1043,1006,1061,901,776)
>
> plot(Date,MORTSFr,type="l")
> par(new=TRUE)
>
> plot(Date,MORTSBu,lwd=2,lty="dashed")
>
> Thanks for your time.
> Best,
> S
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From boris.steipe at utoronto.ca  Mon Mar 23 18:04:05 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 23 Mar 2015 13:04:05 -0400
Subject: [R] Superimposing 2 curves on the same graph with par(new=TRUE)
In-Reply-To: <alpine.LRH.2.11.1503230930210.19659@aeolus.ecy.wa.gov>
References: <1221930182.1466416.1427126077785.JavaMail.yahoo@mail.yahoo.com>
	<alpine.LRH.2.11.1503230930210.19659@aeolus.ecy.wa.gov>
Message-ID: <2B8BEE2D-7D8C-45D7-8040-59A079C35FB5@utoronto.ca>

... which is exactly what he shouldn't do because now it the plot falsely asserts that both curves are plotted to the same scale.


B.



On Mar 23, 2015, at 12:34 PM, Clint Bowman <clint at ecy.wa.gov> wrote:

> Try:
> plot(Date,MORTSBu,lwd=2,lty="dashed",axes=F,xlab="",ylab="")
> 
> 
> 
> Clint Bowman			INTERNET:	clint at ecy.wa.gov
> Air Quality Modeler		INTERNET:	clint at math.utah.edu
> Department of Ecology		VOICE:		(360) 407-6815
> PO Box 47600			FAX:		(360) 407-7534
> Olympia, WA 98504-7600
> 
>        USPS:           PO Box 47600, Olympia, WA 98504-7600
>        Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
> 
> On Mon, 23 Mar 2015, varin sacha wrote:
> 
>> Dear R-Experts,
>> 
>> I try to superimpose/present 2 curves/plots on the same graph. I would like the result/graph to be readable.
>> For that, I use the par(new=TRUE) argument but on the Y-axis there is a superposition of writings and the Y-axis becomes unreadable.
>> How can I solve this problem ?
>> 
>> Here is a reproducible example :
>> Date<-c(1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010)
>> 
>> MORTSFr<-c(16445,17671,18113,17043,14738,14355,15028,14283,13229,13603,13672,13547,13527,13021,12737,11388,11947,10742,11497,11476,11215,10483,9900,9568,9019,8891,8541,8444,8918,8487,8079,8160,7655,6058,5593,5318,4709,4620,4275,4273,3992)
>> 
>> MORTSBu<-c(838,889,934,946,960,1030,1021,1040,1153,1149,1199,1219,1229,1123,1119,1113,1070,1153,1153,1280,1567,1114,1299,1307,1390,1264,1014,915,1003,1047,1012,1011,959,960,943,957,1043,1006,1061,901,776)
>> 
>> plot(Date,MORTSFr,type="l")
>> par(new=TRUE)
>> 
>> plot(Date,MORTSBu,lwd=2,lty="dashed")
>> 
>> Thanks for your time.
>> Best,
>> S
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Mon Mar 23 18:13:02 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 23 Mar 2015 12:13:02 -0500
Subject: [R] Superimposing 2 curves on the same graph with par(new=TRUE)
In-Reply-To: <2B8BEE2D-7D8C-45D7-8040-59A079C35FB5@utoronto.ca>
References: <1221930182.1466416.1427126077785.JavaMail.yahoo@mail.yahoo.com>
	<alpine.LRH.2.11.1503230930210.19659@aeolus.ecy.wa.gov>
	<2B8BEE2D-7D8C-45D7-8040-59A079C35FB5@utoronto.ca>
Message-ID: <EDA5185C-C0DB-4D18-95C1-CDEC9CA23F61@me.com>

Hi,

If he wants the two sets of data plotted on the same y axis scale, with the range of the y axis adjusted to the data, an alternative to the use of plot() and points() is:

  matplot(Date, cbind(MORTSFr, MORTSBu), type = "l")


See ?matplot

Regards,

Marc Schwartz


> On Mar 23, 2015, at 12:04 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> ... which is exactly what he shouldn't do because now it the plot falsely asserts that both curves are plotted to the same scale.
> 
> 
> B.
> 
> 
> 
> On Mar 23, 2015, at 12:34 PM, Clint Bowman <clint at ecy.wa.gov> wrote:
> 
>> Try:
>> plot(Date,MORTSBu,lwd=2,lty="dashed",axes=F,xlab="",ylab="")
>> 
>> 
>> 
>> Clint Bowman			INTERNET:	clint at ecy.wa.gov
>> Air Quality Modeler		INTERNET:	clint at math.utah.edu
>> Department of Ecology		VOICE:		(360) 407-6815
>> PO Box 47600			FAX:		(360) 407-7534
>> Olympia, WA 98504-7600
>> 
>>       USPS:           PO Box 47600, Olympia, WA 98504-7600
>>       Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>> 
>> On Mon, 23 Mar 2015, varin sacha wrote:
>> 
>>> Dear R-Experts,
>>> 
>>> I try to superimpose/present 2 curves/plots on the same graph. I would like the result/graph to be readable.
>>> For that, I use the par(new=TRUE) argument but on the Y-axis there is a superposition of writings and the Y-axis becomes unreadable.
>>> How can I solve this problem ?
>>> 
>>> Here is a reproducible example :
>>> Date<-c(1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010)
>>> 
>>> MORTSFr<-c(16445,17671,18113,17043,14738,14355,15028,14283,13229,13603,13672,13547,13527,13021,12737,11388,11947,10742,11497,11476,11215,10483,9900,9568,9019,8891,8541,8444,8918,8487,8079,8160,7655,6058,5593,5318,4709,4620,4275,4273,3992)
>>> 
>>> MORTSBu<-c(838,889,934,946,960,1030,1021,1040,1153,1149,1199,1219,1229,1123,1119,1113,1070,1153,1153,1280,1567,1114,1299,1307,1390,1264,1014,915,1003,1047,1012,1011,959,960,943,957,1043,1006,1061,901,776)
>>> 
>>> plot(Date,MORTSFr,type="l")
>>> par(new=TRUE)
>>> 
>>> plot(Date,MORTSBu,lwd=2,lty="dashed")
>>> 
>>> Thanks for your time.
>>> Best,
>>> S


From clint at ecy.wa.gov  Mon Mar 23 19:14:25 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Mon, 23 Mar 2015 11:14:25 -0700 (PDT)
Subject: [R] Superimposing 2 curves on the same graph with par(new=TRUE)
In-Reply-To: <2B8BEE2D-7D8C-45D7-8040-59A079C35FB5@utoronto.ca>
References: <1221930182.1466416.1427126077785.JavaMail.yahoo@mail.yahoo.com>
	<alpine.LRH.2.11.1503230930210.19659@aeolus.ecy.wa.gov>
	<2B8BEE2D-7D8C-45D7-8040-59A079C35FB5@utoronto.ca>
Message-ID: <alpine.LRH.2.11.1503231113050.19659@aeolus.ecy.wa.gov>

Agreed--I neglected to add the secondary y-axis (shouldn't hit send so 
fast.)

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Mon, 23 Mar 2015, Boris Steipe wrote:

> ... which is exactly what he shouldn't do because now it the plot falsely asserts that both curves are plotted to the same scale.
>
>
> B.
>
>
>
> On Mar 23, 2015, at 12:34 PM, Clint Bowman <clint at ecy.wa.gov> wrote:
>
>> Try:
>> plot(Date,MORTSBu,lwd=2,lty="dashed",axes=F,xlab="",ylab="")
>>
>>
>>
>> Clint Bowman			INTERNET:	clint at ecy.wa.gov
>> Air Quality Modeler		INTERNET:	clint at math.utah.edu
>> Department of Ecology		VOICE:		(360) 407-6815
>> PO Box 47600			FAX:		(360) 407-7534
>> Olympia, WA 98504-7600
>>
>>        USPS:           PO Box 47600, Olympia, WA 98504-7600
>>        Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>>
>> On Mon, 23 Mar 2015, varin sacha wrote:
>>
>>> Dear R-Experts,
>>>
>>> I try to superimpose/present 2 curves/plots on the same graph. I would like the result/graph to be readable.
>>> For that, I use the par(new=TRUE) argument but on the Y-axis there is a superposition of writings and the Y-axis becomes unreadable.
>>> How can I solve this problem ?
>>>
>>> Here is a reproducible example :
>>> Date<-c(1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010)
>>>
>>> MORTSFr<-c(16445,17671,18113,17043,14738,14355,15028,14283,13229,13603,13672,13547,13527,13021,12737,11388,11947,10742,11497,11476,11215,10483,9900,9568,9019,8891,8541,8444,8918,8487,8079,8160,7655,6058,5593,5318,4709,4620,4275,4273,3992)
>>>
>>> MORTSBu<-c(838,889,934,946,960,1030,1021,1040,1153,1149,1199,1219,1229,1123,1119,1113,1070,1153,1153,1280,1567,1114,1299,1307,1390,1264,1014,915,1003,1047,1012,1011,959,960,943,957,1043,1006,1061,901,776)
>>>
>>> plot(Date,MORTSFr,type="l")
>>> par(new=TRUE)
>>>
>>> plot(Date,MORTSBu,lwd=2,lty="dashed")
>>>
>>> Thanks for your time.
>>> Best,
>>> S
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From boris.steipe at utoronto.ca  Mon Mar 23 19:32:08 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 23 Mar 2015 14:32:08 -0400
Subject: [R] Superimposing 2 curves on the same graph with par(new=TRUE)
In-Reply-To: <alpine.LRH.2.11.1503231113050.19659@aeolus.ecy.wa.gov>
References: <1221930182.1466416.1427126077785.JavaMail.yahoo@mail.yahoo.com>
	<alpine.LRH.2.11.1503230930210.19659@aeolus.ecy.wa.gov>
	<2B8BEE2D-7D8C-45D7-8040-59A079C35FB5@utoronto.ca>
	<alpine.LRH.2.11.1503231113050.19659@aeolus.ecy.wa.gov>
Message-ID: <C14F8107-C322-46B5-A97D-D16650314C31@utoronto.ca>

... and that gives you a "double ordinate plot", a staple of misleading statistics.

Let me give you an analogy: 

Imagine you are on a chemistry mailing list and someone asks about the proper way to mix aluminum powder with fertilizer. Of course, as a chemist you know how. But still - and the same holds for the "double ordinate plot" - just say no.


:-)


For reference (taken from a post on SO):
Junk charts:
  http://junkcharts.typepad.com/junk_charts/2006/06/illusion_of_suc.html
  http://junkcharts.typepad.com/junk_charts/2006/05/the_crossover_l.html
Perecptual Edge ( a more detailed analysis)
  http://www.perceptualedge.com/articles/visual_business_intelligence/dual-scaled_axes.pdf
SMBC's tutorial on infographics (point 4).
  http://www.smbc-comics.com/?id=3167



On Mar 23, 2015, at 2:14 PM, Clint Bowman <clint at ecy.wa.gov> wrote:

> Agreed--I neglected to add the secondary y-axis (shouldn't hit send so fast.)
> 
> Clint Bowman			INTERNET:	clint at ecy.wa.gov
> Air Quality Modeler		INTERNET:	clint at math.utah.edu
> Department of Ecology		VOICE:		(360) 407-6815
> PO Box 47600			FAX:		(360) 407-7534
> Olympia, WA 98504-7600
> 
>        USPS:           PO Box 47600, Olympia, WA 98504-7600
>        Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
> 
> On Mon, 23 Mar 2015, Boris Steipe wrote:
> 
>> ... which is exactly what he shouldn't do because now it the plot falsely asserts that both curves are plotted to the same scale.
>> 
>> 
>> B.
>> 
>> 
>> 
>> On Mar 23, 2015, at 12:34 PM, Clint Bowman <clint at ecy.wa.gov> wrote:
>> 
>>> Try:
>>> plot(Date,MORTSBu,lwd=2,lty="dashed",axes=F,xlab="",ylab="")
>>> 
>>> 
>>> 
>>> Clint Bowman			INTERNET:	clint at ecy.wa.gov
>>> Air Quality Modeler		INTERNET:	clint at math.utah.edu
>>> Department of Ecology		VOICE:		(360) 407-6815
>>> PO Box 47600			FAX:		(360) 407-7534
>>> Olympia, WA 98504-7600
>>> 
>>>       USPS:           PO Box 47600, Olympia, WA 98504-7600
>>>       Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>>> 
>>> On Mon, 23 Mar 2015, varin sacha wrote:
>>> 
>>>> Dear R-Experts,
>>>> 
>>>> I try to superimpose/present 2 curves/plots on the same graph. I would like the result/graph to be readable.
>>>> For that, I use the par(new=TRUE) argument but on the Y-axis there is a superposition of writings and the Y-axis becomes unreadable.
>>>> How can I solve this problem ?
>>>> 
>>>> Here is a reproducible example :
>>>> Date<-c(1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010)
>>>> 
>>>> MORTSFr<-c(16445,17671,18113,17043,14738,14355,15028,14283,13229,13603,13672,13547,13527,13021,12737,11388,11947,10742,11497,11476,11215,10483,9900,9568,9019,8891,8541,8444,8918,8487,8079,8160,7655,6058,5593,5318,4709,4620,4275,4273,3992)
>>>> 
>>>> MORTSBu<-c(838,889,934,946,960,1030,1021,1040,1153,1149,1199,1219,1229,1123,1119,1113,1070,1153,1153,1280,1567,1114,1299,1307,1390,1264,1014,915,1003,1047,1012,1011,959,960,943,957,1043,1006,1061,901,776)
>>>> 
>>>> plot(Date,MORTSFr,type="l")
>>>> par(new=TRUE)
>>>> 
>>>> plot(Date,MORTSBu,lwd=2,lty="dashed")
>>>> 
>>>> Thanks for your time.
>>>> Best,
>>>> S
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 


From lindnerw at t-online.de  Mon Mar 23 19:38:42 2015
From: lindnerw at t-online.de (Dr. Wolfgang Lindner)
Date: Mon, 23 Mar 2015 19:38:42 +0100
Subject: [R] the making of _R_ eBooks
References: <48E60F6FD5CD45C0A7AA320694FB1F8E@Petra>
	<CAAJSdjjb+NjvFKm7tLpSQj_AjGO2YoiAY-8HQ9rcdCvhN3WQjQ@mail.gmail.com>
Message-ID: <B53C078468FD4DEFA19998B61F525356@Petra>

Dear John,

thank you for your kind answer and the historical excursions.
Your detailed post may help and inform other readers, too.
Thanks for your hint to TexStudio (I use[d] Texworks, Texshell, WinEDT).
So TeX will not be the problem, but I have first to learn about texinfo.

| > Thanks for any hint or link by expert R users.
| Oh, well, that excludes me. I'm not an expert.

No, your answer includes you :)
It was very helpful.
Indeed, I should better have said 'enthusiastic R users' ;)

best
Wolfgang


----- Original Message ----- 
From: "John McKown" <john.archie.mckown at gmail.com>
To: "Dr. Wolfgang Lindner" <lindnerw at t-online.de>
Cc: "Help R" <r-help at r-project.org>
Sent: Monday, March 23, 2015 1:36 PM
Subject: Re: [R] the making of _R_ eBooks


| On Mon, Mar 23, 2015 at 3:50 AM, Dr. Wolfgang Lindner
| <lindnerw at t-online.de> wrote:
| > Dear list members,
| >
| > I like the look and feel of the eBook versions of the R manuals very
much.
| > So I would like to generate eBooks (teaching material etc) in that look.
|
| I am not an expert. But I have looked at the source, so I can give you
| some information.
|
| >
| > Q1: is there a description how the _R_ ebooks have been produced?
|
| Looking at the source, it appears that the source manuals are in a
| document markup language called "GNU Texinfo".
| https://www.gnu.org/software/texinfo/
| You can think of this as something akin to, but different from, HTML
| or "markdown" encoding. Texinfo is an evolution by the system first
| designed by Richard Stallman of MIT. He is the driving force behind
| the GPL and most of the GNU software which forms the basis of the user
| space commands for Linux and the *BSD operating systems. Texinfo is
| then converted to TeX. TeX is the typesetting language designed by Dr.
| Donald Knuth. TeX, nominally, is converted into a DVI printer control
| language (DeVice Independent). But in the case of creating a PDF file,
| there is a processor called "pdftex",
| http://en.wikipedia.org/wiki/PdfTeX, which produces a PDF file as
| output . A good site for TeX is https://tug.org/
|
| Texinfo has the plus of also having processor which will convert it to
| UNIX "man" (manual) pages and HTML web pages. So one "source" document
| can generate three different types of output document file types.
|
| Most people use a enhanced TeX called LaTeX instead of "plain TeX"
| when using TeX. LaTeX can be read up on here:
| http://www.latex-project.org/ A good TeX document processor is
| TeXstudio at http://texstudio.sourceforge.net/ . I use this one myself
| (which is not necessary a strong endorsement because I'm nobody
| special).
|
| I feel the need to warn you that TeX is very powerful and, at least to
| me, quite difficult, with a fairly step learning curve. Which may be
| why the R project uses Texinfo because it is quite a bit easier to
| learn.
|
|
| > Q2: which (free) software was used for them?
|
| See the links above. On Fedora Linux, I get the TeX oriented software
| from a bunch of packages which start with "texlive". More information,
| including the processors for Linux, Windows, and Mac are at
| https://www.tug.org/texlive/
|
| > Q3: any other recommendations?
|
| You might consider LyX.
| http://www.lyx.org/
| LyX is a document processor. It would likely be easier to use than the
| above if you are used to MS Word or other word processing system. It
| is cross platform: Linux, Windows, and Mac. It stores files in its own
| textual format, which is somewhat human readable. LyX, like Texinfo,
| translates its format into TeX as an intermediate on its way to its
| ultimate destination. I am still learning LyX, but I personally like
| it.
|
| Your mention of LibreOffice is also a fairly good one. I, personally,
| use LibreOffice. But I don't use it for big documents. I have a
| learned aversion for word processors because it is so easy for them to
| be misused. In my opinion, a good document needs good metadata in it
| as well as just "looking pretty". Word processor users tend to focus
| on the format and not the content. That's just my opinion, based on
| what I've seen where I work.
|
| >
| > Seaching the internet gives me e.g.
| > [1]
| >
https://sites.google.com/site/richardbyrnepdsite/ebooks-and-audiobooks/create-your-own-ebooks
| > [2]  opensource.com/life/13/8/how-create-ebook-open-source-way
| > [3]
http://scottnesbitt.net/ubuntublog/creating-a-ebook-with-libreoffice-writer/
| >
| > but I m not sure, if there are better possibilities..
| >
| > Thanks for any hint or link by expert R users.
|
| Oh, well, that excludes me. I'm not an expert. But maybe it was helpful
anyway.
|
| >
| > Wolfgang Lindner
| > Leichlingen, Germany
|
| -- 
| If you sent twitter messages while exploring, are you on a textpedition?
|
| He's about as useful as a wax frying pan.
|
| 10 to the 12th power microphones = 1 Megaphone
|
| Maranatha! <><
| John McKown
|
| ______________________________________________
| R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
| https://stat.ethz.ch/mailman/listinfo/r-help
| PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
| and provide commented, minimal, self-contained, reproducible code.


From lindnerw at t-online.de  Mon Mar 23 19:39:19 2015
From: lindnerw at t-online.de (Dr. Wolfgang Lindner)
Date: Mon, 23 Mar 2015 19:39:19 +0100
Subject: [R] the making of _R_ eBooks
References: <48E60F6FD5CD45C0A7AA320694FB1F8E@Petra>
	<55100361.9010603@stats.ox.ac.uk>
Message-ID: <139BF08E8346428F9ED95A8CADDD6C7B@Petra>

Dear Prof. Ripley,

thank you for the 2 links w/r to my question.
Section 2.3 in 'R Installation and Administration' seems very condensed to
me. But there is a mention of Calibre, I will read about all that.

| > PLEASE do read the posting guide
| PLEASE do!

I did.

Best
Wolfgang Lindner


----- Original Message ----- 
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Dr. Wolfgang Lindner" <lindnerw at t-online.de>; "Help R"
<r-help at r-project.org>
Sent: Monday, March 23, 2015 1:13 PM
Subject: Re: [R] the making of _R_ eBooks


| On 23/03/2015 08:50, Dr. Wolfgang Lindner wrote:
| > Dear list members,
| >
| > I like the look and feel of the eBook versions of the R manuals very
much.
| > So I would like to generate eBooks (teaching material etc) in that look.
| >
| > Q1: is there a description how the _R_ ebooks have been produced?
| > Q2: which (free) software was used for them?
| > Q3: any other recommendations?
|
| fortunes::fortune(14) applies.  In this case TM is
|
http://cran.r-project.org/doc/manuals/r-release/R-admin.html#Making-the-manuals
| .
|
| >
| > Seaching the internet gives me e.g.
| > [1]
| >
https://sites.google.com/site/richardbyrnepdsite/ebooks-and-audiobooks/create-your-own-ebooks
| > [2]  opensource.com/life/13/8/how-create-ebook-open-source-way
| > [3]
| >
http://scottnesbitt.net/ubuntublog/creating-a-ebook-with-libreoffice-writer/
| >
| > but I m not sure, if there are better possibilities..
| >
| > Thanks for any hint or link by expert R users.
| >
| > Wolfgang Lindner
| > Leichlingen, Germany
|
| > PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
|
| PLEASE do!
|
| -- 
| Brian D. Ripley,                  ripley at stats.ox.ac.uk
| Emeritus Professor of Applied Statistics, University of Oxford
| 1 South Parks Road, Oxford OX1 3TG, UK


From johannesradinger at gmail.com  Mon Mar 23 19:40:19 2015
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Mon, 23 Mar 2015 19:40:19 +0100
Subject: [R] Optimization to fit data to custom density distribution
In-Reply-To: <550D8303.1060204@stats.ox.ac.uk>
References: <CABsGe_w0UP2WeqcsGXb2qaegZZAGKUhwpk+jCaxo0oCOcZLKjw@mail.gmail.com>
	<550D6F38.5000406@stats.ox.ac.uk>
	<CABsGe_yrHCpz2-0fwJp+PS4PpM849ZFuGQMiDNx-YqCUGXA0Zw@mail.gmail.com>
	<550D8303.1060204@stats.ox.ac.uk>
Message-ID: <CABsGe_zmE=yJAAKfHwtoMR2kj69Z2swC4efzrCtV-LHuDZ8Apw@mail.gmail.com>

On Sat, Mar 21, 2015 at 3:41 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk>
wrote:

> On 21/03/2015 14:27, Johannes Radinger wrote:
>
>> Thanks for the fast response. The fitdistr() function works well for the
>> predefined density functions. However, what is the recommended approach
>> to optimize/fit a density function described by two superimposed normal
>> distributions? In my case it is N1(mean=0,sd1)*p+N2(mean=0,sd2)*(1-p).
>> With fitdistr one can only choose among the 15 distributions. Probably
>>
>
> That is simply not true.  The help says
>
> densfun: Either a character string or a function returning a density
>           evaluated at its first argument.
>
> and the second alternative is used in the examples.


Of course, that was my mistake. So fitdistr() works fine for this case.
Here an example to complete that case:

x <- c(rnorm(mean=0,sd=50,70),rnorm(mean=0,sd=500,30))
hist(x,breaks=30)

ddoublenorm <- function(x,sigma_stat,sigma_mob,p) {
  dnorm(x,mean=0,sd=sigma_stat)*p+dnorm(x,mean=0,sd=sigma_mob)*(1-p)}

fitdistr(x=x,densfun=ddoublenorm,
start=list(sigma_stat=30,sigma_mob=300,p=0.5),

 method="L-BFGS-B",lower=c(0.001,0.001,0.00001),upper=c(Inf,Inf,0.99999))

Thanks a lot!

Best regards,
Johannes


>
>
>  this needs an approach using optim()? However I am so far unfamiliar
>> with these packages. So any suggestion ist welcome. :)
>>
>
> There are examples of that in MASS (the book), chapter 16.
>
>
>> /Johannes
>>
>> On Sat, Mar 21, 2015 at 2:16 PM, Prof Brian Ripley
>> <ripley at stats.ox.ac.uk <mailto:ripley at stats.ox.ac.uk>> wrote:
>>
>>     One way using the standard R distribution:
>>
>>     library(MASS)
>>     ?fitdistr
>>
>>     No optimization is needed to fit a normal distribution, though.
>>
>>
>>     On 21/03/2015 13:05, Johannes Radinger wrote:
>>
>>         Hi,
>>
>>         I am looking for a way to fit data (vector of values) to a
>>         density function
>>         using an optimization (ordinary least squares or maximum
>>         likelihood fit).
>>         For example if I have a vector of 100 values generated with rnorm:
>>
>>         rnorm(n=100,mean=500,sd=50)
>>
>>         How can I fit these data to a Gaussian density function to
>>         extract the mean
>>         and sd value of the underlying normal distribution. So the
>>         result should
>>         roughly meet the parameters of the normal distribution used to
>>         generate the
>>         data. The results will ideally be closer the true parameters the
>>         more data
>>         (n) are used to optimize the density function.
>>
>>
>>     That's a concept called 'consistency' from the statistical theory of
>>     estimation.  If you skipped that course, time to read up (but it is
>>     off-topic here).
>>
>>     --
>>     Brian D. Ripley, ripley at stats.ox.ac.uk <mailto:ripley at stats.ox.ac.uk>
>>     Emeritus Professor of Applied Statistics, University of Oxford
>>     1 South Parks Road, Oxford OX1 3TG, UK
>>
>>
>>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>

	[[alternative HTML version deleted]]


From imdb.subscribe at gmail.com  Mon Mar 23 09:31:03 2015
From: imdb.subscribe at gmail.com (im db)
Date: Mon, 23 Mar 2015 08:31:03 +0000 (UTC)
Subject: [R] Connecting Context layer to hidden layer in RSNNS package in R
In-Reply-To: <1455241940.619622.1427099426478.JavaMail.yahoo@mail.yahoo.com>
References: <1455241940.619622.1427099426478.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <120332870.632793.1427099463839.JavaMail.yahoo@mail.yahoo.com>




?Dear All,
 I'm using RSNNS package in R to simulate Elman Network (1991).Here I have more than 1 hidden layer, (10,70,10).
if I want to connect the hidden layer with size 70 to the context layer (It means I would like to have a context layer of size 70), what should I do?
Thank you so much in advance. I need your answer today. 
Best Regards

   
	[[alternative HTML version deleted]]


From Lluis.Hurtado at uv.es  Mon Mar 23 11:44:59 2015
From: Lluis.Hurtado at uv.es (Lluis.Hurtado at uv.es)
Date: Mon, 23 Mar 2015 11:44:59 +0100 (CET)
Subject: [R] Fast evaluation of functions in 3D domains
Message-ID: <5468595262hurgil@uv.es>

Dear all,

I am currently working with the spatstat package with 3D samples. I am trying to 
evaluate a non analytical function over the window that encloses the sample and I 
need to know which is the fastest way of doing it.

The function input is a 3 coordinate position in the window (x,y,z) and a list of 
parameters (a,b,c). The output is a numerical value. 

n <- function(x,y,z,a,b,c)

But I need to do it over the whole volume.

For 2 dimensions it can be done with

A <- as.im(function,window,parameters)
norm <- integral.im(A)

For 3 dimensions I have tried to pass an array of a grid covering the window (like a 
quadrature scheme) and then summing up the output array, but I would like to know if 
there is any faster way of integrating the function.

Thank you very much,

Llu?s Hurtado
IFCA
www.ifca.unican.es


From lucam1968 at gmail.com  Mon Mar 23 09:10:16 2015
From: lucam1968 at gmail.com (Luca Meyer)
Date: Mon, 23 Mar 2015 09:10:16 +0100
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <E8907230-83F6-4489-ABBF-6CD2A59EFD9D@comcast.net>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
	<CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
	<CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>
	<CACk-te2CBQXFGJ-Vhr+kpdY6uccbn0Rp286ca+2YvKO=iHUogg@mail.gmail.com>
	<CACk-te0sTVt5pPb9f-ELgTt8L0Bbaz2NCQ9S4ZsB5e122vdYYA@mail.gmail.com>
	<CABQyo86dF4UQH94v1Q-rFMBV=JRmwc3V9SFgG=ZiwtGatKTwPg@mail.gmail.com>
	<CACk-te3xkirW755s1WSETEEj0wvS=d=FneZw4r=dS=jK3RHNcQ@mail.gmail.com>
	<CACk-te22ZaM5p5H7Wz1ivN24S5zog-FY=AvdHQEbdz2O7AL2gA@mail.gmail.com>
	<CABQyo864GFSgDAEgRrf-0TQhrYLufNv96v2q00-YAb4nsVWYyw@mail.gmail.com>
	<CABQyo86r0h_6R2u8cm3Amg0pPnC7b+Tuy9t3zOiNFqmsTa2DEA@mail.gmail.com>
	<CACk-te1p_PeLO-rbzxo3MBMYWYfWHTf7FkoNhJ+8XafD6mh2ng@mail.gmail.com>
	<CABQyo85jd5xyecoBncF6QesE+YgHLTiv6xHAiVmziWVxY=Oijw@mail.gmail.com>
	<E8907230-83F6-4489-ABBF-6CD2A59EFD9D@comcast.net>
Message-ID: <CABQyo87HOPfwCiiLEQj=wb1jJb01zgU1i-PKPYHzfDL0aZ11Sw@mail.gmail.com>

Hi David, hello R-experts

Thank you for your input. I have tried the syntax you suggested but
unfortunately the marginal distributions v1xv2 change after the
manipulation. Please see below or
https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0 for the
syntax.

> rm(list=ls())
>
> # this is usual (an extract of) the INPUT file I have:
> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
+ "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
+ "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
+ "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917,
1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
+ 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names
= c(2L,
+ 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>
> #first I order the file such that I have 6 distinct v1xv2 combinations
> f1 <- f1[order(f1$v1,f1$v2),]
>
> # then I compute (manually) the relative importance of each v1xv2
combination:
> tAA <-
(18.18530+1.42917)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
# this is for combination v1=A & v2=A
> tAB <-
(3.43806+1.05786)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
# this is for combination v1=A & v2=B
> tAC <-
(0.00273+0.00042)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
# this is for combination v1=A & v2=C
> tBA <-
(2.37232+1.13430)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
# this is for combination v1=B & v2=A
> tBB <-
(3.01835+0.92872)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
# this is for combination v1=B & v2=B
> tBC <-
(0.00000+0.00000)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
# this is for combination v1=B & v2=C
> # and just to make sure I have not made mistakes the following should be
equal to 1
> tAA+tAB+tAC+tBA+tBB+tBC
[1] 1
>
> # procedure suggested by David Winsemius
> lookarr <- array(NA,
dim=c(length(unique(f1$v1)),length(unique(f1$v2)),length(unique(f1$v3)) ) ,
dimnames=list( unique(f1$v1), unique(f1$v2), unique(f1$v3) ) )
> lookarr[] <- c(tAA,tAA,tAB,tAB,tAC,tAC,tBA,tBA,tBB,tBB,tBC,tBC)
> lookarr["A","B","C"]
[1] 0.1250369
> lookarr[ with(f1, cbind(v1, v2, v3)) ]
 [1] 6.213554e-01 1.110842e-01 1.424236e-01 1.250369e-01 9.978703e-05
0.000000e+00 6.213554e-01 1.110842e-01 1.424236e-01 1.250369e-01
9.978703e-05
[12] 0.000000e+00
> f1$v4mod <- f1$v4*lookarr[ with(f1, cbind(v1,v2,v3)) ]
>
> # i compare original vs modified marginal distributions
> aggregate(v4~v1*v2,f1,sum)
  v1 v2       v4
1  A  A 19.61447
2  B  A  3.50662
3  A  B  4.49592
4  B  B  3.94707
5  A  C  0.00315
6  B  C  0.00000
> aggregate(v4mod~v1*v2,f1,sum)
  v1 v2        v4mod
1  A  A 1.145829e+01
2  B  A 1.600057e+00
3  A  B 6.219326e-01
4  B  B 5.460087e-01
5  A  C 2.724186e-07
6  B  C 0.000000e+00
> aggregate(v4~v3,f1,sum)
  v3       v4
1  B 27.01676
2  C  4.55047
> aggregate(v4mod~v3,f1,sum)
  v3      v4mod
1  B 13.6931347
2  C  0.5331569

Any suggestion on how this can be fixed? Remember, I am searching for a
solution where by aggregate(v4~v1*v2,f1,sum)==aggregate(v4~v1*v2,f1,sum)
while aggregate(v4~v3,f1,sum)!=aggregate(v4mod~v3,f1,sum) by specified
amounts (see my earlier example).

Thank you very much,

Luca


2015-03-22 22:11 GMT+01:00 David Winsemius <dwinsemius at comcast.net>:

>
> On Mar 22, 2015, at 1:12 PM, Luca Meyer wrote:
>
> > Hi Bert,
> >
> > Maybe I did not explain myself clearly enough. But let me show you with a
> > manual example that indeed what I would like to do is feasible.
> >
> > The following is also available for download from
> > https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
> >
> > rm(list=ls())
> >
> > This is usual (an extract of) the INPUT file I have:
> >
> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> > "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> > "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> > "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917,
> > 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> > 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names
> =
> > c(2L,
> > 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >
> > This are the initial marginal distributions
> >
> > aggregate(v4~v1*v2,f1,sum)
> > aggregate(v4~v3,f1,sum)
> >
> > First I order the file such that I have nicely listed 6 distinct v1xv2
> > combinations.
> >
> > f1 <- f1[order(f1$v1,f1$v2),]
> >
> > Then I compute (manually) the relative importance of each v1xv2
> combination:
> >
> > tAA <-
> >
> (18.18530+1.42917)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> > # this is for combination v1=A & v2=A
> > tAB <-
> >
> (3.43806+1.05786)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> > # this is for combination v1=A & v2=B
> > tAC <-
> >
> (0.00273+0.00042)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> > # this is for combination v1=A & v2=C
> > tBA <-
> >
> (2.37232+1.13430)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> > # this is for combination v1=B & v2=A
> > tBB <-
> >
> (3.01835+0.92872)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> > # this is for combination v1=B & v2=B
> > tBC <-
> >
> (0.00000+0.00000)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> > # this is for combination v1=B & v2=C
> > # and just to make sure I have not made mistakes the following should be
> > equal to 1
> > tAA+tAB+tAC+tBA+tBB+tBC
> >
> > Next, I know I need to increase v4 any time v3=B and the total increase I
> > need to have over the whole dataset is 29-27.01676=1.98324. In turn, I
> need
> > to dimish v4 any time V3=C by the same amount (4.55047-2.56723=1.98324).
> > This aspect was perhaps not clear at first. I need to move v4 across v3
> > categories, but the totals will always remain unchanged.
> >
> > Since I want the data alteration to be proportional to the v1xv2
> > combinations I do the following:
> >
> > f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="A" & f1$v3=="B",
> f1$v4+(tAA*1.98324),
> > f1$v4)
> > f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="A" & f1$v3=="C",
> f1$v4-(tAA*1.98324),
> > f1$v4)
> > f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="B" & f1$v3=="B",
> f1$v4+(tAB*1.98324),
> > f1$v4)
> > f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="B" & f1$v3=="C",
> f1$v4-(tAB*1.98324),
> > f1$v4)
> > f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="C" & f1$v3=="B",
> f1$v4+(tAC*1.98324),
> > f1$v4)
> > f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="C" & f1$v3=="C",
> f1$v4-(tAC*1.98324),
> > f1$v4)
> > f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="A" & f1$v3=="B",
> f1$v4+(tBA*1.98324),
> > f1$v4)
> > f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="A" & f1$v3=="C",
> f1$v4-(tBA*1.98324),
> > f1$v4)
> > f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="B" & f1$v3=="B",
> f1$v4+(tBB*1.98324),
> > f1$v4)
> > f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="B" & f1$v3=="C",
> f1$v4-(tBB*1.98324),
> > f1$v4)
> > f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="C" & f1$v3=="B",
> f1$v4+(tBC*1.98324),
> > f1$v4)
> > f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="C" & f1$v3=="C",
> f1$v4-(tBC*1.98324),
> > f1$v4)
> >
>
> Seems that this could be done a lot more simply with a lookup matrix and
> ordinary indexing
>
> > lookarr <- array(NA,
> dim=c(length(unique(f1$v1)),length(unique(f1$v2)),length(unique(f1$v3)) ) ,
> dimnames=list( unique(f1$v1), unique(f1$v2), unique(f1$v3) ) )
> > lookarr[] <- c(tAA,tAA,tAB,tAB,tAC,tAC,tBA,tBA,
>                  tBB, tBB, tBC, tBC)
>
> > lookarr[ "A","B","C"]
> [1] 0.1250369
>
> > lookarr[ with(f1, cbind(v1, v2, v3)) ]
>  [1] 6.213554e-01 1.110842e-01 1.424236e-01 1.250369e-01 9.978703e-05
>  [6] 0.000000e+00 6.213554e-01 1.110842e-01 1.424236e-01 1.250369e-01
> [11] 9.978703e-05 0.000000e+00
> > f1$v4mod <- f1$v4*lookarr[ with(f1, cbind(v1,v2,v3)) ]
> > f1
>     v1 v2 v3       v4        v4mod
> 2    A  A  B 18.18530 1.129954e+01
> 41   A  A  C  1.42917 1.587582e-01
> 9    A  B  B  3.43806 4.896610e-01
> 48   A  B  C  1.05786 1.322716e-01
> 11   A  C  B  0.00273 2.724186e-07
> 50   A  C  C  0.00042 0.000000e+00
> 158  B  A  B  2.37232 1.474054e+00
> 197  B  A  C  1.13430 1.260028e-01
> 165  B  B  B  3.01835 4.298844e-01
> 204  B  B  C  0.92872 1.161243e-01
> 167  B  C  B  0.00000 0.000000e+00
> 206  B  C  C  0.00000 0.000000e+00
>
> --
> david.
>
>
> > This are the final marginal distributions:
> >
> > aggregate(v4~v1*v2,f1,sum)
> > aggregate(v4~v3,f1,sum)
> >
> > Can this procedure be made programmatic so that I can run it on the
> > (8x13x13) categories matrix? if so, how would you do it? I have really
> hard
> > time to do it with some (semi)automatic procedure.
> >
> > Thank you very much indeed once more :)
> >
> > Luca
> >
> >
> > 2015-03-22 18:32 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
> >
> >> Nonsense. You are not telling us something or I have failed to
> >> understand something.
> >>
> >> Consider:
> >>
> >> v1 = c("a","b")
> >> v2 = "c("a","a")
> >>
> >> It is not possible to change the value of a sum of values
> >> corresponding to v2="a" without also changing that for v1, which is
> >> not supposed to change according to my understanding of your
> >> specification.
> >>
> >> So I'm done.
> >>
> >> -- Bert
> >>
> >>
> >> Bert Gunter
> >> Genentech Nonclinical Biostatistics
> >> (650) 467-7374
> >>
> >> "Data is not information. Information is not knowledge. And knowledge
> >> is certainly not wisdom."
> >> Clifford Stoll
> >>
> >>
> >>
> >>
> >> On Sun, Mar 22, 2015 at 8:28 AM, Luca Meyer <lucam1968 at gmail.com>
> wrote:
> >>> Sorry forgot to keep the rest of the group in the loop - Luca
> >>> ---------- Forwarded message ----------
> >>> From: Luca Meyer <lucam1968 at gmail.com>
> >>> Date: 2015-03-22 16:27 GMT+01:00
> >>> Subject: Re: [R] Joining two datasets - recursive procedure?
> >>> To: Bert Gunter <gunter.berton at gene.com>
> >>>
> >>>
> >>> Hi Bert,
> >>>
> >>> That is exactly what I am trying to achieve. Please notice that
> negative
> >> v4
> >>> values are allowed. I have done a similar task in the past manually by
> >>> recursively alterating v4 distribution across v3 categories within fix
> >> each
> >>> v1&v2 combination so I am quite positive it can be achieved but
> honestly
> >> I
> >>> took me forever to do it manually and since this is likely to be an
> >>> exercise I need to repeat from time to time I wish I could learn how to
> >> do
> >>> it programmatically....
> >>>
> >>> Thanks again for any further suggestion you might have,
> >>>
> >>> Luca
> >>>
> >>>
> >>> 2015-03-22 16:05 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
> >>>
> >>>> Oh, wait a minute ...
> >>>>
> >>>> You still want the marginals for the other columns to be as
> originally?
> >>>>
> >>>> If so, then this is impossible in general as the sum of all the values
> >>>> must be what they were originally and you cannot therefore choose your
> >>>> values for V3 arbitrarily.
> >>>>
> >>>> Or at least, that seems to be what you are trying to do.
> >>>>
> >>>> -- Bert
> >>>>
> >>>> Bert Gunter
> >>>> Genentech Nonclinical Biostatistics
> >>>> (650) 467-7374
> >>>>
> >>>> "Data is not information. Information is not knowledge. And knowledge
> >>>> is certainly not wisdom."
> >>>> Clifford Stoll
> >>>>
> >>>>
> >>>>
> >>>>
> >>>> On Sun, Mar 22, 2015 at 7:55 AM, Bert Gunter <bgunter at gene.com>
> wrote:
> >>>>> I would have thought that this is straightforward given my previous
> >>>> email...
> >>>>>
> >>>>> Just set z to what you want -- e,g, all B values to 29/number of B's,
> >>>>> and all C values to 2.567/number of C's (etc. for more categories).
> >>>>>
> >>>>> A slick but sort of cheat way to do this programmatically -- in the
> >>>>> sense that it relies on the implementation of factor() rather than
> its
> >>>>> API -- is:
> >>>>>
> >>>>> y <- f1$v3  ## to simplify the notation; could be done using with()
> >>>>> z <- (c(29,2.567)/table(y))[c(y)]
> >>>>>
> >>>>> Then proceed to z1 as I previously described
> >>>>>
> >>>>> -- Bert
> >>>>>
> >>>>>
> >>>>> Bert Gunter
> >>>>> Genentech Nonclinical Biostatistics
> >>>>> (650) 467-7374
> >>>>>
> >>>>> "Data is not information. Information is not knowledge. And knowledge
> >>>>> is certainly not wisdom."
> >>>>> Clifford Stoll
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> On Sun, Mar 22, 2015 at 2:00 AM, Luca Meyer <lucam1968 at gmail.com>
> >> wrote:
> >>>>>> Hi Bert, hello R-experts,
> >>>>>>
> >>>>>> I am close to a solution but I still need one hint w.r.t. the
> >> following
> >>>>>> procedure (available also from
> >>>>>> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0)
> >>>>>>
> >>>>>> rm(list=ls())
> >>>>>>
> >>>>>> # this is (an extract of) the INPUT file I have:
> >>>>>> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> >> "B",
> >>>>>> "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A", "B", "C",
> >> "A",
> >>>>>> "B", "C"), v3 = c("B", "B", "B", "C", "C", "C", "B", "B", "B", "C",
> >> "C",
> >>>>>> "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917, 1.05786, 0.00042,
> >>>> 2.37232,
> >>>>>> 3.01835, 0, 1.13430, 0.92872, 0)), .Names = c("v1", "v2", "v3",
> >> "v4"),
> >>>> class
> >>>>>> = "data.frame", row.names = c(2L, 9L, 11L, 41L, 48L, 50L, 158L,
> 165L,
> >>>> 167L,
> >>>>>> 197L, 204L, 206L))
> >>>>>>
> >>>>>> # this is the procedure that Bert suggested (slightly adjusted):
> >>>>>> z <- rnorm(nrow(f1)) ## or anything you want
> >>>>>> z1 <- round(with(f1,v4 + z -ave(z,v1,v2,FUN=mean)), digits=5)
> >>>>>> aggregate(v4~v1*v2,f1,sum)
> >>>>>> aggregate(z1~v1*v2,f1,sum)
> >>>>>> aggregate(v4~v3,f1,sum)
> >>>>>> aggregate(z1~v3,f1,sum)
> >>>>>>
> >>>>>> My question to you is: how can I set z so that I can obtain specific
> >>>> values
> >>>>>> for z1-v4 in the v3 aggregation?
> >>>>>> In other words, how can I configure the procedure so that e.g. B=29
> >> and
> >>>>>> C=2.56723 after running the procedure:
> >>>>>> aggregate(z1~v3,f1,sum)
> >>>>>>
> >>>>>> Thank you,
> >>>>>>
> >>>>>> Luca
> >>>>>>
> >>>>>> PS: to avoid any doubts you might have about who I am the following
> >> is
> >>>> my
> >>>>>> web page: http://lucameyer.wordpress.com/
> >>>>>>
> >>>>>>
> >>>>>> 2015-03-21 18:13 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
> >>>>>>>
> >>>>>>> ... or cleaner:
> >>>>>>>
> >>>>>>> z1 <- with(f1,v4 + z -ave(z,v1,v2,FUN=mean))
> >>>>>>>
> >>>>>>>
> >>>>>>> Just for curiosity, was this homework? (in which case I should
> >>>>>>> probably have not provided you an answer -- that is, assuming that
> I
> >>>>>>> HAVE provided an answer).
> >>>>>>>
> >>>>>>> Cheers,
> >>>>>>> Bert
> >>>>>>>
> >>>>>>> Bert Gunter
> >>>>>>> Genentech Nonclinical Biostatistics
> >>>>>>> (650) 467-7374
> >>>>>>>
> >>>>>>> "Data is not information. Information is not knowledge. And
> >> knowledge
> >>>>>>> is certainly not wisdom."
> >>>>>>> Clifford Stoll
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> On Sat, Mar 21, 2015 at 7:53 AM, Bert Gunter <bgunter at gene.com>
> >> wrote:
> >>>>>>>> z <- rnorm(nrow(f1)) ## or anything you want
> >>>>>>>> z1 <- f1$v4 + z - with(f1,ave(z,v1,v2,FUN=mean))
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> aggregate(v4~v1,f1,sum)
> >>>>>>>> aggregate(z1~v1,f1,sum)
> >>>>>>>> aggregate(v4~v2,f1,sum)
> >>>>>>>> aggregate(z1~v2,f1,sum)
> >>>>>>>> aggregate(v4~v3,f1,sum)
> >>>>>>>> aggregate(z1~v3,f1,sum)
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> Cheers,
> >>>>>>>> Bert
> >>>>>>>>
> >>>>>>>> Bert Gunter
> >>>>>>>> Genentech Nonclinical Biostatistics
> >>>>>>>> (650) 467-7374
> >>>>>>>>
> >>>>>>>> "Data is not information. Information is not knowledge. And
> >> knowledge
> >>>>>>>> is certainly not wisdom."
> >>>>>>>> Clifford Stoll
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> On Sat, Mar 21, 2015 at 6:49 AM, Luca Meyer <lucam1968 at gmail.com>
> >>>> wrote:
> >>>>>>>>> Hi Bert,
> >>>>>>>>>
> >>>>>>>>> Thank you for your message. I am looking into ave() and tapply()
> >> as
> >>>> you
> >>>>>>>>> suggested but at the same time I have prepared a example of input
> >>>> and
> >>>>>>>>> output
> >>>>>>>>> files, just in case you or someone else would like to make an
> >>>> attempt
> >>>>>>>>> to
> >>>>>>>>> generate a code that goes from input to output.
> >>>>>>>>>
> >>>>>>>>> Please see below or download it from
> >>>>>>>>> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
> >>>>>>>>>
> >>>>>>>>> # this is (an extract of) the INPUT file I have:
> >>>>>>>>> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
> >> "B",
> >>>>>>>>> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >>>>>>>>> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >>>>>>>>> "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273,
> >>>>>>>>> 1.42917,
> >>>>>>>>> 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> >>>>>>>>> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> >>>>>>>>> row.names =
> >>>>>>>>> c(2L,
> >>>>>>>>> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >>>>>>>>>
> >>>>>>>>> # this is (an extract of) the OUTPUT file I would like to obtain:
> >>>>>>>>> f2 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
> >> "B",
> >>>>>>>>> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >>>>>>>>> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >>>>>>>>> "B", "B", "B", "C", "C", "C"), v4 = c(17.83529, 3.43806,0.00295,
> >>>>>>>>> 1.77918,
> >>>>>>>>> 1.05786, 0.0002, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> >>>>>>>>> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> >>>>>>>>> row.names =
> >>>>>>>>> c(2L,
> >>>>>>>>> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >>>>>>>>>
> >>>>>>>>> # please notice that while the aggregated v4 on v3 has changed ?
> >>>>>>>>> aggregate(f1[,c("v4")],list(f1$v3),sum)
> >>>>>>>>> aggregate(f2[,c("v4")],list(f2$v3),sum)
> >>>>>>>>>
> >>>>>>>>> # ? the aggregated v4 over v1xv2 has remained unchanged:
> >>>>>>>>> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
> >>>>>>>>> aggregate(f2[,c("v4")],list(f2$v1,f2$v2),sum)
> >>>>>>>>>
> >>>>>>>>> Thank you very much in advance for your assitance.
> >>>>>>>>>
> >>>>>>>>> Luca
> >>>>>>>>>
> >>>>>>>>> 2015-03-21 13:18 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
> >>>>>>>>>>
> >>>>>>>>>> 1. Still not sure what you mean, but maybe look at ?ave and
> >>>> ?tapply,
> >>>>>>>>>> for which ave() is a wrapper.
> >>>>>>>>>>
> >>>>>>>>>> 2. You still need to heed the rest of Jeff's advice.
> >>>>>>>>>>
> >>>>>>>>>> Cheers,
> >>>>>>>>>> Bert
> >>>>>>>>>>
> >>>>>>>>>> Bert Gunter
> >>>>>>>>>> Genentech Nonclinical Biostatistics
> >>>>>>>>>> (650) 467-7374
> >>>>>>>>>>
> >>>>>>>>>> "Data is not information. Information is not knowledge. And
> >>>> knowledge
> >>>>>>>>>> is certainly not wisdom."
> >>>>>>>>>> Clifford Stoll
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <
> >> lucam1968 at gmail.com>
> >>>>>>>>>> wrote:
> >>>>>>>>>>> Hi Jeff & other R-experts,
> >>>>>>>>>>>
> >>>>>>>>>>> Thank you for your note. I have tried myself to solve the
> >> issue
> >>>>>>>>>>> without
> >>>>>>>>>>> success.
> >>>>>>>>>>>
> >>>>>>>>>>> Following your suggestion, I am providing a sample of the
> >>>> dataset I
> >>>>>>>>>>> am
> >>>>>>>>>>> using below (also downloadble in plain text from
> >>>>>>>>>>>
> >> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
> >>>>>>>>>>>
> >>>>>>>>>>> #this is an extract of the overall dataset (n=1200 cases)
> >>>>>>>>>>> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
> >>>> "B",
> >>>>>>>>>>> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> >>>>>>>>>>> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> >>>>>>>>>>> "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835,
> >>>>>>>>>>> 3.43806581506388,
> >>>>>>>>>>> 0.002733567617055, 1.42917483425029, 1.05786640463504,
> >>>>>>>>>>> 0.000420548864162308,
> >>>>>>>>>>> 2.37232740842861, 3.01835841813241, 0, 1.13430282139936,
> >>>>>>>>>>> 0.928725667117666,
> >>>>>>>>>>> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
> >>>>>>>>>>> row.names
> >>>>>>>>>>> =
> >>>>>>>>>>> c(2L,
> >>>>>>>>>>> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >>>>>>>>>>>
> >>>>>>>>>>> I need to find a automated procedure that allows me to adjust
> >> v3
> >>>>>>>>>>> marginals
> >>>>>>>>>>> while maintaining v1xv2 marginals unchanged.
> >>>>>>>>>>>
> >>>>>>>>>>> That is: modify the v4 values you can find by running:
> >>>>>>>>>>>
> >>>>>>>>>>> aggregate(f1[,c("v4")],list(f1$v3),sum)
> >>>>>>>>>>>
> >>>>>>>>>>> while maintaining costant the values you can find by running:
> >>>>>>>>>>>
> >>>>>>>>>>> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
> >>>>>>>>>>>
> >>>>>>>>>>> Now does it make sense?
> >>>>>>>>>>>
> >>>>>>>>>>> Please notice I have tried to build some syntax that tries to
> >>>> modify
> >>>>>>>>>>> values
> >>>>>>>>>>> within each v1xv2 combination by computing sum of v4, row
> >>>> percentage
> >>>>>>>>>>> in
> >>>>>>>>>>> terms of v4, and there is where my effort is blocked. Not
> >> really
> >>>>>>>>>>> sure
> >>>>>>>>>>> how I
> >>>>>>>>>>> should proceed. Any suggestion?
> >>>>>>>>>>>
> >>>>>>>>>>> Thanks,
> >>>>>>>>>>>
> >>>>>>>>>>> Luca
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>> 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <
> >>>> jdnewmil at dcn.davis.ca.us>:
> >>>>>>>>>>>
> >>>>>>>>>>>> I don't understand your description. The standard practice on
> >>>> this
> >>>>>>>>>>>> list
> >>>>>>>>>>>> is
> >>>>>>>>>>>> to provide a reproducible R example [1] of the kind of data
> >> you
> >>>> are
> >>>>>>>>>>>> working
> >>>>>>>>>>>> with (and any code you have tried) to go along with your
> >>>>>>>>>>>> description.
> >>>>>>>>>>>> In
> >>>>>>>>>>>> this case, that would be two dputs of your input data frames
> >>>> and a
> >>>>>>>>>>>> dput
> >>>>>>>>>>>> of
> >>>>>>>>>>>> an output data frame (generated by hand from your input data
> >>>>>>>>>>>> frame).
> >>>>>>>>>>>> (Probably best to not use the full number of input values
> >> just
> >>>> to
> >>>>>>>>>>>> keep
> >>>>>>>>>>>> the
> >>>>>>>>>>>> size down.) We could then make an attempt to generate code
> >> that
> >>>>>>>>>>>> goes
> >>>>>>>>>>>> from
> >>>>>>>>>>>> input to output.
> >>>>>>>>>>>>
> >>>>>>>>>>>> Of course, if you post that hard work using HTML then it will
> >>>> get
> >>>>>>>>>>>> corrupted (much like the text below from your earlier emails)
> >>>> and
> >>>>>>>>>>>> we
> >>>>>>>>>>>> won't
> >>>>>>>>>>>> be able to use it. Please learn to post from your email
> >> software
> >>>>>>>>>>>> using
> >>>>>>>>>>>> plain text when corresponding with this mailing list.
> >>>>>>>>>>>>
> >>>>>>>>>>>> [1]
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>
> >>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>
> >>
> ---------------------------------------------------------------------------
> >>>>>>>>>>>> Jeff Newmiller                        The     .....
> >>>> .....  Go
> >>>>>>>>>>>> Live...
> >>>>>>>>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.
> >> ##.#.
> >>>>>>>>>>>> Live
> >>>>>>>>>>>> Go...
> >>>>>>>>>>>>                                      Live:   OO#.. Dead:
> >> OO#..
> >>>>>>>>>>>> Playing
> >>>>>>>>>>>> Research Engineer (Solar/Batteries            O.O#.
> >> #.O#.
> >>>>>>>>>>>> with
> >>>>>>>>>>>> /Software/Embedded Controllers)               .OO#.
> >> .OO#.
> >>>>>>>>>>>> rocks...1k
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>
> >>
> ---------------------------------------------------------------------------
> >>>>>>>>>>>> Sent from my phone. Please excuse my brevity.
> >>>>>>>>>>>>
> >>>>>>>>>>>> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <
> >>>> lucam1968 at gmail.com>
> >>>>>>>>>>>> wrote:
> >>>>>>>>>>>>> Thanks for you input Michael,
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> The continuous variable I have measures quantities (down to
> >> the
> >>>>>>>>>>>>> 3rd
> >>>>>>>>>>>>> decimal level) so unfortunately are not frequencies.
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> Any more specific suggestions on how that could be tackled?
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> Thanks & kind regards,
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> Luca
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> ===
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> Michael Friendly wrote:
> >>>>>>>>>>>>> I'm not sure I understand completely what you want to do,
> >> but
> >>>>>>>>>>>>> if the data were frequencies, it sounds like task for
> >> fitting a
> >>>>>>>>>>>>> loglinear model with the model formula
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> ~ V1*V2 + V3
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> On 3/18/2015 2:17 AM, Luca Meyer wrote:
> >>>>>>>>>>>>>> * Hello,
> >>>>>>>>>>>>> *>>* I am facing a quite challenging task (at least to me)
> >> and
> >>>> I
> >>>>>>>>>>>>> was
> >>>>>>>>>>>>> wondering
> >>>>>>>>>>>>> *>* if someone could advise how R could assist me to speed
> >> the
> >>>>>>>>>>>>> task
> >>>>>>>>>>>>> up.
> >>>>>>>>>>>>> *>>* I am dealing with a dataset with 3 discrete variables
> >> and
> >>>> one
> >>>>>>>>>>>>> continuous
> >>>>>>>>>>>>> *>* variable. The discrete variables are:
> >>>>>>>>>>>>> *>>* V1: 8 modalities
> >>>>>>>>>>>>> *>* V2: 13 modalities
> >>>>>>>>>>>>> *>* V3: 13 modalities
> >>>>>>>>>>>>> *>>* The continuous variable V4 is a decimal number always
> >>>> greater
> >>>>>>>>>>>>> than
> >>>>>>>>>>>>> zero in
> >>>>>>>>>>>>> *>* the marginals of each of the 3 variables but it is
> >>>> sometimes
> >>>>>>>>>>>>> equal
> >>>>>>>>>>>>> to zero
> >>>>>>>>>>>>> *>* (and sometimes negative) in the joint tables.
> >>>>>>>>>>>>> *>>* I have got 2 files:
> >>>>>>>>>>>>> *>>* => one with distribution of all possible combinations
> >> of
> >>>>>>>>>>>>> V1xV2
> >>>>>>>>>>>>> (some of
> >>>>>>>>>>>>> *>* which are zero or neagtive) and
> >>>>>>>>>>>>> *>* => one with the marginal distribution of V3.
> >>>>>>>>>>>>> *>>* I am trying to build the long and narrow dataset
> >> V1xV2xV3
> >>>> in
> >>>>>>>>>>>>> such
> >>>>>>>>>>>>> a way
> >>>>>>>>>>>>> *>* that each V1xV2 cell does not get modified and V3 fits
> >> as
> >>>>>>>>>>>>> closely
> >>>>>>>>>>>>> as
> >>>>>>>>>>>>> *>* possible to its marginal distribution. Does it make
> >> sense?
> >>>>>>>>>>>>> *>>* To be even more specific, my 2 input files look like
> >> the
> >>>>>>>>>>>>> following.
> >>>>>>>>>>>>> *>>* FILE 1
> >>>>>>>>>>>>> *>* V1,V2,V4
> >>>>>>>>>>>>> *>* A, A, 24.251
> >>>>>>>>>>>>> *>* A, B, 1.065
> >>>>>>>>>>>>> *>* (...)
> >>>>>>>>>>>>> *>* B, C, 0.294
> >>>>>>>>>>>>> *>* B, D, 2.731
> >>>>>>>>>>>>> *>* (...)
> >>>>>>>>>>>>> *>* H, L, 0.345
> >>>>>>>>>>>>> *>* H, M, 0.000
> >>>>>>>>>>>>> *>>* FILE 2
> >>>>>>>>>>>>> *>* V3, V4
> >>>>>>>>>>>>> *>* A, 1.575
> >>>>>>>>>>>>> *>* B, 4.294
> >>>>>>>>>>>>> *>* C, 10.044
> >>>>>>>>>>>>> *>* (...)
> >>>>>>>>>>>>> *>* L, 5.123
> >>>>>>>>>>>>> *>* M, 3.334
> >>>>>>>>>>>>> *>>* What I need to achieve is a file such as the following
> >>>>>>>>>>>>> *>>* FILE 3
> >>>>>>>>>>>>> *>* V1, V2, V3, V4
> >>>>>>>>>>>>> *>* A, A, A, ???
> >>>>>>>>>>>>> *>* A, A, B, ???
> >>>>>>>>>>>>> *>* (...)
> >>>>>>>>>>>>> *>* D, D, E, ???
> >>>>>>>>>>>>> *>* D, D, F, ???
> >>>>>>>>>>>>> *>* (...)
> >>>>>>>>>>>>> *>* H, M, L, ???
> >>>>>>>>>>>>> *>* H, M, M, ???
> >>>>>>>>>>>>> *>>* Please notice that FILE 3 need to be such that if I
> >>>> aggregate
> >>>>>>>>>>>>> on
> >>>>>>>>>>>>> V1+V2 I
> >>>>>>>>>>>>> *>* recover exactly FILE 1 and that if I aggregate on V3 I
> >> can
> >>>>>>>>>>>>> recover
> >>>>>>>>>>>>> a file
> >>>>>>>>>>>>> *>* as close as possible to FILE 3 (ideally the same file).
> >>>>>>>>>>>>> *>>* Can anyone suggest how I could do that with R?
> >>>>>>>>>>>>> *>>* Thank you very much indeed for any assistance you are
> >>>> able to
> >>>>>>>>>>>>> provide.
> >>>>>>>>>>>>> *>>* Kind regards,
> >>>>>>>>>>>>> *>>* Luca*
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>      [[alternative HTML version deleted]]
>
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From lucam1968 at gmail.com  Mon Mar 23 10:04:08 2015
From: lucam1968 at gmail.com (Luca Meyer)
Date: Mon, 23 Mar 2015 10:04:08 +0100
Subject: [R] Joining two datasets - recursive procedure?
In-Reply-To: <CABQyo87HOPfwCiiLEQj=wb1jJb01zgU1i-PKPYHzfDL0aZ11Sw@mail.gmail.com>
References: <CABQyo87ekB_m2s2frm2fygO5gYAPHqxnnDOXf9Mpd83yr59g1w@mail.gmail.com>
	<A69D7539-270E-4269-8002-59265DA66A64@dcn.davis.CA.us>
	<CABQyo86-BxnMs3gTV-tinp8fFXjBz2+N+1mLsv_U6uvRkucxng@mail.gmail.com>
	<CACk-te3VwKUTkeVg0P67S0SWn7r2OEshMY5r4v3rtfKUQqocYQ@mail.gmail.com>
	<CABQyo86r7+M2OXfAJ-LOuORVrb3kvwWcXu2DU85DN+-cwhA01Q@mail.gmail.com>
	<CACk-te2CBQXFGJ-Vhr+kpdY6uccbn0Rp286ca+2YvKO=iHUogg@mail.gmail.com>
	<CACk-te0sTVt5pPb9f-ELgTt8L0Bbaz2NCQ9S4ZsB5e122vdYYA@mail.gmail.com>
	<CABQyo86dF4UQH94v1Q-rFMBV=JRmwc3V9SFgG=ZiwtGatKTwPg@mail.gmail.com>
	<CACk-te3xkirW755s1WSETEEj0wvS=d=FneZw4r=dS=jK3RHNcQ@mail.gmail.com>
	<CACk-te22ZaM5p5H7Wz1ivN24S5zog-FY=AvdHQEbdz2O7AL2gA@mail.gmail.com>
	<CABQyo864GFSgDAEgRrf-0TQhrYLufNv96v2q00-YAb4nsVWYyw@mail.gmail.com>
	<CABQyo86r0h_6R2u8cm3Amg0pPnC7b+Tuy9t3zOiNFqmsTa2DEA@mail.gmail.com>
	<CACk-te1p_PeLO-rbzxo3MBMYWYfWHTf7FkoNhJ+8XafD6mh2ng@mail.gmail.com>
	<CABQyo85jd5xyecoBncF6QesE+YgHLTiv6xHAiVmziWVxY=Oijw@mail.gmail.com>
	<E8907230-83F6-4489-ABBF-6CD2A59EFD9D@comcast.net>
	<CABQyo87HOPfwCiiLEQj=wb1jJb01zgU1i-PKPYHzfDL0aZ11Sw@mail.gmail.com>
Message-ID: <CABQyo856p7PCJoVHDpYa-9j9KVR9MDiKR6GVY+xiVLbstSuLaA@mail.gmail.com>

Dear All,

I think I have found a fix developing the draft syntax I have provided
yesterday, see below or
https://www.dropbox.com/s/pbz9dcgxu6ljj8x/sample_code_1.txt?dl=0.

Only desirable improvement is related to the block where I compute the
modified v4 (lines 46-60 in the attached file). Provided the real data are
of the dimension 8x13x13 (v1xv2xv3), is there anyway to write that block
sentence in an automated way? I recall some function that could do that but
I can't remenber which one...

Thanks to everybody and especially to Bert and David for trying to assist
me with this one. And apologizes for not being so clear upfront but I was
trying to figure it out myself too...

Kind regards,

Luca

===

rm(list=ls())

# this is usual (an extract of) the INPUT file I have:
f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
"B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
"B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
"B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917,
1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names =
c(2L,
9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))

#first I order the file such that I have 6 distinct v1xv2 combinations
f1 <- f1[order(f1$v1,f1$v2),]

#I compute the relative importance of each v1xv2 automatically
t1 <- aggregate(v4~1,f1,sum)
tXX <- aggregate(v4~v1*v2,f1,sum)
tAA <- as.numeric(tXX$v4[tXX$v1=="A"&tXX$v2=="A"]/t1)
tAB <- as.numeric(tXX$v4[tXX$v1=="A"&tXX$v2=="B"]/t1)
tAC <- as.numeric(tXX$v4[tXX$v1=="A"&tXX$v2=="C"]/t1)
tBA <- as.numeric(tXX$v4[tXX$v1=="B"&tXX$v2=="A"]/t1)
tBB <- as.numeric(tXX$v4[tXX$v1=="B"&tXX$v2=="B"]/t1)
tBC <- as.numeric(tXX$v4[tXX$v1=="B"&tXX$v2=="C"]/t1)
tAA+tAB+tAC+tBA+tBB+tBC
rm(t1)

# Next, I compute the difference I need to compute for each C category
(t1 <- aggregate(v4~v3,f1,sum)) # this is the actual distribution
(t2 <- structure(list(v3 = c("B", "C"), v4 = c(29, 2.56723)), .Names =
c("v3",
"v4"), row.names = c(NA, -2L), class = "data.frame")) # this is the target
distribution

# I verify t1 & t2 total is the same
aggregate(v4~1,t1,sum)
aggregate(v4~1,t2,sum)

# I determine the value to be added/subtracted to each instance of v3
t1 <- merge(t1,t2,by="v3")
t1$dif <- t1$v4.y-t1$v4.x
t1 <- t1[,c("v3","dif")]
t1

# I merge the t1 file with the f1
f1 <- merge (f1,t1,by="v3")
f1
rm(t1,t2)

# I compute the modified v4 value
f1$v4mod <- f1$v4
f1$v4mod <- ifelse (f1$v1=="A" & f1$v2=="A" & f1$v3=="B",
f1$v4+(tAA*f1$dif), f1$v4mod)
f1$v4mod <- ifelse (f1$v1=="A" & f1$v2=="A" & f1$v3=="C",
f1$v4+(tAA*f1$dif), f1$v4mod)
f1$v4mod <- ifelse (f1$v1=="A" & f1$v2=="B" & f1$v3=="B",
f1$v4+(tAB*f1$dif), f1$v4mod)
f1$v4mod <- ifelse (f1$v1=="A" & f1$v2=="B" & f1$v3=="C",
f1$v4+(tAB*f1$dif), f1$v4mod)
f1$v4mod <- ifelse (f1$v1=="A" & f1$v2=="C" & f1$v3=="B",
f1$v4+(tAC*f1$dif), f1$v4mod)
f1$v4mod <- ifelse (f1$v1=="A" & f1$v2=="C" & f1$v3=="C",
f1$v4+(tAC*f1$dif), f1$v4mod)
f1$v4mod <- ifelse (f1$v1=="B" & f1$v2=="A" & f1$v3=="B",
f1$v4+(tBA*f1$dif), f1$v4mod)
f1$v4mod <- ifelse (f1$v1=="B" & f1$v2=="A" & f1$v3=="C",
f1$v4+(tBA*f1$dif), f1$v4mod)
f1$v4mod <- ifelse (f1$v1=="B" & f1$v2=="B" & f1$v3=="B",
f1$v4+(tBB*f1$dif), f1$v4mod)
f1$v4mod <- ifelse (f1$v1=="B" & f1$v2=="B" & f1$v3=="C",
f1$v4+(tBB*f1$dif), f1$v4mod)
f1$v4mod <- ifelse (f1$v1=="B" & f1$v2=="C" & f1$v3=="B",
f1$v4+(tBC*f1$dif), f1$v4mod)
f1$v4mod <- ifelse (f1$v1=="B" & f1$v2=="C" & f1$v3=="C",
f1$v4+(tBC*f1$dif), f1$v4mod)
f1

# i compare original vs modified marginal distributions
aggregate(v4~v1*v2,f1,sum)
aggregate(v4mod~v1*v2,f1,sum)
aggregate(v4~v3,f1,sum)
aggregate(v4mod~v3,f1,sum)
aggregate(v4~1,f1,sum)
aggregate(v4mod~1,f1,sum)

rm(list=ls())



2015-03-23 9:10 GMT+01:00 Luca Meyer <lucam1968 at gmail.com>:

> Hi David, hello R-experts
>
> Thank you for your input. I have tried the syntax you suggested but
> unfortunately the marginal distributions v1xv2 change after the
> manipulation. Please see below or
> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0 for the
> syntax.
>
> > rm(list=ls())
> >
> > # this is usual (an extract of) the INPUT file I have:
> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
> + "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
> + "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
> + "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273,
> 1.42917, 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
> + 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame", row.names
> = c(2L,
> + 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
> >
> > #first I order the file such that I have 6 distinct v1xv2 combinations
> > f1 <- f1[order(f1$v1,f1$v2),]
> >
> > # then I compute (manually) the relative importance of each v1xv2
> combination:
> > tAA <-
> (18.18530+1.42917)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> # this is for combination v1=A & v2=A
> > tAB <-
> (3.43806+1.05786)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> # this is for combination v1=A & v2=B
> > tAC <-
> (0.00273+0.00042)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> # this is for combination v1=A & v2=C
> > tBA <-
> (2.37232+1.13430)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> # this is for combination v1=B & v2=A
> > tBB <-
> (3.01835+0.92872)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> # this is for combination v1=B & v2=B
> > tBC <-
> (0.00000+0.00000)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
> # this is for combination v1=B & v2=C
> > # and just to make sure I have not made mistakes the following should be
> equal to 1
> > tAA+tAB+tAC+tBA+tBB+tBC
> [1] 1
> >
> > # procedure suggested by David Winsemius
> > lookarr <- array(NA,
> dim=c(length(unique(f1$v1)),length(unique(f1$v2)),length(unique(f1$v3)) ) ,
> dimnames=list( unique(f1$v1), unique(f1$v2), unique(f1$v3) ) )
> > lookarr[] <- c(tAA,tAA,tAB,tAB,tAC,tAC,tBA,tBA,tBB,tBB,tBC,tBC)
> > lookarr["A","B","C"]
> [1] 0.1250369
> > lookarr[ with(f1, cbind(v1, v2, v3)) ]
>  [1] 6.213554e-01 1.110842e-01 1.424236e-01 1.250369e-01 9.978703e-05
> 0.000000e+00 6.213554e-01 1.110842e-01 1.424236e-01 1.250369e-01
> 9.978703e-05
> [12] 0.000000e+00
> > f1$v4mod <- f1$v4*lookarr[ with(f1, cbind(v1,v2,v3)) ]
> >
> > # i compare original vs modified marginal distributions
> > aggregate(v4~v1*v2,f1,sum)
>   v1 v2       v4
> 1  A  A 19.61447
> 2  B  A  3.50662
> 3  A  B  4.49592
> 4  B  B  3.94707
> 5  A  C  0.00315
> 6  B  C  0.00000
> > aggregate(v4mod~v1*v2,f1,sum)
>   v1 v2        v4mod
> 1  A  A 1.145829e+01
> 2  B  A 1.600057e+00
> 3  A  B 6.219326e-01
> 4  B  B 5.460087e-01
> 5  A  C 2.724186e-07
> 6  B  C 0.000000e+00
> > aggregate(v4~v3,f1,sum)
>   v3       v4
> 1  B 27.01676
> 2  C  4.55047
> > aggregate(v4mod~v3,f1,sum)
>   v3      v4mod
> 1  B 13.6931347
> 2  C  0.5331569
>
> Any suggestion on how this can be fixed? Remember, I am searching for a
> solution where by aggregate(v4~v1*v2,f1,sum)==aggregate(v4~v1*v2,f1,sum)
> while aggregate(v4~v3,f1,sum)!=aggregate(v4mod~v3,f1,sum) by specified
> amounts (see my earlier example).
>
> Thank you very much,
>
> Luca
>
>
> 2015-03-22 22:11 GMT+01:00 David Winsemius <dwinsemius at comcast.net>:
>
>>
>> On Mar 22, 2015, at 1:12 PM, Luca Meyer wrote:
>>
>> > Hi Bert,
>> >
>> > Maybe I did not explain myself clearly enough. But let me show you with
>> a
>> > manual example that indeed what I would like to do is feasible.
>> >
>> > The following is also available for download from
>> > https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
>> >
>> > rm(list=ls())
>> >
>> > This is usual (an extract of) the INPUT file I have:
>> >
>> > f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>> > "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>> > "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>> > "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273,
>> 1.42917,
>> > 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
>> > 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>> row.names =
>> > c(2L,
>> > 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>> >
>> > This are the initial marginal distributions
>> >
>> > aggregate(v4~v1*v2,f1,sum)
>> > aggregate(v4~v3,f1,sum)
>> >
>> > First I order the file such that I have nicely listed 6 distinct v1xv2
>> > combinations.
>> >
>> > f1 <- f1[order(f1$v1,f1$v2),]
>> >
>> > Then I compute (manually) the relative importance of each v1xv2
>> combination:
>> >
>> > tAA <-
>> >
>> (18.18530+1.42917)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
>> > # this is for combination v1=A & v2=A
>> > tAB <-
>> >
>> (3.43806+1.05786)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
>> > # this is for combination v1=A & v2=B
>> > tAC <-
>> >
>> (0.00273+0.00042)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
>> > # this is for combination v1=A & v2=C
>> > tBA <-
>> >
>> (2.37232+1.13430)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
>> > # this is for combination v1=B & v2=A
>> > tBB <-
>> >
>> (3.01835+0.92872)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
>> > # this is for combination v1=B & v2=B
>> > tBC <-
>> >
>> (0.00000+0.00000)/(18.18530+1.42917+3.43806+1.05786+0.00273+0.00042+2.37232+1.13430+3.01835+0.92872+0.00000+0.00000)
>> > # this is for combination v1=B & v2=C
>> > # and just to make sure I have not made mistakes the following should be
>> > equal to 1
>> > tAA+tAB+tAC+tBA+tBB+tBC
>> >
>> > Next, I know I need to increase v4 any time v3=B and the total increase
>> I
>> > need to have over the whole dataset is 29-27.01676=1.98324. In turn, I
>> need
>> > to dimish v4 any time V3=C by the same amount (4.55047-2.56723=1.98324).
>> > This aspect was perhaps not clear at first. I need to move v4 across v3
>> > categories, but the totals will always remain unchanged.
>> >
>> > Since I want the data alteration to be proportional to the v1xv2
>> > combinations I do the following:
>> >
>> > f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="A" & f1$v3=="B",
>> f1$v4+(tAA*1.98324),
>> > f1$v4)
>> > f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="A" & f1$v3=="C",
>> f1$v4-(tAA*1.98324),
>> > f1$v4)
>> > f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="B" & f1$v3=="B",
>> f1$v4+(tAB*1.98324),
>> > f1$v4)
>> > f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="B" & f1$v3=="C",
>> f1$v4-(tAB*1.98324),
>> > f1$v4)
>> > f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="C" & f1$v3=="B",
>> f1$v4+(tAC*1.98324),
>> > f1$v4)
>> > f1$v4 <- ifelse (f1$v1=="A" & f1$v2=="C" & f1$v3=="C",
>> f1$v4-(tAC*1.98324),
>> > f1$v4)
>> > f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="A" & f1$v3=="B",
>> f1$v4+(tBA*1.98324),
>> > f1$v4)
>> > f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="A" & f1$v3=="C",
>> f1$v4-(tBA*1.98324),
>> > f1$v4)
>> > f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="B" & f1$v3=="B",
>> f1$v4+(tBB*1.98324),
>> > f1$v4)
>> > f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="B" & f1$v3=="C",
>> f1$v4-(tBB*1.98324),
>> > f1$v4)
>> > f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="C" & f1$v3=="B",
>> f1$v4+(tBC*1.98324),
>> > f1$v4)
>> > f1$v4 <- ifelse (f1$v1=="B" & f1$v2=="C" & f1$v3=="C",
>> f1$v4-(tBC*1.98324),
>> > f1$v4)
>> >
>>
>> Seems that this could be done a lot more simply with a lookup matrix and
>> ordinary indexing
>>
>> > lookarr <- array(NA,
>> dim=c(length(unique(f1$v1)),length(unique(f1$v2)),length(unique(f1$v3)) ) ,
>> dimnames=list( unique(f1$v1), unique(f1$v2), unique(f1$v3) ) )
>> > lookarr[] <- c(tAA,tAA,tAB,tAB,tAC,tAC,tBA,tBA,
>>                  tBB, tBB, tBC, tBC)
>>
>> > lookarr[ "A","B","C"]
>> [1] 0.1250369
>>
>> > lookarr[ with(f1, cbind(v1, v2, v3)) ]
>>  [1] 6.213554e-01 1.110842e-01 1.424236e-01 1.250369e-01 9.978703e-05
>>  [6] 0.000000e+00 6.213554e-01 1.110842e-01 1.424236e-01 1.250369e-01
>> [11] 9.978703e-05 0.000000e+00
>> > f1$v4mod <- f1$v4*lookarr[ with(f1, cbind(v1,v2,v3)) ]
>> > f1
>>     v1 v2 v3       v4        v4mod
>> 2    A  A  B 18.18530 1.129954e+01
>> 41   A  A  C  1.42917 1.587582e-01
>> 9    A  B  B  3.43806 4.896610e-01
>> 48   A  B  C  1.05786 1.322716e-01
>> 11   A  C  B  0.00273 2.724186e-07
>> 50   A  C  C  0.00042 0.000000e+00
>> 158  B  A  B  2.37232 1.474054e+00
>> 197  B  A  C  1.13430 1.260028e-01
>> 165  B  B  B  3.01835 4.298844e-01
>> 204  B  B  C  0.92872 1.161243e-01
>> 167  B  C  B  0.00000 0.000000e+00
>> 206  B  C  C  0.00000 0.000000e+00
>>
>> --
>> david.
>>
>>
>> > This are the final marginal distributions:
>> >
>> > aggregate(v4~v1*v2,f1,sum)
>> > aggregate(v4~v3,f1,sum)
>> >
>> > Can this procedure be made programmatic so that I can run it on the
>> > (8x13x13) categories matrix? if so, how would you do it? I have really
>> hard
>> > time to do it with some (semi)automatic procedure.
>> >
>> > Thank you very much indeed once more :)
>> >
>> > Luca
>> >
>> >
>> > 2015-03-22 18:32 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>> >
>> >> Nonsense. You are not telling us something or I have failed to
>> >> understand something.
>> >>
>> >> Consider:
>> >>
>> >> v1 = c("a","b")
>> >> v2 = "c("a","a")
>> >>
>> >> It is not possible to change the value of a sum of values
>> >> corresponding to v2="a" without also changing that for v1, which is
>> >> not supposed to change according to my understanding of your
>> >> specification.
>> >>
>> >> So I'm done.
>> >>
>> >> -- Bert
>> >>
>> >>
>> >> Bert Gunter
>> >> Genentech Nonclinical Biostatistics
>> >> (650) 467-7374
>> >>
>> >> "Data is not information. Information is not knowledge. And knowledge
>> >> is certainly not wisdom."
>> >> Clifford Stoll
>> >>
>> >>
>> >>
>> >>
>> >> On Sun, Mar 22, 2015 at 8:28 AM, Luca Meyer <lucam1968 at gmail.com>
>> wrote:
>> >>> Sorry forgot to keep the rest of the group in the loop - Luca
>> >>> ---------- Forwarded message ----------
>> >>> From: Luca Meyer <lucam1968 at gmail.com>
>> >>> Date: 2015-03-22 16:27 GMT+01:00
>> >>> Subject: Re: [R] Joining two datasets - recursive procedure?
>> >>> To: Bert Gunter <gunter.berton at gene.com>
>> >>>
>> >>>
>> >>> Hi Bert,
>> >>>
>> >>> That is exactly what I am trying to achieve. Please notice that
>> negative
>> >> v4
>> >>> values are allowed. I have done a similar task in the past manually by
>> >>> recursively alterating v4 distribution across v3 categories within fix
>> >> each
>> >>> v1&v2 combination so I am quite positive it can be achieved but
>> honestly
>> >> I
>> >>> took me forever to do it manually and since this is likely to be an
>> >>> exercise I need to repeat from time to time I wish I could learn how
>> to
>> >> do
>> >>> it programmatically....
>> >>>
>> >>> Thanks again for any further suggestion you might have,
>> >>>
>> >>> Luca
>> >>>
>> >>>
>> >>> 2015-03-22 16:05 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>> >>>
>> >>>> Oh, wait a minute ...
>> >>>>
>> >>>> You still want the marginals for the other columns to be as
>> originally?
>> >>>>
>> >>>> If so, then this is impossible in general as the sum of all the
>> values
>> >>>> must be what they were originally and you cannot therefore choose
>> your
>> >>>> values for V3 arbitrarily.
>> >>>>
>> >>>> Or at least, that seems to be what you are trying to do.
>> >>>>
>> >>>> -- Bert
>> >>>>
>> >>>> Bert Gunter
>> >>>> Genentech Nonclinical Biostatistics
>> >>>> (650) 467-7374
>> >>>>
>> >>>> "Data is not information. Information is not knowledge. And knowledge
>> >>>> is certainly not wisdom."
>> >>>> Clifford Stoll
>> >>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>> On Sun, Mar 22, 2015 at 7:55 AM, Bert Gunter <bgunter at gene.com>
>> wrote:
>> >>>>> I would have thought that this is straightforward given my previous
>> >>>> email...
>> >>>>>
>> >>>>> Just set z to what you want -- e,g, all B values to 29/number of
>> B's,
>> >>>>> and all C values to 2.567/number of C's (etc. for more categories).
>> >>>>>
>> >>>>> A slick but sort of cheat way to do this programmatically -- in the
>> >>>>> sense that it relies on the implementation of factor() rather than
>> its
>> >>>>> API -- is:
>> >>>>>
>> >>>>> y <- f1$v3  ## to simplify the notation; could be done using with()
>> >>>>> z <- (c(29,2.567)/table(y))[c(y)]
>> >>>>>
>> >>>>> Then proceed to z1 as I previously described
>> >>>>>
>> >>>>> -- Bert
>> >>>>>
>> >>>>>
>> >>>>> Bert Gunter
>> >>>>> Genentech Nonclinical Biostatistics
>> >>>>> (650) 467-7374
>> >>>>>
>> >>>>> "Data is not information. Information is not knowledge. And
>> knowledge
>> >>>>> is certainly not wisdom."
>> >>>>> Clifford Stoll
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>> On Sun, Mar 22, 2015 at 2:00 AM, Luca Meyer <lucam1968 at gmail.com>
>> >> wrote:
>> >>>>>> Hi Bert, hello R-experts,
>> >>>>>>
>> >>>>>> I am close to a solution but I still need one hint w.r.t. the
>> >> following
>> >>>>>> procedure (available also from
>> >>>>>> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0)
>> >>>>>>
>> >>>>>> rm(list=ls())
>> >>>>>>
>> >>>>>> # this is (an extract of) the INPUT file I have:
>> >>>>>> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B", "B",
>> >> "B",
>> >>>>>> "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A", "B", "C",
>> >> "A",
>> >>>>>> "B", "C"), v3 = c("B", "B", "B", "C", "C", "C", "B", "B", "B", "C",
>> >> "C",
>> >>>>>> "C"), v4 = c(18.18530, 3.43806,0.00273, 1.42917, 1.05786, 0.00042,
>> >>>> 2.37232,
>> >>>>>> 3.01835, 0, 1.13430, 0.92872, 0)), .Names = c("v1", "v2", "v3",
>> >> "v4"),
>> >>>> class
>> >>>>>> = "data.frame", row.names = c(2L, 9L, 11L, 41L, 48L, 50L, 158L,
>> 165L,
>> >>>> 167L,
>> >>>>>> 197L, 204L, 206L))
>> >>>>>>
>> >>>>>> # this is the procedure that Bert suggested (slightly adjusted):
>> >>>>>> z <- rnorm(nrow(f1)) ## or anything you want
>> >>>>>> z1 <- round(with(f1,v4 + z -ave(z,v1,v2,FUN=mean)), digits=5)
>> >>>>>> aggregate(v4~v1*v2,f1,sum)
>> >>>>>> aggregate(z1~v1*v2,f1,sum)
>> >>>>>> aggregate(v4~v3,f1,sum)
>> >>>>>> aggregate(z1~v3,f1,sum)
>> >>>>>>
>> >>>>>> My question to you is: how can I set z so that I can obtain
>> specific
>> >>>> values
>> >>>>>> for z1-v4 in the v3 aggregation?
>> >>>>>> In other words, how can I configure the procedure so that e.g. B=29
>> >> and
>> >>>>>> C=2.56723 after running the procedure:
>> >>>>>> aggregate(z1~v3,f1,sum)
>> >>>>>>
>> >>>>>> Thank you,
>> >>>>>>
>> >>>>>> Luca
>> >>>>>>
>> >>>>>> PS: to avoid any doubts you might have about who I am the following
>> >> is
>> >>>> my
>> >>>>>> web page: http://lucameyer.wordpress.com/
>> >>>>>>
>> >>>>>>
>> >>>>>> 2015-03-21 18:13 GMT+01:00 Bert Gunter <gunter.berton at gene.com>:
>> >>>>>>>
>> >>>>>>> ... or cleaner:
>> >>>>>>>
>> >>>>>>> z1 <- with(f1,v4 + z -ave(z,v1,v2,FUN=mean))
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> Just for curiosity, was this homework? (in which case I should
>> >>>>>>> probably have not provided you an answer -- that is, assuming
>> that I
>> >>>>>>> HAVE provided an answer).
>> >>>>>>>
>> >>>>>>> Cheers,
>> >>>>>>> Bert
>> >>>>>>>
>> >>>>>>> Bert Gunter
>> >>>>>>> Genentech Nonclinical Biostatistics
>> >>>>>>> (650) 467-7374
>> >>>>>>>
>> >>>>>>> "Data is not information. Information is not knowledge. And
>> >> knowledge
>> >>>>>>> is certainly not wisdom."
>> >>>>>>> Clifford Stoll
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> On Sat, Mar 21, 2015 at 7:53 AM, Bert Gunter <bgunter at gene.com>
>> >> wrote:
>> >>>>>>>> z <- rnorm(nrow(f1)) ## or anything you want
>> >>>>>>>> z1 <- f1$v4 + z - with(f1,ave(z,v1,v2,FUN=mean))
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>> aggregate(v4~v1,f1,sum)
>> >>>>>>>> aggregate(z1~v1,f1,sum)
>> >>>>>>>> aggregate(v4~v2,f1,sum)
>> >>>>>>>> aggregate(z1~v2,f1,sum)
>> >>>>>>>> aggregate(v4~v3,f1,sum)
>> >>>>>>>> aggregate(z1~v3,f1,sum)
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>> Cheers,
>> >>>>>>>> Bert
>> >>>>>>>>
>> >>>>>>>> Bert Gunter
>> >>>>>>>> Genentech Nonclinical Biostatistics
>> >>>>>>>> (650) 467-7374
>> >>>>>>>>
>> >>>>>>>> "Data is not information. Information is not knowledge. And
>> >> knowledge
>> >>>>>>>> is certainly not wisdom."
>> >>>>>>>> Clifford Stoll
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>> On Sat, Mar 21, 2015 at 6:49 AM, Luca Meyer <lucam1968 at gmail.com
>> >
>> >>>> wrote:
>> >>>>>>>>> Hi Bert,
>> >>>>>>>>>
>> >>>>>>>>> Thank you for your message. I am looking into ave() and tapply()
>> >> as
>> >>>> you
>> >>>>>>>>> suggested but at the same time I have prepared a example of
>> input
>> >>>> and
>> >>>>>>>>> output
>> >>>>>>>>> files, just in case you or someone else would like to make an
>> >>>> attempt
>> >>>>>>>>> to
>> >>>>>>>>> generate a code that goes from input to output.
>> >>>>>>>>>
>> >>>>>>>>> Please see below or download it from
>> >>>>>>>>> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0
>> >>>>>>>>>
>> >>>>>>>>> # this is (an extract of) the INPUT file I have:
>> >>>>>>>>> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
>> >> "B",
>> >>>>>>>>> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>> >>>>>>>>> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>> >>>>>>>>> "B", "B", "B", "C", "C", "C"), v4 = c(18.18530, 3.43806,0.00273,
>> >>>>>>>>> 1.42917,
>> >>>>>>>>> 1.05786, 0.00042, 2.37232, 3.01835, 0, 1.13430, 0.92872,
>> >>>>>>>>> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>> >>>>>>>>> row.names =
>> >>>>>>>>> c(2L,
>> >>>>>>>>> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>> >>>>>>>>>
>> >>>>>>>>> # this is (an extract of) the OUTPUT file I would like to
>> obtain:
>> >>>>>>>>> f2 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
>> >> "B",
>> >>>>>>>>> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>> >>>>>>>>> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>> >>>>>>>>> "B", "B", "B", "C", "C", "C"), v4 = c(17.83529, 3.43806,0.00295,
>> >>>>>>>>> 1.77918,
>> >>>>>>>>> 1.05786, 0.0002, 2.37232, 3.01835, 0, 1.13430, 0.92872,
>> >>>>>>>>> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>> >>>>>>>>> row.names =
>> >>>>>>>>> c(2L,
>> >>>>>>>>> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>> >>>>>>>>>
>> >>>>>>>>> # please notice that while the aggregated v4 on v3 has changed ?
>> >>>>>>>>> aggregate(f1[,c("v4")],list(f1$v3),sum)
>> >>>>>>>>> aggregate(f2[,c("v4")],list(f2$v3),sum)
>> >>>>>>>>>
>> >>>>>>>>> # ? the aggregated v4 over v1xv2 has remained unchanged:
>> >>>>>>>>> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>> >>>>>>>>> aggregate(f2[,c("v4")],list(f2$v1,f2$v2),sum)
>> >>>>>>>>>
>> >>>>>>>>> Thank you very much in advance for your assitance.
>> >>>>>>>>>
>> >>>>>>>>> Luca
>> >>>>>>>>>
>> >>>>>>>>> 2015-03-21 13:18 GMT+01:00 Bert Gunter <gunter.berton at gene.com
>> >:
>> >>>>>>>>>>
>> >>>>>>>>>> 1. Still not sure what you mean, but maybe look at ?ave and
>> >>>> ?tapply,
>> >>>>>>>>>> for which ave() is a wrapper.
>> >>>>>>>>>>
>> >>>>>>>>>> 2. You still need to heed the rest of Jeff's advice.
>> >>>>>>>>>>
>> >>>>>>>>>> Cheers,
>> >>>>>>>>>> Bert
>> >>>>>>>>>>
>> >>>>>>>>>> Bert Gunter
>> >>>>>>>>>> Genentech Nonclinical Biostatistics
>> >>>>>>>>>> (650) 467-7374
>> >>>>>>>>>>
>> >>>>>>>>>> "Data is not information. Information is not knowledge. And
>> >>>> knowledge
>> >>>>>>>>>> is certainly not wisdom."
>> >>>>>>>>>> Clifford Stoll
>> >>>>>>>>>>
>> >>>>>>>>>>
>> >>>>>>>>>>
>> >>>>>>>>>>
>> >>>>>>>>>> On Sat, Mar 21, 2015 at 4:53 AM, Luca Meyer <
>> >> lucam1968 at gmail.com>
>> >>>>>>>>>> wrote:
>> >>>>>>>>>>> Hi Jeff & other R-experts,
>> >>>>>>>>>>>
>> >>>>>>>>>>> Thank you for your note. I have tried myself to solve the
>> >> issue
>> >>>>>>>>>>> without
>> >>>>>>>>>>> success.
>> >>>>>>>>>>>
>> >>>>>>>>>>> Following your suggestion, I am providing a sample of the
>> >>>> dataset I
>> >>>>>>>>>>> am
>> >>>>>>>>>>> using below (also downloadble in plain text from
>> >>>>>>>>>>>
>> >> https://www.dropbox.com/s/qhmpkkrejjkpbkx/sample_code.txt?dl=0):
>> >>>>>>>>>>>
>> >>>>>>>>>>> #this is an extract of the overall dataset (n=1200 cases)
>> >>>>>>>>>>> f1 <- structure(list(v1 = c("A", "A", "A", "A", "A", "A", "B",
>> >>>> "B",
>> >>>>>>>>>>> "B", "B", "B", "B"), v2 = c("A", "B", "C", "A", "B", "C", "A",
>> >>>>>>>>>>> "B", "C", "A", "B", "C"), v3 = c("B", "B", "B", "C", "C", "C",
>> >>>>>>>>>>> "B", "B", "B", "C", "C", "C"), v4 = c(18.1853007621835,
>> >>>>>>>>>>> 3.43806581506388,
>> >>>>>>>>>>> 0.002733567617055, 1.42917483425029, 1.05786640463504,
>> >>>>>>>>>>> 0.000420548864162308,
>> >>>>>>>>>>> 2.37232740842861, 3.01835841813241, 0, 1.13430282139936,
>> >>>>>>>>>>> 0.928725667117666,
>> >>>>>>>>>>> 0)), .Names = c("v1", "v2", "v3", "v4"), class = "data.frame",
>> >>>>>>>>>>> row.names
>> >>>>>>>>>>> =
>> >>>>>>>>>>> c(2L,
>> >>>>>>>>>>> 9L, 11L, 41L, 48L, 50L, 158L, 165L, 167L, 197L, 204L, 206L))
>> >>>>>>>>>>>
>> >>>>>>>>>>> I need to find a automated procedure that allows me to adjust
>> >> v3
>> >>>>>>>>>>> marginals
>> >>>>>>>>>>> while maintaining v1xv2 marginals unchanged.
>> >>>>>>>>>>>
>> >>>>>>>>>>> That is: modify the v4 values you can find by running:
>> >>>>>>>>>>>
>> >>>>>>>>>>> aggregate(f1[,c("v4")],list(f1$v3),sum)
>> >>>>>>>>>>>
>> >>>>>>>>>>> while maintaining costant the values you can find by running:
>> >>>>>>>>>>>
>> >>>>>>>>>>> aggregate(f1[,c("v4")],list(f1$v1,f1$v2),sum)
>> >>>>>>>>>>>
>> >>>>>>>>>>> Now does it make sense?
>> >>>>>>>>>>>
>> >>>>>>>>>>> Please notice I have tried to build some syntax that tries to
>> >>>> modify
>> >>>>>>>>>>> values
>> >>>>>>>>>>> within each v1xv2 combination by computing sum of v4, row
>> >>>> percentage
>> >>>>>>>>>>> in
>> >>>>>>>>>>> terms of v4, and there is where my effort is blocked. Not
>> >> really
>> >>>>>>>>>>> sure
>> >>>>>>>>>>> how I
>> >>>>>>>>>>> should proceed. Any suggestion?
>> >>>>>>>>>>>
>> >>>>>>>>>>> Thanks,
>> >>>>>>>>>>>
>> >>>>>>>>>>> Luca
>> >>>>>>>>>>>
>> >>>>>>>>>>>
>> >>>>>>>>>>> 2015-03-19 2:38 GMT+01:00 Jeff Newmiller <
>> >>>> jdnewmil at dcn.davis.ca.us>:
>> >>>>>>>>>>>
>> >>>>>>>>>>>> I don't understand your description. The standard practice on
>> >>>> this
>> >>>>>>>>>>>> list
>> >>>>>>>>>>>> is
>> >>>>>>>>>>>> to provide a reproducible R example [1] of the kind of data
>> >> you
>> >>>> are
>> >>>>>>>>>>>> working
>> >>>>>>>>>>>> with (and any code you have tried) to go along with your
>> >>>>>>>>>>>> description.
>> >>>>>>>>>>>> In
>> >>>>>>>>>>>> this case, that would be two dputs of your input data frames
>> >>>> and a
>> >>>>>>>>>>>> dput
>> >>>>>>>>>>>> of
>> >>>>>>>>>>>> an output data frame (generated by hand from your input data
>> >>>>>>>>>>>> frame).
>> >>>>>>>>>>>> (Probably best to not use the full number of input values
>> >> just
>> >>>> to
>> >>>>>>>>>>>> keep
>> >>>>>>>>>>>> the
>> >>>>>>>>>>>> size down.) We could then make an attempt to generate code
>> >> that
>> >>>>>>>>>>>> goes
>> >>>>>>>>>>>> from
>> >>>>>>>>>>>> input to output.
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> Of course, if you post that hard work using HTML then it will
>> >>>> get
>> >>>>>>>>>>>> corrupted (much like the text below from your earlier emails)
>> >>>> and
>> >>>>>>>>>>>> we
>> >>>>>>>>>>>> won't
>> >>>>>>>>>>>> be able to use it. Please learn to post from your email
>> >> software
>> >>>>>>>>>>>> using
>> >>>>>>>>>>>> plain text when corresponding with this mailing list.
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> [1]
>> >>>>>>>>>>>>
>> >>>>>>>>>>>>
>> >>>>>>>>>>>>
>> >>>>
>> >>
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> >>>>>>>>>>>>
>> >>>>>>>>>>>>
>> >>>>>>>>>>>>
>> >>>>
>> >>
>> ---------------------------------------------------------------------------
>> >>>>>>>>>>>> Jeff Newmiller                        The     .....
>> >>>> .....  Go
>> >>>>>>>>>>>> Live...
>> >>>>>>>>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.
>> >> ##.#.
>> >>>>>>>>>>>> Live
>> >>>>>>>>>>>> Go...
>> >>>>>>>>>>>>                                      Live:   OO#.. Dead:
>> >> OO#..
>> >>>>>>>>>>>> Playing
>> >>>>>>>>>>>> Research Engineer (Solar/Batteries            O.O#.
>> >> #.O#.
>> >>>>>>>>>>>> with
>> >>>>>>>>>>>> /Software/Embedded Controllers)               .OO#.
>> >> .OO#.
>> >>>>>>>>>>>> rocks...1k
>> >>>>>>>>>>>>
>> >>>>>>>>>>>>
>> >>>>>>>>>>>>
>> >>>>
>> >>
>> ---------------------------------------------------------------------------
>> >>>>>>>>>>>> Sent from my phone. Please excuse my brevity.
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> On March 18, 2015 9:05:37 AM PDT, Luca Meyer <
>> >>>> lucam1968 at gmail.com>
>> >>>>>>>>>>>> wrote:
>> >>>>>>>>>>>>> Thanks for you input Michael,
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>> The continuous variable I have measures quantities (down to
>> >> the
>> >>>>>>>>>>>>> 3rd
>> >>>>>>>>>>>>> decimal level) so unfortunately are not frequencies.
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>> Any more specific suggestions on how that could be tackled?
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>> Thanks & kind regards,
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>> Luca
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>> ===
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>> Michael Friendly wrote:
>> >>>>>>>>>>>>> I'm not sure I understand completely what you want to do,
>> >> but
>> >>>>>>>>>>>>> if the data were frequencies, it sounds like task for
>> >> fitting a
>> >>>>>>>>>>>>> loglinear model with the model formula
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>> ~ V1*V2 + V3
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>> On 3/18/2015 2:17 AM, Luca Meyer wrote:
>> >>>>>>>>>>>>>> * Hello,
>> >>>>>>>>>>>>> *>>* I am facing a quite challenging task (at least to me)
>> >> and
>> >>>> I
>> >>>>>>>>>>>>> was
>> >>>>>>>>>>>>> wondering
>> >>>>>>>>>>>>> *>* if someone could advise how R could assist me to speed
>> >> the
>> >>>>>>>>>>>>> task
>> >>>>>>>>>>>>> up.
>> >>>>>>>>>>>>> *>>* I am dealing with a dataset with 3 discrete variables
>> >> and
>> >>>> one
>> >>>>>>>>>>>>> continuous
>> >>>>>>>>>>>>> *>* variable. The discrete variables are:
>> >>>>>>>>>>>>> *>>* V1: 8 modalities
>> >>>>>>>>>>>>> *>* V2: 13 modalities
>> >>>>>>>>>>>>> *>* V3: 13 modalities
>> >>>>>>>>>>>>> *>>* The continuous variable V4 is a decimal number always
>> >>>> greater
>> >>>>>>>>>>>>> than
>> >>>>>>>>>>>>> zero in
>> >>>>>>>>>>>>> *>* the marginals of each of the 3 variables but it is
>> >>>> sometimes
>> >>>>>>>>>>>>> equal
>> >>>>>>>>>>>>> to zero
>> >>>>>>>>>>>>> *>* (and sometimes negative) in the joint tables.
>> >>>>>>>>>>>>> *>>* I have got 2 files:
>> >>>>>>>>>>>>> *>>* => one with distribution of all possible combinations
>> >> of
>> >>>>>>>>>>>>> V1xV2
>> >>>>>>>>>>>>> (some of
>> >>>>>>>>>>>>> *>* which are zero or neagtive) and
>> >>>>>>>>>>>>> *>* => one with the marginal distribution of V3.
>> >>>>>>>>>>>>> *>>* I am trying to build the long and narrow dataset
>> >> V1xV2xV3
>> >>>> in
>> >>>>>>>>>>>>> such
>> >>>>>>>>>>>>> a way
>> >>>>>>>>>>>>> *>* that each V1xV2 cell does not get modified and V3 fits
>> >> as
>> >>>>>>>>>>>>> closely
>> >>>>>>>>>>>>> as
>> >>>>>>>>>>>>> *>* possible to its marginal distribution. Does it make
>> >> sense?
>> >>>>>>>>>>>>> *>>* To be even more specific, my 2 input files look like
>> >> the
>> >>>>>>>>>>>>> following.
>> >>>>>>>>>>>>> *>>* FILE 1
>> >>>>>>>>>>>>> *>* V1,V2,V4
>> >>>>>>>>>>>>> *>* A, A, 24.251
>> >>>>>>>>>>>>> *>* A, B, 1.065
>> >>>>>>>>>>>>> *>* (...)
>> >>>>>>>>>>>>> *>* B, C, 0.294
>> >>>>>>>>>>>>> *>* B, D, 2.731
>> >>>>>>>>>>>>> *>* (...)
>> >>>>>>>>>>>>> *>* H, L, 0.345
>> >>>>>>>>>>>>> *>* H, M, 0.000
>> >>>>>>>>>>>>> *>>* FILE 2
>> >>>>>>>>>>>>> *>* V3, V4
>> >>>>>>>>>>>>> *>* A, 1.575
>> >>>>>>>>>>>>> *>* B, 4.294
>> >>>>>>>>>>>>> *>* C, 10.044
>> >>>>>>>>>>>>> *>* (...)
>> >>>>>>>>>>>>> *>* L, 5.123
>> >>>>>>>>>>>>> *>* M, 3.334
>> >>>>>>>>>>>>> *>>* What I need to achieve is a file such as the following
>> >>>>>>>>>>>>> *>>* FILE 3
>> >>>>>>>>>>>>> *>* V1, V2, V3, V4
>> >>>>>>>>>>>>> *>* A, A, A, ???
>> >>>>>>>>>>>>> *>* A, A, B, ???
>> >>>>>>>>>>>>> *>* (...)
>> >>>>>>>>>>>>> *>* D, D, E, ???
>> >>>>>>>>>>>>> *>* D, D, F, ???
>> >>>>>>>>>>>>> *>* (...)
>> >>>>>>>>>>>>> *>* H, M, L, ???
>> >>>>>>>>>>>>> *>* H, M, M, ???
>> >>>>>>>>>>>>> *>>* Please notice that FILE 3 need to be such that if I
>> >>>> aggregate
>> >>>>>>>>>>>>> on
>> >>>>>>>>>>>>> V1+V2 I
>> >>>>>>>>>>>>> *>* recover exactly FILE 1 and that if I aggregate on V3 I
>> >> can
>> >>>>>>>>>>>>> recover
>> >>>>>>>>>>>>> a file
>> >>>>>>>>>>>>> *>* as close as possible to FILE 3 (ideally the same file).
>> >>>>>>>>>>>>> *>>* Can anyone suggest how I could do that with R?
>> >>>>>>>>>>>>> *>>* Thank you very much indeed for any assistance you are
>> >>>> able to
>> >>>>>>>>>>>>> provide.
>> >>>>>>>>>>>>> *>>* Kind regards,
>> >>>>>>>>>>>>> *>>* Luca*
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>>      [[alternative HTML version deleted]]
>>
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>

	[[alternative HTML version deleted]]


From nadia.arrouf at gmail.com  Mon Mar 23 17:37:54 2015
From: nadia.arrouf at gmail.com (Nadia_001)
Date: Mon, 23 Mar 2015 09:37:54 -0700 (PDT)
Subject: [R] My question: glm - binomial family (Probit vs Logit)
Message-ID: <CAOdEu1P1wJwCEKghjnYeirHiidHyXyFoBsakt1z2zUdZRYMzxw@mail.gmail.com>

Hi,

I try to compare the binomial family (i.e. Logit vs Probit) and in order to
do that, I need to make sure that I have the same variance for both link
fuction.
Therefore, I need to change the link scake "s" of the Logit. By default, it
is setted equal to 1 (s=1) and I wanted to set it  equal to sqrt(3)/pi.

Can you tell me how to do that?

Thanks,

Nadia




--
View this message in context: http://r.789695.n4.nabble.com/My-question-glm-binomial-family-Probit-vs-Logit-tp4705004.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From madlene.nussbaum at env.ethz.ch  Mon Mar 23 17:07:43 2015
From: madlene.nussbaum at env.ethz.ch (Nussbaum  Madlene)
Date: Mon, 23 Mar 2015 16:07:43 +0000
Subject: [R] mboost: Proportional odds boosting model - how to specify
 the offset?
References: <550C3769.5000701@fau.de>
Message-ID: <847D4A28424E3F4BB8E890216D28B996224F080C@MBX111.d.ethz.ch>


Dear Benjamin

This solved the problem.


On 03/20/2015 04:06 PM, Benjamin Hofner wrote:

> First, mboost expects the offset to be a scalar or a vector with length
> equal to the number of observations.
> (i.e., x'beta)

ok, I could not figure out how to get the correct link vector from the 
polr. Using glmboost is certainly a good idea.

> Second, there was a bug in mboost.

Thanks for fixing!


> install.packages("mboost", repos="http://R-Forge.R-project.org")

The changes were somehow not included in the newest build. I downloaded 
the function from the SCM Repository directly. It works fine now.

Thank you for your help!
Madlene


From varinsacha at yahoo.fr  Mon Mar 23 20:56:50 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Mon, 23 Mar 2015 19:56:50 +0000 (UTC)
Subject: [R] Superimposing 2 curves on the same graph with par(new=TRUE)
In-Reply-To: <C14F8107-C322-46B5-A97D-D16650314C31@utoronto.ca>
References: <C14F8107-C322-46B5-A97D-D16650314C31@utoronto.ca>
Message-ID: <375864616.1770070.1427140610776.JavaMail.yahoo@mail.yahoo.com>

Dear all,
Excellent, many thanks for everything.
Best,S
      De?: Boris Steipe <boris.steipe at utoronto.ca>
 ??: Clint Bowman <clint at ecy.wa.gov> 
Cc?: varin sacha <varinsacha at yahoo.fr>; "r-help at r-project.org" <r-help at r-project.org> 
 Envoy? le : Lundi 23 mars 2015 19h32
 Objet?: Re: [R] Superimposing 2 curves on the same graph with par(new=TRUE)
   
... and that gives you a "double ordinate plot", a staple of misleading statistics.

Let me give you an analogy: 

Imagine you are on a chemistry mailing list and someone asks about the proper way to mix aluminum powder with fertilizer. Of course, as a chemist you know how. But still - and the same holds for the "double ordinate plot" - just say no.


:-)


For reference (taken from a post on SO):
Junk charts:
? http://junkcharts.typepad.com/junk_charts/2006/06/illusion_of_suc.html
? http://junkcharts.typepad.com/junk_charts/2006/05/the_crossover_l.html
Perecptual Edge ( a more detailed analysis)
? http://www.perceptualedge.com/articles/visual_business_intelligence/dual-scaled_axes.pdf
SMBC's tutorial on infographics (point 4).
? http://www.smbc-comics.com/?id=3167





On Mar 23, 2015, at 2:14 PM, Clint Bowman <clint at ecy.wa.gov> wrote:

> Agreed--I neglected to add the secondary y-axis (shouldn't hit send so fast.)
> 
> Clint Bowman??? ??? ??? INTERNET:??? clint at ecy.wa.gov
> Air Quality Modeler??? ??? INTERNET:??? clint at math.utah.edu
> Department of Ecology??? ??? VOICE:??? ??? (360) 407-6815
> PO Box 47600??? ??? ??? FAX:??? ??? (360) 407-7534
> Olympia, WA 98504-7600
> 
>? ? ? ? USPS:? ? ? ? ? PO Box 47600, Olympia, WA 98504-7600
>? ? ? ? Parcels:? ? ? ? 300 Desmond Drive, Lacey, WA 98503-1274
> 
> On Mon, 23 Mar 2015, Boris Steipe wrote:
> 
>> ... which is exactly what he shouldn't do because now it the plot falsely asserts that both curves are plotted to the same scale.
>> 
>> 
>> B.
>> 
>> 
>> 
>> On Mar 23, 2015, at 12:34 PM, Clint Bowman <clint at ecy.wa.gov> wrote:
>> 
>>> Try:
>>> plot(Date,MORTSBu,lwd=2,lty="dashed",axes=F,xlab="",ylab="")
>>> 
>>> 
>>> 
>>> Clint Bowman??? ??? ??? INTERNET:??? clint at ecy.wa.gov
>>> Air Quality Modeler??? ??? INTERNET:??? clint at math.utah.edu
>>> Department of Ecology??? ??? VOICE:??? ??? (360) 407-6815
>>> PO Box 47600??? ??? ??? FAX:??? ??? (360) 407-7534
>>> Olympia, WA 98504-7600
>>> 
>>>? ? ? USPS:? ? ? ? ? PO Box 47600, Olympia, WA 98504-7600
>>>? ? ? Parcels:? ? ? ? 300 Desmond Drive, Lacey, WA 98503-1274
>>> 
>>> On Mon, 23 Mar 2015, varin sacha wrote:
>>> 
>>>> Dear R-Experts,
>>>> 
>>>> I try to superimpose/present 2 curves/plots on the same graph. I would like the result/graph to be readable.
>>>> For that, I use the par(new=TRUE) argument but on the Y-axis there is a superposition of writings and the Y-axis becomes unreadable.
>>>> How can I solve this problem ?
>>>> 
>>>> Here is a reproducible example :
>>>> Date<-c(1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010)
>>>> 
>>>> MORTSFr<-c(16445,17671,18113,17043,14738,14355,15028,14283,13229,13603,13672,13547,13527,13021,12737,11388,11947,10742,11497,11476,11215,10483,9900,9568,9019,8891,8541,8444,8918,8487,8079,8160,7655,6058,5593,5318,4709,4620,4275,4273,3992)
>>>> 
>>>> MORTSBu<-c(838,889,934,946,960,1030,1021,1040,1153,1149,1199,1219,1229,1123,1119,1113,1070,1153,1153,1280,1567,1114,1299,1307,1390,1264,1014,915,1003,1047,1012,1011,959,960,943,957,1043,1006,1061,901,776)
>>>> 
>>>> plot(Date,MORTSFr,type="l")
>>>> par(new=TRUE)
>>>> 
>>>> plot(Date,MORTSBu,lwd=2,lty="dashed")
>>>> 
>>>> Thanks for your time.
>>>> Best,
>>>> S
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 


  
	[[alternative HTML version deleted]]


From frainj at gmail.com  Mon Mar 23 21:28:39 2015
From: frainj at gmail.com (John C Frain)
Date: Mon, 23 Mar 2015 20:28:39 +0000
Subject: [R] Conversion of Matlab code to an R code
In-Reply-To: <CANtKHPVsOBRRMhtQ4EaLJ-pQ8MJb9niU9M37Mm-EykgSNw3O5A@mail.gmail.com>
References: <CANtKHPVsOBRRMhtQ4EaLJ-pQ8MJb9niU9M37Mm-EykgSNw3O5A@mail.gmail.com>
Message-ID: <CAHrK514HDGScONU6d87wbPy+8V69UPPtWwBb45yfG7rg7w78Vg@mail.gmail.com>

You do not say why you want to convert. I your reason is that you do not
have access to Matlab you might try to run your program in Octave. I think
that there are some syntax errors in your Matlab code. Most of these, but
not all, I think, may have been caused, (as you have already been told) by
the use of HTML in your email.

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 23 March 2015 at 15:10, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:

> Hi,
>
> Can a Matlab code be converted to R code?
>
> I am finding it difficult to do so.
>
> Could you please help me out with it.
>
> Your help will be highly appreciated.
>
> Here comes the Matlab code
> ##############
> if ~isvector(ecg)
>   error('ecg must be a row or column vector');
> end
>
>
> if nargin < 3
>     gr = 1;   % on default the function always plots
> end
> ecg = ecg(:); % vectorize
>
> %% Initialize
> qrs_c =[]; %amplitude of R
> qrs_i =[]; %index
> SIG_LEV = 0;
> nois_c =[];
> nois_i =[];
> delay = 0;
> skip = 0; % becomes one when a T wave is detected
> not_nois = 0; % it is not noise when not_nois = 1
> selected_RR =[]; % Selected RR intervals
> m_selected_RR = 0;
> mean_RR = 0;
> qrs_i_raw =[];
> qrs_amp_raw=[];
> ser_back = 0;
> test_m = 0;
> SIGL_buf = [];
> NOISL_buf = [];
> THRS_buf = [];
> SIGL_buf1 = [];
> NOISL_buf1 = [];
> THRS_buf1 = [];
>
>
> %% Plot differently based on filtering settings
> if gr
>  if fs == 200
>   figure,  ax(1)=subplot(321);plot(ecg);axis tight;title('Raw ECG Signal');
>  else
>   figure,  ax(1)=subplot(3,2,[1 2]);plot(ecg);axis tight;title('Raw ECG
> Signal');
>  end
> end
> %% Noise cancelation(Filtering) % Filters (Filter in between 5-15 Hz)
> if fs == 200
> %% Low Pass Filter  H(z) = ((1 - z^(-6))^2)/(1 - z^(-1))^2
> b = [1 0 0 0 0 0 -2 0 0 0 0 0 1];
> a = [1 -2 1];
> h_l = filter(b,a,[1 zeros(1,12)]);
> ecg_l = conv (ecg ,h_l);
> ecg_l = ecg_l/ max( abs(ecg_l));
> delay = 6; %based on the paper
> if gr
> ax(2)=subplot(322);plot(ecg_l);axis tight;title('Low pass filtered');
> end
> %% High Pass filter H(z) = (-1+32z^(-16)+z^(-32))/(1+z^(-1))
> b = [-1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 32 -32 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> 1];
> a = [1 -1];
> h_h = filter(b,a,[1 zeros(1,32)]);
> ecg_h = conv (ecg_l ,h_h);
> ecg_h = ecg_h/ max( abs(ecg_h));
> delay = delay + 16; % 16 samples for highpass filtering
> if gr
> ax(3)=subplot(323);plot(ecg_h);axis tight;title('High Pass Filtered');
> end
> else
> %% bandpass filter for Noise cancelation of other sampling
> frequencies(Filtering)
> f1=5; %cuttoff low frequency to get rid of baseline wander
> f2=15; %cuttoff frequency to discard high frequency noise
> Wn=[f1 f2]*2/fs; % cutt off based on fs
> N = 3; % order of 3 less processing
> [a,b] = butter(N,Wn); %bandpass filtering
> ecg_h = filtfilt(a,b,ecg);
> ecg_h = ecg_h/ max( abs(ecg_h));
> if gr
> ax(3)=subplot(323);plot(ecg_h);axis tight;title('Band Pass Filtered');
> end
> end
> %% derivative filter H(z) = (1/8T)(-z^(-2) - 2z^(-1) + 2z + z^(2))
> h_d = [-1 -2 0 2 1]*(1/8);%1/8*fs
> ecg_d = conv (ecg_h ,h_d);
> ecg_d = ecg_d/max(ecg_d);
> delay = delay + 2; % delay of derivative filter 2 samples
> if gr
> ax(4)=subplot(324);plot(ecg_d);axis tight;title('Filtered with the
> derivative filter');
> end
> %% Squaring nonlinearly enhance the dominant peaks
> ecg_s = ecg_d.^2;
> if gr
> ax(5)=subplot(325);plot(ecg_s);axis tight;title('Squared');
> end
>
>
>
> %% Moving average Y(nt) = (1/N)[x(nT-(N - 1)T)+ x(nT - (N - 2)T)+...+x(nT)]
> ecg_m = conv(ecg_s ,ones(1 ,round(0.150*fs))/round(0.150*fs));
> delay = delay + 15;
>
> if gr
> ax(6)=subplot(326);plot(ecg_m);axis tight;title('Averaged with 30 samples
> length,Black noise,Green Adaptive Threshold,RED Sig Level,Red circles QRS
> adaptive threshold');
> axis tight;
> end
>
> %% Fiducial Mark
> % Note : a minimum distance of 40 samples is considered between each R wave
> % since in physiological point of view no RR wave can occur in less than
> % 200 msec distance
> [pks,locs] = findpeaks(ecg_m,'MINPEAKDISTANCE',round(0.2*fs));
>
>
>
>
> %% initialize the training phase (2 seconds of the signal) to determine the
> THR_SIG and THR_NOISE
> THR_SIG = max(ecg_m(1:2*fs))*1/3; % 0.25 of the max amplitude
> THR_NOISE = mean(ecg_m(1:2*fs))*1/2; % 0.5 of the mean signal is considered
> to be noise
> SIG_LEV= THR_SIG;
> NOISE_LEV = THR_NOISE;
>
>
> %% Initialize bandpath filter threshold(2 seconds of the bandpass signal)
> THR_SIG1 = max(ecg_h(1:2*fs))*1/3; % 0.25 of the max amplitude
> THR_NOISE1 = mean(ecg_h(1:2*fs))*1/2; %
> SIG_LEV1 = THR_SIG1; % Signal level in Bandpassed filter
> NOISE_LEV1 = THR_NOISE1; % Noise level in Bandpassed filter
> %% Thresholding and online desicion rule
>
> for i = 1 : length(pks)
>
>    %% locate the corresponding peak in the filtered signal
>     if locs(i)-round(0.150*fs)>= 1 && locs(i)<= length(ecg_h)
>           [y_i x_i] = max(ecg_h(locs(i)-round(0.150*fs):locs(i)));
>        else
>           if i == 1
>             [y_i x_i] = max(ecg_h(1:locs(i)));
>             ser_back = 1;
>           elseif locs(i)>= length(ecg_h)
>             [y_i x_i] = max(ecg_h(locs(i)-round(0.150*fs):end));
>           end
>
>      end
>
>
>   %% update the heart_rate (Two heart rate means one the moste recent and
> the other selected)
>     if length(qrs_c) >= 9
>
>         diffRR = diff(qrs_i(end-8:end)); %calculate RR interval
>         mean_RR = mean(diffRR); % calculate the mean of 8 previous R waves
> interval
>         comp =qrs_i(end)-qrs_i(end-1); %latest RR
>         if comp <= 0.92*mean_RR || comp >= 1.16*mean_RR
>             % lower down thresholds to detect better in MVI
>                 THR_SIG = 0.5*(THR_SIG);
>                 %THR_NOISE = 0.5*(THR_SIG);
>                % lower down thresholds to detect better in Bandpass
> filtered
>                 THR_SIG1 = 0.5*(THR_SIG1);
>                 %THR_NOISE1 = 0.5*(THR_SIG1);
>
>         else
>             m_selected_RR = mean_RR; %the latest regular beats mean
>         end
>
>     end
>
>       %% calculate the mean of the last 8 R waves to make sure that QRS is
> not
>        % missing(If no R detected , trigger a search back) 1.66*mean
>
>        if m_selected_RR
>            test_m = m_selected_RR; %if the regular RR availabe use it
>        elseif mean_RR && m_selected_RR == 0
>            test_m = mean_RR;
>        else
>            test_m = 0;
>        end
>
>     if test_m
>           if (locs(i) - qrs_i(end)) >= round(1.66*test_m)% it shows a QRS
> is missed
>               [pks_temp,locs_temp] = max(ecg_m(qrs_i(end)+
> round(0.200*fs):locs(i)-round(0.200*fs))); % search back and locate the max
> in this interval
>               locs_temp = qrs_i(end)+ round(0.200*fs) + locs_temp -1;
> %location
>
>               if pks_temp > THR_NOISE
>                qrs_c = [qrs_c pks_temp];
>                qrs_i = [qrs_i locs_temp];
>
>                % find the location in filtered sig
>                if locs_temp <= length(ecg_h)
>                 [y_i_t x_i_t] =
> max(ecg_h(locs_temp-round(0.150*fs):locs_temp));
>                else
>                 [y_i_t x_i_t] = max(ecg_h(locs_temp-round(0.150*fs):end));
>                end
>                % take care of bandpass signal threshold
>                if y_i_t > THR_NOISE1
>
>                       qrs_i_raw = [qrs_i_raw locs_temp-round(0.150*fs)+
> (x_i_t - 1)];% save index of bandpass
>                       qrs_amp_raw =[qrs_amp_raw y_i_t]; %save amplitude of
> bandpass
>                       SIG_LEV1 = 0.25*y_i_t + 0.75*SIG_LEV1; %when found
> with the second thres
>                end
>
>                not_nois = 1;
>                SIG_LEV = 0.25*pks_temp + 0.75*SIG_LEV ;  %when found with
> the second threshold
>              end
>
>           else
>               not_nois = 0;
>
>           end
>     end
>
>
>
>
>     %%  find noise and QRS peaks
>     if pks(i) >= THR_SIG
>
>                  % if a QRS candidate occurs within 360ms of the previous
> QRS
>                  % ,the algorithm determines if its T wave or QRS
>                  if length(qrs_c) >= 3
>                       if (locs(i)-qrs_i(end)) <= round(0.3600*fs)
>                         Slope1 =
> mean(diff(ecg_m(locs(i)-round(0.075*fs):locs(i)))); %mean slope of the
> waveform at that position
>                         Slope2 =
> mean(diff(ecg_m(qrs_i(end)-round(0.075*fs):qrs_i(end)))); %mean slope of
> previous R wave
>                              if abs(Slope1) <= abs(0.5*(Slope2))  % slope
> less then 0.5 of previous R
>                                  nois_c = [nois_c pks(i)];
>                                  nois_i = [nois_i locs(i)];
>                                  skip = 1; % T wave identification
>                                  % adjust noise level in both filtered and
>                                  % MVI
>                                  NOISE_LEV1 = 0.125*y_i + 0.875*NOISE_LEV1;
>                                  NOISE_LEV = 0.125*pks(i) +
> 0.875*NOISE_LEV;
>                              else
>                                  skip = 0;
>                              end
>
>                       end
>                  end
>
>         if skip == 0  % skip is 1 when a T wave is detected
>         qrs_c = [qrs_c pks(i)];
>         qrs_i = [qrs_i locs(i)];
>
>         % bandpass filter check threshold
>          if y_i >= THR_SIG1
>                         if ser_back
>                            qrs_i_raw = [qrs_i_raw x_i];  % save index of
> bandpass
>                         else
>                            qrs_i_raw = [qrs_i_raw locs(i)-round(0.150*fs)+
> (x_i - 1)];% save index of bandpass
>                         end
>                            qrs_amp_raw =[qrs_amp_raw y_i];% save amplitude
> of bandpass
>           SIG_LEV1 = 0.125*y_i + 0.875*SIG_LEV1;% adjust threshold for
> bandpass filtered sig
>          end
>
>         % adjust Signal level
>         SIG_LEV = 0.125*pks(i) + 0.875*SIG_LEV ;
>         end
>
>
>     elseif THR_NOISE <= pks(i) && pks(i)<THR_SIG
>
>          %adjust Noise level in filtered sig
>          NOISE_LEV1 = 0.125*y_i + 0.875*NOISE_LEV1;
>          %adjust Noise level in MVI
>          NOISE_LEV = 0.125*pks(i) + 0.875*NOISE_LEV;
>
>
>
>     elseif pks(i) < THR_NOISE
>         nois_c = [nois_c pks(i)];
>         nois_i = [nois_i locs(i)];
>
>         % noise level in filtered signal
>         NOISE_LEV1 = 0.125*y_i + 0.875*NOISE_LEV1;
>         %end
>
>          %adjust Noise level in MVI
>         NOISE_LEV = 0.125*pks(i) + 0.875*NOISE_LEV;
>
>
>     end
>
>
>
>
>
>     %% adjust the threshold with SNR
>     if NOISE_LEV ~= 0 || SIG_LEV ~= 0
>         THR_SIG = NOISE_LEV + 0.25*(abs(SIG_LEV - NOISE_LEV));
>         THR_NOISE = 0.5*(THR_SIG);
>     end
>
>     % adjust the threshold with SNR for bandpassed signal
>     if NOISE_LEV1 ~= 0 || SIG_LEV1 ~= 0
>         THR_SIG1 = NOISE_LEV1 + 0.25*(abs(SIG_LEV1 - NOISE_LEV1));
>         THR_NOISE1 = 0.5*(THR_SIG1);
>     end
>
>
> % take a track of thresholds of smoothed signal
> SIGL_buf = [SIGL_buf SIG_LEV];
> NOISL_buf = [NOISL_buf NOISE_LEV];
> THRS_buf = [THRS_buf THR_SIG];
>
> % take a track of thresholds of filtered signal
> SIGL_buf1 = [SIGL_buf1 SIG_LEV1];
> NOISL_buf1 = [NOISL_buf1 NOISE_LEV1];
> THRS_buf1 = [THRS_buf1 THR_SIG1];
>
>
>
>
>  skip = 0; %reset parameters
>  not_nois = 0; %reset parameters
>  ser_back = 0;  %reset bandpass param
> end
>
> if gr
> hold on,scatter(qrs_i,qrs_c,'m');
> hold on,plot(locs,NOISL_buf,'--k','LineWidth',2);
> hold on,plot(locs,SIGL_buf,'--r','LineWidth',2);
> hold on,plot(locs,THRS_buf,'--g','LineWidth',2);
> if ax(:)
> linkaxes(ax,'x');
> zoom on;
> end
> end
>
>
>
>
> %% overlay on the signals
> if gr
> figure,az(1)=subplot(311);plot(ecg_h);title('QRS on Filtered Signal');axis
> tight;
> hold on,scatter(qrs_i_raw,qrs_amp_raw,'m');
> hold on,plot(locs,NOISL_buf1,'LineWidth',2,'Linestyle','--','color','k');
> hold on,plot(locs,SIGL_buf1,'LineWidth',2,'Linestyle','-.','color','r');
> hold on,plot(locs,THRS_buf1,'LineWidth',2,'Linestyle','-.','color','g');
> az(2)=subplot(312);plot(ecg_m);title('QRS on MVI signal and Noise
> level(black),Signal Level (red) and Adaptive Threshold(green)');axis tight;
> hold on,scatter(qrs_i,qrs_c,'m');
> hold on,plot(locs,NOISL_buf,'LineWidth',2,'Linestyle','--','color','k');
> hold on,plot(locs,SIGL_buf,'LineWidth',2,'Linestyle','-.','color','r');
> hold on,plot(locs,THRS_buf,'LineWidth',2,'Linestyle','-.','color','g');
> az(3)=subplot(313);plot(ecg-mean(ecg));title('Pulse train of the found QRS
> on ECG signal');axis tight;
> line(repmat(qrs_i_raw,[2 1]),repmat([min(ecg-mean(ecg))/2;
>
> max(ecg-mean(ecg))/2],size(qrs_i_raw)),'LineWidth',2.5,'LineStyle','-.','Color','r');
> linkaxes(az,'x');
> zoom on;
> end
> ##############
>
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sven.templer at gmail.com  Mon Mar 23 21:57:57 2015
From: sven.templer at gmail.com (Sven E. Templer)
Date: Mon, 23 Mar 2015 21:57:57 +0100
Subject: [R] the making of _R_ eBooks
In-Reply-To: <139BF08E8346428F9ED95A8CADDD6C7B@Petra>
References: <48E60F6FD5CD45C0A7AA320694FB1F8E@Petra>
	<55100361.9010603@stats.ox.ac.uk>
	<139BF08E8346428F9ED95A8CADDD6C7B@Petra>
Message-ID: <CAHuTOvrRfUR-9vGWdJwpmW8xvjxkr+1=qntrurFufUVZqsUPYw@mail.gmail.com>

> Q3: any other recommendations?

You might be interested in the very easy to use R markdown, see:
http://rmarkdown.rstudio.com/

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Mon Mar 23 22:46:08 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 24 Mar 2015 10:46:08 +1300
Subject: [R] Fast evaluation of functions in 3D domains
In-Reply-To: <5468595262hurgil@uv.es>
References: <5468595262hurgil@uv.es>
Message-ID: <551089A0.3020202@auckland.ac.nz>


On 23/03/15 23:44, Lluis.Hurtado at uv.es wrote:

> Dear all,
>
> I am currently working with the spatstat package with 3D samples. I am trying to
> evaluate a non analytical function over the window that encloses the sample and I
> need to know which is the fastest way of doing it.

I gather that you mean that you want to evaluate the *integral* of the 
function over the window.

What do you mean by "non analytical"?  You have, it would appear, some 
way of calculating the function at an arbitrary point (x,y,z) in 
3-space, which makes it at least in some some sense "analytical".

> The function input is a 3 coordinate position in the window (x,y,z) and a list of
> parameters (a,b,c). The output is a numerical value.
>
> n <- function(x,y,z,a,b,c)
>
> But I need to do it over the whole volume.
>
> For 2 dimensions it can be done with
>
> A <- as.im(function,window,parameters)
> norm <- integral.im(A).

There is nothing very sophisticated about the way integral.im() works. 
Just look at the code.  The operative line of code is:

    a <- with(f, sum(v, na.rm = TRUE) * xstep * ystep)

> For 3 dimensions I have tried to pass an array of a grid covering the window (like a
> quadrature scheme) and then summing up the output array, but I would like to know if
> there is any faster way of integrating the function.

It sounds, at least vaguely, as though you are imitating in 3D what 
integral.im() does in 2D.  So, given that you are doing it right, you 
are doing as well as integral.im() does.

The calculations should be pretty fast since sum() is pretty fast.  The 
bulk of the computational burden is likely to be the evaluation of the 
function at all of the voxel centres.

Note that this is a very unsophisticated method of numerical quadrature. 
  The integrand is being approximated by a step function.  The method 
seems to work well enough for the uses that we put it to in spatstat. 
Whether it works well enough for your purposes depends on what your 
purposes are.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From dwinsemius at comcast.net  Mon Mar 23 22:50:11 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 23 Mar 2015 14:50:11 -0700
Subject: [R] Fast evaluation of functions in 3D domains
In-Reply-To: <5468595262hurgil@uv.es>
References: <5468595262hurgil@uv.es>
Message-ID: <36EBCEEB-EBEE-4883-9DAF-50FE66BF1E2B@comcast.net>


On Mar 23, 2015, at 3:44 AM, <Lluis.Hurtado at uv.es> <Lluis.Hurtado at uv.es> wrote:

> Dear all,
> 
> I am currently working with the spatstat package with 3D samples. I am trying to 
> evaluate a non analytical function over the window that encloses the sample and I 
> need to know which is the fastest way of doing it.
> 
> The function input is a 3 coordinate position in the window (x,y,z) and a list of 
> parameters (a,b,c). The output is a numerical value. 
> 
> n <- function(x,y,z,a,b,c)

Perhaps:

dfrm <- as.data.frame.table(your_volume_matrix) 
n.out <- with(dfrm,  mapply( n, x=x, y=y, z=z, MoreArgs=list(a=a,b=b,c=c) ) _
dim(n.out) <- dim(your_volume_matrix)

You don't describe the form of this "3 coordinate position in the window (x,y,z)" so perhaps the arguments will need to be extracted. I took a WAG at one approach. If it's not in long-form, you need configure the array indices for either a volume or surface into a dataframe, perhaps with `expand.grid` or `as.data.frame.table`.

 You also don't describe the sort of integration you imagine. Why not a simple sum of that result divided by the volume? I cannot imagine any faster procedure.


> But I need to do it over the whole volume.
> 
> For 2 dimensions it can be done with
> 
> A <- as.im(function,window,parameters)
> norm <- integral.im(A)
> 
> For 3 dimensions I have tried to pass an array of a grid covering the window (like a 
> quadrature scheme) and then summing up the output array, but I would like to know if 
> there is any faster way of integrating the function.
> 
> Thank you very much,
> 
> Llu?s Hurtado
> IFCA
> www.ifca.unican.es
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From Cindy.Zhou at citizensbank.com  Mon Mar 23 21:07:13 2015
From: Cindy.Zhou at citizensbank.com (Zhou, Cindy)
Date: Mon, 23 Mar 2015 20:07:13 +0000
Subject: [R] Confusion about cointegration for AR(M) model
Message-ID: <7C35B02D01671049B239AB9C2A970867D7ECEB@WEXCRIB00001048.corp.internal.citizensbank.com>

I have a question regarding the concept of cointegration. Does the concept of cointegration apply to any model? Or it only applies to OLS? For example, I fit an autoregressive error model , AR(M)

y_t=x_t*?+v_t

v_t=-?_1*v_(t-1)-...-?_m*v_(t-m)+?_t

If the ADF tests prove that both dependent variable y and independent variable x are stationary at I(1), and the residuals ?_t are stationary at I(0), Can I conclude y and x are cointegrated? The residuals ?_t are the prediction errors from the AR(M) model.

I checked the definition of cointegration, it looks like as long as the residuals from OLS are I(0) and both x and y are I(1), then x and y are cointegrated? Do I need to test stationary of the residuals from my AR(M) model in order to prove that x and y are cointegrated?

You help is appreciated.




Use of email is inherently insecure. Confidential information, including account information, and personally identifiable information, should not be transmitted via email, or email attachment. The information in this email may contain confidential and/or privileged information and is intended only for the use of the individual/entity named above. Any disclosure, copying, distribution or use of this information is strictly prohibited. If you have received this communication in error, please notify the sender immediately and destroy any record of this email.

Citizens Bank, N.A. is an affiliate of Citizens Financial Group, Inc.

	[[alternative HTML version deleted]]


From johnwoodill at gmail.com  Tue Mar 24 02:49:32 2015
From: johnwoodill at gmail.com (A. John Woodill)
Date: Mon, 23 Mar 2015 15:49:32 -1000
Subject: [R] plm, multicollinearity and model checking
Message-ID: <CABr942ok3j35u426sHAtGi_6P=vQe2nvZvmbSzF=40OPkNRMew@mail.gmail.com>

I'm fitting a fixed effect model with plm and know that I'm dealing with
multi-collinearity between two of the independent variables. I working on
identifying multicolliearity in models as a practice and have identified
the variable with alias(), then verified with vif(). I was also able to use
kappa() to show a very large conditional number verifying the
multicollinearity.

My question is why does plm() omit this multicolliearity variable from the
coefficients? There is no output clarifying why and I couldn't find
anything in the documentation. Stata automatically omits this variable and
I'm curious if plm() does a check and then omits.  Does plm() run through
checks when fitting a fixed effect model that checks for collinearity or
any other problems before running the model?  Why is dfmfd98 variable being
omitted in the example below?

Stack Exchange Post :
http://stats.stackexchange.com/questions/141684/multicollinearity-plm-and-omitting-variables

Multicollinearity variable dfmfd98

Reproducible example :

dput :

data <- structure(list(lexptot = c(8.28377505197124, 9.1595012302023,
8.14707583238833,
9.86330744180814, 8.21391453619232, 8.92372556833205, 7.77219149815994,
8.58202430280175, 8.34096828565733, 10.1133857229336, 8.56482997492403,
8.09468633074053, 8.27040804817704, 8.69834992618814, 8.03086333985764,
8.89644392254136, 8.20990433577082, 8.82621293136669, 7.79379981225575,
8.16139809188569, 8.25549748271241, 8.57464947213076, 8.2714431846277,
8.72374048671495, 7.98522888221012, 8.56460042433047, 8.22778847721461,
9.15431416391622, 8.25261818916933, 8.88033778695326), year = c(0L, 1L, 0L,
1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L,
0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L), dfmfdyr = c(0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0), dfmfd98 = c(1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
0, 0, 0), nh = c(11054L, 11054L, 11061L, 11061L, 11081L, 11081L, 11101L,
11101L, 12021L, 12021L, 12035L, 12035L, 12051L, 12051L, 12054L, 12054L,
12081L, 12081L, 12121L, 12121L, 13014L, 13014L, 13015L, 13015L, 13021L,
13021L, 13025L, 13025L, 13035L, 13035L)), .Names = c("lexptot", "year",
"dfmfdyr", "dfmfd98", "nh"), class = c("tbl_df", "data.frame"), row.names =
c(NA, -30L))

Regression Code :

library(plm)

lm <- plm(lexptot ~ year + dfmfdyr + dfmfd98 + nh, data = data, model =
"within", index = "nh")

summary(lm)

Output :

Oneway (individual) effect Within Model

Call:

plm(formula = lexptot ~ year + dfmfdyr + dfmfd98 + nh, data = data,

    model = "within", index = "nh")

Balanced Panel: n=15, T=2, N=30

Residuals :

     Min.   1st Qu.    Median   3rd Qu.      Max.

-4.75e-01 -1.69e-01  4.44e-16  1.69e-01  4.75e-01

Coefficients :

        Estimate Std. Error t-value Pr(>|t|)

year     0.47552    0.23830  1.9955  0.06738 .

dfmfdyr  0.34635    0.29185  1.1867  0.25657

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Total Sum of Squares:    5.7882

Residual Sum of Squares: 1.8455

R-Squared      :  0.68116

      Adj. R-Squared :  0.29517

F-statistic: 13.8864 on 2 and 13 DF, p-value: 0.00059322

	[[alternative HTML version deleted]]


From lindnerw at t-online.de  Tue Mar 24 09:33:47 2015
From: lindnerw at t-online.de (Dr. Wolfgang Lindner)
Date: Tue, 24 Mar 2015 09:33:47 +0100
Subject: [R] the making of _R_ eBooks
References: <48E60F6FD5CD45C0A7AA320694FB1F8E@Petra><55100361.9010603@stats.ox.ac.uk><139BF08E8346428F9ED95A8CADDD6C7B@Petra>
	<CAHuTOvrRfUR-9vGWdJwpmW8xvjxkr+1=qntrurFufUVZqsUPYw@mail.gmail.com>
Message-ID: <06A15DC86E2146E3BA95ACBAF26B90B4@Petra>

From: "Amos B. Elberg" <amos.elberg at gmail.com>
| If you take a look at rmarkdown and the rticles package, you'll find a 
template for | a "tufte ebook" in the style of Edward Tufte.

From: "Sven E. Templer" <sven.templer at gmail.com>
|> Q3: any other recommendations?
| You might be interested in the very easy to use R markdown, see:
| http://rmarkdown.rstudio.com/

Dear Sven, dear Amos,

that's what I was looking for!
Thanks for pointing me to rmarkdown, rticles package and the Tufte template.

best, Wolfgang G Lindner
Leichlingen, Germany


From lkhodakarim at gmail.com  Tue Mar 24 10:47:02 2015
From: lkhodakarim at gmail.com (Soheila Khodakarim)
Date: Tue, 24 Mar 2015 13:17:02 +0330
Subject: [R] missing in neural network
Message-ID: <CACYT75uwxC-BeLkXtjM_QPQoHZq7Mzb6ZKdSjr3NY13Nj70-Pw@mail.gmail.com>

Dear All,

I want to run "neural network" on my dataset.
##########################################################
resp<-c(1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1)
dim(data)
#20*3110

out <- neuralnet(y ~ data, hidden = 4, lifesign = "minimal", linear.output
= FALSE, threshold = 0.1,na.rm = TRUE)
################################################################
but I see this Error
Error in varify.variables(data, formula, startweights, learningrate.limit,
 :
  argument "data" is missing, with no default

What should I do now??

Best Regards,
Soheila

	[[alternative HTML version deleted]]


From phaedrusv at gmail.com  Tue Mar 24 12:55:59 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Tue, 24 Mar 2015 11:55:59 +0000
Subject: [R] Cluster analysis using term frequencies
Message-ID: <551150CF.7000406@gmail.com>

Hi list

I am using the 'tm' package to review meeting notes at a school to 
identify terms frequently associated with 'learning', 'sports', and 
'extra-mural' activities, and then to sort any terms according to these 
three headers in a way that could be supported statistically (as opposed 
to, say, my own bias, etc.).

To accomplish this, I have done the following:

(1) After the usual pre-processing of the text data, loading it as a 
corpus and then converting it into a document term matrix (called 
'allTerms'), I have identified the 20 most frequently occurring terms in 
the meeting notes and extracted these into a named vector called 
'freqTerms'. Many of the terms returned have nothing to do with any of 
the three themes of 'learning', 'sports', or 'extra-mural'.

(2) Therefore, I have also manually generated a list of terms and 
synonyms for 'learning' and 'sports', etc. (e.g. 'football', 'soccer', 
'drama', 'chess', etc.) and then tested for the occurrence of each of 
these terms in the corpus, e.g.:

 > allTerms['soccer']

and have come up with a list of some 30 terms together with their 
frequencies. I manually sorted these according to three headers 
'learning', 'sports', and 'extra-mural' and dropped these into a table 
in a word processing document. Some of these terms are also in the 
freqTerms vector.

What I want to do now is to use cluster analysis (hclust, from the 
'cluster' library) to plot a dendrogram of the terms I have manually 
checked and put into the table, in order to see how closely similar the 
terms are and whether they cluster in ways similar to the way as I 
manually sorted these under the table column headers of 'learning', 
'sports', and 'extra-mural'.

To do this, I dropped these manually sorted terms into a data frame 
together with the associated values (which I called 'tes.df') and then 
tried plotting this as follows:

 > dtes <- dist(tes.df, method = 'euclidean')
 > dtesFreq <- hclust(dtes, method = 'ward.D')
 > plot(dtesFreq, labels = names(tes.df))

However, I get an error message when trying to plot this: "Error in 
graphics:::plotHclust(n1, merge, height, order(x$order), hang,  : 
invalid dendrogram input".

I'm clearly screwing something up, either in my source data.frame or in 
my setting hclust up, but don't know which, nor how.

More than just identifying the error however, I am interested in finding 
a smart (efficient/ elegant) way of checking the occurrence and 
frequency value of the terms that may be associated with 'sports', 
'learning', and 'extra-mural' and extracting these into a matrix or data 
frame so that I can analyse and plot their clustering to see if how I 
associated these terms is actually supported statistically.

I'm sure that there must be a way of doing this in R, but I'm obviously 
not going about it correctly. Can anyone shine a light please?

Thanks for any help/ guidance.

Regards,
Sun


From deter088 at umn.edu  Tue Mar 24 13:18:03 2015
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 24 Mar 2015 07:18:03 -0500
Subject: [R] missing in neural network
In-Reply-To: <CACYT75uwxC-BeLkXtjM_QPQoHZq7Mzb6ZKdSjr3NY13Nj70-Pw@mail.gmail.com>
References: <CACYT75uwxC-BeLkXtjM_QPQoHZq7Mzb6ZKdSjr3NY13Nj70-Pw@mail.gmail.com>
Message-ID: <CAOLJphnZt6QCdztLfop+y=+cd9FzQWJDB1opi4d2ArVbTSVFMw@mail.gmail.com>

Hi Soheila,

You are using the formula argument incorrectly.  The neuralnet function has
a separate argument for data aptly names 'data'.  You can review the
arguments by looking at the documentation  with ?neuralnet.

As I cannot reproduce your data the following is not tested but I think
should work for you.

# Join your response variable to your data set.
mydata <- cbind(data, resp)

# Run neuralnet
out <- neuralnet(resp ~ ., data=mydata, hidden = 4, lifesign = "minimal",
                       linear.output = FALSE, threshold = 0.1,na.rm = TRUE)


Best,
Charles

On Tue, Mar 24, 2015 at 4:47 AM, Soheila Khodakarim <lkhodakarim at gmail.com>
wrote:

> Dear All,
>
> I want to run "neural network" on my dataset.
> ##########################################################
> resp<-c(1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1)
> dim(data)
> #20*3110
>
> out <- neuralnet(y ~ data, hidden = 4, lifesign = "minimal", linear.output
> = FALSE, threshold = 0.1,na.rm = TRUE)
> ################################################################
> but I see this Error
> Error in varify.variables(data, formula, startweights, learningrate.limit,
>  :
>   argument "data" is missing, with no default
>
> What should I do now??
>
> Best Regards,
> Soheila
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ucakche at ucl.ac.uk  Tue Mar 24 14:39:27 2015
From: ucakche at ucl.ac.uk (Christian Hennig)
Date: Tue, 24 Mar 2015 13:39:27 +0000
Subject: [R] Cluster analysis using term frequencies
In-Reply-To: <551150CF.7000406@gmail.com>
References: <551150CF.7000406@gmail.com>
Message-ID: <alpine.GSO.2.00.1503241332050.20878@socrates-a.ucl.ac.uk>

Dear Sun Shine,

>> dtes <- dist(tes.df, method = 'euclidean')
>> dtesFreq <- hclust(dtes, method = 'ward.D')
>> plot(dtesFreq, labels = names(tes.df))
>
> However, I get an error message when trying to plot this: "Error in 
> graphics:::plotHclust(n1, merge, height, order(x$order), hang,  : invalid 
> dendrogram input".

I don't see anything wrong with the code, so what I'd do is run
str(dtes) and str(dtesFreq) to see whether these are what they should be 
(or if not, what they are instead).

> I'm clearly screwing something up, either in my source data.frame or in my 
> setting hclust up, but don't know which, nor how.

Can't comment on your source data but generally, whatever you do, use 
str() or even print() to see whether the R-objects are allright or what 
went wrong.

> More than just identifying the error however, I am interested in finding a 
> smart (efficient/ elegant) way of checking the occurrence and frequency value 
> of the terms that may be associated with 'sports', 'learning', and 
> 'extra-mural' and extracting these into a matrix or data frame so that I can 
> analyse and plot their clustering to see if how I associated these terms is 
> actually supported statistically.

The first thing that comes to my mind (not necessarily the best/most 
elegant) is to run...
dtes3 <- cutree(dtesFreq,3)
...and to table dtes3 against your manual classification.
Note that 3 is the most "natural" number of clusters to cut the tree 
here but may not be the best to match your classification (for example, 
you may have a one-point cluster in the 3-cluster solution, so it may 
effectively be a two-cluster solution with an outlier). Your 
dendrogram, if you succeed plotting it, may give you a hint about that.

Hope this helps,
Christian


>
> I'm sure that there must be a way of doing this in R, but I'm obviously not 
> going about it correctly. Can anyone shine a light please?
>
> Thanks for any help/ guidance.
>
> Regards,
> Sun
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

*** --- ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
c.hennig at ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche


From lkhodakarim at gmail.com  Tue Mar 24 15:58:16 2015
From: lkhodakarim at gmail.com (Soheila Khodakarim)
Date: Tue, 24 Mar 2015 18:28:16 +0330
Subject: [R] Fwd:  missing in neural network
In-Reply-To: <CACYT75vyzxYiyWmKNPG6tJQrLdSvEF+=eX-7cwaXMd5yeX4fyw@mail.gmail.com>
References: <CACYT75uwxC-BeLkXtjM_QPQoHZq7Mzb6ZKdSjr3NY13Nj70-Pw@mail.gmail.com>
	<CAOLJphnZt6QCdztLfop+y=+cd9FzQWJDB1opi4d2ArVbTSVFMw@mail.gmail.com>
	<CACYT75vyzxYiyWmKNPG6tJQrLdSvEF+=eX-7cwaXMd5yeX4fyw@mail.gmail.com>
Message-ID: <CACYT75vON_g_L0bN_Ta6diYDXTmdFKDs_4M5cuLM7q6jEy=WgA@mail.gmail.com>

Dear Charles,

Thanks for your guide.
I run this code:

library("neuralnet")
resp<-c(1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1)
mydata <- cbind(data, resp)
out1 <- neuralnet(resp~mydata[,1:3110],data=mydata, hidden = 4, lifesign =
"minimal", linear.output = FALSE, threshold = 0.1)

I saw this error

Error in neurons[[i]] %*% weights[[i]] : non-conformable arguments

:(:(:(

What should I do now??

Regards,
Soheila


On Tue, Mar 24, 2015 at 3:48 PM, Charles Determan Jr <deter088 at umn.edu>
wrote:

> Hi Soheila,
>
> You are using the formula argument incorrectly.  The neuralnet function
> has a separate argument for data aptly names 'data'.  You can review the
> arguments by looking at the documentation  with ?neuralnet.
>
> As I cannot reproduce your data the following is not tested but I think
> should work for you.
>
> # Join your response variable to your data set.
> mydata <- cbind(data, resp)
>
> # Run neuralnet
> out <- neuralnet(resp ~ ., data=mydata, hidden = 4, lifesign = "minimal",
>                        linear.output = FALSE, threshold = 0.1,na.rm =
> TRUE)
>
>
> Best,
> Charles
>
> On Tue, Mar 24, 2015 at 4:47 AM, Soheila Khodakarim <lkhodakarim at gmail.com
> > wrote:
>
>> Dear All,
>>
>> I want to run "neural network" on my dataset.
>> ##########################################################
>> resp<-c(1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1)
>> dim(data)
>> #20*3110
>>
>> out <- neuralnet(y ~ data, hidden = 4, lifesign = "minimal", linear.output
>> = FALSE, threshold = 0.1,na.rm = TRUE)
>> ################################################################
>> but I see this Error
>> Error in varify.variables(data, formula, startweights, learningrate.limit,
>>  :
>>   argument "data" is missing, with no default
>>
>> What should I do now??
>>
>> Best Regards,
>> Soheila
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>
>

	[[alternative HTML version deleted]]


From deter088 at umn.edu  Tue Mar 24 16:14:32 2015
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 24 Mar 2015 10:14:32 -0500
Subject: [R] missing in neural network
In-Reply-To: <CACYT75vyzxYiyWmKNPG6tJQrLdSvEF+=eX-7cwaXMd5yeX4fyw@mail.gmail.com>
References: <CACYT75uwxC-BeLkXtjM_QPQoHZq7Mzb6ZKdSjr3NY13Nj70-Pw@mail.gmail.com>
	<CAOLJphnZt6QCdztLfop+y=+cd9FzQWJDB1opi4d2ArVbTSVFMw@mail.gmail.com>
	<CACYT75vyzxYiyWmKNPG6tJQrLdSvEF+=eX-7cwaXMd5yeX4fyw@mail.gmail.com>
Message-ID: <CAOLJphkxvBZNSHVfoU6caLOW0ws6hhew0c1i21A34rtFo-0eMA@mail.gmail.com>

I should have actually created some test code for you.  Here is an example:

library(neuralnet)
data(infert)

# create your formula
fm <- as.formula(paste("case ~ ", paste(colnames(infert)[c(3,4,6)],
collapse="+")))

# call neuralnet
net.infert <- neuralnet(fm, infert,
                        err.fct="ce", linear.output=FALSE, likelihood=TRUE)

You don't want to index your dataset like that, you should utilize the
formula interface.  Interestingly, the '.' notation doesn't seem to work
here.  Your formula call probably will look like this:

fm <- as.formula(paste("resp ~ ", paste(colnames(data), collapse="+")))

And you call would be

out1 <- neuralnet(fm,data=mydata, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1)

Regards,

Charles

On Tue, Mar 24, 2015 at 9:56 AM, Soheila Khodakarim <lkhodakarim at gmail.com>
wrote:

> Dear Charles,
>
> Thanks for your guide.
> I run this code:
>
> library("neuralnet")
> resp<-c(1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1)
> mydata <- cbind(data, resp)
> out1 <- neuralnet(resp~mydata[,1:3110],data=mydata, hidden = 4, lifesign =
> "minimal", linear.output = FALSE, threshold = 0.1)
>
> I saw this error
>
> Error in neurons[[i]] %*% weights[[i]] : non-conformable arguments
>
> :(:(:(
>
> What should I do now??
>
> Regards,
> Soheila
>
>
> On Tue, Mar 24, 2015 at 3:48 PM, Charles Determan Jr <deter088 at umn.edu>
> wrote:
>
>> Hi Soheila,
>>
>> You are using the formula argument incorrectly.  The neuralnet function
>> has a separate argument for data aptly names 'data'.  You can review the
>> arguments by looking at the documentation  with ?neuralnet.
>>
>> As I cannot reproduce your data the following is not tested but I think
>> should work for you.
>>
>> # Join your response variable to your data set.
>> mydata <- cbind(data, resp)
>>
>> # Run neuralnet
>> out <- neuralnet(resp ~ ., data=mydata, hidden = 4, lifesign = "minimal",
>>                        linear.output = FALSE, threshold = 0.1,na.rm =
>> TRUE)
>>
>>
>> Best,
>> Charles
>>
>> On Tue, Mar 24, 2015 at 4:47 AM, Soheila Khodakarim <
>> lkhodakarim at gmail.com> wrote:
>>
>>> Dear All,
>>>
>>> I want to run "neural network" on my dataset.
>>> ##########################################################
>>> resp<-c(1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1)
>>> dim(data)
>>> #20*3110
>>>
>>> out <- neuralnet(y ~ data, hidden = 4, lifesign = "minimal",
>>> linear.output
>>> = FALSE, threshold = 0.1,na.rm = TRUE)
>>> ################################################################
>>> but I see this Error
>>> Error in varify.variables(data, formula, startweights,
>>> learningrate.limit,
>>>  :
>>>   argument "data" is missing, with no default
>>>
>>> What should I do now??
>>>
>>> Best Regards,
>>> Soheila
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>>
>>
>


-- 
Dr. Charles Determan, PhD
Integrated Biosciences

	[[alternative HTML version deleted]]


From clint at ecy.wa.gov  Tue Mar 24 17:48:03 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Tue, 24 Mar 2015 09:48:03 -0700 (PDT)
Subject: [R] Superimposing 2 curves on the same graph with par(new=TRUE)
In-Reply-To: <C14F8107-C322-46B5-A97D-D16650314C31@utoronto.ca>
References: <1221930182.1466416.1427126077785.JavaMail.yahoo@mail.yahoo.com>
	<alpine.LRH.2.11.1503230930210.19659@aeolus.ecy.wa.gov>
	<2B8BEE2D-7D8C-45D7-8040-59A079C35FB5@utoronto.ca>
	<alpine.LRH.2.11.1503231113050.19659@aeolus.ecy.wa.gov>
	<C14F8107-C322-46B5-A97D-D16650314C31@utoronto.ca>
Message-ID: <alpine.LRH.2.11.1503240946180.19659@aeolus.ecy.wa.gov>

Because the range is so different between the two series, I'd suggest 
using log="y", ylim=c(500,20000)


Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Mon, 23 Mar 2015, Boris Steipe wrote:

> ... and that gives you a "double ordinate plot", a staple of misleading statistics.
>
> Let me give you an analogy:
>
> Imagine you are on a chemistry mailing list and someone asks about the proper way to mix aluminum powder with fertilizer. Of course, as a chemist you know how. But still - and the same holds for the "double ordinate plot" - just say no.
>
>
> :-)
>
>
> For reference (taken from a post on SO):
> Junk charts:
>  http://junkcharts.typepad.com/junk_charts/2006/06/illusion_of_suc.html
>  http://junkcharts.typepad.com/junk_charts/2006/05/the_crossover_l.html
> Perecptual Edge ( a more detailed analysis)
>  http://www.perceptualedge.com/articles/visual_business_intelligence/dual-scaled_axes.pdf
> SMBC's tutorial on infographics (point 4).
>  http://www.smbc-comics.com/?id=3167
>
>
>
> On Mar 23, 2015, at 2:14 PM, Clint Bowman <clint at ecy.wa.gov> wrote:
>
>> Agreed--I neglected to add the secondary y-axis (shouldn't hit send so fast.)
>>
>> Clint Bowman			INTERNET:	clint at ecy.wa.gov
>> Air Quality Modeler		INTERNET:	clint at math.utah.edu
>> Department of Ecology		VOICE:		(360) 407-6815
>> PO Box 47600			FAX:		(360) 407-7534
>> Olympia, WA 98504-7600
>>
>>        USPS:           PO Box 47600, Olympia, WA 98504-7600
>>        Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>>
>> On Mon, 23 Mar 2015, Boris Steipe wrote:
>>
>>> ... which is exactly what he shouldn't do because now it the plot falsely asserts that both curves are plotted to the same scale.
>>>
>>>
>>> B.
>>>
>>>
>>>
>>> On Mar 23, 2015, at 12:34 PM, Clint Bowman <clint at ecy.wa.gov> wrote:
>>>
>>>> Try:
>>>> plot(Date,MORTSBu,lwd=2,lty="dashed",axes=F,xlab="",ylab="")
>>>>
>>>>
>>>>
>>>> Clint Bowman			INTERNET:	clint at ecy.wa.gov
>>>> Air Quality Modeler		INTERNET:	clint at math.utah.edu
>>>> Department of Ecology		VOICE:		(360) 407-6815
>>>> PO Box 47600			FAX:		(360) 407-7534
>>>> Olympia, WA 98504-7600
>>>>
>>>>       USPS:           PO Box 47600, Olympia, WA 98504-7600
>>>>       Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>>>>
>>>> On Mon, 23 Mar 2015, varin sacha wrote:
>>>>
>>>>> Dear R-Experts,
>>>>>
>>>>> I try to superimpose/present 2 curves/plots on the same graph. I would like the result/graph to be readable.
>>>>> For that, I use the par(new=TRUE) argument but on the Y-axis there is a superposition of writings and the Y-axis becomes unreadable.
>>>>> How can I solve this problem ?
>>>>>
>>>>> Here is a reproducible example :
>>>>> Date<-c(1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010)
>>>>>
>>>>> MORTSFr<-c(16445,17671,18113,17043,14738,14355,15028,14283,13229,13603,13672,13547,13527,13021,12737,11388,11947,10742,11497,11476,11215,10483,9900,9568,9019,8891,8541,8444,8918,8487,8079,8160,7655,6058,5593,5318,4709,4620,4275,4273,3992)
>>>>>
>>>>> MORTSBu<-c(838,889,934,946,960,1030,1021,1040,1153,1149,1199,1219,1229,1123,1119,1113,1070,1153,1153,1280,1567,1114,1299,1307,1390,1264,1014,915,1003,1047,1012,1011,959,960,943,957,1043,1006,1061,901,776)
>>>>>
>>>>> plot(Date,MORTSFr,type="l")
>>>>> par(new=TRUE)
>>>>>
>>>>> plot(Date,MORTSBu,lwd=2,lty="dashed")
>>>>>
>>>>> Thanks for your time.
>>>>> Best,
>>>>> S
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>
>


From jamone_95134 at yahoo.com  Tue Mar 24 07:36:09 2015
From: jamone_95134 at yahoo.com (Jam One)
Date: Tue, 24 Mar 2015 06:36:09 +0000 (UTC)
Subject: [R] ggplot2 Error : cannot allocate vector of size 1.9 Gb
Message-ID: <1930462168.310718.1427178969950.JavaMail.yahoo@mail.yahoo.com>

Dear All,
I have a showstopper here. I cannot run a library(UsingR) because I cannot load the package 'ggplot2'.
> sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] splines   grid      stats     graphics  grDevices utils     datasets  methods  
[9] base     

other attached packages:
[1] Formula_1.2-0   survival_2.38-1 lattice_0.20-29 HistData_0.7-5  MASS_7.3-40    

loaded via a namespace (and not attached):
[1] digest_0.6.6 gtable_0.1.2 tools_3.1.0 
> install.packages("ggplot2")
Installing package into ?C:/Users/xxxxxxx/Documents/R/win-library/3.1?
(as ?lib? is unspecified)
trying URL 'http://cran.rstudio.com/bin/windows/contrib/3.1/ggplot2_1.0.1.zip'
Content type 'application/zip' length 2675835 bytes (2.6 Mb)
opened URL
downloaded 2.6 Mb

package ?ggplot2? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\xxxxxxx\AppData\Local\Temp\RtmpSA08kR\downloaded_packages> memory.limit(4000)
[1] 4000
> library(UsingR)
Loading required package: Hmisc
Loading required package: ggplot2
Error : cannot allocate vector of size 1.9 Gb
In addition: Warning messages:
1: package ?UsingR? was built under R version 3.1.3 
2: package ?Hmisc? was built under R version 3.1.3 
3: package ?ggplot2? was built under R version 3.1.3 
Error: package ?ggplot2? could not be loaded

Can anyone suggest a solution to this problem, and NO switching to a 64-bit machine is not an option?

Thanks in advance.

	[[alternative HTML version deleted]]


From mialopezma at unal.edu.co  Mon Mar 23 21:13:37 2015
From: mialopezma at unal.edu.co (Miguel angel Lopez Martinez)
Date: Mon, 23 Mar 2015 15:13:37 -0500
Subject: [R] =?utf-8?q?Ayuda_con_un_=C3=A1rbol_de_regresi=C3=B3n?=
Message-ID: <CAOxN7gt5MzF0xewSys49KXdKsvecqew0zUWPO5mFgsWg7vh9gg@mail.gmail.com>

ARBOL<-tree(PRECIO~CILINDRAJE_DEL_MOTOR+MODELO,data=CARROST)
ARBOL
plot(ARBOL)
text(ARBOL,cex=0.9)

 este es el c?digo que utilizamos las variables cilindraje y modelo son
categ?ricas transformadas por que si utilizamos las varibales como factor
no las reconoce

	[[alternative HTML version deleted]]


From RLyons at m2s.com  Tue Mar 24 13:40:25 2015
From: RLyons at m2s.com (Robert Lyons)
Date: Tue, 24 Mar 2015 12:40:25 +0000
Subject: [R] reading in from xlsx files
Message-ID: <A7B0FD7A82E925459E733A0D8A8B7873057DF298@mailstore1.m2s.com>

I'm sorry if this is well below the level of this forum.
Using R Console v3.1.3 32-bit
Both of our R Programming sources left the company and I'm in need of some very basic help.
The code is reading in column and row information from two xlsx files.
I made what I thought were some basic changes to the contents of those files, one was a correction to a typo for a row, the other was flipping two columns that were in the wrong order.
When I Source the R Code neither change shows up in the output.

Thank you for your time.

Cordially,
Bob Lyons


________________________________
IMPORTANT NOTICE REGARDING THIS MESSAGE:
This message is intended for the use of the person(s) and/or entity(s) to whom it is addressed and may contain information that is privileged, confidential, and protected from disclosure under applicable law. If you are not the intended recipient, your use of this message for any purpose is strictly prohibited. If you have received this communication in error, please delete the message and notify the sender immediately.

	[[alternative HTML version deleted]]


From sayedurster at gmail.com  Tue Mar 24 06:43:50 2015
From: sayedurster at gmail.com (Sayedur Rahman)
Date: Tue, 24 Mar 2015 16:43:50 +1100
Subject: [R] Light response curve using non rectangular hypebola
Message-ID: <CAEdUYY2EV-nQJ8rcXfdGfYTWbLfgb+GANfuJjHqBMAJcZXrctA@mail.gmail.com>

Hi
I am a student trying to get Amax, thea,phi, and Rd from my light response
data.

I have 3 genotypes with 4 reps under 2 CO2 level. How do I solve the
equation using R. Any one can help me with writing script and solve thE
equation for non rectangular hyperbola

Thank you
Sayedur

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Tue Mar 24 18:56:21 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 24 Mar 2015 13:56:21 -0400
Subject: [R] reading in from xlsx files
In-Reply-To: <A7B0FD7A82E925459E733A0D8A8B7873057DF298@mailstore1.m2s.com>
References: <A7B0FD7A82E925459E733A0D8A8B7873057DF298@mailstore1.m2s.com>
Message-ID: <CAM_vju=QdwVQEXt35SQfUVgSh8zpviMCTJZfB55tENEMxv3Mug@mail.gmail.com>

Did you start in a clean R session?

What is your code? We can't telepathically diagnose code that's not
sent to the list.

Why not just change the data frames in R?

Please read the posting guide linked at the bottom of this message,
and provide enough information that we can reasonably help you. Basic
questions are fine, but we expect the querent to have done a bit of
work on their own, and to provide complete explanations.

Sarah

On Tue, Mar 24, 2015 at 8:40 AM, Robert Lyons <RLyons at m2s.com> wrote:
> I'm sorry if this is well below the level of this forum.
> Using R Console v3.1.3 32-bit
> Both of our R Programming sources left the company and I'm in need of some very basic help.
> The code is reading in column and row information from two xlsx files.
> I made what I thought were some basic changes to the contents of those files, one was a correction to a typo for a row, the other was flipping two columns that were in the wrong order.
> When I Source the R Code neither change shows up in the output.
>
> Thank you for your time.
>
> Cordially,
> Bob Lyons
>
>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee\
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Tue Mar 24 18:58:12 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 24 Mar 2015 13:58:12 -0400
Subject: [R] Light response curve using non rectangular hypebola
In-Reply-To: <CAEdUYY2EV-nQJ8rcXfdGfYTWbLfgb+GANfuJjHqBMAJcZXrctA@mail.gmail.com>
References: <CAEdUYY2EV-nQJ8rcXfdGfYTWbLfgb+GANfuJjHqBMAJcZXrctA@mail.gmail.com>
Message-ID: <CAM_vjunCO-5ctYfiCMjkRq45r_0H_3Opg2ZcthHj9Ls9WC9_eg@mail.gmail.com>

Hi,

Is this homework?

What have you tried? What worked, and what didn't?

What do your data look like?

You'll get much more help on this list if you read the posting guide
and provide reproducible examples, plus some evidence that you've
worked on the problem yourself.

Without a reproducible example that includes some sample data (fake is
fine), the code you used, and some clear idea of what output you
expect, it's impossible to figure out how to help you. Here are some
suggestions for creating a good reproducible example:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

The R-help posting guide may also be useful:
http://www.r-project.org/posting-guide.html

Sarah

On Tue, Mar 24, 2015 at 1:43 AM, Sayedur Rahman <sayedurster at gmail.com> wrote:
> Hi
> I am a student trying to get Amax, thea,phi, and Rd from my light response
> data.
>
> I have 3 genotypes with 4 reps under 2 CO2 level. How do I solve the
> equation using R. Any one can help me with writing script and solve thE
> equation for non rectangular hyperbola
>
> Thank you
> Sayedur
>
>         [[alternative HTML version deleted]]

Please post in plain text.

-- 
Sarah Goslee
http://www.functionaldiversity.org


From john.archie.mckown at gmail.com  Tue Mar 24 19:00:50 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 24 Mar 2015 13:00:50 -0500
Subject: [R] reading in from xlsx files
In-Reply-To: <A7B0FD7A82E925459E733A0D8A8B7873057DF298@mailstore1.m2s.com>
References: <A7B0FD7A82E925459E733A0D8A8B7873057DF298@mailstore1.m2s.com>
Message-ID: <CAAJSdjix6o+OZt3u+eXx6WO+gZyeU+yeznLPeLgs8FBdG2-q+Q@mail.gmail.com>

On Tue, Mar 24, 2015 at 7:40 AM, Robert Lyons <RLyons at m2s.com> wrote:
> I'm sorry if this is well below the level of this forum.
> Using R Console v3.1.3 32-bit
> Both of our R Programming sources left the company and I'm in need of some very basic help.
> The code is reading in column and row information from two xlsx files.
> I made what I thought were some basic changes to the contents of those files, one was a correction to a typo for a row, the other was flipping two columns that were in the wrong order.
> When I Source the R Code neither change shows up in the output.

Well, first of all, nobody can help you with code unless you actually
post the code in question. Hard to fix the car while you're driving
it. [grin]

Second, if you do post some code, you __REALLY__ need to disable
posting in HTML. HTML messages normally come across on this forum as
junk and most won't even try to read them.

I may be off base on the following and likely be corrected if I am.
But, unless the "fix" is simple, which from your post seems likely,
you might be better off hiring a contractor who is an R programmer.
Especially, as it appears in the case, that this is a for-profit
company. TANSTAAFL, although many will help if they are curious and
have time.

>
> Thank you for your time.
>
> Cordially,
> Bob Lyons
>



-- 
If you sent twitter messages while exploring, are you on a textpedition?

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown


From info at aghmed.fsnet.co.uk  Tue Mar 24 19:16:14 2015
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Tue, 24 Mar 2015 18:16:14 +0000
Subject: [R] =?utf-8?q?Ayuda_con_un_=C3=A1rbol_de_regresi=C3=B3n?=
In-Reply-To: <CAOxN7gt5MzF0xewSys49KXdKsvecqew0zUWPO5mFgsWg7vh9gg@mail.gmail.com>
References: <CAOxN7gt5MzF0xewSys49KXdKsvecqew0zUWPO5mFgsWg7vh9gg@mail.gmail.com>
Message-ID: <5511A9EE.1000706@aghmed.fsnet.co.uk>

Miguel, si prefieres escribir en espanol

https://stat.ethz.ch/mailman/listinfo/r-help-es

(This is the address of the Spanish language mailing list)

On 23/03/2015 20:13, Miguel angel Lopez Martinez wrote:
> ARBOL<-tree(PRECIO~CILINDRAJE_DEL_MOTOR+MODELO,data=CARROST)
> ARBOL
> plot(ARBOL)
> text(ARBOL,cex=0.9)
>
>   este es el c?digo que utilizamos las variables cilindraje y modelo son
> categ?ricas transformadas por que si utilizamos las varibales como factor
> no las reconoce
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5751 / Virus Database: 4315/9373 - Release Date: 03/24/15
>

-- 
Michael
http://www.dewey.myzen.co.uk


From panayiotis_geo at hotmail.com  Tue Mar 24 18:31:05 2015
From: panayiotis_geo at hotmail.com (Panayiotis Georgiades)
Date: Tue, 24 Mar 2015 19:31:05 +0200
Subject: [R] RSperl Problem
Message-ID: <DUB109-W19ECE0FB8491EBC9B8B1BFF20A0@phx.gbl>

Hi there, I have Perl version 5.14.2 and R installed on Ubuntu 12.04 and had a problem while trying to install RSPerl. I followed the instructions on the guide in omegahat.org, and ran the commandR CMD INSTALL  --configure-args='--with-in-perl' RSPerl
and the following error occured:* installing to library ?/usr/local/lib/R/site-library?
* installing *source* package ?RSPerl? ...
checking for perl... /usr/bin/perl
No support for any of the Perl modules from calling Perl from R.
*****************************************************

       Set PERL5LIB to /usr/local/lib/R/site-library/RSPerl/perl

*****************************************************
Testing: -L/usr/lib/R/lib -lR
Using '/usr/bin/perl' as the perl executable
Perl modules (no): 
Adding R package to list of Perl modules to enable callbacks to R from Perl
Creating the C code for dynamically loading modules with native code for Perl:  R
modules:   R; linking: 
checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables... 
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
Support R in Perl: yes
configure: creating ./config.status
config.status: creating src/Makevars
config.status: creating inst/scripts/RSPerl.csh
config.status: creating inst/scripts/RSPerl.bsh
config.status: creating src/RinPerlMakefile
config.status: creating src/Makefile.PL
config.status: creating cleanup
config.status: creating src/R.pm
config.status: creating R/perl5lib.R
making target all in RinPerlMakefile
gcc -std=gnu99 -I/usr/share/R/include -I.  -D_REENTRANT -D_GNU_SOURCE -DDEBIAN -fno-strict-aliasing -pipe -fstack-protector -I/usr/local/include -D_LARGEFILE_SOURCE -D_FILE_OFFSET_BITS=64  -I/usr/lib/perl/5.14/CORE  -DPERL_POLLUTE   -D_R_=1 -DUSE_R=1 -DUSE_TOPLEVEL_EXEC=1 -DWITH_R_IN_PERL=1     -fpic  -O3 -pipe  -g -c Converters.c -o Converters.o
Converters.c: In function 'fromPerl':
Converters.c:323:28: error: 'sv_undef' undeclared (first use in this function)
Converters.c:323:28: note: each undeclared identifier is reported only once for each function it appears in
Converters.c: In function 'toPerl':
Converters.c:483:12: error: 'sv_undef' undeclared (first use in this function)
Converters.c: In function 'PerlAddHomogeneousElement':
Converters.c:1056:7: error: duplicate case value
Converters.c:1041:7: error: previously used here
make: *** [Converters.o] Error 1
calling make -f Makefile.perl install
Makefile out-of-date with respect to Makefile.PL
Cleaning current config before rebuilding Makefile...
make -f Makefile.perl.old clean > /dev/null 2>&1
/usr/bin/perl Makefile.PL 
Warning: -L. changed to -L/home/panayiotis/Desktop/RSPerl/src/.
Note (probably harmless): No library found for -lPerlConverter
Writing Makefile.perl for R
Writing MYMETA.yml
==> Your Makefile has been rebuilt. <==
==> Please rerun the make command.  <==
false
make: *** [Makefile.perl] Error 1
chmod: changing permissions of `blib/lib/R.pm': Operation not permitted
Finished configuration
** libs
gcc -std=gnu99 -I/usr/share/R/include -I.  -D_REENTRANT -D_GNU_SOURCE -DDEBIAN -fno-strict-aliasing -pipe -fstack-protector -I/usr/local/include -D_LARGEFILE_SOURCE -D_FILE_OFFSET_BITS=64  -I/usr/lib/perl/5.14/CORE  -DPERL_POLLUTE   -D_R_=1 -DUSE_R=1 -DUSE_TOPLEVEL_EXEC=1 -DWITH_R_IN_PERL=1     -fpic  -O3 -pipe  -g -c Converters.c -o Converters.o
Converters.c: In function ?fromPerl?:
Converters.c:323:28: error: ?sv_undef? undeclared (first use in this function)
Converters.c:323:28: note: each undeclared identifier is reported only once for each function it appears in
Converters.c: In function ?toPerl?:
Converters.c:483:12: error: ?sv_undef? undeclared (first use in this function)
Converters.c: In function ?PerlAddHomogeneousElement?:
Converters.c:1056:7: error: duplicate case value
Converters.c:1041:7: error: previously used here
make: *** [Converters.o] Error 1
ERROR: compilation failed for package ?RSPerl?
* removing ?/usr/local/lib/R/site-library/RSPerl?
Do anyone knows how can I resolve this issue? 		 	   		  
	[[alternative HTML version deleted]]


From john.maindonald at anu.edu.au  Tue Mar 24 22:31:39 2015
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 24 Mar 2015 21:31:39 +0000
Subject: [R] the making of _R_ eBooks
In-Reply-To: <mailman.0.1427194801.26570.r-help@r-project.org>
References: <mailman.0.1427194801.26570.r-help@r-project.org>
Message-ID: <4BA6F5F9-0541-413A-B486-433AD7B4DABE@anu.edu.au>

Thanks for that.  Useful to have that question asked and to get that
information.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 25/03/2015, at 0:00, r-help-request at r-project.org<mailto:r-help-request at r-project.org> wrote:

From: John McKown <john.archie.mckown at gmail.com<mailto:john.archie.mckown at gmail.com>>
Subject: Re: [R] the making of _R_ eBooks
Date: 24 March 2015 1:36:38 NZDT
To: "Dr. Wolfgang Lindner" <lindnerw at t-online.de<mailto:lindnerw at t-online.de>>
Cc: Help R <r-help at r-project.org<mailto:r-help at r-project.org>>


On Mon, Mar 23, 2015 at 3:50 AM, Dr. Wolfgang Lindner
<lindnerw at t-online.de<mailto:lindnerw at t-online.de>> wrote:
Dear list members,

I like the look and feel of the eBook versions of the R manuals very much.
So I would like to generate eBooks (teaching material etc) in that look.

I am not an expert. But I have looked at the source, so I can give you
some information.


Q1: is there a description how the _R_ ebooks have been produced?

Looking at the source, it appears that the source manuals are in a
document markup language called "GNU Texinfo".
https://www.gnu.org/software/texinfo/
You can think of this as something akin to, but different from, HTML
or "markdown" encoding. Texinfo is an evolution by the system first
designed by Richard Stallman of MIT. He is the driving force behind
the GPL and most of the GNU software which forms the basis of the user
space commands for Linux and the *BSD operating systems. Texinfo is
then converted to TeX. TeX is the typesetting language designed by Dr.
Donald Knuth. TeX, nominally, is converted into a DVI printer control
language (DeVice Independent). But in the case of creating a PDF file,
there is a processor called "pdftex",
http://en.wikipedia.org/wiki/PdfTeX, which produces a PDF file as
output . A good site for TeX is https://tug.org/

Texinfo has the plus of also having processor which will convert it to
UNIX "man" (manual) pages and HTML web pages. So one "source" document
can generate three different types of output document file types.

Most people use a enhanced TeX called LaTeX instead of "plain TeX"
when using TeX. LaTeX can be read up on here:
http://www.latex-project.org/ A good TeX document processor is
TeXstudio at http://texstudio.sourceforge.net/ . I use this one myself
(which is not necessary a strong endorsement because I'm nobody
special).

I feel the need to warn you that TeX is very powerful and, at least to
me, quite difficult, with a fairly step learning curve. Which may be
why the R project uses Texinfo because it is quite a bit easier to
learn.


Q2: which (free) software was used for them?

See the links above. On Fedora Linux, I get the TeX oriented software
from a bunch of packages which start with "texlive". More information,
including the processors for Linux, Windows, and Mac are at
https://www.tug.org/texlive/

Q3: any other recommendations?

You might consider LyX.
http://www.lyx.org/
LyX is a document processor. It would likely be easier to use than the
above if you are used to MS Word or other word processing system. It
is cross platform: Linux, Windows, and Mac. It stores files in its own
textual format, which is somewhat human readable. LyX, like Texinfo,
translates its format into TeX as an intermediate on its way to its
ultimate destination. I am still learning LyX, but I personally like
it.

Your mention of LibreOffice is also a fairly good one. I, personally,
use LibreOffice. But I don't use it for big documents. I have a
learned aversion for word processors because it is so easy for them to
be misused. In my opinion, a good document needs good metadata in it
as well as just "looking pretty". Word processor users tend to focus
on the format and not the content. That's just my opinion, based on
what I've seen where I work.


Seaching the internet gives me e.g.
[1]
https://sites.google.com/site/richardbyrnepdsite/ebooks-and-audiobooks/create-your-own-ebooks
[2]  opensource.com/life/13/8/how-create-ebook-open-source-way<http://opensource.com/life/13/8/how-create-ebook-open-source-way>
[3] http://scottnesbitt.net/ubuntublog/creating-a-ebook-with-libreoffice-writer/

but I m not sure, if there are better possibilities..

Thanks for any hint or link by expert R users.

Oh, well, that excludes me. I'm not an expert. But maybe it was helpful anyway.


Wolfgang Lindner
Leichlingen, Germany

--
If you sent twitter messages while exploring, are you on a textpedition?

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown



	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Mar 24 22:44:08 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 24 Mar 2015 14:44:08 -0700
Subject: [R] ggplot2 Error : cannot allocate vector of size 1.9 Gb
In-Reply-To: <1930462168.310718.1427178969950.JavaMail.yahoo@mail.yahoo.com>
References: <1930462168.310718.1427178969950.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <4A7A4511-35D5-42A3-99EC-BAFDA509E5D2@dcn.davis.CA.us>

Upgrade your copy of R to the latest.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 23, 2015 11:36:09 PM PDT, Jam One <jamone_95134 at yahoo.com> wrote:
>Dear All,
>I have a showstopper here. I cannot run a library(UsingR) because I
>cannot load the package 'ggplot2'.
>> sessionInfo()
>R version 3.1.0 (2014-04-10)
>Platform: i386-w64-mingw32/i386 (32-bit)
>
>locale:
>[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>States.1252   
>[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                
>         
>[5] LC_TIME=English_United States.1252    
>
>attached base packages:
>[1] splines   grid      stats     graphics  grDevices utils    
>datasets  methods  
>[9] base     
>
>other attached packages:
>[1] Formula_1.2-0   survival_2.38-1 lattice_0.20-29 HistData_0.7-5 
>MASS_7.3-40    
>
>loaded via a namespace (and not attached):
>[1] digest_0.6.6 gtable_0.1.2 tools_3.1.0 
>> install.packages("ggplot2")
>Installing package into ?C:/Users/xxxxxxx/Documents/R/win-library/3.1?
>(as ?lib? is unspecified)
>trying URL
>'http://cran.rstudio.com/bin/windows/contrib/3.1/ggplot2_1.0.1.zip'
>Content type 'application/zip' length 2675835 bytes (2.6 Mb)
>opened URL
>downloaded 2.6 Mb
>
>package ?ggplot2? successfully unpacked and MD5 sums checked
>
>The downloaded binary packages are in
>	C:\Users\xxxxxxx\AppData\Local\Temp\RtmpSA08kR\downloaded_packages>
>memory.limit(4000)
>[1] 4000
>> library(UsingR)
>Loading required package: Hmisc
>Loading required package: ggplot2
>Error : cannot allocate vector of size 1.9 Gb
>In addition: Warning messages:
>1: package ?UsingR? was built under R version 3.1.3 
>2: package ?Hmisc? was built under R version 3.1.3 
>3: package ?ggplot2? was built under R version 3.1.3 
>Error: package ?ggplot2? could not be loaded
>
>Can anyone suggest a solution to this problem, and NO switching to a
>64-bit machine is not an option?
>
>Thanks in advance.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kp1005 at gmail.com  Wed Mar 25 00:38:21 2015
From: kp1005 at gmail.com (Kruti Pandya)
Date: Tue, 24 Mar 2015 16:38:21 -0700
Subject: [R] make elements of a list into functions
Message-ID: <CAORW=u6FS_sxa9XRDx-aw=JcYFuYVt0OMWgCGFZ6+OYuqEktvA@mail.gmail.com>

Hi I have a list called g as follows and I want to  make elements of g into
functions so that I can evaluate them at randomly generated data point say
c(0,0,0). For example,

change  g[[1]]  (!x[2] & !x[3]) | (!x[2] & x[3]) | (x[2] & x[3]) to
function(x) (!x[2] & !x[3]) | (!x[2] & x[3]) | (x[2] & x[3])

change g[[2]]  (!x[2] & !x[1]) | (!x[2] & x[1]) | (x[2] & !x[1]) to
function(x) (!x[2] & !x[1]) | (!x[2] & x[1]) | (x[2] & !x[1])

and so on......

So that I  can evaluate g[[1]] as follows g1<-function(x) (!x[2] & !x[3]) |
(!x[2] & x[3]) | (x[2] & x[3])

> g1(c(0,0,0))
[1] TRUE

g<-list(structure("(!x[2] & !x[3]) | (!x[2] & x[3]) | (x[2] & x[3])", class
= "noquote"),
        structure("(!x[2] & !x[1]) | (!x[2] & x[1]) | (x[2] & !x[1])",
class = "noquote"),
        structure("(!x[2] & x[3]) | (x[2] & !x[3])", class = "noquote"))

g
[[1]]
[1] (!x[2] & !x[3]) | (!x[2] & x[3]) | (x[2] & x[3])

[[2]]
[1] (!x[2] & !x[1]) | (!x[2] & x[1]) | (x[2] & !x[1])

[[3]]
[1] (!x[2] & x[3]) | (x[2] & !x[3])

Do not know how proceed. Any help is appreciated. I have created a small
example for demo. My actual list g has 50 elements so need a function which
can pick each element of g and convert it into function (x)......

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Wed Mar 25 01:20:36 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 25 Mar 2015 01:20:36 +0100
Subject: [R] make elements of a list into functions
In-Reply-To: <CAORW=u6FS_sxa9XRDx-aw=JcYFuYVt0OMWgCGFZ6+OYuqEktvA@mail.gmail.com>
References: <CAORW=u6FS_sxa9XRDx-aw=JcYFuYVt0OMWgCGFZ6+OYuqEktvA@mail.gmail.com>
Message-ID: <5511FF54.9020406@statistik.tu-dortmund.de>



On 25.03.2015 00:38, Kruti Pandya wrote:
> Hi I have a list called g as follows and I want to  make elements of g into
> functions so that I can evaluate them at randomly generated data point say
> c(0,0,0). For example,
>
> change  g[[1]]  (!x[2] & !x[3]) | (!x[2] & x[3]) | (x[2] & x[3]) to
> function(x) (!x[2] & !x[3]) | (!x[2] & x[3]) | (x[2] & x[3])
>
> change g[[2]]  (!x[2] & !x[1]) | (!x[2] & x[1]) | (x[2] & !x[1]) to
> function(x) (!x[2] & !x[1]) | (!x[2] & x[1]) | (x[2] & !x[1])
>
> and so on......
>
> So that I  can evaluate g[[1]] as follows g1<-function(x) (!x[2] & !x[3]) |
> (!x[2] & x[3]) | (x[2] & x[3])

One way:

f <- function(x) x
gfunc <- lapply(g, function(i) {body(f) <- parse(text=i); f})

So now you have functions in your list gfunc and can call them via

gfunc[[1]](c(0,0,0))


Best,
Uwe Ligges




>
>> g1(c(0,0,0))
> [1] TRUE
>
> g<-list(structure("(!x[2] & !x[3]) | (!x[2] & x[3]) | (x[2] & x[3])", class
> = "noquote"),
>          structure("(!x[2] & !x[1]) | (!x[2] & x[1]) | (x[2] & !x[1])",
> class = "noquote"),
>          structure("(!x[2] & x[3]) | (x[2] & !x[3])", class = "noquote"))
>
> g
> [[1]]
> [1] (!x[2] & !x[3]) | (!x[2] & x[3]) | (x[2] & x[3])
>
> [[2]]
> [1] (!x[2] & !x[1]) | (!x[2] & x[1]) | (x[2] & !x[1])
>
> [[3]]
> [1] (!x[2] & x[3]) | (x[2] & !x[3])
>
> Do not know how proceed. Any help is appreciated. I have created a small
> example for demo. My actual list g has 50 elements so need a function which
> can pick each element of g and convert it into function (x)......
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jamone_95134 at yahoo.com  Wed Mar 25 03:18:29 2015
From: jamone_95134 at yahoo.com (Jam One)
Date: Wed, 25 Mar 2015 02:18:29 +0000 (UTC)
Subject: [R] ggplot2 Error : cannot allocate vector of size 1.9 Gb
In-Reply-To: <4A7A4511-35D5-42A3-99EC-BAFDA509E5D2@dcn.davis.CA.us>
References: <4A7A4511-35D5-42A3-99EC-BAFDA509E5D2@dcn.davis.CA.us>
Message-ID: <1273263241.1186208.1427249909867.JavaMail.yahoo@mail.yahoo.com>

> sessionInfo()
R version 3.1.3 (2015-03-09)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252?? 
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C????????????????????????? 
[5] LC_TIME=English_United States.1252??? 

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods?? base???? 

loaded via a namespace (and not attached):
[1] digest_0.6.6 grid_3.1.3?? gtable_0.1.2 tools_3.1.3 

> library(ggplot2)Error : cannot allocate vector of size 1.9 Gb
In addition: Warning messages:
1: In get(Info[i, 1], envir = env) :
? Reached total allocation of 1535Mb: see help(memory.size)
2: In get(Info[i, 1], envir = env) :
? Reached total allocation of 1535Mb: see help(memory.size)
3: In get(Info[i, 1], envir = env) :
? Reached total allocation of 1535Mb: see help(memory.size)
4: In get(Info[i, 1], envir = env) :
? Reached total allocation of 1535Mb: see help(memory.size)
Error: package or namespace load failed for ?ggplot2?
> memory.size(4000)
[1] 4000
> library(ggplot2)
Error : cannot allocate vector of size 1.9 Gb
Error: package or namespace load failed for ?ggplot2?
Just curious, why did you think that solution would work?
      From: Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
 To: Jam One <jamone_95134 at yahoo.com>; "r-help at R-project.org" <r-help at r-project.org> 
 Sent: Wednesday, March 25, 2015 4:44 AM
 Subject: Re: [R] ggplot2 Error : cannot allocate vector of size 1.9 Gb
   
Upgrade your copy of R to the latest.
---------------------------------------------------------------------------
Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.




>Dear All,
>I have a showstopper here. I cannot run a library(UsingR) because I
>cannot load the package 'ggplot2'.
>> sessionInfo()
>R version 3.1.0 (2014-04-10)
>Platform: i386-w64-mingw32/i386 (32-bit)
>
>locale:
>[1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United
>States.1252? 
>[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C? ? ? ? ? ? ? ? 
>? ? ? ? 
>[5] LC_TIME=English_United States.1252? ? 
>
>attached base packages:
>[1] splines? grid? ? ? stats? ? graphics? grDevices utils? ? 
>datasets? methods? 
>[9] base? ? 
>
>other attached packages:
>[1] Formula_1.2-0? survival_2.38-1 lattice_0.20-29 HistData_0.7-5 
>MASS_7.3-40? ? 
>
>loaded via a namespace (and not attached):
>[1] digest_0.6.6 gtable_0.1.2 tools_3.1.0 
>> install.packages("ggplot2")
>Installing package into ?C:/Users/xxxxxxx/Documents/R/win-library/3.1?
>(as ?lib? is unspecified)
>trying URL
>'http://cran.rstudio.com/bin/windows/contrib/3.1/ggplot2_1.0.1.zip'
>Content type 'application/zip' length 2675835 bytes (2.6 Mb)
>opened URL
>downloaded 2.6 Mb
>
>package ?ggplot2? successfully unpacked and MD5 sums checked
>
>The downloaded binary packages are in
>??? C:\Users\xxxxxxx\AppData\Local\Temp\RtmpSA08kR\downloaded_packages>
>memory.limit(4000)
>[1] 4000
>> library(UsingR)
>Loading required package: Hmisc
>Loading required package: ggplot2
>Error : cannot allocate vector of size 1.9 Gb
>In addition: Warning messages:
>1: package ?UsingR? was built under R version 3.1.3 
>2: package ?Hmisc? was built under R version 3.1.3 
>3: package ?ggplot2? was built under R version 3.1.3 
>Error: package ?ggplot2? could not be loaded
>
>Can anyone suggest a solution to this problem, and NO switching to a
>64-bit machine is not an option?
>
>Thanks in advance.
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



  
	[[alternative HTML version deleted]]


From sackettl at colorado.edu  Tue Mar 24 23:40:11 2015
From: sackettl at colorado.edu (Loren)
Date: Tue, 24 Mar 2015 15:40:11 -0700 (PDT)
Subject: [R] facets work in qplot but facet_wrap produces an error in ggplot
Message-ID: <1427236811798-4705058.post@n4.nabble.com>

Hello all,

I am having a perplexing problem trying to use facet_wrap in ggplot, with
both my real dataset and a simplified dummy dataset.  I am trying to plot
heterozygosity across the genome for multiple individuals, with each
chromosome shown separately.

My dummy data:
chr1	123000	124000	2	0.00002	26	0.00026	indiv1
chr1	124000	125000	3	0.00003	12	0.00012	indiv1
chr1	125000	126000	1	0.00001	6	0.00006	indiv1
chr1	126000	126000	2	0.00002	14	0.00014	indiv1
chr2	123000	124000	6	0.00006	20	0.00020	indiv1
chr2	124000	125000	0	0.00000	12	0.00012	indiv1
chr1	123000	124000	2	0.00002	26	0.00026	indiv2
chr1	124000	125000	3	0.00003	12	0.00012	indiv2
chr1	125000	126000	1	0.00001	6	0.00006	indiv2
chr1	126000	126000	2	0.00002	14	0.00014	indiv2
chr2	123000	124000	6	0.00006	20	0.00020	indiv2
chr2	124000	125000	0	0.00000	12	0.00012	indiv2

My code to read in the data:
hetshoms <- read.table("fakedata.txt", header=F)

chrom <- hetshoms$V1
start.pos <- hetshoms$V2
end.pos <- hetshoms$V3
hets <- hetshoms$V4
het_stat <- hetshoms$V5
homs <- hetshoms$V6
hom_stat <- hetshoms$V7
indiv <- hetshoms$V8

HetRatio <- hets/(hets+homs)

When I try to plot the chromosomes separately in qplot, it works fine:
testplot <- qplot(start.pos, HetRatio, facets = chrom ~ ., colour=chrom)

But when I try an analogous thing in ggplot, it does not work.
The first part works fine:
testplot <- ggplot(hetshoms, aes(x=start.pos, y=HetRatio)) +
geom_point(aes(color=chrom, alpha=1/4)) 

but when I try to add the facet_wrap:
testplot + facet_wrap(~chrom)

This produces the following error (and no plot)
"Error en layout_base(data, vars, drop = drop) : 
  At least one layer must contain all variables used for facetting"

I have tried adding an (as.formula(paste)) and directly calling hetshoms$V1
but neither solves the problem.

Can anyone please point out where I have gone wrong and how to fix my code?  

Much appreciated,
Loren






--
View this message in context: http://r.789695.n4.nabble.com/facets-work-in-qplot-but-facet-wrap-produces-an-error-in-ggplot-tp4705058.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Wed Mar 25 03:44:37 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 24 Mar 2015 19:44:37 -0700
Subject: [R] ggplot2 Error : cannot allocate vector of size 1.9 Gb
In-Reply-To: <1273263241.1186208.1427249909867.JavaMail.yahoo@mail.yahoo.com>
References: <4A7A4511-35D5-42A3-99EC-BAFDA509E5D2@dcn.davis.CA.us>
	<1273263241.1186208.1427249909867.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <076F32AD-20B3-4BC5-8219-88B56869967A@dcn.davis.CA.us>

Because no package loads 1.9GB of data when you load it into memory, so this has to be a bug. The first thing to do when the software is acting buggy is to update to current.

Having done that, I think it is time to contact the maintainer (see ?maintainer).

For future reference, your posting is corrupted because you are posting using HTML format email rather than plain text as the Posting Guide tells you to.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 24, 2015 7:18:29 PM PDT, Jam One <jamone_95134 at yahoo.com> wrote:
>> sessionInfo()
>R version 3.1.3 (2015-03-09)
>Platform: i386-w64-mingw32/i386 (32-bit)
>Running under: Windows 7 (build 7601) Service Pack 1
>
>locale:
>[1] LC_COLLATE=English_United States.1252 
>[2] LC_CTYPE=English_United States.1252?? 
>[3] LC_MONETARY=English_United States.1252
>[4] LC_NUMERIC=C????????????????????????? 
>[5] LC_TIME=English_United States.1252??? 
>
>attached base packages:
>[1] stats???? graphics? grDevices utils???? datasets? methods??
>base???? 
>
>loaded via a namespace (and not attached):
>[1] digest_0.6.6 grid_3.1.3?? gtable_0.1.2 tools_3.1.3 
>
>> library(ggplot2)Error : cannot allocate vector of size 1.9 Gb
>In addition: Warning messages:
>1: In get(Info[i, 1], envir = env) :
>? Reached total allocation of 1535Mb: see help(memory.size)
>2: In get(Info[i, 1], envir = env) :
>? Reached total allocation of 1535Mb: see help(memory.size)
>3: In get(Info[i, 1], envir = env) :
>? Reached total allocation of 1535Mb: see help(memory.size)
>4: In get(Info[i, 1], envir = env) :
>? Reached total allocation of 1535Mb: see help(memory.size)
>Error: package or namespace load failed for ?ggplot2?
>> memory.size(4000)
>[1] 4000
>> library(ggplot2)
>Error : cannot allocate vector of size 1.9 Gb
>Error: package or namespace load failed for ?ggplot2?
>Just curious, why did you think that solution would work?
>      From: Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
>To: Jam One <jamone_95134 at yahoo.com>; "r-help at R-project.org"
><r-help at r-project.org> 
> Sent: Wednesday, March 25, 2015 4:44 AM
> Subject: Re: [R] ggplot2 Error : cannot allocate vector of size 1.9 Gb
>   
>Upgrade your copy of R to the latest.
>---------------------------------------------------------------------------
>Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live
>Go...
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
>Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
>/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.?
>rocks...1k
>---------------------------------------------------------------------------
>
>Sent from my phone. Please excuse my brevity.
>
>
>
>On March 23, 2015 11:36:09 PM PDT, Jam One <jamone_95134 at yahoo.com>
>wrote:
>>Dear All,
>>I have a showstopper here. I cannot run a library(UsingR) because I
>>cannot load the package 'ggplot2'.
>>> sessionInfo()
>>R version 3.1.0 (2014-04-10)
>>Platform: i386-w64-mingw32/i386 (32-bit)
>>
>>locale:
>>[1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United
>>States.1252? 
>>[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C? ? ? ? ? ? ? ?
>
>>? ? ? ? 
>>[5] LC_TIME=English_United States.1252? ? 
>>
>>attached base packages:
>>[1] splines? grid? ? ? stats? ? graphics? grDevices utils? ? 
>>datasets? methods? 
>>[9] base? ? 
>>
>>other attached packages:
>>[1] Formula_1.2-0? survival_2.38-1 lattice_0.20-29 HistData_0.7-5 
>>MASS_7.3-40? ? 
>>
>>loaded via a namespace (and not attached):
>>[1] digest_0.6.6 gtable_0.1.2 tools_3.1.0 
>>> install.packages("ggplot2")
>>Installing package into ?C:/Users/xxxxxxx/Documents/R/win-library/3.1?
>>(as ?lib? is unspecified)
>>trying URL
>>'http://cran.rstudio.com/bin/windows/contrib/3.1/ggplot2_1.0.1.zip'
>>Content type 'application/zip' length 2675835 bytes (2.6 Mb)
>>opened URL
>>downloaded 2.6 Mb
>>
>>package ?ggplot2? successfully unpacked and MD5 sums checked
>>
>>The downloaded binary packages are in
>>???
>C:\Users\xxxxxxx\AppData\Local\Temp\RtmpSA08kR\downloaded_packages>
>>memory.limit(4000)
>>[1] 4000
>>> library(UsingR)
>>Loading required package: Hmisc
>>Loading required package: ggplot2
>>Error : cannot allocate vector of size 1.9 Gb
>>In addition: Warning messages:
>>1: package ?UsingR? was built under R version 3.1.3 
>>2: package ?Hmisc? was built under R version 3.1.3 
>>3: package ?ggplot2? was built under R version 3.1.3 
>>Error: package ?ggplot2? could not be loaded
>>
>>Can anyone suggest a solution to this problem, and NO switching to a
>>64-bit machine is not an option?
>>
>>Thanks in advance.
>>
>>??? [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Mar 25 04:10:11 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 24 Mar 2015 20:10:11 -0700
Subject: [R] ggplot2 Error : cannot allocate vector of size 1.9 Gb
In-Reply-To: <076F32AD-20B3-4BC5-8219-88B56869967A@dcn.davis.CA.us>
References: <4A7A4511-35D5-42A3-99EC-BAFDA509E5D2@dcn.davis.CA.us>
	<1273263241.1186208.1427249909867.JavaMail.yahoo@mail.yahoo.com>
	<076F32AD-20B3-4BC5-8219-88B56869967A@dcn.davis.CA.us>
Message-ID: <EFE36232-D7D4-4DB8-AD3F-871E58A998A5@dcn.davis.CA.us>

Another thought... if you have a ".RData" file in your working directory, you might want to delete or rename it.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 24, 2015 7:44:37 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>Because no package loads 1.9GB of data when you load it into memory, so
>this has to be a bug. The first thing to do when the software is acting
>buggy is to update to current.
>
>Having done that, I think it is time to contact the maintainer (see
>?maintainer).
>
>For future reference, your posting is corrupted because you are posting
>using HTML format email rather than plain text as the Posting Guide
>tells you to.
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>---------------------------------------------------------------------------
>
>Sent from my phone. Please excuse my brevity.
>
>On March 24, 2015 7:18:29 PM PDT, Jam One <jamone_95134 at yahoo.com>
>wrote:
>>> sessionInfo()
>>R version 3.1.3 (2015-03-09)
>>Platform: i386-w64-mingw32/i386 (32-bit)
>>Running under: Windows 7 (build 7601) Service Pack 1
>>
>>locale:
>>[1] LC_COLLATE=English_United States.1252 
>>[2] LC_CTYPE=English_United States.1252?? 
>>[3] LC_MONETARY=English_United States.1252
>>[4] LC_NUMERIC=C????????????????????????? 
>>[5] LC_TIME=English_United States.1252??? 
>>
>>attached base packages:
>>[1] stats???? graphics? grDevices utils???? datasets? methods??
>>base???? 
>>
>>loaded via a namespace (and not attached):
>>[1] digest_0.6.6 grid_3.1.3?? gtable_0.1.2 tools_3.1.3 
>>
>>> library(ggplot2)Error : cannot allocate vector of size 1.9 Gb
>>In addition: Warning messages:
>>1: In get(Info[i, 1], envir = env) :
>>? Reached total allocation of 1535Mb: see help(memory.size)
>>2: In get(Info[i, 1], envir = env) :
>>? Reached total allocation of 1535Mb: see help(memory.size)
>>3: In get(Info[i, 1], envir = env) :
>>? Reached total allocation of 1535Mb: see help(memory.size)
>>4: In get(Info[i, 1], envir = env) :
>>? Reached total allocation of 1535Mb: see help(memory.size)
>>Error: package or namespace load failed for ?ggplot2?
>>> memory.size(4000)
>>[1] 4000
>>> library(ggplot2)
>>Error : cannot allocate vector of size 1.9 Gb
>>Error: package or namespace load failed for ?ggplot2?
>>Just curious, why did you think that solution would work?
>>      From: Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
>>To: Jam One <jamone_95134 at yahoo.com>; "r-help at R-project.org"
>><r-help at r-project.org> 
>> Sent: Wednesday, March 25, 2015 4:44 AM
>> Subject: Re: [R] ggplot2 Error : cannot allocate vector of size 1.9
>Gb
>>   
>>Upgrade your copy of R to the latest.
>>---------------------------------------------------------------------------
>>Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go
>>Live...
>>DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live
>>Go...
>>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..?
>Playing
>>Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
>>/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.?
>>rocks...1k
>>---------------------------------------------------------------------------
>>
>>Sent from my phone. Please excuse my brevity.
>>
>>
>>
>>On March 23, 2015 11:36:09 PM PDT, Jam One <jamone_95134 at yahoo.com>
>>wrote:
>>>Dear All,
>>>I have a showstopper here. I cannot run a library(UsingR) because I
>>>cannot load the package 'ggplot2'.
>>>> sessionInfo()
>>>R version 3.1.0 (2014-04-10)
>>>Platform: i386-w64-mingw32/i386 (32-bit)
>>>
>>>locale:
>>>[1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United
>>>States.1252? 
>>>[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C? ? ? ? ? ? ?
>?
>>
>>>? ? ? ? 
>>>[5] LC_TIME=English_United States.1252? ? 
>>>
>>>attached base packages:
>>>[1] splines? grid? ? ? stats? ? graphics? grDevices utils? ? 
>>>datasets? methods? 
>>>[9] base? ? 
>>>
>>>other attached packages:
>>>[1] Formula_1.2-0? survival_2.38-1 lattice_0.20-29 HistData_0.7-5 
>>>MASS_7.3-40? ? 
>>>
>>>loaded via a namespace (and not attached):
>>>[1] digest_0.6.6 gtable_0.1.2 tools_3.1.0 
>>>> install.packages("ggplot2")
>>>Installing package into
>?C:/Users/xxxxxxx/Documents/R/win-library/3.1?
>>>(as ?lib? is unspecified)
>>>trying URL
>>>'http://cran.rstudio.com/bin/windows/contrib/3.1/ggplot2_1.0.1.zip'
>>>Content type 'application/zip' length 2675835 bytes (2.6 Mb)
>>>opened URL
>>>downloaded 2.6 Mb
>>>
>>>package ?ggplot2? successfully unpacked and MD5 sums checked
>>>
>>>The downloaded binary packages are in
>>>???
>>C:\Users\xxxxxxx\AppData\Local\Temp\RtmpSA08kR\downloaded_packages>
>>>memory.limit(4000)
>>>[1] 4000
>>>> library(UsingR)
>>>Loading required package: Hmisc
>>>Loading required package: ggplot2
>>>Error : cannot allocate vector of size 1.9 Gb
>>>In addition: Warning messages:
>>>1: package ?UsingR? was built under R version 3.1.3 
>>>2: package ?Hmisc? was built under R version 3.1.3 
>>>3: package ?ggplot2? was built under R version 3.1.3 
>>>Error: package ?ggplot2? could not be loaded
>>>
>>>Can anyone suggest a solution to this problem, and NO switching to a
>>>64-bit machine is not an option?
>>>
>>>Thanks in advance.
>>>
>>>??? [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Mar 25 04:11:01 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 25 Mar 2015 14:11:01 +1100
Subject: [R] reading in from xlsx files
In-Reply-To: <CAAJSdjix6o+OZt3u+eXx6WO+gZyeU+yeznLPeLgs8FBdG2-q+Q@mail.gmail.com>
References: <A7B0FD7A82E925459E733A0D8A8B7873057DF298@mailstore1.m2s.com>
	<CAAJSdjix6o+OZt3u+eXx6WO+gZyeU+yeznLPeLgs8FBdG2-q+Q@mail.gmail.com>
Message-ID: <CA+8X3fU09MED_Q8rqYLyTr62yVLaDj=Q4OA0UHc9+LcvRynhFA@mail.gmail.com>

Hi Bob,
Most likely you didn't save the resulting Excel file before sourcing the R
code. I would close Excel (which given the time elapsed since your message
you probably have done) and open the XSLX file again. If the changes are
there in Excel, they should show up when you run the R code (using the xlsx
package, we assume?)

Although Sarah's answer may be more sensible.

Jim


On Wed, Mar 25, 2015 at 5:00 AM, John McKown <john.archie.mckown at gmail.com>
wrote:

> On Tue, Mar 24, 2015 at 7:40 AM, Robert Lyons <RLyons at m2s.com> wrote:
> > I'm sorry if this is well below the level of this forum.
> > Using R Console v3.1.3 32-bit
> > Both of our R Programming sources left the company and I'm in need of
> some very basic help.
> > The code is reading in column and row information from two xlsx files.
> > I made what I thought were some basic changes to the contents of those
> files, one was a correction to a typo for a row, the other was flipping two
> columns that were in the wrong order.
> > When I Source the R Code neither change shows up in the output.
>
> Well, first of all, nobody can help you with code unless you actually
> post the code in question. Hard to fix the car while you're driving
> it. [grin]
>
> Second, if you do post some code, you __REALLY__ need to disable
> posting in HTML. HTML messages normally come across on this forum as
> junk and most won't even try to read them.
>
> I may be off base on the following and likely be corrected if I am.
> But, unless the "fix" is simple, which from your post seems likely,
> you might be better off hiring a contractor who is an R programmer.
> Especially, as it appears in the case, that this is a for-profit
> company. TANSTAAFL, although many will help if they are curious and
> have time.
>
> >
> > Thank you for your time.
> >
> > Cordially,
> > Bob Lyons
> >
>
>
>
> --
> If you sent twitter messages while exploring, are you on a textpedition?
>
> He's about as useful as a wax frying pan.
>
> 10 to the 12th power microphones = 1 Megaphone
>
> Maranatha! <><
> John McKown
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Mar 25 04:19:21 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 24 Mar 2015 20:19:21 -0700
Subject: [R] facets work in qplot but facet_wrap produces an error in
	ggplot
In-Reply-To: <1427236811798-4705058.post@n4.nabble.com>
References: <1427236811798-4705058.post@n4.nabble.com>
Message-ID: <8D4B6E58-8E87-4D26-A3BD-C4671F063F73@dcn.davis.CA.us>

You MUST put all data you plan to refer to into a data frame when using ggplot. There are a couple of ways you could do this... the easiest is to put a header line in the data file with column names. Or, you can assign a vector of new names to the names of the data frame.

names( hetshoms ) <- c( "chrom", "start.pos", "end.pos", "hets", "het_stat", "homs", "hom_stat", "indiv" )
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 24, 2015 3:40:11 PM PDT, Loren <sackettl at colorado.edu> wrote:
>Hello all,
>
>I am having a perplexing problem trying to use facet_wrap in ggplot,
>with
>both my real dataset and a simplified dummy dataset.  I am trying to
>plot
>heterozygosity across the genome for multiple individuals, with each
>chromosome shown separately.
>
>My dummy data:
>chr1	123000	124000	2	0.00002	26	0.00026	indiv1
>chr1	124000	125000	3	0.00003	12	0.00012	indiv1
>chr1	125000	126000	1	0.00001	6	0.00006	indiv1
>chr1	126000	126000	2	0.00002	14	0.00014	indiv1
>chr2	123000	124000	6	0.00006	20	0.00020	indiv1
>chr2	124000	125000	0	0.00000	12	0.00012	indiv1
>chr1	123000	124000	2	0.00002	26	0.00026	indiv2
>chr1	124000	125000	3	0.00003	12	0.00012	indiv2
>chr1	125000	126000	1	0.00001	6	0.00006	indiv2
>chr1	126000	126000	2	0.00002	14	0.00014	indiv2
>chr2	123000	124000	6	0.00006	20	0.00020	indiv2
>chr2	124000	125000	0	0.00000	12	0.00012	indiv2
>
>My code to read in the data:
>hetshoms <- read.table("fakedata.txt", header=F)
>
>chrom <- hetshoms$V1
>start.pos <- hetshoms$V2
>end.pos <- hetshoms$V3
>hets <- hetshoms$V4
>het_stat <- hetshoms$V5
>homs <- hetshoms$V6
>hom_stat <- hetshoms$V7
>indiv <- hetshoms$V8
>
>HetRatio <- hets/(hets+homs)
>
>When I try to plot the chromosomes separately in qplot, it works fine:
>testplot <- qplot(start.pos, HetRatio, facets = chrom ~ .,
>colour=chrom)
>
>But when I try an analogous thing in ggplot, it does not work.
>The first part works fine:
>testplot <- ggplot(hetshoms, aes(x=start.pos, y=HetRatio)) +
>geom_point(aes(color=chrom, alpha=1/4)) 
>
>but when I try to add the facet_wrap:
>testplot + facet_wrap(~chrom)
>
>This produces the following error (and no plot)
>"Error en layout_base(data, vars, drop = drop) : 
>  At least one layer must contain all variables used for facetting"
>
>I have tried adding an (as.formula(paste)) and directly calling
>hetshoms$V1
>but neither solves the problem.
>
>Can anyone please point out where I have gone wrong and how to fix my
>code?  
>
>Much appreciated,
>Loren
>
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/facets-work-in-qplot-but-facet-wrap-produces-an-error-in-ggplot-tp4705058.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lkhodakarim at gmail.com  Wed Mar 25 09:29:34 2015
From: lkhodakarim at gmail.com (Soheila Khodakarim)
Date: Wed, 25 Mar 2015 11:59:34 +0330
Subject: [R] Fwd: missing in neural network
In-Reply-To: <CACYT75tKTLvPy19NaeQTpc8FxmvxPO62kR2j8ywGcX9sK7cJ3Q@mail.gmail.com>
References: <CACYT75uwxC-BeLkXtjM_QPQoHZq7Mzb6ZKdSjr3NY13Nj70-Pw@mail.gmail.com>
	<CAOLJphnZt6QCdztLfop+y=+cd9FzQWJDB1opi4d2ArVbTSVFMw@mail.gmail.com>
	<CACYT75vyzxYiyWmKNPG6tJQrLdSvEF+=eX-7cwaXMd5yeX4fyw@mail.gmail.com>
	<CACYT75vON_g_L0bN_Ta6diYDXTmdFKDs_4M5cuLM7q6jEy=WgA@mail.gmail.com>
	<CAOLJphkfZKVo++efjOmG_rDRb38dDh_dBiW8nzExyDVOmQx=ag@mail.gmail.com>
	<CACYT75tKTLvPy19NaeQTpc8FxmvxPO62kR2j8ywGcX9sK7cJ3Q@mail.gmail.com>
Message-ID: <CACYT75sg4Y8aH5efprNJmTpQb_MdVFqJRffWcVEXr_VDXJFLhw@mail.gmail.com>

Dear Charles,

I rewrote code :
library("neuralnet")
resp<-c(1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1))
mydata <- cbind(data24_2, resp)
dim(mydata)
 >  20 3111
fm <- as.formula(paste("resp ~ ", paste(colnames(mydata)[,1:3110],
collapse="+")))
> Error in colnames(mydata)[, 1:3110] : incorrect number of dimensions
:(((

AND

fm <- as.formula(paste(colnames(mydata)[,3111],
paste(colnames(mydata)[,1:3110], collapse="+")))
> Error in colnames(mydata)[, 3111] : incorrect number of dimensions

Best,
Soheila

On Wed, Mar 25, 2015 at 11:12 AM, Soheila Khodakarim <lkhodakarim at gmail.com>
wrote:

> Hi Charles,
> Many thanks for your help. I will check and let you know.
>
> Best Wishes,
> Soheila
> On Mar 25, 2015 12:17 AM, "Charles Determan Jr" <deter088 at umn.edu> wrote:
>
>> Soheila,
>>
>> Did my second response help you?  It is polite to close say if so, that
>> way others who come across the problem no that it was solved.  If not, feel
>> free to update your question.
>>
>> Regards,
>> Charles
>>
>> On Tue, Mar 24, 2015 at 9:58 AM, Soheila Khodakarim <
>> lkhodakarim at gmail.com> wrote:
>>
>>> Dear Charles,
>>>
>>> Thanks for your guide.
>>> I run this code:
>>>
>>> library("neuralnet")
>>> resp<-c(1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1)
>>> mydata <- cbind(data, resp)
>>> out1 <- neuralnet(resp~mydata[,1:3110],data=mydata, hidden = 4, lifesign
>>> =
>>> "minimal", linear.output = FALSE, threshold = 0.1)
>>>
>>> I saw this error
>>>
>>> Error in neurons[[i]] %*% weights[[i]] : non-conformable arguments
>>>
>>> :(:(:(
>>>
>>> What should I do now??
>>>
>>> Regards,
>>> Soheila
>>>
>>>
>>> On Tue, Mar 24, 2015 at 3:48 PM, Charles Determan Jr <deter088 at umn.edu>
>>> wrote:
>>>
>>> > Hi Soheila,
>>> >
>>> > You are using the formula argument incorrectly.  The neuralnet function
>>> > has a separate argument for data aptly names 'data'.  You can review
>>> the
>>> > arguments by looking at the documentation  with ?neuralnet.
>>> >
>>> > As I cannot reproduce your data the following is not tested but I think
>>> > should work for you.
>>> >
>>> > # Join your response variable to your data set.
>>> > mydata <- cbind(data, resp)
>>> >
>>> > # Run neuralnet
>>> > out <- neuralnet(resp ~ ., data=mydata, hidden = 4, lifesign =
>>> "minimal",
>>> >                        linear.output = FALSE, threshold = 0.1,na.rm =
>>> > TRUE)
>>> >
>>> >
>>> > Best,
>>> > Charles
>>> >
>>> > On Tue, Mar 24, 2015 at 4:47 AM, Soheila Khodakarim <
>>> lkhodakarim at gmail.com
>>> > > wrote:
>>> >
>>> >> Dear All,
>>> >>
>>> >> I want to run "neural network" on my dataset.
>>> >> ##########################################################
>>> >> resp<-c(1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1)
>>> >> dim(data)
>>> >> #20*3110
>>> >>
>>> >> out <- neuralnet(y ~ data, hidden = 4, lifesign = "minimal",
>>> linear.output
>>> >> = FALSE, threshold = 0.1,na.rm = TRUE)
>>> >> ################################################################
>>> >> but I see this Error
>>> >> Error in varify.variables(data, formula, startweights,
>>> learningrate.limit,
>>> >>  :
>>> >>   argument "data" is missing, with no default
>>> >>
>>> >> What should I do now??
>>> >>
>>> >> Best Regards,
>>> >> Soheila
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >
>>> >
>>> >
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>

	[[alternative HTML version deleted]]


From p_connolly at slingshot.co.nz  Wed Mar 25 09:40:41 2015
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Wed, 25 Mar 2015 21:40:41 +1300
Subject: [R] Why can't I access this type?
In-Reply-To: <28E315E85F1.00000296jrkrideau@inbox.com>
References: <CAJ=2b04qLmoA8W--=dsv2vqMHkG1Y7Tv_QQx_9D78oopJku+Yg@mail.gmail.com>
	<28E315E85F1.00000296jrkrideau@inbox.com>
Message-ID: <20150325084041.GA2875@slingshot.co.nz>

On Sun, 22-Mar-2015 at 08:06AM -0800, John Kane wrote:

|> Well, first off, you have no variable called "Name".  You have lost
|> the state names as they are rownames in the matrix state.x77 and
|> not a variable.
|> 
|> Try this. It's ugly and I have no idea why I had to do a cbind()

You don't have to use cbind

|> but it seems to work. Personally I find subset easier to read than
|> the indexing approach.

|> state  <-  rownames(state.x77)
|> all.states <- as.data.frame(state.x77)
|> all.states  <-  cbind(state, all.states) ### ?????

You don't have to use cbind()

all.states  <- within(as.data.frame(state.x77), state <- rownames(state.x77))

but I think cbind is simpler to read.

|> 
|> coldstates  <-   subset(all.states, all.states$Frost > 50, 
|>                         select = c("state","Frost") )

Tidier, even more so than subset():

require(dplyr)
coldstates <- all.states %>% filter(Frost > 150) %>% select(state, Frost)

Or, easier to see what's happening:

coldstates <- all.states %>% 
  filter(Frost > 150) %>% 
  select(state, Frost)


|> 
|> 
|> John Kane
|> Kingston ON Canada
|> 
|> 
|> > -----Original Message-----
|> > From: yoursurrogategod at gmail.com
|> > Sent: Sun, 22 Mar 2015 10:39:03 -0400
|> > To: r-help at r-project.org
|> > Subject: [R] Why can't I access this type?
|> > 
|> > Hi, I'm just learning my way around R.  I got a bunch of states and would
|> > like to access to get all of the ones where it's cold.  But when I do the
|> > following, I will get the following error:
|> > 
|> >> all.states <- as.data.frame(state.x77)
|> >> cold.states <- all.states[all.states$Frost > 150, c("Name", "Frost")]
|> > Error in `[.data.frame`(all.states, all.states$Frost > 150, c("Name",  :
|> >   undefined columns selected
|> > 
|> > I don't get it.  When I look at all.states, this is what I see:
|> > 
|> >> str(all.states)
|> > 'data.frame':   50 obs. of  8 variables:
|> >  $ Population: num  3615 365 2212 2110 21198 ...
|> >  $ Income    : num  3624 6315 4530 3378 5114 ...
|> >  $ Illiteracy: num  2.1 1.5 1.8 1.9 1.1 0.7 1.1 0.9 1.3 2 ...
|> >  $ Life Exp  : num  69 69.3 70.5 70.7 71.7 ...
|> >  $ Murder    : num  15.1 11.3 7.8 10.1 10.3 6.8 3.1 6.2 10.7 13.9 ...
|> >  $ HS Grad   : num  41.3 66.7 58.1 39.9 62.6 63.9 56 54.6 52.6 40.6 ...
|> >  $ Frost     : num  20 152 15 65 20 166 139 103 11 60 ...
|> >  $ Area      : num  50708 566432 113417 51945 156361 ...
|> > 
|> > What am I messing up?
|> > 
|> > 	[[alternative HTML version deleted]]
|> > 
|> > ______________________________________________
|> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> > https://stat.ethz.ch/mailman/listinfo/r-help
|> > PLEASE do read the posting guide
|> > http://www.R-project.org/posting-guide.html
|> > and provide commented, minimal, self-contained, reproducible code.
|> 
|> ____________________________________________________________
|> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
|> Visit http://www.inbox.com/photosharing to find out more!
|> 
|> ______________________________________________
|> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> https://stat.ethz.ch/mailman/listinfo/r-help
|> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From Lluis.Hurtado at uv.es  Wed Mar 25 12:55:00 2015
From: Lluis.Hurtado at uv.es (Lluis.Hurtado at uv.es)
Date: Wed, 25 Mar 2015 12:55:00 +0100 (CET)
Subject: [R] Fast evaluation of functions in 3D domains
In-Reply-To: <36EBCEEB-EBEE-4883-9DAF-50FE66BF1E2B@comcast.net>
References: <36EBCEEB-EBEE-4883-9DAF-50FE66BF1E2B@comcast.net>
Message-ID: <8587793882hurgil@uv.es>

Dear all,

Finally I have tried three different options to integrate a function in a 3D volume. Here 
I show a test example. The volume is the box [0,100] x [0,100] x [0,100] and the 
function is

nfw(d) = 4/((d/5)*(1+(d/5))^2)

where d is the distance between each point in the box to the point (50,50,40).

1-Grid of thick 1 in R (10^6 points)

> model <- function(x) 
{
   d <- sqrt((x[,1]-50)^2 + (x[,2]-50)^2 + (x[,3]-40)^2)
   r <- 4.0/((d/5)*(1+(d/5))^2)
   r
} 
> sum(model(x))
[1] 10287.52
> system.time(sum(model(x)))
   user  system elapsed 
  0.052   0.003   0.053 

2-Grid with thick 1 in C++ calling from R. Function model_cpp is a function written in 
C++ reproducing model function as above. (10^6 points)

>model <- function(x)
  {
  	param <- c(50,50,40,5)
  	.Call('model_cpp',x[,1],x[,2],x[,3],param)
  }
>  sum(model(x))
[1] 10287.52
> system.time(sum(model(x)))
   user  system elapsed 
  0.028   0.000   0.028 

3-cubature. Mr Tom Jagger kindly proposed to use cubature package:
http://cran.r-project.org/web/packages/cubature/cubature.pdf

>model <- function(x) 
+  {
+     d <- sqrt((x[1]-50)^2 + (x[2]-50)^2 + (x[3]-40)^2)
+     r <- 4.0/((d/5)*(1+(d/5))^2)
+     r
+   }
> adaptIntegrate(model, rep(0,3), rep(100,3), tol=1e-4)
$integral
[1] 10303.16

$error
[1] 1.029888

$functionEvaluations
[1] 48609

$returnCode
[1] 0

> system.time(adaptIntegrate(model, rep(0,3), rep(100,3), tol=1e-4))
   user  system elapsed 
  0.232   0.002   0.246

As you can see the second option is the fastest, but the third one is probably more 
accurate. 

The function nfw(d) has an analytical primitive when integrated in a sphere If now we 
reproduce the calculations for cases 1 and 2 in a sphere (named R) of radius 40 
centered in (50,50,40), the first two methods give me the following result:

sum(model(R))
[1] 8204.711

while the exact solution is

> 16*pi*(5^3)*(log(5+40) - log(5) - 40/(40+5))
[1] 8220.516

However, I can not try the same with cubature since the code is prepared only to be 
used in hypercubes.

As I am using non integrable functions I could try to increase the density of the grid 
and see if I can obtain accurate results before reaching high time costs or study how 
important is to reach that accuracy, it may be not that important for my algorithm. 

Anyway, thank you all for you time and ideas.

Llu?s Hurtado
IFCA

> 
> On Mar 23, 2015, at 3:44 AM, <Lluis.Hurtado at uv.es> <Lluis.Hurtado at uv.es> wrote:
> 
> > Dear all,
> > 
> > I am currently working with the spatstat package with 3D samples. I am trying to 
> > evaluate a non analytical function over the window that encloses the sample and I 
> > need to know which is the fastest way of doing it.
> > 
> > The function input is a 3 coordinate position in the window (x,y,z) and a list of 
> > parameters (a,b,c). The output is a numerical value. 
> > 
> > n <- function(x,y,z,a,b,c)
> 
> Perhaps:
> 
> dfrm <- as.data.frame.table(your_volume_matrix) 
> n.out <- with(dfrm,  mapply( n, x=x, y=y, z=z, MoreArgs=list(a=a,b=b,c=c) ) _
> dim(n.out) <- dim(your_volume_matrix)
> 
> You don't describe the form of this "3 coordinate position in the window (x,y,z)" so 
perhaps the arguments will need to be extracted. I took a WAG at one approach. If 
it's not in long-form, you need configure the array indices for either a volume or 
surface into a dataframe, perhaps with `expand.grid` or `as.data.frame.table`.
> 
>  You also don't describe the sort of integration you imagine. Why not a simple sum 
of that result divided by the volume? I cannot imagine any faster procedure .
> 
> 
> > But I need to do it over the whole volume.
> > 
> > For 2 dimensions it can be done with
> > 
> > A <- as.im(function,window,parameters)
> > norm <- integral.im(A)
> > 
> > For 3 dimensions I have tried to pass an array of a grid covering the window (like 
a 
> > quadrature scheme) and then summing up the output array, but I would like to 
know if 
> > there is any faster way of integrating the function.
> > 
> > Thank you very much,
> > 
> > Llu?s Hurtado
> > IFCA
> > www.ifca.unican.es
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guidehtml
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 


--
Llu?s Hurtado-Gil
Observatori Astron?mic. Universitat de Val?ncia.
Edifici Instituts d'Investigaci?. Parc Cient?fic.
C/ Catedr?tico Agust?n Escardino n?7
Campus Burjassot-Paterna
46980 Paterna Val?ncia (Spain).


From murdoch.duncan at gmail.com  Wed Mar 25 13:18:11 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 25 Mar 2015 08:18:11 -0400
Subject: [R] Fast evaluation of functions in 3D domains
In-Reply-To: <8587793882hurgil@uv.es>
References: <36EBCEEB-EBEE-4883-9DAF-50FE66BF1E2B@comcast.net>
	<8587793882hurgil@uv.es>
Message-ID: <5512A783.1030302@gmail.com>

On 25/03/2015 7:55 AM, Lluis.Hurtado at uv.es wrote:
> Dear all,
> 
> Finally I have tried three different options to integrate a function in a 3D volume. Here 
> I show a test example. The volume is the box [0,100] x [0,100] x [0,100] and the 
> function is
> 
> nfw(d) = 4/((d/5)*(1+(d/5))^2)
> 
> where d is the distance between each point in the box to the point (50,50,40).
> 
> 1-Grid of thick 1 in R (10^6 points)
> 
>> model <- function(x) 
> {
>    d <- sqrt((x[,1]-50)^2 + (x[,2]-50)^2 + (x[,3]-40)^2)
>    r <- 4.0/((d/5)*(1+(d/5))^2)
>    r
> } 
>> sum(model(x))
> [1] 10287.52
>> system.time(sum(model(x)))
>    user  system elapsed 
>   0.052   0.003   0.053 
> 
> 2-Grid with thick 1 in C++ calling from R. Function model_cpp is a function written in 
> C++ reproducing model function as above. (10^6 points)
> 
>> model <- function(x)
>   {
>   	param <- c(50,50,40,5)
>   	.Call('model_cpp',x[,1],x[,2],x[,3],param)
>   }
>>  sum(model(x))
> [1] 10287.52
>> system.time(sum(model(x)))
>    user  system elapsed 
>   0.028   0.000   0.028 
> 
> 3-cubature. Mr Tom Jagger kindly proposed to use cubature package:
> http://cran.r-project.org/web/packages/cubature/cubature.pdf
> 
>> model <- function(x) 
> +  {
> +     d <- sqrt((x[1]-50)^2 + (x[2]-50)^2 + (x[3]-40)^2)
> +     r <- 4.0/((d/5)*(1+(d/5))^2)
> +     r
> +   }
>> adaptIntegrate(model, rep(0,3), rep(100,3), tol=1e-4)
> $integral
> [1] 10303.16
> 
> $error
> [1] 1.029888
> 
> $functionEvaluations
> [1] 48609
> 
> $returnCode
> [1] 0
> 
>> system.time(adaptIntegrate(model, rep(0,3), rep(100,3), tol=1e-4))
>    user  system elapsed 
>   0.232   0.002   0.246
> 
> As you can see the second option is the fastest, but the third one is probably more 
> accurate. 
> 
> The function nfw(d) has an analytical primitive when integrated in a sphere If now we 
> reproduce the calculations for cases 1 and 2 in a sphere (named R) of radius 40 
> centered in (50,50,40), the first two methods give me the following result:
> 
> sum(model(R))
> [1] 8204.711
> 
> while the exact solution is
> 
>> 16*pi*(5^3)*(log(5+40) - log(5) - 40/(40+5))
> [1] 8220.516
> 
> However, I can not try the same with cubature since the code is prepared only to be 
> used in hypercubes.

I don't know how well the cubature package would deal with the
discontinuity, but a simple way to integrate over a sphere would be to
set the function value to zero outside of it.  Just change

r <- 4.0/((d/5)*(1+(d/5))^2)

to

r <- ifelse(d < 40, 4.0/((d/5)*(1+(d/5))^2), 0)

Duncan Murdoch

> 
> As I am using non integrable functions I could try to increase the density of the grid 
> and see if I can obtain accurate results before reaching high time costs or study how 
> important is to reach that accuracy, it may be not that important for my algorithm. 
> 
> Anyway, thank you all for you time and ideas.
> 
> Llu?s Hurtado
> IFCA
> 
>>
>> On Mar 23, 2015, at 3:44 AM, <Lluis.Hurtado at uv.es> <Lluis.Hurtado at uv.es> wrote:
>>
>>> Dear all,
>>>
>>> I am currently working with the spatstat package with 3D samples. I am trying to 
>>> evaluate a non analytical function over the window that encloses the sample and I 
>>> need to know which is the fastest way of doing it.
>>>
>>> The function input is a 3 coordinate position in the window (x,y,z) and a list of 
>>> parameters (a,b,c). The output is a numerical value. 
>>>
>>> n <- function(x,y,z,a,b,c)
>>
>> Perhaps:
>>
>> dfrm <- as.data.frame.table(your_volume_matrix) 
>> n.out <- with(dfrm,  mapply( n, x=x, y=y, z=z, MoreArgs=list(a=a,b=b,c=c) ) _
>> dim(n.out) <- dim(your_volume_matrix)
>>
>> You don't describe the form of this "3 coordinate position in the window (x,y,z)" so 
> perhaps the arguments will need to be extracted. I took a WAG at one approach. If 
> it's not in long-form, you need configure the array indices for either a volume or 
> surface into a dataframe, perhaps with `expand.grid` or `as.data.frame.table`.
>>
>>  You also don't describe the sort of integration you imagine. Why not a simple sum 
> of that result divided by the volume? I cannot imagine any faster procedure .
>>
>>
>>> But I need to do it over the whole volume.
>>>
>>> For 2 dimensions it can be done with
>>>
>>> A <- as.im(function,window,parameters)
>>> norm <- integral.im(A)
>>>
>>> For 3 dimensions I have tried to pass an array of a grid covering the window (like 
> a 
>>> quadrature scheme) and then summing up the output array, but I would like to 
> know if 
>>> there is any faster way of integrating the function.
>>>
>>> Thank you very much,
>>>
>>> Llu?s Hurtado
>>> IFCA
>>> www.ifca.unican.es
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guidehtml
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>>
> 
> 
> --
> Llu?s Hurtado-Gil
> Observatori Astron?mic. Universitat de Val?ncia.
> Edifici Instituts d'Investigaci?. Parc Cient?fic.
> C/ Catedr?tico Agust?n Escardino n?7
> Campus Burjassot-Paterna
> 46980 Paterna Val?ncia (Spain).
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From deter088 at umn.edu  Wed Mar 25 13:22:45 2015
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 25 Mar 2015 07:22:45 -0500
Subject: [R] Fwd: missing in neural network
In-Reply-To: <CACYT75sg4Y8aH5efprNJmTpQb_MdVFqJRffWcVEXr_VDXJFLhw@mail.gmail.com>
References: <CACYT75uwxC-BeLkXtjM_QPQoHZq7Mzb6ZKdSjr3NY13Nj70-Pw@mail.gmail.com>
	<CAOLJphnZt6QCdztLfop+y=+cd9FzQWJDB1opi4d2ArVbTSVFMw@mail.gmail.com>
	<CACYT75vyzxYiyWmKNPG6tJQrLdSvEF+=eX-7cwaXMd5yeX4fyw@mail.gmail.com>
	<CACYT75vON_g_L0bN_Ta6diYDXTmdFKDs_4M5cuLM7q6jEy=WgA@mail.gmail.com>
	<CAOLJphkfZKVo++efjOmG_rDRb38dDh_dBiW8nzExyDVOmQx=ag@mail.gmail.com>
	<CACYT75tKTLvPy19NaeQTpc8FxmvxPO62kR2j8ywGcX9sK7cJ3Q@mail.gmail.com>
	<CACYT75sg4Y8aH5efprNJmTpQb_MdVFqJRffWcVEXr_VDXJFLhw@mail.gmail.com>
Message-ID: <CAOLJphn16bhC6-HKe32OVhqQQdHOE5Att_qDiVWO1Jqqhc84CQ@mail.gmail.com>

Soheila,

Set the name of the last column and remove the comma indexing the column
names.  It is a vector and therefore doesn't need a comma for indexing.
Also, after loading your dataset I realized you also have invalid column
names.  The mixes between hyphens and underscores makes the as.formula call
unhappy.  A simple way to fix is to just change all hyphens to underscores
with gsub.

# name 'resp'
colnames(mydata)[ncol(mydata)] <- "resp"

# change hyphens to underscores
colnames(mydata) <- gsub("-","_",colnames(mydata))

# create formula (without comma index on column names)
fm <- as.formula(paste("resp ~", paste(colnames(mydata)[1:3110],
collapse="+")))

# call neuralnet
out <- neuralnet(fm,data=mydata, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1)

Best regards,
Charles


On Wed, Mar 25, 2015 at 3:29 AM, Soheila Khodakarim <lkhodakarim at gmail.com>
wrote:

> Dear Charles,
>
> I rewrote code :
> library("neuralnet")
> resp<-c(1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1))
> mydata <- cbind(data24_2, resp)
> dim(mydata)
>  >  20 3111
> fm <- as.formula(paste("resp ~ ", paste(colnames(mydata)[,1:3110],
> collapse="+")))
> > Error in colnames(mydata)[, 1:3110] : incorrect number of dimensions
> :(((
>
> AND
>
> fm <- as.formula(paste(colnames(mydata)[,3111],
> paste(colnames(mydata)[,1:3110], collapse="+")))
> > Error in colnames(mydata)[, 3111] : incorrect number of dimensions
>
> Best,
> Soheila
>
> On Wed, Mar 25, 2015 at 11:12 AM, Soheila Khodakarim <
> lkhodakarim at gmail.com> wrote:
>
>> Hi Charles,
>> Many thanks for your help. I will check and let you know.
>>
>> Best Wishes,
>> Soheila
>> On Mar 25, 2015 12:17 AM, "Charles Determan Jr" <deter088 at umn.edu> wrote:
>>
>>> Soheila,
>>>
>>> Did my second response help you?  It is polite to close say if so, that
>>> way others who come across the problem no that it was solved.  If not, feel
>>> free to update your question.
>>>
>>> Regards,
>>> Charles
>>>
>>> On Tue, Mar 24, 2015 at 9:58 AM, Soheila Khodakarim <
>>> lkhodakarim at gmail.com> wrote:
>>>
>>>> Dear Charles,
>>>>
>>>> Thanks for your guide.
>>>> I run this code:
>>>>
>>>> library("neuralnet")
>>>> resp<-c(1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1)
>>>> mydata <- cbind(data, resp)
>>>> out1 <- neuralnet(resp~mydata[,1:3110],data=mydata, hidden = 4,
>>>> lifesign =
>>>> "minimal", linear.output = FALSE, threshold = 0.1)
>>>>
>>>> I saw this error
>>>>
>>>> Error in neurons[[i]] %*% weights[[i]] : non-conformable arguments
>>>>
>>>> :(:(:(
>>>>
>>>> What should I do now??
>>>>
>>>> Regards,
>>>> Soheila
>>>>
>>>>
>>>> On Tue, Mar 24, 2015 at 3:48 PM, Charles Determan Jr <deter088 at umn.edu>
>>>> wrote:
>>>>
>>>> > Hi Soheila,
>>>> >
>>>> > You are using the formula argument incorrectly.  The neuralnet
>>>> function
>>>> > has a separate argument for data aptly names 'data'.  You can review
>>>> the
>>>> > arguments by looking at the documentation  with ?neuralnet.
>>>> >
>>>> > As I cannot reproduce your data the following is not tested but I
>>>> think
>>>> > should work for you.
>>>> >
>>>> > # Join your response variable to your data set.
>>>> > mydata <- cbind(data, resp)
>>>> >
>>>> > # Run neuralnet
>>>> > out <- neuralnet(resp ~ ., data=mydata, hidden = 4, lifesign =
>>>> "minimal",
>>>> >                        linear.output = FALSE, threshold = 0.1,na.rm =
>>>> > TRUE)
>>>> >
>>>> >
>>>> > Best,
>>>> > Charles
>>>> >
>>>> > On Tue, Mar 24, 2015 at 4:47 AM, Soheila Khodakarim <
>>>> lkhodakarim at gmail.com
>>>> > > wrote:
>>>> >
>>>> >> Dear All,
>>>> >>
>>>> >> I want to run "neural network" on my dataset.
>>>> >> ##########################################################
>>>> >> resp<-c(1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1)
>>>> >> dim(data)
>>>> >> #20*3110
>>>> >>
>>>> >> out <- neuralnet(y ~ data, hidden = 4, lifesign = "minimal",
>>>> linear.output
>>>> >> = FALSE, threshold = 0.1,na.rm = TRUE)
>>>> >> ################################################################
>>>> >> but I see this Error
>>>> >> Error in varify.variables(data, formula, startweights,
>>>> learningrate.limit,
>>>> >>  :
>>>> >>   argument "data" is missing, with no default
>>>> >>
>>>> >> What should I do now??
>>>> >>
>>>> >> Best Regards,
>>>> >> Soheila
>>>> >>
>>>> >>         [[alternative HTML version deleted]]
>>>> >>
>>>> >> ______________________________________________
>>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >> PLEASE do read the posting guide
>>>> >> http://www.R-project.org/posting-guide.html
>>>> >> and provide commented, minimal, self-contained, reproducible code.
>>>> >>
>>>> >
>>>> >
>>>> >
>>>> >
>>>> >
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>>
>

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Wed Mar 25 13:30:36 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Wed, 25 Mar 2015 15:30:36 +0300
Subject: [R] Fitting a line on trellis plot
Message-ID: <CAGh51gS9PF6u0rEUGgPVhxqCcSFqNw8HArFK_1myzdb8jmr7Hw@mail.gmail.com>

Hi all,

I am doing analysis which involves fitting a line on trellis plot. The
factor is month. As you know a year has 12 months and I expect to get
12 lines one for each month. I am getting the following results which
is different to my expectation. Am I have to do anything about the
data? Any suggestion is welcome. Thanks.


Call:
lm(formula = curr_data[[tmin_col]] ~ curr_data[[year_col]] -
    1 | curr_data[[month_col]])

Residuals:
    Min      1Q  Median      3Q     Max
-5.0625 -0.7625  0.0375  0.9375  4.9375

Coefficients: (1 not defined because of singularities)
                                                       Estimate Std.
Error t value Pr(>|t|)
(Intercept)                                            15.56254
0.01079    1442   <2e-16 ***
curr_data[[year_col]]  | curr_data[[month_col]]TRUE       NA
NA      NA       NA
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 1.327 on 15115 degrees of freedom
  (72 observations deleted due to missingness)

Regards,

Frederic.


Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From info at aghmed.fsnet.co.uk  Wed Mar 25 14:29:27 2015
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Wed, 25 Mar 2015 13:29:27 +0000
Subject: [R] Fitting a line on trellis plot
In-Reply-To: <CAGh51gS9PF6u0rEUGgPVhxqCcSFqNw8HArFK_1myzdb8jmr7Hw@mail.gmail.com>
References: <CAGh51gS9PF6u0rEUGgPVhxqCcSFqNw8HArFK_1myzdb8jmr7Hw@mail.gmail.com>
Message-ID: <5512B837.4030906@aghmed.fsnet.co.uk>



On 25/03/2015 12:30, Frederic Ntirenganya wrote:
> Hi all,
>
> I am doing analysis which involves fitting a line on trellis plot.

But the commands below (or at least the output from them) are not 
plotting commands.

  The
> factor is month. As you know a year has 12 months and I expect to get
> 12 lines one for each month. I am getting the following results which
> is different to my expectation. Am I have to do anything about the
> data? Any suggestion is welcome. Thanks.
>
>
> Call:
> lm(formula = curr_data[[tmin_col]] ~ curr_data[[year_col]] -
>      1 | curr_data[[month_col]])

It would be simpler to say
lm(tmin_col ~ year_col - 1 | month_col, data = curr_data)

What did you think this was going to do? Is there any mention in the 
help for lm that you can use the | here?

It would also be helpful to see the result of str(curr_data) as we do 
not know what year_col is and we need to be sure that month_col is 
indeed a factor.

I am sure calendar experts on this list are readying themselves to 
question your assertion that all calendars have twelve months but that 
is rather off-topic.

>
> Residuals:
>      Min      1Q  Median      3Q     Max
> -5.0625 -0.7625  0.0375  0.9375  4.9375
>
> Coefficients: (1 not defined because of singularities)
>                                                         Estimate Std.
> Error t value Pr(>|t|)
> (Intercept)                                            15.56254
> 0.01079    1442   <2e-16 ***
> curr_data[[year_col]]  | curr_data[[month_col]]TRUE       NA
> NA      NA       NA
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 1.327 on 15115 degrees of freedom
>    (72 observations deleted due to missingness)
>
> Regards,
>
> Frederic.
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5751 / Virus Database: 4315/9378 - Release Date: 03/25/15
>

-- 
Michael
http://www.dewey.myzen.co.uk


From lkhodakarim at gmail.com  Wed Mar 25 14:31:15 2015
From: lkhodakarim at gmail.com (Soheila Khodakarim)
Date: Wed, 25 Mar 2015 17:01:15 +0330
Subject: [R] Fwd:  Fwd: missing in neural network
In-Reply-To: <CACYT75vQ4_ohVXbdWHYpAYCHge_3j099eZ=og-NZMMQBoTXJXQ@mail.gmail.com>
References: <CACYT75uwxC-BeLkXtjM_QPQoHZq7Mzb6ZKdSjr3NY13Nj70-Pw@mail.gmail.com>
	<CAOLJphnZt6QCdztLfop+y=+cd9FzQWJDB1opi4d2ArVbTSVFMw@mail.gmail.com>
	<CACYT75vyzxYiyWmKNPG6tJQrLdSvEF+=eX-7cwaXMd5yeX4fyw@mail.gmail.com>
	<CACYT75vON_g_L0bN_Ta6diYDXTmdFKDs_4M5cuLM7q6jEy=WgA@mail.gmail.com>
	<CAOLJphkfZKVo++efjOmG_rDRb38dDh_dBiW8nzExyDVOmQx=ag@mail.gmail.com>
	<CACYT75tKTLvPy19NaeQTpc8FxmvxPO62kR2j8ywGcX9sK7cJ3Q@mail.gmail.com>
	<CACYT75sg4Y8aH5efprNJmTpQb_MdVFqJRffWcVEXr_VDXJFLhw@mail.gmail.com>
	<CAOLJphn16bhC6-HKe32OVhqQQdHOE5Att_qDiVWO1Jqqhc84CQ@mail.gmail.com>
	<CACYT75u2HFnKcBNEbmjOptRmM_Uma42yhZNm4QgSeL7JW_oasg@mail.gmail.com>
	<CACYT75vQ4_ohVXbdWHYpAYCHge_3j099eZ=og-NZMMQBoTXJXQ@mail.gmail.com>
Message-ID: <CACYT75sT-gHfJqzwN1+Pvb4=_EF09o_bBHhN7__pzRgPpU4ZDg@mail.gmail.com>

I am very grateful Dear Charles.

Soheila

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Wed Mar 25 14:48:20 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 25 Mar 2015 13:48:20 +0000
Subject: [R] Fitting a line on trellis plot
In-Reply-To: <CAGh51gS9PF6u0rEUGgPVhxqCcSFqNw8HArFK_1myzdb8jmr7Hw@mail.gmail.com>
References: <CAGh51gS9PF6u0rEUGgPVhxqCcSFqNw8HArFK_1myzdb8jmr7Hw@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED672CCE61B8@GOLD.corp.lgc-group.com>

 
> Call:
> lm(formula = curr_data[[tmin_col]] ~ curr_data[[year_col]] -
>     1 | curr_data[[month_col]])


First, this is not a sensible formula for lm; lm() does not use '|' to denote grouping. It would be a valid formula for xyplot, in which | specifies grouping variables. In lm(), '|' is simply being treated as 'or', which is why one of your coefficients is for ' curr_data[[year_col]]  | curr_data[[month_col]]TRUE'

Second, you should not normally need things like curr_data[[month_col]], either in lm or xyplot. If curr_data is a data frame, things like

lm(tmin ~ year, data=curr_data)
 
should work.

Third, 'nested' models in lm use the nesting operator '/', not '|'. So if you want 12 lines with separate intercept and gradient from an lm, you need (with month as a factor and the default intercept suppressed)
lm(tmin~month+year/month -1, data=curr_data) #-1 suppresses the intercept and provides a zero-based intercept for each month

This gives you 12 'month' intercepts and one gradient per month. If you wanted a common intercept you'd do 
lm(tmin~ year/month, data=curr_data)
But beware; the coefficients in both cases cannot be interpreted as a simple gradient and intercept for each month: if I recall correctly, the gradients for month2 and on are modelled as an additive increment on the first month gradient. Use predict() if you want an easy way to predict a value for a given (possibly fractional) time of year and 'month'.
[Incidentally I don?t immediately see why that is a sensible thing to do - this fits a monthly summary against a numeric year. But I'm going to assume you know what you want there.]

Finally, though, this model will not help you much with lattice as there's no _simple_ way of putting those lines on different panels in a lattice plot. If you just want a line on each of 12 panels, that's much easier. You can  use the panel() function with panel.lmline to put it there. For example, if you want to plot a line over the data, use 

xyplot(tmin~year|month, curr_data,
	panel=function(x, y, ...) {
		panel.xyplot(x, y, ...)
		panel.lmline(x, y, ...)
	}
)


S Ellison




*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From S.Ellison at LGCGroup.com  Wed Mar 25 14:52:48 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 25 Mar 2015 13:52:48 +0000
Subject: [R] Fwd: missing in neural network
In-Reply-To: <CAOLJphn16bhC6-HKe32OVhqQQdHOE5Att_qDiVWO1Jqqhc84CQ@mail.gmail.com>
References: <CACYT75uwxC-BeLkXtjM_QPQoHZq7Mzb6ZKdSjr3NY13Nj70-Pw@mail.gmail.com>
	<CAOLJphnZt6QCdztLfop+y=+cd9FzQWJDB1opi4d2ArVbTSVFMw@mail.gmail.com>
	<CACYT75vyzxYiyWmKNPG6tJQrLdSvEF+=eX-7cwaXMd5yeX4fyw@mail.gmail.com>
	<CACYT75vON_g_L0bN_Ta6diYDXTmdFKDs_4M5cuLM7q6jEy=WgA@mail.gmail.com>
	<CAOLJphkfZKVo++efjOmG_rDRb38dDh_dBiW8nzExyDVOmQx=ag@mail.gmail.com>
	<CACYT75tKTLvPy19NaeQTpc8FxmvxPO62kR2j8ywGcX9sK7cJ3Q@mail.gmail.com>
	<CACYT75sg4Y8aH5efprNJmTpQb_MdVFqJRffWcVEXr_VDXJFLhw@mail.gmail.com>
	<CAOLJphn16bhC6-HKe32OVhqQQdHOE5Att_qDiVWO1Jqqhc84CQ@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED672CCE61C2@GOLD.corp.lgc-group.com>

 
> # create formula (without comma index on column names) fm <-
> as.formula(paste("resp ~", paste(colnames(mydata)[1:3110],
> collapse="+")))
> 
> # call neuralnet
> out <- neuralnet(fm,data=mydata, hidden = 4, lifesign = "minimal",
> linear.output = FALSE, threshold = 0.1)

Does neuralnet not recognise '.'? If it does and if you include resp in the data frame, you could drastically simplify the formula, to just resp~. That is:

out <- neuralnet(resp~. , data=cbind(resp, mydata), hidden = 4, lifesign = "minimal",
	linear.output = FALSE, threshold = 0.1)


S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From benedetta.brunetti at gmail.com  Wed Mar 25 15:02:50 2015
From: benedetta.brunetti at gmail.com (BenedettaB24 .)
Date: Wed, 25 Mar 2015 16:02:50 +0200
Subject: [R] Graph with ggplot2.
Message-ID: <CAPmikEdF8eqM_pLxTubMvPHPUb+ChuWLD3B+U0MS=rnE6p-9SQ@mail.gmail.com>

Dear all,

I want to run ggplot2 in one of my file.
I do this:

mergefile<- read.csv("path of my file/name.csv")

library(ggplot2)   to import my library

ggplot(percent, aes(x=factor(Cell.lines), y=Percentage, vjust=-0.5,
fill=Prostate )) + geom_bar(colour="black", stat="identity",
position=position_dodge(), size=.3)+ylim(0%,100%)+xlab("Prostate cell
lines")+ylab("Percentage of overlapping")+ggtitle("Comparison between
cell lines against the prostate cancer lines from DNase
esperiment")+theme_bw()+theme(axis.text.x=element_text(angle = 90,
vjust = 0.5))

i used this command three times, but now is not working, the error reported
is:

Error: unexpected ')' in "ggplot(percent, aes(x=factor(Cell.lines),
y=Percentage, vjust=-0.5, fill=Prostate )) + geom_bar(colour="black",
stat="identity", position=position_dodge(), size=.3)+ylim(0%,100%)"


Can some one help me? any suggestions?

Thanks a lot!

Best regards, Benedetta

	[[alternative HTML version deleted]]


From nilsson.henric at gmail.com  Wed Mar 25 15:14:18 2015
From: nilsson.henric at gmail.com (Henric Winell)
Date: Wed, 25 Mar 2015 15:14:18 +0100
Subject: [R] Why can't I access this type?
In-Reply-To: <20150325084041.GA2875@slingshot.co.nz>
References: <CAJ=2b04qLmoA8W--=dsv2vqMHkG1Y7Tv_QQx_9D78oopJku+Yg@mail.gmail.com>
	<28E315E85F1.00000296jrkrideau@inbox.com>
	<20150325084041.GA2875@slingshot.co.nz>
Message-ID: <5512C2BA.6020301@gmail.com>

On 2015-03-25 09:40, Patrick Connolly wrote:

> On Sun, 22-Mar-2015 at 08:06AM -0800, John Kane wrote:
>
> |> Well, first off, you have no variable called "Name".  You have lost
> |> the state names as they are rownames in the matrix state.x77 and
> |> not a variable.
> |>
> |> Try this. It's ugly and I have no idea why I had to do a cbind()
>
> You don't have to use cbind
>
> |> but it seems to work. Personally I find subset easier to read than
> |> the indexing approach.
>
> |> state  <-  rownames(state.x77)
> |> all.states <- as.data.frame(state.x77)
> |> all.states  <-  cbind(state, all.states) ### ?????
>
> You don't have to use cbind()
>
> all.states  <- within(as.data.frame(state.x77), state <- rownames(state.x77))
>
> but I think cbind is simpler to read.
>
> |>
> |> coldstates  <-   subset(all.states, all.states$Frost > 50,
> |>                         select = c("state","Frost") )

I find the indexing approach

coldstates <- all.states[all.states$Frost > 150, c("state","Frost")]

to be the most direct and obvious solution.

> Tidier, even more so than subset():
>
> require(dplyr)
> coldstates <- all.states %>% filter(Frost > 150) %>% select(state, Frost)
>
> Or, easier to see what's happening:
>
> coldstates <- all.states %>%
>    filter(Frost > 150) %>%
>    select(state, Frost)

Well...  Opinions may perhaps differ, but apart from '%>%' being 
butt-ugly it's also fairly slow:

 > library("microbenchmark")
 > microbenchmark(
+     subset(all.states, all.states$Frost > 150, select = 
c("state","Frost")),
+     all.states[all.states$Frost > 150, c("state","Frost")],
+     all.states %>% filter(Frost > 150) %>% select(state, Frost),
+     times = 1000L
+ )
Unit: microseconds
 
    expr
  subset(all.states, all.states$Frost > 150, select = c("state", 
"Frost"))
                        all.states[all.states$Frost > 150, c("state", 
"Frost")]
                    all.states %>% filter(Frost > 150) %>% select(state, 
Frost)
       min       lq      mean    median        uq      max neval cld
   139.112  148.673  163.3960  159.1760  170.7895 1763.200  1000  b
   104.039  111.973  127.2138  120.4395  128.6640 1381.809  1000 a
  1010.076 1033.519 1133.1469 1107.8480 1175.1800 2932.206  1000   c

Of course, this doesn't matter for interactive one-off use.  But lately 
I've seen examples of the '%>%' operator creeping into functions in 
packages.  However, it would be nice to see a fast pipe operator as part 
of base R.


Henric Winell



>
>
> |>
> |>
> |> John Kane
> |> Kingston ON Canada
> |>
> |>
> |> > -----Original Message-----
> |> > From: yoursurrogategod at gmail.com
> |> > Sent: Sun, 22 Mar 2015 10:39:03 -0400
> |> > To: r-help at r-project.org
> |> > Subject: [R] Why can't I access this type?
> |> >
> |> > Hi, I'm just learning my way around R.  I got a bunch of states and would
> |> > like to access to get all of the ones where it's cold.  But when I do the
> |> > following, I will get the following error:
> |> >
> |> >> all.states <- as.data.frame(state.x77)
> |> >> cold.states <- all.states[all.states$Frost > 150, c("Name", "Frost")]
> |> > Error in `[.data.frame`(all.states, all.states$Frost > 150, c("Name",  :
> |> >   undefined columns selected
> |> >
> |> > I don't get it.  When I look at all.states, this is what I see:
> |> >
> |> >> str(all.states)
> |> > 'data.frame':   50 obs. of  8 variables:
> |> >  $ Population: num  3615 365 2212 2110 21198 ...
> |> >  $ Income    : num  3624 6315 4530 3378 5114 ...
> |> >  $ Illiteracy: num  2.1 1.5 1.8 1.9 1.1 0.7 1.1 0.9 1.3 2 ...
> |> >  $ Life Exp  : num  69 69.3 70.5 70.7 71.7 ...
> |> >  $ Murder    : num  15.1 11.3 7.8 10.1 10.3 6.8 3.1 6.2 10.7 13.9 ...
> |> >  $ HS Grad   : num  41.3 66.7 58.1 39.9 62.6 63.9 56 54.6 52.6 40.6 ...
> |> >  $ Frost     : num  20 152 15 65 20 166 139 103 11 60 ...
> |> >  $ Area      : num  50708 566432 113417 51945 156361 ...
> |> >
> |> > What am I messing up?
> |> >
> |> > 	[[alternative HTML version deleted]]
> |> >
> |> > ______________________________________________
> |> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> |> > https://stat.ethz.ch/mailman/listinfo/r-help
> |> > PLEASE do read the posting guide
> |> > http://www.R-project.org/posting-guide.html
> |> > and provide commented, minimal, self-contained, reproducible code.
> |>
> |> ____________________________________________________________
> |> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> |> Visit http://www.inbox.com/photosharing to find out more!
> |>
> |> ______________________________________________
> |> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> |> https://stat.ethz.ch/mailman/listinfo/r-help
> |> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> |> and provide commented, minimal, self-contained, reproducible code.
>


From sackettl at colorado.edu  Wed Mar 25 14:49:07 2015
From: sackettl at colorado.edu (Loren Cassin Sackett)
Date: Wed, 25 Mar 2015 09:49:07 -0400
Subject: [R] facets work in qplot but facet_wrap produces an error in
	ggplot
In-Reply-To: <8D4B6E58-8E87-4D26-A3BD-C4671F063F73@dcn.davis.CA.us>
References: <1427236811798-4705058.post@n4.nabble.com>
	<8D4B6E58-8E87-4D26-A3BD-C4671F063F73@dcn.davis.CA.us>
Message-ID: <CAJtjKAQa4WccTmrjm_CED=SevH44FH67LK9sYJfw=M5AMQwrzQ@mail.gmail.com>

Thanks, Jeff.  I tried this previously by using a header in my data file
(and 'header=TRUE'), but for some reason, that did not seem to work.

Creating a 'names' vector as you suggested did solve the problem, though.

Thank you!
Loren


2015-03-24 23:19 GMT-04:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> You MUST put all data you plan to refer to into a data frame when using
> ggplot. There are a couple of ways you could do this... the easiest is to
> put a header line in the data file with column names. Or, you can assign a
> vector of new names to the names of the data frame.
>
> names( hetshoms ) <- c( "chrom", "start.pos", "end.pos", "hets",
> "het_stat", "homs", "hom_stat", "indiv" )
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On March 24, 2015 3:40:11 PM PDT, Loren <sackettl at colorado.edu> wrote:
> >Hello all,
> >
> >I am having a perplexing problem trying to use facet_wrap in ggplot,
> >with
> >both my real dataset and a simplified dummy dataset.  I am trying to
> >plot
> >heterozygosity across the genome for multiple individuals, with each
> >chromosome shown separately.
> >
> >My dummy data:
> >chr1   123000  124000  2       0.00002 26      0.00026 indiv1
> >chr1   124000  125000  3       0.00003 12      0.00012 indiv1
> >chr1   125000  126000  1       0.00001 6       0.00006 indiv1
> >chr1   126000  126000  2       0.00002 14      0.00014 indiv1
> >chr2   123000  124000  6       0.00006 20      0.00020 indiv1
> >chr2   124000  125000  0       0.00000 12      0.00012 indiv1
> >chr1   123000  124000  2       0.00002 26      0.00026 indiv2
> >chr1   124000  125000  3       0.00003 12      0.00012 indiv2
> >chr1   125000  126000  1       0.00001 6       0.00006 indiv2
> >chr1   126000  126000  2       0.00002 14      0.00014 indiv2
> >chr2   123000  124000  6       0.00006 20      0.00020 indiv2
> >chr2   124000  125000  0       0.00000 12      0.00012 indiv2
> >
> >My code to read in the data:
> >hetshoms <- read.table("fakedata.txt", header=F)
> >
> >chrom <- hetshoms$V1
> >start.pos <- hetshoms$V2
> >end.pos <- hetshoms$V3
> >hets <- hetshoms$V4
> >het_stat <- hetshoms$V5
> >homs <- hetshoms$V6
> >hom_stat <- hetshoms$V7
> >indiv <- hetshoms$V8
> >
> >HetRatio <- hets/(hets+homs)
> >
> >When I try to plot the chromosomes separately in qplot, it works fine:
> >testplot <- qplot(start.pos, HetRatio, facets = chrom ~ .,
> >colour=chrom)
> >
> >But when I try an analogous thing in ggplot, it does not work.
> >The first part works fine:
> >testplot <- ggplot(hetshoms, aes(x=start.pos, y=HetRatio)) +
> >geom_point(aes(color=chrom, alpha=1/4))
> >
> >but when I try to add the facet_wrap:
> >testplot + facet_wrap(~chrom)
> >
> >This produces the following error (and no plot)
> >"Error en layout_base(data, vars, drop = drop) :
> >  At least one layer must contain all variables used for facetting"
> >
> >I have tried adding an (as.formula(paste)) and directly calling
> >hetshoms$V1
> >but neither solves the problem.
> >
> >Can anyone please point out where I have gone wrong and how to fix my
> >code?
> >
> >Much appreciated,
> >Loren
> >
> >
> >
> >
> >
> >
> >--
> >View this message in context:
> >
> http://r.789695.n4.nabble.com/facets-work-in-qplot-but-facet-wrap-produces-an-error-in-ggplot-tp4705058.html
> >Sent from the R help mailing list archive at Nabble.com.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Mar 25 16:08:26 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 25 Mar 2015 08:08:26 -0700
Subject: [R] facets work in qplot but facet_wrap produces an error in
	ggplot
In-Reply-To: <CAJtjKAQa4WccTmrjm_CED=SevH44FH67LK9sYJfw=M5AMQwrzQ@mail.gmail.com>
References: <1427236811798-4705058.post@n4.nabble.com>
	<8D4B6E58-8E87-4D26-A3BD-C4671F063F73@dcn.davis.CA.us>
	<CAJtjKAQa4WccTmrjm_CED=SevH44FH67LK9sYJfw=M5AMQwrzQ@mail.gmail.com>
Message-ID: <AD4A56C0-7861-451C-BF44-5A65DAFE1436@dcn.davis.CA.us>

Perhaps you had forgotten to use header=TRUE when you read the data in.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 25, 2015 6:49:07 AM PDT, Loren Cassin Sackett <sackettl at colorado.edu> wrote:
>Thanks, Jeff.  I tried this previously by using a header in my data
>file
>(and 'header=TRUE'), but for some reason, that did not seem to work.
>
>Creating a 'names' vector as you suggested did solve the problem,
>though.
>
>Thank you!
>Loren
>
>
>2015-03-24 23:19 GMT-04:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>
>> You MUST put all data you plan to refer to into a data frame when
>using
>> ggplot. There are a couple of ways you could do this... the easiest
>is to
>> put a header line in the data file with column names. Or, you can
>assign a
>> vector of new names to the names of the data frame.
>>
>> names( hetshoms ) <- c( "chrom", "start.pos", "end.pos", "hets",
>> "het_stat", "homs", "hom_stat", "indiv" )
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 24, 2015 3:40:11 PM PDT, Loren <sackettl at colorado.edu>
>wrote:
>> >Hello all,
>> >
>> >I am having a perplexing problem trying to use facet_wrap in ggplot,
>> >with
>> >both my real dataset and a simplified dummy dataset.  I am trying to
>> >plot
>> >heterozygosity across the genome for multiple individuals, with each
>> >chromosome shown separately.
>> >
>> >My dummy data:
>> >chr1   123000  124000  2       0.00002 26      0.00026 indiv1
>> >chr1   124000  125000  3       0.00003 12      0.00012 indiv1
>> >chr1   125000  126000  1       0.00001 6       0.00006 indiv1
>> >chr1   126000  126000  2       0.00002 14      0.00014 indiv1
>> >chr2   123000  124000  6       0.00006 20      0.00020 indiv1
>> >chr2   124000  125000  0       0.00000 12      0.00012 indiv1
>> >chr1   123000  124000  2       0.00002 26      0.00026 indiv2
>> >chr1   124000  125000  3       0.00003 12      0.00012 indiv2
>> >chr1   125000  126000  1       0.00001 6       0.00006 indiv2
>> >chr1   126000  126000  2       0.00002 14      0.00014 indiv2
>> >chr2   123000  124000  6       0.00006 20      0.00020 indiv2
>> >chr2   124000  125000  0       0.00000 12      0.00012 indiv2
>> >
>> >My code to read in the data:
>> >hetshoms <- read.table("fakedata.txt", header=F)
>> >
>> >chrom <- hetshoms$V1
>> >start.pos <- hetshoms$V2
>> >end.pos <- hetshoms$V3
>> >hets <- hetshoms$V4
>> >het_stat <- hetshoms$V5
>> >homs <- hetshoms$V6
>> >hom_stat <- hetshoms$V7
>> >indiv <- hetshoms$V8
>> >
>> >HetRatio <- hets/(hets+homs)
>> >
>> >When I try to plot the chromosomes separately in qplot, it works
>fine:
>> >testplot <- qplot(start.pos, HetRatio, facets = chrom ~ .,
>> >colour=chrom)
>> >
>> >But when I try an analogous thing in ggplot, it does not work.
>> >The first part works fine:
>> >testplot <- ggplot(hetshoms, aes(x=start.pos, y=HetRatio)) +
>> >geom_point(aes(color=chrom, alpha=1/4))
>> >
>> >but when I try to add the facet_wrap:
>> >testplot + facet_wrap(~chrom)
>> >
>> >This produces the following error (and no plot)
>> >"Error en layout_base(data, vars, drop = drop) :
>> >  At least one layer must contain all variables used for facetting"
>> >
>> >I have tried adding an (as.formula(paste)) and directly calling
>> >hetshoms$V1
>> >but neither solves the problem.
>> >
>> >Can anyone please point out where I have gone wrong and how to fix
>my
>> >code?
>> >
>> >Much appreciated,
>> >Loren
>> >
>> >
>> >
>> >
>> >
>> >
>> >--
>> >View this message in context:
>> >
>>
>http://r.789695.n4.nabble.com/facets-work-in-qplot-but-facet-wrap-produces-an-error-in-ggplot-tp4705058.html
>> >Sent from the R help mailing list archive at Nabble.com.
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From jdnewmil at dcn.davis.CA.us  Wed Mar 25 16:14:10 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 25 Mar 2015 08:14:10 -0700
Subject: [R] Graph with ggplot2.
In-Reply-To: <CAPmikEdF8eqM_pLxTubMvPHPUb+ChuWLD3B+U0MS=rnE6p-9SQ@mail.gmail.com>
References: <CAPmikEdF8eqM_pLxTubMvPHPUb+ChuWLD3B+U0MS=rnE6p-9SQ@mail.gmail.com>
Message-ID: <6B1F7D8B-DBB8-4707-AE92-13DA7C3A9E12@dcn.davis.CA.us>

It is difficult to read your code because the HTML format messes it up, but I think your ggplot function call is missing a parenthesis between fill=Prostate and the + sign.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 25, 2015 7:02:50 AM PDT, "BenedettaB24 ." <benedetta.brunetti at gmail.com> wrote:
>Dear all,
>
>I want to run ggplot2 in one of my file.
>I do this:
>
>mergefile<- read.csv("path of my file/name.csv")
>
>library(ggplot2)   to import my library
>
>ggplot(percent, aes(x=factor(Cell.lines), y=Percentage, vjust=-0.5,
>fill=Prostate )) + geom_bar(colour="black", stat="identity",
>position=position_dodge(), size=.3)+ylim(0%,100%)+xlab("Prostate cell
>lines")+ylab("Percentage of overlapping")+ggtitle("Comparison between
>cell lines against the prostate cancer lines from DNase
>esperiment")+theme_bw()+theme(axis.text.x=element_text(angle = 90,
>vjust = 0.5))
>
>i used this command three times, but now is not working, the error
>reported
>is:
>
>Error: unexpected ')' in "ggplot(percent, aes(x=factor(Cell.lines),
>y=Percentage, vjust=-0.5, fill=Prostate )) + geom_bar(colour="black",
>stat="identity", position=position_dodge(), size=.3)+ylim(0%,100%)"
>
>
>Can some one help me? any suggestions?
>
>Thanks a lot!
>
>Best regards, Benedetta
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Wed Mar 25 16:17:36 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 25 Mar 2015 16:17:36 +0100
Subject: [R] Graph with ggplot2.
In-Reply-To: <CAPmikEdF8eqM_pLxTubMvPHPUb+ChuWLD3B+U0MS=rnE6p-9SQ@mail.gmail.com>
References: <CAPmikEdF8eqM_pLxTubMvPHPUb+ChuWLD3B+U0MS=rnE6p-9SQ@mail.gmail.com>
Message-ID: <CAJuCY5wp9JyQCQTggxAmhO9YYToyYwWpSzcrxFNRq51A3rLgig@mail.gmail.com>

You need to define limits as defined in the data. ylim(0, 1) instead of
ylim(0%, 100%)

ylim(0%, 100%) is incorrect R syntax.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-25 15:02 GMT+01:00 BenedettaB24 . <benedetta.brunetti at gmail.com>:

> Dear all,
>
> I want to run ggplot2 in one of my file.
> I do this:
>
> mergefile<- read.csv("path of my file/name.csv")
>
> library(ggplot2)   to import my library
>
> ggplot(percent, aes(x=factor(Cell.lines), y=Percentage, vjust=-0.5,
> fill=Prostate )) + geom_bar(colour="black", stat="identity",
> position=position_dodge(), size=.3)+ylim(0%,100%)+xlab("Prostate cell
> lines")+ylab("Percentage of overlapping")+ggtitle("Comparison between
> cell lines against the prostate cancer lines from DNase
> esperiment")+theme_bw()+theme(axis.text.x=element_text(angle = 90,
> vjust = 0.5))
>
> i used this command three times, but now is not working, the error reported
> is:
>
> Error: unexpected ')' in "ggplot(percent, aes(x=factor(Cell.lines),
> y=Percentage, vjust=-0.5, fill=Prostate )) + geom_bar(colour="black",
> stat="identity", position=position_dodge(), size=.3)+ylim(0%,100%)"
>
>
> Can some one help me? any suggestions?
>
> Thanks a lot!
>
> Best regards, Benedetta
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Wed Mar 25 16:19:24 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 25 Mar 2015 15:19:24 +0000
Subject: [R] Graph with ggplot2.
In-Reply-To: <CAPmikEdF8eqM_pLxTubMvPHPUb+ChuWLD3B+U0MS=rnE6p-9SQ@mail.gmail.com>
References: <CAPmikEdF8eqM_pLxTubMvPHPUb+ChuWLD3B+U0MS=rnE6p-9SQ@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED672CCE6297@GOLD.corp.lgc-group.com>

> i used this command three times, 
clearly not exactly this, if it's stopped working ...

> but now is not working, the error reported is:
> Error: unexpected ')' in "ggplot(percent, aes(x=factor(Cell.lines), y=Percentage,
> vjust=-0.5, fill=Prostate )) + geom_bar(colour="black", stat="identity",
> position=position_dodge(), size=.3)+ylim(0%,100%)"
> 
> 
> Can some one help me? any suggestions?

You have an unexpected right parenthesis at 100%). Look for something wrong there or before that - often an unmatched parenthesis, string terminator or operator terminator - would be sensible.

As a clue, you could think about what '%' means in R. It does NOT mean 'percent'

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From JLucke at ria.buffalo.edu  Wed Mar 25 16:27:18 2015
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Wed, 25 Mar 2015 11:27:18 -0400
Subject: [R] Graph with ggplot2.
In-Reply-To: <6B1F7D8B-DBB8-4707-AE92-13DA7C3A9E12@dcn.davis.CA.us>
References: <CAPmikEdF8eqM_pLxTubMvPHPUb+ChuWLD3B+U0MS=rnE6p-9SQ@mail.gmail.com>
	<6B1F7D8B-DBB8-4707-AE92-13DA7C3A9E12@dcn.davis.CA.us>
Message-ID: <OFAC66F83B.1D7FA950-ON85257E13.005496D0-85257E13.0054E5D1@ria.buffalo.edu>

ylim(0%,100%) is not valild.  It should be ylim(0,100).



Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent by: "R-help" <r-help-bounces at r-project.org>
03/25/2015 11:14 AM

To
"BenedettaB24 ." <benedetta.brunetti at gmail.com>, "r-help at r-project.org" 
<r-help at r-project.org>, 
cc

Subject
Re: [R] Graph with ggplot2.






It is difficult to read your code because the HTML format messes it up, 
but I think your ggplot function call is missing a parenthesis between 
fill=Prostate and the + sign.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go 
Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live 
Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#. rocks...1k
--------------------------------------------------------------------------- 

Sent from my phone. Please excuse my brevity.

On March 25, 2015 7:02:50 AM PDT, "BenedettaB24 ." 
<benedetta.brunetti at gmail.com> wrote:
>Dear all,
>
>I want to run ggplot2 in one of my file.
>I do this:
>
>mergefile<- read.csv("path of my file/name.csv")
>
>library(ggplot2)   to import my library
>
>ggplot(percent, aes(x=factor(Cell.lines), y=Percentage, vjust=-0.5,
>fill=Prostate )) + geom_bar(colour="black", stat="identity",
>position=position_dodge(), size=.3)+ylim(0%,100%)+xlab("Prostate cell
>lines")+ylab("Percentage of overlapping")+ggtitle("Comparison between
>cell lines against the prostate cancer lines from DNase
>esperiment")+theme_bw()+theme(axis.text.x=element_text(angle = 90,
>vjust = 0.5))
>
>i used this command three times, but now is not working, the error
>reported
>is:
>
>Error: unexpected ')' in "ggplot(percent, aes(x=factor(Cell.lines),
>y=Percentage, vjust=-0.5, fill=Prostate )) + geom_bar(colour="black",
>stat="identity", position=position_dodge(), size=.3)+ylim(0%,100%)"
>
>
>Can some one help me? any suggestions?
>
>Thanks a lot!
>
>Best regards, Benedetta
>
>                [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Mar 25 16:45:09 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 25 Mar 2015 08:45:09 -0700
Subject: [R] Fast evaluation of functions in 3D domains
In-Reply-To: <8587793882hurgil@uv.es>
References: <36EBCEEB-EBEE-4883-9DAF-50FE66BF1E2B@comcast.net>
	<8587793882hurgil@uv.es>
Message-ID: <D51B3A74-EAC7-4EC1-A6A3-3F0D7A26DE4C@comcast.net>


On Mar 25, 2015, at 4:55 AM, <Lluis.Hurtado at uv.es> <Lluis.Hurtado at uv.es> wrote:

> Dear all,
> 
> Finally I have tried three different options to integrate a function in a 3D volume. Here 
> I show a test example. The volume is the box [0,100] x [0,100] x [0,100] and the 
> function is
> 
> nfw(d) = 4/((d/5)*(1+(d/5))^2)
> 
> where d is the distance between each point in the box to the point (50,50,40).
> 
> 1-Grid of thick 1 in R (10^6 points)
> 
>> model <- function(x) 
> {
>   d <- sqrt((x[,1]-50)^2 + (x[,2]-50)^2 + (x[,3]-40)^2)
>   r <- 4.0/((d/5)*(1+(d/5))^2)
>   r
> } 
>> sum(model(x))
> [1] 10287.52
>> system.time(sum(model(x)))
>   user  system elapsed 
>  0.052   0.003   0.053 
> 
> 2-Grid with thick 1 in C++ calling from R. Function model_cpp is a function written in 
> C++ reproducing model function as above. (10^6 points)
> 
>> model <- function(x)
>  {
>  	param <- c(50,50,40,5)
>  	.Call('model_cpp',x[,1],x[,2],x[,3],param)
>  }
>> sum(model(x))
> [1] 10287.52
>> system.time(sum(model(x)))
>   user  system elapsed 
>  0.028   0.000   0.028 
> 
> 3-cubature. Mr Tom Jagger kindly proposed to use cubature package:
> http://cran.r-project.org/web/packages/cubature/cubature.pdf
> 
>> model <- function(x) 
> +  {
> +     d <- sqrt((x[1]-50)^2 + (x[2]-50)^2 + (x[3]-40)^2)
> +     r <- 4.0/((d/5)*(1+(d/5))^2)
> +     r
> +   }
>> adaptIntegrate(model, rep(0,3), rep(100,3), tol=1e-4)
> $integral
> [1] 10303.16
> 
> $error
> [1] 1.029888
> 
> $functionEvaluations
> [1] 48609
> 
> $returnCode
> [1] 0
> 
>> system.time(adaptIntegrate(model, rep(0,3), rep(100,3), tol=1e-4))
>   user  system elapsed 
>  0.232   0.002   0.246
> 
> As you can see the second option is the fastest, but the third one is probably more 
> accurate. 
> 
> The function nfw(d) has an analytical primitive when integrated in a sphere If now we 
> reproduce the calculations for cases 1 and 2 in a sphere (named R) of radius 40 
> centered in (50,50,40), the first two methods give me the following result:
> 
> sum(model(R))
> [1] 8204.711
> 
> while the exact solution is
> 
>> 16*pi*(5^3)*(log(5+40) - log(5) - 40/(40+5))
> [1] 8220.516
> 
> However, I can not try the same with cubature since the code is prepared only to be 
> used in hypercubes.

This is the same as one gets with considering this to be a radial symmetric function and transforming the problem to one dimension using the infinitesimal transformation dV = 4*pi*dr:

> f <- function(x) 4*pi*x^2*4.0/((x/5)*(1+(x/5))^2)
> integrate(f, 0, 40 , subdivisions=10000)
8220.516 with absolute error < 0.0012

I wasn't able to achieve convergence to that value using adaptIntegrate using a Boolean variation on Duncan's suggestion:

 model <- function(x) 
   {
      d <- sqrt((x[1]-50)^2 + (x[2]-50)^2 + (x[3]-40)^2)
      r <- 4.0/((d/5)*(1+(d/5))^2)
      dinside <- (d <= 40)*r
    }
> adaptIntegrate(model, rep(0,3), rep(100,3), tol=1e-3, maxEval=1000000)
$integral
[1] 8199.022

$error
[1] 33.33091

$functionEvaluations
[1] 1000065

$returnCode
[1] 0

Without the maxEval the method exceeded my patience. If the real problem is radial symmetric (and it might be noting your domain of investigation) this may offer speed and accuracy advantages.

--
David.

> 
> As I am using non integrable functions I could try to increase the density of the grid 
> and see if I can obtain accurate results before reaching high time costs or study how 
> important is to reach that accuracy, it may be not that important for my algorithm. 
> 
> Anyway, thank you all for you time and ideas.
> 
> Llu?s Hurtado
> IFCA
> 
>> 
>> On Mar 23, 2015, at 3:44 AM, <Lluis.Hurtado at uv.es> <Lluis.Hurtado at uv.es> wrote:
>> 
>>> Dear all,
>>> 
>>> I am currently working with the spatstat package with 3D samples. I am trying to 
>>> evaluate a non analytical function over the window that encloses the sample and I 
>>> need to know which is the fastest way of doing it.
>>> 
>>> The function input is a 3 coordinate position in the window (x,y,z) and a list of 
>>> parameters (a,b,c). The output is a numerical value. 
>>> 
>>> n <- function(x,y,z,a,b,c)
>> 
>> Perhaps:
>> 
>> dfrm <- as.data.frame.table(your_volume_matrix) 
>> n.out <- with(dfrm,  mapply( n, x=x, y=y, z=z, MoreArgs=list(a=a,b=b,c=c) ) _
>> dim(n.out) <- dim(your_volume_matrix)
>> 
>> You don't describe the form of this "3 coordinate position in the window (x,y,z)" so 
> perhaps the arguments will need to be extracted. I took a WAG at one approach. If 
> it's not in long-form, you need configure the array indices for either a volume or 
> surface into a dataframe, perhaps with `expand.grid` or `as.data.frame.table`.
>> 
>> You also don't describe the sort of integration you imagine. Why not a simple sum 
> of that result divided by the volume? I cannot imagine any faster procedure .
>> 
>> 
>>> But I need to do it over the whole volume.
>>> 
>>> For 2 dimensions it can be done with
>>> 
>>> A <- as.im(function,window,parameters)
>>> norm <- integral.im(A)
>>> 
>>> For 3 dimensions I have tried to pass an array of a grid covering the window (like 
> a 
>>> quadrature scheme) and then summing up the output array, but I would like to 
> know if 
>>> there is any faster way of integrating the function.
>>> 
>>> Thank you very much,
>>> 
>>> Llu?s Hurtado
>>> IFCA
>>> www.ifca.unican.es
>>> 
> 
> --
> Llu?s Hurtado-Gil
> Observatori Astron?mic. Universitat de Val?ncia.

David Winsemius
Alameda, CA, USA


From peter.br.lomas at gmail.com  Wed Mar 25 19:21:49 2015
From: peter.br.lomas at gmail.com (Peter Lomas)
Date: Wed, 25 Mar 2015 12:21:49 -0600
Subject: [R] Resizing a graph with a legend in the outer margin - wish for
 functionality like mtext()
Message-ID: <CAOHXzyUM9-mU+ELZR_Nb0PS9fmCdQ1yAxnnnQwY=Au9Kf=seZQ@mail.gmail.com>

Dear R-Helpers

I am attempting to get a legend in the outer margins of a graph that has a
similar flexibility to mtext(), within base graphics.  This is used in a
tool that will end up with graphs of many different coordinates, exported
in many different sizes.  I'm trying to come up with a general solution.
I've used "bottom right" before but I found it interferes with the graphs
frequently.

Here was my best attempt at something general, but then I encountered the
graph re-sizing issue:

x <- 1:100
y <- x +rnorm(100, 0,10)
plot(x,y, xlab="", main="Shrink and Enlarge This Graph")
abline(0,1 ,lty=2)

legend(x=grconvertX(1, from = "ndc", to = "user"),
       y=grconvertY(0, from = "ndc", to = "user"),
       lty=2,
       legend="The legend doesn't rescale nicely",
       xjust=1, yjust=0,
       bty="n",
       xpd=TRUE)

mtext("This example has some text in the outer margin.\nIt rescales
nicely.",
      side = 1, line=3.5, adj=0)


Thanks!
Peter

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Mar 25 19:28:38 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 25 Mar 2015 11:28:38 -0700
Subject: [R] Fast evaluation of functions in 3D domains
In-Reply-To: <D51B3A74-EAC7-4EC1-A6A3-3F0D7A26DE4C@comcast.net>
References: <36EBCEEB-EBEE-4883-9DAF-50FE66BF1E2B@comcast.net>
	<8587793882hurgil@uv.es>
	<D51B3A74-EAC7-4EC1-A6A3-3F0D7A26DE4C@comcast.net>
Message-ID: <50DE8CBC-6A6A-410A-BB98-E61F51606450@comcast.net>


On Mar 25, 2015, at 8:45 AM, David Winsemius wrote:

> 
> On Mar 25, 2015, at 4:55 AM, <Lluis.Hurtado at uv.es> <Lluis.Hurtado at uv.es> wrote:
> 
>> Dear all,
>> 
>> Finally I have tried three different options to integrate a function in a 3D volume. Here 
>> I show a test example. The volume is the box [0,100] x [0,100] x [0,100] and the 
>> function is
>> 
>> nfw(d) = 4/((d/5)*(1+(d/5))^2)

snipped quite a bit.

> 
> This is the same as one gets with considering this to be a radial symmetric function and transforming the problem to one dimension using the infinitesimal transformation dV = 4*pi*dr:

I meant to type:
  dV = 4*pi*r^2*dr:

> 
>> f <- function(x) 4*pi*x^2*4.0/((x/5)*(1+(x/5))^2)

But function definition was correct. 

>> integrate(f, 0, 40 , subdivisions=10000)
> 8220.516 with absolute error < 0.0012
> 
> I wasn't able to achieve convergence to that value using adaptIntegrate using a Boolean variation on Duncan's suggestion:
> 
> model <- function(x) 
>   {
>      d <- sqrt((x[1]-50)^2 + (x[2]-50)^2 + (x[3]-40)^2)
>      r <- 4.0/((d/5)*(1+(d/5))^2)
>      dinside <- (d <= 40)*r
>    }
>> adaptIntegrate(model, rep(0,3), rep(100,3), tol=1e-3, maxEval=1000000)
> $integral
> [1] 8199.022
> 
> $error
> [1] 33.33091
> 
> $functionEvaluations
> [1] 1000065
> 
> $returnCode
> [1] 0
> 
> Without the maxEval the method exceeded my patience. If the real problem is radial symmetric (and it might be noting your domain of investigation) this may offer speed and accuracy advantages.
> 
> --
> David.
snipped

David Winsemius
Alameda, CA, USA


From epw at upenn.edu  Wed Mar 25 18:27:40 2015
From: epw at upenn.edu (Turgidson)
Date: Wed, 25 Mar 2015 10:27:40 -0700 (PDT)
Subject: [R] Converting charter string to vector of numbers
Message-ID: <1427304460123-4705097.post@n4.nabble.com>

Apologies for bringing up an old topic, but I am not finding working answers. 
I am also an R newbie, so I'm still on the steep part of the learning curve.

I have a character string :  "0.5 1 2 3 4"

I need to convert it to a vector of numbers.  I get as far as strsplit(),
which gives me 

 "0.5" "1" "2" "3" "4"

this is still treated by R as a single item.  I need to get it to look like
this:  "0.5", "1", "2", "3", "4"

so that I can use as.numeric() and make it into a vector of numbers...   I
have been going mad because for text operations, commas and quotes are
loaded with meaning, and I keep going around in circles.

Any help would be appreciated

Thanks

Paul





--
View this message in context: http://r.789695.n4.nabble.com/Converting-charter-string-to-vector-of-numbers-tp4705097.html
Sent from the R help mailing list archive at Nabble.com.


From M.Simon at har.mrc.ac.uk  Wed Mar 25 18:14:40 2015
From: M.Simon at har.mrc.ac.uk (Michelle Simon)
Date: Wed, 25 Mar 2015 17:14:40 +0000
Subject: [R] y axis in a stacked bar plot
Message-ID: <D1389D4F.9BC60%m.simon@har.mrc.ac.uk>

Hello,
Below is some simple R code I have used to create a stacked bar chart.  However the y-axis tick marks do not reflect the data.  The minimum and maximum data values I have are 3073351 and 66425013 respectively but the graph has data from 0 and the maximum is different  Data file is attached.  What am I doing wrong?  Please help as I cannot be sure the data is represented correctly in the graph (attached).


fn <-"~/Documents/chr7Data.txt"
x<-read.table(fn,check.names = TRUE, header=T)
d <- data.frame(x)
theChart<-ggplot(d, aes(x=factor(Congenic),y=Position, fill=Strain, theme_rect="white")) + geom_bar(stat='identity', position = "stack" ) + scale_fill_manual(values=c("deepskyblue1", "red2", "green3", "steelblue4", "lightblue4", "gray70")) + ylab(c("Position"))+
ggtitle("Strain specific SNP distribution in the congenics") +

#coord_cartesian(ylim = c(min(d$Position), max(d$Position))) +
#scale_y_continuous(breaks=seq(0, 200000000, 50000000)) +
theme_bw()+
theme(plot.title = element_text(size=23),
                axis.text.x = element_text(size=13, angle=90),    #20 before
                axis.text.y = element_text(size=13),
                panel.border = element_rect(colour="BLACK",size=0.5),
                axis.title.x = element_text(size=12),
                axis.title.y = element_text(size=12,angle = 90),
                panel.background = element_rect(fill="transparent"),
                legend.text=element_text(size=13),
                legend.title=element_text(size=12)
                #plot.background = element_rect(fill = "transparent",colour = NA)
)
png("~/Documents/sendToRGrp.png",950,750)
print(theChart)
dev.off()



Many thanks,
Michelle


This email may have a PROTECTIVE MARKING, for an explanation please see: http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sendToRGrp.png
Type: image/png
Size: 83252 bytes
Desc: sendToRGrp.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150325/a01abb3d/attachment-0001.png>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: chr7Data.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150325/a01abb3d/attachment-0001.txt>

From jdnewmil at dcn.davis.CA.us  Wed Mar 25 20:34:21 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 25 Mar 2015 12:34:21 -0700
Subject: [R] Converting charter string to vector of numbers
In-Reply-To: <1427304460123-4705097.post@n4.nabble.com>
References: <1427304460123-4705097.post@n4.nabble.com>
Message-ID: <642A519F-9A2D-4355-A3CE-EE326217FC29@dcn.davis.CA.us>

No, you don't need the commas. All data in R are vectors, and as.numeric handles vectors just fine.

Keep in mind that what you see on the console is not necessarily what is in memory... the syntax you see or use to input data is just that... a tool for helping you communicate. For example, there are no actual quote marks around character strings in memory either, but they get printed to help us understand that they are character strings. Once you are referring to these values with variables they just work under the hood.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 25, 2015 10:27:40 AM PDT, Turgidson <epw at upenn.edu> wrote:
>Apologies for bringing up an old topic, but I am not finding working
>answers. 
>I am also an R newbie, so I'm still on the steep part of the learning
>curve.
>
>I have a character string :  "0.5 1 2 3 4"
>
>I need to convert it to a vector of numbers.  I get as far as
>strsplit(),
>which gives me 
>
> "0.5" "1" "2" "3" "4"
>
>this is still treated by R as a single item.  I need to get it to look
>like
>this:  "0.5", "1", "2", "3", "4"
>
>so that I can use as.numeric() and make it into a vector of numbers... 
> I
>have been going mad because for text operations, commas and quotes are
>loaded with meaning, and I keep going around in circles.
>
>Any help would be appreciated
>
>Thanks
>
>Paul
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Converting-charter-string-to-vector-of-numbers-tp4705097.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From oreslag at gmail.com  Wed Mar 25 20:43:08 2015
From: oreslag at gmail.com (Steven LeBlanc)
Date: Wed, 25 Mar 2015 12:43:08 -0700
Subject: [R] print and rbind within a for loop
Message-ID: <AA7D64D5-235A-4BD8-B825-74A94F6F50F3@gmail.com>

Greets,

I'm trying to iteratively find solutions to a problem given a range of options. Code is as follows:

sim.app.wald<-function(B=0.1,min=10,max=50,alpha=0.05){
	result<-c(fails=0,n=0)
	for(n in min:max){
		x<-seq(1,n-1,1)
		fhat<-x/n
		se<-sqrt((fhat*(1-fhat))/n)
		ci.wald<-fhat+qnorm(1-(alpha/2))*se
		if(sum(ci.wald[ci.wald<=B])){
#			rbind(cbind(fails=x[ci.wald<=B],n=n),result)
			print(cbind(X=x[ci.wald<=B],n))
		}
#	return(result)
	}
}

If you run it like this, you can readily see what I intend to get out; which is the correct result. If you uncomment the two commented lines, nothing useful obtains.

What am I missing here? This seeming codependence of print() and return() and the failure of rbind() to do anything is quite puzzling.

Best Regards,
Steven
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Mar 25 20:44:28 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 25 Mar 2015 12:44:28 -0700
Subject: [R] Converting charter string to vector of numbers
In-Reply-To: <1427304460123-4705097.post@n4.nabble.com>
References: <1427304460123-4705097.post@n4.nabble.com>
Message-ID: <93EB476A-1700-420C-9F64-37FA59FACAEE@comcast.net>


On Mar 25, 2015, at 10:27 AM, Turgidson wrote:

> Apologies for bringing up an old topic, but I am not finding working answers. 
> I am also an R newbie, so I'm still on the steep part of the learning curve.
> 
> I have a character string :  "0.5 1 2 3 4"
> 
> I need to convert it to a vector of numbers.

The releatively recent additon of teh text parameter to scan lets you do this:

scan(text="0.5 1 2 3 4" )

#Read 5 items
#[1] 0.5 1.0 2.0 3.0 4.0

And the values are of course assign()-able:

 num <- scan(text="0.5 1 2 3 4")
#Read 5 items
 num
#[1] 0.5 1.0 2.0 3.0 4.0

In the old days one needed to use textConnection() and one still needs to do so for readLines which does not use scan().


>  I get as far as strsplit(),
> which gives me 
> 
> "0.5" "1" "2" "3" "4"
> 
> this is still treated by R as a single item.  I need to get it to look like
> this:  "0.5", "1", "2", "3", "4"
> 
> so that I can use as.numeric() and make it into a vector of numbers...   I
> have been going mad because for text operations, commas and quotes are
> loaded with meaning, and I keep going around in circles.
> 
> Any help would be appreciated
> 
> Thanks
> 
> Paul
> 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Converting-charter-string-to-vector-of-numbers-tp4705097.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From oreslag at gmail.com  Wed Mar 25 21:04:15 2015
From: oreslag at gmail.com (Steven LeBlanc)
Date: Wed, 25 Mar 2015 13:04:15 -0700
Subject: [R] print and rbind within a for loop
In-Reply-To: <BABD1BF0F5F0E4468CD18153E6B81D8462236A06@mboxes2.campus.vims.edu>
References: <AA7D64D5-235A-4BD8-B825-74A94F6F50F3@gmail.com>
	<BABD1BF0F5F0E4468CD18153E6B81D8462236A06@mboxes2.campus.vims.edu>
Message-ID: <B93D1228-0ED9-4273-B764-367AD6CAD152@gmail.com>

Hi Dave,

Thank you, but that didn't seem to do it. This code produces the same result:

sim.app.wald<-function(B=0.1,min=10,max=50,alpha=0.05){
	result<-c(fails=0,n=0)
	for(n in min:max){
		x<-seq(1,n-1,1)
		fhat<-x/n
		se<-sqrt((fhat*(1-fhat))/n)
		ci.wald<-fhat+qnorm(1-(alpha/2))*se
		if(sum(ci.wald[ci.wald<=B])){
			result<-rbind(cbind(fails=x[ci.wald<=B],n=n),result)
			print(cbind(X=x[ci.wald<=B],n))
		}
	return(result)
	}
}

Once again, commenting out the return() statement shows the correct output via the print() statement.

Best Regards,
Steven

On Mar 25, 2015, at 12:51 PM, David R Forrest <drf at vims.edu> wrote:

> From looking at it it looks like nothing is done with the results of rbind(), and the return() then exits the loop and routine with the unmodified result.
> 
> Dave
> ________________________________________
> From: R-help [r-help-bounces at r-project.org] on behalf of Steven LeBlanc [oreslag at gmail.com]
> Sent: Wednesday, March 25, 2015 3:43 PM
> To: r-help at R-project.org
> Subject: [R] print and rbind within a for loop
> 
> Greets,
> 
> I'm trying to iteratively find solutions to a problem given a range of options. Code is as follows:
> 
> sim.app.wald<-function(B=0.1,min=10,max=50,alpha=0.05){
>        result<-c(fails=0,n=0)
>        for(n in min:max){
>                x<-seq(1,n-1,1)
>                fhat<-x/n
>                se<-sqrt((fhat*(1-fhat))/n)
>                ci.wald<-fhat+qnorm(1-(alpha/2))*se
>                if(sum(ci.wald[ci.wald<=B])){
> #                       rbind(cbind(fails=x[ci.wald<=B],n=n),result)
>                        print(cbind(X=x[ci.wald<=B],n))
>                }
> #       return(result)
>        }
> }
> 
> If you run it like this, you can readily see what I intend to get out; which is the correct result. If you uncomment the two commented lines, nothing useful obtains.
> 
> What am I missing here? This seeming codependence of print() and return() and the failure of rbind() to do anything is quite puzzling.
> 
> Best Regards,
> Steven
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Mar 25 21:13:09 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 25 Mar 2015 13:13:09 -0700
Subject: [R] print and rbind within a for loop
In-Reply-To: <B93D1228-0ED9-4273-B764-367AD6CAD152@gmail.com>
References: <AA7D64D5-235A-4BD8-B825-74A94F6F50F3@gmail.com>
	<BABD1BF0F5F0E4468CD18153E6B81D8462236A06@mboxes2.campus.vims.edu>
	<B93D1228-0ED9-4273-B764-367AD6CAD152@gmail.com>
Message-ID: <CAF8bMcar2_xqUTgfhoj5x1bkFQkXECQ--7LN3aKYvZtu-sxbZQ@mail.gmail.com>

sim.app.wald<-function(B=0.1,min=10,max=50,alpha=0.05){
        result<-c(fails=0,n=0)
        for(n in min:max){
                x<-seq(1,n-1,1)
                ...
        return(result) # indent!  see what's wrong?
        }
}

Make your indentation (of the return line) correspond to the braces in the
code
and you may see the problem sooner.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Mar 25, 2015 at 1:04 PM, Steven LeBlanc <oreslag at gmail.com> wrote:

> Hi Dave,
>
> Thank you, but that didn't seem to do it. This code produces the same
> result:
>
> sim.app.wald<-function(B=0.1,min=10,max=50,alpha=0.05){
>         result<-c(fails=0,n=0)
>         for(n in min:max){
>                 x<-seq(1,n-1,1)
>                 fhat<-x/n
>                 se<-sqrt((fhat*(1-fhat))/n)
>                 ci.wald<-fhat+qnorm(1-(alpha/2))*se
>                 if(sum(ci.wald[ci.wald<=B])){
>
> result<-rbind(cbind(fails=x[ci.wald<=B],n=n),result)
>                         print(cbind(X=x[ci.wald<=B],n))
>                 }
>         return(result)
>         }
> }
>
> Once again, commenting out the return() statement shows the correct output
> via the print() statement.
>
> Best Regards,
> Steven
>
> On Mar 25, 2015, at 12:51 PM, David R Forrest <drf at vims.edu> wrote:
>
> > From looking at it it looks like nothing is done with the results of
> rbind(), and the return() then exits the loop and routine with the
> unmodified result.
> >
> > Dave
> > ________________________________________
> > From: R-help [r-help-bounces at r-project.org] on behalf of Steven LeBlanc
> [oreslag at gmail.com]
> > Sent: Wednesday, March 25, 2015 3:43 PM
> > To: r-help at R-project.org
> > Subject: [R] print and rbind within a for loop
> >
> > Greets,
> >
> > I'm trying to iteratively find solutions to a problem given a range of
> options. Code is as follows:
> >
> > sim.app.wald<-function(B=0.1,min=10,max=50,alpha=0.05){
> >        result<-c(fails=0,n=0)
> >        for(n in min:max){
> >                x<-seq(1,n-1,1)
> >                fhat<-x/n
> >                se<-sqrt((fhat*(1-fhat))/n)
> >                ci.wald<-fhat+qnorm(1-(alpha/2))*se
> >                if(sum(ci.wald[ci.wald<=B])){
> > #                       rbind(cbind(fails=x[ci.wald<=B],n=n),result)
> >                        print(cbind(X=x[ci.wald<=B],n))
> >                }
> > #       return(result)
> >        }
> > }
> >
> > If you run it like this, you can readily see what I intend to get out;
> which is the correct result. If you uncomment the two commented lines,
> nothing useful obtains.
> >
> > What am I missing here? This seeming codependence of print() and
> return() and the failure of rbind() to do anything is quite puzzling.
> >
> > Best Regards,
> > Steven
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From oreslag at gmail.com  Wed Mar 25 21:19:00 2015
From: oreslag at gmail.com (Steven LeBlanc)
Date: Wed, 25 Mar 2015 13:19:00 -0700
Subject: [R] print and rbind within a for loop
In-Reply-To: <BABD1BF0F5F0E4468CD18153E6B81D8462236A5C@mboxes2.campus.vims.edu>
References: <AA7D64D5-235A-4BD8-B825-74A94F6F50F3@gmail.com>
	<BABD1BF0F5F0E4468CD18153E6B81D8462236A06@mboxes2.campus.vims.edu>,
	<B93D1228-0ED9-4273-B764-367AD6CAD152@gmail.com>
	<BABD1BF0F5F0E4468CD18153E6B81D8462236A5C@mboxes2.campus.vims.edu>
Message-ID: <20E4E4EE-6BE6-4FEA-8708-6AA1178ADC45@gmail.com>

Hi Dave, Bill,

Thank you. That was it! <red face, heavy sigh>

Best Regards,
Steven

On Mar 25, 2015, at 1:11 PM, David R Forrest <drf at vims.edu> wrote:

> I'm away from a computer that can check syntax, but make sure the return is outside of the for loop.  To my eye it looks inside.

	[[alternative HTML version deleted]]


From bbaker at reed.edu  Wed Mar 25 22:01:49 2015
From: bbaker at reed.edu (Benjamin Baker)
Date: Wed, 25 Mar 2015 14:01:49 -0700 (PDT)
Subject: [R] Having trouble with gdata read in
Message-ID: <1427317309103.8c3e545d@Nodemailer>

Trying to read and clean up the FERC data on Advanced Metering infrastructure. Of course it is in XLS for the first two survey years and then converts to XLSX for the final two. Bad enough that it is all in excel, they had to change the survey design and data format as well. Still, I?m sorting through it. However, when I try and read in the 2008 data, I?m getting this error:
###
Wide character in print at /Library/Frameworks/R.framework/Versions/3.1/Resources/library/gdata/perl/xls2csv.pl line 270.
Warning message:
In scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,? :
? EOF within quoted string
###



Here is the code I?m running to get the data:
###
install.packages("gdata")
library("gdata")
fileUrl <- "http://www.ferc.gov/industries/electric/indus-act/demand-response/2008/survey/ami_survey_responses.xls"
download.file(fileUrl, destfile="./ami.data/ami-data2008.xls")
list.files("ami.data")
dateDown.2008 <- date()
ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1, header=TRUE)
###


Reviewed the data in the XLS file, and both ?? and # are present within it. Don?t know how to get the read.xls to ignore them so I can read all the data into my data frame. Tried :
###
ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1, quote="", header=TRUE)
###


And it spits out ?More columns than column names? output.


Been searching this, and I can find some ?solutions? for read.table, but nothing specific to read.xls


Many thanks,


Benjamin Baker



?
Sent from Mailbox
	[[alternative HTML version deleted]]


From jpritikin at pobox.com  Wed Mar 25 21:15:00 2015
From: jpritikin at pobox.com (Joshua N Pritikin)
Date: Wed, 25 Mar 2015 16:15:00 -0400
Subject: [R] including internal data in a package
Message-ID: <20150325201500.GH30972@tailwind>

CRAN check is issuing a complaint,

Found the following calls to data() loading into the global environment:
File ?OpenMx/R/MxAlgebra.R?:
  data(omxSymbolTable)
See section ?Good practice? in ??data?.

I tried placing an rda file in the package's R/ directory, but now I get 
a new CRAN check complaint,

Subdirectory 'R' contains invalid file names:
  ?omxSymbolTable.rda?

Furthermore, I can't figure out how to load this file. I found this 2013 
post,

http://r.789695.n4.nabble.com/Good-practice-for-data-for-R-packages-td4660313.html

"The objects will be available in your NAMESPACE." -- I don't 
understand. Can somebody clarify?

Thanks.

-- 
Joshua N. Pritikin
Department of Psychology
University of Virginia
485 McCormick Rd, Gilmer Hall Room 102
Charlottesville, VA 22904
http://people.virginia.edu/~jnp3bc


From paul at stat.auckland.ac.nz  Wed Mar 25 22:56:14 2015
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Thu, 26 Mar 2015 10:56:14 +1300
Subject: [R] Resizing a graph with a legend in the outer margin - wish
 for functionality like mtext()
In-Reply-To: <CAOHXzyUM9-mU+ELZR_Nb0PS9fmCdQ1yAxnnnQwY=Au9Kf=seZQ@mail.gmail.com>
References: <CAOHXzyUM9-mU+ELZR_Nb0PS9fmCdQ1yAxnnnQwY=Au9Kf=seZQ@mail.gmail.com>
Message-ID: <55132EFE.3020204@stat.auckland.ac.nz>

Hi

You can use the recordGraphics() function for this (if you are careful).
For example ...

x <- 1:100
y <- x +rnorm(100, 0,10)
plot(x,y, xlab="", main="Shrink and Enlarge This Graph")
abline(0,1 ,lty=2)

recordGraphics(
     {
         legend(x=grconvertX(1, from = "ndc", to = "user"),
                y=grconvertY(0, from = "ndc", to = "user"),
                lty=2,
                legend="The legend scales nicely!",
                xjust=1, yjust=0,
                bty="n",
                xpd=TRUE)
     },
     list(), getNamespace("graphics"))

mtext("This example has some text in the outer margin.\nIt rescales 
nicely.",
       side = 1, line=3.5, adj=0)


The important result is that those grConvert*() calls are performed on 
every redraw.

Paul

On 03/26/15 07:21, Peter Lomas wrote:
> Dear R-Helpers
>
> I am attempting to get a legend in the outer margins of a graph that has a
> similar flexibility to mtext(), within base graphics.  This is used in a
> tool that will end up with graphs of many different coordinates, exported
> in many different sizes.  I'm trying to come up with a general solution.
> I've used "bottom right" before but I found it interferes with the graphs
> frequently.
>
> Here was my best attempt at something general, but then I encountered the
> graph re-sizing issue:
>
> x <- 1:100
> y <- x +rnorm(100, 0,10)
> plot(x,y, xlab="", main="Shrink and Enlarge This Graph")
> abline(0,1 ,lty=2)
>
> legend(x=grconvertX(1, from = "ndc", to = "user"),
>         y=grconvertY(0, from = "ndc", to = "user"),
>         lty=2,
>         legend="The legend doesn't rescale nicely",
>         xjust=1, yjust=0,
>         bty="n",
>         xpd=TRUE)
>
> mtext("This example has some text in the outer margin.\nIt rescales
> nicely.",
>        side = 1, line=3.5, adj=0)
>
>
> Thanks!
> Peter
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From ligges at statistik.tu-dortmund.de  Wed Mar 25 23:06:40 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 25 Mar 2015 23:06:40 +0100
Subject: [R] including internal data in a package
In-Reply-To: <20150325201500.GH30972@tailwind>
References: <20150325201500.GH30972@tailwind>
Message-ID: <55133170.2080004@statistik.tu-dortmund.de>



On 25.03.2015 21:15, Joshua N Pritikin wrote:
> CRAN check is issuing a complaint,
>
> Found the following calls to data() loading into the global environment:
> File ?OpenMx/R/MxAlgebra.R?:
>    data(omxSymbolTable)
> See section ?Good practice? in ??data?.

Which says "use a file ?R/sysdata.rda?". So why do you use 
'R/omxSymbolTable.rda' then?

Best,
Uwe Ligges


>
> I tried placing an rda file in the package's R/ directory, but now I get
> a new CRAN check complaint,
>
> Subdirectory 'R' contains invalid file names:
>    ?omxSymbolTable.rda?
>
> Furthermore, I can't figure out how to load this file. I found this 2013
> post,
>
> http://r.789695.n4.nabble.com/Good-practice-for-data-for-R-packages-td4660313.html
>
> "The objects will be available in your NAMESPACE." -- I don't
> understand. Can somebody clarify?
>
> Thanks.
>


From ajdamico at gmail.com  Wed Mar 25 23:50:46 2015
From: ajdamico at gmail.com (Anthony Damico)
Date: Wed, 25 Mar 2015 18:50:46 -0400
Subject: [R] Having trouble with gdata read in
In-Reply-To: <1427317309103.8c3e545d@Nodemailer>
References: <1427317309103.8c3e545d@Nodemailer>
Message-ID: <CAOwvMDxJ2rDSXGkzXRO0cN60wKACazsdaWhU5-_d3XA71hZ0Wg@mail.gmail.com>

maybe

library(xlsx)
tf <- tempfile()
ami <- "
http://www.ferc.gov/industries/electric/indus-act/demand-response/2008/survey/ami_survey_responses.xls
"
download.file( ami , tf , mode = 'wb' )
ami.data2008 <- read.xlsx( tf , sheetIndex = 1 )





On Wed, Mar 25, 2015 at 5:01 PM, Benjamin Baker <bbaker at reed.edu> wrote:

> Trying to read and clean up the FERC data on Advanced Metering
> infrastructure. Of course it is in XLS for the first two survey years and
> then converts to XLSX for the final two. Bad enough that it is all in
> excel, they had to change the survey design and data format as well. Still,
> I?m sorting through it. However, when I try and read in the 2008 data, I?m
> getting this error:
> ###
> Wide character in print at
> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/gdata/perl/
> xls2csv.pl line 270.
> Warning message:
> In scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>   EOF within quoted string
> ###
>
>
>
> Here is the code I?m running to get the data:
> ###
> install.packages("gdata")
> library("gdata")
> fileUrl <- "
> http://www.ferc.gov/industries/electric/indus-act/demand-response/2008/survey/ami_survey_responses.xls
> "
> download.file(fileUrl, destfile="./ami.data/ami-data2008.xls")
> list.files("ami.data")
> dateDown.2008 <- date()
> ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1,
> header=TRUE)
> ###
>
>
> Reviewed the data in the XLS file, and both ?? and # are present within
> it. Don?t know how to get the read.xls to ignore them so I can read all the
> data into my data frame. Tried :
> ###
> ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1, quote="",
> header=TRUE)
> ###
>
>
> And it spits out ?More columns than column names? output.
>
>
> Been searching this, and I can find some ?solutions? for read.table, but
> nothing specific to read.xls
>
>
> Many thanks,
>
>
> Benjamin Baker
>
>
>
> ?
> Sent from Mailbox
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From M.Simon at har.mrc.ac.uk  Thu Mar 26 05:29:40 2015
From: M.Simon at har.mrc.ac.uk (Michelle Simon)
Date: Thu, 26 Mar 2015 04:29:40 +0000
Subject: [R] y axis in a stacked bar plot
Message-ID: <D1393BB2.9BCAF%m.simon@har.mrc.ac.uk>

Hello,
Below is some simple R code I have used to create a stacked bar chart.  However the y-axis tick marks do not reflect the data.  The minimum and maximum data values I have are 3073351 and 25329814 respectively but the graph has data from 0 and the maximum is different  The data file is too large so there is a small sample below.  What am I doing wrong?  Please help as I cannot be sure the data is represented correctly in the graph (attached).

fn <-"~/Documents/chr7Data.txt"
x<-read.table(fn,check.names = TRUE, header=T)
d <- data.frame(x)
theChart<-ggplot(d, aes(x=factor(Congenic),y=Position, fill=Strain, theme_rect="white")) + geom_bar(stat='identity', position = "stack" ) + scale_fill_manual(values=c("deepskyblue1", "red2", "green3", "steelblue4", "lightblue4", "gray70")) + ylab(c("Position"))+
ggtitle("Strain specific SNP distribution in the congenics") +

#coord_cartesian(ylim = c(min(d$Position), max(d$Position))) +
#scale_y_continuous(breaks=seq(0, 200000000, 50000000)) +
theme_bw()+
theme(plot.title = element_text(size=23),
                axis.text.x = element_text(size=13, angle=90),    #20 before
                axis.text.y = element_text(size=13),
                panel.border = element_rect(colour="BLACK",size=0.5),
                axis.title.x = element_text(size=12),
                axis.title.y = element_text(size=12,angle = 90),
                panel.background = element_rect(fill="transparent"),
                legend.text=element_text(size=13),
                legend.title=element_text(size=12)
                #plot.background = element_rect(fill = "transparent",colour = NA)
)
png("~/Documents/sendToRGrp.png",950,750)
print(theChart)
dev.off()

??????????? Sample Data ?????????????
Congenic Position Strain
4201 3073351 hets
4203 3073351 reference
4215 3073351 reference
4333 3073351 cba
4335 3073351 cba
4484 3073351 cba
4485 3073351 reference
4496 3073351 hets
4497 3073351 reference
//lots of data//
4201 25329814 reference
4203 25329814 reference
4215 25329814 cba
4333 25329814 balbc
4335 25329814 balbc
4484 25329814 reference
4485 25329814 reference
4496 25329814 balbc
4497 25329814 hets

Many thanks,
Michy


This email may have a PROTECTIVE MARKING, for an explanation please see: http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sampleData.png
Type: image/png
Size: 83735 bytes
Desc: sampleData.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150326/79ac4b04/attachment.png>

From jdnewmil at dcn.davis.CA.us  Thu Mar 26 05:51:47 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 25 Mar 2015 21:51:47 -0700
Subject: [R] y axis in a stacked bar plot
In-Reply-To: <D1393BB2.9BCAF%m.simon@har.mrc.ac.uk>
References: <D1393BB2.9BCAF%m.simon@har.mrc.ac.uk>
Message-ID: <BDA33D20-D209-4B87-8ED6-61EB46556A69@dcn.davis.CA.us>

I don't understand what you expect. Stacked bar charts add the values together. Perhaps that is not really how you want to represent these data?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 25, 2015 9:29:40 PM PDT, Michelle Simon <M.Simon at har.mrc.ac.uk> wrote:
>Hello,
>Below is some simple R code I have used to create a stacked bar chart. 
>However the y-axis tick marks do not reflect the data.  The minimum and
>maximum data values I have are 3073351 and 25329814 respectively but
>the graph has data from 0 and the maximum is different  The data file
>is too large so there is a small sample below.  What am I doing wrong? 
>Please help as I cannot be sure the data is represented correctly in
>the graph (attached).
>
>fn <-"~/Documents/chr7Data.txt"
>x<-read.table(fn,check.names = TRUE, header=T)
>d <- data.frame(x)
>theChart<-ggplot(d, aes(x=factor(Congenic),y=Position, fill=Strain,
>theme_rect="white")) + geom_bar(stat='identity', position = "stack" ) +
>scale_fill_manual(values=c("deepskyblue1", "red2", "green3",
>"steelblue4", "lightblue4", "gray70")) + ylab(c("Position"))+
>ggtitle("Strain specific SNP distribution in the congenics") +
>
>#coord_cartesian(ylim = c(min(d$Position), max(d$Position))) +
>#scale_y_continuous(breaks=seq(0, 200000000, 50000000)) +
>theme_bw()+
>theme(plot.title = element_text(size=23),
>           axis.text.x = element_text(size=13, angle=90),    #20 before
>                axis.text.y = element_text(size=13),
>                panel.border = element_rect(colour="BLACK",size=0.5),
>                axis.title.x = element_text(size=12),
>                axis.title.y = element_text(size=12,angle = 90),
>                panel.background = element_rect(fill="transparent"),
>                legend.text=element_text(size=13),
>                legend.title=element_text(size=12)
>      #plot.background = element_rect(fill = "transparent",colour = NA)
>)
>png("~/Documents/sendToRGrp.png",950,750)
>print(theChart)
>dev.off()
>
>??????????? Sample Data ?????????????
>Congenic Position Strain
>4201 3073351 hets
>4203 3073351 reference
>4215 3073351 reference
>4333 3073351 cba
>4335 3073351 cba
>4484 3073351 cba
>4485 3073351 reference
>4496 3073351 hets
>4497 3073351 reference
>//lots of data//
>4201 25329814 reference
>4203 25329814 reference
>4215 25329814 cba
>4333 25329814 balbc
>4335 25329814 balbc
>4484 25329814 reference
>4485 25329814 reference
>4496 25329814 balbc
>4497 25329814 hets
>
>Many thanks,
>Michy
>
>
>This email may have a PROTECTIVE MARKING, for an explanation please
>see:
>http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From p_connolly at slingshot.co.nz  Thu Mar 26 07:48:52 2015
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Thu, 26 Mar 2015 19:48:52 +1300
Subject: [R] Using and abusing %>% (was Re: Why can't I access this type?)
In-Reply-To: <5512C2BA.6020301@gmail.com>
References: <CAJ=2b04qLmoA8W--=dsv2vqMHkG1Y7Tv_QQx_9D78oopJku+Yg@mail.gmail.com>
	<28E315E85F1.00000296jrkrideau@inbox.com>
	<20150325084041.GA2875@slingshot.co.nz>
	<5512C2BA.6020301@gmail.com>
Message-ID: <20150326064852.GB2875@slingshot.co.nz>

On Wed, 25-Mar-2015 at 03:14PM +0100, Henric Winell wrote:

...

|> Well...  Opinions may perhaps differ, but apart from '%>%' being
|> butt-ugly it's also fairly slow:

Beauty, it is said, is in the eye of the beholder.  I'm impressed by
the way using %>% reduces or eliminates complicated nested brackets.
In this tiny example it's not obvious but it's very clear if the
objective is to sort the dataframe by three or four columns and
various lots of aggregation then returning a largish number of
consecutive columns, omitting the rest.  It's very easy to see what's
going on without the need for intermediate objects.

|>
|>  .....

|> Unit: microseconds
|> 
|>    expr
|>  subset(all.states, all.states$Frost > 150, select = c("state",
|> "Frost"))
|>                        all.states[all.states$Frost > 150,
|> c("state", "Frost")]
|>                    all.states %>% filter(Frost > 150) %>%
|> select(state, Frost)
|>       min       lq      mean    median        uq      max neval cld
|>   139.112  148.673  163.3960  159.1760  170.7895 1763.200  1000  b
|>   104.039  111.973  127.2138  120.4395  128.6640 1381.809  1000 a
|>  1010.076 1033.519 1133.1469 1107.8480 1175.1800 2932.206  1000   c

It's no surprise that instructing a computer in something closer to
human language is an order of magnitude slower.  I'm sure you'd get
something even quicker using machine code.  I spend 3 or 4 orders of
magnitude more time writing code than running it.  It's much more
important to me to be able to read and modify than it is to have it
run at optimum speed.

|> 
|> Of course, this doesn't matter for interactive one-off use.  But
|> lately I've seen examples of the '%>%' operator creeping into
|> functions in packages. 

That could indicate that %>% is seductively easy to use.  It's
probably true that there are places where it should be done the hard
way.


|>  However, it would be nice to see a fast pipe operator as part of
|> base R.

|> 
|> 
|> Henric Winell
|> 

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From ntfredo at gmail.com  Thu Mar 26 08:51:04 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Thu, 26 Mar 2015 10:51:04 +0300
Subject: [R] Fitting a line on trellis plot
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED672CCE61B8@GOLD.corp.lgc-group.com>
References: <CAGh51gS9PF6u0rEUGgPVhxqCcSFqNw8HArFK_1myzdb8jmr7Hw@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED672CCE61B8@GOLD.corp.lgc-group.com>
Message-ID: <CAGh51gQFw+ipYzbtWmjH_GgOF0BPNzuMg3Rs9wVQ7JL-n1DmyA@mail.gmail.com>

Thanks for the help.

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Wed, Mar 25, 2015 at 4:48 PM, S Ellison <S.Ellison at lgcgroup.com> wrote:

>
> > Call:
> > lm(formula = curr_data[[tmin_col]] ~ curr_data[[year_col]] -
> >     1 | curr_data[[month_col]])
>
>
> First, this is not a sensible formula for lm; lm() does not use '|' to
> denote grouping. It would be a valid formula for xyplot, in which |
> specifies grouping variables. In lm(), '|' is simply being treated as 'or',
> which is why one of your coefficients is for ' curr_data[[year_col]]  |
> curr_data[[month_col]]TRUE'
>
> Second, you should not normally need things like curr_data[[month_col]],
> either in lm or xyplot. If curr_data is a data frame, things like
>
> lm(tmin ~ year, data=curr_data)
>
> should work.
>
> Third, 'nested' models in lm use the nesting operator '/', not '|'. So if
> you want 12 lines with separate intercept and gradient from an lm, you need
> (with month as a factor and the default intercept suppressed)
> lm(tmin~month+year/month -1, data=curr_data) #-1 suppresses the intercept
> and provides a zero-based intercept for each month
>
> This gives you 12 'month' intercepts and one gradient per month. If you
> wanted a common intercept you'd do
> lm(tmin~ year/month, data=curr_data)
> But beware; the coefficients in both cases cannot be interpreted as a
> simple gradient and intercept for each month: if I recall correctly, the
> gradients for month2 and on are modelled as an additive increment on the
> first month gradient. Use predict() if you want an easy way to predict a
> value for a given (possibly fractional) time of year and 'month'.
> [Incidentally I don?t immediately see why that is a sensible thing to do -
> this fits a monthly summary against a numeric year. But I'm going to assume
> you know what you want there.]
>
> Finally, though, this model will not help you much with lattice as there's
> no _simple_ way of putting those lines on different panels in a lattice
> plot. If you just want a line on each of 12 panels, that's much easier. You
> can  use the panel() function with panel.lmline to put it there. For
> example, if you want to plot a line over the data, use
>
> xyplot(tmin~year|month, curr_data,
>         panel=function(x, y, ...) {
>                 panel.xyplot(x, y, ...)
>                 panel.lmline(x, y, ...)
>         }
> )
>
>
> S Ellison
>
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:18}}


From drjimlemon at gmail.com  Thu Mar 26 10:27:29 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 26 Mar 2015 20:27:29 +1100
Subject: [R] y axis in a stacked bar plot
In-Reply-To: <BDA33D20-D209-4B87-8ED6-61EB46556A69@dcn.davis.CA.us>
References: <D1393BB2.9BCAF%m.simon@har.mrc.ac.uk>
	<BDA33D20-D209-4B87-8ED6-61EB46556A69@dcn.davis.CA.us>
Message-ID: <CA+8X3fX4k-K8XPUBihg5W-NKFZdauNG9Mx5cfWL6N_XH2dd5qw@mail.gmail.com>

Hi Michy,
I agree with Jeff that you probably don't want a stacked bar chart. What
you describe appears to be a display of relative positions of genetic
elements in different strains of mice and the place to ask is most likely
the Bioconductor mailing list.

Jim


On Thu, Mar 26, 2015 at 3:51 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I don't understand what you expect. Stacked bar charts add the values
> together. Perhaps that is not really how you want to represent these data?
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On March 25, 2015 9:29:40 PM PDT, Michelle Simon <M.Simon at har.mrc.ac.uk>
> wrote:
> >Hello,
> >Below is some simple R code I have used to create a stacked bar chart.
> >However the y-axis tick marks do not reflect the data.  The minimum and
> >maximum data values I have are 3073351 and 25329814 respectively but
> >the graph has data from 0 and the maximum is different  The data file
> >is too large so there is a small sample below.  What am I doing wrong?
> >Please help as I cannot be sure the data is represented correctly in
> >the graph (attached).
> >
> >fn <-"~/Documents/chr7Data.txt"
> >x<-read.table(fn,check.names = TRUE, header=T)
> >d <- data.frame(x)
> >theChart<-ggplot(d, aes(x=factor(Congenic),y=Position, fill=Strain,
> >theme_rect="white")) + geom_bar(stat='identity', position = "stack" ) +
> >scale_fill_manual(values=c("deepskyblue1", "red2", "green3",
> >"steelblue4", "lightblue4", "gray70")) + ylab(c("Position"))+
> >ggtitle("Strain specific SNP distribution in the congenics") +
> >
> >#coord_cartesian(ylim = c(min(d$Position), max(d$Position))) +
> >#scale_y_continuous(breaks=seq(0, 200000000, 50000000)) +
> >theme_bw()+
> >theme(plot.title = element_text(size=23),
> >           axis.text.x = element_text(size=13, angle=90),    #20 before
> >                axis.text.y = element_text(size=13),
> >                panel.border = element_rect(colour="BLACK",size=0.5),
> >                axis.title.x = element_text(size=12),
> >                axis.title.y = element_text(size=12,angle = 90),
> >                panel.background = element_rect(fill="transparent"),
> >                legend.text=element_text(size=13),
> >                legend.title=element_text(size=12)
> >      #plot.background = element_rect(fill = "transparent",colour = NA)
> >)
> >png("~/Documents/sendToRGrp.png",950,750)
> >print(theChart)
> >dev.off()
> >
> >??????????? Sample Data ?????????????
> >Congenic Position Strain
> >4201 3073351 hets
> >4203 3073351 reference
> >4215 3073351 reference
> >4333 3073351 cba
> >4335 3073351 cba
> >4484 3073351 cba
> >4485 3073351 reference
> >4496 3073351 hets
> >4497 3073351 reference
> >//lots of data//
> >4201 25329814 reference
> >4203 25329814 reference
> >4215 25329814 cba
> >4333 25329814 balbc
> >4335 25329814 balbc
> >4484 25329814 reference
> >4485 25329814 reference
> >4496 25329814 balbc
> >4497 25329814 hets
> >
> >Many thanks,
> >Michy
> >
> >
> >This email may have a PROTECTIVE MARKING, for an explanation please
> >see:
> >
> http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm
> >
> >
> >------------------------------------------------------------------------
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Thu Mar 26 13:15:14 2015
From: jholtman at gmail.com (jim holtman)
Date: Thu, 26 Mar 2015 08:15:14 -0400
Subject: [R] Having trouble with gdata read in
In-Reply-To: <1427317309103.8c3e545d@Nodemailer>
References: <1427317309103.8c3e545d@Nodemailer>
Message-ID: <CAAxdm-5aTbG3q0jvaWWKfKw6fNWJE=YeD-e-XtwcZVqF1BMVZA@mail.gmail.com>

My suggestion is to use XLConnect to read the file:


> x <-
"C:\\Users\\jh52822\\AppData\\Local\\Temp\\Rtmp6nVgFC\\file385c632aba3.xls"
> require(XLConnect)
Loading required package: XLConnect
Loading required package: XLConnectJars
XLConnect 0.2-10 by Mirai Solutions GmbH [aut],
  Martin Studer [cre],
  The Apache Software Foundation [ctb, cph] (Apache POI, Apache Commons
    Codec),
  Stephen Colebourne [ctb, cph] (Joda-Time Java library)
http://www.mirai-solutions.com ,
http://miraisolutions.wordpress.com
> input <- f.readXLSheet(x, 1)
>
> str(input)
'data.frame':   2266 obs. of  51 variables:
 $ EIA                                  : num  34 59 87 97 108 118 123 149
150 157 ...
 $ Entity.Name                          : chr  "City of Abbeville" "City of
Abbeville" "City of Ada" "Adams Electric Cooperative" ...
 $ State                                : chr  "SC" "LA" "MN" "IL" ...
 $ NERC.Region                          : chr  "SERC" "SPP" "MRO" "SERC" ...
 $ Filing.Order                         : num  12 11 1237 392 252 ...
 $ Q5.MultRegion                        : chr  "" "" "" "" ...
 $ Q6.OwnMeters.                        : chr  "Yes" "Yes" "Yes" "Yes" ...
 $ Q7.ResMeters                         : num  3051 4253 857 8154 33670 ...
 $ Q7.ComMeters                         : num  531 972 132 155 1719 ...
 $ Q7.IntMeters                         : num  0 19 32 NA 626 NA 29 0 2 NA
...
 $ Q7.TransMeters                       : num  0 NA NA NA NA NA NA 0 0 NA
...
 $ Q7.OtherMeters                       : num  0 NA NA 57 NA NA NA 0 0 NA
...
 $ Q7...total.meters                    : num  3582 5244 1021 8366 36015 ...
 $ Q8.15Min.ResAMI                      : num  0 NA NA NA NA NA NA NA NA NA
...
 $ Q8.15Min.ComAMI                      : num  0 NA NA 155 NA NA NA NA NA
NA ...
 $ Q8.15Min.IndAMI                      : num  0 NA NA NA NA NA NA NA NA NA
...
 $ Q8.15Min.TransAMI                    : num  0 NA NA NA NA NA NA NA NA NA
...
 $ Q8.15Min.OtherAMI                    : num  0 NA NA NA NA NA NA NA NA NA
...
 $ Q8.15Min.TotalAMI                    : num  0 0 0 155 0 0 0 0 0 0 ...
 $ Q8.Hourly.ResAMI                     : num  0 NA NA NA 16100 NA NA NA NA
NA ...
 $ Q8.Hourly.ComAMI                     : num  0 NA NA NA 1600 NA NA NA NA
NA ...
....



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Mar 25, 2015 at 5:01 PM, Benjamin Baker <bbaker at reed.edu> wrote:

> Trying to read and clean up the FERC data on Advanced Metering
> infrastructure. Of course it is in XLS for the first two survey years and
> then converts to XLSX for the final two. Bad enough that it is all in
> excel, they had to change the survey design and data format as well. Still,
> I?m sorting through it. However, when I try and read in the 2008 data, I?m
> getting this error:
> ###
> Wide character in print at
> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/gdata/perl/
> xls2csv.pl line 270.
> Warning message:
> In scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>   EOF within quoted string
> ###
>
>
>
> Here is the code I?m running to get the data:
> ###
> install.packages("gdata")
> library("gdata")
> fileUrl <- "
> http://www.ferc.gov/industries/electric/indus-act/demand-response/2008/survey/ami_survey_responses.xls
> "
> download.file(fileUrl, destfile="./ami.data/ami-data2008.xls")
> list.files("ami.data")
> dateDown.2008 <- date()
> ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1,
> header=TRUE)
> ###
>
>
> Reviewed the data in the XLS file, and both ?? and # are present within
> it. Don?t know how to get the read.xls to ignore them so I can read all the
> data into my data frame. Tried :
> ###
> ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1, quote="",
> header=TRUE)
> ###
>
>
> And it spits out ?More columns than column names? output.
>
>
> Been searching this, and I can find some ?solutions? for read.table, but
> nothing specific to read.xls
>
>
> Many thanks,
>
>
> Benjamin Baker
>
>
>
> ?
> Sent from Mailbox
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From amado at cambrasabadell.org  Thu Mar 26 09:52:39 2015
From: amado at cambrasabadell.org (=?iso-8859-1?Q?Manel_Amado_Mart=ED?=)
Date: Thu, 26 Mar 2015 08:52:39 +0000
Subject: [R] Converting charter string to vector of numbers (Turgidson)
Message-ID: <AM2PR05MB120246768842730A20AF78ACC6080@AM2PR05MB1202.eurprd05.prod.outlook.com>

Hi,

See that strsplit() retorns a list object. Then, to transform a character vector (that is an element into the list), to a num?ric vector, you should access directly to that element to aply as.numeric. The code is:

aux<-"0.5 1 2 3 4"
vectnum<-strsplit(aux," ")
class(vectnum)	## see that is returning a list
numaux<-as.numeric(vectnum[[1]])	## get the nummerical vector form the vector object that stays into the vectnum list


Message: 20
Date: Wed, 25 Mar 2015 10:27:40 -0700 (PDT)
From: Turgidson <epw at upenn.edu>
To: r-help at r-project.org
Subject: [R] Converting charter string to vector of numbers
Message-ID: <1427304460123-4705097.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

Apologies for bringing up an old topic, but I am not finding working answers. 
I am also an R newbie, so I'm still on the steep part of the learning curve.

I have a character string :  "0.5 1 2 3 4"

I need to convert it to a vector of numbers.  I get as far as strsplit(),
which gives me 

 "0.5" "1" "2" "3" "4"

this is still treated by R as a single item.  I need to get it to look like
this:  "0.5", "1", "2", "3", "4"

so that I can use as.numeric() and make it into a vector of numbers...   I
have been going mad because for text operations, commas and quotes are
loaded with meaning, and I keep going around in circles.

Any help would be appreciated

Thanks

Paul





--
View this message in context: http://r.789695.n4.nabble.com/Converting-charter-string-to-vector-of-numbers-tp4705097.html
Sent from the R help mailing list archive at Nabble.com.


    Manel Amado i Mart?
Cap d'Assessoria de Comer? Interior
amado at cambrasabadell.org
Tel. 93 745 12 63 . Fax 93 745 12 64      
Av. Francesc Maci?, 35 . 08206 Sabadell
Apt. corr. 119 . www.cambrasabadell.org  


From erinm.hodgess at gmail.com  Thu Mar 26 19:22:14 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 26 Mar 2015 14:22:14 -0400
Subject: [R]  list output
Message-ID: <CACxE24mpsTpM2n-L9+NdD7HV_ODMxAr3vprvdJiasux67kieHw@mail.gmail.com>

Hello!

I am having some trouble with some list output.

Here is my code:
geobunch <- function(y) {

          out <- vector("list",3)
          aic <- numeric(length=3)
          print(str(out))
          for(i in 1:3) {

          x <- geomin(y,i)
          print(i)
          print(x)
          print(str(x))
          out[i]$phi_0 <- x$phi_0
          out[i]$maxlike <- x$maxlike
          out[i]$bigp <- x$bigp
          aic[i] <- -2*out[i]$maxlike + (2*(i+1))
}
          minaic <- which(aic==min(aic))
          minout <- out[unlist(minaic)]
          return(minout)
}

And here is the output:
> geobunch(ez2a)
List of 3
 $ : NULL
 $ : NULL
 $ : NULL
NULL
[1] 1
$phi_0
[1] 2.856428

$bigp
[1] 0.1584016

$maxlike
[1] -473.0203

List of 3
 $ phi_0  : num 2.86
 $ bigp   : num 0.158
 $ maxlike: num -473
NULL
Error in aic[i] <- -2 * out[i]$maxlike + (2 * (i + 1)) :
  replacement has length zero
In addition: Warning messages:
1: In out[i]$phi_0 <- x$phi_0 :
  number of items to replace is not a multiple of replacement length
2: In out[i]$maxlike <- x$maxlike :
  number of items to replace is not a multiple of replacement length
3: In out[i]$bigp <- x$bigp :
  number of items to replace is not a multiple of replacement length
>

I know that the problem is in how I am setting up the "out" variable, but
I'm not sure how to correct it.  Also, the bigp variable can take on
different lengths.

This is on R version 3.1.3, on Ubuntu 14.04.

Thank you so much for any help.

Sincerely,
Erin



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Mar 26 19:41:00 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 26 Mar 2015 19:41:00 +0100
Subject: [R] list output
In-Reply-To: <CACxE24mpsTpM2n-L9+NdD7HV_ODMxAr3vprvdJiasux67kieHw@mail.gmail.com>
References: <CACxE24mpsTpM2n-L9+NdD7HV_ODMxAr3vprvdJiasux67kieHw@mail.gmail.com>
Message-ID: <0B170CF4-E817-4E31-A90D-4BB07C292E2B@gmail.com>

Erin,

I think you'll have heard people requesting _reproducible_ examples several times by now... This one isn't.

Offhand, I'd suspect that the issue has to do with your single-bracket indexing of the list "out". Try out[[i]].

-Peter

> On 26 Mar 2015, at 19:22 , Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> 
> Hello!
> 
> I am having some trouble with some list output.
> 
> Here is my code:
> geobunch <- function(y) {
> 
>          out <- vector("list",3)
>          aic <- numeric(length=3)
>          print(str(out))
>          for(i in 1:3) {
> 
>          x <- geomin(y,i)
>          print(i)
>          print(x)
>          print(str(x))
>          out[i]$phi_0 <- x$phi_0
>          out[i]$maxlike <- x$maxlike
>          out[i]$bigp <- x$bigp
>          aic[i] <- -2*out[i]$maxlike + (2*(i+1))
> }
>          minaic <- which(aic==min(aic))
>          minout <- out[unlist(minaic)]
>          return(minout)
> }
> 
> And here is the output:
>> geobunch(ez2a)
> List of 3
> $ : NULL
> $ : NULL
> $ : NULL
> NULL
> [1] 1
> $phi_0
> [1] 2.856428
> 
> $bigp
> [1] 0.1584016
> 
> $maxlike
> [1] -473.0203
> 
> List of 3
> $ phi_0  : num 2.86
> $ bigp   : num 0.158
> $ maxlike: num -473
> NULL
> Error in aic[i] <- -2 * out[i]$maxlike + (2 * (i + 1)) :
>  replacement has length zero
> In addition: Warning messages:
> 1: In out[i]$phi_0 <- x$phi_0 :
>  number of items to replace is not a multiple of replacement length
> 2: In out[i]$maxlike <- x$maxlike :
>  number of items to replace is not a multiple of replacement length
> 3: In out[i]$bigp <- x$bigp :
>  number of items to replace is not a multiple of replacement length
>> 
> 
> I know that the problem is in how I am setting up the "out" variable, but
> I'm not sure how to correct it.  Also, the bigp variable can take on
> different lengths.
> 
> This is on R version 3.1.3, on Ubuntu 14.04.
> 
> Thank you so much for any help.
> 
> Sincerely,
> Erin
> 
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From macqueen1 at llnl.gov  Thu Mar 26 20:21:48 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 26 Mar 2015 19:21:48 +0000
Subject: [R] list output
In-Reply-To: <CACxE24mpsTpM2n-L9+NdD7HV_ODMxAr3vprvdJiasux67kieHw@mail.gmail.com>
References: <CACxE24mpsTpM2n-L9+NdD7HV_ODMxAr3vprvdJiasux67kieHw@mail.gmail.com>
Message-ID: <D139A6B3.123C00%macqueen1@llnl.gov>

I don't think you are correctly keeping track of the structure of your
objects.
(and my email software may mess up the indentation, but I can't prevent it)


I have not tested, but try replacing

   out[i]$phi_0 <- x$phi_0
   out[i]$maxlike <- x$maxlike
   out[i]$bigp <- x$bigp

with

   out[[i]] <- list(phi_0=x$phi_0,
                    maxlike=x$maxlike,
                    bigp=x$bigp
                   )

(double bracket, as Peter suggested)

Then also replace
  aic[i] <- -2*out[i]$maxlike + (2*(i+1))
with
 aic[i] <- -2*out[[i]]$maxlike + (2*(i+1))

To begin understanding this, see this little sequence:
> foo <- vector('list',3)
> foo[[2]] <- list(a=1, b=2)
> foo[2]$a
NULL
> foo[[2]]$a
[1] 1




Also, which() does not return a list object as you are using it, so there
is no reason to unlist() it. Might as well use
  which.min(minaic)
while you're at it.

So replace your last three lines with
  out[which.min(minaic)]
as the last line of your function, before the closing }

No need to use return()

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/26/15, 11:22 AM, "Erin Hodgess" <erinm.hodgess at gmail.com> wrote:

>Hello!
>
>I am having some trouble with some list output.
>
>Here is my code:
>geobunch <- function(y) {
>
>          out <- vector("list",3)
>          aic <- numeric(length=3)
>          print(str(out))
>          for(i in 1:3) {
>
>          x <- geomin(y,i)
>          print(i)
>          print(x)
>          print(str(x))
>          out[i]$phi_0 <- x$phi_0
>          out[i]$maxlike <- x$maxlike
>          out[i]$bigp <- x$bigp
>          aic[i] <- -2*out[i]$maxlike + (2*(i+1))
>}
>          minaic <- which(aic==min(aic))
>          minout <- out[unlist(minaic)]
>          return(minout)
>}
>
>And here is the output:
>> geobunch(ez2a)
>List of 3
> $ : NULL
> $ : NULL
> $ : NULL
>NULL
>[1] 1
>$phi_0
>[1] 2.856428
>
>$bigp
>[1] 0.1584016
>
>$maxlike
>[1] -473.0203
>
>List of 3
> $ phi_0  : num 2.86
> $ bigp   : num 0.158
> $ maxlike: num -473
>NULL
>Error in aic[i] <- -2 * out[i]$maxlike + (2 * (i + 1)) :
>  replacement has length zero
>In addition: Warning messages:
>1: In out[i]$phi_0 <- x$phi_0 :
>  number of items to replace is not a multiple of replacement length
>2: In out[i]$maxlike <- x$maxlike :
>  number of items to replace is not a multiple of replacement length
>3: In out[i]$bigp <- x$bigp :
>  number of items to replace is not a multiple of replacement length
>>
>
>I know that the problem is in how I am setting up the "out" variable, but
>I'm not sure how to correct it.  Also, the bigp variable can take on
>different lengths.
>
>This is on R version 3.1.3, on Ubuntu 14.04.
>
>Thank you so much for any help.
>
>Sincerely,
>Erin
>
>
>
>-- 
>Erin Hodgess
>Associate Professor
>Department of Mathematical and Statistics
>University of Houston - Downtown
>mailto: erinm.hodgess at gmail.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From erinm.hodgess at gmail.com  Thu Mar 26 20:36:31 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 26 Mar 2015 15:36:31 -0400
Subject: [R] list output
In-Reply-To: <D139A6B3.123C00%macqueen1@llnl.gov>
References: <CACxE24mpsTpM2n-L9+NdD7HV_ODMxAr3vprvdJiasux67kieHw@mail.gmail.com>
	<D139A6B3.123C00%macqueen1@llnl.gov>
Message-ID: <CACxE24=SwyskfhaBdgDtGt4abOJgaEA2f0x5GMXSOdeb=dvMjw@mail.gmail.com>

It's the double bracket issue.

I replaced that, and all is well.

Thanks to Peter and Don.

Sincerely,
Erin


On Thu, Mar 26, 2015 at 3:21 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> I don't think you are correctly keeping track of the structure of your
> objects.
> (and my email software may mess up the indentation, but I can't prevent it)
>
>
> I have not tested, but try replacing
>
>    out[i]$phi_0 <- x$phi_0
>    out[i]$maxlike <- x$maxlike
>    out[i]$bigp <- x$bigp
>
> with
>
>    out[[i]] <- list(phi_0=x$phi_0,
>                     maxlike=x$maxlike,
>                     bigp=x$bigp
>                    )
>
> (double bracket, as Peter suggested)
>
> Then also replace
>   aic[i] <- -2*out[i]$maxlike + (2*(i+1))
> with
>  aic[i] <- -2*out[[i]]$maxlike + (2*(i+1))
>
> To begin understanding this, see this little sequence:
> > foo <- vector('list',3)
> > foo[[2]] <- list(a=1, b=2)
> > foo[2]$a
> NULL
> > foo[[2]]$a
> [1] 1
>
>
>
>
> Also, which() does not return a list object as you are using it, so there
> is no reason to unlist() it. Might as well use
>   which.min(minaic)
> while you're at it.
>
> So replace your last three lines with
>   out[which.min(minaic)]
> as the last line of your function, before the closing }
>
> No need to use return()
>
> -Don
>
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 3/26/15, 11:22 AM, "Erin Hodgess" <erinm.hodgess at gmail.com> wrote:
>
> >Hello!
> >
> >I am having some trouble with some list output.
> >
> >Here is my code:
> >geobunch <- function(y) {
> >
> >          out <- vector("list",3)
> >          aic <- numeric(length=3)
> >          print(str(out))
> >          for(i in 1:3) {
> >
> >          x <- geomin(y,i)
> >          print(i)
> >          print(x)
> >          print(str(x))
> >          out[i]$phi_0 <- x$phi_0
> >          out[i]$maxlike <- x$maxlike
> >          out[i]$bigp <- x$bigp
> >          aic[i] <- -2*out[i]$maxlike + (2*(i+1))
> >}
> >          minaic <- which(aic==min(aic))
> >          minout <- out[unlist(minaic)]
> >          return(minout)
> >}
> >
> >And here is the output:
> >> geobunch(ez2a)
> >List of 3
> > $ : NULL
> > $ : NULL
> > $ : NULL
> >NULL
> >[1] 1
> >$phi_0
> >[1] 2.856428
> >
> >$bigp
> >[1] 0.1584016
> >
> >$maxlike
> >[1] -473.0203
> >
> >List of 3
> > $ phi_0  : num 2.86
> > $ bigp   : num 0.158
> > $ maxlike: num -473
> >NULL
> >Error in aic[i] <- -2 * out[i]$maxlike + (2 * (i + 1)) :
> >  replacement has length zero
> >In addition: Warning messages:
> >1: In out[i]$phi_0 <- x$phi_0 :
> >  number of items to replace is not a multiple of replacement length
> >2: In out[i]$maxlike <- x$maxlike :
> >  number of items to replace is not a multiple of replacement length
> >3: In out[i]$bigp <- x$bigp :
> >  number of items to replace is not a multiple of replacement length
> >>
> >
> >I know that the problem is in how I am setting up the "out" variable, but
> >I'm not sure how to correct it.  Also, the bigp variable can take on
> >different lengths.
> >
> >This is on R version 3.1.3, on Ubuntu 14.04.
> >
> >Thank you so much for any help.
> >
> >Sincerely,
> >Erin
> >
> >
> >
> >--
> >Erin Hodgess
> >Associate Professor
> >Department of Mathematical and Statistics
> >University of Houston - Downtown
> >mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Thu Mar 26 20:49:54 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Thu, 26 Mar 2015 19:49:54 +0000
Subject: [R] new package: canceR
Message-ID: <CALJKBv9tY0iH+A=iO2VBqZYcrC68v-KTLCL6DGucZXMgGtJd7w@mail.gmail.com>

Dear All,
I am pleased to announce the release of new package named canceR
<http://www.bioconductor.org/packages/devel/bioc/html/canceR.html>. The
main goal of this package is to facilitate to NOT R user the access of
complex cancer genomics data hosted by the MSKCC and available through
cgdsr CRAN package. By simple clic, the user can combine Cases (Samples)
and Genetic profiles to get rapidly without programming skills all
available cancer genomics data (CNA, mRNA, Methylation, Mutation, miRNA,
RPPA) in exportable table.
Compared to cBioportal <http://www.cbioportal.org/>, canceR allows user to
focus on some Studies and get specific data as Amino Acid changes in
Mutation Data for selected gene list.

The second part of canceR focus on modeling. I selected some interesting
fonctions from others packages (see Vignette) and I adapted them to
1-Associate phenotypes (gene / variable ) to disease
2-Classify genes by phenotype or disease
3-Enrichment gene expression data using GSEA-R (Broad Institute)

Other function is in progress to facilitated the visualization of multi
Dimensional Genomics Data  for multiples cancers using Circos styles.

Please fill free for any suggestions.

Karim Mezhoud

	[[alternative HTML version deleted]]


From sjkiss at gmail.com  Thu Mar 26 22:11:50 2015
From: sjkiss at gmail.com (Simon Kiss)
Date: Thu, 26 Mar 2015 17:11:50 -0400
Subject: [R] basic help with as.Date()
Message-ID: <607C14A8-8809-43C8-A002-20E9CFB888EC@gmail.com>

Hi there: normally I?m quite comfortable with as.Date(). But this data set is causing problems.

The core of the data frame looks like the sample data frame below, but my attempt to convert df$mydate to a date object returns only NA. Can anyone provide a suggestion?

Thank you, Simon Kiss

#sample data frame
df<-data.frame(mydate=factor(c('Jan-15', 'Feb-13', 'Mar-11', 'Jul-12')), other=rnorm(4, 3))
#Attempt to convert
as.Date(as.character(df$mydate), format='%b-%y')


From ripley at stats.ox.ac.uk  Thu Mar 26 22:36:52 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 26 Mar 2015 21:36:52 +0000
Subject: [R] basic help with as.Date()
In-Reply-To: <607C14A8-8809-43C8-A002-20E9CFB888EC@gmail.com>
References: <607C14A8-8809-43C8-A002-20E9CFB888EC@gmail.com>
Message-ID: <55147BF4.1090903@stats.ox.ac.uk>

On 26/03/2015 21:11, Simon Kiss wrote:
> Hi there: normally I?m quite comfortable with as.Date(). But this data set is causing problems.
>
> The core of the data frame looks like the sample data frame below, but my attempt to convert df$mydate to a date object returns only NA. Can anyone provide a suggestion?
>
> Thank you, Simon Kiss
>
> #sample data frame
> df<-data.frame(mydate=factor(c('Jan-15', 'Feb-13', 'Mar-11', 'Jul-12')), other=rnorm(4, 3))
> #Attempt to convert
> as.Date(as.character(df$mydate), format='%b-%y')

You would be on surer ground with something like

as.Date(paste0('01-',as.character(df$mydate)), format='%d-%b-%y')

since it is unclear what dates you expected to get.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From marc_schwartz at me.com  Thu Mar 26 22:38:11 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 26 Mar 2015 16:38:11 -0500
Subject: [R] basic help with as.Date()
In-Reply-To: <607C14A8-8809-43C8-A002-20E9CFB888EC@gmail.com>
References: <607C14A8-8809-43C8-A002-20E9CFB888EC@gmail.com>
Message-ID: <8734F374-2545-4544-A919-DC96CBCF9BB8@me.com>


> On Mar 26, 2015, at 4:11 PM, Simon Kiss <sjkiss at gmail.com> wrote:
> 
> Hi there: normally I?m quite comfortable with as.Date(). But this data set is causing problems.
> 
> The core of the data frame looks like the sample data frame below, but my attempt to convert df$mydate to a date object returns only NA. Can anyone provide a suggestion?
> 
> Thank you, Simon Kiss
> 
> #sample data frame
> df<-data.frame(mydate=factor(c('Jan-15', 'Feb-13', 'Mar-11', 'Jul-12')), other=rnorm(4, 3))
> #Attempt to convert
> as.Date(as.character(df$mydate), format='%b-%y')


Hi,

R's default date class object requires a full date, with a month, day and year. 

You might look at the 'zoo' package on CRAN, which has a yearmon() function.

Regards,

Marc Schwartz


From jdnewmil at dcn.davis.CA.us  Thu Mar 26 22:42:08 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 26 Mar 2015 14:42:08 -0700
Subject: [R] basic help with as.Date()
In-Reply-To: <607C14A8-8809-43C8-A002-20E9CFB888EC@gmail.com>
References: <607C14A8-8809-43C8-A002-20E9CFB888EC@gmail.com>
Message-ID: <E6F90782-81C5-4841-B138-080981FF6E73@dcn.davis.CA.us>

That would be because they are not dates... they don't specify the day.

Either add a day of month to the character data before you convert it, or use the yearmon class from zoo.

Something like...

as.Date(paste("1",as.character(df$mydate),sep="-"), format='%d-%b-%y')

And why in the world are you converting to factor and back? Perhaps because you are not preventing conversion to factor when you read in your actual data? Do you know about the stringsAsFactors argument to read.table and friends?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 26, 2015 2:11:50 PM PDT, Simon Kiss <sjkiss at gmail.com> wrote:
>Hi there: normally I?m quite comfortable with as.Date(). But this data
>set is causing problems.
>
>The core of the data frame looks like the sample data frame below, but
>my attempt to convert df$mydate to a date object returns only NA. Can
>anyone provide a suggestion?
>
>Thank you, Simon Kiss
>
>#sample data frame
>df<-data.frame(mydate=factor(c('Jan-15', 'Feb-13', 'Mar-11',
>'Jul-12')), other=rnorm(4, 3))
>#Attempt to convert
>as.Date(as.character(df$mydate), format='%b-%y')
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From yoursurrogategod at gmail.com  Thu Mar 26 21:58:31 2015
From: yoursurrogategod at gmail.com (yoursurrogategod at gmail.com)
Date: Thu, 26 Mar 2015 16:58:31 -0400
Subject: [R] Why can't I access this type?
In-Reply-To: <5512C2BA.6020301@gmail.com>
References: <CAJ=2b04qLmoA8W--=dsv2vqMHkG1Y7Tv_QQx_9D78oopJku+Yg@mail.gmail.com>
	<28E315E85F1.00000296jrkrideau@inbox.com>
	<20150325084041.GA2875@slingshot.co.nz>
	<5512C2BA.6020301@gmail.com>
Message-ID: <3C3115F9-CC96-47D4-B3AF-972F08E9EEA3@gmail.com>





> On Mar 25, 2015, at 10:14, Henric Winell <nilsson.henric at gmail.com> wrote:
> 
>> On 2015-03-25 09:40, Patrick Connolly wrote:
>> 
>> On Sun, 22-Mar-2015 at 08:06AM -0800, John Kane wrote:
>> 
>> |> Well, first off, you have no variable called "Name".  You have lost
>> |> the state names as they are rownames in the matrix state.x77 and
>> |> not a variable.
>> |>
>> |> Try this. It's ugly and I have no idea why I had to do a cbind()
>> 
>> You don't have to use cbind
>> 
>> |> but it seems to work. Personally I find subset easier to read than
>> |> the indexing approach.
>> 
>> |> state  <-  rownames(state.x77)
>> |> all.states <- as.data.frame(state.x77)
>> |> all.states  <-  cbind(state, all.states) ### ?????
>> 
>> You don't have to use cbind()
>> 
>> all.states  <- within(as.data.frame(state.x77), state <- rownames(state.x77))
>> 
>> but I think cbind is simpler to read.
>> 
>> |>
>> |> coldstates  <-   subset(all.states, all.states$Frost > 50,
>> |>                         select = c("state","Frost") )
> 
> I find the indexing approach
> 
> coldstates <- all.states[all.states$Frost > 150, c("state","Frost")]
> 
> to be the most direct and obvious solution.
> 
>> Tidier, even more so than subset():
>> 
>> require(dplyr)
>> coldstates <- all.states %>% filter(Frost > 150) %>% select(state, Frost)
>> 
>> Or, easier to see what's happening:
>> 
>> coldstates <- all.states %>%
>>   filter(Frost > 150) %>%
>>   select(state, Frost)
> 
> Well...  Opinions may perhaps differ, but apart from '%>%' being butt-ugly it's also fairly slow:
> 
> > library("microbenchmark")
> > microbenchmark(
> +     subset(all.states, all.states$Frost > 150, select = c("state","Frost")),
> +     all.states[all.states$Frost > 150, c("state","Frost")],
> +     all.states %>% filter(Frost > 150) %>% select(state, Frost),
> +     times = 1000L
> + )
> Unit: microseconds
>   expr
> subset(all.states, all.states$Frost > 150, select = c("state", "Frost"))
>                       all.states[all.states$Frost > 150, c("state", "Frost")]
>                   all.states %>% filter(Frost > 150) %>% select(state, Frost)
>      min       lq      mean    median        uq      max neval cld
>  139.112  148.673  163.3960  159.1760  170.7895 1763.200  1000  b
>  104.039  111.973  127.2138  120.4395  128.6640 1381.809  1000 a
> 1010.076 1033.519 1133.1469 1107.8480 1175.1800 2932.206  1000   c
> 
> Of course, this doesn't matter for interactive one-off use.  But lately I've seen examples of the '%>%' operator creeping into functions in packages.  However, it would be nice to see a fast pipe operator as part of base R.
> 
> 
> Henric Winell
> 
> 
> 
>> 
>> 
>> |>
>> |>
>> |> John Kane
>> |> Kingston ON Canada
>> |>
>> |>
>> |> > -----Original Message-----
>> |> > From: yoursurrogategod at gmail.com
>> |> > Sent: Sun, 22 Mar 2015 10:39:03 -0400
>> |> > To: r-help at r-project.org
>> |> > Subject: [R] Why can't I access this type?
>> |> >
>> |> > Hi, I'm just learning my way around R.  I got a bunch of states and would
>> |> > like to access to get all of the ones where it's cold.  But when I do the
>> |> > following, I will get the following error:
>> |> >
>> |> >> all.states <- as.data.frame(state.x77)
>> |> >> cold.states <- all.states[all.states$Frost > 150, c("Name", "Frost")]
>> |> > Error in `[.data.frame`(all.states, all.states$Frost > 150, c("Name",  :
>> |> >   undefined columns selected
>> |> >
>> |> > I don't get it.  When I look at all.states, this is what I see:
>> |> >
>> |> >> str(all.states)
>> |> > 'data.frame':   50 obs. of  8 variables:
>> |> >  $ Population: num  3615 365 2212 2110 21198 ...
>> |> >  $ Income    : num  3624 6315 4530 3378 5114 ...
>> |> >  $ Illiteracy: num  2.1 1.5 1.8 1.9 1.1 0.7 1.1 0.9 1.3 2 ...
>> |> >  $ Life Exp  : num  69 69.3 70.5 70.7 71.7 ...
>> |> >  $ Murder    : num  15.1 11.3 7.8 10.1 10.3 6.8 3.1 6.2 10.7 13.9 ...
>> |> >  $ HS Grad   : num  41.3 66.7 58.1 39.9 62.6 63.9 56 54.6 52.6 40.6 ...
>> |> >  $ Frost     : num  20 152 15 65 20 166 139 103 11 60 ...
>> |> >  $ Area      : num  50708 566432 113417 51945 156361 ...
>> |> >
>> |> > What am I messing up?
>> |> >
>> |> >    [[alternative HTML version deleted]]
>> |> >
>> |> > ______________________________________________
>> |> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> |> > https://stat.ethz.ch/mailman/listinfo/r-help
>> |> > PLEASE do read the posting guide
>> |> > http://www.R-project.org/posting-guide.html
>> |> > and provide commented, minimal, self-contained, reproducible code.
>> |>
>> |> ____________________________________________________________
>> |> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
>> |> Visit http://www.inbox.com/photosharing to find out more!
>> |>
>> |> ______________________________________________
>> |> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> |> https://stat.ethz.ch/mailman/listinfo/r-help
>> |> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> |> and provide commented, minimal, self-contained, reproducible code.


I agree with you on the indexing approach.  But even after using within, I still get the same error.
> 


From dstr7320 at uni.sydney.edu.au  Fri Mar 27 06:00:06 2015
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Fri, 27 Mar 2015 05:00:06 +0000
Subject: [R] Vennerable Plots for Publications
Message-ID: <1427432405491.47716@uni.sydney.edu.au>

Does anyone make Venn diagrams for publication using Vennerable ? I found that the font size is too big when the plot is created at 300 DPI, and there's no option to change it, even when the point size argument to the device is changed.

aVenn <- Venn(Sets = list(A = 1:5, B = 3:6))
png("forPublication.png", units = "in", h = 2.55, w = 2.4, res = 300) # Changing pointsize to a smaller number has no effect on size of the text.
plot(aVenn)
dev.off()

--------------------------------------
Dario Strbenac
PhD Student
University of Sydney
Camperdown NSW 2050
Australia


From jatin.kala.jk at gmail.com  Fri Mar 27 06:13:24 2015
From: jatin.kala.jk at gmail.com (Jatin Kala)
Date: Fri, 27 Mar 2015 16:13:24 +1100
Subject: [R] matrix manipulation question
Message-ID: <5514E6F4.9050700@gmail.com>

Hi,
I've got a rather large matrix of about 800 rows and 600000 columns.
Each column is a time-series 800 long.

Out of these 600000 time series, some have missing values (NA).
I want to strip out all columns that have one or more NA values, i.e., 
only want full time series.

This should do the trick:
data_no_NA <- data[,!apply(is.na(data), 2, any)]

I now use data_no_NA as input to a function, which returns output as a 
matrix of the same size as data_no_NA

The trick is that i now need to put these columns back into a new 800 by 
600000 empty matrix, at their original locations.
Any suggestions on how to do that? hopefully without having to use loops.
I'm using R/3.0.3

Cheers,
Jatin.


From rmh at temple.edu  Fri Mar 27 06:30:54 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 27 Mar 2015 01:30:54 -0400
Subject: [R] matrix manipulation question
In-Reply-To: <5514E6F4.9050700@gmail.com>
References: <5514E6F4.9050700@gmail.com>
Message-ID: <CAGx1TMBFjZnL4vBuAysMAAFxuJg_u=VZSUh3VOryC3SP9OhRKg@mail.gmail.com>

just reverse what you did before.

newdata <- data
newdata[] <- NA
newdata[,!apply(is.na(data), 2, any)] <- myfunction(data_no_NA)

On Fri, Mar 27, 2015 at 1:13 AM, Jatin Kala <jatin.kala.jk at gmail.com> wrote:
> Hi,
> I've got a rather large matrix of about 800 rows and 600000 columns.
> Each column is a time-series 800 long.
>
> Out of these 600000 time series, some have missing values (NA).
> I want to strip out all columns that have one or more NA values, i.e., only
> want full time series.
>
> This should do the trick:
> data_no_NA <- data[,!apply(is.na(data), 2, any)]
>
> I now use data_no_NA as input to a function, which returns output as a
> matrix of the same size as data_no_NA
>
> The trick is that i now need to put these columns back into a new 800 by
> 600000 empty matrix, at their original locations.
> Any suggestions on how to do that? hopefully without having to use loops.
> I'm using R/3.0.3
>
> Cheers,
> Jatin.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p_connolly at slingshot.co.nz  Fri Mar 27 09:19:26 2015
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Fri, 27 Mar 2015 21:19:26 +1300
Subject: [R] Why can't I access this type?
In-Reply-To: <3C3115F9-CC96-47D4-B3AF-972F08E9EEA3@gmail.com>
References: <CAJ=2b04qLmoA8W--=dsv2vqMHkG1Y7Tv_QQx_9D78oopJku+Yg@mail.gmail.com>
	<28E315E85F1.00000296jrkrideau@inbox.com>
	<20150325084041.GA2875@slingshot.co.nz>
	<5512C2BA.6020301@gmail.com>
	<3C3115F9-CC96-47D4-B3AF-972F08E9EEA3@gmail.com>
Message-ID: <20150327081926.GD2875@slingshot.co.nz>

On Thu, 26-Mar-2015 at 04:58PM -0400, yoursurrogategod at gmail.com wrote:

[...]
|>  I agree with you on the indexing approach.  But even after using
|> within, I still get the same error.  >

You leave us to guess just what you tried, but if you did this:

> all.states  <- within(as.data.frame(state.x77), state <- rownames(state.x77))
and then again did this:

> cold.states <- all.states[all.states$Frost > 150, c("Name", "Frost")]

of course it will give the same error, because as you haven't
addressed the problem as you've been told

On Sun, 22-Mar-2015 at 08:06AM -0800, John Kane wrote:

|> Well, first off, you have no variable called "Name".  You have lost
|> the state names as they are rownames in the matrix state.x77 and
|> not a variable.

If you did this:

> all.states  <- within(as.data.frame(state.x77), Name <- rownames(state.x77))
instead of
> all.states  <- within(as.data.frame(state.x77), state <- rownames(state.x77))

then this would worka;
> cold.states <- all.states[all.states$Frost > 150, c("Name", "Frost")]

Modify the above to match where my guess at what you tried is in error.


HTH

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From stephane.adamowicz at avignon.inra.fr  Fri Mar 27 09:58:39 2015
From: stephane.adamowicz at avignon.inra.fr (=?iso-8859-1?Q?St=E9phane_Adamowicz?=)
Date: Fri, 27 Mar 2015 09:58:39 +0100
Subject: [R] matrix manipulation question
In-Reply-To: <5514E6F4.9050700@gmail.com>
References: <5514E6F4.9050700@gmail.com>
Message-ID: <D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>

Why not use complete.cases() ?

data_no_NA <- data[, complete.cases(t(data))==T]


Le 27 mars 2015 ? 06:13, Jatin Kala <jatin.kala.jk at gmail.com> a ?crit :

> Hi,
> I've got a rather large matrix of about 800 rows and 600000 columns.
> Each column is a time-series 800 long.
> 
> Out of these 600000 time series, some have missing values (NA).
> I want to strip out all columns that have one or more NA values, i.e., only want full time series.
> 
> This should do the trick:
> data_no_NA <- data[,!apply(is.na(data), 2, any)]
> 
> I now use data_no_NA as input to a function, which returns output as a matrix of the same size as data_no_NA
> 
> The trick is that i now need to put these columns back into a new 800 by 600000 empty matrix, at their original locations.
> Any suggestions on how to do that? hopefully without having to use loops.
> I'm using R/3.0.3
> 
> Cheers,
> Jatin.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Fri Mar 27 10:38:26 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 27 Mar 2015 10:38:26 +0100
Subject: [R] matrix manipulation question
In-Reply-To: <D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>
References: <5514E6F4.9050700@gmail.com>
	<D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>
Message-ID: <950C4B78-0DE6-4C3A-8031-76B0821595C1@gmail.com>


On 27 Mar 2015, at 09:58 , St?phane Adamowicz <stephane.adamowicz at avignon.inra.fr> wrote:

> data_no_NA <- data[, complete.cases(t(data))==T]

Ouch! logical == TRUE is bad, logical == T is worse:

data[, complete.cases(t(data))]


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From drjimlemon at gmail.com  Fri Mar 27 10:48:04 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 27 Mar 2015 20:48:04 +1100
Subject: [R] Vennerable Plots for Publications
In-Reply-To: <1427432405491.47716@uni.sydney.edu.au>
References: <1427432405491.47716@uni.sydney.edu.au>
Message-ID: <CA+8X3fWM0vPvkGG1yDRDgjGEb3KPr6hmRmtuCvXFqmpCSYhrcw@mail.gmail.com>

HI Dario,
Have you tried creating a larger PNG image and then shrinking the result
with an image manipulation program (e.g. GIMP)?

Jim


On Fri, Mar 27, 2015 at 4:00 PM, Dario Strbenac <dstr7320 at uni.sydney.edu.au>
wrote:

> Does anyone make Venn diagrams for publication using Vennerable ? I found
> that the font size is too big when the plot is created at 300 DPI, and
> there's no option to change it, even when the point size argument to the
> device is changed.
>
> aVenn <- Venn(Sets = list(A = 1:5, B = 3:6))
> png("forPublication.png", units = "in", h = 2.55, w = 2.4, res = 300) #
> Changing pointsize to a smaller number has no effect on size of the text.
> plot(aVenn)
> dev.off()
>
> --------------------------------------
> Dario Strbenac
> PhD Student
> University of Sydney
> Camperdown NSW 2050
> Australia
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From stephane.adamowicz at avignon.inra.fr  Fri Mar 27 11:41:57 2015
From: stephane.adamowicz at avignon.inra.fr (=?iso-8859-1?Q?St=E9phane_Adamowicz?=)
Date: Fri, 27 Mar 2015 11:41:57 +0100
Subject: [R] matrix manipulation question
In-Reply-To: <950C4B78-0DE6-4C3A-8031-76B0821595C1@gmail.com>
References: <5514E6F4.9050700@gmail.com>
	<D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>
	<950C4B78-0DE6-4C3A-8031-76B0821595C1@gmail.com>
Message-ID: <040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>

Well, it seems to work with me.

Y <- as.matrix(airquality)
head(Y, n=8)
     Ozone Solar.R Wind Temp Month Day
[1,]    41     190  7.4   67     5   1
[2,]    36     118  8.0   72     5   2
[3,]    12     149 12.6   74     5   3
[4,]    18     313 11.5   62     5   4
[5,]    NA      NA 14.3   56     5   5
[6,]    28      NA 14.9   66     5   6
[7,]    23     299  8.6   65     5   7
[8,]    19      99 13.8   59     5   8

Z <- Y[,complete.cases(t(Y))==T]

head(Z, n=8)
     Wind Temp Month Day
[1,]  7.4   67     5   1
[2,]  8.0   72     5   2
[3,] 12.6   74     5   3
[4,] 11.5   62     5   4
[5,] 14.3   56     5   5
[6,] 14.9   66     5   6
[7,]  8.6   65     5   7
[8,] 13.8   59     5   8

The columns that contained NA were deleted.


Le 27 mars 2015 ? 10:38, peter dalgaard <pdalgd at gmail.com> a ?crit :

> 
> On 27 Mar 2015, at 09:58 , St?phane Adamowicz <stephane.adamowicz at avignon.inra.fr> wrote:
> 
>> data_no_NA <- data[, complete.cases(t(data))==T]
> 
> Ouch! logical == TRUE is bad, logical == T is worse:
> 
> data[, complete.cases(t(data))]
> 
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 



_________________________________
St?phane Adamowicz
Inra, centre de recherche Paca, unit? PSH
228, route de l'a?rodrome
CS 40509
domaine St Paul, site Agroparc
84914 Avignon, cedex 9
France

stephane.adamowicz at avignon.inra.fr
tel.  +33 (0)4 32 72 24 35
fax. +33 (0)4 32 72 24 32
do not dial 0 when out of France
web PSH  : https://www6.paca.inra.fr/psh
web Inra : http://www.inra.fr/
_________________________________


	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Mar 27 12:34:19 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 27 Mar 2015 11:34:19 +0000
Subject: [R] matrix manipulation question
In-Reply-To: <040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>
References: <5514E6F4.9050700@gmail.com>
	<D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>
	<950C4B78-0DE6-4C3A-8031-76B0821595C1@gmail.com>
	<040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2576F@SRVEXCHMBX.precheza.cz>

Very, very, very bad solution.

as.matrix can change silently your data to unwanted format, complete.cases()==T is silly as Peter already pointed out.

I use

head(airquality[ ,colSums(is.na(airquality))==0])
  Wind Temp Month Day
1  7.4   67     5   1
2  8.0   72     5   2
3 12.6   74     5   3
4 11.5   62     5   4
5 14.3   56     5   5
6 14.9   66     5   6

if I want to get rid of columns with NA.

Cheers
Petr


From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of St?phane Adamowicz
Sent: Friday, March 27, 2015 11:42 AM
To: peter dalgaard
Cc: r-help at r-project.org
Subject: Re: [R] matrix manipulation question

Well, it seems to work with me.

Y <- as.matrix(airquality)
head(Y, n=8)
     Ozone Solar.R Wind Temp Month Day
[1,]    41     190  7.4   67     5   1
[2,]    36     118  8.0   72     5   2
[3,]    12     149 12.6   74     5   3
[4,]    18     313 11.5   62     5   4
[5,]    NA      NA 14.3   56     5   5
[6,]    28      NA 14.9   66     5   6
[7,]    23     299  8.6   65     5   7
[8,]    19      99 13.8   59     5   8

Z <- Y[,complete.cases(t(Y))==T]

head(Z, n=8)
     Wind Temp Month Day
[1,]  7.4   67     5   1
[2,]  8.0   72     5   2
[3,] 12.6   74     5   3
[4,] 11.5   62     5   4
[5,] 14.3   56     5   5
[6,] 14.9   66     5   6
[7,]  8.6   65     5   7
[8,] 13.8   59     5   8

The columns that contained NA were deleted.


Le 27 mars 2015 ? 10:38, peter dalgaard <pdalgd at gmail.com<mailto:pdalgd at gmail.com>> a ?crit :

>
> On 27 Mar 2015, at 09:58 , St?phane Adamowicz <stephane.adamowicz at avignon.inra.fr<mailto:stephane.adamowicz at avignon.inra.fr>> wrote:
>
>> data_no_NA <- data[, complete.cases(t(data))==T]
>
> Ouch! logical == TRUE is bad, logical == T is worse:
>
> data[, complete.cases(t(data))]
>
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk<mailto:pd.mes at cbs.dk>  Priv: PDalgd at gmail.com<mailto:PDalgd at gmail.com>
>
>
>
>
>
>
>
>
>



_________________________________
St?phane Adamowicz
Inra, centre de recherche Paca, unit? PSH
228, route de l'a?rodrome
CS 40509
domaine St Paul, site Agroparc
84914 Avignon, cedex 9
France

stephane.adamowicz at avignon.inra.fr<mailto:stephane.adamowicz at avignon.inra.fr>
tel.  +33 (0)4 32 72 24 35
fax. +33 (0)4 32 72 24 32
do not dial 0 when out of France
web PSH  : https://www6.paca.inra.fr/psh
web Inra : http://www.inra.fr/
_________________________________


        [[alternative HTML version deleted]]
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From stephane.adamowicz at avignon.inra.fr  Fri Mar 27 13:26:23 2015
From: stephane.adamowicz at avignon.inra.fr (=?utf-8?Q?St=C3=A9phane_Adamowicz?=)
Date: Fri, 27 Mar 2015 13:26:23 +0100
Subject: [R] matrix manipulation question
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2576F@SRVEXCHMBX.precheza.cz>
References: <5514E6F4.9050700@gmail.com>
	<D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>
	<950C4B78-0DE6-4C3A-8031-76B0821595C1@gmail.com>
	<040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2576F@SRVEXCHMBX.precheza.cz>
Message-ID: <12F2A328-2A4E-411D-BBA2-AD61AA684E09@avignon.inra.fr>


Le 27 mars 2015 ? 12:34, PIKAL Petr <petr.pikal at precheza.cz> a ?crit :

> Very, very, very bad solution.
>  
> as.matrix can change silently your data to unwanted format, complete.cases()==T is silly as Peter already pointed out.
>  
> 

Perhaps, but it happens that in the original message, the question dealt with a matrix not a dataframe, and thus I needed a matrix example. Furthermore in my example no unwanted format occurred. You can check easily that the final matrix contains only ? numeric ? data as in the original data frame.

St?phane
> > 
> > 
> > 
> > 
> > 
> 
> 
> 
> _________________________________
> St?phane Adamowicz
> Inra, centre de recherche Paca, unit? PSH
> 228, route de l'a?rodrome
> CS 40509
> domaine St Paul, site Agroparc
> 84914 Avignon, cedex 9
> France
> 
> stephane.adamowicz at avignon.inra.fr
> tel.  +33 (0)4 32 72 24 35
> fax. +33 (0)4 32 72 24 32
> do not dial 0 when out of France
> web PSH  : https://www6.paca.inra.fr/psh
> web Inra : http://www.inra.fr/
> _________________________________
> 
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From petr.pikal at precheza.cz  Fri Mar 27 13:35:56 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 27 Mar 2015 12:35:56 +0000
Subject: [R] matrix manipulation question
In-Reply-To: <12F2A328-2A4E-411D-BBA2-AD61AA684E09@avignon.inra.fr>
References: <5514E6F4.9050700@gmail.com>
	<D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>
	<950C4B78-0DE6-4C3A-8031-76B0821595C1@gmail.com>
	<040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2576F@SRVEXCHMBX.precheza.cz>
	<12F2A328-2A4E-411D-BBA2-AD61AA684E09@avignon.inra.fr>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C25805@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: St?phane Adamowicz [mailto:stephane.adamowicz at avignon.inra.fr]
> Sent: Friday, March 27, 2015 1:26 PM
> To: PIKAL Petr
> Cc: peter dalgaard; r-help at r-project.org
> Subject: Re: [R] matrix manipulation question
>
>
> Le 27 mars 2015 ? 12:34, PIKAL Petr <petr.pikal at precheza.cz> a ?crit :
>
> > Very, very, very bad solution.
> >
> > as.matrix can change silently your data to unwanted format,
> complete.cases()==T is silly as Peter already pointed out.
> >
> >
>
> Perhaps, but it happens that in the original message, the question

I do not have original message.

> dealt with a matrix not a dataframe, and thus I needed a matrix

But you made matrix from data frame. If one column was not numeric all resulting matrix would chnge to nonnumeric format.

> example. Furthermore in my example no unwanted format occurred. You can

Yes because data.frame was (luckily) numeric.

> check easily that the final matrix contains only ? numeric ? data as in
> the original data frame.

You want matrix? Here it is.

> head(as.matrix(airquality)[ ,colSums(is.na(airquality))==0])
     Wind Temp Month Day
[1,]  7.4   67     5   1
[2,]  8.0   72     5   2
[3,] 12.6   74     5   3
[4,] 11.5   62     5   4
[5,] 14.3   56     5   5
[6,] 14.9   66     5   6

Works same with matrix as with data frame without need to transform it.

Cheers
Petr

>
> St?phane
> > >
> > >
> > >
> > >
> > >
> >
> >
> >
> > _________________________________
> > St phane Adamowicz
> > Inra, centre de recherche Paca, unit  PSH 228, route de l'a rodrome
> CS
> > 40509 domaine St Paul, site Agroparc
> > 84914 Avignon, cedex 9
> > France
> >
> > stephane.adamowicz at avignon.inra.fr
> > tel.  +33 (0)4 32 72 24 35
> > fax. +33 (0)4 32 72 24 32
> > do not dial 0 when out of France
> > web PSH  : https://www6.paca.inra.fr/psh web Inra :
> > http://www.inra.fr/ _________________________________
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
> jsou ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> ze strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> > The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering
> into a contract in any time, for any reason, and without stating any
> reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer)
> excludes any acceptance of the offer on the part of the recipient
> containing any amendment or variation.
> > - the sender insists on that the respective contract is concluded
> only upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by
> the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From stephane.adamowicz at avignon.inra.fr  Fri Mar 27 13:57:53 2015
From: stephane.adamowicz at avignon.inra.fr (=?windows-1252?Q?St=E9phane_Adamowicz?=)
Date: Fri, 27 Mar 2015 13:57:53 +0100
Subject: [R] matrix manipulation question
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C25805@SRVEXCHMBX.precheza.cz>
References: <5514E6F4.9050700@gmail.com>
	<D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>
	<950C4B78-0DE6-4C3A-8031-76B0821595C1@gmail.com>
	<040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2576F@SRVEXCHMBX.precheza.cz>
	<12F2A328-2A4E-411D-BBA2-AD61AA684E09@avignon.inra.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C25805@SRVEXCHMBX.precheza.cz>
Message-ID: <D9A22DDC-1C82-486E-A45A-CDA371204EE0@avignon.inra.fr>


> 
>> example. Furthermore in my example no unwanted format occurred. You can
> 
> Yes because data.frame was (luckily) numeric.
> 

Luck has nothing to do with this. I Chose this example on purpose ?

St?phane


From wandrson01 at gmail.com  Fri Mar 27 15:16:03 2015
From: wandrson01 at gmail.com (Walter Anderson)
Date: Fri, 27 Mar 2015 09:16:03 -0500
Subject: [R] Calculating area of polygons created from a spatial intersect
Message-ID: <55156623.4090405@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Hello all,

I am attempting to automate an analysis that I developed with ArcInfo
using R and the gdal and geos packages (or any other) if possible.

Here is the basic process

I have a shape file (lines) that defines the limits of all of the
projects with each project having a unique identifier.

I have another shape file (polys) that contains total population and
low income population and represent Census block groups.  This shape
file has an area field which has the acreage of the total block group.

Process

Step 1.
I then buffer these project lines to create a second shape file that
represents the 'footprint' of the project. (Creates polys).

Step 2.
In ArcInfo, I perform an intersection of the two shape files
(footprint and census blocks) and this creates a third shape file
which has a unique polygon for every project/census block intersection.

Step 3.
I then perform an area calculation (acres) on this new poly shape file
and use this calculated area divided by the original area of the
associated census block group to apportion the two population datum to
this new polygon.

Step 4.
Finally, I sum the two population datums for each of the projects from
the attribute table of this final shape file.

When I try to replicate the above procedure I run into a problem with
Step 2 when I use what I think is the appropriate command:

gIntersects(buffered_projects, census_blocks, byID=TRUE)

This command is producing a matrix of each project/census block
combination and only providing me a true/false indication.  Is there
any way to replicate the process from ArcInfo that I outlined above
within R?

Walter Anderson
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQIcBAEBAgAGBQJVFWYWAAoJEHfnxjvhypCiMc8P/2Dsja+h4RKuR7ygHx+oI+4/
oEIxl/NtnHwPh6szyL6CBndSYI6hvdWWwBUm86IsJLmLSSFivB1Ru54nkFq+kfKL
tWpxyOAXNZoa2xn1ADaG1ChFiY/hF937zlTTv8D3a5pYAnYtTeyg6UJ3AuHsfjqG
PbFAg6T+QD3AlJvV73JGmEchgYoj7NlxiEmdcfB3X9cgLMMOCsfLgm4d5g5J/mhh
LKZm3Xg9+eXEjPJazHYB9xc0+AF8Jp6SH9XnnZ/DMFN3DuyR3KuTJr6YnHUKvtUs
o/Uog3zAGuVUDqNwF1H9+WNuz4Fm7XXiHl4xX0n9faE3niTe2b63bVn/Ueiyofb9
ky3wIpAr412/Ne3dtMtSDPkE3w2TsdIUKki2VP9duXB/4vEtHHXvQxNtfKdKmlYX
cnyyK/1ZwULiwWhyxZKJNUd6N2GyLYJ8MmJ7AXnT7EboJjNkhNta1BhWBE9Kzx8p
fUN1UwS8P96iFXztgg2jw3aYTPdPIp9rFYFJax5nKCl6n+YbjUw11GuO6F4lqNDv
PoLllcKkmsGWFo04P0TbS+x1zhc0wmyMn2EV8FcIXJ/80pqT/dWwksbjTfrQGoWx
Xo1m1vTR2LVVrdf0vSkWnxHA3xVQPv7YH5erVNBGWvuhgbLRx8j7MPUp7lFHOJvQ
bq1VJbpnZFRvJyZfII2p
=cZWI
-----END PGP SIGNATURE-----


From gilescrane at verizon.net  Fri Mar 27 15:25:56 2015
From: gilescrane at verizon.net (Giles Crane)
Date: Fri, 27 Mar 2015 10:25:56 -0400
Subject: [R] Problem with download.file ?
Message-ID: <55156874.8080408@verizon.net>


# download.file() Seems to put the xlsx file onto hard drive.

>download.file("http://www.udel.edu/johnmack/data_library/zipcode_centroids.xlsx", "zipcode_centroids.xlsx")
trying URL 'http://www.udel.edu/johnmack/data_library/zipcode_centroids.xlsx'
Content type 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet' length 2785832 bytes (2.7 Mb)
opened URL
downloaded 2.7 Mb


# Trouble reading file with xlsx.

library(xlsx)
Loading required package: rJava
Loading required package: xlsxjars
Warning messages:
1: package ?xlsx? was built under R version 3.1.3
2: package ?rJava? was built under R version 3.1.3

>df <- read.xlsx2("zipcode_centroids.xlsx", sheetIndex=1)
Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  :
   java.util.zip.ZipException: invalid entry size (expected 1168 but got 1173 bytes)


# I downloaded the file manually (same name) from the web page and tried again.
# Then I read the file into R with xlsx successfully.


>df <- read.xlsx2("/zipdist/zipcode_centroids.xlsx", sheetIndex=1)
>str(df)
'data.frame':	42961 obs. of  8 variables:
  $ ZIPCODE  : Factor w/ 42961 levels "01001","01002",..: 1 2 3 4 5 6 7 8 9 10 ...
  $ TOWN.    : Factor w/ 18955 levels "Aaronsburg","Abbeville",..: 85 333 333 333 898 1089 1459 1620 1899 2929 ...
  $ STATE    : Factor w/ 52 levels "AK","AL","AR",..: 21 21 21 21 21 21 21 21 21 21 ...
  $ LATITUDE : Factor w/ 37352 levels "-7.209975","19.101978",..: 28020 28948 28916 28971 29047 28624 28326 28418 28197 28603 ...
  $ LONGITUDE: Factor w/ 37241 levels "-100.00991","-100.02632",..: 8799 8706 8811 8715 8470 8639 9019 8608 8531 9065 ...
  $ STFIPS   : Factor w/ 51 levels "01","02","04",..: 22 22 22 22 22 22 22 22 22 22 ...
  $ CD       : Factor w/ 55 levels "00","01","02",..: 3 2 2 2 2 2 2 3 3 2 ...
  $ CONG_DIST: Factor w/ 436 levels "01_01","01_02",..: 191 190 190 190 190 190 190 191 191 190 ...

# Is there a problem with download.file() when file is an Excel file or this particular Excel file?

-- 
Giles L Crane, MPH, ASA, NJPHA
Statistical Consultant and R Instructor
621 Lake Drive
Princeton, NJ  08540
Phone: 609 924-0971
Email: gilescrane at verizon.net


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Mar 27 16:04:06 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 27 Mar 2015 08:04:06 -0700
Subject: [R] Problem with download.file ?
In-Reply-To: <55156874.8080408@verizon.net>
References: <55156874.8080408@verizon.net>
Message-ID: <CAF8bMca+7p0UxwcndAuW=Ox++frJ7NVDsuqbjEJU0jfqFdFM0g@mail.gmail.com>

Add the argument mode="wb" to your call to download.file().  On Windows
this means to use 'binary' format - do not change line endings.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Mar 27, 2015 at 7:25 AM, Giles Crane <gilescrane at verizon.net> wrote:

>
> # download.file() Seems to put the xlsx file onto hard drive.
>
> >download.file("
> http://www.udel.edu/johnmack/data_library/zipcode_centroids.xlsx",
> "zipcode_centroids.xlsx")
> trying URL '
> http://www.udel.edu/johnmack/data_library/zipcode_centroids.xlsx'
> Content type
> 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet' length
> 2785832 bytes (2.7 Mb)
> opened URL
> downloaded 2.7 Mb
>
>
> # Trouble reading file with xlsx.
>
> library(xlsx)
> Loading required package: rJava
> Loading required package: xlsxjars
> Warning messages:
> 1: package ?xlsx? was built under R version 3.1.3
> 2: package ?rJava? was built under R version 3.1.3
>
> >df <- read.xlsx2("zipcode_centroids.xlsx", sheetIndex=1)
> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  :
>    java.util.zip.ZipException: invalid entry size (expected 1168 but got
> 1173 bytes)
>
>
> # I downloaded the file manually (same name) from the web page and tried
> again.
> # Then I read the file into R with xlsx successfully.
>
>
> >df <- read.xlsx2("/zipdist/zipcode_centroids.xlsx", sheetIndex=1)
> >str(df)
> 'data.frame':   42961 obs. of  8 variables:
>   $ ZIPCODE  : Factor w/ 42961 levels "01001","01002",..: 1 2 3 4 5 6 7 8
> 9 10 ...
>   $ TOWN.    : Factor w/ 18955 levels "Aaronsburg","Abbeville",..: 85 333
> 333 333 898 1089 1459 1620 1899 2929 ...
>   $ STATE    : Factor w/ 52 levels "AK","AL","AR",..: 21 21 21 21 21 21 21
> 21 21 21 ...
>   $ LATITUDE : Factor w/ 37352 levels "-7.209975","19.101978",..: 28020
> 28948 28916 28971 29047 28624 28326 28418 28197 28603 ...
>   $ LONGITUDE: Factor w/ 37241 levels "-100.00991","-100.02632",..: 8799
> 8706 8811 8715 8470 8639 9019 8608 8531 9065 ...
>   $ STFIPS   : Factor w/ 51 levels "01","02","04",..: 22 22 22 22 22 22 22
> 22 22 22 ...
>   $ CD       : Factor w/ 55 levels "00","01","02",..: 3 2 2 2 2 2 2 3 3 2
> ...
>   $ CONG_DIST: Factor w/ 436 levels "01_01","01_02",..: 191 190 190 190
> 190 190 190 191 191 190 ...
>
> # Is there a problem with download.file() when file is an Excel file or
> this particular Excel file?
>
> --
> Giles L Crane, MPH, ASA, NJPHA
> Statistical Consultant and R Instructor
> 621 Lake Drive
> Princeton, NJ  08540
> Phone: 609 924-0971
> Email: gilescrane at verizon.net
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Mar 27 18:01:33 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 27 Mar 2015 10:01:33 -0700
Subject: [R] matrix manipulation question
In-Reply-To: <040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>
References: <5514E6F4.9050700@gmail.com>
	<D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>
	<950C4B78-0DE6-4C3A-8031-76B0821595C1@gmail.com>
	<040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>
Message-ID: <7FDAEF53-2F5E-41B2-BCAE-408F1D24042F@comcast.net>


On Mar 27, 2015, at 3:41 AM, St?phane Adamowicz wrote:

> Well, it seems to work with me.
> 

No one is doubting that it worked for you in this instance. What Peter D. was criticizing was the construction :

complete.cases(t(Y))==T

... and it was on two bases that it is "wrong". The first is that `T` is not guaranteed to be TRUE. The second is that the test ==T (or similarly ==TRUE) is completely unnecessary because `complete.cases` returns a logical vector and so that expression is a waste of time.

(The issue of matrix versus dataframe was raised by someone else.)

-- 
David.


> Y <- as.matrix(airquality)
> head(Y, n=8)
>     Ozone Solar.R Wind Temp Month Day
> [1,]    41     190  7.4   67     5   1
> [2,]    36     118  8.0   72     5   2
> [3,]    12     149 12.6   74     5   3
> [4,]    18     313 11.5   62     5   4
> [5,]    NA      NA 14.3   56     5   5
> [6,]    28      NA 14.9   66     5   6
> [7,]    23     299  8.6   65     5   7
> [8,]    19      99 13.8   59     5   8
> 
> Z <- Y[,complete.cases(t(Y))==T]
> 
> head(Z, n=8)
>     Wind Temp Month Day
> [1,]  7.4   67     5   1
> [2,]  8.0   72     5   2
> [3,] 12.6   74     5   3
> [4,] 11.5   62     5   4
> [5,] 14.3   56     5   5
> [6,] 14.9   66     5   6
> [7,]  8.6   65     5   7
> [8,] 13.8   59     5   8
> 
> The columns that contained NA were deleted.
> 
> 
> Le 27 mars 2015 ? 10:38, peter dalgaard <pdalgd at gmail.com> a ?crit :
> 
>> 
>> On 27 Mar 2015, at 09:58 , St?phane Adamowicz <stephane.adamowicz at avignon.inra.fr> wrote:
>> 
>>> data_no_NA <- data[, complete.cases(t(data))==T]
>> 
>> Ouch! logical == TRUE is bad, logical == T is worse:
>> 
>> data[, complete.cases(t(data))]
>> 
>> 
>> -- 
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
> 
> 
> 
> _________________________________
> St?phane Adamowicz
> Inra, centre de recherche Paca, unit? PSH
> 228, route de l'a?rodrome
> CS 40509
> domaine St Paul, site Agroparc
> 84914 Avignon, cedex 9
> France
> 
> stephane.adamowicz at avignon.inra.fr
> tel.  +33 (0)4 32 72 24 35
> fax. +33 (0)4 32 72 24 32
> do not dial 0 when out of France
> web PSH  : https://www6.paca.inra.fr/psh
> web Inra : http://www.inra.fr/
> _________________________________
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From macqueen1 at llnl.gov  Fri Mar 27 18:44:58 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 27 Mar 2015 17:44:58 +0000
Subject: [R] Calculating area of polygons created from a spatial
 intersect
In-Reply-To: <55156623.4090405@gmail.com>
References: <55156623.4090405@gmail.com>
Message-ID: <D13AE31D.123DEA%macqueen1@llnl.gov>

Suggest (strongly) that you move this question to r-sig-geo. Much more
appropriate there, and more people there are more familiar with this kind
of work. But ... I suspect you want gIntersection(), not gIntersects().

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/27/15, 7:16 AM, "Walter Anderson" <wandrson01 at gmail.com> wrote:

>-----BEGIN PGP SIGNED MESSAGE-----
>Hash: SHA1
>
>Hello all,
>
>I am attempting to automate an analysis that I developed with ArcInfo
>using R and the gdal and geos packages (or any other) if possible.
>
>Here is the basic process
>
>I have a shape file (lines) that defines the limits of all of the
>projects with each project having a unique identifier.
>
>I have another shape file (polys) that contains total population and
>low income population and represent Census block groups.  This shape
>file has an area field which has the acreage of the total block group.
>
>Process
>
>Step 1.
>I then buffer these project lines to create a second shape file that
>represents the 'footprint' of the project. (Creates polys).
>
>Step 2.
>In ArcInfo, I perform an intersection of the two shape files
>(footprint and census blocks) and this creates a third shape file
>which has a unique polygon for every project/census block intersection.
>
>Step 3.
>I then perform an area calculation (acres) on this new poly shape file
>and use this calculated area divided by the original area of the
>associated census block group to apportion the two population datum to
>this new polygon.
>
>Step 4.
>Finally, I sum the two population datums for each of the projects from
>the attribute table of this final shape file.
>
>When I try to replicate the above procedure I run into a problem with
>Step 2 when I use what I think is the appropriate command:
>
>gIntersects(buffered_projects, census_blocks, byID=TRUE)
>
>This command is producing a matrix of each project/census block
>combination and only providing me a true/false indication.  Is there
>any way to replicate the process from ArcInfo that I outlined above
>within R?
>
>Walter Anderson
>-----BEGIN PGP SIGNATURE-----
>Version: GnuPG v1
>
>iQIcBAEBAgAGBQJVFWYWAAoJEHfnxjvhypCiMc8P/2Dsja+h4RKuR7ygHx+oI+4/
>oEIxl/NtnHwPh6szyL6CBndSYI6hvdWWwBUm86IsJLmLSSFivB1Ru54nkFq+kfKL
>tWpxyOAXNZoa2xn1ADaG1ChFiY/hF937zlTTv8D3a5pYAnYtTeyg6UJ3AuHsfjqG
>PbFAg6T+QD3AlJvV73JGmEchgYoj7NlxiEmdcfB3X9cgLMMOCsfLgm4d5g5J/mhh
>LKZm3Xg9+eXEjPJazHYB9xc0+AF8Jp6SH9XnnZ/DMFN3DuyR3KuTJr6YnHUKvtUs
>o/Uog3zAGuVUDqNwF1H9+WNuz4Fm7XXiHl4xX0n9faE3niTe2b63bVn/Ueiyofb9
>ky3wIpAr412/Ne3dtMtSDPkE3w2TsdIUKki2VP9duXB/4vEtHHXvQxNtfKdKmlYX
>cnyyK/1ZwULiwWhyxZKJNUd6N2GyLYJ8MmJ7AXnT7EboJjNkhNta1BhWBE9Kzx8p
>fUN1UwS8P96iFXztgg2jw3aYTPdPIp9rFYFJax5nKCl6n+YbjUw11GuO6F4lqNDv
>PoLllcKkmsGWFo04P0TbS+x1zhc0wmyMn2EV8FcIXJ/80pqT/dWwksbjTfrQGoWx
>Xo1m1vTR2LVVrdf0vSkWnxHA3xVQPv7YH5erVNBGWvuhgbLRx8j7MPUp7lFHOJvQ
>bq1VJbpnZFRvJyZfII2p
>=cZWI
>-----END PGP SIGNATURE-----
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lychang at emory.edu  Fri Mar 27 17:06:36 2015
From: lychang at emory.edu (lychang)
Date: Fri, 27 Mar 2015 09:06:36 -0700 (PDT)
Subject: [R] Categorizing by month
Message-ID: <1427472396067-4705173.post@n4.nabble.com>

Hi everyone,

I'm trying to categorize by month in R. How can I do this if my dates are in
date/month/year form?

Thanks,
Lois



--
View this message in context: http://r.789695.n4.nabble.com/Categorizing-by-month-tp4705173.html
Sent from the R help mailing list archive at Nabble.com.


From jatin.kala.jk at gmail.com  Fri Mar 27 10:24:49 2015
From: jatin.kala.jk at gmail.com (Jatin Kala)
Date: Fri, 27 Mar 2015 20:24:49 +1100
Subject: [R] matrix manipulation question
In-Reply-To: <CAGx1TMBFjZnL4vBuAysMAAFxuJg_u=VZSUh3VOryC3SP9OhRKg@mail.gmail.com>
References: <5514E6F4.9050700@gmail.com>
	<CAGx1TMBFjZnL4vBuAysMAAFxuJg_u=VZSUh3VOryC3SP9OhRKg@mail.gmail.com>
Message-ID: <551521E1.6050805@gmail.com>

Thanks Richard,
This works, rather obvious now that i think of it!
=)

On 27/03/2015 4:30 pm, Richard M. Heiberger wrote:
> just reverse what you did before.
>
> newdata <- data
> newdata[] <- NA
> newdata[,!apply(is.na(data), 2, any)] <- myfunction(data_no_NA)
>
> On Fri, Mar 27, 2015 at 1:13 AM, Jatin Kala <jatin.kala.jk at gmail.com> wrote:
>> Hi,
>> I've got a rather large matrix of about 800 rows and 600000 columns.
>> Each column is a time-series 800 long.
>>
>> Out of these 600000 time series, some have missing values (NA).
>> I want to strip out all columns that have one or more NA values, i.e., only
>> want full time series.
>>
>> This should do the trick:
>> data_no_NA <- data[,!apply(is.na(data), 2, any)]
>>
>> I now use data_no_NA as input to a function, which returns output as a
>> matrix of the same size as data_no_NA
>>
>> The trick is that i now need to put these columns back into a new 800 by
>> 600000 empty matrix, at their original locations.
>> Any suggestions on how to do that? hopefully without having to use loops.
>> I'm using R/3.0.3
>>
>> Cheers,
>> Jatin.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From nilsson.henric at gmail.com  Fri Mar 27 13:29:40 2015
From: nilsson.henric at gmail.com (Henric Winell)
Date: Fri, 27 Mar 2015 13:29:40 +0100
Subject: [R] matrix manipulation question
In-Reply-To: <040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>
References: <5514E6F4.9050700@gmail.com>
	<D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>
	<950C4B78-0DE6-4C3A-8031-76B0821595C1@gmail.com>
	<040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>
Message-ID: <55154D34.7010603@gmail.com>

On 2015-03-27 11:41, St?phane Adamowicz wrote:

> Well, it seems to work with me.
>
> Y <- as.matrix(airquality)
> head(Y, n=8)
>       Ozone Solar.R Wind Temp Month Day
> [1,]    41     190  7.4   67     5   1
> [2,]    36     118  8.0   72     5   2
> [3,]    12     149 12.6   74     5   3
> [4,]    18     313 11.5   62     5   4
> [5,]    NA      NA 14.3   56     5   5
> [6,]    28      NA 14.9   66     5   6
> [7,]    23     299  8.6   65     5   7
> [8,]    19      99 13.8   59     5   8
>
> Z <- Y[,complete.cases(t(Y))==T]

Peter's point, I guess, is that

1. complete.cases(t(Y)) is already a vector of logicals
2. T (and F) can be redefined, so what if T <- FALSE?


Henric Winell



>
> head(Z, n=8)
>       Wind Temp Month Day
> [1,]  7.4   67     5   1
> [2,]  8.0   72     5   2
> [3,] 12.6   74     5   3
> [4,] 11.5   62     5   4
> [5,] 14.3   56     5   5
> [6,] 14.9   66     5   6
> [7,]  8.6   65     5   7
> [8,] 13.8   59     5   8
>
> The columns that contained NA were deleted.
>
>
> Le 27 mars 2015 ? 10:38, peter dalgaard <pdalgd at gmail.com> a ?crit :
>
>>
>> On 27 Mar 2015, at 09:58 , St?phane Adamowicz <stephane.adamowicz at avignon.inra.fr> wrote:
>>
>>> data_no_NA <- data[, complete.cases(t(data))==T]
>>
>> Ouch! logical == TRUE is bad, logical == T is worse:
>>
>> data[, complete.cases(t(data))]
>>
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>
>>
>>
>>
>>
>>
>>
>>
>
>
>
> _________________________________
> St?phane Adamowicz
> Inra, centre de recherche Paca, unit? PSH
> 228, route de l'a?rodrome
> CS 40509
> domaine St Paul, site Agroparc
> 84914 Avignon, cedex 9
> France
>
> stephane.adamowicz at avignon.inra.fr
> tel.  +33 (0)4 32 72 24 35
> fax. +33 (0)4 32 72 24 32
> do not dial 0 when out of France
> web PSH  : https://www6.paca.inra.fr/psh
> web Inra : http://www.inra.fr/
> _________________________________
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From nilsson.henric at gmail.com  Fri Mar 27 15:27:19 2015
From: nilsson.henric at gmail.com (Henric Winell)
Date: Fri, 27 Mar 2015 15:27:19 +0100
Subject: [R] Using and abusing %>% (was Re: Why can't I access this
	type?)
In-Reply-To: <20150326064852.GB2875@slingshot.co.nz>
References: <CAJ=2b04qLmoA8W--=dsv2vqMHkG1Y7Tv_QQx_9D78oopJku+Yg@mail.gmail.com>
	<28E315E85F1.00000296jrkrideau@inbox.com>
	<20150325084041.GA2875@slingshot.co.nz>
	<5512C2BA.6020301@gmail.com>
	<20150326064852.GB2875@slingshot.co.nz>
Message-ID: <551568C7.9040400@gmail.com>

On 2015-03-26 07:48, Patrick Connolly wrote:

> On Wed, 25-Mar-2015 at 03:14PM +0100, Henric Winell wrote:
>
> ...
>
> |> Well...  Opinions may perhaps differ, but apart from '%>%' being
> |> butt-ugly it's also fairly slow:
>
> Beauty, it is said, is in the eye of the beholder.  I'm impressed by
> the way using %>% reduces or eliminates complicated nested brackets.

I didn't dispute whether '%>%' may be useful -- I just pointed out that 
it is slow.  However, it is only part of the problem: 'filter()' and 
'select()', although aesthetically pleasing, also seem to be slow:

 > all.states <- data.frame(state.x77, Name = rownames(state.x77))
 >
 > f1 <- function()
+     all.states[all.states$Frost > 150, c("Name", "Frost")]
 >
 > f2 <- function()
+     subset(all.states, Frost > 150, select = c("Name", "Frost"))
 >
 > f3 <- function() {
+     filt <- subset(all.states, Frost > 150)
+     subset(filt, select = c("Name", "Frost"))
+ }
 >
 > f4 <- function()
+     all.states %>% subset(Frost > 150) %>%
+         subset(select = c("Name", "Frost"))
 >
 > f5 <- function()
+     select(filter(all.states, Frost > 150), Name, Frost)
 >
 > f6 <- function()
+     all.states %>% filter(Frost > 150) %>% select(Name, Frost)
 >
 > mb <- microbenchmark(
+     f1(), f2(), f3(), f4(), f5(), f6(),
+     times = 1000L
+ )
 > print(mb, signif = 3L)
Unit: microseconds
  expr min   lq      mean median   uq  max neval   cld
  f1() 115  124  134.8812    129  134 1500  1000 a
  f2() 128  141  147.4694    145  151 1520  1000 a
  f3() 303  328  344.3175    338  348 1740  1000  b
  f4() 458  494  518.0830    510  523 1890  1000   c
  f5() 806  848  887.7270    875  894 3510  1000    d
  f6() 971 1010 1056.5659   1040 1060 3110  1000     e

So, using '%>%', but leaving 'filter()' and 'select()' out of the 
equation, as in 'f4()' is only half as bad as the "full" 'dplyr' idiom 
in 'f6()'.  In this case, since we're talking microseconds, the speed-up 
is negligible but that *is* beside the point.

> In this tiny example it's not obvious but it's very clear if the
> objective is to sort the dataframe by three or four columns and
> various lots of aggregation then returning a largish number of
> consecutive columns, omitting the rest.  It's very easy to see what's
> going on without the need for intermediate objects.

Why are you opposed to using intermediate objects?  In this case, as can 
be seen from 'f3()', it will also have the benefit of being faster than 
either '%>%' or the "full" 'dplyr' idiom.

> |> [...]
>
> It's no surprise that instructing a computer in something closer to
> human language is an order of magnitude slower.

Certainly not true, at least for compiled languages.  In any case, 
judging from off-list correspondence, it definitely came as a surprise 
to some R users...

Given that '%>%' is so heavily marketed through 'dplyr', where the 
latter is said to provide "blazing fast performance for in-memory data 
by writing key pieces in C++" and "a fast, consistent tool for working 
with data frame like objects, both in memory and out of memory", I don't 
think it's far-fetched to expect that it should be more performant than 
base R.

> I'm sure you'd get something even quicker using machine code.

Don't be ridiculous.  We're mainly discussing

all.states[all.states$Frost > 150, c("state", "Frost")]

vs.

all.states %>% filter(Frost > 150) %>% select(state, Frost)

i.e., pure R code.

> I spend 3 or 4 orders of magnitude more time writing code than running it.

You and me both.  But that doesn't mean speed is of no or little importance.

> It's much more important to me to be able to read and modify than
 > it is to have it run at optimum speed.

Good for you.  But surely, if this is your goal, nothing beats 
intermediate objects.  And like I said, it may still be faster than the 
'dplyr' idiom.

> |> Of course, this doesn't matter for interactive one-off use.  But
> |> lately I've seen examples of the '%>%' operator creeping into
> |> functions in packages.
>
> That could indicate that %>% is seductively easy to use.  It's
> probably true that there are places where it should be done the hard
> way.

We all know how easy it is to write ugly and sluggish code in R.  But 
'foo[i,j]' is neither ugly nor sluggish and certainly not "the hard way."

> |>  However, it would be nice to see a fast pipe operator as part of
> |> base R.

Heck, it doesn't even have to be fast as long as it's a bit more elegant 
than '%>%'.


Henric Winell



>
> |>
> |>
> |> Henric Winell
> |>
>


From nilsson.henric at gmail.com  Fri Mar 27 13:53:28 2015
From: nilsson.henric at gmail.com (Henric Winell)
Date: Fri, 27 Mar 2015 13:53:28 +0100
Subject: [R] Why can't I access this type?
In-Reply-To: <20150327081926.GD2875@slingshot.co.nz>
References: <CAJ=2b04qLmoA8W--=dsv2vqMHkG1Y7Tv_QQx_9D78oopJku+Yg@mail.gmail.com>
	<28E315E85F1.00000296jrkrideau@inbox.com>
	<20150325084041.GA2875@slingshot.co.nz>
	<5512C2BA.6020301@gmail.com>
	<3C3115F9-CC96-47D4-B3AF-972F08E9EEA3@gmail.com>
	<20150327081926.GD2875@slingshot.co.nz>
Message-ID: <551552C8.6060202@gmail.com>

On 2015-03-27 09:19, Patrick Connolly wrote:

> [...]
>
> On Sun, 22-Mar-2015 at 08:06AM -0800, John Kane wrote:
>
> |> Well, first off, you have no variable called "Name".  You have lost
> |> the state names as they are rownames in the matrix state.x77 and
> |> not a variable.
>
> If you did this:
>
>> all.states  <- within(as.data.frame(state.x77), Name <- rownames(state.x77))
> instead of
>> all.states  <- within(as.data.frame(state.x77), state <- rownames(state.x77))

Alternatively, since 'data.frame()' coerces internally, one could do

all.states <- data.frame(state.x77, Name = rownames(state.x77))


Henric Winell



>
> then this would worka;
>> cold.states <- all.states[all.states$Frost > 150, c("Name", "Frost")]
>
> Modify the above to match where my guess at what you tried is in error.
>
>
> HTH
>


From rodolfopelinson at gmail.com  Fri Mar 27 20:06:49 2015
From: rodolfopelinson at gmail.com (Rodolfo Pelinson)
Date: Fri, 27 Mar 2015 16:06:49 -0300
Subject: [R] vif in package car: there are aliased coefficients in the model
Message-ID: <CAHEYhxO+FXLM2+iKwz=OGj+n8ZSLpjv42S+YJJc_tJL3pa8SeA@mail.gmail.com>

Hello. I'm trying to use the function vif from package car in a lm. However
it returns the following error:
"Error in vif.default(lm(MDescores.sitescores ~ hidroperiodo + localizacao
+  : there are aliased coefficients in the model"

When I exclude any predictor from the model, it returns this warning
message:
"Warning message: In cov2cor(v) : diag(.) had 0 or NA entries; non-finite
result is doubtful"

When I exclude any other predictor from the model vif finally works. I
can't figure it out whats the problem. This are the results that R returns
me:

> vif(lm(MDescores.sitescores ~ hidroperiodo + localizacao + area +
profundidade + NTVM +  NTVI + PCs...c.1.., data = MDVIF))
Error in vif.default(lm(MDescores.sitescores ~ hidroperiodo + localizacao +
 :   there are aliased coefficients in the model

> vif(lm(MDescores.sitescores ~ localizacao + area + profundidade + NTVM +
 NTVI + PCs...c.1.., data = MDVIF))
             GVIF Df GVIF^(1/(2*Df))
localizacao   NaN  2             NaN
area          NaN  1             NaN
profundidade  NaN  1             NaN
NTVM          NaN  1             NaN
NTVI          NaN  1             NaN
PCs...c.1..   NaN  1             NaN
Warning message:
In cov2cor(v) : diag(.) had 0 or NA entries; non-finite result is doubtful

Thanks.
-- 
Rodolfo Mei Pelinson.

	[[alternative HTML version deleted]]


From bbaker at reed.edu  Fri Mar 27 20:52:38 2015
From: bbaker at reed.edu (Benjamin Baker)
Date: Fri, 27 Mar 2015 12:52:38 -0700 (PDT)
Subject: [R] Having trouble with gdata read in
In-Reply-To: <CAAxdm-5aTbG3q0jvaWWKfKw6fNWJE=YeD-e-XtwcZVqF1BMVZA@mail.gmail.com>
References: <CAAxdm-5aTbG3q0jvaWWKfKw6fNWJE=YeD-e-XtwcZVqF1BMVZA@mail.gmail.com>
Message-ID: <1427485957856.c70d8eeb@Nodemailer>

Jim,




I?m not seeing the command f.readXLSheet in the documentation, nor is it executing in my code.




?
Sent from Mailbox





On Thursday, Mar 26, 2015 at 5:15 AM, jim holtman <jholtman at gmail.com>, wrote:

My suggestion is to use XLConnect to read the file:






> x <- "C:\\Users\\jh52822\\AppData\\Local\\Temp\\Rtmp6nVgFC\\file385c632aba3.xls"

> require(XLConnect)

Loading required package: XLConnect

Loading required package: XLConnectJars

XLConnect 0.2-10 by Mirai Solutions GmbH [aut],

? Martin Studer [cre],

? The Apache Software Foundation [ctb, cph] (Apache POI, Apache Commons

? ? Codec),

? Stephen Colebourne [ctb, cph] (Joda-Time Java library)


http://www.mirai-solutions.com ,

http://miraisolutions.wordpress.com

> input <- f.readXLSheet(x, 1)

>?

> str(input)

'data.frame': ? 2266 obs. of ?51 variables:

?$ EIA ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?: num ?34 59 87 97 108 118 123 149 150 157 ...

?$ Entity.Name ? ? ? ? ? ? ? ? ? ? ? ? ?: chr ?"City of Abbeville" "City of Abbeville" "City of Ada" "Adams Electric Cooperative" ...

?$ State ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?: chr ?"SC" "LA" "MN" "IL" ...

?$ NERC.Region ? ? ? ? ? ? ? ? ? ? ? ? ?: chr ?"SERC" "SPP" "MRO" "SERC" ...

?$ Filing.Order ? ? ? ? ? ? ? ? ? ? ? ? : num ?12 11 1237 392 252 ...

?$ Q5.MultRegion ? ? ? ? ? ? ? ? ? ? ? ?: chr ?"" "" "" "" ...

?$ Q6.OwnMeters. ? ? ? ? ? ? ? ? ? ? ? ?: chr ?"Yes" "Yes" "Yes" "Yes" ...

?$ Q7.ResMeters ? ? ? ? ? ? ? ? ? ? ? ? : num ?3051 4253 857 8154 33670 ...

?$ Q7.ComMeters ? ? ? ? ? ? ? ? ? ? ? ? : num ?531 972 132 155 1719 ...

?$ Q7.IntMeters ? ? ? ? ? ? ? ? ? ? ? ? : num ?0 19 32 NA 626 NA 29 0 2 NA ...

?$ Q7.TransMeters ? ? ? ? ? ? ? ? ? ? ? : num ?0 NA NA NA NA NA NA 0 0 NA ...

?$ Q7.OtherMeters ? ? ? ? ? ? ? ? ? ? ? : num ?0 NA NA 57 NA NA NA 0 0 NA ...

?$ Q7...total.meters ? ? ? ? ? ? ? ? ? ?: num ?3582 5244 1021 8366 36015 ...

?$ Q8.15Min.ResAMI ? ? ? ? ? ? ? ? ? ? ?: num ?0 NA NA NA NA NA NA NA NA NA ...

?$ Q8.15Min.ComAMI ? ? ? ? ? ? ? ? ? ? ?: num ?0 NA NA 155 NA NA NA NA NA NA ...

?$ Q8.15Min.IndAMI ? ? ? ? ? ? ? ? ? ? ?: num ?0 NA NA NA NA NA NA NA NA NA ...

?$ Q8.15Min.TransAMI ? ? ? ? ? ? ? ? ? ?: num ?0 NA NA NA NA NA NA NA NA NA ...

?$ Q8.15Min.OtherAMI ? ? ? ? ? ? ? ? ? ?: num ?0 NA NA NA NA NA NA NA NA NA ...

?$ Q8.15Min.TotalAMI ? ? ? ? ? ? ? ? ? ?: num ?0 0 0 155 0 0 0 0 0 0 ...

?$ Q8.Hourly.ResAMI ? ? ? ? ? ? ? ? ? ? : num ?0 NA NA NA 16100 NA NA NA NA NA ...

?$ Q8.Hourly.ComAMI ? ? ? ? ? ? ? ? ? ? : num ?0 NA NA NA 1600 NA NA NA NA NA ...



....










Jim Holtman
Data Munger Guru
?
What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.



On Wed, Mar 25, 2015 at 5:01 PM, Benjamin Baker <bbaker at reed.edu> wrote:
Trying to read and clean up the FERC data on Advanced Metering infrastructure. Of course it is in XLS for the first two survey years and then converts to XLSX for the final two. Bad enough that it is all in excel, they had to change the survey design and data format as well. Still, I?m sorting through it. However, when I try and read in the 2008 data, I?m getting this error:

###

Wide character in print at /Library/Frameworks/R.framework/Versions/3.1/Resources/library/gdata/perl/xls2csv.pl line 270.

Warning message:

In scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,? :

? EOF within quoted string

###




Here is the code I?m running to get the data:

###

install.packages("gdata")

library("gdata")

fileUrl <- "http://www.ferc.gov/industries/electric/indus-act/demand-response/2008/survey/ami_survey_responses.xls"

download.file(fileUrl, destfile="./ami.data/ami-data2008.xls")

list.files("ami.data")

dateDown.2008 <- date()

ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1, header=TRUE)

###



Reviewed the data in the XLS file, and both ?? and # are present within it. Don?t know how to get the read.xls to ignore them so I can read all the data into my data frame. Tried :

###

ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1, quote="", header=TRUE)

###



And it spits out ?More columns than column names? output.



Been searching this, and I can find some ?solutions? for read.table, but nothing specific to read.xls



Many thanks,



Benjamin Baker




?

Sent from Mailbox

? ? ? ? [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From bbaker at reed.edu  Fri Mar 27 20:52:55 2015
From: bbaker at reed.edu (Benjamin Baker)
Date: Fri, 27 Mar 2015 12:52:55 -0700 (PDT)
Subject: [R] Having trouble with gdata read in
In-Reply-To: <CAOwvMDxJ2rDSXGkzXRO0cN60wKACazsdaWhU5-_d3XA71hZ0Wg@mail.gmail.com>
References: <CAOwvMDxJ2rDSXGkzXRO0cN60wKACazsdaWhU5-_d3XA71hZ0Wg@mail.gmail.com>
Message-ID: <1427485975037.50199fe6@Nodemailer>

Anthony,




XLSX won?t read an XLS file. Additionally, the legacy Java that is required for the xlsx package really effs up my computer. Have to reinstall my OS to fix it.




?
Sent from Mailbox

On Wed, Mar 25, 2015 at 3:51 PM, Anthony Damico <ajdamico at gmail.com>
wrote:

> maybe
> library(xlsx)
> tf <- tempfile()
> ami <- "
> http://www.ferc.gov/industries/electric/indus-act/demand-response/2008/survey/ami_survey_responses.xls
> "
> download.file( ami , tf , mode = 'wb' )
> ami.data2008 <- read.xlsx( tf , sheetIndex = 1 )
> On Wed, Mar 25, 2015 at 5:01 PM, Benjamin Baker <bbaker at reed.edu> wrote:
>> Trying to read and clean up the FERC data on Advanced Metering
>> infrastructure. Of course it is in XLS for the first two survey years and
>> then converts to XLSX for the final two. Bad enough that it is all in
>> excel, they had to change the survey design and data format as well. Still,
>> I?m sorting through it. However, when I try and read in the 2008 data, I?m
>> getting this error:
>> ###
>> Wide character in print at
>> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/gdata/perl/
>> xls2csv.pl line 270.
>> Warning message:
>> In scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>>   EOF within quoted string
>> ###
>>
>>
>>
>> Here is the code I?m running to get the data:
>> ###
>> install.packages("gdata")
>> library("gdata")
>> fileUrl <- "
>> http://www.ferc.gov/industries/electric/indus-act/demand-response/2008/survey/ami_survey_responses.xls
>> "
>> download.file(fileUrl, destfile="./ami.data/ami-data2008.xls")
>> list.files("ami.data")
>> dateDown.2008 <- date()
>> ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1,
>> header=TRUE)
>> ###
>>
>>
>> Reviewed the data in the XLS file, and both ?? and # are present within
>> it. Don?t know how to get the read.xls to ignore them so I can read all the
>> data into my data frame. Tried :
>> ###
>> ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1, quote="",
>> header=TRUE)
>> ###
>>
>>
>> And it spits out ?More columns than column names? output.
>>
>>
>> Been searching this, and I can find some ?solutions? for read.table, but
>> nothing specific to read.xls
>>
>>
>> Many thanks,
>>
>>
>> Benjamin Baker
>>
>>
>>
>> ?
>> Sent from Mailbox
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From bbaker at reed.edu  Fri Mar 27 22:28:09 2015
From: bbaker at reed.edu (Benjamin Baker)
Date: Fri, 27 Mar 2015 14:28:09 -0700 (PDT)
Subject: [R] Having trouble with gdata read in
In-Reply-To: <CAAxdm-5aTbG3q0jvaWWKfKw6fNWJE=YeD-e-XtwcZVqF1BMVZA@mail.gmail.com>
References: <CAAxdm-5aTbG3q0jvaWWKfKw6fNWJE=YeD-e-XtwcZVqF1BMVZA@mail.gmail.com>
Message-ID: <1427491688584.9336958a@Nodemailer>

Jim,




Thanks, XLConnect with proper syntax works great for both types of files.


?
Sent from Mailbox

On Thu, Mar 26, 2015 at 5:15 AM, jim holtman <jholtman at gmail.com> wrote:

> My suggestion is to use XLConnect to read the file:
>> x <-
> "C:\\Users\\jh52822\\AppData\\Local\\Temp\\Rtmp6nVgFC\\file385c632aba3.xls"
>> require(XLConnect)
> Loading required package: XLConnect
> Loading required package: XLConnectJars
> XLConnect 0.2-10 by Mirai Solutions GmbH [aut],
>   Martin Studer [cre],
>   The Apache Software Foundation [ctb, cph] (Apache POI, Apache Commons
>     Codec),
>   Stephen Colebourne [ctb, cph] (Joda-Time Java library)
> http://www.mirai-solutions.com ,
> http://miraisolutions.wordpress.com
>> input <- f.readXLSheet(x, 1)
>>
>> str(input)
> 'data.frame':   2266 obs. of  51 variables:
>  $ EIA                                  : num  34 59 87 97 108 118 123 149
> 150 157 ...
>  $ Entity.Name                          : chr  "City of Abbeville" "City of
> Abbeville" "City of Ada" "Adams Electric Cooperative" ...
>  $ State                                : chr  "SC" "LA" "MN" "IL" ...
>  $ NERC.Region                          : chr  "SERC" "SPP" "MRO" "SERC" ...
>  $ Filing.Order                         : num  12 11 1237 392 252 ...
>  $ Q5.MultRegion                        : chr  "" "" "" "" ...
>  $ Q6.OwnMeters.                        : chr  "Yes" "Yes" "Yes" "Yes" ...
>  $ Q7.ResMeters                         : num  3051 4253 857 8154 33670 ...
>  $ Q7.ComMeters                         : num  531 972 132 155 1719 ...
>  $ Q7.IntMeters                         : num  0 19 32 NA 626 NA 29 0 2 NA
> ...
>  $ Q7.TransMeters                       : num  0 NA NA NA NA NA NA 0 0 NA
> ...
>  $ Q7.OtherMeters                       : num  0 NA NA 57 NA NA NA 0 0 NA
> ...
>  $ Q7...total.meters                    : num  3582 5244 1021 8366 36015 ...
>  $ Q8.15Min.ResAMI                      : num  0 NA NA NA NA NA NA NA NA NA
> ...
>  $ Q8.15Min.ComAMI                      : num  0 NA NA 155 NA NA NA NA NA
> NA ...
>  $ Q8.15Min.IndAMI                      : num  0 NA NA NA NA NA NA NA NA NA
> ...
>  $ Q8.15Min.TransAMI                    : num  0 NA NA NA NA NA NA NA NA NA
> ...
>  $ Q8.15Min.OtherAMI                    : num  0 NA NA NA NA NA NA NA NA NA
> ...
>  $ Q8.15Min.TotalAMI                    : num  0 0 0 155 0 0 0 0 0 0 ...
>  $ Q8.Hourly.ResAMI                     : num  0 NA NA NA 16100 NA NA NA NA
> NA ...
>  $ Q8.Hourly.ComAMI                     : num  0 NA NA NA 1600 NA NA NA NA
> NA ...
> ....
> Jim Holtman
> Data Munger Guru
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> On Wed, Mar 25, 2015 at 5:01 PM, Benjamin Baker <bbaker at reed.edu> wrote:
>> Trying to read and clean up the FERC data on Advanced Metering
>> infrastructure. Of course it is in XLS for the first two survey years and
>> then converts to XLSX for the final two. Bad enough that it is all in
>> excel, they had to change the survey design and data format as well. Still,
>> I?m sorting through it. However, when I try and read in the 2008 data, I?m
>> getting this error:
>> ###
>> Wide character in print at
>> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/gdata/perl/
>> xls2csv.pl line 270.
>> Warning message:
>> In scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>>   EOF within quoted string
>> ###
>>
>>
>>
>> Here is the code I?m running to get the data:
>> ###
>> install.packages("gdata")
>> library("gdata")
>> fileUrl <- "
>> http://www.ferc.gov/industries/electric/indus-act/demand-response/2008/survey/ami_survey_responses.xls
>> "
>> download.file(fileUrl, destfile="./ami.data/ami-data2008.xls")
>> list.files("ami.data")
>> dateDown.2008 <- date()
>> ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1,
>> header=TRUE)
>> ###
>>
>>
>> Reviewed the data in the XLS file, and both ?? and # are present within
>> it. Don?t know how to get the read.xls to ignore them so I can read all the
>> data into my data frame. Tried :
>> ###
>> ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1, quote="",
>> header=TRUE)
>> ###
>>
>>
>> And it spits out ?More columns than column names? output.
>>
>>
>> Been searching this, and I can find some ?solutions? for read.table, but
>> nothing specific to read.xls
>>
>>
>> Many thanks,
>>
>>
>> Benjamin Baker
>>
>>
>>
>> ?
>> Sent from Mailbox
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From bsmith030465 at gmail.com  Sat Mar 28 00:39:41 2015
From: bsmith030465 at gmail.com (Brian Smith)
Date: Fri, 27 Mar 2015 19:39:41 -0400
Subject: [R] hash - extract key values
Message-ID: <CAEQKoCF_Oe4qwVe+N=76wQ3MC1fDj-GBCRhgJU-47Gt4Bnc7Hg@mail.gmail.com>

Hi,

I was trying to use hash, but can't seem to get the keys from the hash.
According to the hash documentation ('hash' package pdf, the following
should work:

> hx <- hash( c('a','b','c'), 1:3 )
> class(hx)
[1] "hash"
attr(,"package")
[1] "hash"
> hx$a
[1] 1
> keys(hx)
Error in (function (classes, fdef, mtable)  :
  unable to find an inherited method for function ?keys? for signature
?"hash"?

How can I get the keys for my hash?

thanks!

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Sat Mar 28 01:00:16 2015
From: btupper at bigelow.org (Ben Tupper)
Date: Fri, 27 Mar 2015 20:00:16 -0400
Subject: [R] Categorizing by month
In-Reply-To: <1427472396067-4705173.post@n4.nabble.com>
References: <1427472396067-4705173.post@n4.nabble.com>
Message-ID: <9E64D1B8-C8B7-49F6-AF6D-FC8DA665FEE8@bigelow.org>

Hi,

On Mar 27, 2015, at 12:06 PM, lychang <lychang at emory.edu> wrote:

> Hi everyone,
> 
> I'm trying to categorize by month in R. How can I do this if my dates are in
> date/month/year form?
> 

I'm not sure about the date form you describe, but if you have the dates as POSIXct you can extract the month as character and categorize with that.

x <- seq(from = as.POSIXct("2000/1/1", format="%Y/%m/%d"), to = as.POSIXct("2009/12/1", format="%Y/%m/%d"), by = 'month')
mon <- format(x, '%m')
xx <- split(x, mon)
str(xx)
List of 12
 $ 01: POSIXct[1:10], format: "2000-01-01" "2001-01-01" "2002-01-01" "2003-01-01" ...
 $ 02: POSIXct[1:10], format: "2000-02-01" "2001-02-01" "2002-02-01" "2003-02-01" ...
 $ 03: POSIXct[1:10], format: "2000-03-01" "2001-03-01" "2002-03-01" "2003-03-01" ...
 $ 04: POSIXct[1:10], format: "2000-04-01" "2001-04-01" "2002-04-01" "2003-04-01" ...
 $ 05: POSIXct[1:10], format: "2000-05-01" "2001-05-01" "2002-05-01" "2003-05-01" ...
 $ 06: POSIXct[1:10], format: "2000-06-01" "2001-06-01" "2002-06-01" "2003-06-01" ...
 $ 07: POSIXct[1:10], format: "2000-07-01" "2001-07-01" "2002-07-01" "2003-07-01" ...
 $ 08: POSIXct[1:10], format: "2000-08-01" "2001-08-01" "2002-08-01" "2003-08-01" ...
 $ 09: POSIXct[1:10], format: "2000-09-01" "2001-09-01" "2002-09-01" "2003-09-01" ...
 $ 10: POSIXct[1:10], format: "2000-10-01" "2001-10-01" "2002-10-01" "2003-10-01" ...
 $ 11: POSIXct[1:10], format: "2000-11-01" "2001-11-01" "2002-11-01" "2003-11-01" ...
 $ 12: POSIXct[1:10], format: "2000-12-01" "2001-12-01" "2002-12-01" "2003-12-01" ...

Does that help?

Ben

> Thanks,
> Lois
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Categorizing-by-month-tp4705173.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From jholtman at gmail.com  Sat Mar 28 01:45:49 2015
From: jholtman at gmail.com (jim holtman)
Date: Fri, 27 Mar 2015 20:45:49 -0400
Subject: [R] Having trouble with gdata read in
In-Reply-To: <1427485957856.c70d8eeb@Nodemailer>
References: <CAAxdm-5aTbG3q0jvaWWKfKw6fNWJE=YeD-e-XtwcZVqF1BMVZA@mail.gmail.com>
	<1427485957856.c70d8eeb@Nodemailer>
Message-ID: <CAAxdm-6_e_jbtW=QMzUnELT8+3GLaRfurKsrLd42DVBS3y2yFg@mail.gmail.com>

pardon me it was my function which is just a call to "readWorksheetFromFile"


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Mar 27, 2015 at 3:52 PM, Benjamin Baker <bbaker at reed.edu> wrote:

>  Jim,
>
> I?m not seeing the command f.readXLSheet in the documentation, nor is it
> executing in my code.
>
>
> ?
> Sent from Mailbox <https://www.dropbox.com/mailbox>
>
> On Thursday, Mar 26, 2015 at 5:15 AM, jim holtman <jholtman at gmail.com>,
> wrote:
>
>> My suggestion is to use XLConnect to read the file:
>>
>>
>>  > x <-
>> "C:\\Users\\jh52822\\AppData\\Local\\Temp\\Rtmp6nVgFC\\file385c632aba3.xls"
>> > require(XLConnect)
>> Loading required package: XLConnect
>> Loading required package: XLConnectJars
>> XLConnect 0.2-10 by Mirai Solutions GmbH [aut],
>>   Martin Studer [cre],
>>   The Apache Software Foundation [ctb, cph] (Apache POI, Apache Commons
>>     Codec),
>>   Stephen Colebourne [ctb, cph] (Joda-Time Java library)
>>  http://www.mirai-solutions.com ,
>> http://miraisolutions.wordpress.com
>> > input <- f.readXLSheet(x, 1)
>> >
>> > str(input)
>> 'data.frame':   2266 obs. of  51 variables:
>>  $ EIA                                  : num  34 59 87 97 108 118 123
>> 149 150 157 ...
>>  $ Entity.Name                          : chr  "City of Abbeville" "City
>> of Abbeville" "City of Ada" "Adams Electric Cooperative" ...
>>  $ State                                : chr  "SC" "LA" "MN" "IL" ...
>>  $ NERC.Region                          : chr  "SERC" "SPP" "MRO" "SERC"
>> ...
>>  $ Filing.Order                         : num  12 11 1237 392 252 ...
>>  $ Q5.MultRegion                        : chr  "" "" "" "" ...
>>  $ Q6.OwnMeters.                        : chr  "Yes" "Yes" "Yes" "Yes" ...
>>  $ Q7.ResMeters                         : num  3051 4253 857 8154 33670
>> ...
>>  $ Q7.ComMeters                         : num  531 972 132 155 1719 ...
>>  $ Q7.IntMeters                         : num  0 19 32 NA 626 NA 29 0 2
>> NA ...
>>  $ Q7.TransMeters                       : num  0 NA NA NA NA NA NA 0 0 NA
>> ...
>>  $ Q7.OtherMeters                       : num  0 NA NA 57 NA NA NA 0 0 NA
>> ...
>>  $ Q7...total.meters                    : num  3582 5244 1021 8366 36015
>> ...
>>  $ Q8.15Min.ResAMI                      : num  0 NA NA NA NA NA NA NA NA
>> NA ...
>>  $ Q8.15Min.ComAMI                      : num  0 NA NA 155 NA NA NA NA NA
>> NA ...
>>  $ Q8.15Min.IndAMI                      : num  0 NA NA NA NA NA NA NA NA
>> NA ...
>>  $ Q8.15Min.TransAMI                    : num  0 NA NA NA NA NA NA NA NA
>> NA ...
>>  $ Q8.15Min.OtherAMI                    : num  0 NA NA NA NA NA NA NA NA
>> NA ...
>>  $ Q8.15Min.TotalAMI                    : num  0 0 0 155 0 0 0 0 0 0 ...
>>  $ Q8.Hourly.ResAMI                     : num  0 NA NA NA 16100 NA NA NA
>> NA NA ...
>>  $ Q8.Hourly.ComAMI                     : num  0 NA NA NA 1600 NA NA NA
>> NA NA ...
>>  ....
>>
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Wed, Mar 25, 2015 at 5:01 PM, Benjamin Baker <bbaker at reed.edu> wrote:
>>
>>> Trying to read and clean up the FERC data on Advanced Metering
>>> infrastructure. Of course it is in XLS for the first two survey years and
>>> then converts to XLSX for the final two. Bad enough that it is all in
>>> excel, they had to change the survey design and data format as well. Still,
>>> I?m sorting through it. However, when I try and read in the 2008 data, I?m
>>> getting this error:
>>> ###
>>> Wide character in print at
>>> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/gdata/perl/
>>> xls2csv.pl line 270.
>>> Warning message:
>>> In scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>>>   EOF within quoted string
>>> ###
>>>
>>>
>>>
>>> Here is the code I?m running to get the data:
>>> ###
>>> install.packages("gdata")
>>> library("gdata")
>>> fileUrl <- "
>>> http://www.ferc.gov/industries/electric/indus-act/demand-response/2008/survey/ami_survey_responses.xls
>>> "
>>> download.file(fileUrl, destfile="./ami.data/ami-data2008.xls")
>>> list.files("ami.data")
>>> dateDown.2008 <- date()
>>> ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1,
>>> header=TRUE)
>>> ###
>>>
>>>
>>> Reviewed the data in the XLS file, and both ?? and # are present within
>>> it. Don?t know how to get the read.xls to ignore them so I can read all the
>>> data into my data frame. Tried :
>>> ###
>>> ami.data2008 <- read.xls("./ami.data/ami-data2008.xls", sheet=1,
>>> quote="", header=TRUE)
>>> ###
>>>
>>>
>>> And it spits out ?More columns than column names? output.
>>>
>>>
>>> Been searching this, and I can find some ?solutions? for read.table, but
>>> nothing specific to read.xls
>>>
>>>
>>> Many thanks,
>>>
>>>
>>> Benjamin Baker
>>>
>>>
>>>
>>> ?
>>> Sent from Mailbox
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Sat Mar 28 01:51:08 2015
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 27 Mar 2015 20:51:08 -0400
Subject: [R] vif in package car: there are aliased coefficients in the
	model
In-Reply-To: <CAHEYhxO+FXLM2+iKwz=OGj+n8ZSLpjv42S+YJJc_tJL3pa8SeA@mail.gmail.com>
References: <CAHEYhxO+FXLM2+iKwz=OGj+n8ZSLpjv42S+YJJc_tJL3pa8SeA@mail.gmail.com>
Message-ID: <005901d068f1$47ceb300$d76c1900$@mcmaster.ca>

Dear Rodolfo,

It's apparently the case that at least one of the columns of the model
matrix for your model is perfectly collinear with others. 

There's not nearly enough information here to figure out exactly what the
problem is, and the information that you provided certainly falls short of
allowing me or anyone else to reproduce your problem and diagnose it
properly. It's not even clear from your message exactly what the structure
of the model is, although localizacao  is apparently a factor with 3 levels.


If you look at the summary() output for your model or just print it, you
should at least see which coefficients are aliased, and that might help you
understand what went wrong.

I hope this helps,
 John

-------------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rodolfo
> Pelinson
> Sent: March-27-15 3:07 PM
> To: r-help at r-project.org
> Subject: [R] vif in package car: there are aliased coefficients in the
model
> 
> Hello. I'm trying to use the function vif from package car in a lm.
However it
> returns the following error:
> "Error in vif.default(lm(MDescores.sitescores ~ hidroperiodo + localizacao
> +  : there are aliased coefficients in the model"
> 
> When I exclude any predictor from the model, it returns this warning
> message:
> "Warning message: In cov2cor(v) : diag(.) had 0 or NA entries; non-finite
> result is doubtful"
> 
> When I exclude any other predictor from the model vif finally works. I
can't
> figure it out whats the problem. This are the results that R returns
> me:
> 
> > vif(lm(MDescores.sitescores ~ hidroperiodo + localizacao + area +
> profundidade + NTVM +  NTVI + PCs...c.1.., data = MDVIF)) Error in
> vif.default(lm(MDescores.sitescores ~ hidroperiodo + localizacao +
>  :   there are aliased coefficients in the model
> 
> > vif(lm(MDescores.sitescores ~ localizacao + area + profundidade + NTVM
> > +
>  NTVI + PCs...c.1.., data = MDVIF))
>              GVIF Df GVIF^(1/(2*Df))
> localizacao   NaN  2             NaN
> area          NaN  1             NaN
> profundidade  NaN  1             NaN
> NTVM          NaN  1             NaN
> NTVI          NaN  1             NaN
> PCs...c.1..   NaN  1             NaN
> Warning message:
> In cov2cor(v) : diag(.) had 0 or NA entries; non-finite result is doubtful
> 
> Thanks.
> --
> Rodolfo Mei Pelinson.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


---
This email has been checked for viruses by Avast antivirus software.
http://www.avast.com


From boris.steipe at utoronto.ca  Sat Mar 28 02:54:40 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 27 Mar 2015 21:54:40 -0400
Subject: [R] hash - extract key values
In-Reply-To: <CAEQKoCF_Oe4qwVe+N=76wQ3MC1fDj-GBCRhgJU-47Gt4Bnc7Hg@mail.gmail.com>
References: <CAEQKoCF_Oe4qwVe+N=76wQ3MC1fDj-GBCRhgJU-47Gt4Bnc7Hg@mail.gmail.com>
Message-ID: <1E56370E-8FD1-4383-9D12-FE114D9CF0F7@utoronto.ca>

Works for me :

> library(hash)
hash-2.2.6 provided by Decision Patterns

> hx <- hash( c('a','b','c'), 1:3 )
> class(hx)
[1] "hash"
attr(,"package")
[1] "hash"
> hx$a
[1] 1
> keys(hx)
[1] "a" "b" "c"


Maybe restart your session? Clear your workspace? Upgrade?

B.





On Mar 27, 2015, at 7:39 PM, Brian Smith <bsmith030465 at gmail.com> wrote:

> Hi,
> 
> I was trying to use hash, but can't seem to get the keys from the hash.
> According to the hash documentation ('hash' package pdf, the following
> should work:
> 
>> hx <- hash( c('a','b','c'), 1:3 )
>> class(hx)
> [1] "hash"
> attr(,"package")
> [1] "hash"
>> hx$a
> [1] 1
>> keys(hx)
> Error in (function (classes, fdef, mtable)  :
>  unable to find an inherited method for function ?keys? for signature
> ?"hash"?
> 
> How can I get the keys for my hash?
> 
> thanks!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Sat Mar 28 05:40:21 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 27 Mar 2015 21:40:21 -0700
Subject: [R] Using and abusing %>% (was Re: Why can't I access this
	type?)
In-Reply-To: <551568C7.9040400@gmail.com>
References: <CAJ=2b04qLmoA8W--=dsv2vqMHkG1Y7Tv_QQx_9D78oopJku+Yg@mail.gmail.com>
	<28E315E85F1.00000296jrkrideau@inbox.com>
	<20150325084041.GA2875@slingshot.co.nz>
	<5512C2BA.6020301@gmail.com> <20150326064852.GB2875@slingshot.co.nz>
	<551568C7.9040400@gmail.com>
Message-ID: <CABdHhvFNXR3iNmck0EF68gbvQOQ6LoVA19muKBEGVCjFQan1oA@mail.gmail.com>

> I didn't dispute whether '%>%' may be useful -- I just pointed out that it
> is slow.  However, it is only part of the problem: 'filter()' and
> 'select()', although aesthetically pleasing, also seem to be slow:
>
>> all.states <- data.frame(state.x77, Name = rownames(state.x77))
>>
>> f1 <- function()
> +     all.states[all.states$Frost > 150, c("Name", "Frost")]
>>
>> f2 <- function()
> +     subset(all.states, Frost > 150, select = c("Name", "Frost"))
>>
>> f3 <- function() {
> +     filt <- subset(all.states, Frost > 150)
> +     subset(filt, select = c("Name", "Frost"))
> + }
>>
>> f4 <- function()
> +     all.states %>% subset(Frost > 150) %>%
> +         subset(select = c("Name", "Frost"))
>>
>> f5 <- function()
> +     select(filter(all.states, Frost > 150), Name, Frost)
>>
>> f6 <- function()
> +     all.states %>% filter(Frost > 150) %>% select(Name, Frost)
>>
>> mb <- microbenchmark(
> +     f1(), f2(), f3(), f4(), f5(), f6(),
> +     times = 1000L
> + )
>> print(mb, signif = 3L)
> Unit: microseconds
>  expr min   lq      mean median   uq  max neval   cld
>  f1() 115  124  134.8812    129  134 1500  1000 a
>  f2() 128  141  147.4694    145  151 1520  1000 a
>  f3() 303  328  344.3175    338  348 1740  1000  b
>  f4() 458  494  518.0830    510  523 1890  1000   c
>  f5() 806  848  887.7270    875  894 3510  1000    d
>  f6() 971 1010 1056.5659   1040 1060 3110  1000     e
>
> So, using '%>%', but leaving 'filter()' and 'select()' out of the equation,
> as in 'f4()' is only half as bad as the "full" 'dplyr' idiom in 'f6()'.  In
> this case, since we're talking microseconds, the speed-up is negligible but
> that *is* beside the point.

When benchmarking it's important to consider both the relative and
absolute difference and to think about how the cost scales as the data
grows - the cost of using using %>% is fixed, and 500 ?s doesn't seem
like a huge performance penalty to me.

Hadley

-- 
http://had.co.nz/


From bsmith030465 at gmail.com  Sat Mar 28 07:03:09 2015
From: bsmith030465 at gmail.com (Brian Smith)
Date: Sat, 28 Mar 2015 02:03:09 -0400
Subject: [R] hash - extract key values
In-Reply-To: <1E56370E-8FD1-4383-9D12-FE114D9CF0F7@utoronto.ca>
References: <CAEQKoCF_Oe4qwVe+N=76wQ3MC1fDj-GBCRhgJU-47Gt4Bnc7Hg@mail.gmail.com>
	<1E56370E-8FD1-4383-9D12-FE114D9CF0F7@utoronto.ca>
Message-ID: <CAEQKoCF3dT1LYaSog6d=UfC8LxwVScS9zanBxTkzS3eOM8xXpg@mail.gmail.com>

Exactly. Used to work for me, but not anymore. I tried restarting session,
installing the most recent package of 'hash' etc.

Here is my sessionInfo():

> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
 [1] grid      parallel  stats4    stats     graphics  grDevices utils
datasets  methods   base

other attached packages:
 [1] mapdata_2.2-3        maps_2.3-9           org.Hs.eg.db_3.0.0
multicore_0.1-7      nlme_3.1-120         Rgraphviz_2.10.0
 [7] biomaRt_2.22.0       topGO_2.18.0         SparseM_1.6
 GO.db_3.0.0          graph_1.44.1         mouse4302.db_3.0.0
[13] org.Mm.eg.db_3.0.0   RSQLite_1.0.0        DBI_0.3.1
 AnnotationDbi_1.28.1 GenomeInfoDb_1.2.4   IRanges_2.0.1
[19] S4Vectors_0.4.0      Biobase_2.26.0       BiocGenerics_0.12.1
 XML_3.98-1.1         gap_1.1-12           som_0.3-5
[25] pvclust_1.3-2        foreign_0.8-63       hash_3.0.1

loaded via a namespace (and not attached):
[1] bitops_1.0-6    lattice_0.20-29 RCurl_1.95-4.5  tools_3.1.2




On Fri, Mar 27, 2015 at 9:54 PM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> Works for me :
>
> > library(hash)
> hash-2.2.6 provided by Decision Patterns
>
> > hx <- hash( c('a','b','c'), 1:3 )
> > class(hx)
> [1] "hash"
> attr(,"package")
> [1] "hash"
> > hx$a
> [1] 1
> > keys(hx)
> [1] "a" "b" "c"
>
>
> Maybe restart your session? Clear your workspace? Upgrade?
>
> B.
>
>
>
>
>
> On Mar 27, 2015, at 7:39 PM, Brian Smith <bsmith030465 at gmail.com> wrote:
>
> > Hi,
> >
> > I was trying to use hash, but can't seem to get the keys from the hash.
> > According to the hash documentation ('hash' package pdf, the following
> > should work:
> >
> >> hx <- hash( c('a','b','c'), 1:3 )
> >> class(hx)
> > [1] "hash"
> > attr(,"package")
> > [1] "hash"
> >> hx$a
> > [1] 1
> >> keys(hx)
> > Error in (function (classes, fdef, mtable)  :
> >  unable to find an inherited method for function ?keys? for signature
> > ?"hash"?
> >
> > How can I get the keys for my hash?
> >
> > thanks!
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From p_connolly at slingshot.co.nz  Sat Mar 28 08:48:52 2015
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Sat, 28 Mar 2015 20:48:52 +1300
Subject: [R] Using and abusing %>% (was Re: Why can't I access this
	type?)
In-Reply-To: <551568C7.9040400@gmail.com>
References: <CAJ=2b04qLmoA8W--=dsv2vqMHkG1Y7Tv_QQx_9D78oopJku+Yg@mail.gmail.com>
	<28E315E85F1.00000296jrkrideau@inbox.com>
	<20150325084041.GA2875@slingshot.co.nz>
	<5512C2BA.6020301@gmail.com>
	<20150326064852.GB2875@slingshot.co.nz>
	<551568C7.9040400@gmail.com>
Message-ID: <20150328074852.GE2875@slingshot.co.nz>

On Fri, 27-Mar-2015 at 03:27PM +0100, Henric Winell wrote:

|> On 2015-03-26 07:48, Patrick Connolly wrote:
|> 
|> >On Wed, 25-Mar-2015 at 03:14PM +0100, Henric Winell wrote:
|> >
|> >...
|> >
|> >|> Well...  Opinions may perhaps differ, but apart from '%>%' being
|> >|> butt-ugly it's also fairly slow:
|> >
|> >Beauty, it is said, is in the eye of the beholder.  I'm impressed by
|> >the way using %>% reduces or eliminates complicated nested brackets.
|> 
|> I didn't dispute whether '%>%' may be useful -- I just pointed out

Likewise I didn't dispute that it might not be as fast as other ways,
but I was disputing the claim that it was ugly.

|> that it is slow.  However, it is only part of the problem:
|> 'filter()' and 'select()', although aesthetically pleasing, also
|> seem to be slow:

So not 'butt ugly' like '%>%'?

|> 
....

|> > mb <- microbenchmark(
|> +     f1(), f2(), f3(), f4(), f5(), f6(),
|> +     times = 1000L
|> + )
|> > print(mb, signif = 3L)
|> Unit: microseconds
|>  expr min   lq      mean median   uq  max neval   cld
|>  f1() 115  124  134.8812    129  134 1500  1000 a
|>  f2() 128  141  147.4694    145  151 1520  1000 a
|>  f3() 303  328  344.3175    338  348 1740  1000  b
|>  f4() 458  494  518.0830    510  523 1890  1000   c
|>  f5() 806  848  887.7270    875  894 3510  1000    d
|>  f6() 971 1010 1056.5659   1040 1060 3110  1000     e
|> 
|> So, using '%>%', but leaving 'filter()' and 'select()' out of the
|> equation, as in 'f4()' is only half as bad as the "full" 'dplyr'
|> idiom in 'f6()'.  In this case, since we're talking microseconds,
|> the speed-up is negligible but that *is* beside the point.

Agreed that the more 'dplyr' used the slower it gets but don't agree
that it's an issue except in packages that should be optimized.  The
lack of speed won't stop me using it any more than I'll stop using
dataframes because matrices are much faster than them.  The OP's
example can be done using matrix syntax:

state.x77[state.x77[, "Frost"] > 150, "Frost", drop = FALSE] 


which is more than an order of magnitude faster than subscripting a
dataframe.  See No 4. here:

  microbenchmark(## 1. using subset()
        subset(all.states, all.states$Frost > 150, select = c("state","Frost")),
        ## 2. standard R indexing
        all.states[all.states$Frost > 150, c("state","Frost")],
        ## 3. leave out redundant 'state' column
        all.states[all.states$Frost > 150, "Frost", drop = FALSE],
        ## 4. avoid using 'slow' dataframes altogether
        state.x77[state.x77[, "Frost"] > 150, "Frost", drop = FALSE],
        ## 5. easy, slow way without square brackets or quote marks
        all.states %>% filter(Frost > 150) %>% select(state, Frost),
        times = 1000L
        )

Unit: microseconds
                                                                      expr
  subset(all.states, all.states$Frost > 150, select = c("state", "Frost"))
                   all.states[all.states$Frost > 150, c("state", "Frost")]
                 all.states[all.states$Frost > 150, "Frost", drop = FALSE]
              state.x77[state.x77[, "Frost"] > 150, "Frost", drop = FALSE]
               all.states %>% filter(Frost > 150) %>% select(state, Frost)
      min        lq       mean    median        uq      max neval  cld
  223.960  229.9290  236.16557  232.4060  241.4165  291.083  1000   c 
  177.187  182.6075  203.04666  185.1475  194.4815 7259.760  1000   c 
  125.281  130.4835  135.83826  132.6985  141.7375  210.576  1000  b  
    6.442   10.3860   10.61733   11.0405   11.4855   25.077  1000 a   
 1416.592 1437.7015 1562.91898 1447.5695 1473.4440 9394.071  1000    d
> 

[...]

|> 
|> >In this tiny example it's not obvious but it's very clear if the
|> >objective is to sort the dataframe by three or four columns and
|> >various lots of aggregation then returning a largish number of
|> >consecutive columns, omitting the rest.  It's very easy to see what's
|> >going on without the need for intermediate objects.
|> 
|> Why are you opposed to using intermediate objects?  In this case,

I'm not opposed to intermediate objects nor to dogs.  It's just easier
to keep things tidy without either.


|> as can be seen from 'f3()', it will also have the benefit of being
|> faster than either '%>%' or the "full" 'dplyr' idiom.
|> 
|> >|> [...]
|> >
|> >It's no surprise that instructing a computer in something closer to
|> >human language is an order of magnitude slower.
|> 
|> Certainly not true, at least for compiled languages.  In any case,
|> judging from off-list correspondence, it definitely came as a
|> surprise to some R users...
|> 
|> Given that '%>%' is so heavily marketed through 'dplyr', where the
|> latter is said to provide "blazing fast performance for in-memory
|> data by writing key pieces in C++" and "a fast, consistent tool for
|> working with data frame like objects, both in memory and out of
|> memory", I don't think it's far-fetched to expect that it should be
|> more performant than base R.
|> 

I've never come across 'marketing' of free software.  Evidently that's
a looser use of the word.

...


|> >I spend 3 or 4 orders of magnitude more time writing code than running it.
|> 
|> You and me both.  But that doesn't mean speed is of no or little importance.

I never claimed it was.  Tardiness hasn't yet become an issue for me.
When it does, I'll revert to the old ways.

|> 
|> >It's much more important to me to be able to read and modify than
|> > it is to have it run at optimum speed.
|> 
|> Good for you.  But surely, if this is your goal, nothing beats
|> intermediate objects.  

Nothing except chaining, that is.  I went 16 years without it and now
find it amazing how useful it is.  As they say: You're never too old
to learn.


|>  And like I said, it may still be faster than the 'dplyr' idiom.
|> 
|> >|> Of course, this doesn't matter for interactive one-off use.  But
|> >|> lately I've seen examples of the '%>%' operator creeping into
|> >|> functions in packages.
|> >
|> >That could indicate that %>% is seductively easy to use.  It's
|> >probably true that there are places where it should be done the hard
|> >way.
|> 
|> We all know how easy it is to write ugly and sluggish code in R.
|> But 'foo[i,j]' is neither ugly nor sluggish and certainly not "the
|> hard way."

I meant to put a ':-)' in there. Such adjectives as 'easy' and 'hard' are
relative.  There's little difference in difficulty at each step, but
integrating them and revising later are considerably easier using the
so-called "'dplyr' idiom" -- especially if each link in the chain is
on a separate line.

|> 
|> >|>  However, it would be nice to see a fast pipe operator as part of
|> >|> base R.
|> 
|> Heck, it doesn't even have to be fast as long as it's a bit more
|> elegant than '%>%'.

IMHO, %>% fits in nicely with %/%, %%, and %in%.  Elegance, like
beauty, is in the eye of the beholder.

|> 
|> 
|> Henric Winell
|> 
|> 
|> 
|> >
|> >|>
|> >|>
|> >|> Henric Winell
|> >|>
|> >

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From ligges at statistik.tu-dortmund.de  Sat Mar 28 10:02:13 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 28 Mar 2015 10:02:13 +0100
Subject: [R] hash - extract key values
In-Reply-To: <CAEQKoCF3dT1LYaSog6d=UfC8LxwVScS9zanBxTkzS3eOM8xXpg@mail.gmail.com>
References: <CAEQKoCF_Oe4qwVe+N=76wQ3MC1fDj-GBCRhgJU-47Gt4Bnc7Hg@mail.gmail.com>	<1E56370E-8FD1-4383-9D12-FE114D9CF0F7@utoronto.ca>
	<CAEQKoCF3dT1LYaSog6d=UfC8LxwVScS9zanBxTkzS3eOM8xXpg@mail.gmail.com>
Message-ID: <55166E15.7090108@statistik.tu-dortmund.de>

Try to reinstall hash. Sounds like a broken installation.

Best,
Uwe Ligges


On 28.03.2015 07:03, Brian Smith wrote:
> Exactly. Used to work for me, but not anymore. I tried restarting session,
> installing the most recent package of 'hash' etc.
>
> Here is my sessionInfo():
>
>> sessionInfo()
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
>   [1] grid      parallel  stats4    stats     graphics  grDevices utils
> datasets  methods   base
>
> other attached packages:
>   [1] mapdata_2.2-3        maps_2.3-9           org.Hs.eg.db_3.0.0
> multicore_0.1-7      nlme_3.1-120         Rgraphviz_2.10.0
>   [7] biomaRt_2.22.0       topGO_2.18.0         SparseM_1.6
>   GO.db_3.0.0          graph_1.44.1         mouse4302.db_3.0.0
> [13] org.Mm.eg.db_3.0.0   RSQLite_1.0.0        DBI_0.3.1
>   AnnotationDbi_1.28.1 GenomeInfoDb_1.2.4   IRanges_2.0.1
> [19] S4Vectors_0.4.0      Biobase_2.26.0       BiocGenerics_0.12.1
>   XML_3.98-1.1         gap_1.1-12           som_0.3-5
> [25] pvclust_1.3-2        foreign_0.8-63       hash_3.0.1
>
> loaded via a namespace (and not attached):
> [1] bitops_1.0-6    lattice_0.20-29 RCurl_1.95-4.5  tools_3.1.2
>
>
>
>
> On Fri, Mar 27, 2015 at 9:54 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
>
>> Works for me :
>>
>>> library(hash)
>> hash-2.2.6 provided by Decision Patterns
>>
>>> hx <- hash( c('a','b','c'), 1:3 )
>>> class(hx)
>> [1] "hash"
>> attr(,"package")
>> [1] "hash"
>>> hx$a
>> [1] 1
>>> keys(hx)
>> [1] "a" "b" "c"
>>
>>
>> Maybe restart your session? Clear your workspace? Upgrade?
>>
>> B.
>>
>>
>>
>>
>>
>> On Mar 27, 2015, at 7:39 PM, Brian Smith <bsmith030465 at gmail.com> wrote:
>>
>>> Hi,
>>>
>>> I was trying to use hash, but can't seem to get the keys from the hash.
>>> According to the hash documentation ('hash' package pdf, the following
>>> should work:
>>>
>>>> hx <- hash( c('a','b','c'), 1:3 )
>>>> class(hx)
>>> [1] "hash"
>>> attr(,"package")
>>> [1] "hash"
>>>> hx$a
>>> [1] 1
>>>> keys(hx)
>>> Error in (function (classes, fdef, mtable)  :
>>>   unable to find an inherited method for function ?keys? for signature
>>> ?"hash"?
>>>
>>> How can I get the keys for my hash?
>>>
>>> thanks!
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ragia11 at hotmail.com  Sat Mar 28 11:42:59 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Sat, 28 Mar 2015 12:42:59 +0200
Subject: [R] creating matrix row by row
In-Reply-To: <DUB125-W71E579AA58379A7F03777FB3F70@phx.gbl>
References: <DUB125-W74A585A523EF697C41BF54B33F0@phx.gbl>,
	<CAJRuHor1WGZVMSMk5xyxDNqwTePme73MXzs48sdzKeEJCgut7Q@mail.gmail.com>,
	<DUB125-W71E579AA58379A7F03777FB3F70@phx.gbl>
Message-ID: <DUB125-W459EBECB8BCC1F7F55D2E0B3F70@phx.gbl>

 



Hi,
 I have a original adjacency  matrix  n X n , and I want to connect certain row with
 a set of other selected columns (could be not the same as in the 
original matrix).
this in each iteration I have a new row of this connections matrix , how to create this matrix.
having original row number and the numbers of columns that will be connected to.

e.g. 
   1 2 3 4 5
1  1 1 1 1 1
2  1 1 0 0 1
3
4
4

inf first iteration row 1 will have only connections to columns 2 and 5
and in secondly  row 2 will have only relation to column 2

how can I do this
thanks in advance

 		 	   		   		 	   		  
	[[alternative HTML version deleted]]


From ispanyolcom at gmail.com  Sat Mar 28 00:41:35 2015
From: ispanyolcom at gmail.com (=?UTF-8?Q?Temel_=C4=B0spanyolca?=)
Date: Sat, 28 Mar 2015 00:41:35 +0100
Subject: [R] multiple break in univariate series
Message-ID: <CAMUSX8p2f8zQsao5NvTv_1fmkp2bufW2oa_xV-vTst2QVokDVA@mail.gmail.com>

Hello
Any one knows multiple break test for univariate series ?

-- 
*Thanks*
Engin YILMAZ

	[[alternative HTML version deleted]]


From raluca.gui at business.uzh.ch  Sat Mar 28 00:32:26 2015
From: raluca.gui at business.uzh.ch (RiGui)
Date: Fri, 27 Mar 2015 16:32:26 -0700 (PDT)
Subject: [R] Error in lm() with very small (close to zero) regressor
Message-ID: <1427499146685-4705185.post@n4.nabble.com>

Hello everybody,

I have encountered the following problem with lm():

When running lm() with a regressor close to zero - of the order e-10, the
value of the estimate is of huge absolute value , of order millions. 

However, if I write the formula of the OLS estimator, in matrix notation:
pseudoinverse(t(X)*X) * t(X) * y , the results are correct, meaning the
estimate has value 0.

here is the code:

y  <- rnorm(n_obs, 10,2.89)
x1 <- rnorm(n_obs, 0.00000000000001235657,0.000000000000000045)
x2 <- rnorm(n_obs, 10,3.21)
X  <- cbind(x1,x2)

bFE <- lm(y ~ x1 + x2)
bFE

bOLS <- pseudoinverse(t(X) %*% X) %*% t(X) %*% y
bOLS


Note: I am applying a deviation from the mean projection to the data, that
is why I have some regressors with such small values.

Thank you for any help!

Raluca






--
View this message in context: http://r.789695.n4.nabble.com/Error-in-lm-with-very-small-close-to-zero-regressor-tp4705185.html
Sent from the R help mailing list archive at Nabble.com.


From tr206 at kent.ac.uk  Sat Mar 28 10:04:04 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sat, 28 Mar 2015 09:04:04 +0000
Subject: [R] cannot load midasr package
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A12F536BA62@EX10-LIVE-MBN2.ad.kent.ac.uk>

Dear Sirs,
I am trying to implement the MIDAS regression but I cannot load the midasr package.
When I load the package I get following message:
> library(midasr)
Loading required package: sandwich
Loading required package: optimx
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called 'Rcpp'
Error: package 'optimx' could not be loaded
> rvh<-mls(rv,0:(h-1),1)
Error: could not find function "mls"

I am using version 3.1.3 and 3.0.2 but neither version works. When I was working with it last week everything was okay but now it does not work anymore. What can I do?

Thanks for your help.

Kind regards,
T. Riedle



	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sat Mar 28 16:29:39 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 28 Mar 2015 08:29:39 -0700
Subject: [R] cannot load midasr package
In-Reply-To: <AEB16B1613D44C4793A7E6B6986B7A12F536BA62@EX10-LIVE-MBN2.ad.kent.ac.uk>
References: <AEB16B1613D44C4793A7E6B6986B7A12F536BA62@EX10-LIVE-MBN2.ad.kent.ac.uk>
Message-ID: <8EE85730-CF99-48D1-8B69-C4BC710D16EF@dcn.davis.CA.us>

Have you read the error message? Can you load the other packages being complained about? Have you read and considered using the information supplied by "?maintainer" ?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 28, 2015 2:04:04 AM PDT, "T.Riedle" <tr206 at kent.ac.uk> wrote:
>Dear Sirs,
>I am trying to implement the MIDAS regression but I cannot load the
>midasr package.
>When I load the package I get following message:
>> library(midasr)
>Loading required package: sandwich
>Loading required package: optimx
>Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
>vI[[i]]) :
>  there is no package called 'Rcpp'
>Error: package 'optimx' could not be loaded
>> rvh<-mls(rv,0:(h-1),1)
>Error: could not find function "mls"
>
>I am using version 3.1.3 and 3.0.2 but neither version works. When I
>was working with it last week everything was okay but now it does not
>work anymore. What can I do?
>
>Thanks for your help.
>
>Kind regards,
>T. Riedle
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sat Mar 28 16:33:23 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 28 Mar 2015 16:33:23 +0100
Subject: [R] Error in lm() with very small (close to zero) regressor
In-Reply-To: <1427499146685-4705185.post@n4.nabble.com>
References: <1427499146685-4705185.post@n4.nabble.com>
Message-ID: <25BAAC3A-D5C0-4094-BFB6-6D67328CC33E@gmail.com>


> On 28 Mar 2015, at 00:32 , RiGui <raluca.gui at business.uzh.ch> wrote:
> 
> Hello everybody,
> 
> I have encountered the following problem with lm():
> 
> When running lm() with a regressor close to zero - of the order e-10, the
> value of the estimate is of huge absolute value , of order millions. 
> 
> However, if I write the formula of the OLS estimator, in matrix notation:
> pseudoinverse(t(X)*X) * t(X) * y , the results are correct, meaning the
> estimate has value 0.
> 
> here is the code:
> 
> y  <- rnorm(n_obs, 10,2.89)
> x1 <- rnorm(n_obs, 0.00000000000001235657,0.000000000000000045)
> x2 <- rnorm(n_obs, 10,3.21)
> X  <- cbind(x1,x2)
> 
> bFE <- lm(y ~ x1 + x2)
> bFE
> 
> bOLS <- pseudoinverse(t(X) %*% X) %*% t(X) %*% y
> bOLS
> 
> 
> Note: I am applying a deviation from the mean projection to the data, that
> is why I have some regressors with such small values.
> 
> Thank you for any help!
> 
> Raluca
> 
Example not reproducible:

> y  <- rnorm(n_obs, 10,2.89)
Error in rnorm(n_obs, 10, 2.89) : object 'n_obs' not found
> x1 <- rnorm(n_obs, 0.00000000000001235657,0.000000000000000045)
Error in rnorm(n_obs, 1.235657e-14, 4.5e-17) : object 'n_obs' not found
> x2 <- rnorm(n_obs, 10,3.21)
Error in rnorm(n_obs, 10, 3.21) : object 'n_obs' not found
> X  <- cbind(x1,x2)
Error in cbind(x1, x2) : object 'x1' not found
> 
> bFE <- lm(y ~ x1 + x2)
Error in eval(expr, envir, enclos) : object 'y' not found
> bFE
Error: object 'bFE' not found
> 
> bOLS <- pseudoinverse(t(X) %*% X) %*% t(X) %*% y
Error: could not find function "pseudoinverse"
> bOLS
Error: object 'bOLS' not found



-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bbolker at gmail.com  Sat Mar 28 18:28:22 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 28 Mar 2015 17:28:22 +0000
Subject: [R] Error in lm() with very small (close to zero) regressor
References: <1427499146685-4705185.post@n4.nabble.com>
	<25BAAC3A-D5C0-4094-BFB6-6D67328CC33E@gmail.com>
Message-ID: <loom.20150328T181834-1@post.gmane.org>

peter dalgaard <pdalgd <at> gmail.com> writes:

> 
> 
> > On 28 Mar 2015, at 00:32 , RiGui <raluca.gui <at> business.uzh.ch> wrote:
> > 
> > Hello everybody,
> > 
> > I have encountered the following problem with lm():
> > 
> > When running lm() with a regressor close to zero - 
> of the order e-10, the
> > value of the estimate is of huge absolute value , of order millions. 
> > 
> > However, if I write the formula of the OLS estimator, 
> in matrix notation:
> > pseudoinverse(t(X)*X) * t(X) * y , the results are correct, meaning the
> > estimate has value 0.

  How do you know this answer is "correct"?

> > here is the code:
> > 
> > y  <- rnorm(n_obs, 10,2.89)
> > x1 <- rnorm(n_obs, 0.00000000000001235657,0.000000000000000045)
> > x2 <- rnorm(n_obs, 10,3.21)
> > X  <- cbind(x1,x2)
> > 
> > bFE <- lm(y ~ x1 + x2)
> > bFE
> > 
> > bOLS <- pseudoinverse(t(X) %*% X) %*% t(X) %*% y
> > bOLS
> > 
> > 
> > Note: I am applying a deviation from the 
> mean projection to the data, that
> > is why I have some regressors with such small values.
> > 
> > Thank you for any help!
> > 
> > Raluca

  Is there a reason you can't scale your regressors?

> > 
> Example not reproducible:
> 

  I agree that the OP's question was not reproducible, but it's
not too hard to make it reproducible. I bothered to use
library("sos"); findFn("pseudoinverse") to find pseudoinverse()
in corpcor:

It is true that we get estimates with very large magnitudes,
but their 

set.seed(101)
n_obs <- 1000
y  <- rnorm(n_obs, 10,2.89)
x1 <- rnorm(n_obs, mean=1.235657e-14,sd=4.5e-17)
x2 <- rnorm(n_obs, 10,3.21)
X  <- cbind(x1,x2)
 
bFE <- lm(y ~ x1 + x2)
bFE
coef(summary(bFE))

                 Estimate   Std. Error     t value  Pr(>|t|)
(Intercept)  1.155959e+01 2.312956e+01  0.49977541 0.6173435
x1          -1.658420e+14 1.872598e+15 -0.08856254 0.9294474
x2           3.797342e-02 2.813000e-02  1.34992593 0.1773461

library("corpcor")
bOLS <- pseudoinverse(t(X) %*% X) %*% t(X) %*% y
bOLS

             [,1]
[1,] 9.807664e-16
[2,] 8.880273e-01

And if we scale the predictor:

bFE2 <- lm(y ~ I(1e14*x1) + x2)
coef(summary(bFE2))

                 Estimate Std. Error     t value  Pr(>|t|)
(Intercept)   11.55958731   23.12956  0.49977541 0.6173435
I(1e+14 * x1) -1.65842037   18.72598 -0.08856254 0.9294474
x2             0.03797342    0.02813  1.34992593 0.1773461

bOLS stays constant.

To be honest, I haven't thought about this enough to see
which answer is actually correct, although I suspect the
problem is in bOLS, since the numerical methods (unlike
the brute-force pseudoinverse method given here) behind
lm have been carefully considered for numerical stability.


From jfox at mcmaster.ca  Sat Mar 28 19:17:52 2015
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 28 Mar 2015 14:17:52 -0400
Subject: [R] vif in package car: there are aliased coefficients in the
	model
In-Reply-To: <CAHEYhxNduK+dqo_33PQH15EigyaffD96OQycz0u6G3A4aeN_zg@mail.gmail.com>
References: <CAHEYhxO+FXLM2+iKwz=OGj+n8ZSLpjv42S+YJJc_tJL3pa8SeA@mail.gmail.com>
	<005901d068f1$47ceb300$d76c1900$@mcmaster.ca>
	<CAHEYhxNduK+dqo_33PQH15EigyaffD96OQycz0u6G3A4aeN_zg@mail.gmail.com>
Message-ID: <web-553901633@cgpsrv2.cis.mcmaster.ca>

Dear Rodolfo,

Sending the data helps, though if you had done what I suggested, you would have seen what's going on:

-------------------- snip ------------------

> dim(data)
[1] 8 8

> summary(lm(response_variable ~ predictor_1 + predictor_2 + predictor_3 + predictor_4 
+             + predictor_5 + predictor_6 + predictor_7, data = data))

Call:
lm(formula = response_variable ~ predictor_1 + predictor_2 + 
    predictor_3 + predictor_4 + predictor_5 + predictor_6 + predictor_7, 
    data = data)

Residuals:
ALL 8 residuals are 0: no residual degrees of freedom!

Coefficients: (1 not defined because of singularities)
                    Estimate Std. Error t value Pr(>|t|)
(Intercept)          -5.1905         NA      NA       NA
predictor_1yellow     2.4477         NA      NA       NA
predictor_2fora       6.5056         NA      NA       NA
predictor_2interior   6.0769         NA      NA       NA
predictor_3           0.6750         NA      NA       NA
predictor_4           3.0742         NA      NA       NA
predictor_5           0.6715         NA      NA       NA
predictor_6          -0.9850         NA      NA       NA
predictor_7               NA         NA      NA       NA

Residual standard error: NaN on 0 degrees of freedom
Multiple R-squared:      1,	Adjusted R-squared:    NaN 
F-statistic:   NaN on 7 and 0 DF,  p-value: NA

-------------------- snip ------------------

So the data set that you're using has 8 cases and 8 variables, one of which is a factor with 3 levels. Consequently, the model you're fitting my LS has 9 coefficients. Necessarily the rank of the model matrix is deficient. When you eliminate a coefficient, you get a perfect fit: 8 coefficients fit to 8 cases with 0 df for error.

This is of course nonsense: You don't have enough data to fit a model of this complexity. In fact, you might not have enough data to reasonably fit a model with just 1 predictor.

I'm cc'ing this response to the r-help email list, where you started this thread.

Best,
 John

On Sat, 28 Mar 2015 12:04:05 -0300
 Rodolfo Pelinson <rodolfopelinson at gmail.com> wrote:
> Thanks a lot for your answer and your time! But Im still having the same
> problem.
> 
> That's the script I am using:
> ____________________________________________________________________________________________________________________
> library(car)
> 
> data <-read.table("data_vif.txt", header = T, sep = "\t", row.names = 1)
> data
> 
> vif(lm(response_variable ~ predictor_1 + predictor_2 + predictor_3 +
> predictor_4 + predictor_5 + predictor_6 + predictor_7, data = data))
> 
> vif(lm(response_variable ~ predictor_1 + predictor_2 + predictor_3 +
> predictor_4 + predictor_5 + predictor_6, data = data))
> ____________________________________________________________________________________________________________________
> 
> the first vif function above returns me the following error:
> 
> "Error in vif.default(lm(response_variable ~ predictor_1 + predictor_2 +  :
>   there are aliased coefficients in the model"
> 
> Then if I remove any one of the predictors (in the script I removed
> predictor_7 as an example), it returns this:
> 
>             GVIF Df GVIF^(1/(2*Df))
> predictor_1  NaN  1             NaN
> predictor_2  NaN  2             NaN
> predictor_3  NaN  1             NaN
> predictor_4  NaN  1             NaN
> predictor_5  NaN  1             NaN
> predictor_6  NaN  1             NaN
> Warning message:
> In cov2cor(v) : diag(.) had 0 or NA entries; non-finite result is doubtful
> 
> 
> Can you help me with this? I even attached to this e-mail my data set. It's
> a small table.
> 
> Sorry for the question.
> 
> 
> 
> 2015-03-27 21:51 GMT-03:00 John Fox <jfox at mcmaster.ca>:
> 
> > Dear Rodolfo,
> >
> > It's apparently the case that at least one of the columns of the model
> > matrix for your model is perfectly collinear with others.
> >
> > There's not nearly enough information here to figure out exactly what the
> > problem is, and the information that you provided certainly falls short of
> > allowing me or anyone else to reproduce your problem and diagnose it
> > properly. It's not even clear from your message exactly what the structure
> > of the model is, although localizacao  is apparently a factor with 3
> > levels.
> >
> >
> > If you look at the summary() output for your model or just print it, you
> > should at least see which coefficients are aliased, and that might help you
> > understand what went wrong.
> >
> > I hope this helps,
> >  John
> >
> > -------------------------------------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.mcmaster.ca/jfox/
> >
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rodolfo
> > > Pelinson
> > > Sent: March-27-15 3:07 PM
> > > To: r-help at r-project.org
> > > Subject: [R] vif in package car: there are aliased coefficients in the
> > model
> > >
> > > Hello. I'm trying to use the function vif from package car in a lm.
> > However it
> > > returns the following error:
> > > "Error in vif.default(lm(MDescores.sitescores ~ hidroperiodo +
> > localizacao
> > > +  : there are aliased coefficients in the model"
> > >
> > > When I exclude any predictor from the model, it returns this warning
> > > message:
> > > "Warning message: In cov2cor(v) : diag(.) had 0 or NA entries; non-finite
> > > result is doubtful"
> > >
> > > When I exclude any other predictor from the model vif finally works. I
> > can't
> > > figure it out whats the problem. This are the results that R returns
> > > me:
> > >
> > > > vif(lm(MDescores.sitescores ~ hidroperiodo + localizacao + area +
> > > profundidade + NTVM +  NTVI + PCs...c.1.., data = MDVIF)) Error in
> > > vif.default(lm(MDescores.sitescores ~ hidroperiodo + localizacao +
> > >  :   there are aliased coefficients in the model
> > >
> > > > vif(lm(MDescores.sitescores ~ localizacao + area + profundidade + NTVM
> > > > +
> > >  NTVI + PCs...c.1.., data = MDVIF))
> > >              GVIF Df GVIF^(1/(2*Df))
> > > localizacao   NaN  2             NaN
> > > area          NaN  1             NaN
> > > profundidade  NaN  1             NaN
> > > NTVM          NaN  1             NaN
> > > NTVI          NaN  1             NaN
> > > PCs...c.1..   NaN  1             NaN
> > > Warning message:
> > > In cov2cor(v) : diag(.) had 0 or NA entries; non-finite result is
> > doubtful
> > >
> > > Thanks.
> > > --
> > > Rodolfo Mei Pelinson.
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > ---
> > This email has been checked for viruses by Avast antivirus software.
> > http://www.avast.com
> >
> >
> 
> 
> -- 
> Rodolfo Mei Pelinson.

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From bsmith030465 at gmail.com  Sat Mar 28 22:56:51 2015
From: bsmith030465 at gmail.com (Brian Smith)
Date: Sat, 28 Mar 2015 17:56:51 -0400
Subject: [R] hash - extract key values
In-Reply-To: <55166E15.7090108@statistik.tu-dortmund.de>
References: <CAEQKoCF_Oe4qwVe+N=76wQ3MC1fDj-GBCRhgJU-47Gt4Bnc7Hg@mail.gmail.com>
	<1E56370E-8FD1-4383-9D12-FE114D9CF0F7@utoronto.ca>
	<CAEQKoCF3dT1LYaSog6d=UfC8LxwVScS9zanBxTkzS3eOM8xXpg@mail.gmail.com>
	<55166E15.7090108@statistik.tu-dortmund.de>
Message-ID: <CAEQKoCGg8=LLSirutpVQJfQqwWxYEGg8OW4kAumYBYx42n9AUw@mail.gmail.com>

I deleted the 'hash' directory and re-installed (several times!) it, but it
is still wierd......


> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.1.2
> library(hash)
hash-3.0.1 provided by Decision Patterns

> myhash <- hash(key=letters,values=1:26)
> myhash
<hash> containing 2 key-value pair(s).
  key : a b c d e f g h i j k l m n o p q r s t u v w x y z
  values :  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21
22 23 24 25 26
> keys(myhash)
[1] "key"    "values"
> myhash$key
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q"
"r" "s" "t" "u" "v" "w" "x" "y" "z"
> myhash$values
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
24 25 26
> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] hash_3.0.1

loaded via a namespace (and not attached):
[1] tools_3.1.2
>

On Sat, Mar 28, 2015 at 5:02 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

> Try to reinstall hash. Sounds like a broken installation.
>
> Best,
> Uwe Ligges
>
>
>
> On 28.03.2015 07:03, Brian Smith wrote:
>
>> Exactly. Used to work for me, but not anymore. I tried restarting session,
>> installing the most recent package of 'hash' etc.
>>
>> Here is my sessionInfo():
>>
>>  sessionInfo()
>>>
>> R version 3.1.2 (2014-10-31)
>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>>   [1] grid      parallel  stats4    stats     graphics  grDevices utils
>> datasets  methods   base
>>
>> other attached packages:
>>   [1] mapdata_2.2-3        maps_2.3-9           org.Hs.eg.db_3.0.0
>> multicore_0.1-7      nlme_3.1-120         Rgraphviz_2.10.0
>>   [7] biomaRt_2.22.0       topGO_2.18.0         SparseM_1.6
>>   GO.db_3.0.0          graph_1.44.1         mouse4302.db_3.0.0
>> [13] org.Mm.eg.db_3.0.0   RSQLite_1.0.0        DBI_0.3.1
>>   AnnotationDbi_1.28.1 GenomeInfoDb_1.2.4   IRanges_2.0.1
>> [19] S4Vectors_0.4.0      Biobase_2.26.0       BiocGenerics_0.12.1
>>   XML_3.98-1.1         gap_1.1-12           som_0.3-5
>> [25] pvclust_1.3-2        foreign_0.8-63       hash_3.0.1
>>
>> loaded via a namespace (and not attached):
>> [1] bitops_1.0-6    lattice_0.20-29 RCurl_1.95-4.5  tools_3.1.2
>>
>>
>>
>>
>> On Fri, Mar 27, 2015 at 9:54 PM, Boris Steipe <boris.steipe at utoronto.ca>
>> wrote:
>>
>>  Works for me :
>>>
>>>  library(hash)
>>>>
>>> hash-2.2.6 provided by Decision Patterns
>>>
>>>  hx <- hash( c('a','b','c'), 1:3 )
>>>> class(hx)
>>>>
>>> [1] "hash"
>>> attr(,"package")
>>> [1] "hash"
>>>
>>>> hx$a
>>>>
>>> [1] 1
>>>
>>>> keys(hx)
>>>>
>>> [1] "a" "b" "c"
>>>
>>>
>>> Maybe restart your session? Clear your workspace? Upgrade?
>>>
>>> B.
>>>
>>>
>>>
>>>
>>>
>>> On Mar 27, 2015, at 7:39 PM, Brian Smith <bsmith030465 at gmail.com> wrote:
>>>
>>>  Hi,
>>>>
>>>> I was trying to use hash, but can't seem to get the keys from the hash.
>>>> According to the hash documentation ('hash' package pdf, the following
>>>> should work:
>>>>
>>>>  hx <- hash( c('a','b','c'), 1:3 )
>>>>> class(hx)
>>>>>
>>>> [1] "hash"
>>>> attr(,"package")
>>>> [1] "hash"
>>>>
>>>>> hx$a
>>>>>
>>>> [1] 1
>>>>
>>>>> keys(hx)
>>>>>
>>>> Error in (function (classes, fdef, mtable)  :
>>>>   unable to find an inherited method for function ?keys? for signature
>>>> ?"hash"?
>>>>
>>>> How can I get the keys for my hash?
>>>>
>>>> thanks!
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>>
>>> http://www.R-project.org/posting-guide.html
>>>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Sat Mar 28 23:04:52 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 28 Mar 2015 23:04:52 +0100
Subject: [R] multiple break in univariate series
In-Reply-To: <CALXfEDqdJ+N9bm_atZ+9H+v9LKs=XbEHyLAWFgSvYmfNSMW71A@mail.gmail.com>
References: <CAMUSX8p2f8zQsao5NvTv_1fmkp2bufW2oa_xV-vTst2QVokDVA@mail.gmail.com>	<5516ECAD.7080700@statistik.tu-dortmund.de>
	<CALXfEDqdJ+N9bm_atZ+9H+v9LKs=XbEHyLAWFgSvYmfNSMW71A@mail.gmail.com>
Message-ID: <55172584.4060104@statistik.tu-dortmund.de>

>> -------- Forwarded Message --------
>> Subject: [R] multiple break in univariate series
>> Date: Sat, 28 Mar 2015 00:41:35 +0100
>> From: Temel ?spanyolca <ispanyolcom at gmail.com>
>> To: R-help at r-project.org
>>
>> Hello
>> Any one knows multiple break test for univariate series ?


Which kind of breaks? shift?

You may want to look for CUSUM or MOSUM tests or even permutation tests.

Packages: strucchange, changepoint

http://cran.r-project.org/web/packages/changepoint/index.html

http://cran.r-project.org/web/packages/strucchange/index.html

Best,
Uwe Ligges




>> --
>> *Thanks*
>> Engin YILMAZ
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>


From wdunlap at tibco.com  Sun Mar 29 00:36:37 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 28 Mar 2015 16:36:37 -0700
Subject: [R] hash - extract key values
In-Reply-To: <CAEQKoCGg8=LLSirutpVQJfQqwWxYEGg8OW4kAumYBYx42n9AUw@mail.gmail.com>
References: <CAEQKoCF_Oe4qwVe+N=76wQ3MC1fDj-GBCRhgJU-47Gt4Bnc7Hg@mail.gmail.com>
	<1E56370E-8FD1-4383-9D12-FE114D9CF0F7@utoronto.ca>
	<CAEQKoCF3dT1LYaSog6d=UfC8LxwVScS9zanBxTkzS3eOM8xXpg@mail.gmail.com>
	<55166E15.7090108@statistik.tu-dortmund.de>
	<CAEQKoCGg8=LLSirutpVQJfQqwWxYEGg8OW4kAumYBYx42n9AUw@mail.gmail.com>
Message-ID: <CAF8bMcZE8T9xuGkz+0zwB0pGYnYFHU4OWvES6Zf37k5AiNrzWA@mail.gmail.com>

Try using the plural 'keys' instead of 'key' (as help(hash) says):
   yourhash <- hash(keys=letters, values=1:26)
Then there will be 26 items in the hash table and keys(yourhash)
will return the 26 lowercase letters.  Is that what you want?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Mar 28, 2015 at 2:56 PM, Brian Smith <bsmith030465 at gmail.com> wrote:

> I deleted the 'hash' directory and re-installed (several times!) it, but it
> is still wierd......
>
>
> > sessionInfo()
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.2
> > library(hash)
> hash-3.0.1 provided by Decision Patterns
>
> > myhash <- hash(key=letters,values=1:26)
> > myhash
> <hash> containing 2 key-value pair(s).
>   key : a b c d e f g h i j k l m n o p q r s t u v w x y z
>   values :  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21
> 22 23 24 25 26
> > keys(myhash)
> [1] "key"    "values"
> > myhash$key
>  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q"
> "r" "s" "t" "u" "v" "w" "x" "y" "z"
> > myhash$values
>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
> 24 25 26
> > sessionInfo()
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] hash_3.0.1
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.2
> >
>
> On Sat, Mar 28, 2015 at 5:02 AM, Uwe Ligges <
> ligges at statistik.tu-dortmund.de
> > wrote:
>
> > Try to reinstall hash. Sounds like a broken installation.
> >
> > Best,
> > Uwe Ligges
> >
> >
> >
> > On 28.03.2015 07:03, Brian Smith wrote:
> >
> >> Exactly. Used to work for me, but not anymore. I tried restarting
> session,
> >> installing the most recent package of 'hash' etc.
> >>
> >> Here is my sessionInfo():
> >>
> >>  sessionInfo()
> >>>
> >> R version 3.1.2 (2014-10-31)
> >> Platform: x86_64-apple-darwin10.8.0 (64-bit)
> >>
> >> locale:
> >> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >>
> >> attached base packages:
> >>   [1] grid      parallel  stats4    stats     graphics  grDevices utils
> >> datasets  methods   base
> >>
> >> other attached packages:
> >>   [1] mapdata_2.2-3        maps_2.3-9           org.Hs.eg.db_3.0.0
> >> multicore_0.1-7      nlme_3.1-120         Rgraphviz_2.10.0
> >>   [7] biomaRt_2.22.0       topGO_2.18.0         SparseM_1.6
> >>   GO.db_3.0.0          graph_1.44.1         mouse4302.db_3.0.0
> >> [13] org.Mm.eg.db_3.0.0   RSQLite_1.0.0        DBI_0.3.1
> >>   AnnotationDbi_1.28.1 GenomeInfoDb_1.2.4   IRanges_2.0.1
> >> [19] S4Vectors_0.4.0      Biobase_2.26.0       BiocGenerics_0.12.1
> >>   XML_3.98-1.1         gap_1.1-12           som_0.3-5
> >> [25] pvclust_1.3-2        foreign_0.8-63       hash_3.0.1
> >>
> >> loaded via a namespace (and not attached):
> >> [1] bitops_1.0-6    lattice_0.20-29 RCurl_1.95-4.5  tools_3.1.2
> >>
> >>
> >>
> >>
> >> On Fri, Mar 27, 2015 at 9:54 PM, Boris Steipe <boris.steipe at utoronto.ca
> >
> >> wrote:
> >>
> >>  Works for me :
> >>>
> >>>  library(hash)
> >>>>
> >>> hash-2.2.6 provided by Decision Patterns
> >>>
> >>>  hx <- hash( c('a','b','c'), 1:3 )
> >>>> class(hx)
> >>>>
> >>> [1] "hash"
> >>> attr(,"package")
> >>> [1] "hash"
> >>>
> >>>> hx$a
> >>>>
> >>> [1] 1
> >>>
> >>>> keys(hx)
> >>>>
> >>> [1] "a" "b" "c"
> >>>
> >>>
> >>> Maybe restart your session? Clear your workspace? Upgrade?
> >>>
> >>> B.
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> On Mar 27, 2015, at 7:39 PM, Brian Smith <bsmith030465 at gmail.com>
> wrote:
> >>>
> >>>  Hi,
> >>>>
> >>>> I was trying to use hash, but can't seem to get the keys from the
> hash.
> >>>> According to the hash documentation ('hash' package pdf, the following
> >>>> should work:
> >>>>
> >>>>  hx <- hash( c('a','b','c'), 1:3 )
> >>>>> class(hx)
> >>>>>
> >>>> [1] "hash"
> >>>> attr(,"package")
> >>>> [1] "hash"
> >>>>
> >>>>> hx$a
> >>>>>
> >>>> [1] 1
> >>>>
> >>>>> keys(hx)
> >>>>>
> >>>> Error in (function (classes, fdef, mtable)  :
> >>>>   unable to find an inherited method for function ?keys? for signature
> >>>> ?"hash"?
> >>>>
> >>>> How can I get the keys for my hash?
> >>>>
> >>>> thanks!
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>>
> >>> http://www.R-project.org/posting-guide.html
> >>>
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>
> >>>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bsmith030465 at gmail.com  Sun Mar 29 00:45:30 2015
From: bsmith030465 at gmail.com (Brian Smith)
Date: Sat, 28 Mar 2015 19:45:30 -0400
Subject: [R] hash - extract key values
In-Reply-To: <CAF8bMcZE8T9xuGkz+0zwB0pGYnYFHU4OWvES6Zf37k5AiNrzWA@mail.gmail.com>
References: <CAEQKoCF_Oe4qwVe+N=76wQ3MC1fDj-GBCRhgJU-47Gt4Bnc7Hg@mail.gmail.com>
	<1E56370E-8FD1-4383-9D12-FE114D9CF0F7@utoronto.ca>
	<CAEQKoCF3dT1LYaSog6d=UfC8LxwVScS9zanBxTkzS3eOM8xXpg@mail.gmail.com>
	<55166E15.7090108@statistik.tu-dortmund.de>
	<CAEQKoCGg8=LLSirutpVQJfQqwWxYEGg8OW4kAumYBYx42n9AUw@mail.gmail.com>
	<CAF8bMcZE8T9xuGkz+0zwB0pGYnYFHU4OWvES6Zf37k5AiNrzWA@mail.gmail.com>
Message-ID: <CAEQKoCFFY=A1NQaAAXSVoLPKbjDF=eBZAQAg1Fp3ypOfbYBpog@mail.gmail.com>

Hi William,

That's the point - the 'keys()' doesn't seem to work..


On Sat, Mar 28, 2015 at 7:36 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Try using the plural 'keys' instead of 'key' (as help(hash) says):
>    yourhash <- hash(keys=letters, values=1:26)
> Then there will be 26 items in the hash table and keys(yourhash)
> will return the 26 lowercase letters.  Is that what you want?
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Sat, Mar 28, 2015 at 2:56 PM, Brian Smith <bsmith030465 at gmail.com>
> wrote:
>
>> I deleted the 'hash' directory and re-installed (several times!) it, but
>> it
>> is still wierd......
>>
>>
>> > sessionInfo()
>> R version 3.1.2 (2014-10-31)
>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.1.2
>> > library(hash)
>> hash-3.0.1 provided by Decision Patterns
>>
>> > myhash <- hash(key=letters,values=1:26)
>> > myhash
>> <hash> containing 2 key-value pair(s).
>>   key : a b c d e f g h i j k l m n o p q r s t u v w x y z
>>   values :  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21
>> 22 23 24 25 26
>> > keys(myhash)
>> [1] "key"    "values"
>> > myhash$key
>>  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q"
>> "r" "s" "t" "u" "v" "w" "x" "y" "z"
>> > myhash$values
>>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
>> 24 25 26
>> > sessionInfo()
>> R version 3.1.2 (2014-10-31)
>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] hash_3.0.1
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.1.2
>> >
>>
>> On Sat, Mar 28, 2015 at 5:02 AM, Uwe Ligges <
>> ligges at statistik.tu-dortmund.de
>> > wrote:
>>
>> > Try to reinstall hash. Sounds like a broken installation.
>> >
>> > Best,
>> > Uwe Ligges
>> >
>> >
>> >
>> > On 28.03.2015 07:03, Brian Smith wrote:
>> >
>> >> Exactly. Used to work for me, but not anymore. I tried restarting
>> session,
>> >> installing the most recent package of 'hash' etc.
>> >>
>> >> Here is my sessionInfo():
>> >>
>> >>  sessionInfo()
>> >>>
>> >> R version 3.1.2 (2014-10-31)
>> >> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>> >>
>> >> locale:
>> >> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> >>
>> >> attached base packages:
>> >>   [1] grid      parallel  stats4    stats     graphics  grDevices utils
>> >> datasets  methods   base
>> >>
>> >> other attached packages:
>> >>   [1] mapdata_2.2-3        maps_2.3-9           org.Hs.eg.db_3.0.0
>> >> multicore_0.1-7      nlme_3.1-120         Rgraphviz_2.10.0
>> >>   [7] biomaRt_2.22.0       topGO_2.18.0         SparseM_1.6
>> >>   GO.db_3.0.0          graph_1.44.1         mouse4302.db_3.0.0
>> >> [13] org.Mm.eg.db_3.0.0   RSQLite_1.0.0        DBI_0.3.1
>> >>   AnnotationDbi_1.28.1 GenomeInfoDb_1.2.4   IRanges_2.0.1
>> >> [19] S4Vectors_0.4.0      Biobase_2.26.0       BiocGenerics_0.12.1
>> >>   XML_3.98-1.1         gap_1.1-12           som_0.3-5
>> >> [25] pvclust_1.3-2        foreign_0.8-63       hash_3.0.1
>> >>
>> >> loaded via a namespace (and not attached):
>> >> [1] bitops_1.0-6    lattice_0.20-29 RCurl_1.95-4.5  tools_3.1.2
>> >>
>> >>
>> >>
>> >>
>> >> On Fri, Mar 27, 2015 at 9:54 PM, Boris Steipe <
>> boris.steipe at utoronto.ca>
>> >> wrote:
>> >>
>> >>  Works for me :
>> >>>
>> >>>  library(hash)
>> >>>>
>> >>> hash-2.2.6 provided by Decision Patterns
>> >>>
>> >>>  hx <- hash( c('a','b','c'), 1:3 )
>> >>>> class(hx)
>> >>>>
>> >>> [1] "hash"
>> >>> attr(,"package")
>> >>> [1] "hash"
>> >>>
>> >>>> hx$a
>> >>>>
>> >>> [1] 1
>> >>>
>> >>>> keys(hx)
>> >>>>
>> >>> [1] "a" "b" "c"
>> >>>
>> >>>
>> >>> Maybe restart your session? Clear your workspace? Upgrade?
>> >>>
>> >>> B.
>> >>>
>> >>>
>> >>>
>> >>>
>> >>>
>> >>> On Mar 27, 2015, at 7:39 PM, Brian Smith <bsmith030465 at gmail.com>
>> wrote:
>> >>>
>> >>>  Hi,
>> >>>>
>> >>>> I was trying to use hash, but can't seem to get the keys from the
>> hash.
>> >>>> According to the hash documentation ('hash' package pdf, the
>> following
>> >>>> should work:
>> >>>>
>> >>>>  hx <- hash( c('a','b','c'), 1:3 )
>> >>>>> class(hx)
>> >>>>>
>> >>>> [1] "hash"
>> >>>> attr(,"package")
>> >>>> [1] "hash"
>> >>>>
>> >>>>> hx$a
>> >>>>>
>> >>>> [1] 1
>> >>>>
>> >>>>> keys(hx)
>> >>>>>
>> >>>> Error in (function (classes, fdef, mtable)  :
>> >>>>   unable to find an inherited method for function ?keys? for
>> signature
>> >>>> ?"hash"?
>> >>>>
>> >>>> How can I get the keys for my hash?
>> >>>>
>> >>>> thanks!
>> >>>>
>> >>>>        [[alternative HTML version deleted]]
>> >>>>
>> >>>> ______________________________________________
>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>> PLEASE do read the posting guide
>> >>>>
>> >>> http://www.R-project.org/posting-guide.html
>> >>>
>> >>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>
>> >>>
>> >>>
>> >>>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/
>> >> posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Mar 29 00:57:56 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 28 Mar 2015 16:57:56 -0700
Subject: [R] hash - extract key values
In-Reply-To: <CAEQKoCFFY=A1NQaAAXSVoLPKbjDF=eBZAQAg1Fp3ypOfbYBpog@mail.gmail.com>
References: <CAEQKoCF_Oe4qwVe+N=76wQ3MC1fDj-GBCRhgJU-47Gt4Bnc7Hg@mail.gmail.com>
	<1E56370E-8FD1-4383-9D12-FE114D9CF0F7@utoronto.ca>
	<CAEQKoCF3dT1LYaSog6d=UfC8LxwVScS9zanBxTkzS3eOM8xXpg@mail.gmail.com>
	<55166E15.7090108@statistik.tu-dortmund.de>
	<CAEQKoCGg8=LLSirutpVQJfQqwWxYEGg8OW4kAumYBYx42n9AUw@mail.gmail.com>
	<CAF8bMcZE8T9xuGkz+0zwB0pGYnYFHU4OWvES6Zf37k5AiNrzWA@mail.gmail.com>
	<CAEQKoCFFY=A1NQaAAXSVoLPKbjDF=eBZAQAg1Fp3ypOfbYBpog@mail.gmail.com>
Message-ID: <CAF8bMcYPDeeyxh4wZQsnVyLe6Ewy_BG0hyKAmVP8R-xquS9--Q@mail.gmail.com>

What part of the following does not work as expected?
   > z <- hash(keys=letters[1:5], values=lapply(1:5,seq_len))
   > keys(z)
   [1] "a" "b" "c" "d" "e"
   > z$b
   [1] 1 2


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Mar 28, 2015 at 4:45 PM, Brian Smith <bsmith030465 at gmail.com> wrote:

> Hi William,
>
> That's the point - the 'keys()' doesn't seem to work..
>
>
> On Sat, Mar 28, 2015 at 7:36 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
>> Try using the plural 'keys' instead of 'key' (as help(hash) says):
>>    yourhash <- hash(keys=letters, values=1:26)
>> Then there will be 26 items in the hash table and keys(yourhash)
>> will return the 26 lowercase letters.  Is that what you want?
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Sat, Mar 28, 2015 at 2:56 PM, Brian Smith <bsmith030465 at gmail.com>
>> wrote:
>>
>>> I deleted the 'hash' directory and re-installed (several times!) it, but
>>> it
>>> is still wierd......
>>>
>>>
>>> > sessionInfo()
>>> R version 3.1.2 (2014-10-31)
>>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>>
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_3.1.2
>>> > library(hash)
>>> hash-3.0.1 provided by Decision Patterns
>>>
>>> > myhash <- hash(key=letters,values=1:26)
>>> > myhash
>>> <hash> containing 2 key-value pair(s).
>>>   key : a b c d e f g h i j k l m n o p q r s t u v w x y z
>>>   values :  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21
>>> 22 23 24 25 26
>>> > keys(myhash)
>>> [1] "key"    "values"
>>> > myhash$key
>>>  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q"
>>> "r" "s" "t" "u" "v" "w" "x" "y" "z"
>>> > myhash$values
>>>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
>>> 24 25 26
>>> > sessionInfo()
>>> R version 3.1.2 (2014-10-31)
>>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>>
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] hash_3.0.1
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_3.1.2
>>> >
>>>
>>> On Sat, Mar 28, 2015 at 5:02 AM, Uwe Ligges <
>>> ligges at statistik.tu-dortmund.de
>>> > wrote:
>>>
>>> > Try to reinstall hash. Sounds like a broken installation.
>>> >
>>> > Best,
>>> > Uwe Ligges
>>> >
>>> >
>>> >
>>> > On 28.03.2015 07:03, Brian Smith wrote:
>>> >
>>> >> Exactly. Used to work for me, but not anymore. I tried restarting
>>> session,
>>> >> installing the most recent package of 'hash' etc.
>>> >>
>>> >> Here is my sessionInfo():
>>> >>
>>> >>  sessionInfo()
>>> >>>
>>> >> R version 3.1.2 (2014-10-31)
>>> >> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>> >>
>>> >> locale:
>>> >> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>> >>
>>> >> attached base packages:
>>> >>   [1] grid      parallel  stats4    stats     graphics  grDevices
>>> utils
>>> >> datasets  methods   base
>>> >>
>>> >> other attached packages:
>>> >>   [1] mapdata_2.2-3        maps_2.3-9           org.Hs.eg.db_3.0.0
>>> >> multicore_0.1-7      nlme_3.1-120         Rgraphviz_2.10.0
>>> >>   [7] biomaRt_2.22.0       topGO_2.18.0         SparseM_1.6
>>> >>   GO.db_3.0.0          graph_1.44.1         mouse4302.db_3.0.0
>>> >> [13] org.Mm.eg.db_3.0.0   RSQLite_1.0.0        DBI_0.3.1
>>> >>   AnnotationDbi_1.28.1 GenomeInfoDb_1.2.4   IRanges_2.0.1
>>> >> [19] S4Vectors_0.4.0      Biobase_2.26.0       BiocGenerics_0.12.1
>>> >>   XML_3.98-1.1         gap_1.1-12           som_0.3-5
>>> >> [25] pvclust_1.3-2        foreign_0.8-63       hash_3.0.1
>>> >>
>>> >> loaded via a namespace (and not attached):
>>> >> [1] bitops_1.0-6    lattice_0.20-29 RCurl_1.95-4.5  tools_3.1.2
>>> >>
>>> >>
>>> >>
>>> >>
>>> >> On Fri, Mar 27, 2015 at 9:54 PM, Boris Steipe <
>>> boris.steipe at utoronto.ca>
>>> >> wrote:
>>> >>
>>> >>  Works for me :
>>> >>>
>>> >>>  library(hash)
>>> >>>>
>>> >>> hash-2.2.6 provided by Decision Patterns
>>> >>>
>>> >>>  hx <- hash( c('a','b','c'), 1:3 )
>>> >>>> class(hx)
>>> >>>>
>>> >>> [1] "hash"
>>> >>> attr(,"package")
>>> >>> [1] "hash"
>>> >>>
>>> >>>> hx$a
>>> >>>>
>>> >>> [1] 1
>>> >>>
>>> >>>> keys(hx)
>>> >>>>
>>> >>> [1] "a" "b" "c"
>>> >>>
>>> >>>
>>> >>> Maybe restart your session? Clear your workspace? Upgrade?
>>> >>>
>>> >>> B.
>>> >>>
>>> >>>
>>> >>>
>>> >>>
>>> >>>
>>> >>> On Mar 27, 2015, at 7:39 PM, Brian Smith <bsmith030465 at gmail.com>
>>> wrote:
>>> >>>
>>> >>>  Hi,
>>> >>>>
>>> >>>> I was trying to use hash, but can't seem to get the keys from the
>>> hash.
>>> >>>> According to the hash documentation ('hash' package pdf, the
>>> following
>>> >>>> should work:
>>> >>>>
>>> >>>>  hx <- hash( c('a','b','c'), 1:3 )
>>> >>>>> class(hx)
>>> >>>>>
>>> >>>> [1] "hash"
>>> >>>> attr(,"package")
>>> >>>> [1] "hash"
>>> >>>>
>>> >>>>> hx$a
>>> >>>>>
>>> >>>> [1] 1
>>> >>>>
>>> >>>>> keys(hx)
>>> >>>>>
>>> >>>> Error in (function (classes, fdef, mtable)  :
>>> >>>>   unable to find an inherited method for function ?keys? for
>>> signature
>>> >>>> ?"hash"?
>>> >>>>
>>> >>>> How can I get the keys for my hash?
>>> >>>>
>>> >>>> thanks!
>>> >>>>
>>> >>>>        [[alternative HTML version deleted]]
>>> >>>>
>>> >>>> ______________________________________________
>>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>>> PLEASE do read the posting guide
>>> >>>>
>>> >>> http://www.R-project.org/posting-guide.html
>>> >>>
>>> >>>> and provide commented, minimal, self-contained, reproducible code.
>>> >>>>
>>> >>>
>>> >>>
>>> >>>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide http://www.R-project.org/
>>> >> posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Sun Mar 29 01:52:59 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 29 Mar 2015 01:52:59 +0100
Subject: [R] multiple break in univariate series
In-Reply-To: <CAMUSX8pbQ2BQicR-HfO-iczivMiTsSh0aKnHMx9BTq0z0qB1Dg@mail.gmail.com>
References: <CAMUSX8p2f8zQsao5NvTv_1fmkp2bufW2oa_xV-vTst2QVokDVA@mail.gmail.com>	<5516ECAD.7080700@statistik.tu-dortmund.de>	<CALXfEDqdJ+N9bm_atZ+9H+v9LKs=XbEHyLAWFgSvYmfNSMW71A@mail.gmail.com>	<55172584.4060104@statistik.tu-dortmund.de>
	<CAMUSX8pbQ2BQicR-HfO-iczivMiTsSh0aKnHMx9BTq0z0qB1Dg@mail.gmail.com>
Message-ID: <55174CEB.2030300@statistik.tu-dortmund.de>



On 29.03.2015 00:09, Temel ?spanyolca wrote:
>
>     DR. UWE LIGGES
>
>
> I have sent turkish real Gdp data (1998-2013) in annex.
> Turkey has lived two crises in this period, in 2001 and 2008. You can
> see in data.
> My problem is to indicate these dates any statistic test as a structural
> change or point change.

Have you tried CUSUM? Or some permutations test? You do not have muh 
data ....

Best,
Uwe Ligges



>
> Sincerely
> Engin
>
> 2015-03-28 23:04 GMT+01:00 Uwe Ligges <ligges at statistik.tu-dortmund.de
> <mailto:ligges at statistik.tu-dortmund.de>>:
>
>             -------- Forwarded Message --------
>             Subject: [R] multiple break in univariate series
>             Date: Sat, 28 Mar 2015 00:41:35 +0100
>             From: Temel ?spanyolca <ispanyolcom at gmail.com
>             <mailto:ispanyolcom at gmail.com>>
>             To: R-help at r-project.org <mailto:R-help at r-project.org>
>
>             Hello
>             Any one knows multiple break test for univariate series ?
>
>
>
>     Which kind of breaks? shift?
>
>     You may want to look for CUSUM or MOSUM tests or even permutation tests.
>
>     Packages: strucchange, changepoint
>
>     http://cran.r-project.org/web/__packages/changepoint/index.__html
>     <http://cran.r-project.org/web/packages/changepoint/index.html>
>
>     http://cran.r-project.org/web/__packages/strucchange/index.__html
>     <http://cran.r-project.org/web/packages/strucchange/index.html>
>
>     Best,
>     Uwe Ligges
>
>
>
>
>             --
>             *Thanks*
>             Engin YILMAZ
>
>                       [[alternative HTML version deleted]]
>
>             ________________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>             list -- To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/__listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>             PLEASE do read the posting guide
>             http://www.R-project.org/__posting-guide.html
>             <http://www.R-project.org/posting-guide.html>
>             and provide commented, minimal, self-contained, reproducible
>             code.
>
>
>
>
>
> --
> *Sayg?lar?mla*
> Engin YILMAZ


From gunter.berton at gene.com  Sun Mar 29 03:56:53 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 28 Mar 2015 18:56:53 -0700
Subject: [R] multiple break in univariate series
In-Reply-To: <55174CEB.2030300@statistik.tu-dortmund.de>
References: <CAMUSX8p2f8zQsao5NvTv_1fmkp2bufW2oa_xV-vTst2QVokDVA@mail.gmail.com>
	<5516ECAD.7080700@statistik.tu-dortmund.de>
	<CALXfEDqdJ+N9bm_atZ+9H+v9LKs=XbEHyLAWFgSvYmfNSMW71A@mail.gmail.com>
	<55172584.4060104@statistik.tu-dortmund.de>
	<CAMUSX8pbQ2BQicR-HfO-iczivMiTsSh0aKnHMx9BTq0z0qB1Dg@mail.gmail.com>
	<55174CEB.2030300@statistik.tu-dortmund.de>
Message-ID: <CACk-te2LftBZh_845B=vDny21JkSmGELa6k=Feo=nZz6_hxr8g@mail.gmail.com>

Once you have looked at the data and chosen change points to test
based on the data, the tests for change points are invalid (unless you
make appropriate adjustments for post hoc tests).

And no, I am not making this up. Consult any competent statistician.

Cheers,
Bert





Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Mar 28, 2015 at 5:52 PM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 29.03.2015 00:09, Temel ?spanyolca wrote:
>>
>>
>>     DR. UWE LIGGES
>>
>>
>> I have sent turkish real Gdp data (1998-2013) in annex.
>> Turkey has lived two crises in this period, in 2001 and 2008. You can
>> see in data.
>> My problem is to indicate these dates any statistic test as a structural
>> change or point change.
>
>
> Have you tried CUSUM? Or some permutations test? You do not have muh data
> ....
>
> Best,
> Uwe Ligges
>
>
>
>>
>> Sincerely
>> Engin
>>
>> 2015-03-28 23:04 GMT+01:00 Uwe Ligges <ligges at statistik.tu-dortmund.de
>> <mailto:ligges at statistik.tu-dortmund.de>>:
>>
>>             -------- Forwarded Message --------
>>             Subject: [R] multiple break in univariate series
>>             Date: Sat, 28 Mar 2015 00:41:35 +0100
>>             From: Temel ?spanyolca <ispanyolcom at gmail.com
>>             <mailto:ispanyolcom at gmail.com>>
>>             To: R-help at r-project.org <mailto:R-help at r-project.org>
>>
>>             Hello
>>             Any one knows multiple break test for univariate series ?
>>
>>
>>
>>     Which kind of breaks? shift?
>>
>>     You may want to look for CUSUM or MOSUM tests or even permutation
>> tests.
>>
>>     Packages: strucchange, changepoint
>>
>>     http://cran.r-project.org/web/__packages/changepoint/index.__html
>>     <http://cran.r-project.org/web/packages/changepoint/index.html>
>>
>>     http://cran.r-project.org/web/__packages/strucchange/index.__html
>>     <http://cran.r-project.org/web/packages/strucchange/index.html>
>>
>>     Best,
>>     Uwe Ligges
>>
>>
>>
>>
>>             --
>>             *Thanks*
>>             Engin YILMAZ
>>
>>                       [[alternative HTML version deleted]]
>>
>>             ________________________________________________
>>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>             list -- To UNSUBSCRIBE and more, see
>>             https://stat.ethz.ch/mailman/__listinfo/r-help
>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>             PLEASE do read the posting guide
>>             http://www.R-project.org/__posting-guide.html
>>             <http://www.R-project.org/posting-guide.html>
>>             and provide commented, minimal, self-contained, reproducible
>>             code.
>>
>>
>>
>>
>>
>> --
>> *Sayg?lar?mla*
>> Engin YILMAZ
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sun Mar 29 12:42:23 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 29 Mar 2015 12:42:23 +0200
Subject: [R] Error in lm() with very small (close to zero) regressor
In-Reply-To: <loom.20150328T181834-1@post.gmane.org>
References: <1427499146685-4705185.post@n4.nabble.com>
	<25BAAC3A-D5C0-4094-BFB6-6D67328CC33E@gmail.com>
	<loom.20150328T181834-1@post.gmane.org>
Message-ID: <638A5903-B18C-40CF-B0E5-DDD8C186A7F4@gmail.com>


> On 28 Mar 2015, at 18:28 , Ben Bolker <bbolker at gmail.com> wrote:
> 
> peter dalgaard <pdalgd <at> gmail.com> writes:
> 
>> 
>> 
>>> On 28 Mar 2015, at 00:32 , RiGui <raluca.gui <at> business.uzh.ch> wrote:
>>> 
>>> Hello everybody,
>>> 
>>> I have encountered the following problem with lm():
>>> 
>>> When running lm() with a regressor close to zero - 
>> of the order e-10, the
>>> value of the estimate is of huge absolute value , of order millions. 
>>> 
>>> However, if I write the formula of the OLS estimator, 
>> in matrix notation:
>>> pseudoinverse(t(X)*X) * t(X) * y , the results are correct, meaning the
>>> estimate has value 0.
> 
>  How do you know this answer is "correct"?
> 
>>> here is the code:
>>> 
>>> y  <- rnorm(n_obs, 10,2.89)
>>> x1 <- rnorm(n_obs, 0.00000000000001235657,0.000000000000000045)
>>> x2 <- rnorm(n_obs, 10,3.21)
>>> X  <- cbind(x1,x2)
>>> 
>>> bFE <- lm(y ~ x1 + x2)
>>> bFE
>>> 
>>> bOLS <- pseudoinverse(t(X) %*% X) %*% t(X) %*% y
>>> bOLS
>>> 
>>> 
>>> Note: I am applying a deviation from the 
>> mean projection to the data, that
>>> is why I have some regressors with such small values.
>>> 
>>> Thank you for any help!
>>> 
>>> Raluca
> 
>  Is there a reason you can't scale your regressors?
> 
>>> 
>> Example not reproducible:
>> 
> 
>  I agree that the OP's question was not reproducible, but it's
> not too hard to make it reproducible. I bothered to use
> library("sos"); findFn("pseudoinverse") to find pseudoinverse()
> in corpcor:

Well, it shouldn't be my work, nor yours... And I thought it particularly egregious to treat a function from an unspecified package as gospel.

> 
> It is true that we get estimates with very large magnitudes,
> but their 
> 
> set.seed(101)
> n_obs <- 1000
> y  <- rnorm(n_obs, 10,2.89)
> x1 <- rnorm(n_obs, mean=1.235657e-14,sd=4.5e-17)
> x2 <- rnorm(n_obs, 10,3.21)
> X  <- cbind(x1,x2)
> 
> bFE <- lm(y ~ x1 + x2)
> bFE
> coef(summary(bFE))
> 
>                 Estimate   Std. Error     t value  Pr(>|t|)
> (Intercept)  1.155959e+01 2.312956e+01  0.49977541 0.6173435
> x1          -1.658420e+14 1.872598e+15 -0.08856254 0.9294474
> x2           3.797342e-02 2.813000e-02  1.34992593 0.1773461
> 
> library("corpcor")
> bOLS <- pseudoinverse(t(X) %*% X) %*% t(X) %*% y
> bOLS
> 
>             [,1]
> [1,] 9.807664e-16
> [2,] 8.880273e-01
> 
> And if we scale the predictor:
> 
> bFE2 <- lm(y ~ I(1e14*x1) + x2)
> coef(summary(bFE2))
> 
>                 Estimate Std. Error     t value  Pr(>|t|)
> (Intercept)   11.55958731   23.12956  0.49977541 0.6173435
> I(1e+14 * x1) -1.65842037   18.72598 -0.08856254 0.9294474
> x2             0.03797342    0.02813  1.34992593 0.1773461
> 
> bOLS stays constant.
> 
> To be honest, I haven't thought about this enough to see
> which answer is actually correct, although I suspect the
> problem is in bOLS, since the numerical methods (unlike
> the brute-force pseudoinverse method given here) behind
> lm have been carefully considered for numerical stability.

In particular, the pseudoinverse() function has a tol= argument which allows it to zap small singular values. 

> pseudoinverse(crossprod(X))%*%crossprod(X,y)
             [,1]
[1,] 9.807664e-16
[2,] 8.880273e-01
> pseudoinverse(crossprod(X),tol=1e-40)%*%crossprod(X,y)
              [,1]
[1,]  1.286421e+15
[2,] -5.327384e-01

Also, notice that there is no intercept in the above, so it would be more reasonable to compare to 

> bFE <- lm(y ~ x1 + x2-1)
> summary(bFE)

Call:
lm(formula = y ~ x1 + x2 - 1)

Residuals:
    Min      1Q  Median      3Q     Max 
-9.1712 -1.9439 -0.0321  1.7637  9.4540 

Coefficients:
    Estimate Std. Error t value Pr(>|t|)    
x1 7.700e+14  2.435e+13   31.62   <2e-16 ***
x2 3.766e-02  2.811e-02    1.34    0.181    
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 2.771 on 998 degrees of freedom
Multiple R-squared:  0.9275,	Adjusted R-squared:  0.9273 
F-statistic:  6382 on 2 and 998 DF,  p-value: < 2.2e-16

Or, maybe better to use cbind(1,X) in the pseudoinverse() method. It doesn't help, though.

What really surprises me is this

> X  <- cbind(x1,x2)
> crossprod(X)
             x1           x2
x1 1.526698e-25 1.265085e-10
x2 1.265085e-10 1.145462e+05
> solve(crossprod(X))
Error in solve.default(crossprod(X)) : 
  system is computationally singular: reciprocal condition number = 1.13052e-31
> solve(crossprod(X), tol=1e-40)
              x1            x2
x1  7.722232e+25 -8.528686e+10
x2 -8.528686e+10  1.029237e-04
> pseudoinverse(crossprod(X), tol=1e-40)
              [,1]          [,2]
[1,]  6.222152e+25 -6.217178e+10
[2,] -6.871948e+10  7.739466e-05

How does pseudoinverse() go so badly wrong? Notice that apart from the scaling, this really isn't very ill-conditioned, but a lot of accuracy seems to be lost in its SVD step. Notice that

> X  <- cbind(1e14*x1,x2)
> solve(crossprod(X))
                            x2
    0.0077222325 -0.0008528686
x2 -0.0008528686  0.0001029237
> pseudoinverse(crossprod(X))
              [,1]          [,2]
[1,]  0.0077222325 -0.0008528686
[2,] -0.0008528686  0.0001029237


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Achim.Zeileis at uibk.ac.at  Sun Mar 29 12:43:18 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sun, 29 Mar 2015 12:43:18 +0200 (CEST)
Subject: [R] multiple break in univariate series
In-Reply-To: <CACk-te2LftBZh_845B=vDny21JkSmGELa6k=Feo=nZz6_hxr8g@mail.gmail.com>
References: <CAMUSX8p2f8zQsao5NvTv_1fmkp2bufW2oa_xV-vTst2QVokDVA@mail.gmail.com>
	<5516ECAD.7080700@statistik.tu-dortmund.de>
	<CALXfEDqdJ+N9bm_atZ+9H+v9LKs=XbEHyLAWFgSvYmfNSMW71A@mail.gmail.com>
	<55172584.4060104@statistik.tu-dortmund.de>
	<CAMUSX8pbQ2BQicR-HfO-iczivMiTsSh0aKnHMx9BTq0z0qB1Dg@mail.gmail.com>
	<55174CEB.2030300@statistik.tu-dortmund.de>
	<CACk-te2LftBZh_845B=vDny21JkSmGELa6k=Feo=nZz6_hxr8g@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1503291235580.27133@paninaro.uibk.ac.at>

On Sat, 28 Mar 2015, Bert Gunter wrote:

> Once you have looked at the data and chosen change points to test
> based on the data, the tests for change points are invalid (unless you
> make appropriate adjustments for post hoc tests).
>
> And no, I am not making this up. Consult any competent statistician.

Yes, you must not select a breakpoint by eyeballing a time series and then 
conduct a structural break test for this given breakpoint as if it were 
exogenously given. This will be far too liberal.

But most practitioners would think it is still ok to conduct a structural 
break test with _unknown_ breakpoint. Ideally, the hypothesis to be tested 
and the significance level were formulated prior to the collection of the 
data, though.

To add to Uwe's comments: maxstat_test() in package "coin" would be a 
non-parametric permutation test. sctest() in package "strucchange" 
provides a wide range of tests for general parametric models, especially 
linear regressions.

Best,
Z

> Cheers,
> Bert
>
>
>
>
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sat, Mar 28, 2015 at 5:52 PM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de> wrote:
>>
>>
>> On 29.03.2015 00:09, Temel ?spanyolca wrote:
>>>
>>>
>>>     DR. UWE LIGGES
>>>
>>>
>>> I have sent turkish real Gdp data (1998-2013) in annex.
>>> Turkey has lived two crises in this period, in 2001 and 2008. You can
>>> see in data.
>>> My problem is to indicate these dates any statistic test as a structural
>>> change or point change.
>>
>>
>> Have you tried CUSUM? Or some permutations test? You do not have muh data
>> ....
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>>>
>>> Sincerely
>>> Engin
>>>
>>> 2015-03-28 23:04 GMT+01:00 Uwe Ligges <ligges at statistik.tu-dortmund.de
>>> <mailto:ligges at statistik.tu-dortmund.de>>:
>>>
>>>             -------- Forwarded Message --------
>>>             Subject: [R] multiple break in univariate series
>>>             Date: Sat, 28 Mar 2015 00:41:35 +0100
>>>             From: Temel ?spanyolca <ispanyolcom at gmail.com
>>>             <mailto:ispanyolcom at gmail.com>>
>>>             To: R-help at r-project.org <mailto:R-help at r-project.org>
>>>
>>>             Hello
>>>             Any one knows multiple break test for univariate series ?
>>>
>>>
>>>
>>>     Which kind of breaks? shift?
>>>
>>>     You may want to look for CUSUM or MOSUM tests or even permutation
>>> tests.
>>>
>>>     Packages: strucchange, changepoint
>>>
>>>     http://cran.r-project.org/web/__packages/changepoint/index.__html
>>>     <http://cran.r-project.org/web/packages/changepoint/index.html>
>>>
>>>     http://cran.r-project.org/web/__packages/strucchange/index.__html
>>>     <http://cran.r-project.org/web/packages/strucchange/index.html>
>>>
>>>     Best,
>>>     Uwe Ligges
>>>
>>>
>>>
>>>
>>>             --
>>>             *Thanks*
>>>             Engin YILMAZ
>>>
>>>                       [[alternative HTML version deleted]]
>>>
>>>             ________________________________________________
>>>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>>             list -- To UNSUBSCRIBE and more, see
>>>             https://stat.ethz.ch/mailman/__listinfo/r-help
>>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>             PLEASE do read the posting guide
>>>             http://www.R-project.org/__posting-guide.html
>>>             <http://www.R-project.org/posting-guide.html>
>>>             and provide commented, minimal, self-contained, reproducible
>>>             code.
>>>
>>>
>>>
>>>
>>>
>>> --
>>> *Sayg?lar?mla*
>>> Engin YILMAZ
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lychang at emory.edu  Sat Mar 28 16:04:44 2015
From: lychang at emory.edu (lychang)
Date: Sat, 28 Mar 2015 08:04:44 -0700 (PDT)
Subject: [R] Categorizing by month
In-Reply-To: <9E64D1B8-C8B7-49F6-AF6D-FC8DA665FEE8@bigelow.org>
References: <1427472396067-4705173.post@n4.nabble.com>
	<9E64D1B8-C8B7-49F6-AF6D-FC8DA665FEE8@bigelow.org>
Message-ID: <1427555084404-4705208.post@n4.nabble.com>

Thanks for that Ben, I appreciate it a lot. 

I have another question if you don't mind taking the time to answer it. I
want to create a subset from dataset called "datafile5" with only the
variables "Date," "PM2.5 mean concentration," "SITE_LONGITUDE," and
"SITE_LATITUDE," dating only in September 2009. 

Do you know how I can do this? 



--
View this message in context: http://r.789695.n4.nabble.com/Categorizing-by-month-tp4705173p4705208.html
Sent from the R help mailing list archive at Nabble.com.


From ispanyolcom at gmail.com  Sun Mar 29 00:09:52 2015
From: ispanyolcom at gmail.com (=?UTF-8?Q?Temel_=C4=B0spanyolca?=)
Date: Sun, 29 Mar 2015 00:09:52 +0100
Subject: [R] multiple break in univariate series
In-Reply-To: <55172584.4060104@statistik.tu-dortmund.de>
References: <CAMUSX8p2f8zQsao5NvTv_1fmkp2bufW2oa_xV-vTst2QVokDVA@mail.gmail.com>
	<5516ECAD.7080700@statistik.tu-dortmund.de>
	<CALXfEDqdJ+N9bm_atZ+9H+v9LKs=XbEHyLAWFgSvYmfNSMW71A@mail.gmail.com>
	<55172584.4060104@statistik.tu-dortmund.de>
Message-ID: <CAMUSX8pbQ2BQicR-HfO-iczivMiTsSh0aKnHMx9BTq0z0qB1Dg@mail.gmail.com>

DR. UWE LIGGES

I have sent turkish real Gdp data (1998-2013) in annex.
Turkey has lived two crises in this period, in 2001 and 2008. You can see
in data.
My problem is to indicate these dates any statistic test as a structural
change or point change.

Sincerely
Engin

2015-03-28 23:04 GMT+01:00 Uwe Ligges <ligges at statistik.tu-dortmund.de>:

> -------- Forwarded Message --------
>>> Subject: [R] multiple break in univariate series
>>> Date: Sat, 28 Mar 2015 00:41:35 +0100
>>> From: Temel ?spanyolca <ispanyolcom at gmail.com>
>>> To: R-help at r-project.org
>>>
>>> Hello
>>> Any one knows multiple break test for univariate series ?
>>>
>>
>
> Which kind of breaks? shift?
>
> You may want to look for CUSUM or MOSUM tests or even permutation tests.
>
> Packages: strucchange, changepoint
>
> http://cran.r-project.org/web/packages/changepoint/index.html
>
> http://cran.r-project.org/web/packages/strucchange/index.html
>
> Best,
> Uwe Ligges
>
>
>
>
>  --
>>> *Thanks*
>>> Engin YILMAZ
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>


-- 
*Sayg?lar?mla*
Engin YILMAZ

From tr206 at kent.ac.uk  Sun Mar 29 14:59:48 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sun, 29 Mar 2015 12:59:48 +0000
Subject: [R] generating phi using function()
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A12F536BB55@EX10-LIVE-MBN2.ad.kent.ac.uk>

Hi everybody,
I am trying to generate the formula shown in the attachment. My formula so far looks as follows:

phi <- function(w1, w2, j, k, K){
zaehler <- (k/K)^(w1-1)*(1-k/K)^(w2-1)
nenner <- sum( ((1:K)/K)^(w1-1)*(1-(1:K)/K)^(w2-1))
return( zaehler/nenner )
}

Unfortunately something must be wrong here as I get the following message when running a midas regression

m22.phi<- midas_r(rv~mls(rvh,1:max.lag+h1,1,phi), start = list(rvh=c(1,1)))
Error in phi(c(1, 1), 44L, 1) : argument "K" is missing, with no default
Called from: .rs.breakOnError(TRUE)
Browse[1]> K<-125
Browse[1]> 125

Could anybody look into my phi formula and tell me what is wrong with it?

Thanks in advance.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: psi.png
Type: image/png
Size: 2199 bytes
Desc: psi.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150329/3191bef5/attachment.png>

From raluca.gui at business.uzh.ch  Sat Mar 28 18:52:17 2015
From: raluca.gui at business.uzh.ch (RiGui)
Date: Sat, 28 Mar 2015 10:52:17 -0700 (PDT)
Subject: [R] Error in lm() with very small (close to zero) regressor
In-Reply-To: <loom.20150328T181834-1@post.gmane.org>
References: <1427499146685-4705185.post@n4.nabble.com>
	<25BAAC3A-D5C0-4094-BFB6-6D67328CC33E@gmail.com>
	<loom.20150328T181834-1@post.gmane.org>
Message-ID: <1427565137780-4705212.post@n4.nabble.com>

Thank you for your replies! 

I am terribly sorry for the code not being reproducible, is the first time I
am posting here, I run the code several times before I posted, but...I
forgot about the library used.

To answer to your questions:

How do you know this answer is "correct"? 

What I am doing is actually a "fixed effect" estimation. I apply a
projection matrix to the data, both dependent and independent variables,
projection which renders the regressors that do not vary, equal to basically
zero - the x1 from the post. 

Once I apply the projection, I need to run OLS to get the estimates, so x1
should be zero. 

Therefore, the results with the scaled regressor is not correct. 

Besides, I do not see why the bOLS is wrong, since is the formula of the OLS
estimator from any Econometrics book.

Here again the corrected code: 

install.packages("corpcor")
library(corpcor)

n_obs <- 1000
y  <- rnorm(n_obs, 10,2.89)
x1 <- rnorm(n_obs, 0.00000000000001235657,0.000000000000000045)
x2 <- rnorm(n_obs, 10,3.21)
X  <- cbind(x1,x2)

 bFE <- lm(y ~ x1 + x2)
 bFE

 bOLS <- pseudoinverse(t(X) %*% X) %*% t(X) %*% y
 bOLS


Best,

Raluca Gui 




--
View this message in context: http://r.789695.n4.nabble.com/Error-in-lm-with-very-small-close-to-zero-regressor-tp4705185p4705212.html
Sent from the R help mailing list archive at Nabble.com.


From pdalgd at gmail.com  Sun Mar 29 20:31:14 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 29 Mar 2015 20:31:14 +0200
Subject: [R] Error in lm() with very small (close to zero) regressor
In-Reply-To: <1427565137780-4705212.post@n4.nabble.com>
References: <1427499146685-4705185.post@n4.nabble.com>
	<25BAAC3A-D5C0-4094-BFB6-6D67328CC33E@gmail.com>
	<loom.20150328T181834-1@post.gmane.org>
	<1427565137780-4705212.post@n4.nabble.com>
Message-ID: <B3C3208E-15EF-4FA0-A610-52EF895EE950@gmail.com>


> On 28 Mar 2015, at 18:52 , RiGui <raluca.gui at business.uzh.ch> wrote:
> 
> Thank you for your replies! 
> 
> I am terribly sorry for the code not being reproducible, is the first time I
> am posting here, I run the code several times before I posted, but...I
> forgot about the library used.
> 
> To answer to your questions:
> 
> How do you know this answer is "correct"? 
> 
> What I am doing is actually a "fixed effect" estimation. I apply a
> projection matrix to the data, both dependent and independent variables,
> projection which renders the regressors that do not vary, equal to basically
> zero - the x1 from the post. 
> 
> Once I apply the projection, I need to run OLS to get the estimates, so x1
> should be zero. 

Please rethink: If a regressor is very small, the regression coefficient will be very large; if it is small and random, OLS estimators will be highly variable. 

R has no way of knowing that a regressor with small values isn't what the user intended (e.g. it could be picoMolar concentrations stated in Molar units); if you want a mechanism that eliminates near-zero regressors you need to do it explicitly. 

> Therefore, the results with the scaled regressor is not correct. 
> 
> Besides, I do not see why the bOLS is wrong, since is the formula of the OLS
> estimator from any Econometrics book.

Textbooks often gloss over details like numerical stability (and in general, textbooks often use slightly oversimplified methods in order not to confuse students unnecessarily). 
Better books will give the (X'X)^-1 X'Y formula with a warning not to use it as is, but e.g. use the X=QR decomposition [which gives (R'Q'QR)^-1 R'Q'Y = (R'R)^-1 R'Q'Y = R^-1 Q'Y].


> Here again the corrected code: 
> 
> install.packages("corpcor")
> library(corpcor)
> 
> n_obs <- 1000
> y  <- rnorm(n_obs, 10,2.89)
> x1 <- rnorm(n_obs, 0.00000000000001235657,0.000000000000000045)
> x2 <- rnorm(n_obs, 10,3.21)
> X  <- cbind(x1,x2)
> 
> bFE <- lm(y ~ x1 + x2)
> bFE
> 
> bOLS <- pseudoinverse(t(X) %*% X) %*% t(X) %*% y
> bOLS
> 

Notice again, that these are not comparable in that bFE has an intercept term and bOLS hasn't. You need to compare with

y ~ x1 + x2 - 1

and 

y ~ x2 - 1


> 
> Best,
> 
> Raluca Gui 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Error-in-lm-with-very-small-close-to-zero-regressor-tp4705185p4705212.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bbolker at gmail.com  Sun Mar 29 20:34:50 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 29 Mar 2015 18:34:50 +0000
Subject: [R] Error in lm() with very small (close to zero) regressor
References: <1427499146685-4705185.post@n4.nabble.com>
	<25BAAC3A-D5C0-4094-BFB6-6D67328CC33E@gmail.com>
	<loom.20150328T181834-1@post.gmane.org>
	<1427565137780-4705212.post@n4.nabble.com>
Message-ID: <loom.20150329T202838-558@post.gmane.org>

RiGui <raluca.gui <at> business.uzh.ch> writes:

>

[snip]
 
> I am terribly sorry for the code not being reproducible, is the
> first time I am posting here, I run the code several times before I
> posted, but...I forgot about the library used.

  Thanks for updating.
 
> To answer to your questions:
> 
>> How do you know this answer is "correct"? 
 
> What I am doing is actually a "fixed effect" estimation. I apply a
> projection matrix to the data, both dependent and independent
> variables, projection which renders the regressors that do not vary,
> equal to basically zero - the x1 from the post.
 
> Once I apply the projection, I need to run OLS to get the estimates,
> so x1 should be zero.

  Yes, but not *exactly* zero.
 
> Therefore, the results with the scaled regressor is not correct. 
 
> Besides, I do not see why the bOLS is wrong, since is the formula of
> the OLS estimator from any Econometrics book.

 Because it's numerically unstable.
 Unfortunately, you can't always translate formulas directly from
books into code and expect them to be reliable.

  Based on Peter's comments, I believe that as expected lm()
is actually getting closer to the 'correct' answer.

> Here again the corrected code: 

> library(corpcor)
> 
> n_obs <- 1000
> y  <- rnorm(n_obs, 10,2.89)
> x1 <- rnorm(n_obs, 0.00000000000001235657,0.000000000000000045)
> x2 <- rnorm(n_obs, 10,3.21)
> X  <- cbind(x1,x2)

As Peter points out, one example uses an intercept and the
other doesn't: you should either use X <- cbind(1,x1,x2) or
lm(y~x1+x2-1) for compatibility.

>  bFE <- lm(y ~ x1 + x2)
>  bFE
> 
>  bOLS <- pseudoinverse(t(X) %*% X) %*% t(X) %*% y
>  bOLS

[snip: Gmane doesn't like it if I quote "too much"]


From raluca.gui at business.uzh.ch  Sun Mar 29 21:53:46 2015
From: raluca.gui at business.uzh.ch (RiGui)
Date: Sun, 29 Mar 2015 12:53:46 -0700 (PDT)
Subject: [R] Error in lm() with very small (close to zero) regressor
In-Reply-To: <loom.20150329T202838-558@post.gmane.org>
References: <1427499146685-4705185.post@n4.nabble.com>
	<25BAAC3A-D5C0-4094-BFB6-6D67328CC33E@gmail.com>
	<loom.20150328T181834-1@post.gmane.org>
	<1427565137780-4705212.post@n4.nabble.com>
	<loom.20150329T202838-558@post.gmane.org>
Message-ID: <1427658826595-4705231.post@n4.nabble.com>


RiGui <raluca.gui <at> business.uzh.ch> writes:

>

[snip]
 
> I am terribly sorry for the code not being reproducible, is the
> first time I am posting here, I run the code several times before I
> posted, but...I forgot about the library used.

  Thanks for updating.
 
> To answer to your questions:
> 
>> How do you know this answer is "correct"? 
 
> What I am doing is actually a "fixed effect" estimation. I apply a
> projection matrix to the data, both dependent and independent
> variables, projection which renders the regressors that do not vary,
> equal to basically zero - the x1 from the post.
 
> Once I apply the projection, I need to run OLS to get the estimates,
> so x1 should be zero.

  Yes, but not *exactly* zero.
 
> Therefore, the results with the scaled regressor is not correct. 
 
> Besides, I do not see why the bOLS is wrong, since is the formula of
> the OLS estimator from any Econometrics book.

" Because it's numerically unstable.
 Unfortunately, you can't always translate formulas directly from
books into code and expect them to be reliable.

  Based on Peter's comments, I believe that as expected lm()
is actually getting closer to the 'correct' answer.
"


Thank you to both of you for your comments! I will re-do the analysis
following your advice.

Best,

Raluca





--
View this message in context: http://r.789695.n4.nabble.com/Error-in-lm-with-very-small-close-to-zero-regressor-tp4705185p4705231.html
Sent from the R help mailing list archive at Nabble.com.


From david.crow at cide.edu  Sun Mar 29 23:59:59 2015
From: david.crow at cide.edu (David Crow)
Date: Sun, 29 Mar 2015 15:59:59 -0600
Subject: [R] Help w/ variable names in loop with lmer
Message-ID: <CAMeG5ZhKHXfk0H++XaLviNobxtEc_XmN9e7n4_v3-dh9_3enFg@mail.gmail.com>

Hi, R users-

I'm estimating random effects models with cross-level interactions; I want
to interact each of a vector of level-1 variables with each of a vector of
level-2 variables.  Here's the code:

====================
#create data frame with level-1 variables
k <- as.data.frame(cbind(robo, asalto, secuestro, asesinato))

#create data frame with level-2 variables
l <- as.data.frame(cbind(IDH_IDH, IDH_ingpc, eco_pb, IM_indice, tasa_robo,
hom_tasa, totdelitos1, totdelitos2, total, pri, pan, prd))

#get cross-level interactions

for (i in 1:length(k)) {
for (j in 1:length(l)) {
print(summary(lmer(hrprotcrim ~ k[,i]*l[,j] + (k[,i] | Municipio))))
}
}
======================

The code works and produces 48 (4 level-1 x 12 level-2) sets of output.
The problem is, the output is illegible because instead of the variable
names, I get the indices:

[output]
==================================
Linear mixed model fit by REML ['lmerMod']
Formula: hrprotcrim ~ k[, i] * l[, j] + (k[, i] | Municipio)

REML criterion at convergence: 8801.4

Scaled residuals:
    Min      1Q  Median      3Q     Max
-2.4447 -0.7017 -0.2639  0.6766  3.0835

Random effects:
 Groups    Name        Variance Std.Dev. Corr
 Municipio (Intercept) 1.067868 1.0334
           k[, i]      0.005387 0.0734   1.00
 Residual              2.976150 1.7252
Number of obs: 2163, groups:  Municipio, 180

Fixed effects:
               Estimate Std. Error t value
(Intercept)    2.710847   0.101715  26.651
k[, i]        -0.056720   0.355802  -0.159
l[, j]         0.002701   0.002289   1.180
k[, i]:l[, j]  0.006510   0.006340   1.027

Correlation of Fixed Effects:
            (Intr) k[, i] l[, j]
k[, i]      -0.048
l[, j]      -0.514  0.028
k[,i]:l[,j]  0.034 -0.566 -0.072
==================================

Two questions:

1)  How can I get variable names instead of indices in the above output
2)  How can I estimate this with "mapply" instead of the double loop?

Here's the code for "mapply"

M4 <- mapply(function(k,l){summary(lmer(hrprotcrim ~ k*l + (k |
Municipio)))})

And here's what I get:

list()

I'd be grateful for any pointers.

Best,
David



-- 
Personal Web site:
http://investigadores.cide.edu/crow/

Web site for M?xico, las Am?ricas y el Mundo:
http://mexicoyelmundo.cide.edu/

====================================
David Crow, Ph.D.
Profesor-Investigador/Assistant Professor
Director General, *Las Am?ricas y el Mundo*
Divisi?n de Estudios Internacionales
Carretera M?xico-Toluca 3655
Col. Lomas de Santa Fe 01210  M?xico, D.F.
Tel.:  5727-9800, ext. 2152
Fax:  5727-9872
====================================

Conmutador: 5727-98-00 Lada sin costo: 01 800 021 2433 (CIDE) |?

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Mar 30 00:13:24 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 29 Mar 2015 22:13:24 +0000
Subject: [R] Help w/ variable names in loop with lmer
References: <CAMeG5ZhKHXfk0H++XaLviNobxtEc_XmN9e7n4_v3-dh9_3enFg@mail.gmail.com>
Message-ID: <loom.20150330T000835-77@post.gmane.org>

David Crow <david.crow <at> cide.edu> writes:

> 
> Hi, R users-
> 
> I'm estimating random effects models with cross-level interactions; I want
> to interact each of a vector of level-1 variables with each of a vector of
> level-2 variables.  Here's the code:
> 
> ====================
> #create data frame with level-1 variables
> k <- as.data.frame(cbind(robo, asalto, secuestro, asesinato))
> 
> #create data frame with level-2 variables
> l <- as.data.frame(cbind(IDH_IDH, IDH_ingpc, eco_pb, IM_indice, tasa_robo,
> hom_tasa, totdelitos1, totdelitos2, total, pri, pan, prd))
> 
> #get cross-level interactions
> 
> for (i in 1:length(k)) {
> for (j in 1:length(l)) {
> print(summary(lmer(hrprotcrim ~ k[,i]*l[,j] + (k[,i] | Municipio))))
> }
> }
> ======================
> 
> The code works and produces 48 (4 level-1 x 12 level-2) sets of output.
> The problem is, the output is illegible because instead of the variable
> names, I get the indices:
> 
> [output]
> ==================================
> Linear mixed model fit by REML ['lmerMod']
> Formula: hrprotcrim ~ k[, i] * l[, j] + (k[, i] | Municipio)
> 

[snip]

> Two questions:
> 
> 1)  How can I get variable names instead of indices in the above output
> 2)  How can I estimate this with "mapply" instead of the double loop?
> 
> Here's the code for "mapply"
> 
> M4 <- mapply(function(k,l){summary(lmer(hrprotcrim ~ k*l + (k |
> Municipio)))})
> 
> And here's what I get:
> 
> list()
> 

I would suggest appropriate use of ?reformulate

Assume dd is a data frame containing all variables

lev1vars <- c("robo", "asalto", "secuestro", "asesinato")
lev2vars <- c("IDH_IDH", "IDH_ingpc", ...)
ffun <- function(L1var,L2var) {
    ff <- reformulate(paste(L1var,L2var,sep="*"),
                      paste(L1var,"Municipio",sep="|"),
                      response="hrprotcrim")
    environment(ff) <- parent.frame()  ## trickiness
    return(summary(lmer(ff,data=dd)))
}
mapply(ffun,lev1vars,lev2vars)

?

If you had given a reproducible example I could have tested this ...


From drjimlemon at gmail.com  Mon Mar 30 01:08:03 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 30 Mar 2015 10:08:03 +1100
Subject: [R] generating phi using function()
In-Reply-To: <AEB16B1613D44C4793A7E6B6986B7A12F536BB55@EX10-LIVE-MBN2.ad.kent.ac.uk>
References: <AEB16B1613D44C4793A7E6B6986B7A12F536BB55@EX10-LIVE-MBN2.ad.kent.ac.uk>
Message-ID: <CA+8X3fWVy1dMiUM40oEKHFUufc5_AARrVmwkqe_4xo0uHA00Vw@mail.gmail.com>

Hi T.,
Your translation of the formula looks okay, and the error message is about
a missing argument. Perhaps you have not included the necessary arguments
to "phi" in the call to "mls".

Jim


On Sun, Mar 29, 2015 at 11:59 PM, T.Riedle <tr206 at kent.ac.uk> wrote:

> Hi everybody,
> I am trying to generate the formula shown in the attachment. My formula so
> far looks as follows:
>
> phi <- function(w1, w2, j, k, K){
> zaehler <- (k/K)^(w1-1)*(1-k/K)^(w2-1)
> nenner <- sum( ((1:K)/K)^(w1-1)*(1-(1:K)/K)^(w2-1))
> return( zaehler/nenner )
> }
>
> Unfortunately something must be wrong here as I get the following message
> when running a midas regression
>
> m22.phi<- midas_r(rv~mls(rvh,1:max.lag+h1,1,phi), start = list(rvh=c(1,1)))
> Error in phi(c(1, 1), 44L, 1) : argument "K" is missing, with no default
> Called from: .rs.breakOnError(TRUE)
> Browse[1]> K<-125
> Browse[1]> 125
>
> Could anybody look into my phi formula and tell me what is wrong with it?
>
> Thanks in advance.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From teepe24 at hotmail.com  Mon Mar 30 00:08:15 2015
From: teepe24 at hotmail.com (=?iso-8859-1?B?Q+lsaW5lIGI=?=)
Date: Mon, 30 Mar 2015 00:08:15 +0200
Subject: [R] Use Rstudio and RAnalyticFlow together
In-Reply-To: <mailman.2428.1427308829.3183.r-help@r-project.org>
References: <mailman.2428.1427308829.3183.r-help@r-project.org>
Message-ID: <DUB111-W3316C16BB8FCC4CAFB4978A8F60@phx.gbl>

Hi,

I would like to know if someone has any idea to use RAnalyticFlow and Rstudio together, i.e., use the nice flowchart system of RAnalyticFlow within the great interface of Rstudio ? I searched on the internet but without success ...
This would simplify/clarify so much my codes ! :)
Thank for any help.
 		 	   		  
	[[alternative HTML version deleted]]


From dstr7320 at uni.sydney.edu.au  Mon Mar 30 01:00:40 2015
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Sun, 29 Mar 2015 23:00:40 +0000
Subject: [R] Vennerable Plots for Publications
In-Reply-To: <CA+8X3fWM0vPvkGG1yDRDgjGEb3KPr6hmRmtuCvXFqmpCSYhrcw@mail.gmail.com>
References: <1427432405491.47716@uni.sydney.edu.au>,
	<CA+8X3fWM0vPvkGG1yDRDgjGEb3KPr6hmRmtuCvXFqmpCSYhrcw@mail.gmail.com>
Message-ID: <1427670039447.32135@uni.sydney.edu.au>

That is an adequate solution. It's always better if R package authors don't hard-code graphics parameters, though.

From ianlester43 at gmail.com  Mon Mar 30 00:52:54 2015
From: ianlester43 at gmail.com (Ian Lester)
Date: Mon, 30 Mar 2015 09:52:54 +1100
Subject: [R] A problem someone should know about
Message-ID: <300ADC7E-A143-4193-8A88-171CA053B721@mensa.org.au>

I?m a novice and this message looks like it shouldn?t be ignored. Someone who knows what they?re doing should probably take a look.
Thanks
Ian Lester

>logfat.lm<-(lm(body.fat~log(BMI)))
> plot(logfat)
Error in plot(logfat) : object 'logfat' not found
> plot(logfat.lm)
Hit <Return> to see next plot: 
Hit <Return> to see next plot: 
Hit <Return> to see next plot: 
Mar 29 18:10:18 iansimac.gateway rsession[69550] <Error>: Error: this application, or a library it uses, has passed an invalid numeric value (NaN, or not-a-number) to CoreGraphics API. This is a serious error and contributes to an overall degradation of system stability and reliability. This notice is a courtesy: please fix this problem. It will become a fatal error in an upcoming update.

From john.maindonald at anu.edu.au  Mon Mar 30 02:42:23 2015
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 30 Mar 2015 00:42:23 +0000
Subject: [R] Error in lm() with very small (close to zero) regressor
In-Reply-To: <mailman.0.1427623202.21078.r-help@r-project.org>
References: <mailman.0.1427623202.21078.r-help@r-project.org>
Message-ID: <ED9DD647-6B26-4C27-8E02-3AFAFA7DA725@anu.edu.au>

There are two issues:
1) Damage was done to accuracy in the calculation of t(X) %*% X
Where the mean to SD ratio is large, maybe even of the order of
100 or so, centre that column.

2) pseudo inverse() goes awry with columns of X that are of the
order of large negative (or, I expect, +ve) powers of ten.
were supplied to it. I?d guess that this has to do with the way that
a check for singularity is implemented.

Ben?s example:

set.seed(101)
n_obs <- 1000
y  <- rnorm(n_obs, 10,2.89)
x1 <- rnorm(n_obs, mean=1.235657e-14,sd=4.5e-17)
x2 <- rnorm(n_obs, 10,3.21)
X  <- cbind(rep(1,n_obs),x1,x2)

coef(lm(y~x1+x2))
##   (Intercept)            x1            x2
##  1.155959e+01 -1.658420e+14  3.797342e-02

library(corpcor)
t(cbind(coef(lm(y~x1+x2)),
           as.vector(pseudoinverse(t(X) %*% X) %*% t(X) %*% y)))
##      (Intercept)            x1         x2
## [1,]   11.559587 -1.658420e+14 0.03797342
## [2,]     9.511348  1.151908e-13  0.03788714

## Examine mean to SD ratios
round(c(mean(x1)/sd(x1), mean(x2)/sd(x2)), 2)
## [1] 263.65   3.28
## Notice that the coefficients for x2, where the mean/sd ratio
## is smaller, roughly agree.

## Damage was done to accuracy in the calculation of t(X) %*% X
## (but there is more to it than that, as we will see).

## Try
xc1 <- scale(x1,center=TRUE, scale=FALSE)
xc2 <- scale(x2,center=TRUE, scale=FALSE)
Xc <- cbind(rep(1,n_obs),x1,x2)
as.vector(pseudoinverse(t(Xc) %*% Xc) %*% t(Xc) %*% y)
## [1] 9.511348e+00 1.151908e-13 3.788714e-02

## Note now, however, that one should be able to dispense with
## the column of 1s, with no change to the coefficients of x1 & x2
Xc0 <- cbind(xc1,xc2)
as.vector(pseudoinverse(t(Xc0) %*% Xc0) %*% t(Xc0) %*% y)
## [1] 1.971167e-20 3.788714e-02

##
## Now try a more sensible scaling for xc1
Xcs <- cbind(rep(1,n_obs), xc1*1e14, xc2)
Xcs0 <- cbind(xc1*1e14, xc2)

t(cbind(coef(lm(y~I(1e14*xc1)+xc2)),
            as.vector(pseudoinverse(t(Xcs) %*% Xcs) %*% t(Xcs) %*% y)))
##      (Intercept) I(1e+14 * xc1)        xc2
## [1,]    9.899249       -1.65842 0.03797342
## [2,]    9.899249       -1.65842 0.03797342

## Eureka!

## cf also
as.vector(pseudoinverse(t(Xcs0) %*% Xcs0) %*% t(Xcs0) %*% y)
## [1] -1.65842037  0.03797342


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

Centre for Mathematics & Its Applications,

Australian National University, Canberra ACT 0200.


On 29/03/2015, at 23:00, <r-help-request at r-project.org<mailto:r-help-request at r-project.org>> <r-help-request at r-project.org<mailto:r-help-request at r-project.org>> wrote:

From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
Subject: Re: [R] Error in lm() with very small (close to zero) regressor
Date: 29 March 2015 6:28:22 NZDT
To: <r-help at stat.math.ethz.ch<mailto:r-help at stat.math.ethz.ch>>


peter dalgaard <pdalgd <at> gmail.com<http://gmail.com/>> writes:



On 28 Mar 2015, at 00:32 , RiGui <raluca.gui <at> business.uzh.ch<http://business.uzh.ch/>> wrote:

Hello everybody,

I have encountered the following problem with lm():

When running lm() with a regressor close to zero -
of the order e-10, the
value of the estimate is of huge absolute value , of order millions.

However, if I write the formula of the OLS estimator,
in matrix notation:
pseudoinverse(t(X)*X) * t(X) * y , the results are correct, meaning the
estimate has value 0.

 How do you know this answer is "correct"?

here is the code:

y  <- rnorm(n_obs, 10,2.89)
x1 <- rnorm(n_obs, 0.00000000000001235657,0.000000000000000045)
x2 <- rnorm(n_obs, 10,3.21)
X  <- cbind(x1,x2)

Eh?  You want
X  <- cbind(rep(1,n_obs),x1,x2)

bFE <- lm(y ~ x1 + x2)
bFE

bOLS <- pseudoinverse(t(X) %*% X) %*% t(X) %*% y
bOLS


Note: I am applying a deviation from the
mean projection to the data, that
is why I have some regressors with such small values.

Thank you for any help!

Raluca

 Is there a reason you can't scale your regressors?


Example not reproducible:


 I agree that the OP's question was not reproducible, but it's
not too hard to make it reproducible. I bothered to use
library("sos"); findFn("pseudoinverse") to find pseudoinverse()
in corpcor:

It is true that we get estimates with very large magnitudes,
but their

set.seed(101)
n_obs <- 1000
y  <- rnorm(n_obs, 10,2.89)
x1 <- rnorm(n_obs, mean=1.235657e-14,sd=4.5e-17)
x2 <- rnorm(n_obs, 10,3.21)
X  <- cbind(x1,x2)

bFE <- lm(y ~ x1 + x2)
bFE
coef(summary(bFE))

                Estimate   Std. Error     t value  Pr(>|t|)
(Intercept)  1.155959e+01 2.312956e+01  0.49977541 0.6173435
x1          -1.658420e+14 1.872598e+15 -0.08856254 0.9294474
x2           3.797342e-02 2.813000e-02  1.34992593 0.1773461

library("corpcor")
bOLS <- pseudoinverse(t(X) %*% X) %*% t(X) %*% y
bOLS

            [,1]
[1,] 9.807664e-16
[2,] 8.880273e-01

And if we scale the predictor:

bFE2 <- lm(y ~ I(1e14*x1) + x2)
coef(summary(bFE2))

                Estimate Std. Error     t value  Pr(>|t|)
(Intercept)   11.55958731   23.12956  0.49977541 0.6173435
I(1e+14 * x1) -1.65842037   18.72598 -0.08856254 0.9294474
x2             0.03797342    0.02813  1.34992593 0.1773461

bOLS stays constant.

To be honest, I haven't thought about this enough to see
which answer is actually correct, although I suspect the
problem is in bOLS, since the numerical methods (unlike
the brute-force pseudoinverse method given here) behind
lm have been carefully considered for numerical stability.




	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Mon Mar 30 03:59:49 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 30 Mar 2015 14:59:49 +1300
Subject: [R] A problem someone should know about
In-Reply-To: <300ADC7E-A143-4193-8A88-171CA053B721@mensa.org.au>
References: <300ADC7E-A143-4193-8A88-171CA053B721@mensa.org.au>
Message-ID: <5518AE15.9030308@auckland.ac.nz>

On 30/03/15 11:52, Ian Lester wrote:
> I?m a novice and this message looks like it shouldn?t be ignored. Someone who knows what they?re doing should probably take a look.
> Thanks
> Ian Lester
>
>> logfat.lm<-(lm(body.fat~log(BMI)))
>> plot(logfat)
> Error in plot(logfat) : object 'logfat' not found
>> plot(logfat.lm)
> Hit <Return> to see next plot:
> Hit <Return> to see next plot:
> Hit <Return> to see next plot:
> Mar 29 18:10:18 iansimac.gateway rsession[69550] <Error>: Error: this
> application, or a library it uses, has passed an invalid numeric
> value (NaN, or not-a-number) to CoreGraphics API. This is a serious
> error and contributes to an overall degradation of system stability
> and reliability. This notice is a courtesy: please fix this problem.
> It will become a fatal error in an upcoming update.

Please make your examples *reproducible* as the posting guide requests.

I *presume* that your data are the "fat" data from the "UsingR" package,
which you did not mention.

After installing and loading "UsingR" I did

 > logfat.lm <- lm(body.fat~log(BMI),data=fat)
 > plot(logfat.lm)

and got a sequence of plots, with no error thrown. It would appear that 
whatever is causing the error that you saw is peculiar to your system.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From rmh at temple.edu  Mon Mar 30 04:21:17 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 29 Mar 2015 22:21:17 -0400
Subject: [R] A problem someone should know about
In-Reply-To: <5518AE15.9030308@auckland.ac.nz>
References: <300ADC7E-A143-4193-8A88-171CA053B721@mensa.org.au>
	<5518AE15.9030308@auckland.ac.nz>
Message-ID: <CAGx1TMBbdDQOf_eFCo0f-AXgwQk0r9VmpocKVqOia8dXkfSxDg@mail.gmail.com>

This looks like a specific Macintosh error that appears at random intervals.
I get it at random, and unreproducible times.  I reported it (or
perhaps a close relative)
to the r-sig-mac list in September 2014.

Rich


On Sun, Mar 29, 2015 at 9:59 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 30/03/15 11:52, Ian Lester wrote:
>>
>> I?m a novice and this message looks like it shouldn?t be ignored. Someone
>> who knows what they?re doing should probably take a look.
>> Thanks
>> Ian Lester
>>
>>> logfat.lm<-(lm(body.fat~log(BMI)))
>>> plot(logfat)
>>
>> Error in plot(logfat) : object 'logfat' not found
>>>
>>> plot(logfat.lm)
>>
>> Hit <Return> to see next plot:
>> Hit <Return> to see next plot:
>> Hit <Return> to see next plot:
>> Mar 29 18:10:18 iansimac.gateway rsession[69550] <Error>: Error: this
>> application, or a library it uses, has passed an invalid numeric
>> value (NaN, or not-a-number) to CoreGraphics API. This is a serious
>> error and contributes to an overall degradation of system stability
>> and reliability. This notice is a courtesy: please fix this problem.
>> It will become a fatal error in an upcoming update.
>
>
> Please make your examples *reproducible* as the posting guide requests.
>
> I *presume* that your data are the "fat" data from the "UsingR" package,
> which you did not mention.
>
> After installing and loading "UsingR" I did
>
>> logfat.lm <- lm(body.fat~log(BMI),data=fat)
>> plot(logfat.lm)
>
> and got a sequence of plots, with no error thrown. It would appear that
> whatever is causing the error that you saw is peculiar to your system.
>
> cheers,
>
> Rolf Turner
>
> --
> Rolf Turner
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> Home phone: +64-9-480-4619
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pnsinha68 at gmail.com  Mon Mar 30 08:10:12 2015
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Mon, 30 Mar 2015 11:40:12 +0530
Subject: [R] Sampling
Message-ID: <CADcgpJf=Gd0frj80g1WO0VETZsCYO+pFhcg1uZ4zHrgZHvScNA@mail.gmail.com>

I have 1000 data points.  i want to take 30 samples and find mean. I
also want to repeat this process 100 times. How to go about it?
Regards
Parth


From djnordlund at frontier.com  Mon Mar 30 08:12:24 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Sun, 29 Mar 2015 23:12:24 -0700
Subject: [R] generating phi using function()
In-Reply-To: <CA+8X3fWVy1dMiUM40oEKHFUufc5_AARrVmwkqe_4xo0uHA00Vw@mail.gmail.com>
References: <AEB16B1613D44C4793A7E6B6986B7A12F536BB55@EX10-LIVE-MBN2.ad.kent.ac.uk>
	<CA+8X3fWVy1dMiUM40oEKHFUufc5_AARrVmwkqe_4xo0uHA00Vw@mail.gmail.com>
Message-ID: <5518E948.7010200@frontier.com>


The argument 'K' is missing since you are only passing four arguments to 
the phi() function, but you defined it with five formal parameters. It 
looks like the argument 'j' is not necessary in the function.  It is an 
unnecessary carry-over from the summation notation and it is never used 
in the function.

Dan


On 3/29/2015 4:08 PM, Jim Lemon wrote:
> Hi T.,
> Your translation of the formula looks okay, and the error message is about
> a missing argument. Perhaps you have not included the necessary arguments
> to "phi" in the call to "mls".
>
> Jim
>
>
> On Sun, Mar 29, 2015 at 11:59 PM, T.Riedle <tr206 at kent.ac.uk> wrote:
>
>> Hi everybody,
>> I am trying to generate the formula shown in the attachment. My formula so
>> far looks as follows:
>>
>> phi <- function(w1, w2, j, k, K){
>> zaehler <- (k/K)^(w1-1)*(1-k/K)^(w2-1)
>> nenner <- sum( ((1:K)/K)^(w1-1)*(1-(1:K)/K)^(w2-1))
>> return( zaehler/nenner )
>> }
>>
>> Unfortunately something must be wrong here as I get the following message
>> when running a midas regression
>>
>> m22.phi<- midas_r(rv~mls(rvh,1:max.lag+h1,1,phi), start = list(rvh=c(1,1)))
>> Error in phi(c(1, 1), 44L, 1) : argument "K" is missing, with no default
>> Called from: .rs.breakOnError(TRUE)
>> Browse[1]> K<-125
>> Browse[1]> 125
>>
>> Could anybody look into my phi formula and tell me what is wrong with it?
>>
>> Thanks in advance.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Daniel Nordlund
Bothell, WA USA


From djnordlund at frontier.com  Mon Mar 30 08:23:45 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Sun, 29 Mar 2015 23:23:45 -0700
Subject: [R] Sampling
In-Reply-To: <CADcgpJf=Gd0frj80g1WO0VETZsCYO+pFhcg1uZ4zHrgZHvScNA@mail.gmail.com>
References: <CADcgpJf=Gd0frj80g1WO0VETZsCYO+pFhcg1uZ4zHrgZHvScNA@mail.gmail.com>
Message-ID: <5518EBF1.6070106@frontier.com>

On 3/29/2015 11:10 PM, Partha Sinha wrote:
> I have 1000 data points.  i want to take 30 samples and find mean. I
> also want to repeat this process 100 times. How to go about it?
> Regards
> Parth
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

see ?replicate and ?sample.  Simple example where yourdata is a simple 
vector of values, and assuming you want to sample without replacement. 
Generalizing it to other data structures is left as an exercise for the 
reader.

replicate(100,mean(sample(yourdata,30, replace=FALSE)))

hope this is helpful,

Dan

-- 
Daniel Nordlund
Bothell, WA USA


From chirleu at gmail.com  Mon Mar 30 09:27:07 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Mon, 30 Mar 2015 09:27:07 +0200
Subject: [R] temporal autocorrelation in MCMCglmm
Message-ID: <CALC46t_UBBBZAER2B3md619hNdcKKmy+jiLcak_UkX=Kuy0Ptg@mail.gmail.com>

Hi,
For a number of individuals, I have measured several behavioral traits in
the wild. Those traits (e.g. home range) can be estimated on different
temporal scales, for example daily, weekly or monthly. I want to estimate
repeatability of those traits, assuming that the daily/weekly/monthly
measurements represent replicates. I have 3 months (90 days) of data for
each trait. Two questions:

1) How can assess if there is temporal autocorrelation in my model? I guess
that if I consider daily measurements as replicates (90 replicates), I will
have some autocorrelation, but if I use just monthly measurements (3
replicates) maybe I avoid it.

2) How can account for temporal autocorrelation in MCMCglmm?

Sorry for this pretty basic questions but I haven't found an answer so far.

Thanks!

David

	[[alternative HTML version deleted]]


From stephane.adamowicz at avignon.inra.fr  Mon Mar 30 09:59:36 2015
From: stephane.adamowicz at avignon.inra.fr (=?iso-8859-1?Q?St=E9phane_Adamowicz?=)
Date: Mon, 30 Mar 2015 09:59:36 +0200
Subject: [R] matrix manipulation question
In-Reply-To: <7FDAEF53-2F5E-41B2-BCAE-408F1D24042F@comcast.net>
References: <5514E6F4.9050700@gmail.com>
	<D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>
	<950C4B78-0DE6-4C3A-8031-76B0821595C1@gmail.com>
	<040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>
	<7FDAEF53-2F5E-41B2-BCAE-408F1D24042F@comcast.net>
Message-ID: <519F0EDD-ED21-4EA2-99C6-5F0AE59E7C25@avignon.inra.fr>


Le 27 mars 2015 ? 18:01, David Winsemius <dwinsemius at comcast.net> a ?crit :

> 
> On Mar 27, 2015, at 3:41 AM, St?phane Adamowicz wrote:
> 
>> Well, it seems to work with me.
>> 
> 
> No one is doubting that it worked for you in this instance. What Peter D. was criticizing was the construction :
> 
> complete.cases(t(Y))==T
> 
> ... and it was on two bases that it is "wrong". The first is that `T` is not guaranteed to be TRUE. The second is that the test ==T (or similarly ==TRUE) is completely unnecessary because `complete.cases` returns a logical vector and so that expression is a waste of time.
> 

Indeed, You are right, the following code was enough :
?  Z <- Y[, complete.cases(t(Y) ] ?


However, in order to help me understand, would you be so kind as to give me a matrix or data.frame example where ? complete.cases(X)== T ? or ? complete.cases(X)== TRUE ? would give some unwanted result ?

St?phane


	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Mon Mar 30 10:36:35 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 30 Mar 2015 10:36:35 +0200
Subject: [R] matrix manipulation question
In-Reply-To: <519F0EDD-ED21-4EA2-99C6-5F0AE59E7C25@avignon.inra.fr>
References: <5514E6F4.9050700@gmail.com>
	<D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>
	<950C4B78-0DE6-4C3A-8031-76B0821595C1@gmail.com>
	<040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>
	<7FDAEF53-2F5E-41B2-BCAE-408F1D24042F@comcast.net>
	<519F0EDD-ED21-4EA2-99C6-5F0AE59E7C25@avignon.inra.fr>
Message-ID: <BC7BE8EB-1249-48D9-8C07-CCE5B2A490D1@xs4all.nl>


> On 30-03-2015, at 09:59, St?phane Adamowicz <stephane.adamowicz at avignon.inra.fr> wrote:
> 
> 
> Le 27 mars 2015 ? 18:01, David Winsemius <dwinsemius at comcast.net> a ?crit :
> 
>> 
>> On Mar 27, 2015, at 3:41 AM, St?phane Adamowicz wrote:
>> 
>>> Well, it seems to work with me.
>>> 
>> 
>> No one is doubting that it worked for you in this instance. What Peter D. was criticizing was the construction :
>> 
>> complete.cases(t(Y))==T
>> 
>> ... and it was on two bases that it is "wrong". The first is that `T` is not guaranteed to be TRUE. The second is that the test ==T (or similarly ==TRUE) is completely unnecessary because `complete.cases` returns a logical vector and so that expression is a waste of time.
>> 
> 
> Indeed, You are right, the following code was enough :
> ?  Z <- Y[, complete.cases(t(Y) ] ?
> 
> 
> However, in order to help me understand, would you be so kind as to give me a matrix or data.frame example where ? complete.cases(X)== T ? or ? complete.cases(X)== TRUE ? would give some unwanted result ?

T can be redefined.
Try this in your example with airquality:

T <- "hello"
Z <- Y[,complete.cases(t(Y))==T]
Z

TRUE is a reserved word and cannot be changed. But why use ==TRUE if not necessary?
All of this mentioned already by David Winsemius in a previous reply.

Berend


From pdalgd at gmail.com  Mon Mar 30 10:42:46 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 30 Mar 2015 10:42:46 +0200
Subject: [R] matrix manipulation question
In-Reply-To: <519F0EDD-ED21-4EA2-99C6-5F0AE59E7C25@avignon.inra.fr>
References: <5514E6F4.9050700@gmail.com>
	<D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>
	<950C4B78-0DE6-4C3A-8031-76B0821595C1@gmail.com>
	<040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>
	<7FDAEF53-2F5E-41B2-BCAE-408F1D24042F@comcast.net>
	<519F0EDD-ED21-4EA2-99C6-5F0AE59E7C25@avignon.inra.fr>
Message-ID: <CA8ED6B3-7342-46D4-9459-ED00DF4EEBCD@gmail.com>


> On 30 Mar 2015, at 09:59 , St?phane Adamowicz <stephane.adamowicz at avignon.inra.fr> wrote:
> 
> 
> However, in order to help me understand, would you be so kind as to give me a matrix or data.frame example where ? complete.cases(X)== T ? or ? complete.cases(X)== TRUE ? would give some unwanted result ?

The standard problem with T for TRUE is if T has been used for some other purpose, like a time variable. E.g., T <- 0 ; complete.cases(X)==T.

complete.cases()==TRUE is just silly, like (x==0)==TRUE or ((x==0)==TRUE)==TRUE). 

(However, notice that x==TRUE is different from as.logical(x) if x is numeric, so ifelse(x,y,z) may differ from ifelse(x==TRUE,y,z).) 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From HDoran at air.org  Mon Mar 30 11:40:56 2015
From: HDoran at air.org (Doran, Harold)
Date: Mon, 30 Mar 2015 09:40:56 +0000
Subject: [R] POSIX and ecdf()
Message-ID: <D13E9266.25502%hdoran@air.org>

Below is some working code that, generally speaking, accomplishes why I want, but am looking for a necessary improvement in the final step. The code below scrapes data from a website (thousands of pages actually) and organizes athlete?s scores in a data frame. The final variable, called Workout05 in the original data is a timed event. So, I use strplit() to pull out the data I want in that column and format it using as.POSIXct() as you can see in the code below (using a regular expression I?m sure would improve on how to pull out those data in the column, but that is not my primary question).

After I have all data, I want to find the empirical CDF of the data, so I use ecdf() on those data just as I would on other variables. Now, the main issue I?m interested is in the final step where you plug in a specific time to find its percentile

## These are below in context of the real problem as well
fn <- ecdf(dat$score5)
fn(dat$score5[1])

This works, but not in the way I want. What I want is for a user to easily be able to enter their time in ?lay? terms such as 5:35 and from that it would return the percentile rank.

So, I?d like something like the following to be able to work

fn(5:35)

The larger context for this problem for why I want this can be seen if you visit my web app built using shiny. I?ve built a site where athletes can build customized reports based on their performance on certain events by entering in data. This specific issue would be found on the ?get my percentile? tab where a user can use the text input box to enter their time in a way humans typically understand it and then it gets passed to the R fn() function that runs in the background and builds the plot for them.

https://hdoran.shinyapps.io/openAnalysis/

So, my question is how can I structure this such that a time can be expressed as simply minute:seconds (e.g., 4:52) in a text box so that it would still work to return a percentile rank as I?ve described here.

Thanks



library(XML)

        i = 1; j = 0; division = 1
        url <-
        paste(paste('http://games.crossfit.com/scores/leaderboard.php?stage=5&sort=0&page=', i, sep=''), paste('&division=1&region=', j, sep=''), '&numberperpage=100&competition=0&frontpage=0&expanded=1&year=15&full=1&showtoggles=0&hidedropdowns=0&showathleteac=1&=&is_mobile=0', sep='')
        tmp <- try(readHTMLTable(readLines(url), which=1, header=TRUE))
if(!is.null(dim(tmp))){ # new part here
        names(tmp) <- gsub("\\n", "", names(tmp))
        names(tmp) <- gsub(" +", "", names(tmp))
        tmp[] <- lapply(tmp, function(x) gsub("\\n", "", x))
        tmp$region <- j
        }
        dat <- tmp

   aa <- strsplit(dat$Workout05, split = '\\(')
bb <- sapply(aa, function(x) x[2])
aa <- strsplit(bb, split = '\\)')

dat$score5 <- as.character(sapply(strsplit(bb, split = '\\)'), function(x) x))
dat$score5 <- as.POSIXct(dat$score5, format="%M:%S")

fn <- ecdf(dat$score5)
fn(dat$score5[1])

	[[alternative HTML version deleted]]


From lkhodakarim at gmail.com  Mon Mar 30 14:10:57 2015
From: lkhodakarim at gmail.com (Soheila Khodakarim)
Date: Mon, 30 Mar 2015 15:40:57 +0330
Subject: [R] non-conformable arguments
Message-ID: <CACYT75tu2HDpQFV6eBTca+7BRKvdqunALqeUVBWGuhvJhC-+Qg@mail.gmail.com>

Dear All,

I want to run neural network on my data.

i run these codes:

#load mydata
dim(mydata)
# 20 3111
library(neuralnet)
fm <- as.formula(paste("resp ~", paste(colnames(mydata)[1:3110],
collapse="+")))
out <- neuralnet(fm,data=mydata, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1)
#load testset
dim(testset)
# 20 3111
out.results <- compute(out, testset)
Error in neurons[[i]] %*% weights[[i]] : non-conformable arguments

what should I do now?

Regards,
Soheila

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Mar 30 14:26:50 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 30 Mar 2015 14:26:50 +0200
Subject: [R] non-conformable arguments
In-Reply-To: <CACYT75tu2HDpQFV6eBTca+7BRKvdqunALqeUVBWGuhvJhC-+Qg@mail.gmail.com>
References: <CACYT75tu2HDpQFV6eBTca+7BRKvdqunALqeUVBWGuhvJhC-+Qg@mail.gmail.com>
Message-ID: <CAJuCY5ztdK5nXKGSG00M63cB1fErvRMt0NUJWMSgg8M8uWWi8w@mail.gmail.com>

You should sent us a commented, minimal, self-contained, reproducible code
as the posting guide tells you to do.
Your code is not self-contained. So we can only speculate what when wrong.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-30 14:10 GMT+02:00 Soheila Khodakarim <lkhodakarim at gmail.com>:

> Dear All,
>
> I want to run neural network on my data.
>
> i run these codes:
>
> #load mydata
> dim(mydata)
> # 20 3111
> library(neuralnet)
> fm <- as.formula(paste("resp ~", paste(colnames(mydata)[1:3110],
> collapse="+")))
> out <- neuralnet(fm,data=mydata, hidden = 4, lifesign = "minimal",
> linear.output = FALSE, threshold = 0.1)
> #load testset
> dim(testset)
> # 20 3111
> out.results <- compute(out, testset)
> Error in neurons[[i]] %*% weights[[i]] : non-conformable arguments
>
> what should I do now?
>
> Regards,
> Soheila
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lkhodakarim at gmail.com  Mon Mar 30 14:47:17 2015
From: lkhodakarim at gmail.com (Soheila Khodakarim)
Date: Mon, 30 Mar 2015 16:17:17 +0330
Subject: [R] Fwd: non-conformable arguments
In-Reply-To: <CACYT75tu2HDpQFV6eBTca+7BRKvdqunALqeUVBWGuhvJhC-+Qg@mail.gmail.com>
References: <CACYT75tu2HDpQFV6eBTca+7BRKvdqunALqeUVBWGuhvJhC-+Qg@mail.gmail.com>
Message-ID: <CACYT75tdTbL3xOWVrUe2P_JQmdtoh_2C7ZcVYkS55ZHLzC09dQ@mail.gmail.com>

Dear Thierry Onkelinx,

Thank you so much to answer me. But I do not know what information I should
send for you
I want to run neural network on my data.I run these codes and I saw this
Error in the last line

#load mydata
dim(mydata)
# 20 3111
library(neuralnet)
fm <- as.formula(paste("resp ~", paste(colnames(mydata)[1:3110],
collapse="+")))
out <- neuralnet(fm,data=mydata, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1)
Call: neuralnet(formula = fm, data = mydata, hidden = 4, threshold = 0.1,
  lifesign = "minimal", linear.output = FALSE)

1 repetition was calculated.

        Error Reached Threshold Steps
1 2.402157856     0.06958374995     9
#load testset
dim(testset)
# 20 3111
out.results <- compute(out, testset)
Error in neurons[[i]] %*% weights[[i]] : non-conformable arguments


Regards,
Soheila

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Mar 30 14:52:42 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 30 Mar 2015 14:52:42 +0200
Subject: [R] non-conformable arguments
In-Reply-To: <CACYT75tdTbL3xOWVrUe2P_JQmdtoh_2C7ZcVYkS55ZHLzC09dQ@mail.gmail.com>
References: <CACYT75tu2HDpQFV6eBTca+7BRKvdqunALqeUVBWGuhvJhC-+Qg@mail.gmail.com>
	<CACYT75tdTbL3xOWVrUe2P_JQmdtoh_2C7ZcVYkS55ZHLzC09dQ@mail.gmail.com>
Message-ID: <CAJuCY5z_np1EyCeWcDX1MRYf9UsvkwfDbfxC2YuipkLuyZNCNA@mail.gmail.com>

We need enough information to run your code on our computer and get the
same error as you. In this case we are missing the data. See e.g.
http://adv-r.had.co.nz/Reproducibility.html If you can't provide the
original data, then try to make a (small) example which reproduces your
problem.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-30 14:47 GMT+02:00 Soheila Khodakarim <lkhodakarim at gmail.com>:

> Dear Thierry Onkelinx,
>
> Thank you so much to answer me. But I do not know what information I
> should send for you
> I want to run neural network on my data.I run these codes and I saw this
> Error in the last line
>
> #load mydata
> dim(mydata)
> # 20 3111
> library(neuralnet)
> fm <- as.formula(paste("resp ~", paste(colnames(mydata)[1:3110],
> collapse="+")))
> out <- neuralnet(fm,data=mydata, hidden = 4, lifesign = "minimal",
> linear.output = FALSE, threshold = 0.1)
> Call: neuralnet(formula = fm, data = mydata, hidden = 4, threshold = 0.1,
>     lifesign = "minimal", linear.output = FALSE)
>
> 1 repetition was calculated.
>
>         Error Reached Threshold Steps
> 1 2.402157856     0.06958374995     9
> #load testset
> dim(testset)
> # 20 3111
> out.results <- compute(out, testset)
> Error in neurons[[i]] %*% weights[[i]] : non-conformable arguments
>
>
> Regards,
> Soheila
>
>

	[[alternative HTML version deleted]]


From dakotajudo at mac.com  Mon Mar 30 15:00:16 2015
From: dakotajudo at mac.com (Peter Claussen)
Date: Mon, 30 Mar 2015 08:00:16 -0500
Subject: [R] A problem someone should know about
In-Reply-To: <CAGx1TMBbdDQOf_eFCo0f-AXgwQk0r9VmpocKVqOia8dXkfSxDg@mail.gmail.com>
References: <300ADC7E-A143-4193-8A88-171CA053B721@mensa.org.au>
	<5518AE15.9030308@auckland.ac.nz>
	<CAGx1TMBbdDQOf_eFCo0f-AXgwQk0r9VmpocKVqOia8dXkfSxDg@mail.gmail.com>
Message-ID: <FB2B8956-4C4E-4CC0-8990-70FB5B72EFDD@mac.com>

Rich,

You?ve probably reported the error to the wrong group.

A quick search suggests this is not an R issue, but an RStudio issue. The error message is unique enough. Google returns this as the first link:

https://support.rstudio.com/hc/communities/public/questions/200807456-Error-when-plotting-graphics-on-Mac-OSX-Mavericks

Peter

> On Mar 29, 2015, at 9:21 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> 
> This looks like a specific Macintosh error that appears at random intervals.
> I get it at random, and unreproducible times.  I reported it (or
> perhaps a close relative)
> to the r-sig-mac list in September 2014.
> 
> Rich
> 
> 
> On Sun, Mar 29, 2015 at 9:59 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>> On 30/03/15 11:52, Ian Lester wrote:
>>> 
>>> I?m a novice and this message looks like it shouldn?t be ignored. Someone
>>> who knows what they?re doing should probably take a look.
>>> Thanks
>>> Ian Lester
>>> 
>>>> logfat.lm<-(lm(body.fat~log(BMI)))
>>>> plot(logfat)
>>> 
>>> Error in plot(logfat) : object 'logfat' not found
>>>> 
>>>> plot(logfat.lm)
>>> 
>>> Hit <Return> to see next plot:
>>> Hit <Return> to see next plot:
>>> Hit <Return> to see next plot:
>>> Mar 29 18:10:18 iansimac.gateway rsession[69550] <Error>: Error: this
>>> application, or a library it uses, has passed an invalid numeric
>>> value (NaN, or not-a-number) to CoreGraphics API. This is a serious
>>> error and contributes to an overall degradation of system stability
>>> and reliability. This notice is a courtesy: please fix this problem.
>>> It will become a fatal error in an upcoming update.
>> 
>> 
>> Please make your examples *reproducible* as the posting guide requests.
>> 
>> I *presume* that your data are the "fat" data from the "UsingR" package,
>> which you did not mention.
>> 
>> After installing and loading "UsingR" I did
>> 
>>> logfat.lm <- lm(body.fat~log(BMI),data=fat)
>>> plot(logfat.lm)
>> 
>> and got a sequence of plots, with no error thrown. It would appear that
>> whatever is causing the error that you saw is peculiar to your system.
>> 
>> cheers,
>> 
>> Rolf Turner
>> 
>> --
>> Rolf Turner
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>> Home phone: +64-9-480-4619
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ntfredo at gmail.com  Mon Mar 30 15:39:46 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Mon, 30 Mar 2015 16:39:46 +0300
Subject: [R] Multiple Plots using ggplot
Message-ID: <CAGh51gS7eX0QggStQ+G=1VW=Z48vRSfK9XzDSpH47bGfnaO-LA@mail.gmail.com>

Dear All,

I want to plot multiple using ggplot function from a data frame of
many columns. I want to plot only str1, str2 and str3 and I failed to
make it. What I want is to compare str1, str2 and str3 by plotting
vertical line. I also need to add points to the plot to be able to
separate them.


Here is how the data look like and how I tried to make it.

Date NumberofRaindays TotalRains str1 str2 str3 1/1/1952 86 1360.5 92 120
112 1/1/1953 96 1100 98 100 110
...                                           ....
....             ...              ....            ....

df1 <-data.frame(data)
df1
df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
df2

ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type = "h")

Kindly any help is welcome. Thanks

Regards,
Frederic.

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From r at catwhisker.org  Mon Mar 30 15:50:59 2015
From: r at catwhisker.org (David Wolfskill)
Date: Mon, 30 Mar 2015 06:50:59 -0700
Subject: [R] data.frame: data-driven column selections that vary by row??
Message-ID: <20150330135059.GL1250@albert.catwhisker.org>

Sorry if that's confusing: I'm probably confused. :-(

I am collecting and trying to analyze data regarding performance of
computer systems.

After extracting the data from its repository, I have created and
used a Perl script to generate a (relatively) simple CSV, each
record of which contains:
* a POSIXct timestamp
* a hostname
* a collection of metrics for the interval identified by the timestamp,
  and specific to the host in question, as well as some factors to
  group the hosts (e.g., whether it's in a "control" vs. a "test"
  group; a broad categorization of how the host is provisioned; which
  version of the software it was running at the time...).  (Each
  metric and factor is in a uniquely-named column.)

As extracted from the repository, there were several records for each
such hostname/timestamp pair -- e.g., there would be separate records
for:
* Input bandwidth utilization for network interface 1
* Output bandwidth utilization for network interface 1
* Input bandwidth utilization for network interface 2
* Output bandwidth utilization for network interface 2

(And the same field would be used for each of these -- the
interpretation being driven by the content of other fields in teh
record.)

Working with the data as described (immediately) above directly in R
seemed... daunting, at best: thus the excursion into Perl.

And for some of the data, what I have works well enough.

But now I also want to analyze information from disk drives, and things
get messy (as far as I can see).

First, each disk drive has a collection of 17 metrics (such as
"busy_pct", "kb_per_transfer_read", and "transfers_per_second_write"),
as well as a factor ("dev_type").  Each also has a device name that is
unique within the host where it resides (e.g. "da1", "da2", "da3"....).
(The "dev_type" factor identifies whether the drive is a solid-state
device or a spinning disk.)

I have thus made the corresponding columns unique by pasting the drive
name and the name of the metric (or factor), separating the two with
"_" (e.g. "da7_busy_pct"; "ada0_mb_per_second_write";
"ada4_queue_length").  I am not certain that's the best thing I could
have done -- and I'm open to changing the approach.

The challenge for me is that different (classes of) machines are
provisioned differently; some consequennces of that:
* While da1 may be a spinning disk on host A, that has no bearing on
  whether or not the "da1" on host B is a spinning disk or an SSD.
* Host C may not even have a "da1" device.
* Host D may be of a type that normally has a "da1," but in this case,
  the drive has failed and has been disabled (so host D won't report
  anything about "da1").

(I'm not too bothered about the "non-reporting" case, but cite it so we
all know about it.)

I expect I will want to be using groupings:
* All disk devices -- this one is easy.
* All SSD devices (excluding spinning disks).
* All spinning disks (excluding SSDs).

I'm having trouble with the latter two (though, certainly, if I solve
one, the other is also solved).

Also, for some  of the metrics, I will want to sum them; for others,
I will want to do other things -- find minima or maxima, or average
them.  So pre-calculating such aggregates in the Perl script isn't
something that appeals to me.

Finally (as far as complications go), I'm trying to write the code in
such a way that if we deploy a new configuration of machine that has
(say) twice as many drives as the biggest one we presently deploy, the
code Just Works -- I shouldn't need to update the code merely to adapt
to another hardware configuration.

I have been able to write a function that takes the data.frame obtained
by reading the above-cited CSV, and generates a data.frame with a row
for each host, and depicts the "dev_type" for each device for that host;
here's an abbreviated (and slightly redacted) copy of its output to
illustrate some of the above:

       ada0 ada1 ada2 ada3 ada4 ada5 da30 da31 da32 da33 da34 da35 da36 da3
host_A  ssd  ssd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd hdd
host_B  ssd  ssd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd hdd
host_G  ssd  ssd  ssd  ssd  ssd  ssd                                    ssd
host_H  ssd  ssd  ssd  ssd  ssd  ssd                                    ssd
host_M  ssd  ssd  ssd  ssd  ssd  ssd                                    ssd
host_N  ssd  ssd  ssd  ssd  ssd  ssd                                    ssd

(That function is written with the explicit assumption(!) that for the
period covered by a given set of input data, a given host's
configuration remains static: we won't have drives changing type
mid-stream.)

So the point of this lengthy(!) note is to ask if there's a
somewhat-sane way to be able to group the metrics for the "ssd" devices
(for example), given the above.

(So far, the least obnoxious way that comes to mind is to actually
create 2 columns for each device metric: one for the device if it's an
"ssd";l the other for "hdd" -- so instead of columns such as:
* da3_busy_pct
* da3_dev_type
* da3_kb_per_transfer_read
* da36_cam_timeouts
* da36_dev_type
* da36_mb_per_second_read

I would have:
* da3_hdd_busy_pct
* da3_ssd_busy_pct
* da3_hdd_dev_type
* da3_ssd_dev_type
* da3_hdd_kb_per_transfer_read
* da3_ssd_kb_per_transfer_read
* da36_hdd_cam_timeouts
* da36_ssd_cam_timeouts
* da36_hdd_dev_type
* da36_ssd_dev_type
* da36_hdd_mb_per_second_read
* da36_ssd_mb_per_second_read

and no more than half of those would actually be populated (depending on
the content of "dev_type" when the Perl script is creating the CSV).

That seems rather hackish, though.

Thank you in advance for any insight.

Peace,
david
-- 
David H. Wolfskill				r at catwhisker.org
Those who murder in the name of God or prophet are blasphemous cowards.

See http://www.catwhisker.org/~david/publickey.gpg for my public key.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 949 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150330/984d379b/attachment.bin>

From Jose.Iparraguirre at ageuk.org.uk  Mon Mar 30 15:51:27 2015
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Mon, 30 Mar 2015 13:51:27 +0000
Subject: [R] =?utf-8?q?Ayuda_con_un_=C3=A1rbol_de_regresi=C3=B3n?=
In-Reply-To: <5511A9EE.1000706@aghmed.fsnet.co.uk>
References: <CAOxN7gt5MzF0xewSys49KXdKsvecqew0zUWPO5mFgsWg7vh9gg@mail.gmail.com>
	<5511A9EE.1000706@aghmed.fsnet.co.uk>
Message-ID: <5F8EC5C77B9AE547A8959F690F04C7B2440194C9@AGEPXMB006.uk.age.local>


Miguel,

Sin tus datos es imposible brindarte una respuesta precisa pero ten en cuenta que la descripci?n del argumento 'f?rmula' en la funci?n tree del paquete del mismo nombre dice que la variable dependiente -PRECIO en tu caso- debe ser un vector num?rico si quieres estimar un ?rbol de regressi?n o un factor si deseas producir un ?rbol de clasificaci?n. No veo t?rminos de interacci?n en tu f?rmula, cuya presencia no es permitida, por lo que te sugiero revises qu? clase de objeto es PRECIO, para lo cual puedes escribir str(CARROST$PRECIO). Puede que necesites modificar la clase a vector num?rico.

Without any of your data we can't give you a precise answer, but take into account that the description of the formula argument of the tree function (package tree) reads: "The left-hand-side (response) should be either a numerical vector when a regression tree will be fitted or a factor, when a classification tree is produced. The right-hand-side should be a series of numeric or factor variables separated by +; there should be no interaction terms". Your formula contains no interaction terms, so I'd suggest you should check what class of object PRECIO is -type str(CARROST$PRECIO). You may need to change it to a numerical vector.

Jos?



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael Dewey
Sent: 24 March 2015 18:16
To: Miguel angel Lopez Martinez; r-help at r-project.org
Subject: Re: [R] Ayuda con un ?rbol de regresi?n

Miguel, si prefieres escribir en espanol

https://stat.ethz.ch/mailman/listinfo/r-help-es

(This is the address of the Spanish language mailing list)

On 23/03/2015 20:13, Miguel angel Lopez Martinez wrote:
> ARBOL<-tree(PRECIO~CILINDRAJE_DEL_MOTOR+MODELO,data=CARROST)
> ARBOL
> plot(ARBOL)
> text(ARBOL,cex=0.9)
>
>   este es el c?digo que utilizamos las variables cilindraje y modelo 
> son categ?ricas transformadas por que si utilizamos las varibales como 
> factor no las reconoce
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5751 / Virus Database: 4315/9373 - Release Date: 
> 03/24/15
>

--
Michael
http://www.dewey.myzen.co.uk

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Age UK Group

Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798) Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA. 

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited. Age UK Enterprises Limited is authorised and regulated by the Financial Conduct Authority.

Charitable Services are offered through Age UK (the Charity) and commercial products and services are offered by the Charity?s subsidiary companies. The Age UK Group comprises of Age UK, and its subsidiary companies and charities, dedicated to improving the lives of people in later life. Our network includes the three national charities Age Cymru, Age NI and Age Scotland and more than 160 local Age UK charities.

This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are addressed. If you receive a message in error, please advise the sender and delete immediately.

Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing through its network and may block or modify mails which are deemed to be unsuitable.

From JLucke at ria.buffalo.edu  Mon Mar 30 16:01:03 2015
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Mon, 30 Mar 2015 10:01:03 -0400
Subject: [R] generating phi using function()
In-Reply-To: <AEB16B1613D44C4793A7E6B6986B7A12F536BB55@EX10-LIVE-MBN2.ad.kent.ac.uk>
References: <AEB16B1613D44C4793A7E6B6986B7A12F536BB55@EX10-LIVE-MBN2.ad.kent.ac.uk>
Message-ID: <OFDE256A41.D56A507C-ON85257E18.004CC8B2-85257E18.004D003C@ria.buffalo.edu>

Your function phi has 5 arguments with no defaults.  Your call only has 3 
arguments.  Hence the error message.


> phi <- function(w1, w2, j, k, K){
+   zaehler <- (k/K)^(w1-1)*(1-k/K)^(w2-1)
+   nenner <- sum( ((1:K)/K)^(w1-1)*(1-(1:K)/K)^(w2-1))
+   return( zaehler/nenner )
+ }
> phi(c(1, 1), 44L, 1)
Error in phi(c(1, 1), 44L, 1) : argument "k" is missing, with no default




> 





"T.Riedle" <tr206 at kent.ac.uk> 
Sent by: "R-help" <r-help-bounces at r-project.org>
03/29/2015 08:59 AM

To
"r-help at r-project.org" <r-help at r-project.org>, 
cc

Subject
[R] generating phi using function()






Hi everybody,
I am trying to generate the formula shown in the attachment. My formula so 
far looks as follows:

phi <- function(w1, w2, j, k, K){
zaehler <- (k/K)^(w1-1)*(1-k/K)^(w2-1)
nenner <- sum( ((1:K)/K)^(w1-1)*(1-(1:K)/K)^(w2-1))
return( zaehler/nenner )
}

Unfortunately something must be wrong here as I get the following message 
when running a midas regression

m22.phi<- midas_r(rv~mls(rvh,1:max.lag+h1,1,phi), start = 
list(rvh=c(1,1)))
Error in phi(c(1, 1), 44L, 1) : argument "K" is missing, with no default
Called from: .rs.breakOnError(TRUE)
Browse[1]> K<-125
Browse[1]> 125

Could anybody look into my phi formula and tell me what is wrong with it?

Thanks in advance.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From crypticlineage at gmail.com  Mon Mar 30 15:54:39 2015
From: crypticlineage at gmail.com (Vikram Chhatre)
Date: Mon, 30 Mar 2015 09:54:39 -0400
Subject: [R] changing column labels for data frames inside a list
Message-ID: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>

> summary(mygenfreqt)
                  Length Class  Mode
dat1.str 59220  -none- numeric
dat2.str 59220  -none- numeric
dat3.str 59220  -none- numeric

> head(mylist[[1]])
           1     2     3     4     5     6     7     8     9    10    11
 12
L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475 0.350
0.275
L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525 0.650
0.725

I want to change 1:12 to pop1:pop12

mylist<- lapply(mylist, function(e) colnames(e) <- paste0('pop',1:12))

What this is doing is replacing the data frames with just names
pop1:pop12.  I just want to replace the column labels.

Thanks for any suggestions.

	[[alternative HTML version deleted]]


From ianlester43 at gmail.com  Mon Mar 30 07:59:23 2015
From: ianlester43 at gmail.com (Ian Lester)
Date: Mon, 30 Mar 2015 16:59:23 +1100
Subject: [R] Again: A problem someone should know about
References: <300ADC7E-A143-4193-8A88-171CA053B721@mensa.org.au>
Message-ID: <AD7FEE31-C682-4F1A-B6D3-DF9B229307E7@mensa.org.au>

i have no idea what to do

> plot(body.fat, BMI,xlab="Body fat",ylab="BMI",main=?Figure 2.1: BMI vs Body fat (n=252)?)
Error: unexpected input in "plot(body.fat, BMI,xlab="Body fat",ylab="BMI",main=?"
> plot(body.fat, BMI,xlab="Body fat",ylab="BMI")
 serious error. This application, or a library it uses, is using an invalid context  and is thereby contributing to an overall degradation of system stability and reliability. This notice is a courtesy: please fix this problem. It will become a fatal error in an upcoming update.
> 
> Begin forwarded message:
> 
> From: Ian Lester <ihlester at mensa.org.au>
> Reply-To: ihlester at mensa.org.au
> Subject: A problem someone should know about
> Date: 30 March 2015 9:52:54 am AEDT
> To: r-help at r-project.org
> 
> I?m a novice and this message looks like it shouldn?t be ignored. Someone who knows what they?re doing should probably take a look.
> Thanks
> Ian Lester
> 
>> logfat.lm<-(lm(body.fat~log(BMI)))
>> plot(logfat)
> Error in plot(logfat) : object 'logfat' not found
>> plot(logfat.lm)
> Hit <Return> to see next plot: 
> Hit <Return> to see next plot: 
> Hit <Return> to see next plot: 
> Mar 29 18:10:18 iansimac.gateway rsession[69550] <Error>: Error: this application, or a library it uses, has passed an invalid numeric value (NaN, or not-a-number) to CoreGraphics API. This is a serious error and contributes to an overall degradation of system stability and reliability. This notice is a courtesy: please fix this problem. It will become a fatal error in an upcoming update.


	[[alternative HTML version deleted]]


From ssefick at gmail.com  Mon Mar 30 16:34:09 2015
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 30 Mar 2015 09:34:09 -0500
Subject: [R] Multiple Plots using ggplot
In-Reply-To: <CAGh51gS7eX0QggStQ+G=1VW=Z48vRSfK9XzDSpH47bGfnaO-LA@mail.gmail.com>
References: <CAGh51gS7eX0QggStQ+G=1VW=Z48vRSfK9XzDSpH47bGfnaO-LA@mail.gmail.com>
Message-ID: <CADKEMqhsaeDC9S1fZVdefm-P2mFwFEPJYFGp0e-=Fh=XR+y48Q@mail.gmail.com>

Hi Frederic,

Can you provide a minimal reproducible example including either real data
(dput), or simulated data that mimics your situation? This will allow more
people to help.

Stephen

On Mon, Mar 30, 2015 at 8:39 AM, Frederic Ntirenganya <ntfredo at gmail.com>
wrote:

> Dear All,
>
> I want to plot multiple using ggplot function from a data frame of
> many columns. I want to plot only str1, str2 and str3 and I failed to
> make it. What I want is to compare str1, str2 and str3 by plotting
> vertical line. I also need to add points to the plot to be able to
> separate them.
>
>
> Here is how the data look like and how I tried to make it.
>
> Date NumberofRaindays TotalRains str1 str2 str3 1/1/1952 86 1360.5 92 120
> 112 1/1/1953 96 1100 98 100 110
> ...                                           ....
> ....             ...              ....            ....
>
> df1 <-data.frame(data)
> df1
> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
> df2
>
> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type = "h")
>
> Kindly any help is welcome. Thanks
>
> Regards,
> Frederic.
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From ldhrf at siswa.ukm.edu.my  Mon Mar 30 14:06:45 2015
From: ldhrf at siswa.ukm.edu.my (Nasr Al-Dhurafi)
Date: Mon, 30 Mar 2015 20:06:45 +0800
Subject: [R] Joint distribution of wind data
Message-ID: <CAFUdcV_E2MY2kqWEhy=A3mQY9Q0cOZVmm=2fQdM2b_4=-ZzfZA@mail.gmail.com>

* Hi,
** I'm dealing with wind data and I'd like to model their**
distribution.** Wind** direction *
* are typically following a vonmises distribution and wind speeds
**follow a weibull distribution. I'd like to build a joint**
distribution** of directions and speeds as a VonMises-Weibull
bivariate*
* distribution.
**An alternative in such cases (i.e., when marginals are available
but** the** joint is difficult to postulate) is to use copulas, which
can** construct*



* multivariate distributions from univariate marginals. Therefore, if
anyone has an idea of how to do whether joint distribution or copula
forwind data in R,Please, contact with me.*


*Best Regards *

*Nasr *

	[[alternative HTML version deleted]]


From ldhrf at siswa.ukm.edu.my  Mon Mar 30 14:22:56 2015
From: ldhrf at siswa.ukm.edu.my (Nasr Al-Dhurafi)
Date: Mon, 30 Mar 2015 20:22:56 +0800
Subject: [R] Transformation of the circular variable into linear variable
Message-ID: <CAFUdcV_DUC3EMG44gcfJ_cdWpmFBw1B+tWjuDuFyHm6uKDZfEQ@mail.gmail.com>

I am working with a circular data ( wind direction ) and i have problem
in transforming  the circular variable into linear variable. I have found
an equation that can be used to convert the circular variable into linear
variable which is included in this paper *" ARMA based approaches for
forecasting the tuple of wind speed and direction". *The equation is called
as the inverse of a link function and i have attached  the summery of it.T
herefore,Please, if you have an idea of how to conduct it in R programming
or  if you have another method for transformation, let me know it. Your
cooperation is highly appreciated.

My Best Regards &  All The Best
Nasr

	[[alternative HTML version deleted]]


From rodolfopelinson at gmail.com  Mon Mar 30 14:53:50 2015
From: rodolfopelinson at gmail.com (Rodolfo Pelinson)
Date: Mon, 30 Mar 2015 09:53:50 -0300
Subject: [R] vif in package car: there are aliased coefficients in the
	model
In-Reply-To: <web-553901633@cgpsrv2.cis.mcmaster.ca>
References: <CAHEYhxO+FXLM2+iKwz=OGj+n8ZSLpjv42S+YJJc_tJL3pa8SeA@mail.gmail.com>
	<005901d068f1$47ceb300$d76c1900$@mcmaster.ca>
	<CAHEYhxNduK+dqo_33PQH15EigyaffD96OQycz0u6G3A4aeN_zg@mail.gmail.com>
	<web-553901633@cgpsrv2.cis.mcmaster.ca>
Message-ID: <CAHEYhxNEBEB7A7sRPHBtYpR6i8Rsd11ab9voFhV9=EVLEmoEmg@mail.gmail.com>

Thanks a lot for the answer and I'm sorry for the silly question!

Also thanks for the conceptual advice! It was also a doubt of me and my
advisors.


Best!

2015-03-28 15:17 GMT-03:00 John Fox <jfox at mcmaster.ca>:

> Dear Rodolfo,
>
> Sending the data helps, though if you had done what I suggested, you would
> have seen what's going on:
>
> -------------------- snip ------------------
>
> > dim(data)
> [1] 8 8
>
> > summary(lm(response_variable ~ predictor_1 + predictor_2 + predictor_3 +
> predictor_4
> +             + predictor_5 + predictor_6 + predictor_7, data = data))
>
> Call:
> lm(formula = response_variable ~ predictor_1 + predictor_2 +
>     predictor_3 + predictor_4 + predictor_5 + predictor_6 + predictor_7,
>     data = data)
>
> Residuals:
> ALL 8 residuals are 0: no residual degrees of freedom!
>
> Coefficients: (1 not defined because of singularities)
>                     Estimate Std. Error t value Pr(>|t|)
> (Intercept)          -5.1905         NA      NA       NA
> predictor_1yellow     2.4477         NA      NA       NA
> predictor_2fora       6.5056         NA      NA       NA
> predictor_2interior   6.0769         NA      NA       NA
> predictor_3           0.6750         NA      NA       NA
> predictor_4           3.0742         NA      NA       NA
> predictor_5           0.6715         NA      NA       NA
> predictor_6          -0.9850         NA      NA       NA
> predictor_7               NA         NA      NA       NA
>
> Residual standard error: NaN on 0 degrees of freedom
> Multiple R-squared:      1,     Adjusted R-squared:    NaN
> F-statistic:   NaN on 7 and 0 DF,  p-value: NA
>
> -------------------- snip ------------------
>
> So the data set that you're using has 8 cases and 8 variables, one of
> which is a factor with 3 levels. Consequently, the model you're fitting my
> LS has 9 coefficients. Necessarily the rank of the model matrix is
> deficient. When you eliminate a coefficient, you get a perfect fit: 8
> coefficients fit to 8 cases with 0 df for error.
>
> This is of course nonsense: You don't have enough data to fit a model of
> this complexity. In fact, you might not have enough data to reasonably fit
> a model with just 1 predictor.
>
> I'm cc'ing this response to the r-help email list, where you started this
> thread.
>
> Best,
>  John
>
> On Sat, 28 Mar 2015 12:04:05 -0300
>  Rodolfo Pelinson <rodolfopelinson at gmail.com> wrote:
> > Thanks a lot for your answer and your time! But Im still having the same
> > problem.
> >
> > That's the script I am using:
> >
> ____________________________________________________________________________________________________________________
> > library(car)
> >
> > data <-read.table("data_vif.txt", header = T, sep = "\t", row.names = 1)
> > data
> >
> > vif(lm(response_variable ~ predictor_1 + predictor_2 + predictor_3 +
> > predictor_4 + predictor_5 + predictor_6 + predictor_7, data = data))
> >
> > vif(lm(response_variable ~ predictor_1 + predictor_2 + predictor_3 +
> > predictor_4 + predictor_5 + predictor_6, data = data))
> >
> ____________________________________________________________________________________________________________________
> >
> > the first vif function above returns me the following error:
> >
> > "Error in vif.default(lm(response_variable ~ predictor_1 + predictor_2
> +  :
> >   there are aliased coefficients in the model"
> >
> > Then if I remove any one of the predictors (in the script I removed
> > predictor_7 as an example), it returns this:
> >
> >             GVIF Df GVIF^(1/(2*Df))
> > predictor_1  NaN  1             NaN
> > predictor_2  NaN  2             NaN
> > predictor_3  NaN  1             NaN
> > predictor_4  NaN  1             NaN
> > predictor_5  NaN  1             NaN
> > predictor_6  NaN  1             NaN
> > Warning message:
> > In cov2cor(v) : diag(.) had 0 or NA entries; non-finite result is
> doubtful
> >
> >
> > Can you help me with this? I even attached to this e-mail my data set.
> It's
> > a small table.
> >
> > Sorry for the question.
> >
> >
> >
> > 2015-03-27 21:51 GMT-03:00 John Fox <jfox at mcmaster.ca>:
> >
> > > Dear Rodolfo,
> > >
> > > It's apparently the case that at least one of the columns of the model
> > > matrix for your model is perfectly collinear with others.
> > >
> > > There's not nearly enough information here to figure out exactly what
> the
> > > problem is, and the information that you provided certainly falls
> short of
> > > allowing me or anyone else to reproduce your problem and diagnose it
> > > properly. It's not even clear from your message exactly what the
> structure
> > > of the model is, although localizacao  is apparently a factor with 3
> > > levels.
> > >
> > >
> > > If you look at the summary() output for your model or just print it,
> you
> > > should at least see which coefficients are aliased, and that might
> help you
> > > understand what went wrong.
> > >
> > > I hope this helps,
> > >  John
> > >
> > > -------------------------------------------------------
> > > John Fox, Professor
> > > McMaster University
> > > Hamilton, Ontario, Canada
> > > http://socserv.mcmaster.ca/jfox/
> > >
> > >
> > > > -----Original Message-----
> > > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Rodolfo
> > > > Pelinson
> > > > Sent: March-27-15 3:07 PM
> > > > To: r-help at r-project.org
> > > > Subject: [R] vif in package car: there are aliased coefficients in
> the
> > > model
> > > >
> > > > Hello. I'm trying to use the function vif from package car in a lm.
> > > However it
> > > > returns the following error:
> > > > "Error in vif.default(lm(MDescores.sitescores ~ hidroperiodo +
> > > localizacao
> > > > +  : there are aliased coefficients in the model"
> > > >
> > > > When I exclude any predictor from the model, it returns this warning
> > > > message:
> > > > "Warning message: In cov2cor(v) : diag(.) had 0 or NA entries;
> non-finite
> > > > result is doubtful"
> > > >
> > > > When I exclude any other predictor from the model vif finally works.
> I
> > > can't
> > > > figure it out whats the problem. This are the results that R returns
> > > > me:
> > > >
> > > > > vif(lm(MDescores.sitescores ~ hidroperiodo + localizacao + area +
> > > > profundidade + NTVM +  NTVI + PCs...c.1.., data = MDVIF)) Error in
> > > > vif.default(lm(MDescores.sitescores ~ hidroperiodo + localizacao +
> > > >  :   there are aliased coefficients in the model
> > > >
> > > > > vif(lm(MDescores.sitescores ~ localizacao + area + profundidade +
> NTVM
> > > > > +
> > > >  NTVI + PCs...c.1.., data = MDVIF))
> > > >              GVIF Df GVIF^(1/(2*Df))
> > > > localizacao   NaN  2             NaN
> > > > area          NaN  1             NaN
> > > > profundidade  NaN  1             NaN
> > > > NTVM          NaN  1             NaN
> > > > NTVI          NaN  1             NaN
> > > > PCs...c.1..   NaN  1             NaN
> > > > Warning message:
> > > > In cov2cor(v) : diag(.) had 0 or NA entries; non-finite result is
> > > doubtful
> > > >
> > > > Thanks.
> > > > --
> > > > Rodolfo Mei Pelinson.
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > > guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > > ---
> > > This email has been checked for viruses by Avast antivirus software.
> > > http://www.avast.com
> > >
> > >
> >
> >
> > --
> > Rodolfo Mei Pelinson.
>
> ------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
>
>
>
>


-- 
Rodolfo Mei Pelinson.

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Mon Mar 30 16:41:21 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 30 Mar 2015 10:41:21 -0400
Subject: [R] Again: A problem someone should know about
In-Reply-To: <AD7FEE31-C682-4F1A-B6D3-DF9B229307E7@mensa.org.au>
References: <300ADC7E-A143-4193-8A88-171CA053B721@mensa.org.au>
	<AD7FEE31-C682-4F1A-B6D3-DF9B229307E7@mensa.org.au>
Message-ID: <CAM_vjunEDnSy_TMpq2T5n8c9tJLUF4=nkq5DOGNWDff=pHJ7=w@mail.gmail.com>

On Mon, Mar 30, 2015 at 1:59 AM, Ian Lester <ianlester43 at gmail.com> wrote:
> i have no idea what to do

One of the other responses already told you it was probably an Rstudio
problem, so not using Rstudip seems like a good place to start.

Sarah

>
>> plot(body.fat, BMI,xlab="Body fat",ylab="BMI",main=?Figure 2.1: BMI vs Body fat (n=252)?)
> Error: unexpected input in "plot(body.fat, BMI,xlab="Body fat",ylab="BMI",main=?"
>> plot(body.fat, BMI,xlab="Body fat",ylab="BMI")
>  serious error. This application, or a library it uses, is using an invalid context  and is thereby contributing to an overall degradation of system stability and reliability. This notice is a courtesy: please fix this problem. It will become a fatal error in an upcoming update.
>>
>> Begin forwarded message:
>>


From dcarlson at tamu.edu  Mon Mar 30 16:42:36 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 30 Mar 2015 14:42:36 +0000
Subject: [R] Again: A problem someone should know about
In-Reply-To: <AD7FEE31-C682-4F1A-B6D3-DF9B229307E7@mensa.org.au>
References: <300ADC7E-A143-4193-8A88-171CA053B721@mensa.org.au>
	<AD7FEE31-C682-4F1A-B6D3-DF9B229307E7@mensa.org.au>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D67A302@mb02.ads.tamu.edu>

In your first example you created logfat.lm and then tried to plot logfat so you got an error indicating that logfat did not exist. 

In your second example we have no idea what body.fat. You must make your examples reproducible so that we can reproduce your error. It looks like you could also benefit from spending a little time learning about R using a free tutorial.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ian Lester
Sent: Monday, March 30, 2015 12:59 AM
To: r-help at r-project.org
Subject: [R] Again: A problem someone should know about

i have no idea what to do

> plot(body.fat, BMI,xlab="Body fat",ylab="BMI",main=?Figure 2.1: BMI vs Body fat (n=252)?)
Error: unexpected input in "plot(body.fat, BMI,xlab="Body fat",ylab="BMI",main=?"
> plot(body.fat, BMI,xlab="Body fat",ylab="BMI")
 serious error. This application, or a library it uses, is using an invalid context  and is thereby contributing to an overall degradation of system stability and reliability. This notice is a courtesy: please fix this problem. It will become a fatal error in an upcoming update.
> 
> Begin forwarded message:
> 
> From: Ian Lester <ihlester at mensa.org.au>
> Reply-To: ihlester at mensa.org.au
> Subject: A problem someone should know about
> Date: 30 March 2015 9:52:54 am AEDT
> To: r-help at r-project.org
> 
> I?m a novice and this message looks like it shouldn?t be ignored. Someone who knows what they?re doing should probably take a look.
> Thanks
> Ian Lester
> 
>> logfat.lm<-(lm(body.fat~log(BMI)))
>> plot(logfat)
> Error in plot(logfat) : object 'logfat' not found
>> plot(logfat.lm)
> Hit <Return> to see next plot: 
> Hit <Return> to see next plot: 
> Hit <Return> to see next plot: 
> Mar 29 18:10:18 iansimac.gateway rsession[69550] <Error>: Error: this application, or a library it uses, has passed an invalid numeric value (NaN, or not-a-number) to CoreGraphics API. This is a serious error and contributes to an overall degradation of system stability and reliability. This notice is a courtesy: please fix this problem. It will become a fatal error in an upcoming update.


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From sarah.goslee at gmail.com  Mon Mar 30 16:47:01 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 30 Mar 2015 10:47:01 -0400
Subject: [R] changing column labels for data frames inside a list
In-Reply-To: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
References: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
Message-ID: <CAM_vju=pYBO9XwKMNEQxsGY9-0Y2TxUAZicwrW5=WC3pULY-MA@mail.gmail.com>

colnames(e) <- paste0('pop',1:12)

isn't a function and doesn't return anything.

> mylist <- list(
+ data.frame(a = runif(10), b = runif(10)),
+ data.frame(c = runif(10), d = runif(10)),
+ data.frame(e = runif(10), f = runif(10)))
> mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop', 1:2); e})
> colnames(mylist2[[1]])
[1] "pop1" "pop2"

Sarah

On Mon, Mar 30, 2015 at 9:54 AM, Vikram Chhatre
<crypticlineage at gmail.com> wrote:
>> summary(mygenfreqt)
>                   Length Class  Mode
> dat1.str 59220  -none- numeric
> dat2.str 59220  -none- numeric
> dat3.str 59220  -none- numeric
>
>> head(mylist[[1]])
>            1     2     3     4     5     6     7     8     9    10    11
>  12
> L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475 0.350
> 0.275
> L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525 0.650
> 0.725
>
> I want to change 1:12 to pop1:pop12
>
> mylist<- lapply(mylist, function(e) colnames(e) <- paste0('pop',1:12))
>
> What this is doing is replacing the data frames with just names
> pop1:pop12.  I just want to replace the column labels.
>
> Thanks for any suggestions.
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From macqueen1 at llnl.gov  Mon Mar 30 16:48:26 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 30 Mar 2015 14:48:26 +0000
Subject: [R] changing column labels for data frames inside a list
In-Reply-To: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
References: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
Message-ID: <D13EAE56.12403C%macqueen1@llnl.gov>

Assuming that the elements of mylist are data frames, try this:

mylist <- lapply(mylist, function(e) { names(e) <- paste0('pop',1:12) ; e})


With certain exceptions, the result of a function is the result of the
last expression in the function body. As you defined it, the last
expression was
  colnames(e) <- paste0('pop',1:12)
that is, the column names (not "labels", but names).

If the elements really are data frames, then names() can be used instead
of colnames(), but colnames() is ok. I don't know if one of them is better
than the other for data frames.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/30/15, 6:54 AM, "Vikram Chhatre" <crypticlineage at gmail.com> wrote:

>> summary(mygenfreqt)
>                  Length Class  Mode
>dat1.str 59220  -none- numeric
>dat2.str 59220  -none- numeric
>dat3.str 59220  -none- numeric
>
>> head(mylist[[1]])
>           1     2     3     4     5     6     7     8     9    10    11
> 12
>L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475 0.350
>0.275
>L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525 0.650
>0.725
>
>I want to change 1:12 to pop1:pop12
>
>mylist<- lapply(mylist, function(e) colnames(e) <- paste0('pop',1:12))
>
>What this is doing is replacing the data frames with just names
>pop1:pop12.  I just want to replace the column labels.
>
>Thanks for any suggestions.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ivan.calandra at univ-reims.fr  Mon Mar 30 16:50:44 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Mon, 30 Mar 2015 16:50:44 +0200
Subject: [R] changing column labels for data frames inside a list
In-Reply-To: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
References: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
Message-ID: <551962C4.2020503@univ-reims.fr>

I am not sure it would do it since there is no reproducible example, but 
try names() instead of colnames().

HTH,
Ivan

--
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 30/03/15 15:54, Vikram Chhatre a ?crit :
>> summary(mygenfreqt)
>                    Length Class  Mode
> dat1.str 59220  -none- numeric
> dat2.str 59220  -none- numeric
> dat3.str 59220  -none- numeric
>
>> head(mylist[[1]])
>             1     2     3     4     5     6     7     8     9    10    11
>   12
> L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475 0.350
> 0.275
> L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525 0.650
> 0.725
>
> I want to change 1:12 to pop1:pop12
>
> mylist<- lapply(mylist, function(e) colnames(e) <- paste0('pop',1:12))
>
> What this is doing is replacing the data frames with just names
> pop1:pop12.  I just want to replace the column labels.
>
> Thanks for any suggestions.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sven.templer at gmail.com  Mon Mar 30 16:56:06 2015
From: sven.templer at gmail.com (Sven E. Templer)
Date: Mon, 30 Mar 2015 16:56:06 +0200
Subject: [R] changing column labels for data frames inside a list
In-Reply-To: <CAM_vju=pYBO9XwKMNEQxsGY9-0Y2TxUAZicwrW5=WC3pULY-MA@mail.gmail.com>
References: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
	<CAM_vju=pYBO9XwKMNEQxsGY9-0Y2TxUAZicwrW5=WC3pULY-MA@mail.gmail.com>
Message-ID: <CAHuTOvo1PXvv5ANVTPQB8zEOwg3a8WFyn1kNY_eJD6cL0SJ+2Q@mail.gmail.com>

On 30 March 2015 at 16:47, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> colnames(e) <- paste0('pop',1:12)
>
> isn't a function and doesn't return anything.
>

But
function(e){colnames(e) <- paste0('pop', 1:2)}
is a function and it returns something (the last evaluated expression! -
here the paste0 return):

> mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop', 1:2)})
> mylist2
[[1]]
[1] "pop1" "pop2"

[[2]]
[1] "pop1" "pop2"

[[3]]
[1] "pop1" "pop2"

 from ?return:

If the end of a function is reached without calling return, the value of
the last evaluated expression is returned.

>
> > mylist <- list(
> + data.frame(a = runif(10), b = runif(10)),
> + data.frame(c = runif(10), d = runif(10)),
> + data.frame(e = runif(10), f = runif(10)))
> > mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop', 1:2);
> e})
> > colnames(mylist2[[1]])
> [1] "pop1" "pop2"
>
> Sarah
>
> On Mon, Mar 30, 2015 at 9:54 AM, Vikram Chhatre
> <crypticlineage at gmail.com> wrote:
> >> summary(mygenfreqt)
> >                   Length Class  Mode
> > dat1.str 59220  -none- numeric
> > dat2.str 59220  -none- numeric
> > dat3.str 59220  -none- numeric
> >
> >> head(mylist[[1]])
> >            1     2     3     4     5     6     7     8     9    10    11
> >  12
> > L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475 0.350
> > 0.275
> > L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525 0.650
> > 0.725
> >
> > I want to change 1:12 to pop1:pop12
> >
> > mylist<- lapply(mylist, function(e) colnames(e) <- paste0('pop',1:12))
> >
> > What this is doing is replacing the data frames with just names
> > pop1:pop12.  I just want to replace the column labels.
> >
> > Thanks for any suggestions.
> >
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gian.benucci at gmail.com  Mon Mar 30 17:11:23 2015
From: gian.benucci at gmail.com (=?UTF-8?Q?Gian_Maria_Niccol=C3=B2_Benucci?=)
Date: Mon, 30 Mar 2015 17:11:23 +0200
Subject: [R] error MANOVA in R
Message-ID: <CAPxEaESWK9qKUO68DF1Z9SuUkWdsKrb5ZSHf7dF_hD2VGPe9fg@mail.gmail.com>

Dear R-usrs,

I am trying to perform a MANOVA on a data frame with 31 columns about soil
parameters and 1 column containing the explanatory variable (Fraction) that
have three levels.
my code is the following:

datam <- read.table("data_manova2.csv", header=T, sep=",")
names(datam)

manova_fraction2 <- manova(cbind(pH, AWC, WEOC, WEN, C.mic, CO2.C, Ca, Mg,
K, Na, sol.exch.Fe, easily.reducible.Fe, amourphou.Fe.oxide...Fe.OM,
crystalline.Fe.oxides, TN, TOC, NH4.N, NO3.N, N.org, organic.P, avaiable.P,
Total.PLFA, Tot.Bat, Gram., Gram..1, Funghi, AMF, protozoa, actinomiceti,
non.specifici) ~ as.factor(Fraction), data= datam)

summary(manova_fraction2)

when I did the summary I got this error

> summary(manova_fraction2)
Error in summary.manova(manova_fraction2) : residuals have rank 18 < 30

?Is this error possibly due to high correlation between my variables?

Many thanks in advance,


-- 
Gian

	[[alternative HTML version deleted]]


From crypticlineage at gmail.com  Mon Mar 30 17:19:03 2015
From: crypticlineage at gmail.com (Vikram Chhatre)
Date: Mon, 30 Mar 2015 11:19:03 -0400
Subject: [R] changing column labels for data frames inside a list
In-Reply-To: <CAHuTOvo1PXvv5ANVTPQB8zEOwg3a8WFyn1kNY_eJD6cL0SJ+2Q@mail.gmail.com>
References: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
	<CAM_vju=pYBO9XwKMNEQxsGY9-0Y2TxUAZicwrW5=WC3pULY-MA@mail.gmail.com>
	<CAHuTOvo1PXvv5ANVTPQB8zEOwg3a8WFyn1kNY_eJD6cL0SJ+2Q@mail.gmail.com>
Message-ID: <CAJZnH0kKktxpNTpVsw6K+TRh2QJOWK-cckjqgq8i92_US8SQRw@mail.gmail.com>

First of all, thank you for all the quick replies.  Here is a solution that
worked for me.

mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',1:12);
return(e)})

> head(mylist2[[1]])
        pop1  pop2  pop3  pop4  pop5  pop6  pop7  pop8  pop9 pop10 pop11
pop12
L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475 0.350
0.275
L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525 0.650
0.725

While we are at this, I wanted to create a 13th column in each data frame
for average of each row.

# Calculate average
myavg <- lapply(mylist2, function(e) rowSums(mylist2)/12)

# Attach to the main data frame
mylist3 <- cbind(mylist2, myavg)

This does not work the way I imagined it would.  The myavg vector is
attached directly to mylist2, not to individual dataframes within.

p.s. Is it a standard convention to always copy the reply to the last
person who responded?

On Mon, Mar 30, 2015 at 10:56 AM, Sven E. Templer <sven.templer at gmail.com>
wrote:

> On 30 March 2015 at 16:47, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>
> > colnames(e) <- paste0('pop',1:12)
> >
> > isn't a function and doesn't return anything.
> >
>
> But
> function(e){colnames(e) <- paste0('pop', 1:2)}
> is a function and it returns something (the last evaluated expression! -
> here the paste0 return):
>
> > mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop', 1:2)})
> > mylist2
> [[1]]
> [1] "pop1" "pop2"
>
> [[2]]
> [1] "pop1" "pop2"
>
> [[3]]
> [1] "pop1" "pop2"
>
>  from ?return:
>
> If the end of a function is reached without calling return, the value of
> the last evaluated expression is returned.
>
> >
> > > mylist <- list(
> > + data.frame(a = runif(10), b = runif(10)),
> > + data.frame(c = runif(10), d = runif(10)),
> > + data.frame(e = runif(10), f = runif(10)))
> > > mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',
> 1:2);
> > e})
> > > colnames(mylist2[[1]])
> > [1] "pop1" "pop2"
> >
> > Sarah
> >
> > On Mon, Mar 30, 2015 at 9:54 AM, Vikram Chhatre
> > <crypticlineage at gmail.com> wrote:
> > >> summary(mygenfreqt)
> > >                   Length Class  Mode
> > > dat1.str 59220  -none- numeric
> > > dat2.str 59220  -none- numeric
> > > dat3.str 59220  -none- numeric
> > >
> > >> head(mylist[[1]])
> > >            1     2     3     4     5     6     7     8     9    10
> 11
> > >  12
> > > L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475
> 0.350
> > > 0.275
> > > L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525
> 0.650
> > > 0.725
> > >
> > > I want to change 1:12 to pop1:pop12
> > >
> > > mylist<- lapply(mylist, function(e) colnames(e) <- paste0('pop',1:12))
> > >
> > > What this is doing is replacing the data frames with just names
> > > pop1:pop12.  I just want to replace the column labels.
> > >
> > > Thanks for any suggestions.
> > >
> >
> > --
> > Sarah Goslee
> > http://www.functionaldiversity.org
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Mon Mar 30 17:31:07 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 30 Mar 2015 08:31:07 -0700
Subject: [R] changing column labels for data frames inside a list
In-Reply-To: <CAHuTOvo1PXvv5ANVTPQB8zEOwg3a8WFyn1kNY_eJD6cL0SJ+2Q@mail.gmail.com>
References: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
	<CAM_vju=pYBO9XwKMNEQxsGY9-0Y2TxUAZicwrW5=WC3pULY-MA@mail.gmail.com>
	<CAHuTOvo1PXvv5ANVTPQB8zEOwg3a8WFyn1kNY_eJD6cL0SJ+2Q@mail.gmail.com>
Message-ID: <CACk-te0F8wQ76OQuGrKNARHeTJmmDSTRrW+7KPAr=bcsTFkySg@mail.gmail.com>

Sarah's statement is correct.

So is yours. They are not contradictory, and I believe Sarah's point
was that the OP needed to learn the appropriate syntax.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Mar 30, 2015 at 7:56 AM, Sven E. Templer <sven.templer at gmail.com> wrote:
> On 30 March 2015 at 16:47, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>
>> colnames(e) <- paste0('pop',1:12)
>>
>> isn't a function and doesn't return anything.
>>
>
> But
> function(e){colnames(e) <- paste0('pop', 1:2)}
> is a function and it returns something (the last evaluated expression! -
> here the paste0 return):
>
>> mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop', 1:2)})
>> mylist2
> [[1]]
> [1] "pop1" "pop2"
>
> [[2]]
> [1] "pop1" "pop2"
>
> [[3]]
> [1] "pop1" "pop2"
>
>  from ?return:
>
> If the end of a function is reached without calling return, the value of
> the last evaluated expression is returned.
>
>>
>> > mylist <- list(
>> + data.frame(a = runif(10), b = runif(10)),
>> + data.frame(c = runif(10), d = runif(10)),
>> + data.frame(e = runif(10), f = runif(10)))
>> > mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop', 1:2);
>> e})
>> > colnames(mylist2[[1]])
>> [1] "pop1" "pop2"
>>
>> Sarah
>>
>> On Mon, Mar 30, 2015 at 9:54 AM, Vikram Chhatre
>> <crypticlineage at gmail.com> wrote:
>> >> summary(mygenfreqt)
>> >                   Length Class  Mode
>> > dat1.str 59220  -none- numeric
>> > dat2.str 59220  -none- numeric
>> > dat3.str 59220  -none- numeric
>> >
>> >> head(mylist[[1]])
>> >            1     2     3     4     5     6     7     8     9    10    11
>> >  12
>> > L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475 0.350
>> > 0.275
>> > L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525 0.650
>> > 0.725
>> >
>> > I want to change 1:12 to pop1:pop12
>> >
>> > mylist<- lapply(mylist, function(e) colnames(e) <- paste0('pop',1:12))
>> >
>> > What this is doing is replacing the data frames with just names
>> > pop1:pop12.  I just want to replace the column labels.
>> >
>> > Thanks for any suggestions.
>> >
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sven.templer at gmail.com  Mon Mar 30 17:39:12 2015
From: sven.templer at gmail.com (Sven E. Templer)
Date: Mon, 30 Mar 2015 17:39:12 +0200
Subject: [R] changing column labels for data frames inside a list
In-Reply-To: <CAJZnH0kKktxpNTpVsw6K+TRh2QJOWK-cckjqgq8i92_US8SQRw@mail.gmail.com>
References: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
	<CAM_vju=pYBO9XwKMNEQxsGY9-0Y2TxUAZicwrW5=WC3pULY-MA@mail.gmail.com>
	<CAHuTOvo1PXvv5ANVTPQB8zEOwg3a8WFyn1kNY_eJD6cL0SJ+2Q@mail.gmail.com>
	<CAJZnH0kKktxpNTpVsw6K+TRh2QJOWK-cckjqgq8i92_US8SQRw@mail.gmail.com>
Message-ID: <CAHuTOvp_OqDFiqfJ95rJ2Tp9tLOFMz8BZYky_6Z3bRGoKeT+kA@mail.gmail.com>

On 30 March 2015 at 17:19, Vikram Chhatre <crypticlineage at gmail.com> wrote:

> First of all, thank you for all the quick replies.  Here is a solution that
> worked for me.
>
> mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',1:12);
> return(e)})
>
> > head(mylist2[[1]])
>         pop1  pop2  pop3  pop4  pop5  pop6  pop7  pop8  pop9 pop10 pop11
> pop12
> L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475 0.350
> 0.275
> L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525 0.650
> 0.725
>
> While we are at this, I wanted to create a 13th column in each data frame
> for average of each row.
>

For new problems you should use a new topic.


>
> # Calculate average
> myavg <- lapply(mylist2, function(e) rowSums(mylist2)/12)
>
> # Attach to the main data frame
> mylist3 <- cbind(mylist2, myavg)
>

> This does not work the way I imagined it would.  The myavg vector is
> attached directly to mylist2, not to individual dataframes within.
>
>
But it works as expected (read ?cbind).
You try to cbind two lists (myavg and mylist2).
You want to cbind each list object (the data.frames) with each rowSums
output.
So, use cbind within your first lapply.

p.s. Is it a standard convention to always copy the reply to the last
> person who responded?
>

I guess it depends on which answer you refer to.


>
> On Mon, Mar 30, 2015 at 10:56 AM, Sven E. Templer <sven.templer at gmail.com>
> wrote:
>
> > On 30 March 2015 at 16:47, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> >
> > > colnames(e) <- paste0('pop',1:12)
> > >
> > > isn't a function and doesn't return anything.
> > >
> >
> > But
> > function(e){colnames(e) <- paste0('pop', 1:2)}
> > is a function and it returns something (the last evaluated expression! -
> > here the paste0 return):
> >
> > > mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',
> 1:2)})
> > > mylist2
> > [[1]]
> > [1] "pop1" "pop2"
> >
> > [[2]]
> > [1] "pop1" "pop2"
> >
> > [[3]]
> > [1] "pop1" "pop2"
> >
> >  from ?return:
> >
> > If the end of a function is reached without calling return, the value of
> > the last evaluated expression is returned.
> >
> > >
> > > > mylist <- list(
> > > + data.frame(a = runif(10), b = runif(10)),
> > > + data.frame(c = runif(10), d = runif(10)),
> > > + data.frame(e = runif(10), f = runif(10)))
> > > > mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',
> > 1:2);
> > > e})
> > > > colnames(mylist2[[1]])
> > > [1] "pop1" "pop2"
> > >
> > > Sarah
> > >
> > > On Mon, Mar 30, 2015 at 9:54 AM, Vikram Chhatre
> > > <crypticlineage at gmail.com> wrote:
> > > >> summary(mygenfreqt)
> > > >                   Length Class  Mode
> > > > dat1.str 59220  -none- numeric
> > > > dat2.str 59220  -none- numeric
> > > > dat3.str 59220  -none- numeric
> > > >
> > > >> head(mylist[[1]])
> > > >            1     2     3     4     5     6     7     8     9    10
> > 11
> > > >  12
> > > > L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475
> > 0.350
> > > > 0.275
> > > > L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525
> > 0.650
> > > > 0.725
> > > >
> > > > I want to change 1:12 to pop1:pop12
> > > >
> > > > mylist<- lapply(mylist, function(e) colnames(e) <-
> paste0('pop',1:12))
> > > >
> > > > What this is doing is replacing the data frames with just names
> > > > pop1:pop12.  I just want to replace the column labels.
> > > >
> > > > Thanks for any suggestions.
> > > >
> > >
> > > --
> > > Sarah Goslee
> > > http://www.functionaldiversity.org
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Guillaume.Tahon at UGent.be  Mon Mar 30 17:30:50 2015
From: Guillaume.Tahon at UGent.be (gktahon)
Date: Mon, 30 Mar 2015 08:30:50 -0700 (PDT)
Subject: [R] Vennerable plot
Message-ID: <1427729450665-4705278.post@n4.nabble.com>

Hi all,

I frequently use Vennerable to design diagrams of my data.
However, when I want to make a weighed diagram for a set of 4 samples, type
ChowRuskey, I get a nice view, but the font size of both numbers and sample
names is too small. Furthermore, the place of the sample names isn't always
that good. It places some names in the diagram (always on the same place).

Does anyone know how to
1) Change font size
2) Place labels somewhere else

This is an example of a plot I make:
library(Vennerable)
Vdemo3 <- Venn(SetNames = c("KP2","KP15","KP43", "KP53"), Weight = c('0000'
= 0, '1000' = 40, '0100' = 54, '0010' = 38, '0001' = 68,  '1100' = 0, '1010'
= 0, '0110' = 0, '0011' =1, '0101' = 0, '1001' = 1, '1110' = 0, '1101' = 0,
'1011' = 0, '0111' = 0, '1111' = 0))
plot(Vdemo3, doWeight = TRUE, type = "ChowRuskey")


Many thanks in advance,
Guillaume




--
View this message in context: http://r.789695.n4.nabble.com/Vennerable-plot-tp4705278.html
Sent from the R help mailing list archive at Nabble.com.


From sven.templer at gmail.com  Mon Mar 30 17:43:24 2015
From: sven.templer at gmail.com (Sven E. Templer)
Date: Mon, 30 Mar 2015 17:43:24 +0200
Subject: [R] changing column labels for data frames inside a list
In-Reply-To: <CACk-te0F8wQ76OQuGrKNARHeTJmmDSTRrW+7KPAr=bcsTFkySg@mail.gmail.com>
References: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
	<CAM_vju=pYBO9XwKMNEQxsGY9-0Y2TxUAZicwrW5=WC3pULY-MA@mail.gmail.com>
	<CAHuTOvo1PXvv5ANVTPQB8zEOwg3a8WFyn1kNY_eJD6cL0SJ+2Q@mail.gmail.com>
	<CACk-te0F8wQ76OQuGrKNARHeTJmmDSTRrW+7KPAr=bcsTFkySg@mail.gmail.com>
Message-ID: <CAHuTOvpCPubdV9Sin3ib3Fa8t1eoGFwgYsRH=Eh28xxmp2sR4w@mail.gmail.com>

On 30 March 2015 at 17:31, Bert Gunter <gunter.berton at gene.com> wrote:

> Sarah's statement is correct.
>
> So is yours. They are not contradictory, and I believe Sarah's point
> was that the OP needed to learn the appropriate syntax.
>
>
That's why I pointed to ?return.
Sarah's statement was not so clear (and might have been misleading) for me
regarding the R expertise of the OP.


> -- Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Mon, Mar 30, 2015 at 7:56 AM, Sven E. Templer <sven.templer at gmail.com>
> wrote:
> > On 30 March 2015 at 16:47, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> >
> >> colnames(e) <- paste0('pop',1:12)
> >>
> >> isn't a function and doesn't return anything.
> >>
> >
> > But
> > function(e){colnames(e) <- paste0('pop', 1:2)}
> > is a function and it returns something (the last evaluated expression! -
> > here the paste0 return):
> >
> >> mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',
> 1:2)})
> >> mylist2
> > [[1]]
> > [1] "pop1" "pop2"
> >
> > [[2]]
> > [1] "pop1" "pop2"
> >
> > [[3]]
> > [1] "pop1" "pop2"
> >
> >  from ?return:
> >
> > If the end of a function is reached without calling return, the value of
> > the last evaluated expression is returned.
> >
> >>
> >> > mylist <- list(
> >> + data.frame(a = runif(10), b = runif(10)),
> >> + data.frame(c = runif(10), d = runif(10)),
> >> + data.frame(e = runif(10), f = runif(10)))
> >> > mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',
> 1:2);
> >> e})
> >> > colnames(mylist2[[1]])
> >> [1] "pop1" "pop2"
> >>
> >> Sarah
> >>
> >> On Mon, Mar 30, 2015 at 9:54 AM, Vikram Chhatre
> >> <crypticlineage at gmail.com> wrote:
> >> >> summary(mygenfreqt)
> >> >                   Length Class  Mode
> >> > dat1.str 59220  -none- numeric
> >> > dat2.str 59220  -none- numeric
> >> > dat3.str 59220  -none- numeric
> >> >
> >> >> head(mylist[[1]])
> >> >            1     2     3     4     5     6     7     8     9    10
> 11
> >> >  12
> >> > L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475
> 0.350
> >> > 0.275
> >> > L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525
> 0.650
> >> > 0.725
> >> >
> >> > I want to change 1:12 to pop1:pop12
> >> >
> >> > mylist<- lapply(mylist, function(e) colnames(e) <- paste0('pop',1:12))
> >> >
> >> > What this is doing is replacing the data frames with just names
> >> > pop1:pop12.  I just want to replace the column labels.
> >> >
> >> > Thanks for any suggestions.
> >> >
> >>
> >> --
> >> Sarah Goslee
> >> http://www.functionaldiversity.org
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Mon Mar 30 17:47:30 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 30 Mar 2015 08:47:30 -0700
Subject: [R] Fwd:  changing column labels for data frames inside a list
In-Reply-To: <CACk-te1hzQJJX=o9v3JBZEXunDk6xi25URTYdMZwhN+UfXKXcw@mail.gmail.com>
References: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
	<CAM_vju=pYBO9XwKMNEQxsGY9-0Y2TxUAZicwrW5=WC3pULY-MA@mail.gmail.com>
	<CAHuTOvo1PXvv5ANVTPQB8zEOwg3a8WFyn1kNY_eJD6cL0SJ+2Q@mail.gmail.com>
	<CAJZnH0kKktxpNTpVsw6K+TRh2QJOWK-cckjqgq8i92_US8SQRw@mail.gmail.com>
	<CACk-te1hzQJJX=o9v3JBZEXunDk6xi25URTYdMZwhN+UfXKXcw@mail.gmail.com>
Message-ID: <CACk-te0Y__J8WQmw=gZ4GYbNg2J+YcApePGnZ369huO4WfZckQ@mail.gmail.com>

Sorry, I failed to cc the list.

-- Bert





---------- Forwarded message ----------
From: Bert Gunter <bgunter at gene.com>
Date: Mon, Mar 30, 2015 at 8:36 AM
Subject: Re: [R] changing column labels for data frames inside a list
To: Vikram Chhatre <crypticlineage at gmail.com>


You really really need to spend (more?) time with a good R tutorial
before posting further. Your questions are entirely due to your
ignorance of standard language syntax that you should learn if you
intend to use R. Of course, feel free to ask for help if there are
places in the tutorials where, after an honest effort, you remain
flummoxed.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Mar 30, 2015 at 8:19 AM, Vikram Chhatre
<crypticlineage at gmail.com> wrote:
> First of all, thank you for all the quick replies.  Here is a solution that
> worked for me.
>
> mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',1:12);
> return(e)})
>
>> head(mylist2[[1]])
>         pop1  pop2  pop3  pop4  pop5  pop6  pop7  pop8  pop9 pop10 pop11
> pop12
> L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475 0.350
> 0.275
> L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525 0.650
> 0.725
>
> While we are at this, I wanted to create a 13th column in each data frame
> for average of each row.
>
> # Calculate average
> myavg <- lapply(mylist2, function(e) rowSums(mylist2)/12)
>
> # Attach to the main data frame
> mylist3 <- cbind(mylist2, myavg)
>
> This does not work the way I imagined it would.  The myavg vector is
> attached directly to mylist2, not to individual dataframes within.
>
> p.s. Is it a standard convention to always copy the reply to the last
> person who responded?
>
> On Mon, Mar 30, 2015 at 10:56 AM, Sven E. Templer <sven.templer at gmail.com>
> wrote:
>
>> On 30 March 2015 at 16:47, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> > colnames(e) <- paste0('pop',1:12)
>> >
>> > isn't a function and doesn't return anything.
>> >
>>
>> But
>> function(e){colnames(e) <- paste0('pop', 1:2)}
>> is a function and it returns something (the last evaluated expression! -
>> here the paste0 return):
>>
>> > mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop', 1:2)})
>> > mylist2
>> [[1]]
>> [1] "pop1" "pop2"
>>
>> [[2]]
>> [1] "pop1" "pop2"
>>
>> [[3]]
>> [1] "pop1" "pop2"
>>
>>  from ?return:
>>
>> If the end of a function is reached without calling return, the value of
>> the last evaluated expression is returned.
>>
>> >
>> > > mylist <- list(
>> > + data.frame(a = runif(10), b = runif(10)),
>> > + data.frame(c = runif(10), d = runif(10)),
>> > + data.frame(e = runif(10), f = runif(10)))
>> > > mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',
>> 1:2);
>> > e})
>> > > colnames(mylist2[[1]])
>> > [1] "pop1" "pop2"
>> >
>> > Sarah
>> >
>> > On Mon, Mar 30, 2015 at 9:54 AM, Vikram Chhatre
>> > <crypticlineage at gmail.com> wrote:
>> > >> summary(mygenfreqt)
>> > >                   Length Class  Mode
>> > > dat1.str 59220  -none- numeric
>> > > dat2.str 59220  -none- numeric
>> > > dat3.str 59220  -none- numeric
>> > >
>> > >> head(mylist[[1]])
>> > >            1     2     3     4     5     6     7     8     9    10
>> 11
>> > >  12
>> > > L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475
>> 0.350
>> > > 0.275
>> > > L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525
>> 0.650
>> > > 0.725
>> > >
>> > > I want to change 1:12 to pop1:pop12
>> > >
>> > > mylist<- lapply(mylist, function(e) colnames(e) <- paste0('pop',1:12))
>> > >
>> > > What this is doing is replacing the data frames with just names
>> > > pop1:pop12.  I just want to replace the column labels.
>> > >
>> > > Thanks for any suggestions.
>> > >
>> >
>> > --
>> > Sarah Goslee
>> > http://www.functionaldiversity.org
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Mon Mar 30 17:50:08 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 30 Mar 2015 11:50:08 -0400
Subject: [R] changing column labels for data frames inside a list
In-Reply-To: <CAHuTOvpCPubdV9Sin3ib3Fa8t1eoGFwgYsRH=Eh28xxmp2sR4w@mail.gmail.com>
References: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
	<CAM_vju=pYBO9XwKMNEQxsGY9-0Y2TxUAZicwrW5=WC3pULY-MA@mail.gmail.com>
	<CAHuTOvo1PXvv5ANVTPQB8zEOwg3a8WFyn1kNY_eJD6cL0SJ+2Q@mail.gmail.com>
	<CACk-te0F8wQ76OQuGrKNARHeTJmmDSTRrW+7KPAr=bcsTFkySg@mail.gmail.com>
	<CAHuTOvpCPubdV9Sin3ib3Fa8t1eoGFwgYsRH=Eh28xxmp2sR4w@mail.gmail.com>
Message-ID: <CAM_vjuk6dYiz1ZLdt2mgQSDMZsusxfA__H+ftQ4pyAVnqUSBUg@mail.gmail.com>

On Mon, Mar 30, 2015 at 11:43 AM, Sven E. Templer
<sven.templer at gmail.com> wrote:
>
>
> On 30 March 2015 at 17:31, Bert Gunter <gunter.berton at gene.com> wrote:
>>
>> Sarah's statement is correct.
>>
>> So is yours. They are not contradictory, and I believe Sarah's point
>> was that the OP needed to learn the appropriate syntax.
>>
>
> That's why I pointed to ?return.
> Sarah's statement was not so clear (and might have been misleading) for me
> regarding the R expertise of the OP.

You're right: I totally wasn't clear. I got involved making a working
reproducible example and didn't explain what I was doing. And you are
totally correct, the last expression will be returned. Mea culpa.

Sarah


>>
>> -- Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Mon, Mar 30, 2015 at 7:56 AM, Sven E. Templer <sven.templer at gmail.com>
>> wrote:
>> > On 30 March 2015 at 16:47, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> >
>> >> colnames(e) <- paste0('pop',1:12)
>> >>
>> >> isn't a function and doesn't return anything.
>> >>
>> >
>> > But
>> > function(e){colnames(e) <- paste0('pop', 1:2)}
>> > is a function and it returns something (the last evaluated expression! -
>> > here the paste0 return):
>> >
>> >> mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',
>> >> 1:2)})
>> >> mylist2
>> > [[1]]
>> > [1] "pop1" "pop2"
>> >
>> > [[2]]
>> > [1] "pop1" "pop2"
>> >
>> > [[3]]
>> > [1] "pop1" "pop2"
>> >
>> >  from ?return:
>> >
>> > If the end of a function is reached without calling return, the value of
>> > the last evaluated expression is returned.
>> >
>> >>
>> >> > mylist <- list(
>> >> + data.frame(a = runif(10), b = runif(10)),
>> >> + data.frame(c = runif(10), d = runif(10)),
>> >> + data.frame(e = runif(10), f = runif(10)))
>> >> > mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',
>> >> > 1:2);
>> >> e})
>> >> > colnames(mylist2[[1]])
>> >> [1] "pop1" "pop2"
>> >>
>> >> Sarah
>> >>
>> >> On Mon, Mar 30, 2015 at 9:54 AM, Vikram Chhatre
>> >> <crypticlineage at gmail.com> wrote:
>> >> >> summary(mygenfreqt)
>> >> >                   Length Class  Mode
>> >> > dat1.str 59220  -none- numeric
>> >> > dat2.str 59220  -none- numeric
>> >> > dat3.str 59220  -none- numeric
>> >> >
>> >> >> head(mylist[[1]])
>> >> >            1     2     3     4     5     6     7     8     9    10
>> >> > 11
>> >> >  12
>> >> > L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475
>> >> > 0.350
>> >> > 0.275
>> >> > L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525
>> >> > 0.650
>> >> > 0.725
>> >> >
>> >> > I want to change 1:12 to pop1:pop12
>> >> >
>> >> > mylist<- lapply(mylist, function(e) colnames(e) <-
>> >> > paste0('pop',1:12))
>> >> >
>> >> > What this is doing is replacing the data frames with just names
>> >> > pop1:pop12.  I just want to replace the column labels.
>> >> >
>> >> > Thanks for any suggestions.
>> >> >
>> >>
>> >> --
>> >> Sarah Goslee
>> >> http://www.functionaldiversity.org


From sven.templer at gmail.com  Mon Mar 30 18:12:41 2015
From: sven.templer at gmail.com (Sven E. Templer)
Date: Mon, 30 Mar 2015 18:12:41 +0200
Subject: [R] changing column labels for data frames inside a list
In-Reply-To: <CAM_vjuk6dYiz1ZLdt2mgQSDMZsusxfA__H+ftQ4pyAVnqUSBUg@mail.gmail.com>
References: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
	<CAM_vju=pYBO9XwKMNEQxsGY9-0Y2TxUAZicwrW5=WC3pULY-MA@mail.gmail.com>
	<CAHuTOvo1PXvv5ANVTPQB8zEOwg3a8WFyn1kNY_eJD6cL0SJ+2Q@mail.gmail.com>
	<CACk-te0F8wQ76OQuGrKNARHeTJmmDSTRrW+7KPAr=bcsTFkySg@mail.gmail.com>
	<CAHuTOvpCPubdV9Sin3ib3Fa8t1eoGFwgYsRH=Eh28xxmp2sR4w@mail.gmail.com>
	<CAM_vjuk6dYiz1ZLdt2mgQSDMZsusxfA__H+ftQ4pyAVnqUSBUg@mail.gmail.com>
Message-ID: <CAHuTOvqv9273OGDJV=qZT2CaVoDjF4cf63nveyc1YkfBO4EOag@mail.gmail.com>

On 30 March 2015 at 17:50, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> On Mon, Mar 30, 2015 at 11:43 AM, Sven E. Templer
> <sven.templer at gmail.com> wrote:
> >
> >
> > On 30 March 2015 at 17:31, Bert Gunter <gunter.berton at gene.com> wrote:
> >>
> >> Sarah's statement is correct.
> >>
> >> So is yours. They are not contradictory, and I believe Sarah's point
> >> was that the OP needed to learn the appropriate syntax.
> >>
> >
> > That's why I pointed to ?return.
> > Sarah's statement was not so clear (and might have been misleading) for
> me
> > regarding the R expertise of the OP.
>
> You're right: I totally wasn't clear. I got involved making a working
> reproducible example and didn't explain what I was doing. And you are
> totally correct, the last expression will be returned. Mea culpa.
>
>
No one to blame but the missing reproducible example, I agree!

Sven


> Sarah
>
>
> >>
> >> -- Bert
> >>
> >> Bert Gunter
> >> Genentech Nonclinical Biostatistics
> >> (650) 467-7374
> >>
> >> "Data is not information. Information is not knowledge. And knowledge
> >> is certainly not wisdom."
> >> Clifford Stoll
> >>
> >>
> >>
> >>
> >> On Mon, Mar 30, 2015 at 7:56 AM, Sven E. Templer <
> sven.templer at gmail.com>
> >> wrote:
> >> > On 30 March 2015 at 16:47, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
> >> >
> >> >> colnames(e) <- paste0('pop',1:12)
> >> >>
> >> >> isn't a function and doesn't return anything.
> >> >>
> >> >
> >> > But
> >> > function(e){colnames(e) <- paste0('pop', 1:2)}
> >> > is a function and it returns something (the last evaluated
> expression! -
> >> > here the paste0 return):
> >> >
> >> >> mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',
> >> >> 1:2)})
> >> >> mylist2
> >> > [[1]]
> >> > [1] "pop1" "pop2"
> >> >
> >> > [[2]]
> >> > [1] "pop1" "pop2"
> >> >
> >> > [[3]]
> >> > [1] "pop1" "pop2"
> >> >
> >> >  from ?return:
> >> >
> >> > If the end of a function is reached without calling return, the value
> of
> >> > the last evaluated expression is returned.
> >> >
> >> >>
> >> >> > mylist <- list(
> >> >> + data.frame(a = runif(10), b = runif(10)),
> >> >> + data.frame(c = runif(10), d = runif(10)),
> >> >> + data.frame(e = runif(10), f = runif(10)))
> >> >> > mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',
> >> >> > 1:2);
> >> >> e})
> >> >> > colnames(mylist2[[1]])
> >> >> [1] "pop1" "pop2"
> >> >>
> >> >> Sarah
> >> >>
> >> >> On Mon, Mar 30, 2015 at 9:54 AM, Vikram Chhatre
> >> >> <crypticlineage at gmail.com> wrote:
> >> >> >> summary(mygenfreqt)
> >> >> >                   Length Class  Mode
> >> >> > dat1.str 59220  -none- numeric
> >> >> > dat2.str 59220  -none- numeric
> >> >> > dat3.str 59220  -none- numeric
> >> >> >
> >> >> >> head(mylist[[1]])
> >> >> >            1     2     3     4     5     6     7     8     9    10
> >> >> > 11
> >> >> >  12
> >> >> > L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475
> >> >> > 0.350
> >> >> > 0.275
> >> >> > L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525
> >> >> > 0.650
> >> >> > 0.725
> >> >> >
> >> >> > I want to change 1:12 to pop1:pop12
> >> >> >
> >> >> > mylist<- lapply(mylist, function(e) colnames(e) <-
> >> >> > paste0('pop',1:12))
> >> >> >
> >> >> > What this is doing is replacing the data frames with just names
> >> >> > pop1:pop12.  I just want to replace the column labels.
> >> >> >
> >> >> > Thanks for any suggestions.
> >> >> >
> >> >>
> >> >> --
> >> >> Sarah Goslee
> >> >> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]


From rmh at temple.edu  Mon Mar 30 18:29:16 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 30 Mar 2015 12:29:16 -0400
Subject: [R] A problem someone should know about
In-Reply-To: <FB2B8956-4C4E-4CC0-8990-70FB5B72EFDD@mac.com>
References: <300ADC7E-A143-4193-8A88-171CA053B721@mensa.org.au>
	<5518AE15.9030308@auckland.ac.nz>
	<CAGx1TMBbdDQOf_eFCo0f-AXgwQk0r9VmpocKVqOia8dXkfSxDg@mail.gmail.com>
	<FB2B8956-4C4E-4CC0-8990-70FB5B72EFDD@mac.com>
Message-ID: <CAGx1TMABSi4DdzANc5vooyMK+ZOUVEq5_hJMY99yKQarppNNFA@mail.gmail.com>

My error is Mac because I don't use R-Studio.  The phrasing of Ian's
error is similar to the error I reported
and still occasionally get.  As I said, it is random and therefore not
reproducible.

This is consistent with the comments on the rstudio link you pointed us to.

Rich

On Mon, Mar 30, 2015 at 9:00 AM, Peter Claussen <dakotajudo at mac.com> wrote:
> Rich,
>
> You?ve probably reported the error to the wrong group.
>
> A quick search suggests this is not an R issue, but an RStudio issue. The error message is unique enough. Google returns this as the first link:
>
> https://support.rstudio.com/hc/communities/public/questions/200807456-Error-when-plotting-graphics-on-Mac-OSX-Mavericks
>
> Peter
>
>> On Mar 29, 2015, at 9:21 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>>
>> This looks like a specific Macintosh error that appears at random intervals.
>> I get it at random, and unreproducible times.  I reported it (or
>> perhaps a close relative)
>> to the r-sig-mac list in September 2014.
>>
>> Rich
>>
>>
>> On Sun, Mar 29, 2015 at 9:59 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>> On 30/03/15 11:52, Ian Lester wrote:
>>>>
>>>> I?m a novice and this message looks like it shouldn?t be ignored. Someone
>>>> who knows what they?re doing should probably take a look.
>>>> Thanks
>>>> Ian Lester
>>>>
>>>>> logfat.lm<-(lm(body.fat~log(BMI)))
>>>>> plot(logfat)
>>>>
>>>> Error in plot(logfat) : object 'logfat' not found
>>>>>
>>>>> plot(logfat.lm)
>>>>
>>>> Hit <Return> to see next plot:
>>>> Hit <Return> to see next plot:
>>>> Hit <Return> to see next plot:
>>>> Mar 29 18:10:18 iansimac.gateway rsession[69550] <Error>: Error: this
>>>> application, or a library it uses, has passed an invalid numeric
>>>> value (NaN, or not-a-number) to CoreGraphics API. This is a serious
>>>> error and contributes to an overall degradation of system stability
>>>> and reliability. This notice is a courtesy: please fix this problem.
>>>> It will become a fatal error in an upcoming update.
>>>
>>>
>>> Please make your examples *reproducible* as the posting guide requests.
>>>
>>> I *presume* that your data are the "fat" data from the "UsingR" package,
>>> which you did not mention.
>>>
>>> After installing and loading "UsingR" I did
>>>
>>>> logfat.lm <- lm(body.fat~log(BMI),data=fat)
>>>> plot(logfat.lm)
>>>
>>> and got a sequence of plots, with no error thrown. It would appear that
>>> whatever is causing the error that you saw is peculiar to your system.
>>>
>>> cheers,
>>>
>>> Rolf Turner
>>>
>>> --
>>> Rolf Turner
>>> Technical Editor ANZJS
>>> Department of Statistics
>>> University of Auckland
>>> Phone: +64-9-373-7599 ext. 88276
>>> Home phone: +64-9-480-4619
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From macqueen1 at llnl.gov  Mon Mar 30 18:54:03 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 30 Mar 2015 16:54:03 +0000
Subject: [R] changing column labels for data frames inside a list
In-Reply-To: <CAJZnH0kKktxpNTpVsw6K+TRh2QJOWK-cckjqgq8i92_US8SQRw@mail.gmail.com>
References: <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ@mail.gmail.com>
	<CAM_vju=pYBO9XwKMNEQxsGY9-0Y2TxUAZicwrW5=WC3pULY-MA@mail.gmail.com>
	<CAHuTOvo1PXvv5ANVTPQB8zEOwg3a8WFyn1kNY_eJD6cL0SJ+2Q@mail.gmail.com>
	<CAJZnH0kKktxpNTpVsw6K+TRh2QJOWK-cckjqgq8i92_US8SQRw@mail.gmail.com>
Message-ID: <D13ECC9F.124096%macqueen1@llnl.gov>

Regarding the averages, someone else mentioned that it's preferred to
start a new question in a new post to the list.

That said, you are confusing "inside" the list with "outside" the list.
Try this:

(the following R expression is supposed to be all on one line, but my
email software may cause a line break)

myavgs <- lapply(mylist2, function(e) {cbind( e, avgs=rowSums(e)/12)} )

With no example data I can't test it. The brackets {} are not, strictly
speaking, necessary, but I think they help clarify what is inside the
function with what is outside it.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/30/15, 8:19 AM, "Vikram Chhatre" <crypticlineage at gmail.com> wrote:

>First of all, thank you for all the quick replies.  Here is a solution
>that
>worked for me.
>
>mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',1:12);
>return(e)})
>
>> head(mylist2[[1]])
>        pop1  pop2  pop3  pop4  pop5  pop6  pop7  pop8  pop9 pop10 pop11
>pop12
>L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475 0.350
>0.275
>L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525 0.650
>0.725
>
>While we are at this, I wanted to create a 13th column in each data frame
>for average of each row.
>
># Calculate average
>myavg <- lapply(mylist2, function(e) rowSums(mylist2)/12)
>
># Attach to the main data frame
>mylist3 <- cbind(mylist2, myavg)
>
>This does not work the way I imagined it would.  The myavg vector is
>attached directly to mylist2, not to individual dataframes within.
>
>p.s. Is it a standard convention to always copy the reply to the last
>person who responded?
>
>On Mon, Mar 30, 2015 at 10:56 AM, Sven E. Templer <sven.templer at gmail.com>
>wrote:
>
>> On 30 March 2015 at 16:47, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> > colnames(e) <- paste0('pop',1:12)
>> >
>> > isn't a function and doesn't return anything.
>> >
>>
>> But
>> function(e){colnames(e) <- paste0('pop', 1:2)}
>> is a function and it returns something (the last evaluated expression! -
>> here the paste0 return):
>>
>> > mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',
>>1:2)})
>> > mylist2
>> [[1]]
>> [1] "pop1" "pop2"
>>
>> [[2]]
>> [1] "pop1" "pop2"
>>
>> [[3]]
>> [1] "pop1" "pop2"
>>
>>  from ?return:
>>
>> If the end of a function is reached without calling return, the value of
>> the last evaluated expression is returned.
>>
>> >
>> > > mylist <- list(
>> > + data.frame(a = runif(10), b = runif(10)),
>> > + data.frame(c = runif(10), d = runif(10)),
>> > + data.frame(e = runif(10), f = runif(10)))
>> > > mylist2 <- lapply(mylist, function(e){colnames(e) <- paste0('pop',
>> 1:2);
>> > e})
>> > > colnames(mylist2[[1]])
>> > [1] "pop1" "pop2"
>> >
>> > Sarah
>> >
>> > On Mon, Mar 30, 2015 at 9:54 AM, Vikram Chhatre
>> > <crypticlineage at gmail.com> wrote:
>> > >> summary(mygenfreqt)
>> > >                   Length Class  Mode
>> > > dat1.str 59220  -none- numeric
>> > > dat2.str 59220  -none- numeric
>> > > dat3.str 59220  -none- numeric
>> > >
>> > >> head(mylist[[1]])
>> > >            1     2     3     4     5     6     7     8     9    10
>> 11
>> > >  12
>> > > L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475
>> 0.350
>> > > 0.275
>> > > L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525
>> 0.650
>> > > 0.725
>> > >
>> > > I want to change 1:12 to pop1:pop12
>> > >
>> > > mylist<- lapply(mylist, function(e) colnames(e) <-
>>paste0('pop',1:12))
>> > >
>> > > What this is doing is replacing the data frames with just names
>> > > pop1:pop12.  I just want to replace the column labels.
>> > >
>> > > Thanks for any suggestions.
>> > >
>> >
>> > --
>> > Sarah Goslee
>> > http://www.functionaldiversity.org
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Ingrid.Charvet at rms.com  Mon Mar 30 19:46:38 2015
From: Ingrid.Charvet at rms.com (Ingrid Charvet)
Date: Mon, 30 Mar 2015 17:46:38 +0000
Subject: [R] multinomial probabilities with mlogit
Message-ID: <CO1PR06MB828DE0DFAB02584F57B9F7597F50@CO1PR06MB828.namprd06.prod.outlook.com>

Hello,

When fitting a logit multinomial model with "mlogit" I can retrieve the response probabilities using
fit$fitted.values (for a given object "fit")

However, I am trying to calculate those response probabilities myself using the maximum likelihood estimates (i.e. fit$coefficients) given by mlogit.

I have used the model given in Agresti (2002):

Prob_j(x) = exp( linearpredictor_j(x) ) / (1 + sum (linearpredictor(x)))

Which is for a category j the exponential of the linear predictor for category j divided by 1 + the sum of all logits across categories, aside from the reference category.

But I cannot get my fitted probabilities calculated using this equation to match the output of mlogit fit$fitted values.

Can anyone tell me how those fitted values are calculated? Or point me to the corresponding documentation (which I cannot seem to find by googling!)

Many thanks
Ingrid

	[[alternative HTML version deleted]]


From kw1958 at gmail.com  Mon Mar 30 19:50:52 2015
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Mon, 30 Mar 2015 13:50:52 -0400
Subject: [R] Debug package options
Message-ID: <FD1CBB1B-9061-4754-A6D4-2515EC511C63@gmail.com>

Folks,

I would like change some of the options for the Tk window that pops up when using the debug package.

I know how to change the options: e.g. options(debug.font = "Courier 12 italic?).

Is there a way to ?preset? these in my environment so when debug starts up I have all the options set up the way I want them?

Do I do this in a .First file? Does the .First file have to load the debug package every time I start up R?

No need to do my work for me. Just point me to the right doc.

Best,
KW


From murdoch.duncan at gmail.com  Mon Mar 30 20:05:18 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 30 Mar 2015 14:05:18 -0400
Subject: [R] Debug package options
In-Reply-To: <FD1CBB1B-9061-4754-A6D4-2515EC511C63@gmail.com>
References: <FD1CBB1B-9061-4754-A6D4-2515EC511C63@gmail.com>
Message-ID: <5519905E.3030604@gmail.com>

On 30/03/2015 1:50 PM, Keith S Weintraub wrote:
> Folks,
> 
> I would like change some of the options for the Tk window that pops up when using the debug package.
> 
> I know how to change the options: e.g. options(debug.font = "Courier 12 italic?).
> 
> Is there a way to ?preset? these in my environment so when debug starts up I have all the options set up the way I want them?
> 
> Do I do this in a .First file? Does the .First file have to load the debug package every time I start up R?
> 
> No need to do my work for me. Just point me to the right doc.

See the ?Startup help topic.  You probably want to use one of the
profile files rather than .First, because .First needs to be in a
workspace, and you shouldn't be loading a workspace every time.

Duncan Murdoch


From r.turner at auckland.ac.nz  Mon Mar 30 21:07:05 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 31 Mar 2015 08:07:05 +1300
Subject: [R] multinomial probabilities with mlogit
In-Reply-To: <CO1PR06MB828DE0DFAB02584F57B9F7597F50@CO1PR06MB828.namprd06.prod.outlook.com>
References: <CO1PR06MB828DE0DFAB02584F57B9F7597F50@CO1PR06MB828.namprd06.prod.outlook.com>
Message-ID: <55199ED9.4000208@auckland.ac.nz>



Reproducible example???

cheers,

Rolf Turner

P.S.  Where does "mlogit" come from?  Note fortune(182).

R. T.

On 31/03/15 06:46, Ingrid Charvet wrote:
> Hello,
>
> When fitting a logit multinomial model with "mlogit" I can retrieve
> the response probabilities using fit$fitted.values (for a given
> object "fit")
>
> However, I am trying to calculate those response probabilities myself
> using the maximum likelihood estimates (i.e. fit$coefficients) given
> by mlogit.
>
> I have used the model given in Agresti (2002):
>
> Prob_j(x) = exp( linearpredictor_j(x) ) / (1 + sum
> (linearpredictor(x)))
>
> Which is for a category j the exponential of the linear predictor for
> category j divided by 1 + the sum of all logits across categories,
> aside from the reference category.
>
> But I cannot get my fitted probabilities calculated using this
> equation to match the output of mlogit fit$fitted values.
>
> Can anyone tell me how those fitted values are calculated? Or point
> me to the corresponding documentation (which I cannot seem to find by
> googling!)

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From amc5981 at gmail.com  Tue Mar 31 01:07:05 2015
From: amc5981 at gmail.com (Alexandra Catena)
Date: Mon, 30 Mar 2015 16:07:05 -0700
Subject: [R] Plotting using tapply function output
Message-ID: <CAHpsUFY9jtcTNH6=7_QMjqjzwuUz6063_0tYvT3CfU3kKmBUsg@mail.gmail.com>

Hello,

I am trying to plot the hourly standard deviation of wind speeds from
13 different measured locations over many years. I imported the data
using readLines and into a dataframe called finalData. Using tapply, I
determined the standard deviation of the windspeed (ws) for each hour
(hour) from every location (stn) using this command line:

statHour = tapply(finalData$ws,list(finalData$stn,finalData$hour),sd)

I want to plot the standard deviation for each hour of the day, with
hours as the x-axis and the standard deviation for the y-axis, and
each station as a different color.  I've managed to get a boxplot of
this, but ideally, I'd like a scatter plot to determine the variations
between each instrument throughout the day.  The boxplot command is
this:

boxplot(statHour, names=colnames(statHour),xlab='Hour of the
Day',ylab='Standard Deviation of Wind Speed')

I also tried to make a dataframe of the tapply output but it ends up
using the hours as the column names instead of putting it into the
dataframe.  Please help!!

I have R version 3.1.1

Thanks a lot,
Alexandra


From desta_yo at yahoo.com  Tue Mar 31 01:09:12 2015
From: desta_yo at yahoo.com (Desta Yoseph)
Date: Mon, 30 Mar 2015 23:09:12 +0000 (UTC)
Subject: [R] Mann-Kendall test for many independent columns data set at a
	time
Message-ID: <151362667.1979300.1427756952311.JavaMail.yahoo@mail.yahoo.com>

I am analyzing trend test using Mann-kendall monotonic trendtest for 10,368 independent grid cell, each grid has 34 years dataset. ?I supposed to find Kendall ?tau? for each gridcell (each grid has 34 years data). The data is arranged in column wise (Iattached? part of the grid dataset? as a sample).

To find Kendall tau, I wrote R script as:


desta<-read.csv("rainfall.csv",header=T, sep=",")

require(Kendall) 

MK<-function(y) {

??????? ?nc<-ncol(y)

?????? MannKendalltau<-numeric(nc)

??????? for(i in 2:nc){

? ? ? ? ? ?MannKendalltau[i]<-MannKendall(y[,i])

?????????? }

????? ??????MannKendalltau

??? }

??? MK(desta)


The result displayed both ?tau??and ?2-sided pvalue?. ?But, I wantonly ?tau? value that is printed in organized way. Anyone can tell me how can Iget orderly printed ?tau? value ?for allgrid cells at a time. ???


Thank you for your help in advance,Desta WodeboTU-DresdenGermany?

From HDoran at air.org  Tue Mar 31 03:15:09 2015
From: HDoran at air.org (Doran, Harold)
Date: Tue, 31 Mar 2015 01:15:09 +0000
Subject: [R] Help with POSIX
Message-ID: <D13F6D5B.25599%hdoran@air.org>

I?m struggling a bit with learning about POSIX objects to do some basic things with objects of this class. Suppose I have the following simple example

times <- c("03:20", "29:56", "03:30", "21:03", "56:26")

aa <- strptime(times, "%M:%S?)

I can do means, and some other basic things, but I cannot correlate the objects with some other variable

cor(aa, rnorm(5))

Also, for purposes of a user-interface I have built with shiny, I need for the time to be viewed as simply as minutes:seconds, such as this

format(aa, '%M:%S?)

But of course after doing this I lose the ability to work with this object as a time variable.

Thank you
Harold

	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Tue Mar 31 03:48:45 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 30 Mar 2015 21:48:45 -0400
Subject: [R] Trying to understand a function passed to lapply
Message-ID: <5519C4BD020000CB00127E0C@smtp.medicine.umaryland.edu>

Colleagues,
I am trying to understand the syntax of a function passed to apply. The code below generates a matrix, and passes the matrix to a function that is called by apply. I don't understand the syntax of the function. In some way the function computes data[,"delta"]/data[,"SE"]. I can't understand how the body of the function, x[c1]/x[c2] refers to the columns "data" and "SE" of the matrix data. Can someone help me understand the syntax? 
Thank you,
John

myfun <- function(x, c1, c2) x[c1]/x[c2]
apply(data,1,myfun,c1="delta",c2="SE")

CODE:

data<-matrix(data=c(-0.70 ,-0.90, -0.50, 20, 20,
                    -0.30 ,-0.43, -0.17, 43, 43,
                    -0.50 ,-1.05,  0.05, 16, 18,
                     0.00 ,-0.21,  0.21, 22, 23,
                    -1.30 ,-1.48, -1.12, 28, 32,
                    -0.90 ,-1.01, -0.79, 18, 15,
                    -0.20 ,-0.47,  0.07, 39, 39,
                    -0.30 ,-0.83,  0.23, 27, 27),
                     nrow=8,ncol=5,byrow=TRUE)
dimnames(data) <- list(NULL,c("delta","low","high","n1","n2"))
data
CI <- data[,"high"]-data[,"low"]
data <- cbind(data,CI)
data
data <- cbind(data,SE=data[,"CI"]/(4*1.96))
data
data <- cbind(data,SD=data[,"SE"]*sqrt(data[,"n1"]+data[,"n2"]))
data
myfun <- function(x, c1, c2) x[c1]/x[c2]
apply(data,1,myfun,c1="delta",c2="SE")

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From drjimlemon at gmail.com  Tue Mar 31 04:10:00 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 31 Mar 2015 13:10:00 +1100
Subject: [R] Plotting using tapply function output
In-Reply-To: <CAHpsUFY9jtcTNH6=7_QMjqjzwuUz6063_0tYvT3CfU3kKmBUsg@mail.gmail.com>
References: <CAHpsUFY9jtcTNH6=7_QMjqjzwuUz6063_0tYvT3CfU3kKmBUsg@mail.gmail.com>
Message-ID: <CA+8X3fWRi-rNO7N47CnPhiw1Wb65m-UuLzw_S+-TcqkLQQ9sXg@mail.gmail.com>

Hi Alexandra,
This produces a rather messy plot, but it might get you started:

finalData<-data.frame(ws=sample(0:100,1300,TRUE),
 stn=rep(1:13,each=100),hour=rep(1:24,length.out=1300))
statHour = tapply(finalData$ws,list(finalData$stn,finalData$hour),sd)
# open a wide device
x11(width=13)
# leave room for an external legend
par(mar=c(5,4,4,6))
matplot(1:24,t(statHour),type="b",
 main="Wind speed standard deviation by hour of day",
 xlab="Hour",ylab="Wind speed standard deviation",lty=1)
legend(25.2,40,legend=paste("Stn",1:13,sep=""),pch=c(0:9,"a","b","c"),
 col=1:13,xpd=TRUE)

Jim


On Tue, Mar 31, 2015 at 10:07 AM, Alexandra Catena <amc5981 at gmail.com>
wrote:

> Hello,
>
> I am trying to plot the hourly standard deviation of wind speeds from
> 13 different measured locations over many years. I imported the data
> using readLines and into a dataframe called finalData. Using tapply, I
> determined the standard deviation of the windspeed (ws) for each hour
> (hour) from every location (stn) using this command line:
>
> statHour = tapply(finalData$ws,list(finalData$stn,finalData$hour),sd)
>
> I want to plot the standard deviation for each hour of the day, with
> hours as the x-axis and the standard deviation for the y-axis, and
> each station as a different color.  I've managed to get a boxplot of
> this, but ideally, I'd like a scatter plot to determine the variations
> between each instrument throughout the day.  The boxplot command is
> this:
>
> boxplot(statHour, names=colnames(statHour),xlab='Hour of the
> Day',ylab='Standard Deviation of Wind Speed')
>
> I also tried to make a dataframe of the tapply output but it ends up
> using the hours as the column names instead of putting it into the
> dataframe.  Please help!!
>
> I have R version 3.1.1
>
> Thanks a lot,
> Alexandra
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Mar 31 04:11:53 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 30 Mar 2015 19:11:53 -0700
Subject: [R] Help with POSIX
In-Reply-To: <D13F6D5B.25599%hdoran@air.org>
References: <D13F6D5B.25599%hdoran@air.org>
Message-ID: <07A432C6-C6C1-43BA-AFDB-E836A9B79188@dcn.davis.CA.us>

You seem to be trying to make POSIXt into something it isn't, as though this was Excel. 

First, POSIXt is not the same as numeric. You can convert between them, but they are not the same. If you want to do numeric operations, convert.

Second, POSIXt is not time of day only. When you provide only minutes and seconds to strptime, it includes the current date in the result as well. Thus, values converted today will be different than values converted tomorrow. You should probably pick a specific date to include in every "time" value, and paste it with the actual data before converting.

Finally, formatting of all non-character data is always associated with conversion to character. You either need to reconvert on demand or keep a copy of the data around unconverted for use when you need it.

Oh, and your use of HTML is leading to corruption of your code. Learn to use your email program so you don't send us garbage to guess at.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 30, 2015 6:15:09 PM PDT, "Doran, Harold" <HDoran at air.org> wrote:
>I?m struggling a bit with learning about POSIX objects to do some basic
>things with objects of this class. Suppose I have the following simple
>example
>
>times <- c("03:20", "29:56", "03:30", "21:03", "56:26")
>
>aa <- strptime(times, "%M:%S?)
>
>I can do means, and some other basic things, but I cannot correlate the
>objects with some other variable
>
>cor(aa, rnorm(5))
>
>Also, for purposes of a user-interface I have built with shiny, I need
>for the time to be viewed as simply as minutes:seconds, such as this
>
>format(aa, '%M:%S?)
>
>But of course after doing this I lose the ability to work with this
>object as a time variable.
>
>Thank you
>Harold
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r at catwhisker.org  Tue Mar 31 04:13:39 2015
From: r at catwhisker.org (David Wolfskill)
Date: Mon, 30 Mar 2015 19:13:39 -0700
Subject: [R] Help with POSIX
In-Reply-To: <D13F6D5B.25599%hdoran@air.org>
References: <D13F6D5B.25599%hdoran@air.org>
Message-ID: <20150331021339.GP1250@albert.catwhisker.org>

On Tue, Mar 31, 2015 at 01:15:09AM +0000, Doran, Harold wrote:
> I?m struggling a bit with learning about POSIX objects to do some basic things with objects of this class. Suppose I have the following simple example
> 
> times <- c("03:20", "29:56", "03:30", "21:03", "56:26")
> 
> aa <- strptime(times, "%M:%S?)
> 
> I can do means, and some other basic things, but I cannot correlate the objects with some other variable
> 
> cor(aa, rnorm(5))

I suspect you will find that manipulating times as numeric quantities
(so you can do arithmetic on them) will be easier if you convert to
seconds (possibly using a different vector, leaving "times" as it was).

> Also, for purposes of a user-interface I have built with shiny, I need for the time to be viewed as simply as minutes:seconds, such as this
> 
> format(aa, '%M:%S?)
> 
> But of course after doing this I lose the ability to work with this object as a time variable.

So do that with a copy -- the output of format() need not destroy its
input.

>...

Peace,
david
-- 
David H. Wolfskill				r at catwhisker.org
Those who murder in the name of God or prophet are blasphemous cowards.

See http://www.catwhisker.org/~david/publickey.gpg for my public key.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 949 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150330/3851a8ba/attachment.bin>

From wdunlap at tibco.com  Tue Mar 31 04:52:19 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 30 Mar 2015 19:52:19 -0700
Subject: [R] Trying to understand a function passed to lapply
In-Reply-To: <5519C4BD020000CB00127E0C@smtp.medicine.umaryland.edu>
References: <5519C4BD020000CB00127E0C@smtp.medicine.umaryland.edu>
Message-ID: <CAF8bMcbxRwDyV8hxPeZ1pWEfV32WwbJYcsBa35eyLrnYCFmqKQ@mail.gmail.com>

> I can't understand how the body of the function, x[c1]/x[c2] refers to
the columns "data" and "SE" of the matrix data.

If you put the line 'str(x)' at the start of myfun(), as in
   myfun <- function(x, c1, c2) {
      str(x)
      x[c1]/x[c2]
   }
you would start to see why it works - extracting a row from a matrix gives
you a vector with names copied from the column names of the matrix.
Thus subscripting with a single name (or number) works.
  > apply(data,1,myfun,c1="delta",c2="SE")
   Named num [1:8] -0.7 -0.9 -0.5 20 20 ...
   - attr(*, "names")= chr [1:8] "delta" "low" "high" "n1" ...
   Named num [1:8] -0.3 -0.43 -0.17 43 43 ...
   - attr(*, "names")= chr [1:8] "delta" "low" "high" "n1" ...
   Named num [1:8] -0.5 -1.05 0.05 16 18 ...
   ...
   Named num [1:8] -0.3 -0.83 0.23 27 27 ...
   - attr(*, "names")= chr [1:8] "delta" "low" "high" "n1" ...
  [1] -13.720000  -9.046154  -3.563636   0.000000 -28.311111 -32.072727
 -2.903704  -2.218868

By the way, that call to apply is just a slow way of dividing two columns
of the matrix
  > data[, "delta"]/data[, "SE"]
  [1] -13.720000  -9.046154  -3.563636   0.000000 -28.311111 -32.072727
 -2.903704  -2.218868


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Mar 30, 2015 at 6:48 PM, John Sorkin <jsorkin at grecc.umaryland.edu>
wrote:

> Colleagues,
> I am trying to understand the syntax of a function passed to apply. The
> code below generates a matrix, and passes the matrix to a function that is
> called by apply. I don't understand the syntax of the function. In some way
> the function computes data[,"delta"]/data[,"SE"]. I can't understand how
> the body of the function, x[c1]/x[c2] refers to the columns "data" and "SE"
> of the matrix data. Can someone help me understand the syntax?
> Thank you,
> John
>
> myfun <- function(x, c1, c2) x[c1]/x[c2]
> apply(data,1,myfun,c1="delta",c2="SE")
>
> CODE:
>
> data<-matrix(data=c(-0.70 ,-0.90, -0.50, 20, 20,
>                     -0.30 ,-0.43, -0.17, 43, 43,
>                     -0.50 ,-1.05,  0.05, 16, 18,
>                      0.00 ,-0.21,  0.21, 22, 23,
>                     -1.30 ,-1.48, -1.12, 28, 32,
>                     -0.90 ,-1.01, -0.79, 18, 15,
>                     -0.20 ,-0.47,  0.07, 39, 39,
>                     -0.30 ,-0.83,  0.23, 27, 27),
>                      nrow=8,ncol=5,byrow=TRUE)
> dimnames(data) <- list(NULL,c("delta","low","high","n1","n2"))
> data
> CI <- data[,"high"]-data[,"low"]
> data <- cbind(data,CI)
> data
> data <- cbind(data,SE=data[,"CI"]/(4*1.96))
> data
> data <- cbind(data,SD=data[,"SE"]*sqrt(data[,"n1"]+data[,"n2"]))
> data
> myfun <- function(x, c1, c2) x[c1]/x[c2]
> apply(data,1,myfun,c1="delta",c2="SE")
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From drjimlemon at gmail.com  Tue Mar 31 04:59:20 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 31 Mar 2015 13:59:20 +1100
Subject: [R] Trying to understand a function passed to lapply
In-Reply-To: <5519C4BD020000CB00127E0C@smtp.medicine.umaryland.edu>
References: <5519C4BD020000CB00127E0C@smtp.medicine.umaryland.edu>
Message-ID: <CA+8X3fWyKE32y7zJYDf1BoUEnr64JbD0ES_LSGK6BSfs8bWYFg@mail.gmail.com>

Hi John,
What happens is that you have passed two named arguments to your function
"myfun" along with the matrix "data". Because these arguments have
associated values ("delta", "SE"), these values are substituted into the
expression like this:

x["delta"]/x["SE"]

which is the return value of "myfun". If you just type in:

data["delta"]
data["SE"]

you will see the values that are successively selected for the calculation
in "myfun"

Jim


On Tue, Mar 31, 2015 at 12:48 PM, John Sorkin <jsorkin at grecc.umaryland.edu>
wrote:

> Colleagues,
> I am trying to understand the syntax of a function passed to apply. The
> code below generates a matrix, and passes the matrix to a function that is
> called by apply. I don't understand the syntax of the function. In some way
> the function computes data[,"delta"]/data[,"SE"]. I can't understand how
> the body of the function, x[c1]/x[c2] refers to the columns "data" and "SE"
> of the matrix data. Can someone help me understand the syntax?
> Thank you,
> John
>
> myfun <- function(x, c1, c2) x[c1]/x[c2]
> apply(data,1,myfun,c1="delta",c2="SE")
>
> CODE:
>
> data<-matrix(data=c(-0.70 ,-0.90, -0.50, 20, 20,
>                     -0.30 ,-0.43, -0.17, 43, 43,
>                     -0.50 ,-1.05,  0.05, 16, 18,
>                      0.00 ,-0.21,  0.21, 22, 23,
>                     -1.30 ,-1.48, -1.12, 28, 32,
>                     -0.90 ,-1.01, -0.79, 18, 15,
>                     -0.20 ,-0.47,  0.07, 39, 39,
>                     -0.30 ,-0.83,  0.23, 27, 27),
>                      nrow=8,ncol=5,byrow=TRUE)
> dimnames(data) <- list(NULL,c("delta","low","high","n1","n2"))
> data
> CI <- data[,"high"]-data[,"low"]
> data <- cbind(data,CI)
> data
> data <- cbind(data,SE=data[,"CI"]/(4*1.96))
> data
> data <- cbind(data,SD=data[,"SE"]*sqrt(data[,"n1"]+data[,"n2"]))
> data
> myfun <- function(x, c1, c2) x[c1]/x[c2]
> apply(data,1,myfun,c1="delta",c2="SE")
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From tr206 at kent.ac.uk  Mon Mar 30 21:30:11 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Mon, 30 Mar 2015 19:30:11 +0000
Subject: [R] generating phi using function()
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A12F536BD79@EX10-LIVE-MBN2.ad.kent.ac.uk>

Hi,
I am struggling with following function
> phi <- function(w1, w2, j, k, K){
+   zaehler <- (k/K)^(w1-1)*(1-k/K)^(w2-1)
+   nenner <- sum( ((1:K)/K)^(w1-1)*(1-(1:K)/K)^(w2-1))
+   return( zaehler/nenner )
+ }
> phi(c(1, 1), 44L, 1)
Error in phi(c(1, 1), 44L, 1) : argument "k" is missing, with no default


Hence, I have changed the function to

phi <- function(w, k, K){
+ w1 <- w[1]
+ w2 <- w[2]
+ zaehler <- (k/K)^(w1-1)*(1-k/K)^(w2-1)
+ nenner <- sum( ((1:K)/K)^(w1-1)*(1-(1:K)/K)^(w2-1))
+ return( zaehler/nenner )
+ }

 Unfortunately, when running the midas regression I get the following error message

 m22.phi<- midas_r(rv~mls(rvh,1:max.lag+h1,1,phi), start = list(rvh=c(1,1)))

Error in X[, inds] %*% fun(st) : non-conformable arguments

I guess the problem is w but I do not find a solution how to produce the formula shown in the attached file where the exponents are w1 and w2, respectively.

Thanks for your help


From: JLucke at ria.buffalo.edu [mailto:JLucke at ria.buffalo.edu]
Sent: 30 March 2015 16:01
To: T.Riedle
Cc: r-help at r-project.org; R-help
Subject: Re: [R] generating phi using function()

Your function phi has 5 arguments with no defaults.  Your call only has 3 arguments.  Hence the error message.
> phi <- function(w1, w2, j, k, K){
+   zaehler <- (k/K)^(w1-1)*(1-k/K)^(w2-1)
+   nenner <- sum( ((1:K)/K)^(w1-1)*(1-(1:K)/K)^(w2-1))
+   return( zaehler/nenner )
+ }
> phi(c(1, 1), 44L, 1)
Error in phi(c(1, 1), 44L, 1) : argument "k" is missing, with no default



>





"T.Riedle" <tr206 at kent.ac.uk<mailto:tr206 at kent.ac.uk>>
Sent by: "R-help" <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>>

03/29/2015 08:59 AM

To

"r-help at r-project.org<mailto:r-help at r-project.org>" <r-help at r-project.org<mailto:r-help at r-project.org>>,

cc

Subject

[R] generating phi using function()







Hi everybody,
I am trying to generate the formula shown in the attachment. My formula so far looks as follows:

phi <- function(w1, w2, j, k, K){
zaehler <- (k/K)^(w1-1)*(1-k/K)^(w2-1)
nenner <- sum( ((1:K)/K)^(w1-1)*(1-(1:K)/K)^(w2-1))
return( zaehler/nenner )
}

Unfortunately something must be wrong here as I get the following message when running a midas regression

m22.phi<- midas_r(rv~mls(rvh,1:max.lag+h1,1,phi), start = list(rvh=c(1,1)))
Error in phi(c(1, 1), 44L, 1) : argument "K" is missing, with no default
Called from: .rs.breakOnError(TRUE)
Browse[1]> K<-125
Browse[1]> 125

Could anybody look into my phi formula and tell me what is wrong with it?

Thanks in advance.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: psi.png
Type: image/png
Size: 2199 bytes
Desc: psi.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150330/69a1a9c5/attachment.png>

From tr206 at kent.ac.uk  Mon Mar 30 21:58:24 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Mon, 30 Mar 2015 19:58:24 +0000
Subject: [R] how to deal with changing weighting functions
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A12F536BD9C@EX10-LIVE-MBN2.ad.kent.ac.uk>

Hi everybody,
Does anybody have an idea how I can generate tau according to the attached formula? The point is that phi changes with k and I thought I could make it by using a for-function in R but I am not sure how to do that.

Could anyone help me?
Thanks in advance.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: tau.png
Type: image/png
Size: 1797 bytes
Desc: tau.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150330/efbe259f/attachment.png>

From ben.bighair at gmail.com  Tue Mar 31 03:37:40 2015
From: ben.bighair at gmail.com (Ben Tupper)
Date: Mon, 30 Mar 2015 21:37:40 -0400
Subject: [R] Help with POSIX
In-Reply-To: <D13F6D5B.25599%hdoran@air.org>
References: <D13F6D5B.25599%hdoran@air.org>
Message-ID: <7CD84690-D9A3-4EF5-A81B-3F53336E3295@gmail.com>

Hi,


On Mar 30, 2015, at 9:15 PM, Doran, Harold <HDoran at air.org> wrote:

> I?m struggling a bit with learning about POSIX objects to do some basic things with objects of this class. Suppose I have the following simple example
> 
> times <- c("03:20", "29:56", "03:30", "21:03", "56:26")
> 
> aa <- strptime(times, "%M:%S?)
> 
> I can do means, and some other basic things, but I cannot correlate the objects with some other variable
> 
> cor(aa, rnorm(5))
> 


You can cast your POSIXlt values to numeric

cor(as.numeric(aa), rnorm(5))


> Also, for purposes of a user-interface I have built with shiny, I need for the time to be viewed as simply as minutes:seconds, such as this
> 
> format(aa, '%M:%S?)
> 
> But of course after doing this I lose the ability to work with this object as a time variable.
> 

You may need to keep a copy of your times in a POSIX or numeric format in addition to converting to character.  It's hard to tell without more information.

Cheers,
Ben

> Thank you
> Harold
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Tue Mar 31 04:59:00 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 31 Mar 2015 02:59:00 +0000
Subject: [R] temporal autocorrelation in MCMCglmm
References: <CALC46t_UBBBZAER2B3md619hNdcKKmy+jiLcak_UkX=Kuy0Ptg@mail.gmail.com>
Message-ID: <loom.20150331T045617-3@post.gmane.org>

David Villegas R?os <chirleu <at> gmail.com> writes:

> Hi,
> For a number of individuals, I have measured several behavioral traits in
> the wild. Those traits (e.g. home range) can be estimated on different
> temporal scales, for example daily, weekly or monthly. I want to estimate
> repeatability of those traits, assuming that the daily/weekly/monthly
> measurements represent replicates. I have 3 months (90 days) of data for
> each trait. Two questions:
> 
> 1) How can assess if there is temporal autocorrelation in my model? I guess
> that if I consider daily measurements as replicates (90 replicates), I will
> have some autocorrelation, but if I use just monthly measurements (3
> replicates) maybe I avoid it.
> 
> 2) How can account for temporal autocorrelation in MCMCglmm?
> 
> Sorry for this pretty basic questions but I haven't found an answer so far.

You'll probably be better off asking this question at r-sig-mixed-models
(at) r-project.org.

As a first pass, you might be able take the residuals from your fit and use
acf() to compute the autocorrelation function.  Actually, though, you'll
probably be better off fitting a 'null' lme() model (fixed=resid~1,
random=~1|individual) and then using the ACF() method (not the same
thing as acf()) on the resulting model fit.

  Ben Bolker


From ntfredo at gmail.com  Tue Mar 31 07:56:48 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 31 Mar 2015 08:56:48 +0300
Subject: [R] Multiple Plots using ggplot
In-Reply-To: <CADKEMqhsaeDC9S1fZVdefm-P2mFwFEPJYFGp0e-=Fh=XR+y48Q@mail.gmail.com>
References: <CAGh51gS7eX0QggStQ+G=1VW=Z48vRSfK9XzDSpH47bGfnaO-LA@mail.gmail.com>
	<CADKEMqhsaeDC9S1fZVdefm-P2mFwFEPJYFGp0e-=Fh=XR+y48Q@mail.gmail.com>
Message-ID: <CAGh51gR5psHsbW1raEru6PpG=nt8u40rr2Q_0nW34nuh91GbSg@mail.gmail.com>

Hi Stephen,

Sorry, the data came in bad way.
Here is the head of the data.

> head(data)        Date Number.of.Rain.Days Total.rain Start.of.Rain..i. Start.of.Rain..ii. Start.of.Rain..iii. Start.Rain..iv.
1 1952-01-01                  86   1139.952                92
      239                 112             112
2 1953-01-01                  96    977.646                98
       98                 112             112
3 1954-01-01                 114   1382.014                92
       92                 120             120
4 1955-01-01                 119   1323.086               100
      100                 125             174
5 1956-01-01                 123   1266.444                92
       92                 119             119
6 1957-01-01                 124   1235.964                92
       92                 112             112



Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Mon, Mar 30, 2015 at 5:34 PM, stephen sefick <ssefick at gmail.com> wrote:

> Hi Frederic,
>
> Can you provide a minimal reproducible example including either real data
> (dput), or simulated data that mimics your situation? This will allow more
> people to help.
>
> Stephen
>
> On Mon, Mar 30, 2015 at 8:39 AM, Frederic Ntirenganya <ntfredo at gmail.com>
> wrote:
>
>> Dear All,
>>
>> I want to plot multiple using ggplot function from a data frame of
>> many columns. I want to plot only str1, str2 and str3 and I failed to
>> make it. What I want is to compare str1, str2 and str3 by plotting
>> vertical line. I also need to add points to the plot to be able to
>> separate them.
>>
>>
>> Here is how the data look like and how I tried to make it.
>>
>> Date NumberofRaindays TotalRains str1 str2 str3 1/1/1952 86 1360.5 92 120
>> 112 1/1/1953 96 1100 98 100 110
>> ...                                           ....
>> ....             ...              ....            ....
>>
>> df1 <-data.frame(data)
>> df1
>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>> df2
>>
>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type = "h")
>>
>> Kindly any help is welcome. Thanks
>>
>> Regards,
>> Frederic.
>>
>> Frederic Ntirenganya
>> Maseno University,
>> African Maths Initiative,
>> Kenya.
>> Mobile:(+254)718492836
>> Email: fredo at aims.ac.za
>> https://sites.google.com/a/aims.ac.za/fredo/
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Mar 31 08:24:51 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 30 Mar 2015 23:24:51 -0700
Subject: [R] Multiple Plots using ggplot
In-Reply-To: <CAGh51gR5psHsbW1raEru6PpG=nt8u40rr2Q_0nW34nuh91GbSg@mail.gmail.com>
References: <CAGh51gS7eX0QggStQ+G=1VW=Z48vRSfK9XzDSpH47bGfnaO-LA@mail.gmail.com>
	<CADKEMqhsaeDC9S1fZVdefm-P2mFwFEPJYFGp0e-=Fh=XR+y48Q@mail.gmail.com>
	<CAGh51gR5psHsbW1raEru6PpG=nt8u40rr2Q_0nW34nuh91GbSg@mail.gmail.com>
Message-ID: <4BB41E12-07C6-491B-90A3-38894C7A7761@dcn.davis.CA.us>

This is no better because (a) you are still posting using HTML format, and (b) using printed output loses the internal representation of the data. The dput function is very helpful for solving this. [1]

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 30, 2015 10:56:48 PM PDT, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
>Hi Stephen,
>
>Sorry, the data came in bad way.
>Here is the head of the data.
>
>> head(data)        Date Number.of.Rain.Days Total.rain
>Start.of.Rain..i. Start.of.Rain..ii. Start.of.Rain..iii.
>Start.Rain..iv.
>1 1952-01-01                  86   1139.952                92
>      239                 112             112
>2 1953-01-01                  96    977.646                98
>       98                 112             112
>3 1954-01-01                 114   1382.014                92
>       92                 120             120
>4 1955-01-01                 119   1323.086               100
>      100                 125             174
>5 1956-01-01                 123   1266.444                92
>       92                 119             119
>6 1957-01-01                 124   1235.964                92
>       92                 112             112
>
>
>
>Frederic Ntirenganya
>Maseno University,
>African Maths Initiative,
>Kenya.
>Mobile:(+254)718492836
>Email: fredo at aims.ac.za
>https://sites.google.com/a/aims.ac.za/fredo/
>
>On Mon, Mar 30, 2015 at 5:34 PM, stephen sefick <ssefick at gmail.com>
>wrote:
>
>> Hi Frederic,
>>
>> Can you provide a minimal reproducible example including either real
>data
>> (dput), or simulated data that mimics your situation? This will allow
>more
>> people to help.
>>
>> Stephen
>>
>> On Mon, Mar 30, 2015 at 8:39 AM, Frederic Ntirenganya
><ntfredo at gmail.com>
>> wrote:
>>
>>> Dear All,
>>>
>>> I want to plot multiple using ggplot function from a data frame of
>>> many columns. I want to plot only str1, str2 and str3 and I failed
>to
>>> make it. What I want is to compare str1, str2 and str3 by plotting
>>> vertical line. I also need to add points to the plot to be able to
>>> separate them.
>>>
>>>
>>> Here is how the data look like and how I tried to make it.
>>>
>>> Date NumberofRaindays TotalRains str1 str2 str3 1/1/1952 86 1360.5
>92 120
>>> 112 1/1/1953 96 1100 98 100 110
>>> ...                                           ....
>>> ....             ...              ....            ....
>>>
>>> df1 <-data.frame(data)
>>> df1
>>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>>> df2
>>>
>>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type =
>"h")
>>>
>>> Kindly any help is welcome. Thanks
>>>
>>> Regards,
>>> Frederic.
>>>
>>> Frederic Ntirenganya
>>> Maseno University,
>>> African Maths Initiative,
>>> Kenya.
>>> Mobile:(+254)718492836
>>> Email: fredo at aims.ac.za
>>> https://sites.google.com/a/aims.ac.za/fredo/
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>> --
>> Stephen Sefick
>> **************************************************
>> Auburn University
>> Biological Sciences
>> 331 Funchess Hall
>> Auburn, Alabama
>> 36849
>> **************************************************
>> sas0025 at auburn.edu
>> http://www.auburn.edu/~sas0025
>> **************************************************
>>
>> Let's not spend our time and resources thinking about things that are
>so
>> little or so large that all they really do for us is puff us up and
>make us
>> feel like gods.  We are mammals, and have not exhausted the annoying
>little
>> problems of being mammals.
>>
>>                                 -K. Mullis
>>
>> "A big computer, a complex algorithm and a long time does not equal
>> science."
>>
>>                               -Robert Gentleman
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From djnordlund at frontier.com  Tue Mar 31 08:30:14 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Mon, 30 Mar 2015 23:30:14 -0700
Subject: [R] generating phi using function()
In-Reply-To: <AEB16B1613D44C4793A7E6B6986B7A12F536BD79@EX10-LIVE-MBN2.ad.kent.ac.uk>
References: <AEB16B1613D44C4793A7E6B6986B7A12F536BD79@EX10-LIVE-MBN2.ad.kent.ac.uk>
Message-ID: <551A3EF6.9030605@frontier.com>

On 3/30/2015 12:30 PM, T.Riedle wrote:
> Hi,
> I am struggling with following function
>> phi <- function(w1, w2, j, k, K){
> +   zaehler <- (k/K)^(w1-1)*(1-k/K)^(w2-1)
> +   nenner <- sum( ((1:K)/K)^(w1-1)*(1-(1:K)/K)^(w2-1))
> +   return( zaehler/nenner )
> + }
>> phi(c(1, 1), 44L, 1)
> Error in phi(c(1, 1), 44L, 1) : argument "k" is missing, with no default
>
>
> Hence, I have changed the function to
>
> phi <- function(w, k, K){
> + w1 <- w[1]
> + w2 <- w[2]
> + zaehler <- (k/K)^(w1-1)*(1-k/K)^(w2-1)
> + nenner <- sum( ((1:K)/K)^(w1-1)*(1-(1:K)/K)^(w2-1))
> + return( zaehler/nenner )
> + }
>
>   Unfortunately, when running the midas regression I get the following error message
>
>   m22.phi<- midas_r(rv~mls(rvh,1:max.lag+h1,1,phi), start = list(rvh=c(1,1)))
>
> Error in X[, inds] %*% fun(st) : non-conformable arguments
>
> I guess the problem is w but I do not find a solution how to produce the formula shown in the attached file where the exponents are w1 and w2, respectively.
>
> Thanks for your help
>
>
> From: JLucke at ria.buffalo.edu [mailto:JLucke at ria.buffalo.edu]
> Sent: 30 March 2015 16:01
> To: T.Riedle
> Cc: r-help at r-project.org; R-help
> Subject: Re: [R] generating phi using function()
>
> Your function phi has 5 arguments with no defaults.  Your call only has 3 arguments.  Hence the error message.
>> phi <- function(w1, w2, j, k, K){
> +   zaehler <- (k/K)^(w1-1)*(1-k/K)^(w2-1)
> +   nenner <- sum( ((1:K)/K)^(w1-1)*(1-(1:K)/K)^(w2-1))
> +   return( zaehler/nenner )
> + }
>> phi(c(1, 1), 44L, 1)
> Error in phi(c(1, 1), 44L, 1) : argument "k" is missing, with no default
>
>
>
>>
>
>
>
>
>
> "T.Riedle" <tr206 at kent.ac.uk<mailto:tr206 at kent.ac.uk>>
> Sent by: "R-help" <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>>
>
> 03/29/2015 08:59 AM
>
> To
>
> "r-help at r-project.org<mailto:r-help at r-project.org>" <r-help at r-project.org<mailto:r-help at r-project.org>>,
>
> cc
>
> Subject
>
> [R] generating phi using function()
>
>
>
>
>
>
>
> Hi everybody,
> I am trying to generate the formula shown in the attachment. My formula so far looks as follows:
>
> phi <- function(w1, w2, j, k, K){
> zaehler <- (k/K)^(w1-1)*(1-k/K)^(w2-1)
> nenner <- sum( ((1:K)/K)^(w1-1)*(1-(1:K)/K)^(w2-1))
> return( zaehler/nenner )
> }
>
> Unfortunately something must be wrong here as I get the following message when running a midas regression
>
> m22.phi<- midas_r(rv~mls(rvh,1:max.lag+h1,1,phi), start = list(rvh=c(1,1)))
> Error in phi(c(1, 1), 44L, 1) : argument "K" is missing, with no default
> Called from: .rs.breakOnError(TRUE)
> Browse[1]> K<-125
> Browse[1]> 125
>
> Could anybody look into my phi formula and tell me what is wrong with it?
>
> Thanks in advance.
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

You haven't provided a reproducible example, so it is difficult to 
trouble shoot errors.  However, it is not obvious to me that the error 
message has anything to do with parameter, w, in the phi function.  In 
reading the documentation for midas_r(), the help says of the formula 
argument

formula 	

formula for restricted MIDAS regression or midas_r object. Formula must 
include fmls function

your formula does not include the fmls() function, it uses mls().  So I 
think your problem may have to do with how you are calling the midas_r 
function, and how the parameters are created and passed to phi().


Unfortunately, I can't be of much more help,

Dan

-- 
Daniel Nordlund
Bothell, WA USA


From stephane.adamowicz at avignon.inra.fr  Tue Mar 31 09:34:49 2015
From: stephane.adamowicz at avignon.inra.fr (=?iso-8859-1?Q?St=E9phane_Adamowicz?=)
Date: Tue, 31 Mar 2015 09:34:49 +0200
Subject: [R] matrix manipulation question
In-Reply-To: <CA8ED6B3-7342-46D4-9459-ED00DF4EEBCD@gmail.com>
References: <5514E6F4.9050700@gmail.com>
	<D3D1F7BC-3954-4B0C-B862-B9F822556DB9@avignon.inra.fr>
	<950C4B78-0DE6-4C3A-8031-76B0821595C1@gmail.com>
	<040A3B9E-AE0C-4DFC-8B08-05C404756BF5@avignon.inra.fr>
	<7FDAEF53-2F5E-41B2-BCAE-408F1D24042F@comcast.net>
	<519F0EDD-ED21-4EA2-99C6-5F0AE59E7C25@avignon.inra.fr>
	<CA8ED6B3-7342-46D4-9459-ED00DF4EEBCD@gmail.com>
Message-ID: <52C7787D-1C61-46F1-8E2F-0E7AA46D1833@avignon.inra.fr>

Many thanks,

St?phane

Le 30 mars 2015 ? 10:42, peter dalgaard <pdalgd at gmail.com> a ?crit :

> 
>> On 30 Mar 2015, at 09:59 , St?phane Adamowicz <stephane.adamowicz at avignon.inra.fr> wrote:
>> 
>> 
>> However, in order to help me understand, would you be so kind as to give me a matrix or data.frame example where ? complete.cases(X)== T ? or ? complete.cases(X)== TRUE ? would give some unwanted result ?
> 
> The standard problem with T for TRUE is if T has been used for some other purpose, like a time variable. E.g., T <- 0 ; complete.cases(X)==T.
> 
> complete.cases()==TRUE is just silly, like (x==0)==TRUE or ((x==0)==TRUE)==TRUE). 
> 
> (However, notice that x==TRUE is different from as.logical(x) if x is numeric, so ifelse(x,y,z) may differ from ifelse(x==TRUE,y,z).) 
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 


From ntfredo at gmail.com  Tue Mar 31 09:55:11 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 31 Mar 2015 10:55:11 +0300
Subject: [R] Multiple Plots using ggplot
In-Reply-To: <4BB41E12-07C6-491B-90A3-38894C7A7761@dcn.davis.CA.us>
References: <CAGh51gS7eX0QggStQ+G=1VW=Z48vRSfK9XzDSpH47bGfnaO-LA@mail.gmail.com>
	<CADKEMqhsaeDC9S1fZVdefm-P2mFwFEPJYFGp0e-=Fh=XR+y48Q@mail.gmail.com>
	<CAGh51gR5psHsbW1raEru6PpG=nt8u40rr2Q_0nW34nuh91GbSg@mail.gmail.com>
	<4BB41E12-07C6-491B-90A3-38894C7A7761@dcn.davis.CA.us>
Message-ID: <CAGh51gR0vT4b0GKNea=DO6cwyug_mPhzQZ3txXi+=Q9eggUkUQ@mail.gmail.com>

 Hi All,

Sorry for the shape of data which was not good enough.This is how my
data look like.

I want to plot multiple using ggplot function from a data frame of
many columns. I want to plot only Start.of.Rain..i.,
Start.of.Rain..ii. and  Start.of.Rain..iii. and I failed to make it.
What I want is to compare Start.of.Rain..i., Start.of.Rain..ii. and
Start.of.Rain..iii. by plotting vertical line. I also need to add
points to the plot to be able to separate them. The x-axis must be
date column. Thanks!

Here is how the data look like and how I tried to make it.



Date Number.of.Rain.Days Total.rain Start.of.Rain..i. Start.of.Rain..ii.
Start.of.Rain..iii. 1952-01-01 86 1139.952 92 239 11 1953-01-01 96 977.646
98 98 11 1954-01-01 114 1382.014 92 92 12 1955-01-01 119 1323.086 100 100
12 1956-01-01 123 1266.444 92 92 11 1957-01-01 124 1235.964 92 92 11


Here is how I tried to solve the problem.

df1 <-data.frame(data)
df1
df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
df2

ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type = "h")

Kindly any help is welcome. Thanks

Regards,
Frederic.

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Tue, Mar 31, 2015 at 9:24 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> This is no better because (a) you are still posting using HTML format, and
> (b) using printed output loses the internal representation of the data. The
> dput function is very helpful for solving this. [1]
>
> [1]
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On March 30, 2015 10:56:48 PM PDT, Frederic Ntirenganya <ntfredo at gmail.com>
> wrote:
> >Hi Stephen,
> >
> >Sorry, the data came in bad way.
> >Here is the head of the data.
> >
> >> head(data)        Date Number.of.Rain.Days Total.rain
> >Start.of.Rain..i. Start.of.Rain..ii. Start.of.Rain..iii.
> >Start.Rain..iv.
> >1 1952-01-01                  86   1139.952                92
> >      239                 112             112
> >2 1953-01-01                  96    977.646                98
> >       98                 112             112
> >3 1954-01-01                 114   1382.014                92
> >       92                 120             120
> >4 1955-01-01                 119   1323.086               100
> >      100                 125             174
> >5 1956-01-01                 123   1266.444                92
> >       92                 119             119
> >6 1957-01-01                 124   1235.964                92
> >       92                 112             112
> >
> >
> >
> >Frederic Ntirenganya
> >Maseno University,
> >African Maths Initiative,
> >Kenya.
> >Mobile:(+254)718492836
> >Email: fredo at aims.ac.za
> >https://sites.google.com/a/aims.ac.za/fredo/
> >
> >On Mon, Mar 30, 2015 at 5:34 PM, stephen sefick <ssefick at gmail.com>
> >wrote:
> >
> >> Hi Frederic,
> >>
> >> Can you provide a minimal reproducible example including either real
> >data
> >> (dput), or simulated data that mimics your situation? This will allow
> >more
> >> people to help.
> >>
> >> Stephen
> >>
> >> On Mon, Mar 30, 2015 at 8:39 AM, Frederic Ntirenganya
> ><ntfredo at gmail.com>
> >> wrote:
> >>
> >>> Dear All,
> >>>
> >>> I want to plot multiple using ggplot function from a data frame of
> >>> many columns. I want to plot only str1, str2 and str3 and I failed
> >to
> >>> make it. What I want is to compare str1, str2 and str3 by plotting
> >>> vertical line. I also need to add points to the plot to be able to
> >>> separate them.
> >>>
> >>>
> >>> Here is how the data look like and how I tried to make it.
> >>>
> >>> Date NumberofRaindays TotalRains str1 str2 str3 1/1/1952 86 1360.5
> >92 120
> >>> 112 1/1/1953 96 1100 98 100 110
> >>> ...                                           ....
> >>> ....             ...              ....            ....
> >>>
> >>> df1 <-data.frame(data)
> >>> df1
> >>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
> >>> df2
> >>>
> >>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type =
> >"h")
> >>>
> >>> Kindly any help is welcome. Thanks
> >>>
> >>> Regards,
> >>> Frederic.
> >>>
> >>> Frederic Ntirenganya
> >>> Maseno University,
> >>> African Maths Initiative,
> >>> Kenya.
> >>> Mobile:(+254)718492836
> >>> Email: fredo at aims.ac.za
> >>> https://sites.google.com/a/aims.ac.za/fredo/
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >>
> >> --
> >> Stephen Sefick
> >> **************************************************
> >> Auburn University
> >> Biological Sciences
> >> 331 Funchess Hall
> >> Auburn, Alabama
> >> 36849
> >> **************************************************
> >> sas0025 at auburn.edu
> >> http://www.auburn.edu/~sas0025
> >> **************************************************
> >>
> >> Let's not spend our time and resources thinking about things that are
> >so
> >> little or so large that all they really do for us is puff us up and
> >make us
> >> feel like gods.  We are mammals, and have not exhausted the annoying
> >little
> >> problems of being mammals.
> >>
> >>                                 -K. Mullis
> >>
> >> "A big computer, a complex algorithm and a long time does not equal
> >> science."
> >>
> >>                               -Robert Gentleman
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From kylie.lange at adelaide.edu.au  Tue Mar 31 08:38:34 2015
From: kylie.lange at adelaide.edu.au (Kylie Lange)
Date: Tue, 31 Mar 2015 06:38:34 +0000
Subject: [R] MethComp exported object namespace error
Message-ID: <117D5AFEB07BF04899B1FC6A0DAD1A00B3CB1884@MAILMB02.ad.adelaide.edu.au>

Hi everyone,

I am using the MCmcmc function of the MethComp package and receive the following error:

Error: 'coda.samples' is not an exported object from 'namespace:coda'

I emailed the package author last week but haven't had a reply. I have installed JAGS 3.4.0 as required by MethComp. I am using  R 3.1.2 and the MethComp currently on CRAN (1.22.1). I am not a regular R user so haven't had any luck making sense of the error, though there are references to namespace in the package check results here: http://cran.itam.mx/web/checks/check_results_bxc_at_steno.dk.html#MethComp. Not sure if that's relevant.

Any suggestions would be appreciated. Apologies if I haven't provided any required information.

The following shows my code and error (code taken from the package author's text 'Comparing Clinical Measurement Methods', Bendix Carstensen, section 7.5.3) :

>library(MethComp)
>data(ox)
>ox<- Meth(ox)
>m3<- MCmcmc(ox, IxR=TRUE, n.iter=50000)

Comparison of 2 methods, using 354 measurements on 61 items, with up to 3 replicate measurements, (replicate values are in the set: 1 2 3 ) 
( 2 * 61 * 3 = 366 ): 

No. items with measurements on each method:
        #Replicates
Method    1   2   3 #Items #Obs: 354 Values:  min  med  max
  CO      1   4  56     61       177         22.2 78.6 93.5
  pulse   1   4  56     61       177         24.0 75.0 94.0

Simulation run of a model with 
- method by item and item by replicate interaction: 
- using 4 chains run for 50000 iterations (of which 25000 are burn-in), 
- monitoring every 25 values of the chain: 
- giving a posterior sample of 4000 observations.

Loading required package: coda
Linked to JAGS 3.4.0
Loaded modules: basemod,bugs
Initialization and burn-in:
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
   Graph Size: 2868

Initializing model

  |++++++++++++++++++++++++++++++++++++++++++++++++++| 100%
Sampling:
Error: 'coda.samples' is not an exported object from 'namespace:coda'


Thanks,
Kylie.


From raluca.gui at business.uzh.ch  Tue Mar 31 14:10:33 2015
From: raluca.gui at business.uzh.ch (RiGui)
Date: Tue, 31 Mar 2015 05:10:33 -0700 (PDT)
Subject: [R] Error in lm() with very small (close to zero) regressor
In-Reply-To: <1427499146685-4705185.post@n4.nabble.com>
References: <1427499146685-4705185.post@n4.nabble.com>
Message-ID: <1427803833418-4705328.post@n4.nabble.com>

I found a fix to my problem using the fastLm() from package RcppEigen, using
the Jacobi singular value decomposition (SVD) (method 4) or a method based
on the eigenvalue-eigenvector decomposition of X'X - method 5 of the fastLm
function



install.packages("RcppEigen")
library(RcppEigen)

n_obs <- 1500
y  <- rnorm(n_obs, 10,2.89)
x1 <- rnorm(n_obs, 0.00000000000001235657,0.000000000000000045)
x2 <- rnorm(n_obs, 10,3.21)
X  <- cbind(x1,x2)



bFE <- fastLm(y ~ x1 + x2, method =4)
bFE

Call:
fastLm.formula(formula = y ~ x1 + x2, method = 4)

Coefficients:
        (Intercept)                  x1                  x2 
9.94832839474159414 0.00000000000012293 0.00440078989949841 


Best,

Raluca





--
View this message in context: http://r.789695.n4.nabble.com/Error-in-lm-with-very-small-close-to-zero-regressor-tp4705185p4705328.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Tue Mar 31 14:56:02 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 31 Mar 2015 05:56:02 -0700
Subject: [R] Multiple Plots using ggplot
In-Reply-To: <CAGh51gR0vT4b0GKNea=DO6cwyug_mPhzQZ3txXi+=Q9eggUkUQ@mail.gmail.com>
References: <CAGh51gS7eX0QggStQ+G=1VW=Z48vRSfK9XzDSpH47bGfnaO-LA@mail.gmail.com>
	<CADKEMqhsaeDC9S1fZVdefm-P2mFwFEPJYFGp0e-=Fh=XR+y48Q@mail.gmail.com>
	<CAGh51gR5psHsbW1raEru6PpG=nt8u40rr2Q_0nW34nuh91GbSg@mail.gmail.com>
	<4BB41E12-07C6-491B-90A3-38894C7A7761@dcn.davis.CA.us>
	<CAGh51gR0vT4b0GKNea=DO6cwyug_mPhzQZ3txXi+=Q9eggUkUQ@mail.gmail.com>
Message-ID: <527FC122-E681-44AE-B55C-9DF82C01ADB5@dcn.davis.CA.us>

By failing to take the advice given to you, you make it harder to help you. Learn to control your email program to send plain text, and learn to use the dput function.

With regard to this function call:

> ggplot(df2, aes(Date,value)) +

I highly recommend using named parameters in the aes call. Also, if you want different values of "variable" to be plotted with different colors, you should map that column to the colour dimension:

ggplot(df2, aes(x=Date,y=value,colour=variable)) +

The "type" argument applies to base graphics rather than ggplot graphics, and you should never put fixed values inside the aes call. Since colour has already been taken care of, you can give no parameters in the geom_line call:

geom_line()

So all together then:

ggplot(df2, aes(x=Date,y=value,colour=variable)) +
geom_line()

but I cannot test it because you have not followed my other advice.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On March 31, 2015 12:55:11 AM PDT, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
> Hi All,
>
>Sorry for the shape of data which was not good enough.This is how my
>data look like.
>
>I want to plot multiple using ggplot function from a data frame of
>many columns. I want to plot only Start.of.Rain..i.,
>Start.of.Rain..ii. and  Start.of.Rain..iii. and I failed to make it.
>What I want is to compare Start.of.Rain..i., Start.of.Rain..ii. and
>Start.of.Rain..iii. by plotting vertical line. I also need to add
>points to the plot to be able to separate them. The x-axis must be
>date column. Thanks!
>
>Here is how the data look like and how I tried to make it.
>
>
>
>Date Number.of.Rain.Days Total.rain Start.of.Rain..i.
>Start.of.Rain..ii.
>Start.of.Rain..iii. 1952-01-01 86 1139.952 92 239 11 1953-01-01 96
>977.646
>98 98 11 1954-01-01 114 1382.014 92 92 12 1955-01-01 119 1323.086 100
>100
>12 1956-01-01 123 1266.444 92 92 11 1957-01-01 124 1235.964 92 92 11
>
>
>Here is how I tried to solve the problem.
>
>df1 <-data.frame(data)
>df1
>df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>df2
>
>ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type = "h")
>
>Kindly any help is welcome. Thanks
>
>Regards,
>Frederic.
>
>Frederic Ntirenganya
>Maseno University,
>African Maths Initiative,
>Kenya.
>Mobile:(+254)718492836
>Email: fredo at aims.ac.za
>https://sites.google.com/a/aims.ac.za/fredo/
>
>On Tue, Mar 31, 2015 at 9:24 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> This is no better because (a) you are still posting using HTML
>format, and
>> (b) using printed output loses the internal representation of the
>data. The
>> dput function is very helpful for solving this. [1]
>>
>> [1]
>>
>http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 30, 2015 10:56:48 PM PDT, Frederic Ntirenganya
><ntfredo at gmail.com>
>> wrote:
>> >Hi Stephen,
>> >
>> >Sorry, the data came in bad way.
>> >Here is the head of the data.
>> >
>> >> head(data)        Date Number.of.Rain.Days Total.rain
>> >Start.of.Rain..i. Start.of.Rain..ii. Start.of.Rain..iii.
>> >Start.Rain..iv.
>> >1 1952-01-01                  86   1139.952                92
>> >      239                 112             112
>> >2 1953-01-01                  96    977.646                98
>> >       98                 112             112
>> >3 1954-01-01                 114   1382.014                92
>> >       92                 120             120
>> >4 1955-01-01                 119   1323.086               100
>> >      100                 125             174
>> >5 1956-01-01                 123   1266.444                92
>> >       92                 119             119
>> >6 1957-01-01                 124   1235.964                92
>> >       92                 112             112
>> >
>> >
>> >
>> >Frederic Ntirenganya
>> >Maseno University,
>> >African Maths Initiative,
>> >Kenya.
>> >Mobile:(+254)718492836
>> >Email: fredo at aims.ac.za
>> >https://sites.google.com/a/aims.ac.za/fredo/
>> >
>> >On Mon, Mar 30, 2015 at 5:34 PM, stephen sefick <ssefick at gmail.com>
>> >wrote:
>> >
>> >> Hi Frederic,
>> >>
>> >> Can you provide a minimal reproducible example including either
>real
>> >data
>> >> (dput), or simulated data that mimics your situation? This will
>allow
>> >more
>> >> people to help.
>> >>
>> >> Stephen
>> >>
>> >> On Mon, Mar 30, 2015 at 8:39 AM, Frederic Ntirenganya
>> ><ntfredo at gmail.com>
>> >> wrote:
>> >>
>> >>> Dear All,
>> >>>
>> >>> I want to plot multiple using ggplot function from a data frame
>of
>> >>> many columns. I want to plot only str1, str2 and str3 and I
>failed
>> >to
>> >>> make it. What I want is to compare str1, str2 and str3 by
>plotting
>> >>> vertical line. I also need to add points to the plot to be able
>to
>> >>> separate them.
>> >>>
>> >>>
>> >>> Here is how the data look like and how I tried to make it.
>> >>>
>> >>> Date NumberofRaindays TotalRains str1 str2 str3 1/1/1952 86
>1360.5
>> >92 120
>> >>> 112 1/1/1953 96 1100 98 100 110
>> >>> ...                                           ....
>> >>> ....             ...              ....            ....
>> >>>
>> >>> df1 <-data.frame(data)
>> >>> df1
>> >>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>> >>> df2
>> >>>
>> >>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type
>=
>> >"h")
>> >>>
>> >>> Kindly any help is welcome. Thanks
>> >>>
>> >>> Regards,
>> >>> Frederic.
>> >>>
>> >>> Frederic Ntirenganya
>> >>> Maseno University,
>> >>> African Maths Initiative,
>> >>> Kenya.
>> >>> Mobile:(+254)718492836
>> >>> Email: fredo at aims.ac.za
>> >>> https://sites.google.com/a/aims.ac.za/fredo/
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible
>code.
>> >>>
>> >>
>> >>
>> >>
>> >> --
>> >> Stephen Sefick
>> >> **************************************************
>> >> Auburn University
>> >> Biological Sciences
>> >> 331 Funchess Hall
>> >> Auburn, Alabama
>> >> 36849
>> >> **************************************************
>> >> sas0025 at auburn.edu
>> >> http://www.auburn.edu/~sas0025
>> >> **************************************************
>> >>
>> >> Let's not spend our time and resources thinking about things that
>are
>> >so
>> >> little or so large that all they really do for us is puff us up
>and
>> >make us
>> >> feel like gods.  We are mammals, and have not exhausted the
>annoying
>> >little
>> >> problems of being mammals.
>> >>
>> >>                                 -K. Mullis
>> >>
>> >> "A big computer, a complex algorithm and a long time does not
>equal
>> >> science."
>> >>
>> >>                               -Robert Gentleman
>> >>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From ssefick at gmail.com  Tue Mar 31 15:20:30 2015
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 31 Mar 2015 08:20:30 -0500
Subject: [R] Multiple Plots using ggplot
In-Reply-To: <CAGh51gR0vT4b0GKNea=DO6cwyug_mPhzQZ3txXi+=Q9eggUkUQ@mail.gmail.com>
References: <CAGh51gS7eX0QggStQ+G=1VW=Z48vRSfK9XzDSpH47bGfnaO-LA@mail.gmail.com>
	<CADKEMqhsaeDC9S1fZVdefm-P2mFwFEPJYFGp0e-=Fh=XR+y48Q@mail.gmail.com>
	<CAGh51gR5psHsbW1raEru6PpG=nt8u40rr2Q_0nW34nuh91GbSg@mail.gmail.com>
	<4BB41E12-07C6-491B-90A3-38894C7A7761@dcn.davis.CA.us>
	<CAGh51gR0vT4b0GKNea=DO6cwyug_mPhzQZ3txXi+=Q9eggUkUQ@mail.gmail.com>
Message-ID: <CADKEMqjLk-j0w5f=A=013NjXyEcj5LHwe8JjG756Y-Vnx3scSw@mail.gmail.com>

Your data and post is still not provided in one of the formats provided
here:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example.
I am unsure of what you want to do, but I have made a reproducible example
that might help.

zz <- "Date Number.of.Rain.Days Total.rain Start.of.Rain..i.
Start.of.Rain..ii.   Start.of.Rain..iii.
 1952-01-01                  86   1139.952                92
 239                 11
 1953-01-01                  96    977.646                98
  98                 11
 1954-01-01                 114   1382.014                92
  92                 12
 1955-01-01                 119   1323.086               100
 100                 12
 1956-01-01                 123   1266.444                92
  92                 11
 1957-01-01                 124   1235.964                92
  92                 11"

library(reshape)
library(ggplot2)

Data <- read.table(text=zz, header = TRUE)

df1 <-data.frame(Data)

df2 <- melt(df1 ,  id = c('Date', 'Number.of.Rain.Days'))

df3 <- df2[-grep("Total.rain", df2$variable),]

qplot(Date,value, data=df3) +facet_wrap(~variable)

On Tue, Mar 31, 2015 at 2:55 AM, Frederic Ntirenganya <ntfredo at gmail.com>
wrote:

>  Hi All,
>
> Sorry for the shape of data which was not good enough.This is how my data look like.
>
> I want to plot multiple using ggplot function from a data frame of many columns. I want to plot only Start.of.Rain..i., Start.of.Rain..ii. and  Start.of.Rain..iii. and I failed to make it. What I want is to compare Start.of.Rain..i., Start.of.Rain..ii. and Start.of.Rain..iii. by plotting vertical line. I also need to add points to the plot to be able to separate them. The x-axis must be date column. Thanks!
>
> Here is how the data look like and how I tried to make it.
>
>
>
> Date Number.of.Rain.Days Total.rain Start.of.Rain..i. Start.of.Rain..ii.
> Start.of.Rain..iii. 1952-01-01 86 1139.952 92 239 11 1953-01-01 96 977.646
> 98 98 11 1954-01-01 114 1382.014 92 92 12 1955-01-01 119 1323.086 100 100
> 12 1956-01-01 123 1266.444 92 92 11 1957-01-01 124 1235.964 92 92 11
>
>
> Here is how I tried to solve the problem.
>
> df1 <-data.frame(data)
> df1
> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
> df2
>
> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type = "h")
>
> Kindly any help is welcome. Thanks
>
> Regards,
> Frederic.
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> On Tue, Mar 31, 2015 at 9:24 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> This is no better because (a) you are still posting using HTML format,
>> and (b) using printed output loses the internal representation of the data.
>> The dput function is very helpful for solving this. [1]
>>
>> [1]
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 30, 2015 10:56:48 PM PDT, Frederic Ntirenganya <
>> ntfredo at gmail.com> wrote:
>> >Hi Stephen,
>> >
>> >Sorry, the data came in bad way.
>> >Here is the head of the data.
>> >
>> >> head(data)        Date Number.of.Rain.Days Total.rain
>> >Start.of.Rain..i. Start.of.Rain..ii. Start.of.Rain..iii.
>> >Start.Rain..iv.
>> >1 1952-01-01                  86   1139.952                92
>> >      239                 112             112
>> >2 1953-01-01                  96    977.646                98
>> >       98                 112             112
>> >3 1954-01-01                 114   1382.014                92
>> >       92                 120             120
>> >4 1955-01-01                 119   1323.086               100
>> >      100                 125             174
>> >5 1956-01-01                 123   1266.444                92
>> >       92                 119             119
>> >6 1957-01-01                 124   1235.964                92
>> >       92                 112             112
>> >
>> >
>> >
>> >Frederic Ntirenganya
>> >Maseno University,
>> >African Maths Initiative,
>> >Kenya.
>> >Mobile:(+254)718492836
>> >Email: fredo at aims.ac.za
>> >https://sites.google.com/a/aims.ac.za/fredo/
>> >
>> >On Mon, Mar 30, 2015 at 5:34 PM, stephen sefick <ssefick at gmail.com>
>> >wrote:
>> >
>> >> Hi Frederic,
>> >>
>> >> Can you provide a minimal reproducible example including either real
>> >data
>> >> (dput), or simulated data that mimics your situation? This will allow
>> >more
>> >> people to help.
>> >>
>> >> Stephen
>> >>
>> >> On Mon, Mar 30, 2015 at 8:39 AM, Frederic Ntirenganya
>> ><ntfredo at gmail.com>
>> >> wrote:
>> >>
>> >>> Dear All,
>> >>>
>> >>> I want to plot multiple using ggplot function from a data frame of
>> >>> many columns. I want to plot only str1, str2 and str3 and I failed
>> >to
>> >>> make it. What I want is to compare str1, str2 and str3 by plotting
>> >>> vertical line. I also need to add points to the plot to be able to
>> >>> separate them.
>> >>>
>> >>>
>> >>> Here is how the data look like and how I tried to make it.
>> >>>
>> >>> Date NumberofRaindays TotalRains str1 str2 str3 1/1/1952 86 1360.5
>> >92 120
>> >>> 112 1/1/1953 96 1100 98 100 110
>> >>> ...                                           ....
>> >>> ....             ...              ....            ....
>> >>>
>> >>> df1 <-data.frame(data)
>> >>> df1
>> >>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>> >>> df2
>> >>>
>> >>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type =
>> >"h")
>> >>>
>> >>> Kindly any help is welcome. Thanks
>> >>>
>> >>> Regards,
>> >>> Frederic.
>> >>>
>> >>> Frederic Ntirenganya
>> >>> Maseno University,
>> >>> African Maths Initiative,
>> >>> Kenya.
>> >>> Mobile:(+254)718492836
>> >>> Email: fredo at aims.ac.za
>> >>> https://sites.google.com/a/aims.ac.za/fredo/
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>
>> >>
>> >>
>> >> --
>> >> Stephen Sefick
>> >> **************************************************
>> >> Auburn University
>> >> Biological Sciences
>> >> 331 Funchess Hall
>> >> Auburn, Alabama
>> >> 36849
>> >> **************************************************
>> >> sas0025 at auburn.edu
>> >> http://www.auburn.edu/~sas0025
>> >> **************************************************
>> >>
>> >> Let's not spend our time and resources thinking about things that are
>> >so
>> >> little or so large that all they really do for us is puff us up and
>> >make us
>> >> feel like gods.  We are mammals, and have not exhausted the annoying
>> >little
>> >> problems of being mammals.
>> >>
>> >>                                 -K. Mullis
>> >>
>> >> "A big computer, a complex algorithm and a long time does not equal
>> >> science."
>> >>
>> >>                               -Robert Gentleman
>> >>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Tue Mar 31 15:35:05 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 31 Mar 2015 05:35:05 -0800
Subject: [R] Multiple Plots using ggplot
In-Reply-To: <CAGh51gR0vT4b0GKNea=DO6cwyug_mPhzQZ3txXi+=Q9eggUkUQ@mail.gmail.com>
References: <cagh51gr5pshsbw1raeru6ppg=nt8u40rr2q_0nw34nuh91gbsg@mail.gmail.com>
	<cadkemqhsaedc9s1fzvdefm-p2mfwfepjyfgp0e-=fh=xr+y48q@mail.gmail.com>
	<cagh51gs7ex0qggstq+g=1vw=z48vrsfk9xzdsph47bgfnao-la@mail.gmail.com>
	<4bb41e12-07c6-491b-90a3-38894c7a7761@dcn.davis.ca.us>
Message-ID: <98B9392D851.00000659jrkrideau@inbox.com>

The data you supplied is still in a useless format.

Please send it to us in dput format (and don't post in html)

Here is a complete example of creating a data.frame and converting it to a useable data set that readers on R-help can use

##=============Start Example===============##
# Simple example data set in a data.frame
data1  <-  data.frame(xx = 1:20, yy = sample(letters[1:26], 20, replace = TRUE), zz  <-  rnorm(20))

dput(data1)  # convert to dput() format for tranfering to other userss
 
# dput() result. Copy and paste back into your editor
structure(list(xx = 1:20, yy = structure(c(6L, 3L, 7L, 12L, 1L, 
1L, 2L, 7L, 9L, 6L, 8L, 7L, 9L, 5L, 4L, 10L, 11L, 4L, 8L, 11L
), .Label = c("a", "f", "g", "h", "i", "j", "k", "o", "p", "u", 
"w", "z"), class = "factor"), zz....rnorm.20. = c(0.379202224643519, 
-0.293649882956148, 2.27761155645142, 0.0378126031936277, 0.518138385757923, 
1.11655160886907, -1.64262245261915, 1.11341365979718, -0.184737977758355, 
0.439361470235051, 1.2597110753159, -0.795425331570368, 0.974654694801041, 
-0.309087884123705, -1.55929705211554, 0.147715827800676, -0.542626171203849, 
0.745294589678554, -0.254290052908619, 0.939894889209173)), .Names = c("xx", 
"yy", "zz....rnorm.20."), row.names = c(NA, -20L), class = "data.frame")

#  Read data back into standard R format, calling the data "dat1"

dat1  <-  structure(list(xx = 1:20, yy = structure(c(6L, 3L, 7L, 12L, 1L, 
1L, 2L, 7L, 9L, 6L, 8L, 7L, 9L, 5L, 4L, 10L, 11L, 4L, 8L, 11L
), .Label = c("a", "f", "g", "h", "i", "j", "k", "o", "p", "u", 
"w", "z"), class = "factor"), zz....rnorm.20. = c(0.379202224643519, 
-0.293649882956148, 2.27761155645142, 0.0378126031936277, 0.518138385757923, 
1.11655160886907, -1.64262245261915, 1.11341365979718, -0.184737977758355, 
0.439361470235051, 1.2597110753159, -0.795425331570368, 0.974654694801041, 
-0.309087884123705, -1.55929705211554, 0.147715827800676, -0.542626171203849, 
0.745294589678554, -0.254290052908619, 0.939894889209173)), .Names = c("xx", 
"yy", "zz....rnorm.20."), row.names = c(NA, -20L), class = "data.frame")

dat1
##=============End Example===============##

John Kane
Kingston ON Canada


> -----Original Message-----
> From: ntfredo at gmail.com
> Sent: Tue, 31 Mar 2015 10:55:11 +0300
> To: jdnewmil at dcn.davis.ca.us
> Subject: Re: [R] Multiple Plots using ggplot
> 
>  Hi All,
> 
> Sorry for the shape of data which was not good enough.This is how my
> data look like.
> 
> I want to plot multiple using ggplot function from a data frame of
> many columns. I want to plot only Start.of.Rain..i.,
> Start.of.Rain..ii. and  Start.of.Rain..iii. and I failed to make it.
> What I want is to compare Start.of.Rain..i., Start.of.Rain..ii. and
> Start.of.Rain..iii. by plotting vertical line. I also need to add
> points to the plot to be able to separate them. The x-axis must be
> date column. Thanks!
> 
> Here is how the data look like and how I tried to make it.
> 
> 
> 
> Date Number.of.Rain.Days Total.rain Start.of.Rain..i. Start.of.Rain..ii.
> Start.of.Rain..iii. 1952-01-01 86 1139.952 92 239 11 1953-01-01 96
> 977.646
> 98 98 11 1954-01-01 114 1382.014 92 92 12 1955-01-01 119 1323.086 100 100
> 12 1956-01-01 123 1266.444 92 92 11 1957-01-01 124 1235.964 92 92 11
> 
> 
> Here is how I tried to solve the problem.
> 
> df1 <-data.frame(data)
> df1
> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
> df2
> 
> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type = "h")
> 
> Kindly any help is welcome. Thanks
> 
> Regards,
> Frederic.
> 
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
> 
> On Tue, Mar 31, 2015 at 9:24 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
>> This is no better because (a) you are still posting using HTML format,
>> and
>> (b) using printed output loses the internal representation of the data.
>> The
>> dput function is very helpful for solving this. [1]
>> 
>> [1]
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>> 
>> On March 30, 2015 10:56:48 PM PDT, Frederic Ntirenganya
>> <ntfredo at gmail.com>
>> wrote:
>> >Hi Stephen,
>>> 
>> >Sorry, the data came in bad way.
>> >Here is the head of the data.
>>> 
>>>> head(data)        Date Number.of.Rain.Days Total.rain
>> >Start.of.Rain..i. Start.of.Rain..ii. Start.of.Rain..iii.
>> >Start.Rain..iv.
>> >1 1952-01-01                  86   1139.952                92
>>>      239                 112             112
>> >2 1953-01-01                  96    977.646                98
>>>       98                 112             112
>> >3 1954-01-01                 114   1382.014                92
>>>       92                 120             120
>> >4 1955-01-01                 119   1323.086               100
>>>      100                 125             174
>> >5 1956-01-01                 123   1266.444                92
>>>       92                 119             119
>> >6 1957-01-01                 124   1235.964                92
>>>       92                 112             112
>>> 
>>> 
>>> 
>> >Frederic Ntirenganya
>> >Maseno University,
>> >African Maths Initiative,
>> >Kenya.
>> >Mobile:(+254)718492836
>> >Email: fredo at aims.ac.za
>> >https://sites.google.com/a/aims.ac.za/fredo/
>>> 
>> >On Mon, Mar 30, 2015 at 5:34 PM, stephen sefick <ssefick at gmail.com>
>> >wrote:
>>> 
>>>> Hi Frederic,
>>>> 
>>>> Can you provide a minimal reproducible example including either real
>> >data
>>>> (dput), or simulated data that mimics your situation? This will allow
>> >more
>>>> people to help.
>>>> 
>>>> Stephen
>>>> 
>>>> On Mon, Mar 30, 2015 at 8:39 AM, Frederic Ntirenganya
>> ><ntfredo at gmail.com>
>>>> wrote:
>>>> 
>>>>> Dear All,
>>>>> 
>>>>> I want to plot multiple using ggplot function from a data frame of
>>>>> many columns. I want to plot only str1, str2 and str3 and I failed
>> >to
>>>>> make it. What I want is to compare str1, str2 and str3 by plotting
>>>>> vertical line. I also need to add points to the plot to be able to
>>>>> separate them.
>>>>> 
>>>>> 
>>>>> Here is how the data look like and how I tried to make it.
>>>>> 
>>>>> Date NumberofRaindays TotalRains str1 str2 str3 1/1/1952 86 1360.5
>> >92 120
>>>>> 112 1/1/1953 96 1100 98 100 110
>>>>> ...                                           ....
>>>>> ....             ...              ....            ....
>>>>> 
>>>>> df1 <-data.frame(data)
>>>>> df1
>>>>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>>>>> df2
>>>>> 
>>>>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type =
>> >"h")
>>>>> 
>>>>> Kindly any help is welcome. Thanks
>>>>> 
>>>>> Regards,
>>>>> Frederic.
>>>>> 
>>>>> Frederic Ntirenganya
>>>>> Maseno University,
>>>>> African Maths Initiative,
>>>>> Kenya.
>>>>> Mobile:(+254)718492836
>>>>> Email: fredo at aims.ac.za
>>>>> https://sites.google.com/a/aims.ac.za/fredo/
>>>>> 
>>>>>         [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>> 
>>>> 
>>>> --
>>>> Stephen Sefick
>>>> **************************************************
>>>> Auburn University
>>>> Biological Sciences
>>>> 331 Funchess Hall
>>>> Auburn, Alabama
>>>> 36849
>>>> **************************************************
>>>> sas0025 at auburn.edu
>>>> http://www.auburn.edu/~sas0025
>>>> **************************************************
>>>> 
>>>> Let's not spend our time and resources thinking about things that are
>> >so
>>>> little or so large that all they really do for us is puff us up and
>> >make us
>>>> feel like gods.  We are mammals, and have not exhausted the annoying
>> >little
>>>> problems of being mammals.
>>>> 
>>>>                                 -K. Mullis
>>>> 
>>>> "A big computer, a complex algorithm and a long time does not equal
>>>> science."
>>>> 
>>>>                               -Robert Gentleman
>>>> 
>>>> 
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From ntfredo at gmail.com  Tue Mar 31 15:46:43 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 31 Mar 2015 16:46:43 +0300
Subject: [R] Multiple Plots using ggplot
In-Reply-To: <CADKEMqjLk-j0w5f=A=013NjXyEcj5LHwe8JjG756Y-Vnx3scSw@mail.gmail.com>
References: <CAGh51gS7eX0QggStQ+G=1VW=Z48vRSfK9XzDSpH47bGfnaO-LA@mail.gmail.com>
	<CADKEMqhsaeDC9S1fZVdefm-P2mFwFEPJYFGp0e-=Fh=XR+y48Q@mail.gmail.com>
	<CAGh51gR5psHsbW1raEru6PpG=nt8u40rr2Q_0nW34nuh91GbSg@mail.gmail.com>
	<4BB41E12-07C6-491B-90A3-38894C7A7761@dcn.davis.CA.us>
	<CAGh51gR0vT4b0GKNea=DO6cwyug_mPhzQZ3txXi+=Q9eggUkUQ@mail.gmail.com>
	<CADKEMqjLk-j0w5f=A=013NjXyEcj5LHwe8JjG756Y-Vnx3scSw@mail.gmail.com>
Message-ID: <CAGh51gT9Nw0-+vF6GVWgvV0VwndxXy3COBeXu6hYpbu8_yUYcw@mail.gmail.com>

Hi All,

Thanks for the help. I want to plot some of the columns on the same graph
not all of them. Sorry, I failed to follow the instructions. Here is the
output of *dput()* but I don't know how it works.

> dput(head(data))structure(list(Date = structure(c(-6575, -6209, -5844, -5479,
-5114, -4748), class = "Date"), Number.of.Rain.Days = c(86L,
96L, 114L, 119L, 123L, 124L), Total.rain = c(1139.952, 977.646,
1382.014, 1323.086, 1266.444, 1235.964), Start.of.Rain..i. = c(92L,
98L, 92L, 100L, 92L, 92L), Start.of.Rain..ii. = c(239L, 98L,
92L, 100L, 92L, 92L), Start.of.Rain..iii. = c(112L, 112L, 120L,
125L, 119L, 112L), Start.Rain..iv. = c(112L, 112L, 120L, 174L,
119L, 112L), End.of.Rain.Season = c(228L, 229L, 240L, 228L, 228L,
228L)), .Names = c("Date", "Number.of.Rain.Days", "Total.rain",
"Start.of.Rain..i.", "Start.of.Rain..ii.", "Start.of.Rain..iii.",
"Start.Rain..iv.", "End.of.Rain.Season"), row.names = c(NA, 6L
), class = "data.frame")

 I think I need subset function then melt. Here is the approach I used:

d <- subset(df1,
select=c(Date,Start.of.Rain..i.,Start.of.Rain..ii.,Start.of.Rain..iii.))
d
d2 <- melt(d ,  id = 'Date', variable_name = 'Start')

ggplot(d2, aes(Date,value)) + geom_line(aes(colour = start),type = "h")

 but the error is:

Don't know how to automatically pick scale for object of type
function. Defaulting to continuousError in data.frame(colour =
function (x, ...)  :
  arguments imply differing number of rows: 0, 183


Thanks,

Frederic.



Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Tue, Mar 31, 2015 at 4:20 PM, stephen sefick <ssefick at gmail.com> wrote:

> Your data and post is still not provided in one of the formats provided
> here:
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example.
> I am unsure of what you want to do, but I have made a reproducible example
> that might help.
>
> zz <- "Date Number.of.Rain.Days Total.rain Start.of.Rain..i.
> Start.of.Rain..ii.   Start.of.Rain..iii.
>  1952-01-01                  86   1139.952                92
>  239                 11
>  1953-01-01                  96    977.646                98
>   98                 11
>  1954-01-01                 114   1382.014                92
>   92                 12
>  1955-01-01                 119   1323.086               100
>  100                 12
>  1956-01-01                 123   1266.444                92
>   92                 11
>  1957-01-01                 124   1235.964                92
>   92                 11"
>
> library(reshape)
> library(ggplot2)
>
> Data <- read.table(text=zz, header = TRUE)
>
> df1 <-data.frame(Data)
>
> df2 <- melt(df1 ,  id = c('Date', 'Number.of.Rain.Days'))
>
> df3 <- df2[-grep("Total.rain", df2$variable),]
>
> qplot(Date,value, data=df3) +facet_wrap(~variable)
>
> On Tue, Mar 31, 2015 at 2:55 AM, Frederic Ntirenganya <ntfredo at gmail.com>
> wrote:
>
>>  Hi All,
>>
>> Sorry for the shape of data which was not good enough.This is how my data look like.
>>
>> I want to plot multiple using ggplot function from a data frame of many columns. I want to plot only Start.of.Rain..i., Start.of.Rain..ii. and  Start.of.Rain..iii. and I failed to make it. What I want is to compare Start.of.Rain..i., Start.of.Rain..ii. and Start.of.Rain..iii. by plotting vertical line. I also need to add points to the plot to be able to separate them. The x-axis must be date column. Thanks!
>>
>> Here is how the data look like and how I tried to make it.
>>
>>
>>
>> Date Number.of.Rain.Days Total.rain Start.of.Rain..i. Start.of.Rain..ii.
>> Start.of.Rain..iii. 1952-01-01 86 1139.952 92 239 11 1953-01-01 96 977.646
>> 98 98 11 1954-01-01 114 1382.014 92 92 12 1955-01-01 119 1323.086 100 100
>> 12 1956-01-01 123 1266.444 92 92 11 1957-01-01 124 1235.964 92 92 11
>>
>>
>> Here is how I tried to solve the problem.
>>
>> df1 <-data.frame(data)
>> df1
>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>> df2
>>
>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type = "h")
>>
>> Kindly any help is welcome. Thanks
>>
>> Regards,
>> Frederic.
>>
>> Frederic Ntirenganya
>> Maseno University,
>> African Maths Initiative,
>> Kenya.
>> Mobile:(+254)718492836
>> Email: fredo at aims.ac.za
>> https://sites.google.com/a/aims.ac.za/fredo/
>>
>> On Tue, Mar 31, 2015 at 9:24 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us
>> > wrote:
>>
>>> This is no better because (a) you are still posting using HTML format,
>>> and (b) using printed output loses the internal representation of the data.
>>> The dput function is very helpful for solving this. [1]
>>>
>>> [1]
>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>                                       Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>>
>>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 30, 2015 10:56:48 PM PDT, Frederic Ntirenganya <
>>> ntfredo at gmail.com> wrote:
>>> >Hi Stephen,
>>> >
>>> >Sorry, the data came in bad way.
>>> >Here is the head of the data.
>>> >
>>> >> head(data)        Date Number.of.Rain.Days Total.rain
>>> >Start.of.Rain..i. Start.of.Rain..ii. Start.of.Rain..iii.
>>> >Start.Rain..iv.
>>> >1 1952-01-01                  86   1139.952                92
>>> >      239                 112             112
>>> >2 1953-01-01                  96    977.646                98
>>> >       98                 112             112
>>> >3 1954-01-01                 114   1382.014                92
>>> >       92                 120             120
>>> >4 1955-01-01                 119   1323.086               100
>>> >      100                 125             174
>>> >5 1956-01-01                 123   1266.444                92
>>> >       92                 119             119
>>> >6 1957-01-01                 124   1235.964                92
>>> >       92                 112             112
>>> >
>>> >
>>> >
>>> >Frederic Ntirenganya
>>> >Maseno University,
>>> >African Maths Initiative,
>>> >Kenya.
>>> >Mobile:(+254)718492836
>>> >Email: fredo at aims.ac.za
>>> >https://sites.google.com/a/aims.ac.za/fredo/
>>> >
>>> >On Mon, Mar 30, 2015 at 5:34 PM, stephen sefick <ssefick at gmail.com>
>>> >wrote:
>>> >
>>> >> Hi Frederic,
>>> >>
>>> >> Can you provide a minimal reproducible example including either real
>>> >data
>>> >> (dput), or simulated data that mimics your situation? This will allow
>>> >more
>>> >> people to help.
>>> >>
>>> >> Stephen
>>> >>
>>> >> On Mon, Mar 30, 2015 at 8:39 AM, Frederic Ntirenganya
>>> ><ntfredo at gmail.com>
>>> >> wrote:
>>> >>
>>> >>> Dear All,
>>> >>>
>>> >>> I want to plot multiple using ggplot function from a data frame of
>>> >>> many columns. I want to plot only str1, str2 and str3 and I failed
>>> >to
>>> >>> make it. What I want is to compare str1, str2 and str3 by plotting
>>> >>> vertical line. I also need to add points to the plot to be able to
>>> >>> separate them.
>>> >>>
>>> >>>
>>> >>> Here is how the data look like and how I tried to make it.
>>> >>>
>>> >>> Date NumberofRaindays TotalRains str1 str2 str3 1/1/1952 86 1360.5
>>> >92 120
>>> >>> 112 1/1/1953 96 1100 98 100 110
>>> >>> ...                                           ....
>>> >>> ....             ...              ....            ....
>>> >>>
>>> >>> df1 <-data.frame(data)
>>> >>> df1
>>> >>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>>> >>> df2
>>> >>>
>>> >>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type =
>>> >"h")
>>> >>>
>>> >>> Kindly any help is welcome. Thanks
>>> >>>
>>> >>> Regards,
>>> >>> Frederic.
>>> >>>
>>> >>> Frederic Ntirenganya
>>> >>> Maseno University,
>>> >>> African Maths Initiative,
>>> >>> Kenya.
>>> >>> Mobile:(+254)718492836
>>> >>> Email: fredo at aims.ac.za
>>> >>> https://sites.google.com/a/aims.ac.za/fredo/
>>> >>>
>>> >>>         [[alternative HTML version deleted]]
>>> >>>
>>> >>> ______________________________________________
>>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>> PLEASE do read the posting guide
>>> >>> http://www.R-project.org/posting-guide.html
>>> >>> and provide commented, minimal, self-contained, reproducible code.
>>> >>>
>>> >>
>>> >>
>>> >>
>>> >> --
>>> >> Stephen Sefick
>>> >> **************************************************
>>> >> Auburn University
>>> >> Biological Sciences
>>> >> 331 Funchess Hall
>>> >> Auburn, Alabama
>>> >> 36849
>>> >> **************************************************
>>> >> sas0025 at auburn.edu
>>> >> http://www.auburn.edu/~sas0025
>>> >> **************************************************
>>> >>
>>> >> Let's not spend our time and resources thinking about things that are
>>> >so
>>> >> little or so large that all they really do for us is puff us up and
>>> >make us
>>> >> feel like gods.  We are mammals, and have not exhausted the annoying
>>> >little
>>> >> problems of being mammals.
>>> >>
>>> >>                                 -K. Mullis
>>> >>
>>> >> "A big computer, a complex algorithm and a long time does not equal
>>> >> science."
>>> >>
>>> >>                               -Robert Gentleman
>>> >>
>>> >>
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> >______________________________________________
>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >PLEASE do read the posting guide
>>> >http://www.R-project.org/posting-guide.html
>>> >and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>
>
> --
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Tue Mar 31 15:48:51 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 31 Mar 2015 05:48:51 -0800
Subject: [R] Plotting using tapply function output
In-Reply-To: <CAHpsUFY9jtcTNH6=7_QMjqjzwuUz6063_0tYvT3CfU3kKmBUsg@mail.gmail.com>
Message-ID: <98D7FED3605.00000692jrkrideau@inbox.com>

Reproducibility
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example


John Kane
Kingston ON Canada


> -----Original Message-----
> From: amc5981 at gmail.com
> Sent: Mon, 30 Mar 2015 16:07:05 -0700
> To: r-help at r-project.org
> Subject: [R] Plotting using tapply function output
> 
> Hello,
> 
> I am trying to plot the hourly standard deviation of wind speeds from
> 13 different measured locations over many years. I imported the data
> using readLines and into a dataframe called finalData. Using tapply, I
> determined the standard deviation of the windspeed (ws) for each hour
> (hour) from every location (stn) using this command line:
> 
> statHour = tapply(finalData$ws,list(finalData$stn,finalData$hour),sd)
> 
> I want to plot the standard deviation for each hour of the day, with
> hours as the x-axis and the standard deviation for the y-axis, and
> each station as a different color.  I've managed to get a boxplot of
> this, but ideally, I'd like a scatter plot to determine the variations
> between each instrument throughout the day.  The boxplot command is
> this:
> 
> boxplot(statHour, names=colnames(statHour),xlab='Hour of the
> Day',ylab='Standard Deviation of Wind Speed')
> 
> I also tried to make a dataframe of the tapply output but it ends up
> using the hours as the column names instead of putting it into the
> dataframe.  Please help!!
> 
> I have R version 3.1.1
> 
> Thanks a lot,
> Alexandra
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From ntfredo at gmail.com  Tue Mar 31 15:55:56 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 31 Mar 2015 16:55:56 +0300
Subject: [R] Multiple Plots using ggplot
In-Reply-To: <CAGh51gT9Nw0-+vF6GVWgvV0VwndxXy3COBeXu6hYpbu8_yUYcw@mail.gmail.com>
References: <CAGh51gS7eX0QggStQ+G=1VW=Z48vRSfK9XzDSpH47bGfnaO-LA@mail.gmail.com>
	<CADKEMqhsaeDC9S1fZVdefm-P2mFwFEPJYFGp0e-=Fh=XR+y48Q@mail.gmail.com>
	<CAGh51gR5psHsbW1raEru6PpG=nt8u40rr2Q_0nW34nuh91GbSg@mail.gmail.com>
	<4BB41E12-07C6-491B-90A3-38894C7A7761@dcn.davis.CA.us>
	<CAGh51gR0vT4b0GKNea=DO6cwyug_mPhzQZ3txXi+=Q9eggUkUQ@mail.gmail.com>
	<CADKEMqjLk-j0w5f=A=013NjXyEcj5LHwe8JjG756Y-Vnx3scSw@mail.gmail.com>
	<CAGh51gT9Nw0-+vF6GVWgvV0VwndxXy3COBeXu6hYpbu8_yUYcw@mail.gmail.com>
Message-ID: <CAGh51gRKvcLPe5BSGXam8Sedo0o=Qdo0oT1dLcqYGN4m2byihA@mail.gmail.com>

Hi John,

Sorry for the mistake I made for providing useless data.
Here I am interest only on Tmin and Tmax columns. I want to use the same
approach with the previous data. I want to plot on the same graph not
separate graph. Thanks

> dput(head(BUTemp))structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L
), Month = c(2L, 2L, 2L, 2L, 2L, 2L), Day = 1:6, Rain = c(0,
0, 0, 0, 0, 0), Tmax = c(24.3, 25, 25.6, 26.5, 27.8, 27.5), Tmin = c(13.5,
13.2, 12.7, 12.7, 12.2, 14)), .Names = c("Year", "Month", "Day",
"Rain", "Tmax", "Tmin"), row.names = c(NA, 6L), class = "data.frame")

Regards,

Frederic.



Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Tue, Mar 31, 2015 at 4:46 PM, Frederic Ntirenganya <ntfredo at gmail.com>
wrote:

> Hi All,
>
> Thanks for the help. I want to plot some of the columns on the same graph
> not all of them. Sorry, I failed to follow the instructions. Here is the
> output of *dput()* but I don't know how it works.
>
> > dput(head(data))structure(list(Date = structure(c(-6575, -6209, -5844, -5479,
> -5114, -4748), class = "Date"), Number.of.Rain.Days = c(86L,
> 96L, 114L, 119L, 123L, 124L), Total.rain = c(1139.952, 977.646,
> 1382.014, 1323.086, 1266.444, 1235.964), Start.of.Rain..i. = c(92L,
> 98L, 92L, 100L, 92L, 92L), Start.of.Rain..ii. = c(239L, 98L,
> 92L, 100L, 92L, 92L), Start.of.Rain..iii. = c(112L, 112L, 120L,
> 125L, 119L, 112L), Start.Rain..iv. = c(112L, 112L, 120L, 174L,
> 119L, 112L), End.of.Rain.Season = c(228L, 229L, 240L, 228L, 228L,
> 228L)), .Names = c("Date", "Number.of.Rain.Days", "Total.rain",
> "Start.of.Rain..i.", "Start.of.Rain..ii.", "Start.of.Rain..iii.",
> "Start.Rain..iv.", "End.of.Rain.Season"), row.names = c(NA, 6L
> ), class = "data.frame")
>
>  I think I need subset function then melt. Here is the approach I used:
>
> d <- subset(df1, select=c(Date,Start.of.Rain..i.,Start.of.Rain..ii.,Start.of.Rain..iii.))
> d
> d2 <- melt(d ,  id = 'Date', variable_name = 'Start')
>
> ggplot(d2, aes(Date,value)) + geom_line(aes(colour = start),type = "h")
>
>  but the error is:
>
> Don't know how to automatically pick scale for object of type function. Defaulting to continuousError in data.frame(colour = function (x, ...)  :
>   arguments imply differing number of rows: 0, 183
>
>
> Thanks,
>
> Frederic.
>
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> On Tue, Mar 31, 2015 at 4:20 PM, stephen sefick <ssefick at gmail.com> wrote:
>
>> Your data and post is still not provided in one of the formats provided
>> here:
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example.
>> I am unsure of what you want to do, but I have made a reproducible example
>> that might help.
>>
>> zz <- "Date Number.of.Rain.Days Total.rain Start.of.Rain..i.
>> Start.of.Rain..ii.   Start.of.Rain..iii.
>>  1952-01-01                  86   1139.952                92
>>    239                 11
>>  1953-01-01                  96    977.646                98
>>     98                 11
>>  1954-01-01                 114   1382.014                92
>>     92                 12
>>  1955-01-01                 119   1323.086               100
>>    100                 12
>>  1956-01-01                 123   1266.444                92
>>     92                 11
>>  1957-01-01                 124   1235.964                92
>>     92                 11"
>>
>> library(reshape)
>> library(ggplot2)
>>
>> Data <- read.table(text=zz, header = TRUE)
>>
>> df1 <-data.frame(Data)
>>
>> df2 <- melt(df1 ,  id = c('Date', 'Number.of.Rain.Days'))
>>
>> df3 <- df2[-grep("Total.rain", df2$variable),]
>>
>> qplot(Date,value, data=df3) +facet_wrap(~variable)
>>
>> On Tue, Mar 31, 2015 at 2:55 AM, Frederic Ntirenganya <ntfredo at gmail.com>
>> wrote:
>>
>>>  Hi All,
>>>
>>> Sorry for the shape of data which was not good enough.This is how my data look like.
>>>
>>> I want to plot multiple using ggplot function from a data frame of many columns. I want to plot only Start.of.Rain..i., Start.of.Rain..ii. and  Start.of.Rain..iii. and I failed to make it. What I want is to compare Start.of.Rain..i., Start.of.Rain..ii. and Start.of.Rain..iii. by plotting vertical line. I also need to add points to the plot to be able to separate them. The x-axis must be date column. Thanks!
>>>
>>> Here is how the data look like and how I tried to make it.
>>>
>>>
>>>
>>> Date Number.of.Rain.Days Total.rain Start.of.Rain..i. Start.of.Rain..ii.
>>> Start.of.Rain..iii. 1952-01-01 86 1139.952 92 239 11 1953-01-01 96 977.646
>>> 98 98 11 1954-01-01 114 1382.014 92 92 12 1955-01-01 119 1323.086 100 100
>>> 12 1956-01-01 123 1266.444 92 92 11 1957-01-01 124 1235.964 92 92 11
>>>
>>>
>>> Here is how I tried to solve the problem.
>>>
>>> df1 <-data.frame(data)
>>> df1
>>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>>> df2
>>>
>>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type = "h")
>>>
>>> Kindly any help is welcome. Thanks
>>>
>>> Regards,
>>> Frederic.
>>>
>>> Frederic Ntirenganya
>>> Maseno University,
>>> African Maths Initiative,
>>> Kenya.
>>> Mobile:(+254)718492836
>>> Email: fredo at aims.ac.za
>>> https://sites.google.com/a/aims.ac.za/fredo/
>>>
>>> On Tue, Mar 31, 2015 at 9:24 AM, Jeff Newmiller <
>>> jdnewmil at dcn.davis.ca.us> wrote:
>>>
>>>> This is no better because (a) you are still posting using HTML format,
>>>> and (b) using printed output loses the internal representation of the data.
>>>> The dput function is very helpful for solving this. [1]
>>>>
>>>> [1]
>>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>>
>>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>> Go...
>>>>                                       Live:   OO#.. Dead: OO#..  Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>> rocks...1k
>>>>
>>>> ---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On March 30, 2015 10:56:48 PM PDT, Frederic Ntirenganya <
>>>> ntfredo at gmail.com> wrote:
>>>> >Hi Stephen,
>>>> >
>>>> >Sorry, the data came in bad way.
>>>> >Here is the head of the data.
>>>> >
>>>> >> head(data)        Date Number.of.Rain.Days Total.rain
>>>> >Start.of.Rain..i. Start.of.Rain..ii. Start.of.Rain..iii.
>>>> >Start.Rain..iv.
>>>> >1 1952-01-01                  86   1139.952                92
>>>> >      239                 112             112
>>>> >2 1953-01-01                  96    977.646                98
>>>> >       98                 112             112
>>>> >3 1954-01-01                 114   1382.014                92
>>>> >       92                 120             120
>>>> >4 1955-01-01                 119   1323.086               100
>>>> >      100                 125             174
>>>> >5 1956-01-01                 123   1266.444                92
>>>> >       92                 119             119
>>>> >6 1957-01-01                 124   1235.964                92
>>>> >       92                 112             112
>>>> >
>>>> >
>>>> >
>>>> >Frederic Ntirenganya
>>>> >Maseno University,
>>>> >African Maths Initiative,
>>>> >Kenya.
>>>> >Mobile:(+254)718492836
>>>> >Email: fredo at aims.ac.za
>>>> >https://sites.google.com/a/aims.ac.za/fredo/
>>>> >
>>>> >On Mon, Mar 30, 2015 at 5:34 PM, stephen sefick <ssefick at gmail.com>
>>>> >wrote:
>>>> >
>>>> >> Hi Frederic,
>>>> >>
>>>> >> Can you provide a minimal reproducible example including either real
>>>> >data
>>>> >> (dput), or simulated data that mimics your situation? This will allow
>>>> >more
>>>> >> people to help.
>>>> >>
>>>> >> Stephen
>>>> >>
>>>> >> On Mon, Mar 30, 2015 at 8:39 AM, Frederic Ntirenganya
>>>> ><ntfredo at gmail.com>
>>>> >> wrote:
>>>> >>
>>>> >>> Dear All,
>>>> >>>
>>>> >>> I want to plot multiple using ggplot function from a data frame of
>>>> >>> many columns. I want to plot only str1, str2 and str3 and I failed
>>>> >to
>>>> >>> make it. What I want is to compare str1, str2 and str3 by plotting
>>>> >>> vertical line. I also need to add points to the plot to be able to
>>>> >>> separate them.
>>>> >>>
>>>> >>>
>>>> >>> Here is how the data look like and how I tried to make it.
>>>> >>>
>>>> >>> Date NumberofRaindays TotalRains str1 str2 str3 1/1/1952 86 1360.5
>>>> >92 120
>>>> >>> 112 1/1/1953 96 1100 98 100 110
>>>> >>> ...                                           ....
>>>> >>> ....             ...              ....            ....
>>>> >>>
>>>> >>> df1 <-data.frame(data)
>>>> >>> df1
>>>> >>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>>>> >>> df2
>>>> >>>
>>>> >>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type =
>>>> >"h")
>>>> >>>
>>>> >>> Kindly any help is welcome. Thanks
>>>> >>>
>>>> >>> Regards,
>>>> >>> Frederic.
>>>> >>>
>>>> >>> Frederic Ntirenganya
>>>> >>> Maseno University,
>>>> >>> African Maths Initiative,
>>>> >>> Kenya.
>>>> >>> Mobile:(+254)718492836
>>>> >>> Email: fredo at aims.ac.za
>>>> >>> https://sites.google.com/a/aims.ac.za/fredo/
>>>> >>>
>>>> >>>         [[alternative HTML version deleted]]
>>>> >>>
>>>> >>> ______________________________________________
>>>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>> PLEASE do read the posting guide
>>>> >>> http://www.R-project.org/posting-guide.html
>>>> >>> and provide commented, minimal, self-contained, reproducible code.
>>>> >>>
>>>> >>
>>>> >>
>>>> >>
>>>> >> --
>>>> >> Stephen Sefick
>>>> >> **************************************************
>>>> >> Auburn University
>>>> >> Biological Sciences
>>>> >> 331 Funchess Hall
>>>> >> Auburn, Alabama
>>>> >> 36849
>>>> >> **************************************************
>>>> >> sas0025 at auburn.edu
>>>> >> http://www.auburn.edu/~sas0025
>>>> >> **************************************************
>>>> >>
>>>> >> Let's not spend our time and resources thinking about things that are
>>>> >so
>>>> >> little or so large that all they really do for us is puff us up and
>>>> >make us
>>>> >> feel like gods.  We are mammals, and have not exhausted the annoying
>>>> >little
>>>> >> problems of being mammals.
>>>> >>
>>>> >>                                 -K. Mullis
>>>> >>
>>>> >> "A big computer, a complex algorithm and a long time does not equal
>>>> >> science."
>>>> >>
>>>> >>                               -Robert Gentleman
>>>> >>
>>>> >>
>>>> >
>>>> >       [[alternative HTML version deleted]]
>>>> >
>>>> >______________________________________________
>>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >PLEASE do read the posting guide
>>>> >http://www.R-project.org/posting-guide.html
>>>> >and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>
>>
>> --
>> Stephen Sefick
>> **************************************************
>> Auburn University
>> Biological Sciences
>> 331 Funchess Hall
>> Auburn, Alabama
>> 36849
>> **************************************************
>> sas0025 at auburn.edu
>> http://www.auburn.edu/~sas0025
>> **************************************************
>>
>> Let's not spend our time and resources thinking about things that are so
>> little or so large that all they really do for us is puff us up and make us
>> feel like gods.  We are mammals, and have not exhausted the annoying little
>> problems of being mammals.
>>
>>                                 -K. Mullis
>>
>> "A big computer, a complex algorithm and a long time does not equal
>> science."
>>
>>                               -Robert Gentleman
>>
>>
>

	[[alternative HTML version deleted]]


From ssefick at gmail.com  Tue Mar 31 15:57:13 2015
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 31 Mar 2015 08:57:13 -0500
Subject: [R] Multiple Plots using ggplot
In-Reply-To: <CAGh51gT9Nw0-+vF6GVWgvV0VwndxXy3COBeXu6hYpbu8_yUYcw@mail.gmail.com>
References: <CAGh51gS7eX0QggStQ+G=1VW=Z48vRSfK9XzDSpH47bGfnaO-LA@mail.gmail.com>
	<CADKEMqhsaeDC9S1fZVdefm-P2mFwFEPJYFGp0e-=Fh=XR+y48Q@mail.gmail.com>
	<CAGh51gR5psHsbW1raEru6PpG=nt8u40rr2Q_0nW34nuh91GbSg@mail.gmail.com>
	<4BB41E12-07C6-491B-90A3-38894C7A7761@dcn.davis.CA.us>
	<CAGh51gR0vT4b0GKNea=DO6cwyug_mPhzQZ3txXi+=Q9eggUkUQ@mail.gmail.com>
	<CADKEMqjLk-j0w5f=A=013NjXyEcj5LHwe8JjG756Y-Vnx3scSw@mail.gmail.com>
	<CAGh51gT9Nw0-+vF6GVWgvV0VwndxXy3COBeXu6hYpbu8_yUYcw@mail.gmail.com>
Message-ID: <CADKEMqjbjKP=Nxqo87Q35Bmk_L9Aq3Usod1LJdRCpcQ7KuU2xg@mail.gmail.com>

The error message is very informative. You named a column in the melted
data "Start", and told ggplot to use "start". "start" is a function. R is
case sensitive.

On Tue, Mar 31, 2015 at 8:46 AM, Frederic Ntirenganya <ntfredo at gmail.com>
wrote:

> Hi All,
>
> Thanks for the help. I want to plot some of the columns on the same graph
> not all of them. Sorry, I failed to follow the instructions. Here is the
> output of *dput()* but I don't know how it works.
>
> > dput(head(data))structure(list(Date = structure(c(-6575, -6209, -5844, -5479,
> -5114, -4748), class = "Date"), Number.of.Rain.Days = c(86L,
> 96L, 114L, 119L, 123L, 124L), Total.rain = c(1139.952, 977.646,
> 1382.014, 1323.086, 1266.444, 1235.964), Start.of.Rain..i. = c(92L,
> 98L, 92L, 100L, 92L, 92L), Start.of.Rain..ii. = c(239L, 98L,
> 92L, 100L, 92L, 92L), Start.of.Rain..iii. = c(112L, 112L, 120L,
> 125L, 119L, 112L), Start.Rain..iv. = c(112L, 112L, 120L, 174L,
> 119L, 112L), End.of.Rain.Season = c(228L, 229L, 240L, 228L, 228L,
> 228L)), .Names = c("Date", "Number.of.Rain.Days", "Total.rain",
> "Start.of.Rain..i.", "Start.of.Rain..ii.", "Start.of.Rain..iii.",
> "Start.Rain..iv.", "End.of.Rain.Season"), row.names = c(NA, 6L
> ), class = "data.frame")
>
>  I think I need subset function then melt. Here is the approach I used:
>
> d <- subset(df1, select=c(Date,Start.of.Rain..i.,Start.of.Rain..ii.,Start.of.Rain..iii.))
> d
> d2 <- melt(d ,  id = 'Date', variable_name = 'Start')
>
> ggplot(d2, aes(Date,value)) + geom_line(aes(colour = start),type = "h")
>
>  but the error is:
>
> Don't know how to automatically pick scale for object of type function. Defaulting to continuousError in data.frame(colour = function (x, ...)  :
>   arguments imply differing number of rows: 0, 183
>
>
> Thanks,
>
> Frederic.
>
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> On Tue, Mar 31, 2015 at 4:20 PM, stephen sefick <ssefick at gmail.com> wrote:
>
>> Your data and post is still not provided in one of the formats provided
>> here:
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example.
>> I am unsure of what you want to do, but I have made a reproducible example
>> that might help.
>>
>> zz <- "Date Number.of.Rain.Days Total.rain Start.of.Rain..i.
>> Start.of.Rain..ii.   Start.of.Rain..iii.
>>  1952-01-01                  86   1139.952                92
>>    239                 11
>>  1953-01-01                  96    977.646                98
>>     98                 11
>>  1954-01-01                 114   1382.014                92
>>     92                 12
>>  1955-01-01                 119   1323.086               100
>>    100                 12
>>  1956-01-01                 123   1266.444                92
>>     92                 11
>>  1957-01-01                 124   1235.964                92
>>     92                 11"
>>
>> library(reshape)
>> library(ggplot2)
>>
>> Data <- read.table(text=zz, header = TRUE)
>>
>> df1 <-data.frame(Data)
>>
>> df2 <- melt(df1 ,  id = c('Date', 'Number.of.Rain.Days'))
>>
>> df3 <- df2[-grep("Total.rain", df2$variable),]
>>
>> qplot(Date,value, data=df3) +facet_wrap(~variable)
>>
>> On Tue, Mar 31, 2015 at 2:55 AM, Frederic Ntirenganya <ntfredo at gmail.com>
>> wrote:
>>
>>>  Hi All,
>>>
>>> Sorry for the shape of data which was not good enough.This is how my data look like.
>>>
>>> I want to plot multiple using ggplot function from a data frame of many columns. I want to plot only Start.of.Rain..i., Start.of.Rain..ii. and  Start.of.Rain..iii. and I failed to make it. What I want is to compare Start.of.Rain..i., Start.of.Rain..ii. and Start.of.Rain..iii. by plotting vertical line. I also need to add points to the plot to be able to separate them. The x-axis must be date column. Thanks!
>>>
>>> Here is how the data look like and how I tried to make it.
>>>
>>>
>>>
>>> Date Number.of.Rain.Days Total.rain Start.of.Rain..i. Start.of.Rain..ii.
>>> Start.of.Rain..iii. 1952-01-01 86 1139.952 92 239 11 1953-01-01 96 977.646
>>> 98 98 11 1954-01-01 114 1382.014 92 92 12 1955-01-01 119 1323.086 100 100
>>> 12 1956-01-01 123 1266.444 92 92 11 1957-01-01 124 1235.964 92 92 11
>>>
>>>
>>> Here is how I tried to solve the problem.
>>>
>>> df1 <-data.frame(data)
>>> df1
>>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>>> df2
>>>
>>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type = "h")
>>>
>>> Kindly any help is welcome. Thanks
>>>
>>> Regards,
>>> Frederic.
>>>
>>> Frederic Ntirenganya
>>> Maseno University,
>>> African Maths Initiative,
>>> Kenya.
>>> Mobile:(+254)718492836
>>> Email: fredo at aims.ac.za
>>> https://sites.google.com/a/aims.ac.za/fredo/
>>>
>>> On Tue, Mar 31, 2015 at 9:24 AM, Jeff Newmiller <
>>> jdnewmil at dcn.davis.ca.us> wrote:
>>>
>>>> This is no better because (a) you are still posting using HTML format,
>>>> and (b) using printed output loses the internal representation of the data.
>>>> The dput function is very helpful for solving this. [1]
>>>>
>>>> [1]
>>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>>
>>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>> Go...
>>>>                                       Live:   OO#.. Dead: OO#..  Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>> rocks...1k
>>>>
>>>> ---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On March 30, 2015 10:56:48 PM PDT, Frederic Ntirenganya <
>>>> ntfredo at gmail.com> wrote:
>>>> >Hi Stephen,
>>>> >
>>>> >Sorry, the data came in bad way.
>>>> >Here is the head of the data.
>>>> >
>>>> >> head(data)        Date Number.of.Rain.Days Total.rain
>>>> >Start.of.Rain..i. Start.of.Rain..ii. Start.of.Rain..iii.
>>>> >Start.Rain..iv.
>>>> >1 1952-01-01                  86   1139.952                92
>>>> >      239                 112             112
>>>> >2 1953-01-01                  96    977.646                98
>>>> >       98                 112             112
>>>> >3 1954-01-01                 114   1382.014                92
>>>> >       92                 120             120
>>>> >4 1955-01-01                 119   1323.086               100
>>>> >      100                 125             174
>>>> >5 1956-01-01                 123   1266.444                92
>>>> >       92                 119             119
>>>> >6 1957-01-01                 124   1235.964                92
>>>> >       92                 112             112
>>>> >
>>>> >
>>>> >
>>>> >Frederic Ntirenganya
>>>> >Maseno University,
>>>> >African Maths Initiative,
>>>> >Kenya.
>>>> >Mobile:(+254)718492836
>>>> >Email: fredo at aims.ac.za
>>>> >https://sites.google.com/a/aims.ac.za/fredo/
>>>> >
>>>> >On Mon, Mar 30, 2015 at 5:34 PM, stephen sefick <ssefick at gmail.com>
>>>> >wrote:
>>>> >
>>>> >> Hi Frederic,
>>>> >>
>>>> >> Can you provide a minimal reproducible example including either real
>>>> >data
>>>> >> (dput), or simulated data that mimics your situation? This will allow
>>>> >more
>>>> >> people to help.
>>>> >>
>>>> >> Stephen
>>>> >>
>>>> >> On Mon, Mar 30, 2015 at 8:39 AM, Frederic Ntirenganya
>>>> ><ntfredo at gmail.com>
>>>> >> wrote:
>>>> >>
>>>> >>> Dear All,
>>>> >>>
>>>> >>> I want to plot multiple using ggplot function from a data frame of
>>>> >>> many columns. I want to plot only str1, str2 and str3 and I failed
>>>> >to
>>>> >>> make it. What I want is to compare str1, str2 and str3 by plotting
>>>> >>> vertical line. I also need to add points to the plot to be able to
>>>> >>> separate them.
>>>> >>>
>>>> >>>
>>>> >>> Here is how the data look like and how I tried to make it.
>>>> >>>
>>>> >>> Date NumberofRaindays TotalRains str1 str2 str3 1/1/1952 86 1360.5
>>>> >92 120
>>>> >>> 112 1/1/1953 96 1100 98 100 110
>>>> >>> ...                                           ....
>>>> >>> ....             ...              ....            ....
>>>> >>>
>>>> >>> df1 <-data.frame(data)
>>>> >>> df1
>>>> >>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>>>> >>> df2
>>>> >>>
>>>> >>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type =
>>>> >"h")
>>>> >>>
>>>> >>> Kindly any help is welcome. Thanks
>>>> >>>
>>>> >>> Regards,
>>>> >>> Frederic.
>>>> >>>
>>>> >>> Frederic Ntirenganya
>>>> >>> Maseno University,
>>>> >>> African Maths Initiative,
>>>> >>> Kenya.
>>>> >>> Mobile:(+254)718492836
>>>> >>> Email: fredo at aims.ac.za
>>>> >>> https://sites.google.com/a/aims.ac.za/fredo/
>>>> >>>
>>>> >>>         [[alternative HTML version deleted]]
>>>> >>>
>>>> >>> ______________________________________________
>>>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>> PLEASE do read the posting guide
>>>> >>> http://www.R-project.org/posting-guide.html
>>>> >>> and provide commented, minimal, self-contained, reproducible code.
>>>> >>>
>>>> >>
>>>> >>
>>>> >>
>>>> >> --
>>>> >> Stephen Sefick
>>>> >> **************************************************
>>>> >> Auburn University
>>>> >> Biological Sciences
>>>> >> 331 Funchess Hall
>>>> >> Auburn, Alabama
>>>> >> 36849
>>>> >> **************************************************
>>>> >> sas0025 at auburn.edu
>>>> >> http://www.auburn.edu/~sas0025
>>>> >> **************************************************
>>>> >>
>>>> >> Let's not spend our time and resources thinking about things that are
>>>> >so
>>>> >> little or so large that all they really do for us is puff us up and
>>>> >make us
>>>> >> feel like gods.  We are mammals, and have not exhausted the annoying
>>>> >little
>>>> >> problems of being mammals.
>>>> >>
>>>> >>                                 -K. Mullis
>>>> >>
>>>> >> "A big computer, a complex algorithm and a long time does not equal
>>>> >> science."
>>>> >>
>>>> >>                               -Robert Gentleman
>>>> >>
>>>> >>
>>>> >
>>>> >       [[alternative HTML version deleted]]
>>>> >
>>>> >______________________________________________
>>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >PLEASE do read the posting guide
>>>> >http://www.R-project.org/posting-guide.html
>>>> >and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>
>>
>> --
>> Stephen Sefick
>> **************************************************
>> Auburn University
>> Biological Sciences
>> 331 Funchess Hall
>> Auburn, Alabama
>> 36849
>> **************************************************
>> sas0025 at auburn.edu
>> http://www.auburn.edu/~sas0025
>> **************************************************
>>
>> Let's not spend our time and resources thinking about things that are so
>> little or so large that all they really do for us is puff us up and make us
>> feel like gods.  We are mammals, and have not exhausted the annoying little
>> problems of being mammals.
>>
>>                                 -K. Mullis
>>
>> "A big computer, a complex algorithm and a long time does not equal
>> science."
>>
>>                               -Robert Gentleman
>>
>>
>


-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Tue Mar 31 16:32:00 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 31 Mar 2015 06:32:00 -0800
Subject: [R] Multiple Plots using ggplot
In-Reply-To: <CAGh51gRKvcLPe5BSGXam8Sedo0o=Qdo0oT1dLcqYGN4m2byihA@mail.gmail.com>
References: <cadkemqjlk-j0w5f=a=013njxyecj5lhwe8jjg756y-vnx3scsw@mail.gmail.com>
	<cagh51gr0vt4b0gknea=do6cwyug_mphzqz3txxi+=q9eggukuq@mail.gmail.com>
	<cagh51gt9nw0-+vf6gvwgvv0vwndxxy3cobexu6hypbu8_yuycw@mail.gmail.com>
	<cagh51gs7ex0qggstq+g=1vw=z48vrsfk9xzdsph47bgfnao-la@mail.gmail.com>
	<cagh51gr5pshsbw1raeru6ppg=nt8u40rr2q_0nw34nuh91gbsg@mail.gmail.com>
	<4bb41e12-07c6-491b-90a3-38894c7a7761@dcn.davis.ca.us>
	<cadkemqhsaedc9s1fzvdefm-p2mfwfepjyfgp0e-=fh=xr+y48q@mail.gmail.com>
Message-ID: <993877E7CD9.00000746jrkrideau@inbox.com>

Hi Frederic,

Thanks for sending the data in dput() format. All it does in convert a data set into a standardized format (perfect copy) that anyone with R can read. People have different setups and defaults for reading data and so on and what you may read in to R as a character variable may be a factor when I read it it in and we can have some serious problems just trying to decide what the data looks like. 

I had a look at your code and it is confused. See my comments below

d <- subset(df1, select=c(Date,Start.of.Rain..i.,Start.of.Rain..ii.,Start.of.Rain..iii.)) 

d 

d2 <- melt(d , id = 'Date', variable_name = 'Start') 

# You do not have any variable in your data.frame called ?Start?

# Reshape2 seems to have just ignored ?variable_name = 'Start' and did the melt based on id = 'Date'. Strange, I would have expected an error but it worked !

d2 <- melt(d , id = 'Date') will give you exactly the same result.

ggplot(d2, aes(Date,value)) + geom_line(aes(colour = start),type = "h") 

Again you do not have a variable (column name) called 'start'. You have three column names (variables) in d2 These are "Date" "variable" and "value" .

ggplot(d2, aes(Date,value)) + geom_line(aes(colour = start),type = "h") 

Point one, you have no variable called start.  

Point two, what is type = ?h? doing here? It is, as far as I can see not an option in geom_line for such an option. See ?geom_line for this point.

 I think you are confusing basic graphics commands ("type =")  with ggplot commands. Have a look at http://www.cookbook-r.com/Graphs/Shapes_and_line_types/ for some examples that show the differences.

Below is what I think you may be trying to do (note I use dat1 for the data.frame rather than your df1).

###==============================================
dat1  <-  structure(list(Date = structure(c(-6575, -6209, -5844, -5479,
-5114, -4748), class = "Date"), Number.of.Rain.Days = c(86L,
96L, 114L, 119L, 123L, 124L), Total.rain = c(1139.952, 977.646,
1382.014, 1323.086, 1266.444, 1235.964), Start.of.Rain..i. = c(92L,
98L, 92L, 100L, 92L, 92L), Start.of.Rain..ii. = c(239L, 98L,
92L, 100L, 92L, 92L), Start.of.Rain..iii. = c(112L, 112L, 120L,
125L, 119L, 112L), Start.Rain..iv. = c(112L, 112L, 120L, 174L,
119L, 112L), End.of.Rain.Season = c(228L, 229L, 240L, 228L, 228L,
228L)), .Names = c("Date", "Number.of.Rain.Days", "Total.rain",
"Start.of.Rain..i.", "Start.of.Rain..ii.", "Start.of.Rain..iii.",
"Start.Rain..iv.", "End.of.Rain.Season"), row.names = c(NA, 6L
), class = "data.frame")

dd <- subset(dat1, select=c(Date,Start.of.Rain..i.,Start.of.Rain..ii.,Start.of.Rain..iii.))

d2 <- melt(dd ,  id = 'Date')

ggplot(d2, aes(Date,value)) + geom_line(aes(colour = variable))

ggplot(d2, aes(Date, value)) + 
           geom_histogram(  position="dodge",  stat = "identity", aes(fill = variable))

##============================================
John Kane
Kingston ON Canada


> -----Original Message-----
> From: ntfredo at gmail.com
> Sent: Tue, 31 Mar 2015 16:55:56 +0300
> To: ssefick at gmail.com
> Subject: Re: [R] Multiple Plots using ggplot
> 
> Hi John,
> 
> Sorry for the mistake I made for providing useless data.
> Here I am interest only on Tmin and Tmax columns. I want to use the same
> approach with the previous data. I want to plot on the same graph not
> separate graph. Thanks
> 
>> dput(head(BUTemp))structure(list(Year = c(1971L, 1971L, 1971L, 1971L,
>> 1971L, 1971L
> ), Month = c(2L, 2L, 2L, 2L, 2L, 2L), Day = 1:6, Rain = c(0,
> 0, 0, 0, 0, 0), Tmax = c(24.3, 25, 25.6, 26.5, 27.8, 27.5), Tmin =
> c(13.5,
> 13.2, 12.7, 12.7, 12.2, 14)), .Names = c("Year", "Month", "Day",
> "Rain", "Tmax", "Tmin"), row.names = c(NA, 6L), class = "data.frame")
> 
> Regards,
> 
> Frederic.
> 
> 
> 
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
> 
> On Tue, Mar 31, 2015 at 4:46 PM, Frederic Ntirenganya <ntfredo at gmail.com>
> wrote:
> 
>> Hi All,
>> 
>> Thanks for the help. I want to plot some of the columns on the same
>> graph
>> not all of them. Sorry, I failed to follow the instructions. Here is the
>> output of *dput()* but I don't know how it works.
>> 
>>> dput(head(data))structure(list(Date = structure(c(-6575, -6209, -5844,
>>> -5479,
>> -5114, -4748), class = "Date"), Number.of.Rain.Days = c(86L,
>> 96L, 114L, 119L, 123L, 124L), Total.rain = c(1139.952, 977.646,
>> 1382.014, 1323.086, 1266.444, 1235.964), Start.of.Rain..i. = c(92L,
>> 98L, 92L, 100L, 92L, 92L), Start.of.Rain..ii. = c(239L, 98L,
>> 92L, 100L, 92L, 92L), Start.of.Rain..iii. = c(112L, 112L, 120L,
>> 125L, 119L, 112L), Start.Rain..iv. = c(112L, 112L, 120L, 174L,
>> 119L, 112L), End.of.Rain.Season = c(228L, 229L, 240L, 228L, 228L,
>> 228L)), .Names = c("Date", "Number.of.Rain.Days", "Total.rain",
>> "Start.of.Rain..i.", "Start.of.Rain..ii.", "Start.of.Rain..iii.",
>> "Start.Rain..iv.", "End.of.Rain.Season"), row.names = c(NA, 6L
>> ), class = "data.frame")
>> 
>>  I think I need subset function then melt. Here is the approach I used:
>> 
>> d <- subset(df1,
>> select=c(Date,Start.of.Rain..i.,Start.of.Rain..ii.,Start.of.Rain..iii.))
>> d
>> d2 <- melt(d ,  id = 'Date', variable_name = 'Start')
>> 
>> ggplot(d2, aes(Date,value)) + geom_line(aes(colour = start),type = "h")
>> 
>>  but the error is:
>> 
>> Don't know how to automatically pick scale for object of type function.
>> Defaulting to continuousError in data.frame(colour = function (x, ...)
>> :
>>   arguments imply differing number of rows: 0, 183
>> 
>> 
>> Thanks,
>> 
>> Frederic.
>> 
>> 
>> 
>> Frederic Ntirenganya
>> Maseno University,
>> African Maths Initiative,
>> Kenya.
>> Mobile:(+254)718492836
>> Email: fredo at aims.ac.za
>> https://sites.google.com/a/aims.ac.za/fredo/
>> 
>> On Tue, Mar 31, 2015 at 4:20 PM, stephen sefick <ssefick at gmail.com>
>> wrote:
>> 
>>> Your data and post is still not provided in one of the formats provided
>>> here:
>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example.
>>> I am unsure of what you want to do, but I have made a reproducible
>>> example
>>> that might help.
>>> 
>>> zz <- "Date Number.of.Rain.Days Total.rain Start.of.Rain..i.
>>> Start.of.Rain..ii.   Start.of.Rain..iii.
>>>  1952-01-01                  86   1139.952                92
>>>    239                 11
>>>  1953-01-01                  96    977.646                98
>>>     98                 11
>>>  1954-01-01                 114   1382.014                92
>>>     92                 12
>>>  1955-01-01                 119   1323.086               100
>>>    100                 12
>>>  1956-01-01                 123   1266.444                92
>>>     92                 11
>>>  1957-01-01                 124   1235.964                92
>>>     92                 11"
>>> 
>>> library(reshape)
>>> library(ggplot2)
>>> 
>>> Data <- read.table(text=zz, header = TRUE)
>>> 
>>> df1 <-data.frame(Data)
>>> 
>>> df2 <- melt(df1 ,  id = c('Date', 'Number.of.Rain.Days'))
>>> 
>>> df3 <- df2[-grep("Total.rain", df2$variable),]
>>> 
>>> qplot(Date,value, data=df3) +facet_wrap(~variable)
>>> 
>>> On Tue, Mar 31, 2015 at 2:55 AM, Frederic Ntirenganya
>>> <ntfredo at gmail.com>
>>> wrote:
>>> 
>>>>  Hi All,
>>>> 
>>>> Sorry for the shape of data which was not good enough.This is how my
>>>> data look like.
>>>> 
>>>> I want to plot multiple using ggplot function from a data frame of
>>>> many columns. I want to plot only Start.of.Rain..i.,
>>>> Start.of.Rain..ii. and  Start.of.Rain..iii. and I failed to make it.
>>>> What I want is to compare Start.of.Rain..i., Start.of.Rain..ii. and
>>>> Start.of.Rain..iii. by plotting vertical line. I also need to add
>>>> points to the plot to be able to separate them. The x-axis must be
>>>> date column. Thanks!
>>>> 
>>>> Here is how the data look like and how I tried to make it.
>>>> 
>>>> 
>>>> 
>>>> Date Number.of.Rain.Days Total.rain Start.of.Rain..i.
>>>> Start.of.Rain..ii.
>>>> Start.of.Rain..iii. 1952-01-01 86 1139.952 92 239 11 1953-01-01 96
>>>> 977.646
>>>> 98 98 11 1954-01-01 114 1382.014 92 92 12 1955-01-01 119 1323.086 100
>>>> 100
>>>> 12 1956-01-01 123 1266.444 92 92 11 1957-01-01 124 1235.964 92 92 11
>>>> 
>>>> 
>>>> Here is how I tried to solve the problem.
>>>> 
>>>> df1 <-data.frame(data)
>>>> df1
>>>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>>>> df2
>>>> 
>>>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type =
>>>> "h")
>>>> 
>>>> Kindly any help is welcome. Thanks
>>>> 
>>>> Regards,
>>>> Frederic.
>>>> 
>>>> Frederic Ntirenganya
>>>> Maseno University,
>>>> African Maths Initiative,
>>>> Kenya.
>>>> Mobile:(+254)718492836
>>>> Email: fredo at aims.ac.za
>>>> https://sites.google.com/a/aims.ac.za/fredo/
>>>> 
>>>> On Tue, Mar 31, 2015 at 9:24 AM, Jeff Newmiller <
>>>> jdnewmil at dcn.davis.ca.us> wrote:
>>>> 
>>>>> This is no better because (a) you are still posting using HTML
>>>>> format,
>>>>> and (b) using printed output loses the internal representation of the
>>>>> data.
>>>>> The dput function is very helpful for solving this. [1]
>>>>> 
>>>>> [1]
>>>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>>> 
>>>>> ---------------------------------------------------------------------------
>>>>> Jeff Newmiller                        The     .....       .....  Go
>>>>> Live...
>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>>> Go...
>>>>>                                       Live:   OO#.. Dead: OO#..
>>>>> Playing
>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>>> rocks...1k
>>>>> 
>>>>> ---------------------------------------------------------------------------
>>>>> Sent from my phone. Please excuse my brevity.
>>>>> 
>>>>> On March 30, 2015 10:56:48 PM PDT, Frederic Ntirenganya <
>>>>> ntfredo at gmail.com> wrote:
>>>>> >Hi Stephen,
>>>>>> 
>>>>> >Sorry, the data came in bad way.
>>>>> >Here is the head of the data.
>>>>>> 
>>>>>>> head(data)        Date Number.of.Rain.Days Total.rain
>>>>> >Start.of.Rain..i. Start.of.Rain..ii. Start.of.Rain..iii.
>>>>> >Start.Rain..iv.
>>>>> >1 1952-01-01                  86   1139.952                92
>>>>>>      239                 112             112
>>>>> >2 1953-01-01                  96    977.646                98
>>>>>>       98                 112             112
>>>>> >3 1954-01-01                 114   1382.014                92
>>>>>>       92                 120             120
>>>>> >4 1955-01-01                 119   1323.086               100
>>>>>>      100                 125             174
>>>>> >5 1956-01-01                 123   1266.444                92
>>>>>>       92                 119             119
>>>>> >6 1957-01-01                 124   1235.964                92
>>>>>>       92                 112             112
>>>>>> 
>>>>>> 
>>>>>> 
>>>>> >Frederic Ntirenganya
>>>>> >Maseno University,
>>>>> >African Maths Initiative,
>>>>> >Kenya.
>>>>> >Mobile:(+254)718492836
>>>>> >Email: fredo at aims.ac.za
>>>>> >https://sites.google.com/a/aims.ac.za/fredo/
>>>>>> 
>>>>> >On Mon, Mar 30, 2015 at 5:34 PM, stephen sefick <ssefick at gmail.com>
>>>>> >wrote:
>>>>>> 
>>>>>>> Hi Frederic,
>>>>>>> 
>>>>>>> Can you provide a minimal reproducible example including either
>>>>>>> real
>>>>> >data
>>>>>>> (dput), or simulated data that mimics your situation? This will
>>>>>>> allow
>>>>> >more
>>>>>>> people to help.
>>>>>>> 
>>>>>>> Stephen
>>>>>>> 
>>>>>>> On Mon, Mar 30, 2015 at 8:39 AM, Frederic Ntirenganya
>>>>> ><ntfredo at gmail.com>
>>>>>>> wrote:
>>>>>>> 
>>>>>>>> Dear All,
>>>>>>>> 
>>>>>>>> I want to plot multiple using ggplot function from a data frame of
>>>>>>>> many columns. I want to plot only str1, str2 and str3 and I failed
>>>>> >to
>>>>>>>> make it. What I want is to compare str1, str2 and str3 by plotting
>>>>>>>> vertical line. I also need to add points to the plot to be able to
>>>>>>>> separate them.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Here is how the data look like and how I tried to make it.
>>>>>>>> 
>>>>>>>> Date NumberofRaindays TotalRains str1 str2 str3 1/1/1952 86 1360.5
>>>>> >92 120
>>>>>>>> 112 1/1/1953 96 1100 98 100 110
>>>>>>>> ...                                           ....
>>>>>>>> ....             ...              ....            ....
>>>>>>>> 
>>>>>>>> df1 <-data.frame(data)
>>>>>>>> df1
>>>>>>>> df2 <- melt(df1 ,  id = 'Date', variable_name = 'start of Rains')
>>>>>>>> df2
>>>>>>>> 
>>>>>>>> ggplot(df2, aes(Date,value)) + geom_line(aes(colour ="red"),type =
>>>>> >"h")
>>>>>>>> 
>>>>>>>> Kindly any help is welcome. Thanks
>>>>>>>> 
>>>>>>>> Regards,
>>>>>>>> Frederic.
>>>>>>>> 
>>>>>>>> Frederic Ntirenganya
>>>>>>>> Maseno University,
>>>>>>>> African Maths Initiative,
>>>>>>>> Kenya.
>>>>>>>> Mobile:(+254)718492836
>>>>>>>> Email: fredo at aims.ac.za
>>>>>>>> https://sites.google.com/a/aims.ac.za/fredo/
>>>>>>>> 
>>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> --
>>>>>>> Stephen Sefick
>>>>>>> **************************************************
>>>>>>> Auburn University
>>>>>>> Biological Sciences
>>>>>>> 331 Funchess Hall
>>>>>>> Auburn, Alabama
>>>>>>> 36849
>>>>>>> **************************************************
>>>>>>> sas0025 at auburn.edu
>>>>>>> http://www.auburn.edu/~sas0025
>>>>>>> **************************************************
>>>>>>> 
>>>>>>> Let's not spend our time and resources thinking about things that
>>>>>>> are
>>>>> >so
>>>>>>> little or so large that all they really do for us is puff us up and
>>>>> >make us
>>>>>>> feel like gods.  We are mammals, and have not exhausted the
>>>>>>> annoying
>>>>> >little
>>>>>>> problems of being mammals.
>>>>>>> 
>>>>>>>                                 -K. Mullis
>>>>>>> 
>>>>>>> "A big computer, a complex algorithm and a long time does not equal
>>>>>>> science."
>>>>>>> 
>>>>>>>                               -Robert Gentleman
>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>>       [[alternative HTML version deleted]]
>>>>>> 
>>>>> >______________________________________________
>>>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> >PLEASE do read the posting guide
>>>>> >http://www.R-project.org/posting-guide.html
>>>>> >and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> 
>>>> 
>>> 
>>> 
>>> --
>>> Stephen Sefick
>>> **************************************************
>>> Auburn University
>>> Biological Sciences
>>> 331 Funchess Hall
>>> Auburn, Alabama
>>> 36849
>>> **************************************************
>>> sas0025 at auburn.edu
>>> http://www.auburn.edu/~sas0025
>>> **************************************************
>>> 
>>> Let's not spend our time and resources thinking about things that are
>>> so
>>> little or so large that all they really do for us is puff us up and
>>> make us
>>> feel like gods.  We are mammals, and have not exhausted the annoying
>>> little
>>> problems of being mammals.
>>> 
>>>                                 -K. Mullis
>>> 
>>> "A big computer, a complex algorithm and a long time does not equal
>>> science."
>>> 
>>>                               -Robert Gentleman
>>> 
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jrkrideau at inbox.com  Tue Mar 31 17:11:28 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 31 Mar 2015 07:11:28 -0800
Subject: [R] data.frame: data-driven column selections that vary by row??
In-Reply-To: <20150330135059.GL1250@albert.catwhisker.org>
Message-ID: <9990A6ED67E.000007F3jrkrideau@inbox.com>

I think we need some data and code 
Reproducibility
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example



John Kane
Kingston ON Canada


> -----Original Message-----
> From: r at catwhisker.org
> Sent: Mon, 30 Mar 2015 06:50:59 -0700
> To: r-help at r-project.org
> Subject: [R] data.frame: data-driven column selections that vary by row??
> 
> Sorry if that's confusing: I'm probably confused. :-(
> 
> I am collecting and trying to analyze data regarding performance of
> computer systems.
> 
> After extracting the data from its repository, I have created and
> used a Perl script to generate a (relatively) simple CSV, each
> record of which contains:
> * a POSIXct timestamp
> * a hostname
> * a collection of metrics for the interval identified by the timestamp,
>   and specific to the host in question, as well as some factors to
>   group the hosts (e.g., whether it's in a "control" vs. a "test"
>   group; a broad categorization of how the host is provisioned; which
>   version of the software it was running at the time...).  (Each
>   metric and factor is in a uniquely-named column.)
> 
> As extracted from the repository, there were several records for each
> such hostname/timestamp pair -- e.g., there would be separate records
> for:
> * Input bandwidth utilization for network interface 1
> * Output bandwidth utilization for network interface 1
> * Input bandwidth utilization for network interface 2
> * Output bandwidth utilization for network interface 2
> 
> (And the same field would be used for each of these -- the
> interpretation being driven by the content of other fields in teh
> record.)
> 
> Working with the data as described (immediately) above directly in R
> seemed... daunting, at best: thus the excursion into Perl.
> 
> And for some of the data, what I have works well enough.
> 
> But now I also want to analyze information from disk drives, and things
> get messy (as far as I can see).
> 
> First, each disk drive has a collection of 17 metrics (such as
> "busy_pct", "kb_per_transfer_read", and "transfers_per_second_write"),
> as well as a factor ("dev_type").  Each also has a device name that is
> unique within the host where it resides (e.g. "da1", "da2", "da3"....).
> (The "dev_type" factor identifies whether the drive is a solid-state
> device or a spinning disk.)
> 
> I have thus made the corresponding columns unique by pasting the drive
> name and the name of the metric (or factor), separating the two with
> "_" (e.g. "da7_busy_pct"; "ada0_mb_per_second_write";
> "ada4_queue_length").  I am not certain that's the best thing I could
> have done -- and I'm open to changing the approach.
> 
> The challenge for me is that different (classes of) machines are
> provisioned differently; some consequennces of that:
> * While da1 may be a spinning disk on host A, that has no bearing on
>   whether or not the "da1" on host B is a spinning disk or an SSD.
> * Host C may not even have a "da1" device.
> * Host D may be of a type that normally has a "da1," but in this case,
>   the drive has failed and has been disabled (so host D won't report
>   anything about "da1").
> 
> (I'm not too bothered about the "non-reporting" case, but cite it so we
> all know about it.)
> 
> I expect I will want to be using groupings:
> * All disk devices -- this one is easy.
> * All SSD devices (excluding spinning disks).
> * All spinning disks (excluding SSDs).
> 
> I'm having trouble with the latter two (though, certainly, if I solve
> one, the other is also solved).
> 
> Also, for some  of the metrics, I will want to sum them; for others,
> I will want to do other things -- find minima or maxima, or average
> them.  So pre-calculating such aggregates in the Perl script isn't
> something that appeals to me.
> 
> Finally (as far as complications go), I'm trying to write the code in
> such a way that if we deploy a new configuration of machine that has
> (say) twice as many drives as the biggest one we presently deploy, the
> code Just Works -- I shouldn't need to update the code merely to adapt
> to another hardware configuration.
> 
> I have been able to write a function that takes the data.frame obtained
> by reading the above-cited CSV, and generates a data.frame with a row
> for each host, and depicts the "dev_type" for each device for that host;
> here's an abbreviated (and slightly redacted) copy of its output to
> illustrate some of the above:
> 
>        ada0 ada1 ada2 ada3 ada4 ada5 da30 da31 da32 da33 da34 da35 da36
> da3
> host_A  ssd  ssd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd
> hdd
> host_B  ssd  ssd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd  hdd
> hdd
> host_G  ssd  ssd  ssd  ssd  ssd  ssd
> ssd
> host_H  ssd  ssd  ssd  ssd  ssd  ssd
> ssd
> host_M  ssd  ssd  ssd  ssd  ssd  ssd
> ssd
> host_N  ssd  ssd  ssd  ssd  ssd  ssd
> ssd
> 
> (That function is written with the explicit assumption(!) that for the
> period covered by a given set of input data, a given host's
> configuration remains static: we won't have drives changing type
> mid-stream.)
> 
> So the point of this lengthy(!) note is to ask if there's a
> somewhat-sane way to be able to group the metrics for the "ssd" devices
> (for example), given the above.
> 
> (So far, the least obnoxious way that comes to mind is to actually
> create 2 columns for each device metric: one for the device if it's an
> "ssd";l the other for "hdd" -- so instead of columns such as:
> * da3_busy_pct
> * da3_dev_type
> * da3_kb_per_transfer_read
> * da36_cam_timeouts
> * da36_dev_type
> * da36_mb_per_second_read
> 
> I would have:
> * da3_hdd_busy_pct
> * da3_ssd_busy_pct
> * da3_hdd_dev_type
> * da3_ssd_dev_type
> * da3_hdd_kb_per_transfer_read
> * da3_ssd_kb_per_transfer_read
> * da36_hdd_cam_timeouts
> * da36_ssd_cam_timeouts
> * da36_hdd_dev_type
> * da36_ssd_dev_type
> * da36_hdd_mb_per_second_read
> * da36_ssd_mb_per_second_read
> 
> and no more than half of those would actually be populated (depending on
> the content of "dev_type" when the Perl script is creating the CSV).
> 
> That seems rather hackish, though.
> 
> Thank you in advance for any insight.
> 
> Peace,
> david
> --
> David H. Wolfskill				r at catwhisker.org
> Those who murder in the name of God or prophet are blasphemous cowards.
> 
> See http://www.catwhisker.org/~david/publickey.gpg for my public key.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From kw1958 at gmail.com  Tue Mar 31 17:40:14 2015
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Tue, 31 Mar 2015 11:40:14 -0400
Subject: [R] Debug package options
In-Reply-To: <5519905E.3030604@gmail.com>
References: <FD1CBB1B-9061-4754-A6D4-2515EC511C63@gmail.com>
	<5519905E.3030604@gmail.com>
Message-ID: <6013E810-600D-4D6A-A3D5-B59B073A161A@gmail.com>

Duncan,
Thanks for the help.

Since I am the only person using this machine and I couldn?t figure out where to put the option statement aside from:
    C:\Program Files\R\R-3.1.2\etc
In the file Rprofile.site

The option that I wanted was:
options(debug.font = "Consolas 12?)

Which allowed me to have the right size font and Tk window to be able to do debugging using the debug package.

In case you are interested I use Windows 7 on my Mac via Parallels.

Thanks again,
Best,
KW



> On Mar 30, 2015, at 2:05 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 30/03/2015 1:50 PM, Keith S Weintraub wrote:
>> Folks,
>> 
>> I would like change some of the options for the Tk window that pops up when using the debug package.
>> 
>> I know how to change the options: e.g. options(debug.font = "Courier 12 italic?).
>> 
>> Is there a way to ?preset? these in my environment so when debug starts up I have all the options set up the way I want them?
>> 
>> Do I do this in a .First file? Does the .First file have to load the debug package every time I start up R?
>> 
>> No need to do my work for me. Just point me to the right doc.
> 
> See the ?Startup help topic.  You probably want to use one of the
> profile files rather than .First, because .First needs to be in a
> workspace, and you shouldn't be loading a workspace every time.
> 
> Duncan Murdoch


From desta_yo at yahoo.com  Tue Mar 31 18:08:56 2015
From: desta_yo at yahoo.com (Desta Yoseph)
Date: Tue, 31 Mar 2015 16:08:56 +0000 (UTC)
Subject: [R] Calculating Kendall's tau
Message-ID: <86655573.2601510.1427818136642.JavaMail.yahoo@mail.yahoo.com>

I am analyzing trend ?using Mann-kendall ?test for 31 independent sample, each sample ?have 34 years dataset. ?I supposed to find Kendall ?tau? for each sample. The data is arranged in column wise (I attached ?the data).To find Kendall tau, I wrote R script as:
? ? ?desta<-read.csv("rainfall.csv", header=T, sep=",")? ? ?require(Kendall)? ? ? ? ? ? ? MK<-function(y) {? ? ? ? ? ? ? ? ?nc<-ncol(y)? ? ? ? ? ? ? ? ?MannKendalltau<- numeric(nc)? ? ? ? ? ? ? ? ?for(i in 2:nc){? ? ? ? ? ? ? ? ? ? ? ? ? MannKendalltau[i]<-MannKendall(y[,i])?????????? }????? ??????MannKendalltau??? }? ? MK(desta)
The ?displayed result showed ?both ?tau?? and ?2-sided p-value?in unorganized way. ?But, I want only ?tau? value that is presented in organized ?manner. Anyone can tell me how can I get orderly displayed ??tau? value? here is my sample result:?? ? ?[[1]][1] 0
[[2]][1] 0.4352941attr(,"Csingle")[1] TRUE
[[3]][1] 0.5462185attr(,"Csingle")[1] TRUE
[[4]][1] 0.4218487attr(,"Csingle")[1] TRUE....Thank you for your guidance?

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Mar 31 18:14:13 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 31 Mar 2015 09:14:13 -0700
Subject: [R] Calculating Kendall's tau
In-Reply-To: <86655573.2601510.1427818136642.JavaMail.yahoo@mail.yahoo.com>
References: <86655573.2601510.1427818136642.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CACk-te1uajV6L6cdwG9Yn6NzASOfSmwbFyuzgx0unBeGsE-ciw@mail.gmail.com>

This sounds like homework. Homework is discouraged on this list (but
you might get lucky).

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Mar 31, 2015 at 9:08 AM, Desta Yoseph via R-help
<r-help at r-project.org> wrote:
> I am analyzing trend  using Mann-kendall  test for 31 independent sample, each sample  have 34 years dataset.  I supposed to find Kendall ?tau? for each sample. The data is arranged in column wise (I attached  the data).To find Kendall tau, I wrote R script as:
>      desta<-read.csv("rainfall.csv", header=T, sep=",")     require(Kendall)              MK<-function(y) {                 nc<-ncol(y)                 MannKendalltau<- numeric(nc)                 for(i in 2:nc){                          MannKendalltau[i]<-MannKendall(y[,i])           }            MannKendalltau    }    MK(desta)
> The  displayed result showed  both ?tau?  and ?2-sided p-value?in unorganized way.  But, I want only ?tau? value that is presented in organized  manner. Anyone can tell me how can I get orderly displayed  ?tau? value? here is my sample result:      [[1]][1] 0
> [[2]][1] 0.4352941attr(,"Csingle")[1] TRUE
> [[3]][1] 0.5462185attr(,"Csingle")[1] TRUE
> [[4]][1] 0.4218487attr(,"Csingle")[1] TRUE....Thank you for your guidance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Mar 31 18:31:19 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 31 Mar 2015 09:31:19 -0700
Subject: [R] Error in lm() with very small (close to zero) regressor
In-Reply-To: <1427803833418-4705328.post@n4.nabble.com>
References: <1427499146685-4705185.post@n4.nabble.com>
	<1427803833418-4705328.post@n4.nabble.com>
Message-ID: <CAF8bMcZRBfXeV1hpRriYOCOZzDBqNGznnxMmwJZkmddY0u9b6Q@mail.gmail.com>

If you really want your coefficient estimates to be scale-equivariant you
should test those methods for such a thing.  E.g., here are functions that
let you check how scaling one predictor affects the estimated coefficients
- they should give the same results for any scale factor.

f <-
function (scale=1, n=100, data=data.frame(Y=seq_len(n),
X1=sqrt(seq_len(n)), X2=log(seq_len(n))))
{
    cf <- coef(lm(data=data, Y ~ X1 + I(X2/scale)))
    cf * c(1, 1, 1/scale)
}
g <-
function (scale=1, n=100, data=data.frame(Y=seq_len(n),
X1=sqrt(seq_len(n)), X2=log(seq_len(n))))
{
    cf <- coef(fastLm(data=data, Y ~ X1 + I(X2/scale), method=4))
    cf * c(1, 1, 1/scale)
}
h <-
function (scale=1, n=100, data=data.frame(Y=seq_len(n),
X1=sqrt(seq_len(n)), X2=log(seq_len(n))))
{
    cf <- coef(fastLm(data=data, Y ~ X1 + I(X2/scale), method=5))
    cf * c(1, 1, 1/scale)
}

See how they compare for scale factors between 10^-15 and 10^15.  lm() is
looking pretty good.
> options(digits=4)
> scale <- 10 ^ seq(-15,15,by=5)
> sapply(scale, f)
               [,1]    [,2]    [,3]    [,4]    [,5]    [,6]    [,7]
(Intercept)  -9.393  -9.393  -9.393  -9.393  -9.393  -9.393  -9.393
X1           19.955  19.955  19.955  19.955  19.955  19.955  19.955
I(X2/scale) -20.372 -20.372 -20.372 -20.372 -20.372 -20.372 -20.372
> sapply(scale, g)
                 [,1]    [,2]    [,3]    [,4]    [,5]    [,6]       [,7]
(Intercept) 0.000e+00  -9.393  -9.393  -9.393  -9.393  -9.393 -3.126e+01
X1          2.772e-29  19.955  19.955  19.955  19.955  19.955  1.218e+01
I(X2/scale) 1.474e+01 -20.372 -20.372 -20.372 -20.372 -20.372 -2.892e-29
> sapply(scale, h)
                 [,1]      [,2]    [,3]    [,4]    [,5]       [,6]
[,7]
(Intercept) 0.000e+00 3.807e-20  -9.395  -9.393  -9.393 -3.126e+01
-3.126e+01
X1          2.945e-29 2.772e-19  19.954  19.955  19.955  1.218e+01
 1.218e+01
I(X2/scale) 1.474e+01 1.474e+01 -20.369 -20.372 -20.372 -2.892e-19
 6.596e-30



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Mar 31, 2015 at 5:10 AM, RiGui <raluca.gui at business.uzh.ch> wrote:

> I found a fix to my problem using the fastLm() from package RcppEigen,
> using
> the Jacobi singular value decomposition (SVD) (method 4) or a method based
> on the eigenvalue-eigenvector decomposition of X'X - method 5 of the fastLm
> function
>
>
>
> install.packages("RcppEigen")
> library(RcppEigen)
>
> n_obs <- 1500
> y  <- rnorm(n_obs, 10,2.89)
> x1 <- rnorm(n_obs, 0.00000000000001235657,0.000000000000000045)
> x2 <- rnorm(n_obs, 10,3.21)
> X  <- cbind(x1,x2)
>
>
>
> bFE <- fastLm(y ~ x1 + x2, method =4)
> bFE
>
> Call:
> fastLm.formula(formula = y ~ x1 + x2, method = 4)
>
> Coefficients:
>         (Intercept)                  x1                  x2
> 9.94832839474159414 0.00000000000012293 0.00440078989949841
>
>
> Best,
>
> Raluca
>
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Error-in-lm-with-very-small-close-to-zero-regressor-tp4705185p4705328.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Mar 31 18:32:22 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 31 Mar 2015 09:32:22 -0700
Subject: [R] Calculating Kendall's tau
In-Reply-To: <1772509796.2649745.1427819085500.JavaMail.yahoo@mail.yahoo.com>
References: <CACk-te1uajV6L6cdwG9Yn6NzASOfSmwbFyuzgx0unBeGsE-ciw@mail.gmail.com>
	<1772509796.2649745.1427819085500.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CACk-te19EUc1ynpY_NKdcEjqVodXVa9CE1V4ecoREC2HGRFkpA@mail.gmail.com>

OK.

But always reply to the list (which I am ccing here) so that everyone
knows -- and re-submit your OP in **PLAIN TEXT**, not html, as this is
a plain text  list and html typically garbles everything.

Also, reading and following the posting guide (see end of this email)
generally improves your chance of getting useful help.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Mar 31, 2015 at 9:24 AM, Desta Yoseph <desta_yo at yahoo.com> wrote:
> Dear Bert,
> It is not homework. Actually my real work is for 10,360 sample data. But if
> some one showed me for 31 sample dataset, i can manage for large sample
> data.
> hopefully this give you few hint why i really want  someone help.
> cheers
>
>
>
> On Tuesday, March 31, 2015 6:14 PM, Bert Gunter <gunter.berton at gene.com>
> wrote:
>
>
> This sounds like homework. Homework is discouraged on this list (but
> you might get lucky).
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Tue, Mar 31, 2015 at 9:08 AM, Desta Yoseph via R-help
> <r-help at r-project.org> wrote:
>> I am analyzing trend  using Mann-kendall  test for 31 independent sample,
>> each sample  have 34 years dataset.  I supposed to find Kendall ?tau? for
>> each sample. The data is arranged in column wise (I attached  the data).To
>> find Kendall tau, I wrote R script as:
>>      desta<-read.csv("rainfall.csv", header=T, sep=",")
>> require(Kendall)              MK<-function(y) {                nc<-ncol(y)
>> MannKendalltau<- numeric(nc)                for(i in 2:nc){
>> MannKendalltau[i]<-MannKendall(y[,i])          }            MannKendalltau
>> }    MK(desta)
>> The  displayed result showed  both ?tau?  and ?2-sided p-value?in
>> unorganized way.  But, I want only ?tau? value that is presented in
>> organized  manner. Anyone can tell me how can I get orderly displayed  ?tau?
>> value? here is my sample result:      [[1]][1] 0
>> [[2]][1] 0.4352941attr(,"Csingle")[1] TRUE
>> [[3]][1] 0.5462185attr(,"Csingle")[1] TRUE
>> [[4]][1] 0.4218487attr(,"Csingle")[1] TRUE....Thank you for your guidance
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From r-help at mmmmarascio.xyz  Tue Mar 31 17:38:39 2015
From: r-help at mmmmarascio.xyz (r-help at mmmmarascio.xyz)
Date: Tue, 31 Mar 2015 08:38:39 -0700
Subject: [R] changing column labels for data frames inside a list
Message-ID: <20150331153839.lyd1f5Jw%r-help@mmmmarascio.xyz>

> Date: Mon, 30 Mar 2015 09:54:39 -0400
> From: Vikram Chhatre <crypticlineage at gmail.com>
> To: r-help at r-project.org
> Subject: [R] changing column labels for data frames inside a list
> Message-ID:
>         <CAJZnH0=uGay_1VzjVTMMc=FweydKDJxm_TPi4hZO-ArDZTr1eQ at mail.gmai
> Content-Type: text/plain; charset="UTF-8"
>
> > summary(mygenfreqt)
>                   Length Class  Mode
> dat1.str 59220  -none- numeric
> dat2.str 59220  -none- numeric
> dat3.str 59220  -none- numeric
>
> > head(mylist[[1]])
>            1     2     3     4     5     6     7     8     9    10
>  12
> L0001.1 0.60 0.500 0.325 0.675 0.600 0.500 0.500 0.375 0.550 0.475 0.3
> 0.275
> L0001.2 0.40 0.500 0.675 0.325 0.400 0.500 0.500 0.625 0.450 0.525 0.6
> 0.725
>
> I want to change 1:12 to pop1:pop12
>
> mylist<- lapply(mylist, function(e) colnames(e) <- paste0('pop',1:12))
>
> What this is doing is replacing the data frames with just names
> pop1:pop12.  I just want to replace the column labels.
>
> Thanks for any suggestions.

Some readers have already replied, but here is another option that exploits lapply()'s "..." parameter.  First, we make a reproducible example.

(lista <- list(mtcars, mtcars))

Now, we get the unique number of columns of the data frames in the variable "lista".

(n.cols <- unique(sapply(lista, ncol)))

Finally, we call lapply() and `colnames<-` to change the column names of both data frames in "lista".  See lapply()'s "..." parameter (?lapply).

(lista <- lapply(X = lista, FUN = `colnames<-`, paste0("pop", seq_len(n.cols))))

>         [[alternative HTML version deleted]]


From jvadams at usgs.gov  Tue Mar 31 19:04:33 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 31 Mar 2015 12:04:33 -0500
Subject: [R] how to deal with changing weighting functions
In-Reply-To: <AEB16B1613D44C4793A7E6B6986B7A12F536BD9C@EX10-LIVE-MBN2.ad.kent.ac.uk>
References: <AEB16B1613D44C4793A7E6B6986B7A12F536BD9C@EX10-LIVE-MBN2.ad.kent.ac.uk>
Message-ID: <CAN5YmCFWA822nvGtshk7Xj64P7s67kQBXuYiYetc233k=biD5g@mail.gmail.com>

Can you give a concrete simple example of inputs with expected results?  Is
phi a function?  Of omega 1 and 2?  Is the summation over everything
through V_d-k?

On Mon, Mar 30, 2015 at 2:58 PM, T.Riedle <tr206 at kent.ac.uk> wrote:

> Hi everybody,
> Does anybody have an idea how I can generate tau according to the attached
> formula? The point is that phi changes with k and I thought I could make it
> by using a for-function in R but I am not sure how to do that.
>
> Could anyone help me?
> Thanks in advance.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kevin.thorpe at utoronto.ca  Tue Mar 31 19:05:15 2015
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 31 Mar 2015 13:05:15 -0400
Subject: [R] Randomly interleaving data frames while preserving order
Message-ID: <551AD3CB.6070401@utoronto.ca>

Hello.

I am trying to simulate recruitment in a randomized trial. Suppose I 
have three streams (strata) of patients represented by these data frames.

df1 <- data.frame(strat=rep(1,10),id=1:10,pid=1001:1010)
df2 <- data.frame(strat=rep(2,10),id=1:10,pid=2001:2010)
df3 <- data.frame(strat=rep(3,10),id=1:10,pid=3001:3010)

What I need to do is construct a data frame with all of these combined 
where the order of selection from one of the three data frames is 
randomized but once a stratum is selected patients are selected 
sequentially from that data frame.

To see what I'm looking to achieve, suppose the first five subjects were 
to come, in order, from strata (data frames) 1, 2, 1, 3 and 2. The 
expected result should look like this:

rbind(df1[1,],df2[1,],df1[2,],df3[1,],df2[2,])
    strat id  pid
1      1  1 1001
2      2  1 2001
21     1  2 1002
4      3  1 3001
22     2  2 2002

I hope what I'm trying to accomplish makes sense. Maybe I'm missing 
something obvious, but I really have no idea at the moment how to 
achieve this elegantly. Since I need to simulate many trial recruitments 
it needs to be general and compact.

I appreciate any advice.

Kevin

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From r at catwhisker.org  Tue Mar 31 19:22:09 2015
From: r at catwhisker.org (David Wolfskill)
Date: Tue, 31 Mar 2015 10:22:09 -0700
Subject: [R] data.frame: data-driven column selections that vary by row??
In-Reply-To: <9990A6ED67E.000007F3jrkrideau@inbox.com>
References: <20150330135059.GL1250@albert.catwhisker.org>
	<9990A6ED67E.000007F3jrkrideau@inbox.com>
Message-ID: <20150331172209.GW1250@albert.catwhisker.org>

On Tue, Mar 31, 2015 at 07:11:28AM -0800, John Kane wrote:
> I think we need some data and code 
> Reproducibility
> https://github.com/hadley/devtools/wiki/Reproducibility
>  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ....

I apologize for failing to provide that.

Here is a quite small subset of the data (with a few edits to reduce
excess verbosity in names of things) that still illustrates the
challenge I perceive:

> dput(bw)
structure(list(timestamp = c(1426892400L, 1426892400L, 1426892400L, 
1426892400L, 1426892400L, 1426892400L, 1426892460L, 1426892460L, 
1426892460L, 1426892460L, 1426892460L, 1426892460L, 1426892520L, 
1426892520L, 1426892520L, 1426892520L, 1426892520L, 1426892520L
), hostname = c("c001", "c002", "c021", "c022", "c041", "c051", 
"c001", "c002", "c021", "c022", "c041", "c051", "c001", "c002", 
"c021", "c022", "c041", "c051"), health = c(0.0549374999999983, 
0.250585416666667, 1, 1, 0.577784167075767, 0.546805261621527, 
0.1599375, 0.24954375, 1, 1, 0.582307554123614, 0.558298168996525, 
0.2813125, 0.270877083333333, 1, 1, 0.579231349457365, 0.542973020177151
), hw = c(1.9, 1.9, 1.4, 1.4, 1.5, 1.5, 1.9, 1.9, 1.4, 1.4, 1.5, 
1.5, 1.9, 1.9, 1.4, 1.4, 1.5, 1.5), fw = structure(c(1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L
), .Label = "2015Q1.2", class = "factor"), role = structure(c(1L, 
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
2L), .Label = c("control", "test"), class = "factor"), type = structure(c(3L, 
3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 
2L), .Label = c("D", "F", "H"), class = "factor"), da20_busy_pct = c(79.1, 
62.8, NA, NA, NA, NA, 75, 64.8, NA, NA, NA, NA, 72.2, 74.5, NA, 
NA, NA, NA), da20_dev_type = structure(c(2L, 2L, 1L, 1L, 1L, 
1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L), .Label = c("", 
"hdd"), class = "factor"), da20_kb_per_xfer_read = c(727.23, 
665.81, NA, NA, NA, NA, 737.04, 691.38, NA, NA, NA, NA, 721.71, 
668.96, NA, NA, NA, NA), da20_kb_per_xfer_write = c(0, 0, NA, 
NA, NA, NA, 0, 0, NA, NA, NA, NA, 0, 0, NA, NA, NA, NA), da20_mb_per_sec_read = c(39.77, 
31.21, NA, NA, NA, NA, 36.71, 32.41, NA, NA, NA, NA, 35.94, 37.24, 
NA, NA, NA, NA), da20_mb_per_sec_write = c(0, 0, NA, NA, NA, 
NA, 0, 0, NA, NA, NA, NA, 0, 0, NA, NA, NA, NA), da20_ms_per_xactn_read = c(43.5, 
31.6, NA, NA, NA, NA, 35.7, 30.2, NA, NA, NA, NA, 32.7, 34.6, 
NA, NA, NA, NA), da20_ms_per_xactn_write = c(0, 0, NA, NA, NA, 
NA, 0, 0, NA, NA, NA, NA, 0, 0, NA, NA, NA, NA), da20_Q_length = c(0, 
0, NA, NA, NA, NA, 2, 0, NA, NA, NA, NA, 1, 1, NA, NA, NA, NA
), da20_xfers_per_sec_other = c(0, 0, NA, NA, NA, NA, 0, 0, NA, 
NA, NA, NA, 0, 0, NA, NA, NA, NA), da20_xfers_per_sec_read = c(56, 
48, NA, NA, NA, NA, 51, 48, NA, NA, NA, NA, 51, 57, NA, NA, NA, 
NA), da20_xfers_per_sec_write = c(0, 0, NA, NA, NA, NA, 0, 0, 
NA, NA, NA, NA, 0, 0, NA, NA, NA, NA), da2_busy_pct = c(84.5, 
81.8, 29.5, 26.7, 55.5, 50.9, 80.6, 79.7, 29.2, 27.3, 58.8, 50.2, 
74.6, 79.3, 29.4, 26.6, 55.4, 50.1), da2_dev_type = structure(c(2L, 
2L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 
3L), .Label = c("", "hdd", "ssd"), class = "factor"), da2_kb_per_xfer_read = c(690.67, 
686.63, 613.78, 587, 571.64, 553.27, 692.26, 660.05, 612.01, 
594.28, 560.16, 566.41, 672.68, 670.25, 604.64, 592.16, 565.02, 
564.43), da2_kb_per_xfer_write = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0), da2_mb_per_sec_read = c(44.52, 41.57, 
134.26, 120.38, 252.88, 229.09, 41.24, 39.96, 132.68, 123.61, 
268.04, 227.34, 37.44, 39.93, 133.45, 120.28, 251.06, 225.99), 
    da2_mb_per_sec_write = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
    0, 0, 0, 0, 0, 0, 0), da2_ms_per_xactn_read = c(49.1, 47.8, 
    2, 1.8, 2.6, 2.4, 40.3, 43.9, 2, 1.8, 2.8, 2.4, 37.1, 40.9, 
    1.9, 1.8, 2.6, 2.4), da2_ms_per_xactn_write = c(0, 0, 0, 
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), da2_Q_length = c(0, 
    2, 0, 1, 3, 0, 3, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 3), da2_xfers_per_sec_other = c(0, 
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), da2_xfers_per_sec_read = c(66, 
    62, 224, 210, 453, 424, 61, 62, 222, 213, 490, 411, 57, 61, 
    226, 208, 455, 410), da2_xfers_per_sec_write = c(0, 0, 0, 
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)), .Names = c("timestamp", 
"hostname", "health", "hw", "fw", "role", "type", "da20_busy_pct", 
"da20_dev_type", "da20_kb_per_xfer_read", "da20_kb_per_xfer_write", 
"da20_mb_per_sec_read", "da20_mb_per_sec_write", "da20_ms_per_xactn_read", 
"da20_ms_per_xactn_write", "da20_Q_length", "da20_xfers_per_sec_other", 
"da20_xfers_per_sec_read", "da20_xfers_per_sec_write", "da2_busy_pct", 
"da2_dev_type", "da2_kb_per_xfer_read", "da2_kb_per_xfer_write", 
"da2_mb_per_sec_read", "da2_mb_per_sec_write", "da2_ms_per_xactn_read", 
"da2_ms_per_xactn_write", "da2_Q_length", "da2_xfers_per_sec_other", 
"da2_xfers_per_sec_read", "da2_xfers_per_sec_write"), class = "data.frame", row.names = c(1L, 
2L, 7L, 8L, 13L, 16L, 19L, 20L, 25L, 26L, 31L, 34L, 37L, 38L, 
43L, 44L, 49L, 52L))
> dim(bw)
[1] 18 31

(In the current case, there are a few more columns per device, as
well as about 40 more devices -- and thousands of rows -- represented
in the data.)

For reference (as well):
> version
               _                                          
platform       i386-portbld-freebsd10.1                   
arch           i386                                       
os             freebsd10.1                                
system         i386, freebsd10.1                          
status         Patched                                    
major          3                                          
minor          0.2                                        
year           2013                                       
month          11                                         
day            12                                         
svn rev        64207                                      
language       R                                          
version.string R version 3.0.2 Patched (2013-11-12 r64207)
nickname       Frisbee Sailing                            
> 

[BTW: the first link cited (above) is now a redirect to
<http://adv-r.had.co.nz/Reproducibility.html>.]

Peace,
david
-- 
David H. Wolfskill				r at catwhisker.org
Those who murder in the name of God or prophet are blasphemous cowards.

See http://www.catwhisker.org/~david/publickey.gpg for my public key.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 949 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150331/0f006ce0/attachment.bin>

From sarah.goslee at gmail.com  Tue Mar 31 19:41:26 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 31 Mar 2015 13:41:26 -0400
Subject: [R] Randomly interleaving data frames while preserving order
In-Reply-To: <551AD3CB.6070401@utoronto.ca>
References: <551AD3CB.6070401@utoronto.ca>
Message-ID: <CAM_vjumAjdZMSV1_WP+fE59ogeTo6uaUg2Dgp8a169CSCcFobg@mail.gmail.com>

That's a fun one. Here's one possible approach. (Note that it can be
done without using a loop, but I find that a loop here increases
readability.)

I wrote it to work on a list of data frames. If the selection is
random, I'd set it up so that size is passed to the function, but
selection is generated within the function using sample().

recruitment <- function(dflist, selection) {
    results <- data.frame(matrix(NA, nrow=length(selection),
ncol=ncol(dflist[[1]])))
    colnames(results) <- colnames(dflist[[1]])
    for(i in unique(selection)) {
        results[selection == i, ] <- dflist[[i]][seq_len(sum(selection == i)),]
    }
    results
}


# and your example:


df1 <- data.frame(strat=rep(1,10),id=1:10,pid=1001:1010)
df2 <- data.frame(strat=rep(2,10),id=1:10,pid=2001:2010)
df3 <- data.frame(strat=rep(3,10),id=1:10,pid=3001:3010)

touse <- c(1, 2, 1, 3, 1) # could be generated using sample

dfall <- list(df1, df2, df3)

touse <- c(1, 2, 1, 3, 1)
# could be generated using sample given the size argument
# touse <- sample(seq_along(dfall), size=5, replace=TRUE)

> recruitment(dfall, touse)
  strat id  pid
1     1  1 1001
2     2  1 2001
3     1  2 1002
4     3  1 3001
5     1  3 1003

Sarah

On Tue, Mar 31, 2015 at 1:05 PM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> Hello.
>
> I am trying to simulate recruitment in a randomized trial. Suppose I have
> three streams (strata) of patients represented by these data frames.
>
> df1 <- data.frame(strat=rep(1,10),id=1:10,pid=1001:1010)
> df2 <- data.frame(strat=rep(2,10),id=1:10,pid=2001:2010)
> df3 <- data.frame(strat=rep(3,10),id=1:10,pid=3001:3010)
>
> What I need to do is construct a data frame with all of these combined where
> the order of selection from one of the three data frames is randomized but
> once a stratum is selected patients are selected sequentially from that data
> frame.
>
> To see what I'm looking to achieve, suppose the first five subjects were to
> come, in order, from strata (data frames) 1, 2, 1, 3 and 2. The expected
> result should look like this:
>
> rbind(df1[1,],df2[1,],df1[2,],df3[1,],df2[2,])
>    strat id  pid
> 1      1  1 1001
> 2      2  1 2001
> 21     1  2 1002
> 4      3  1 3001
> 22     2  2 2002
>
> I hope what I'm trying to accomplish makes sense. Maybe I'm missing
> something obvious, but I really have no idea at the moment how to achieve
> this elegantly. Since I need to simulate many trial recruitments it needs to
> be general and compact.
>
> I appreciate any advice.
>
> Kevin
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From murdoch.duncan at gmail.com  Tue Mar 31 19:44:47 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 31 Mar 2015 13:44:47 -0400
Subject: [R] Randomly interleaving data frames while preserving order
In-Reply-To: <551AD3CB.6070401@utoronto.ca>
References: <551AD3CB.6070401@utoronto.ca>
Message-ID: <551ADD0F.1030006@gmail.com>

On 31/03/2015 1:05 PM, Kevin E. Thorpe wrote:
> Hello.
> 
> I am trying to simulate recruitment in a randomized trial. Suppose I 
> have three streams (strata) of patients represented by these data frames.
> 
> df1 <- data.frame(strat=rep(1,10),id=1:10,pid=1001:1010)
> df2 <- data.frame(strat=rep(2,10),id=1:10,pid=2001:2010)
> df3 <- data.frame(strat=rep(3,10),id=1:10,pid=3001:3010)
> 
> What I need to do is construct a data frame with all of these combined 
> where the order of selection from one of the three data frames is 
> randomized but once a stratum is selected patients are selected 
> sequentially from that data frame.
> 
> To see what I'm looking to achieve, suppose the first five subjects were 
> to come, in order, from strata (data frames) 1, 2, 1, 3 and 2. The 
> expected result should look like this:
> 
> rbind(df1[1,],df2[1,],df1[2,],df3[1,],df2[2,])
>     strat id  pid
> 1      1  1 1001
> 2      2  1 2001
> 21     1  2 1002
> 4      3  1 3001
> 22     2  2 2002
> 
> I hope what I'm trying to accomplish makes sense. Maybe I'm missing 
> something obvious, but I really have no idea at the moment how to 
> achieve this elegantly. Since I need to simulate many trial recruitments 
> it needs to be general and compact.
> 
> I appreciate any advice.

How about something like this:

# Permute an ordered vector of selections:
sel <- sample(c(rep(1, nrow(df1)), rep(2, nrow(df2)), rep(3, nrow(df3))))

# Create an empty dataframe to hold the results
df <- data.frame(strat=NA, id=NA, pid=NA)[rep(1, length(sel)),]

# Put the original dataframes into the appropriate slots:
df[sel == 1,] <- df1
df[sel == 2,] <- df2
df[sel == 3,] <- df3

# Clean up the rownames
rownames(df) <- NULL

Duncan Murdoch


From sarah.goslee at gmail.com  Tue Mar 31 19:46:03 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 31 Mar 2015 13:46:03 -0400
Subject: [R] idiom for constructing data frame
Message-ID: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>

Hi folks,

I KNOW there has to be a way to do this more elegantly, but I
consistently fail to come up with it, as I was just reminded while
writing an example for a query on this list.

What's a nifty way to construct a data frame of a given size? The only
way I know of it to use matrix(), eg

data.frame(matrix(NA, nrow=10, ncol=3))

and then to set the colnames in a second step.

This comes up a lot when pre-allocated a data frame before using a
loop: I know the size and column names, but want an empty structure to
fill later.

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Tue Mar 31 19:52:12 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 31 Mar 2015 13:52:12 -0400
Subject: [R] idiom for constructing data frame
In-Reply-To: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
References: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
Message-ID: <CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>

I just snagged this from Duncan Murdoch's reply to the same question:

# Create an empty dataframe to hold the results
df <- data.frame(strat=NA, id=NA, pid=NA)[rep(1, length(sel)),]

This skips matrix(), but how to set the column names programmatically
within a function?

Sarah, still sure I'm missing something obvious


On Tue, Mar 31, 2015 at 1:46 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> Hi folks,
>
> I KNOW there has to be a way to do this more elegantly, but I
> consistently fail to come up with it, as I was just reminded while
> writing an example for a query on this list.
>
> What's a nifty way to construct a data frame of a given size? The only
> way I know of it to use matrix(), eg
>
> data.frame(matrix(NA, nrow=10, ncol=3))
>
> and then to set the colnames in a second step.
>
> This comes up a lot when pre-allocated a data frame before using a
> loop: I know the size and column names, but want an empty structure to
> fill later.
>
> Sarah
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From kevin.thorpe at utoronto.ca  Tue Mar 31 19:52:35 2015
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 31 Mar 2015 13:52:35 -0400
Subject: [R] Randomly interleaving data frames while preserving order
In-Reply-To: <551ADD0F.1030006@gmail.com>
References: <551AD3CB.6070401@utoronto.ca> <551ADD0F.1030006@gmail.com>
Message-ID: <551ADEE3.8040808@utoronto.ca>

On 03/31/2015 01:44 PM, Duncan Murdoch wrote:
> On 31/03/2015 1:05 PM, Kevin E. Thorpe wrote:
>> Hello.
>>
>> I am trying to simulate recruitment in a randomized trial. Suppose I
>> have three streams (strata) of patients represented by these data frames.
>>
>> df1 <- data.frame(strat=rep(1,10),id=1:10,pid=1001:1010)
>> df2 <- data.frame(strat=rep(2,10),id=1:10,pid=2001:2010)
>> df3 <- data.frame(strat=rep(3,10),id=1:10,pid=3001:3010)
>>
>> What I need to do is construct a data frame with all of these combined
>> where the order of selection from one of the three data frames is
>> randomized but once a stratum is selected patients are selected
>> sequentially from that data frame.
>>
>> To see what I'm looking to achieve, suppose the first five subjects were
>> to come, in order, from strata (data frames) 1, 2, 1, 3 and 2. The
>> expected result should look like this:
>>
>> rbind(df1[1,],df2[1,],df1[2,],df3[1,],df2[2,])
>>      strat id  pid
>> 1      1  1 1001
>> 2      2  1 2001
>> 21     1  2 1002
>> 4      3  1 3001
>> 22     2  2 2002
>>
>> I hope what I'm trying to accomplish makes sense. Maybe I'm missing
>> something obvious, but I really have no idea at the moment how to
>> achieve this elegantly. Since I need to simulate many trial recruitments
>> it needs to be general and compact.
>>
>> I appreciate any advice.
>
> How about something like this:
>
> # Permute an ordered vector of selections:
> sel <- sample(c(rep(1, nrow(df1)), rep(2, nrow(df2)), rep(3, nrow(df3))))
>
> # Create an empty dataframe to hold the results
> df <- data.frame(strat=NA, id=NA, pid=NA)[rep(1, length(sel)),]
>
> # Put the original dataframes into the appropriate slots:
> df[sel == 1,] <- df1
> df[sel == 2,] <- df2
> df[sel == 3,] <- df3
>
> # Clean up the rownames
> rownames(df) <- NULL
>
> Duncan Murdoch
>

Thanks Duncan.

Once you see the solution it is indeed obvious.

Kevin

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From tom at maladmin.com  Tue Mar 31 19:59:56 2015
From: tom at maladmin.com (Tom Wright)
Date: Tue, 31 Mar 2015 13:59:56 -0400
Subject: [R] Randomly interleaving data frames while preserving order
In-Reply-To: <551AD3CB.6070401@utoronto.ca>
References: <551AD3CB.6070401@utoronto.ca>
Message-ID: <1427824796.3658.7.camel@maladmin.com>

samples<-sample(c(rep(1,10),rep(2,10),rep(3,10)),30)
samples[samples==1]<-1001:1010
samples[samples==2]<-2001:2010
samples[samples==3]<-3001:3010

fullDf<-rbind(df1,df2,df3)

fullDf[sort(order(samples),index.return=TRUE)$ix,]

On Tue, 2015-03-31 at 13:05 -0400, Kevin E. Thorpe wrote:
> Hello.
> 
> I am trying to simulate recruitment in a randomized trial. Suppose I 
> have three streams (strata) of patients represented by these data frames.
> 

> 
> What I need to do is construct a data frame with all of these combined 
> where the order of selection from one of the three data frames is 
> randomized but once a stratum is selected patients are selected 
> sequentially from that data frame.
> 
> To see what I'm looking to achieve, suppose the first five subjects were 
> to come, in order, from strata (data frames) 1, 2, 1, 3 and 2. The 
> expected result should look like this:
> 
> rbind(df1[1,],df2[1,],df1[2,],df3[1,],df2[2,])
>     strat id  pid
> 1      1  1 1001
> 2      2  1 2001
> 21     1  2 1002
> 4      3  1 3001
> 22     2  2 2002
> 
> I hope what I'm trying to accomplish makes sense. Maybe I'm missing 
> something obvious, but I really have no idea at the moment how to 
> achieve this elegantly. Since I need to simulate many trial recruitments 
> it needs to be general and compact.
> 
> I appreciate any advice.
> 
> Kevin
>


From murdoch.duncan at gmail.com  Tue Mar 31 20:03:02 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 31 Mar 2015 14:03:02 -0400
Subject: [R] idiom for constructing data frame
In-Reply-To: <CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>
References: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
	<CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>
Message-ID: <551AE156.8070206@gmail.com>

On 31/03/2015 1:52 PM, Sarah Goslee wrote:
> I just snagged this from Duncan Murdoch's reply to the same question:
>
> # Create an empty dataframe to hold the results
> df <- data.frame(strat=NA, id=NA, pid=NA)[rep(1, length(sel)),]
>
> This skips matrix(), but how to set the column names programmatically
> within a function?
>
> Sarah, still sure I'm missing something obvious

The matrix() function has a dimnames argument, so you could do this:

names <- c("strat", "id", "pid")
data.frame(matrix(NA, nrow=10, ncol=3, dimnames=list(NULL, names)))

Duncan Murdoch
>
>
> On Tue, Mar 31, 2015 at 1:46 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> > Hi folks,
> >
> > I KNOW there has to be a way to do this more elegantly, but I
> > consistently fail to come up with it, as I was just reminded while
> > writing an example for a query on this list.
> >
> > What's a nifty way to construct a data frame of a given size? The only
> > way I know of it to use matrix(), eg
> >
> > data.frame(matrix(NA, nrow=10, ncol=3))
> >
> > and then to set the colnames in a second step.
> >
> > This comes up a lot when pre-allocated a data frame before using a
> > loop: I know the size and column names, but want an empty structure to
> > fill later.
> >
> > Sarah
> >
>


From NordlDJ at dshs.wa.gov  Tue Mar 31 20:06:48 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 31 Mar 2015 18:06:48 +0000
Subject: [R] Randomly interleaving data frames while preserving order
In-Reply-To: <551ADEE3.8040808@utoronto.ca>
References: <551AD3CB.6070401@utoronto.ca> <551ADD0F.1030006@gmail.com>
	<551ADEE3.8040808@utoronto.ca>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276623B35723@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kevin
> E. Thorpe
> Sent: Tuesday, March 31, 2015 10:53 AM
> To: Duncan Murdoch
> Cc: R Help Mailing List
> Subject: Re: [R] Randomly interleaving data frames while preserving
> order
> 
> On 03/31/2015 01:44 PM, Duncan Murdoch wrote:
> > On 31/03/2015 1:05 PM, Kevin E. Thorpe wrote:
> >> Hello.
> >>
> >> I am trying to simulate recruitment in a randomized trial. Suppose I
> >> have three streams (strata) of patients represented by these data
> frames.
> >>
> >> df1 <- data.frame(strat=rep(1,10),id=1:10,pid=1001:1010)
> >> df2 <- data.frame(strat=rep(2,10),id=1:10,pid=2001:2010)
> >> df3 <- data.frame(strat=rep(3,10),id=1:10,pid=3001:3010)
> >>
> >> What I need to do is construct a data frame with all of these
> combined
> >> where the order of selection from one of the three data frames is
> >> randomized but once a stratum is selected patients are selected
> >> sequentially from that data frame.
> >>
> >> To see what I'm looking to achieve, suppose the first five subjects
> were
> >> to come, in order, from strata (data frames) 1, 2, 1, 3 and 2. The
> >> expected result should look like this:
> >>
> >> rbind(df1[1,],df2[1,],df1[2,],df3[1,],df2[2,])
> >>      strat id  pid
> >> 1      1  1 1001
> >> 2      2  1 2001
> >> 21     1  2 1002
> >> 4      3  1 3001
> >> 22     2  2 2002
> >>
> >> I hope what I'm trying to accomplish makes sense. Maybe I'm missing
> >> something obvious, but I really have no idea at the moment how to
> >> achieve this elegantly. Since I need to simulate many trial
> recruitments
> >> it needs to be general and compact.
> >>
> >> I appreciate any advice.
> >
> > How about something like this:
> >
> > # Permute an ordered vector of selections:
> > sel <- sample(c(rep(1, nrow(df1)), rep(2, nrow(df2)), rep(3,
> nrow(df3))))
> >
> > # Create an empty dataframe to hold the results
> > df <- data.frame(strat=NA, id=NA, pid=NA)[rep(1, length(sel)),]
> >
> > # Put the original dataframes into the appropriate slots:
> > df[sel == 1,] <- df1
> > df[sel == 2,] <- df2
> > df[sel == 3,] <- df3
> >
> > # Clean up the rownames
> > rownames(df) <- NULL
> >
> > Duncan Murdoch
> >
> 
> Thanks Duncan.
> 
> Once you see the solution it is indeed obvious.
> 
> Kevin
> 
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
> 

Another option would be to stack your strata and then sample from the combined data frame, something like this:

sample_size <- 10
population <- rbind(df1,df2,df3)
sim.sample <- pop[sample(nrow(pop),sample_size, replace=FALSE),]

Hope this is helpful,

Dan

Daniel J. Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services



From istazahn at gmail.com  Tue Mar 31 20:19:34 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 31 Mar 2015 14:19:34 -0400
Subject: [R] data.frame: data-driven column selections that vary by row??
In-Reply-To: <20150331172209.GW1250@albert.catwhisker.org>
References: <20150330135059.GL1250@albert.catwhisker.org>
	<9990A6ED67E.000007F3jrkrideau@inbox.com>
	<20150331172209.GW1250@albert.catwhisker.org>
Message-ID: <CA+vqiLEp7D2rvEWEDSVENgijKWnoBRBaNYkHmuv_R9u+Uo9hHw@mail.gmail.com>

Hi David,

I suggest reading http://www.jstatsoft.org/v59/i10, then:

library(tidyr)
library(dplyr)
bw <- gather(bw, key = "tmp", value = "value", matches("^d[a-z]+[0-9]+"))
bw <- separate(bw, tmp, c("disc", "var"), "_", extra = "merge")
bw <- spread(bw, var, value)

Best,
Ista

On Tue, Mar 31, 2015 at 1:22 PM, David Wolfskill <r at catwhisker.org> wrote:
> On Tue, Mar 31, 2015 at 07:11:28AM -0800, John Kane wrote:
>> I think we need some data and code
>> Reproducibility
>> https://github.com/hadley/devtools/wiki/Reproducibility
>>  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> ....
>
> I apologize for failing to provide that.
>
> Here is a quite small subset of the data (with a few edits to reduce
> excess verbosity in names of things) that still illustrates the
> challenge I perceive:
>
>> dput(bw)
> structure(list(timestamp = c(1426892400L, 1426892400L, 1426892400L,
> 1426892400L, 1426892400L, 1426892400L, 1426892460L, 1426892460L,
> 1426892460L, 1426892460L, 1426892460L, 1426892460L, 1426892520L,
> 1426892520L, 1426892520L, 1426892520L, 1426892520L, 1426892520L
> ), hostname = c("c001", "c002", "c021", "c022", "c041", "c051",
> "c001", "c002", "c021", "c022", "c041", "c051", "c001", "c002",
> "c021", "c022", "c041", "c051"), health = c(0.0549374999999983,
> 0.250585416666667, 1, 1, 0.577784167075767, 0.546805261621527,
> 0.1599375, 0.24954375, 1, 1, 0.582307554123614, 0.558298168996525,
> 0.2813125, 0.270877083333333, 1, 1, 0.579231349457365, 0.542973020177151
> ), hw = c(1.9, 1.9, 1.4, 1.4, 1.5, 1.5, 1.9, 1.9, 1.4, 1.4, 1.5,
> 1.5, 1.9, 1.9, 1.4, 1.4, 1.5, 1.5), fw = structure(c(1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L
> ), .Label = "2015Q1.2", class = "factor"), role = structure(c(1L,
> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
> 2L), .Label = c("control", "test"), class = "factor"), type = structure(c(3L,
> 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L,
> 2L), .Label = c("D", "F", "H"), class = "factor"), da20_busy_pct = c(79.1,
> 62.8, NA, NA, NA, NA, 75, 64.8, NA, NA, NA, NA, 72.2, 74.5, NA,
> NA, NA, NA), da20_dev_type = structure(c(2L, 2L, 1L, 1L, 1L,
> 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L), .Label = c("",
> "hdd"), class = "factor"), da20_kb_per_xfer_read = c(727.23,
> 665.81, NA, NA, NA, NA, 737.04, 691.38, NA, NA, NA, NA, 721.71,
> 668.96, NA, NA, NA, NA), da20_kb_per_xfer_write = c(0, 0, NA,
> NA, NA, NA, 0, 0, NA, NA, NA, NA, 0, 0, NA, NA, NA, NA), da20_mb_per_sec_read = c(39.77,
> 31.21, NA, NA, NA, NA, 36.71, 32.41, NA, NA, NA, NA, 35.94, 37.24,
> NA, NA, NA, NA), da20_mb_per_sec_write = c(0, 0, NA, NA, NA,
> NA, 0, 0, NA, NA, NA, NA, 0, 0, NA, NA, NA, NA), da20_ms_per_xactn_read = c(43.5,
> 31.6, NA, NA, NA, NA, 35.7, 30.2, NA, NA, NA, NA, 32.7, 34.6,
> NA, NA, NA, NA), da20_ms_per_xactn_write = c(0, 0, NA, NA, NA,
> NA, 0, 0, NA, NA, NA, NA, 0, 0, NA, NA, NA, NA), da20_Q_length = c(0,
> 0, NA, NA, NA, NA, 2, 0, NA, NA, NA, NA, 1, 1, NA, NA, NA, NA
> ), da20_xfers_per_sec_other = c(0, 0, NA, NA, NA, NA, 0, 0, NA,
> NA, NA, NA, 0, 0, NA, NA, NA, NA), da20_xfers_per_sec_read = c(56,
> 48, NA, NA, NA, NA, 51, 48, NA, NA, NA, NA, 51, 57, NA, NA, NA,
> NA), da20_xfers_per_sec_write = c(0, 0, NA, NA, NA, NA, 0, 0,
> NA, NA, NA, NA, 0, 0, NA, NA, NA, NA), da2_busy_pct = c(84.5,
> 81.8, 29.5, 26.7, 55.5, 50.9, 80.6, 79.7, 29.2, 27.3, 58.8, 50.2,
> 74.6, 79.3, 29.4, 26.6, 55.4, 50.1), da2_dev_type = structure(c(2L,
> 2L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L,
> 3L), .Label = c("", "hdd", "ssd"), class = "factor"), da2_kb_per_xfer_read = c(690.67,
> 686.63, 613.78, 587, 571.64, 553.27, 692.26, 660.05, 612.01,
> 594.28, 560.16, 566.41, 672.68, 670.25, 604.64, 592.16, 565.02,
> 564.43), da2_kb_per_xfer_write = c(0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0), da2_mb_per_sec_read = c(44.52, 41.57,
> 134.26, 120.38, 252.88, 229.09, 41.24, 39.96, 132.68, 123.61,
> 268.04, 227.34, 37.44, 39.93, 133.45, 120.28, 251.06, 225.99),
>     da2_mb_per_sec_write = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>     0, 0, 0, 0, 0, 0, 0), da2_ms_per_xactn_read = c(49.1, 47.8,
>     2, 1.8, 2.6, 2.4, 40.3, 43.9, 2, 1.8, 2.8, 2.4, 37.1, 40.9,
>     1.9, 1.8, 2.6, 2.4), da2_ms_per_xactn_write = c(0, 0, 0,
>     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), da2_Q_length = c(0,
>     2, 0, 1, 3, 0, 3, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 3), da2_xfers_per_sec_other = c(0,
>     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), da2_xfers_per_sec_read = c(66,
>     62, 224, 210, 453, 424, 61, 62, 222, 213, 490, 411, 57, 61,
>     226, 208, 455, 410), da2_xfers_per_sec_write = c(0, 0, 0,
>     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)), .Names = c("timestamp",
> "hostname", "health", "hw", "fw", "role", "type", "da20_busy_pct",
> "da20_dev_type", "da20_kb_per_xfer_read", "da20_kb_per_xfer_write",
> "da20_mb_per_sec_read", "da20_mb_per_sec_write", "da20_ms_per_xactn_read",
> "da20_ms_per_xactn_write", "da20_Q_length", "da20_xfers_per_sec_other",
> "da20_xfers_per_sec_read", "da20_xfers_per_sec_write", "da2_busy_pct",
> "da2_dev_type", "da2_kb_per_xfer_read", "da2_kb_per_xfer_write",
> "da2_mb_per_sec_read", "da2_mb_per_sec_write", "da2_ms_per_xactn_read",
> "da2_ms_per_xactn_write", "da2_Q_length", "da2_xfers_per_sec_other",
> "da2_xfers_per_sec_read", "da2_xfers_per_sec_write"), class = "data.frame", row.names = c(1L,
> 2L, 7L, 8L, 13L, 16L, 19L, 20L, 25L, 26L, 31L, 34L, 37L, 38L,
> 43L, 44L, 49L, 52L))
>> dim(bw)
> [1] 18 31
>
> (In the current case, there are a few more columns per device, as
> well as about 40 more devices -- and thousands of rows -- represented
> in the data.)
>
> For reference (as well):
>> version
>                _
> platform       i386-portbld-freebsd10.1
> arch           i386
> os             freebsd10.1
> system         i386, freebsd10.1
> status         Patched
> major          3
> minor          0.2
> year           2013
> month          11
> day            12
> svn rev        64207
> language       R
> version.string R version 3.0.2 Patched (2013-11-12 r64207)
> nickname       Frisbee Sailing
>>
>
> [BTW: the first link cited (above) is now a redirect to
> <http://adv-r.had.co.nz/Reproducibility.html>.]
>
> Peace,
> david
> --
> David H. Wolfskill                              r at catwhisker.org
> Those who murder in the name of God or prophet are blasphemous cowards.
>
> See http://www.catwhisker.org/~david/publickey.gpg for my public key.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tom at maladmin.com  Tue Mar 31 20:31:40 2015
From: tom at maladmin.com (Tom Wright)
Date: Tue, 31 Mar 2015 14:31:40 -0400
Subject: [R] data.frame: data-driven column selections that vary by row??
In-Reply-To: <20150331172209.GW1250@albert.catwhisker.org>
References: <20150330135059.GL1250@albert.catwhisker.org>
	<9990A6ED67E.000007F3jrkrideau@inbox.com>
	<20150331172209.GW1250@albert.catwhisker.org>
Message-ID: <1427826700.3658.12.camel@maladmin.com>

Not entirely sure I understand your problem here (your first email was a
lot of reading).

Would it make sense to add an extra column device_name

Thus ending up with something like:
Host	  Device  Type
host_A    ada0    ssd
host_A    ada1    ssd
host_A    ada2    hdd
...
host_N    da3     ssd


You could then subset this dataframe:
subset(data,Type=="ssd" & Device=="ada0")

On Tue, 2015-03-31 at 10:22 -0700, David Wolfskill wrote:
> On Tue, Mar 31, 2015 at 07:11:28AM -0800, John Kane wrote:
> > I think we need some data and code 
> > Reproducibility
> > https://github.com/hadley/devtools/wiki/Reproducibility
> >  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> > ....
> 
> I apologize for failing to provide that.
> 
> Here is a quite small subset of the data (with a few edits to reduce
> excess verbosity in names of things) that still illustrates the
> challenge I perceive:
> 
> > dput(bw)
> structure(list(timestamp = c(1426892400L, 1426892400L, 1426892400L, 
> 1426892400L, 1426892400L, 1426892400L, 1426892460L, 1426892460L, 
> 1426892460L, 1426892460L, 1426892460L, 1426892460L, 1426892520L, 
> 1426892520L, 1426892520L, 1426892520L, 1426892520L, 1426892520L
> ), hostname = c("c001", "c002", "c021", "c022", "c041", "c051", 
> "c001", "c002", "c021", "c022", "c041", "c051", "c001", "c002", 
> "c021", "c022", "c041", "c051"), health = c(0.0549374999999983, 
> 0.250585416666667, 1, 1, 0.577784167075767, 0.546805261621527, 
> 0.1599375, 0.24954375, 1, 1, 0.582307554123614, 0.558298168996525, 
> 0.2813125, 0.270877083333333, 1, 1, 0.579231349457365, 0.542973020177151
> ), hw = c(1.9, 1.9, 1.4, 1.4, 1.5, 1.5, 1.9, 1.9, 1.4, 1.4, 1.5, 
> 1.5, 1.9, 1.9, 1.4, 1.4, 1.5, 1.5), fw = structure(c(1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L
> ), .Label = "2015Q1.2", class = "factor"), role = structure(c(1L, 
> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
> 2L), .Label = c("control", "test"), class = "factor"), type = structure(c(3L, 
> 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 3L, 1L, 1L, 2L, 
> 2L), .Label = c("D", "F", "H"), class = "factor"), da20_busy_pct = c(79.1, 
> 62.8, NA, NA, NA, NA, 75, 64.8, NA, NA, NA, NA, 72.2, 74.5, NA, 
> NA, NA, NA), da20_dev_type = structure(c(2L, 2L, 1L, 1L, 1L, 
> 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L), .Label = c("", 
> "hdd"), class = "factor"), da20_kb_per_xfer_read = c(727.23, 
> 665.81, NA, NA, NA, NA, 737.04, 691.38, NA, NA, NA, NA, 721.71, 
> 668.96, NA, NA, NA, NA), da20_kb_per_xfer_write = c(0, 0, NA, 
> NA, NA, NA, 0, 0, NA, NA, NA, NA, 0, 0, NA, NA, NA, NA), da20_mb_per_sec_read = c(39.77, 
> 31.21, NA, NA, NA, NA, 36.71, 32.41, NA, NA, NA, NA, 35.94, 37.24, 
> NA, NA, NA, NA), da20_mb_per_sec_write = c(0, 0, NA, NA, NA, 
> NA, 0, 0, NA, NA, NA, NA, 0, 0, NA, NA, NA, NA), da20_ms_per_xactn_read = c(43.5, 
> 31.6, NA, NA, NA, NA, 35.7, 30.2, NA, NA, NA, NA, 32.7, 34.6, 
> NA, NA, NA, NA), da20_ms_per_xactn_write = c(0, 0, NA, NA, NA, 
> NA, 0, 0, NA, NA, NA, NA, 0, 0, NA, NA, NA, NA), da20_Q_length = c(0, 
> 0, NA, NA, NA, NA, 2, 0, NA, NA, NA, NA, 1, 1, NA, NA, NA, NA
> ), da20_xfers_per_sec_other = c(0, 0, NA, NA, NA, NA, 0, 0, NA, 
> NA, NA, NA, 0, 0, NA, NA, NA, NA), da20_xfers_per_sec_read = c(56, 
> 48, NA, NA, NA, NA, 51, 48, NA, NA, NA, NA, 51, 57, NA, NA, NA, 
> NA), da20_xfers_per_sec_write = c(0, 0, NA, NA, NA, NA, 0, 0, 
> NA, NA, NA, NA, 0, 0, NA, NA, NA, NA), da2_busy_pct = c(84.5, 
> 81.8, 29.5, 26.7, 55.5, 50.9, 80.6, 79.7, 29.2, 27.3, 58.8, 50.2, 
> 74.6, 79.3, 29.4, 26.6, 55.4, 50.1), da2_dev_type = structure(c(2L, 
> 2L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 
> 3L), .Label = c("", "hdd", "ssd"), class = "factor"), da2_kb_per_xfer_read = c(690.67, 
> 686.63, 613.78, 587, 571.64, 553.27, 692.26, 660.05, 612.01, 
> 594.28, 560.16, 566.41, 672.68, 670.25, 604.64, 592.16, 565.02, 
> 564.43), da2_kb_per_xfer_write = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 
> 0, 0, 0, 0, 0, 0, 0, 0, 0), da2_mb_per_sec_read = c(44.52, 41.57, 
> 134.26, 120.38, 252.88, 229.09, 41.24, 39.96, 132.68, 123.61, 
> 268.04, 227.34, 37.44, 39.93, 133.45, 120.28, 251.06, 225.99), 
>     da2_mb_per_sec_write = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
>     0, 0, 0, 0, 0, 0, 0), da2_ms_per_xactn_read = c(49.1, 47.8, 
>     2, 1.8, 2.6, 2.4, 40.3, 43.9, 2, 1.8, 2.8, 2.4, 37.1, 40.9, 
>     1.9, 1.8, 2.6, 2.4), da2_ms_per_xactn_write = c(0, 0, 0, 
>     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), da2_Q_length = c(0, 
>     2, 0, 1, 3, 0, 3, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 3), da2_xfers_per_sec_other = c(0, 
>     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), da2_xfers_per_sec_read = c(66, 
>     62, 224, 210, 453, 424, 61, 62, 222, 213, 490, 411, 57, 61, 
>     226, 208, 455, 410), da2_xfers_per_sec_write = c(0, 0, 0, 
>     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)), .Names = c("timestamp", 
> "hostname", "health", "hw", "fw", "role", "type", "da20_busy_pct", 
> "da20_dev_type", "da20_kb_per_xfer_read", "da20_kb_per_xfer_write", 
> "da20_mb_per_sec_read", "da20_mb_per_sec_write", "da20_ms_per_xactn_read", 
> "da20_ms_per_xactn_write", "da20_Q_length", "da20_xfers_per_sec_other", 
> "da20_xfers_per_sec_read", "da20_xfers_per_sec_write", "da2_busy_pct", 
> "da2_dev_type", "da2_kb_per_xfer_read", "da2_kb_per_xfer_write", 
> "da2_mb_per_sec_read", "da2_mb_per_sec_write", "da2_ms_per_xactn_read", 
> "da2_ms_per_xactn_write", "da2_Q_length", "da2_xfers_per_sec_other", 
> "da2_xfers_per_sec_read", "da2_xfers_per_sec_write"), class = "data.frame", row.names = c(1L, 
> 2L, 7L, 8L, 13L, 16L, 19L, 20L, 25L, 26L, 31L, 34L, 37L, 38L, 
> 43L, 44L, 49L, 52L))
> > dim(bw)
> [1] 18 31
> 
> (In the current case, there are a few more columns per device, as
> well as about 40 more devices -- and thousands of rows -- represented
> in the data.)
> 
> For reference (as well):
> > version
>                _                                          
> platform       i386-portbld-freebsd10.1                   
> arch           i386                                       
> os             freebsd10.1                                
> system         i386, freebsd10.1                          
> status         Patched                                    
> major          3                                          
> minor          0.2                                        
> year           2013                                       
> month          11                                         
> day            12                                         
> svn rev        64207                                      
> language       R                                          
> version.string R version 3.0.2 Patched (2013-11-12 r64207)
> nickname       Frisbee Sailing                            
> > 
> 
> [BTW: the first link cited (above) is now a redirect to
> <http://adv-r.had.co.nz/Reproducibility.html>.]
> 
> Peace,
> david
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tom at maladmin.com  Tue Mar 31 20:35:19 2015
From: tom at maladmin.com (Tom Wright)
Date: Tue, 31 Mar 2015 14:35:19 -0400
Subject: [R] data.frame: data-driven column selections that vary by row??
In-Reply-To: <CA+vqiLEp7D2rvEWEDSVENgijKWnoBRBaNYkHmuv_R9u+Uo9hHw@mail.gmail.com>
References: <20150330135059.GL1250@albert.catwhisker.org>
	<9990A6ED67E.000007F3jrkrideau@inbox.com>
	<20150331172209.GW1250@albert.catwhisker.org>
	<CA+vqiLEp7D2rvEWEDSVENgijKWnoBRBaNYkHmuv_R9u+Uo9hHw@mail.gmail.com>
Message-ID: <1427826919.3658.13.camel@maladmin.com>

Nice clean-up!!!

On Tue, 2015-03-31 at 14:19 -0400, Ista Zahn wrote:
> library(tidyr)
> library(dplyr)
> bw <- gather(bw, key = "tmp", value = "value",
> matches("^d[a-z]+[0-9]+"))
> bw <- separate(bw, tmp, c("disc", "var"), "_", extra = "merge")
> bw <- spread(bw, var, value)


From sarah.goslee at gmail.com  Tue Mar 31 20:37:03 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 31 Mar 2015 14:37:03 -0400
Subject: [R] idiom for constructing data frame
In-Reply-To: <551AE156.8070206@gmail.com>
References: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
	<CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>
	<551AE156.8070206@gmail.com>
Message-ID: <CAM_vjukjkkPBbGt3n12EeJL+yiOxgjJ3VvPFEk+w5r8uAX7mKw@mail.gmail.com>

Hi,

Duncan Murdoch suggested:

> The matrix() function has a dimnames argument, so you could do this:
>
> names <- c("strat", "id", "pid")
> data.frame(matrix(NA, nrow=10, ncol=3, dimnames=list(NULL, names)))

That's a definite improvement, thanks. But no way to skip matrix()? It
just seems unRlike, although since it's only full of NA values there
are no coercion issues with column types or anything, so it doesn't
hurt. It's just inelegant. :)

Sarah
-- 
Sarah Goslee
http://www.functionaldiversity.org


From laura.gianfagna at outlook.it  Tue Mar 31 18:39:59 2015
From: laura.gianfagna at outlook.it (Laura Gianfagna)
Date: Tue, 31 Mar 2015 16:39:59 +0000
Subject: [R] =?utf-8?q?Does_fitCopula_work_for_amhCopula_and_joeCopula=3F?=
Message-ID: <DUB407-EAS95CE8BE31F5717A220EBE8BF40@phx.gbl>

Good evening, this is a part of my Routine  which calculates the copula parameter and loglikelihood for each pair of rows of a data matrix, choosing, for each pair, the copula which gives the maximum likelihood. If I do my computation with this routine with only:


f <- frankCopula(2,2)
  g <- gumbelCopula(2,2)
  c <- claytonCopula(2,2)


the program works correctly and gives the expected results.

If  I insert also:


  a <- amhCopula(1,2)
  j <- joeCopula(2,2)


then the program doesn?t work anymore. 

I tried on samples such as:


n <- 1000
f <- frankCopula(20,2)
x_1 <- rCopula(n,f)
f <- gumbelCopula(50,2)
x_2 <- rCopula(n,f)
f <- joeCopula(70,2)
x_3<- rCopula(n,f)
x <- cbind(x_1, x_2, x_3)
data <- t(x)
dim <- dim(data)[1]





Here is the part of code of Routine_Copula:

Routine_Copula <- function(data,dim){
  
  library(copula)
  library(gtools)
  
  n <- dim(data)[1];  # number of rows of the input matrix
  m <- dim(data)[2];  # number of columns of the input matrix
  
  # Probability integral transform of the data
  ecdf <- matrix(0,n,m);
  for (i in 1:n){
    e <- matrix(data[i,],m,1);
    #ecdf[i,] <- pobs(e);
    ecdf[i,] <- pobs(e, na.last=TRUE);
    #na.last for controlling the treatment of NAs. If TRUE, missing values in the data are put last; if FALSE, they are put first; if NA, they are removed; if "keep" they are kept with rank NA.
    
  }



f <- frankCopula(2,2)
  g <- gumbelCopula(2,2)
  c <- claytonCopula(2,2)
  a <- amhCopula(1,2)
  j <- joeCopula(2,2)





[?.]


 for (j in 1:n_comb){
    input <- t(ecdf[comb[,j],])
    
    try(summary <- fitCopula(f,input,method='mpl',start=2),silent=TRUE);
    resmatpar[j,1] <- summary at estimate;
    resmatllk[j,1] <- summary at loglik;
    
    try(summary <- fitCopula(g,input,method='mpl',start=2),silent=TRUE);
    resmatpar[j,2] <- summary at estimate;
    resmatllk[j,2] <- summary at loglik;
    
    try(summary <- fitCopula(c,input,method='mpl',start=2),silent=TRUE);
    resmatpar[j,3] <- summary at estimate;
    resmatllk[j,3] <- summary at loglik;


try(summary <- fitCopula(a,input,method='mpl',start=1),silent=TRUE);
    resmatpar[j,4] <- summary at estimate;
     resmatllk[j,4] <- summary at loglik;
     
try(summary <- fitCopula(j,input,method='mpl',start=2),silent=TRUE);     

 resmatpar[j,5] <- summary at estimate;
resmatllk[j,5] <- summary at loglik;

d <- c(resmatllk[j,1],resmatllk[j,2],resmatllk[j,3],resmatllk[j,4],resmatllk[j,5]);


    
    copchoice[j] <- which(d==max(d));
    param[j] <- resmatpar[j,copchoice[j]];
    loglik[j] <- resmatllk[j,copchoice[j]];
    
  }


Thank you

Laura Gianfagna


?
	[[alternative HTML version deleted]]


From istazahn at gmail.com  Tue Mar 31 20:50:12 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 31 Mar 2015 14:50:12 -0400
Subject: [R] idiom for constructing data frame
In-Reply-To: <CAM_vjukjkkPBbGt3n12EeJL+yiOxgjJ3VvPFEk+w5r8uAX7mKw@mail.gmail.com>
References: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
	<CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>
	<551AE156.8070206@gmail.com>
	<CAM_vjukjkkPBbGt3n12EeJL+yiOxgjJ3VvPFEk+w5r8uAX7mKw@mail.gmail.com>
Message-ID: <CA+vqiLGpvKtdG85PbVtw7Z_zkWTnqVjZ3saPAwpX2_kAM2xn_Q@mail.gmail.com>

You can make it as elegant as you want, e.g.,

make.empty.df <- function(nrow,ncol, names) {
    if(length(names) %% ncol != 0) stop("Lenght of names is not a
multiple of the number of colums")
    data.frame(matrix(NA, nrow, ncol, dimnames = list(NULL, names)))
}


Best,
Ista

On Tue, Mar 31, 2015 at 2:37 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> Hi,
>
> Duncan Murdoch suggested:
>
>> The matrix() function has a dimnames argument, so you could do this:
>>
>> names <- c("strat", "id", "pid")
>> data.frame(matrix(NA, nrow=10, ncol=3, dimnames=list(NULL, names)))
>
> That's a definite improvement, thanks. But no way to skip matrix()? It
> just seems unRlike, although since it's only full of NA values there
> are no coercion issues with column types or anything, so it doesn't
> hurt. It's just inelegant. :)
>
> Sarah
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Mar 31 20:55:08 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 31 Mar 2015 11:55:08 -0700
Subject: [R] idiom for constructing data frame
In-Reply-To: <CAM_vjukjkkPBbGt3n12EeJL+yiOxgjJ3VvPFEk+w5r8uAX7mKw@mail.gmail.com>
References: <CAM_vjukgbVpGBYq5b5goCgS4RhEGDn4+Djxof9Zgm9dB2863Cg@mail.gmail.com>
	<CAM_vjuk4eK5=+7QepLPiQvFBz9s-9yu+XirMFTWFyLmoeVg7gQ@mail.gmail.com>
	<551AE156.8070206@gmail.com>
	<CAM_vjukjkkPBbGt3n12EeJL+yiOxgjJ3VvPFEk+w5r8uAX7mKw@mail.gmail.com>
Message-ID: <CAF8bMcY6n+ue7jDasUW4nLTuEu4eVRJNU1zsrg8yUysNPRe6YQ@mail.gmail.com>

You can use structure() to attach the names to a list that is input to
data.frame.
E.g.,

dfNames <- c("First", "Second Name")
data.frame(lapply(structure(dfNames, names=dfNames),
function(name)rep(NA_real_, 5)))


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Mar 31, 2015 at 11:37 AM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hi,
>
> Duncan Murdoch suggested:
>
> > The matrix() function has a dimnames argument, so you could do this:
> >
> > names <- c("strat", "id", "pid")
> > data.frame(matrix(NA, nrow=10, ncol=3, dimnames=list(NULL, names)))
>
> That's a definite improvement, thanks. But no way to skip matrix()? It
> just seems unRlike, although since it's only full of NA values there
> are no coercion issues with column types or anything, so it doesn't
> hurt. It's just inelegant. :)
>
> Sarah
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lkhodakarim at gmail.com  Tue Mar 31 21:18:33 2015
From: lkhodakarim at gmail.com (Soheila Khodakarim)
Date: Tue, 31 Mar 2015 22:48:33 +0330
Subject: [R] Fwd: non-conformable arguments
In-Reply-To: <CACYT75tu2HDpQFV6eBTca+7BRKvdqunALqeUVBWGuhvJhC-+Qg@mail.gmail.com>
References: <CACYT75tu2HDpQFV6eBTca+7BRKvdqunALqeUVBWGuhvJhC-+Qg@mail.gmail.com>
Message-ID: <CACYT75v43cC4DChX-H9R-5Lj8egu9iTWoBFLRBJc1n=eXL_N-w@mail.gmail.com>

Dear All,

I want to run neural network on my data.

i run these codes:

#load mydata
dim(mydata)
# 20 3111
library(neuralnet)
fm <- as.formula(paste("resp ~", paste(colnames(mydata)[1:3110],
collapse="+")))
out <- neuralnet(fm,data=mydata, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1)
#load testset
dim(testset)
# 20 3111
out.results <- compute(out, testset)
Error in neurons[[i]] %*% weights[[i]] : non-conformable arguments

what should I do now?

Regards,
Soheila

	[[alternative HTML version deleted]]


From wandrson01 at gmail.com  Tue Mar 31 21:51:12 2015
From: wandrson01 at gmail.com (Walter Anderson)
Date: Tue, 31 Mar 2015 14:51:12 -0500
Subject: [R] How to obtain a cross tab count of unique values
Message-ID: <551AFAB0.7000805@gmail.com>

I have a data frame that shows all of the parks (including duplicates)
that are impacted by a projects 'footprint':

PROJECT PARKNAME
A       PRK A
A       PRK B
A       PRK A
B       PRK C
B       PRK A
C       PRK B
C       PRK D
...

What I need is a cross tabulation that shows me the number of unique
parks for each project.  If I using the standard table(df$PROJECT) it
reports:

A 3
B 2
C 2
...

where I need it to ignore duplicates and report:

A 2
B 2
C 2
...

Anyone have any suggestions on how to do this within the R paradigm?

Walter Anderson


From sarah.goslee at gmail.com  Tue Mar 31 22:04:20 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 31 Mar 2015 16:04:20 -0400
Subject: [R] How to obtain a cross tab count of unique values
In-Reply-To: <551AFAB0.7000805@gmail.com>
References: <551AFAB0.7000805@gmail.com>
Message-ID: <CAM_vju=SG57Do9g1krTJ3nOzEEbThZTvRg52DnKOYTjFZacSEA@mail.gmail.com>

Sure: tell R you want unique rows.

> mydf <- data.frame(PROJECT=c("A","A","A","B","B","C","C"), PARKNAME=c("PRK A", "PRK B", "PRK A", "PRK C", "PRK A", "PRK B", "PRK D"), stringsAsFactors=FALSE)
> mydf
  PROJECT PARKNAME
1       A    PRK A
2       A    PRK B
3       A    PRK A
4       B    PRK C
5       B    PRK A
6       C    PRK B
7       C    PRK D

> mydf.unique <- unique(mydf)
> table(mydf.unique$PROJECT)

A B C
2 2 2

Please provide reproducible data yourself in the future.

Sarah

On Tue, Mar 31, 2015 at 3:51 PM, Walter Anderson <wandrson01 at gmail.com> wrote:
> I have a data frame that shows all of the parks (including duplicates)
> that are impacted by a projects 'footprint':
>
> PROJECT PARKNAME
> A       PRK A
> A       PRK B
> A       PRK A
> B       PRK C
> B       PRK A
> C       PRK B
> C       PRK D
> ...
>
> What I need is a cross tabulation that shows me the number of unique
> parks for each project.  If I using the standard table(df$PROJECT) it
> reports:
>
> A 3
> B 2
> C 2
> ...
>
> where I need it to ignore duplicates and report:
>
> A 2
> B 2
> C 2
> ...
>
> Anyone have any suggestions on how to do this within the R paradigm?
>
> Walter Anderson

-- 
Sarah Goslee
http://www.functionaldiversity.org


From ruipbarradas at sapo.pt  Tue Mar 31 22:40:49 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 31 Mar 2015 21:40:49 +0100
Subject: [R] How to obtain a cross tab count of unique values
In-Reply-To: <551AFAB0.7000805@gmail.com>
References: <551AFAB0.7000805@gmail.com>
Message-ID: <551B0651.8080906@sapo.pt>

Hello,

Try the following.

table(unique(df)$PROJECT)


And please note that 'df' is the name of an R function, use something else.

Hope this helps,

Rui Barradas

Em 31-03-2015 20:51, Walter Anderson escreveu:
> I have a data frame that shows all of the parks (including duplicates)
> that are impacted by a projects 'footprint':
>
> PROJECT PARKNAME
> A       PRK A
> A       PRK B
> A       PRK A
> B       PRK C
> B       PRK A
> C       PRK B
> C       PRK D
> ...
>
> What I need is a cross tabulation that shows me the number of unique
> parks for each project.  If I using the standard table(df$PROJECT) it
> reports:
>
> A 3
> B 2
> C 2
> ...
>
> where I need it to ignore duplicates and report:
>
> A 2
> B 2
> C 2
> ...
>
> Anyone have any suggestions on how to do this within the R paradigm?
>
> Walter Anderson
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tom at maladmin.com  Tue Mar 31 22:42:50 2015
From: tom at maladmin.com (Tom Wright)
Date: Tue, 31 Mar 2015 16:42:50 -0400
Subject: [R] How to obtain a cross tab count of unique values
In-Reply-To: <551AFAB0.7000805@gmail.com>
References: <551AFAB0.7000805@gmail.com>
Message-ID: <1427834570.3658.15.camel@maladmin.com>

table(unique(df)$PROJECT)

On Tue, 2015-03-31 at 14:51 -0500, Walter Anderson wrote:
> I have a data frame that shows all of the parks (including duplicates)
> that are impacted by a projects 'footprint':
> 
> PROJECT PARKNAME
> A       PRK A
> A       PRK B
> A       PRK A
> B       PRK C
> B       PRK A
> C       PRK B
> C       PRK D
> ...
> 
> What I need is a cross tabulation that shows me the number of unique
> parks for each project.  If I using the standard table(df$PROJECT) it
> reports:
> 
> A 3
> B 2
> C 2
> ...
> 
> where I need it to ignore duplicates and report:
> 
> A 2
> B 2
> C 2
> ...
> 
> Anyone have any suggestions on how to do this within the R paradigm?
> 
> Walter Anderson
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From angela.baldo at ARS.USDA.GOV  Tue Mar 31 22:19:49 2015
From: angela.baldo at ARS.USDA.GOV (a b)
Date: Tue, 31 Mar 2015 13:19:49 -0700 (PDT)
Subject: [R] Can not load Rcmdr
In-Reply-To: <1418399588968-4700714.post@n4.nabble.com>
References: <04735153FC67984B82384850D67AD6B92083DD85@SN2PRD0102MB156.prod.exchangelabs.com>
	<1358324274.2051.20.camel@milan> <516C6865.6000406@gmx.de>
	<web-453502593@cgpsrv2.cis.mcmaster.ca>
	<1418399588968-4700714.post@n4.nabble.com>
Message-ID: <1427833189081-4705370.post@n4.nabble.com>

I have a similar issue with tcl.

I am using R on a Linux server.  Rcmdr installed OK, but it won't run:

> R.Version()
$platform
[1] "x86_64-unknown-linux-gnu"

$arch
[1] "x86_64"

$os
[1] "linux-gnu"

$system
[1] "x86_64, linux-gnu"

$status
[1] ""

$major
[1] "3"

$minor
[1] "1.0"

$year
[1] "2014"

$month
[1] "04"

$day
[1] "10"

$`svn rev`
[1] "65387"

$language
[1] "R"

$version.string
[1] "R version 3.1.0 (2014-04-10)"

$nickname
[1] "Spring Dance"

> library(Rcmdr)
Error : .onAttach failed in attachNamespace() for 'Rcmdr', details:
  call: structure(.External(.C_dotTcl, ...), class = "tclObj")
  error: [tcl] Invalid state name hover.

Error: package or namespace load failed for 'Rcmdr'
> 


This is kind of frustrating because I don't have admin privileges to install
Rstudio on this server, either.  

I guess it's time to use Emacs.



--
View this message in context: http://r.789695.n4.nabble.com/Can-not-load-Rcmdr-tp4655656p4705370.html
Sent from the R help mailing list archive at Nabble.com.


From tr206 at kent.ac.uk  Tue Mar 31 22:47:49 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Tue, 31 Mar 2015 20:47:49 +0000
Subject: [R] Using matlab code in R
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A12F536C01C@EX10-LIVE-MBN2.ad.kent.ac.uk>

Hi everybody,
I have a matlab code which I would like to use for my empirical analysis. Unfortunately, I am not familiar with matlab and it would be great if there was a tool to "translate" the matlab code into R so that I can work with the code in R.
Is there such a tool or package in R?

Kind regards,
T.

	[[alternative HTML version deleted]]


From imdb.subscribe at gmail.com  Tue Mar 31 23:26:24 2015
From: imdb.subscribe at gmail.com (im db)
Date: Tue, 31 Mar 2015 21:26:24 +0000 (UTC)
Subject: [R] Calculating different PCAs in R
Message-ID: <1688822560.2389058.1427837184259.JavaMail.yahoo@mail.yahoo.com>

Dear All, I want to use princomp() function in R in order to calculate Principle Component Analysis.In different papers, I have seen "PCA 1", "PCA 2", "PCA 11" , etc. Would you please tell me how can i calculate different PCAs in R?At the moment i just use this line "eigenVectors <- pca$loadings"But I don?t know if it is correct to use loadings.Thank you in advance. ?Best regards,
Iman Dabbaghi

	[[alternative HTML version deleted]]


